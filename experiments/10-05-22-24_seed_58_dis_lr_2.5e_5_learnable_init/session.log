Train: Epoch [1/3000], Step [30/158]| g_loss: 52.784| d_loss: 1.998| gp_loss: 0.000| r_loss: 42.907| p_loss: 19.012| v_loss: 0.082| per_loss: 2.884 | a_loss: 0.000
Train: Epoch [1/3000], Step [60/158]| g_loss: 34.671| d_loss: 1.987| gp_loss: 0.000| r_loss: 28.489| p_loss: 11.620| v_loss: 0.079| per_loss: 2.923 | a_loss: 0.000
Train: Epoch [1/3000], Step [90/158]| g_loss: 23.213| d_loss: 1.944| gp_loss: 0.000| r_loss: 17.941| p_loss: 9.808| v_loss: 0.076| per_loss: 2.912 | a_loss: 0.000
Train: Epoch [1/3000], Step [120/158]| g_loss: 14.849| d_loss: 1.852| gp_loss: 0.000| r_loss: 9.913| p_loss: 9.139| v_loss: 0.071| per_loss: 2.945 | a_loss: 0.001
Train: Epoch [1/3000], Step [150/158]| g_loss: 9.082| d_loss: 1.742| gp_loss: 0.000| r_loss: 4.819| p_loss: 7.799| v_loss: 0.079| per_loss: 2.784 | a_loss: 0.006
Train: Epoch [2/3000], Step [30/158]| g_loss: 6.500| d_loss: 1.501| gp_loss: 0.000| r_loss: 2.602| p_loss: 7.018| v_loss: 0.076| per_loss: 2.775 | a_loss: 0.036
Train: Epoch [2/3000], Step [60/158]| g_loss: 5.644| d_loss: 1.198| gp_loss: 0.001| r_loss: 1.988| p_loss: 6.457| v_loss: 0.076| per_loss: 2.659 | a_loss: 0.086
Train: Epoch [2/3000], Step [90/158]| g_loss: 5.328| d_loss: 1.037| gp_loss: 0.001| r_loss: 1.798| p_loss: 6.073| v_loss: 0.081| per_loss: 2.632 | a_loss: 0.150
Train: Epoch [2/3000], Step [120/158]| g_loss: 5.331| d_loss: 1.135| gp_loss: 0.002| r_loss: 1.739| p_loss: 6.071| v_loss: 0.077| per_loss: 2.732 | a_loss: 0.207
Train: Epoch [2/3000], Step [150/158]| g_loss: 5.156| d_loss: 1.201| gp_loss: 0.002| r_loss: 1.699| p_loss: 5.845| v_loss: 0.081| per_loss: 2.684 | a_loss: 0.185
Train: Epoch [3/3000], Step [30/158]| g_loss: 4.921| d_loss: 1.176| gp_loss: 0.007| r_loss: 1.625| p_loss: 5.411| v_loss: 0.080| per_loss: 2.777 | a_loss: 0.233
Train: Epoch [3/3000], Step [60/158]| g_loss: 4.355| d_loss: 1.344| gp_loss: 0.003| r_loss: 1.562| p_loss: 4.569| v_loss: 0.077| per_loss: 2.778 | a_loss: 0.154
Train: Epoch [3/3000], Step [90/158]| g_loss: 4.198| d_loss: 1.338| gp_loss: 0.003| r_loss: 1.542| p_loss: 4.308| v_loss: 0.083| per_loss: 2.762 | a_loss: 0.143
Train: Epoch [3/3000], Step [120/158]| g_loss: 4.263| d_loss: 1.187| gp_loss: 0.003| r_loss: 1.504| p_loss: 4.458| v_loss: 0.082| per_loss: 2.721 | a_loss: 0.176
Train: Epoch [3/3000], Step [150/158]| g_loss: 4.069| d_loss: 1.198| gp_loss: 0.004| r_loss: 1.485| p_loss: 4.110| v_loss: 0.077| per_loss: 2.761 | a_loss: 0.176
Train: Epoch [4/3000], Step [30/158]| g_loss: 4.098| d_loss: 1.213| gp_loss: 0.009| r_loss: 1.493| p_loss: 4.110| v_loss: 0.080| per_loss: 2.696 | a_loss: 0.200
Train: Epoch [4/3000], Step [60/158]| g_loss: 3.819| d_loss: 1.104| gp_loss: 0.005| r_loss: 1.384| p_loss: 3.809| v_loss: 0.076| per_loss: 2.640 | a_loss: 0.190
Train: Epoch [4/3000], Step [90/158]| g_loss: 3.746| d_loss: 1.175| gp_loss: 0.005| r_loss: 1.384| p_loss: 3.677| v_loss: 0.085| per_loss: 2.616 | a_loss: 0.177
Train: Epoch [4/3000], Step [120/158]| g_loss: 3.685| d_loss: 1.213| gp_loss: 0.006| r_loss: 1.374| p_loss: 3.603| v_loss: 0.081| per_loss: 2.552 | a_loss: 0.173
Train: Epoch [4/3000], Step [150/158]| g_loss: 3.618| d_loss: 1.068| gp_loss: 0.006| r_loss: 1.368| p_loss: 3.422| v_loss: 0.080| per_loss: 2.500 | a_loss: 0.210
Train: Epoch [5/3000], Step [30/158]| g_loss: 3.632| d_loss: 1.082| gp_loss: 0.015| r_loss: 1.349| p_loss: 3.492| v_loss: 0.078| per_loss: 2.506 | a_loss: 0.209
Train: Epoch [5/3000], Step [60/158]| g_loss: 3.588| d_loss: 1.191| gp_loss: 0.008| r_loss: 1.332| p_loss: 3.372| v_loss: 0.083| per_loss: 2.455 | a_loss: 0.242
Train: Epoch [5/3000], Step [90/158]| g_loss: 3.475| d_loss: 1.183| gp_loss: 0.008| r_loss: 1.338| p_loss: 3.225| v_loss: 0.077| per_loss: 2.434 | a_loss: 0.203
Train: Epoch [5/3000], Step [120/158]| g_loss: 3.290| d_loss: 0.943| gp_loss: 0.008| r_loss: 1.237| p_loss: 3.008| v_loss: 0.079| per_loss: 2.398 | a_loss: 0.230
Train: Epoch [5/3000], Step [150/158]| g_loss: 3.455| d_loss: 1.116| gp_loss: 0.009| r_loss: 1.324| p_loss: 3.148| v_loss: 0.080| per_loss: 2.328 | a_loss: 0.245
Train: Epoch [6/3000], Step [30/158]| g_loss: 3.332| d_loss: 0.903| gp_loss: 0.022| r_loss: 1.285| p_loss: 2.838| v_loss: 0.080| per_loss: 2.320 | a_loss: 0.315
Train: Epoch [6/3000], Step [60/158]| g_loss: 3.298| d_loss: 1.166| gp_loss: 0.009| r_loss: 1.268| p_loss: 2.921| v_loss: 0.081| per_loss: 2.277 | a_loss: 0.261
Train: Epoch [6/3000], Step [90/158]| g_loss: 3.413| d_loss: 0.946| gp_loss: 0.009| r_loss: 1.317| p_loss: 2.946| v_loss: 0.081| per_loss: 2.250 | a_loss: 0.317
Train: Epoch [6/3000], Step [120/158]| g_loss: 3.353| d_loss: 0.983| gp_loss: 0.010| r_loss: 1.308| p_loss: 2.912| v_loss: 0.079| per_loss: 2.222 | a_loss: 0.287
Train: Epoch [6/3000], Step [150/158]| g_loss: 3.493| d_loss: 0.854| gp_loss: 0.010| r_loss: 1.282| p_loss: 3.058| v_loss: 0.087| per_loss: 2.183 | a_loss: 0.378
Train: Epoch [7/3000], Step [30/158]| g_loss: 3.513| d_loss: 0.822| gp_loss: 0.017| r_loss: 1.337| p_loss: 2.864| v_loss: 0.081| per_loss: 2.203 | a_loss: 0.442
Train: Epoch [7/3000], Step [60/158]| g_loss: 3.273| d_loss: 0.924| gp_loss: 0.007| r_loss: 1.291| p_loss: 2.683| v_loss: 0.085| per_loss: 2.261 | a_loss: 0.330
Train: Epoch [7/3000], Step [90/158]| g_loss: 3.323| d_loss: 0.816| gp_loss: 0.007| r_loss: 1.279| p_loss: 2.573| v_loss: 0.086| per_loss: 2.171 | a_loss: 0.455
Train: Epoch [7/3000], Step [120/158]| g_loss: 3.152| d_loss: 0.798| gp_loss: 0.007| r_loss: 1.239| p_loss: 2.357| v_loss: 0.082| per_loss: 2.171 | a_loss: 0.437
Train: Epoch [7/3000], Step [150/158]| g_loss: 3.175| d_loss: 0.772| gp_loss: 0.007| r_loss: 1.222| p_loss: 2.466| v_loss: 0.084| per_loss: 2.172 | a_loss: 0.420
Train: Epoch [8/3000], Step [30/158]| g_loss: 3.324| d_loss: 0.736| gp_loss: 0.020| r_loss: 1.248| p_loss: 2.565| v_loss: 0.086| per_loss: 2.254 | a_loss: 0.482
Train: Epoch [8/3000], Step [60/158]| g_loss: 3.327| d_loss: 0.804| gp_loss: 0.009| r_loss: 1.231| p_loss: 2.605| v_loss: 0.084| per_loss: 2.254 | a_loss: 0.483
Train: Epoch [8/3000], Step [90/158]| g_loss: 3.319| d_loss: 0.821| gp_loss: 0.008| r_loss: 1.250| p_loss: 2.542| v_loss: 0.083| per_loss: 2.310 | a_loss: 0.483
Train: Epoch [8/3000], Step [120/158]| g_loss: 3.338| d_loss: 0.792| gp_loss: 0.009| r_loss: 1.255| p_loss: 2.598| v_loss: 0.085| per_loss: 2.360 | a_loss: 0.464
Train: Epoch [8/3000], Step [150/158]| g_loss: 3.155| d_loss: 0.899| gp_loss: 0.008| r_loss: 1.176| p_loss: 2.437| v_loss: 0.084| per_loss: 2.313 | a_loss: 0.446
Train: Epoch [9/3000], Step [30/158]| g_loss: 3.219| d_loss: 0.768| gp_loss: 0.025| r_loss: 1.152| p_loss: 2.481| v_loss: 0.078| per_loss: 2.299 | a_loss: 0.518
Train: Epoch [9/3000], Step [60/158]| g_loss: 3.378| d_loss: 0.773| gp_loss: 0.008| r_loss: 1.221| p_loss: 2.612| v_loss: 0.079| per_loss: 2.352 | a_loss: 0.537
Train: Epoch [9/3000], Step [90/158]| g_loss: 3.342| d_loss: 0.790| gp_loss: 0.008| r_loss: 1.141| p_loss: 2.622| v_loss: 0.083| per_loss: 2.250 | a_loss: 0.582
Train: Epoch [9/3000], Step [120/158]| g_loss: 3.230| d_loss: 0.668| gp_loss: 0.008| r_loss: 1.132| p_loss: 2.368| v_loss: 0.082| per_loss: 2.210 | a_loss: 0.611
Train: Epoch [9/3000], Step [150/158]| g_loss: 3.312| d_loss: 0.721| gp_loss: 0.008| r_loss: 1.163| p_loss: 2.455| v_loss: 0.081| per_loss: 2.331 | a_loss: 0.608
Train: Epoch [10/3000], Step [30/158]| g_loss: 3.077| d_loss: 0.801| gp_loss: 0.024| r_loss: 1.090| p_loss: 2.195| v_loss: 0.079| per_loss: 2.323 | a_loss: 0.578
Train: Epoch [10/3000], Step [60/158]| g_loss: 3.187| d_loss: 0.628| gp_loss: 0.008| r_loss: 1.173| p_loss: 2.267| v_loss: 0.082| per_loss: 2.341 | a_loss: 0.564
Train: Epoch [10/3000], Step [90/158]| g_loss: 3.143| d_loss: 0.664| gp_loss: 0.008| r_loss: 1.104| p_loss: 2.263| v_loss: 0.082| per_loss: 2.367 | a_loss: 0.589
Train: Epoch [10/3000], Step [120/158]| g_loss: 3.214| d_loss: 0.668| gp_loss: 0.009| r_loss: 1.146| p_loss: 2.237| v_loss: 0.090| per_loss: 2.394 | a_loss: 0.619
Train: Epoch [10/3000], Step [150/158]| g_loss: 3.128| d_loss: 0.595| gp_loss: 0.010| r_loss: 1.163| p_loss: 2.091| v_loss: 0.082| per_loss: 2.407 | a_loss: 0.597
Train: Epoch [11/3000], Step [30/158]| g_loss: 3.233| d_loss: 0.647| gp_loss: 0.026| r_loss: 1.225| p_loss: 2.189| v_loss: 0.084| per_loss: 2.399 | a_loss: 0.589
Train: Epoch [11/3000], Step [60/158]| g_loss: 3.472| d_loss: 0.732| gp_loss: 0.010| r_loss: 1.352| p_loss: 2.430| v_loss: 0.091| per_loss: 2.381 | a_loss: 0.576
Train: Epoch [11/3000], Step [90/158]| g_loss: 3.384| d_loss: 0.729| gp_loss: 0.009| r_loss: 1.325| p_loss: 2.303| v_loss: 0.082| per_loss: 2.337 | a_loss: 0.592
Train: Epoch [11/3000], Step [120/158]| g_loss: 3.348| d_loss: 0.593| gp_loss: 0.009| r_loss: 1.271| p_loss: 2.255| v_loss: 0.085| per_loss: 2.276 | a_loss: 0.637
Train: Epoch [11/3000], Step [150/158]| g_loss: 3.332| d_loss: 0.674| gp_loss: 0.010| r_loss: 1.286| p_loss: 2.415| v_loss: 0.085| per_loss: 2.398 | a_loss: 0.514
Train: Epoch [12/3000], Step [30/158]| g_loss: 3.379| d_loss: 0.742| gp_loss: 0.028| r_loss: 1.344| p_loss: 2.337| v_loss: 0.080| per_loss: 2.380 | a_loss: 0.548
Train: Epoch [12/3000], Step [60/158]| g_loss: 3.339| d_loss: 0.731| gp_loss: 0.009| r_loss: 1.242| p_loss: 2.533| v_loss: 0.075| per_loss: 2.453 | a_loss: 0.511
Train: Epoch [12/3000], Step [90/158]| g_loss: 3.659| d_loss: 0.881| gp_loss: 0.008| r_loss: 1.286| p_loss: 2.927| v_loss: 0.083| per_loss: 2.412 | a_loss: 0.585
Train: Epoch [12/3000], Step [120/158]| g_loss: 3.260| d_loss: 0.728| gp_loss: 0.008| r_loss: 1.179| p_loss: 2.398| v_loss: 0.085| per_loss: 2.364 | a_loss: 0.561
Train: Epoch [12/3000], Step [150/158]| g_loss: 3.196| d_loss: 0.659| gp_loss: 0.009| r_loss: 1.114| p_loss: 2.256| v_loss: 0.078| per_loss: 2.293 | a_loss: 0.647
Train: Epoch [13/3000], Step [30/158]| g_loss: 3.129| d_loss: 0.648| gp_loss: 0.025| r_loss: 1.128| p_loss: 2.163| v_loss: 0.082| per_loss: 2.291 | a_loss: 0.608
Train: Epoch [13/3000], Step [60/158]| g_loss: 3.179| d_loss: 0.768| gp_loss: 0.010| r_loss: 1.197| p_loss: 2.306| v_loss: 0.084| per_loss: 2.238 | a_loss: 0.521
Train: Epoch [13/3000], Step [90/158]| g_loss: 3.169| d_loss: 0.700| gp_loss: 0.010| r_loss: 1.180| p_loss: 2.241| v_loss: 0.080| per_loss: 2.192 | a_loss: 0.570
Train: Epoch [13/3000], Step [120/158]| g_loss: 3.096| d_loss: 0.722| gp_loss: 0.010| r_loss: 1.136| p_loss: 2.138| v_loss: 0.076| per_loss: 2.302 | a_loss: 0.585
Train: Epoch [13/3000], Step [150/158]| g_loss: 3.143| d_loss: 0.623| gp_loss: 0.010| r_loss: 1.159| p_loss: 2.073| v_loss: 0.083| per_loss: 2.239 | a_loss: 0.641
Train: Epoch [14/3000], Step [30/158]| g_loss: 3.009| d_loss: 0.720| gp_loss: 0.032| r_loss: 1.100| p_loss: 2.024| v_loss: 0.082| per_loss: 2.260 | a_loss: 0.589
Train: Epoch [14/3000], Step [60/158]| g_loss: 3.024| d_loss: 0.726| gp_loss: 0.010| r_loss: 1.124| p_loss: 1.997| v_loss: 0.084| per_loss: 2.305 | a_loss: 0.587
Train: Epoch [14/3000], Step [90/158]| g_loss: 2.814| d_loss: 0.687| gp_loss: 0.010| r_loss: 1.038| p_loss: 1.778| v_loss: 0.082| per_loss: 2.291 | a_loss: 0.576
Train: Epoch [14/3000], Step [120/158]| g_loss: 2.853| d_loss: 0.551| gp_loss: 0.009| r_loss: 1.051| p_loss: 1.849| v_loss: 0.076| per_loss: 2.343 | a_loss: 0.567
Train: Epoch [14/3000], Step [150/158]| g_loss: 3.035| d_loss: 0.597| gp_loss: 0.010| r_loss: 1.099| p_loss: 2.002| v_loss: 0.088| per_loss: 2.409 | a_loss: 0.606
Train: Epoch [15/3000], Step [30/158]| g_loss: 2.989| d_loss: 0.723| gp_loss: 0.029| r_loss: 1.068| p_loss: 2.027| v_loss: 0.081| per_loss: 2.405 | a_loss: 0.585
Train: Epoch [15/3000], Step [60/158]| g_loss: 2.850| d_loss: 0.612| gp_loss: 0.010| r_loss: 1.003| p_loss: 1.825| v_loss: 0.079| per_loss: 2.479 | a_loss: 0.607
Train: Epoch [15/3000], Step [90/158]| g_loss: 2.935| d_loss: 0.476| gp_loss: 0.011| r_loss: 1.065| p_loss: 1.806| v_loss: 0.082| per_loss: 2.556 | a_loss: 0.629
Train: Epoch [15/3000], Step [120/158]| g_loss: 2.976| d_loss: 0.664| gp_loss: 0.011| r_loss: 1.085| p_loss: 1.871| v_loss: 0.086| per_loss: 2.493 | a_loss: 0.620
Train: Epoch [15/3000], Step [150/158]| g_loss: 2.845| d_loss: 0.642| gp_loss: 0.011| r_loss: 1.044| p_loss: 1.787| v_loss: 0.083| per_loss: 2.430 | a_loss: 0.581
Train: Epoch [16/3000], Step [30/158]| g_loss: 2.925| d_loss: 0.668| gp_loss: 0.024| r_loss: 1.073| p_loss: 1.950| v_loss: 0.083| per_loss: 2.371 | a_loss: 0.558
Train: Epoch [16/3000], Step [60/158]| g_loss: 2.846| d_loss: 0.551| gp_loss: 0.012| r_loss: 1.021| p_loss: 1.722| v_loss: 0.082| per_loss: 2.473 | a_loss: 0.635
Train: Epoch [16/3000], Step [90/158]| g_loss: 2.877| d_loss: 0.584| gp_loss: 0.013| r_loss: 1.034| p_loss: 1.761| v_loss: 0.079| per_loss: 2.400 | a_loss: 0.643
Train: Epoch [16/3000], Step [120/158]| g_loss: 2.852| d_loss: 0.499| gp_loss: 0.014| r_loss: 1.016| p_loss: 1.668| v_loss: 0.085| per_loss: 2.419 | a_loss: 0.676
Train: Epoch [16/3000], Step [150/158]| g_loss: 2.842| d_loss: 0.598| gp_loss: 0.014| r_loss: 1.039| p_loss: 1.746| v_loss: 0.082| per_loss: 2.374 | a_loss: 0.611
Train: Epoch [17/3000], Step [30/158]| g_loss: 2.777| d_loss: 0.574| gp_loss: 0.039| r_loss: 0.980| p_loss: 1.656| v_loss: 0.085| per_loss: 2.369 | a_loss: 0.648
Train: Epoch [17/3000], Step [60/158]| g_loss: 2.797| d_loss: 0.514| gp_loss: 0.015| r_loss: 0.977| p_loss: 1.656| v_loss: 0.084| per_loss: 2.366 | a_loss: 0.672
Train: Epoch [17/3000], Step [90/158]| g_loss: 2.816| d_loss: 0.497| gp_loss: 0.015| r_loss: 1.023| p_loss: 1.686| v_loss: 0.081| per_loss: 2.289 | a_loss: 0.640
Train: Epoch [17/3000], Step [120/158]| g_loss: 2.796| d_loss: 0.578| gp_loss: 0.017| r_loss: 0.984| p_loss: 1.674| v_loss: 0.080| per_loss: 2.250 | a_loss: 0.670
Train: Epoch [17/3000], Step [150/158]| g_loss: 2.792| d_loss: 0.479| gp_loss: 0.017| r_loss: 0.980| p_loss: 1.682| v_loss: 0.079| per_loss: 2.263 | a_loss: 0.665
Train: Epoch [18/3000], Step [30/158]| g_loss: 2.733| d_loss: 0.565| gp_loss: 0.070| r_loss: 0.974| p_loss: 1.672| v_loss: 0.074| per_loss: 2.189 | a_loss: 0.630
Train: Epoch [18/3000], Step [60/158]| g_loss: 2.762| d_loss: 0.456| gp_loss: 0.017| r_loss: 0.967| p_loss: 1.572| v_loss: 0.082| per_loss: 2.210 | a_loss: 0.707
Train: Epoch [18/3000], Step [90/158]| g_loss: 2.715| d_loss: 0.525| gp_loss: 0.018| r_loss: 0.960| p_loss: 1.621| v_loss: 0.081| per_loss: 2.182 | a_loss: 0.645
Train: Epoch [18/3000], Step [120/158]| g_loss: 2.781| d_loss: 0.573| gp_loss: 0.020| r_loss: 0.980| p_loss: 1.700| v_loss: 0.079| per_loss: 2.182 | a_loss: 0.653
Train: Epoch [18/3000], Step [150/158]| g_loss: 2.867| d_loss: 0.481| gp_loss: 0.019| r_loss: 1.006| p_loss: 1.729| v_loss: 0.085| per_loss: 2.384 | a_loss: 0.673
Train: Epoch [19/3000], Step [30/158]| g_loss: 2.927| d_loss: 0.599| gp_loss: 0.055| r_loss: 1.004| p_loss: 1.845| v_loss: 0.084| per_loss: 2.305 | a_loss: 0.686
Train: Epoch [19/3000], Step [60/158]| g_loss: 2.776| d_loss: 0.469| gp_loss: 0.018| r_loss: 0.968| p_loss: 1.661| v_loss: 0.086| per_loss: 2.258 | a_loss: 0.667
Train: Epoch [19/3000], Step [90/158]| g_loss: 2.887| d_loss: 0.510| gp_loss: 0.019| r_loss: 1.014| p_loss: 1.785| v_loss: 0.080| per_loss: 2.272 | a_loss: 0.674
Train: Epoch [19/3000], Step [120/158]| g_loss: 2.771| d_loss: 0.450| gp_loss: 0.020| r_loss: 0.967| p_loss: 1.645| v_loss: 0.080| per_loss: 2.387 | a_loss: 0.662
Train: Epoch [19/3000], Step [150/158]| g_loss: 2.989| d_loss: 0.462| gp_loss: 0.022| r_loss: 1.060| p_loss: 1.831| v_loss: 0.081| per_loss: 2.399 | a_loss: 0.692
Train: Epoch [20/3000], Step [30/158]| g_loss: 2.859| d_loss: 0.527| gp_loss: 0.042| r_loss: 1.015| p_loss: 1.764| v_loss: 0.076| per_loss: 2.356 | a_loss: 0.651
Train: Epoch [20/3000], Step [60/158]| g_loss: 2.939| d_loss: 0.511| gp_loss: 0.020| r_loss: 1.030| p_loss: 1.796| v_loss: 0.084| per_loss: 2.336 | a_loss: 0.694
Train: Epoch [20/3000], Step [90/158]| g_loss: 2.723| d_loss: 0.500| gp_loss: 0.022| r_loss: 0.944| p_loss: 1.628| v_loss: 0.081| per_loss: 2.367 | a_loss: 0.647
Train: Epoch [20/3000], Step [120/158]| g_loss: 2.682| d_loss: 0.448| gp_loss: 0.022| r_loss: 0.925| p_loss: 1.552| v_loss: 0.079| per_loss: 2.398 | a_loss: 0.662
Train: Epoch [20/3000], Step [150/158]| g_loss: 2.759| d_loss: 0.402| gp_loss: 0.022| r_loss: 0.945| p_loss: 1.551| v_loss: 0.082| per_loss: 2.319 | a_loss: 0.725
Train: Epoch [21/3000], Step [30/158]| g_loss: 2.750| d_loss: 0.462| gp_loss: 0.049| r_loss: 0.948| p_loss: 1.592| v_loss: 0.083| per_loss: 2.374 | a_loss: 0.685
Train: Epoch [21/3000], Step [60/158]| g_loss: 2.767| d_loss: 0.427| gp_loss: 0.021| r_loss: 0.953| p_loss: 1.553| v_loss: 0.085| per_loss: 2.324 | a_loss: 0.721
Train: Epoch [21/3000], Step [90/158]| g_loss: 2.800| d_loss: 0.414| gp_loss: 0.021| r_loss: 0.980| p_loss: 1.638| v_loss: 0.082| per_loss: 2.338 | a_loss: 0.686
Train: Epoch [21/3000], Step [120/158]| g_loss: 2.846| d_loss: 0.521| gp_loss: 0.022| r_loss: 0.968| p_loss: 1.668| v_loss: 0.082| per_loss: 2.348 | a_loss: 0.727
Train: Epoch [21/3000], Step [150/158]| g_loss: 2.726| d_loss: 0.464| gp_loss: 0.022| r_loss: 0.947| p_loss: 1.568| v_loss: 0.086| per_loss: 2.298 | a_loss: 0.679
Train: Epoch [22/3000], Step [30/158]| g_loss: 2.671| d_loss: 0.429| gp_loss: 0.064| r_loss: 0.901| p_loss: 1.525| v_loss: 0.083| per_loss: 2.347 | a_loss: 0.690
Train: Epoch [22/3000], Step [60/158]| g_loss: 2.659| d_loss: 0.421| gp_loss: 0.022| r_loss: 0.925| p_loss: 1.531| v_loss: 0.075| per_loss: 2.317 | a_loss: 0.662
Train: Epoch [22/3000], Step [90/158]| g_loss: 2.741| d_loss: 0.463| gp_loss: 0.022| r_loss: 0.910| p_loss: 1.576| v_loss: 0.084| per_loss: 2.286 | a_loss: 0.730
Train: Epoch [22/3000], Step [120/158]| g_loss: 2.646| d_loss: 0.440| gp_loss: 0.022| r_loss: 0.897| p_loss: 1.485| v_loss: 0.079| per_loss: 2.272 | a_loss: 0.700
Train: Epoch [22/3000], Step [150/158]| g_loss: 2.640| d_loss: 0.454| gp_loss: 0.023| r_loss: 0.910| p_loss: 1.446| v_loss: 0.085| per_loss: 2.278 | a_loss: 0.694
Train: Epoch [23/3000], Step [30/158]| g_loss: 2.634| d_loss: 0.477| gp_loss: 0.067| r_loss: 0.920| p_loss: 1.471| v_loss: 0.078| per_loss: 2.211 | a_loss: 0.680
Train: Epoch [23/3000], Step [60/158]| g_loss: 2.663| d_loss: 0.456| gp_loss: 0.024| r_loss: 0.917| p_loss: 1.467| v_loss: 0.082| per_loss: 2.193 | a_loss: 0.711
Train: Epoch [23/3000], Step [90/158]| g_loss: 2.518| d_loss: 0.556| gp_loss: 0.024| r_loss: 0.868| p_loss: 1.417| v_loss: 0.085| per_loss: 2.169 | a_loss: 0.640
Train: Epoch [23/3000], Step [120/158]| g_loss: 2.593| d_loss: 0.437| gp_loss: 0.023| r_loss: 0.872| p_loss: 1.390| v_loss: 0.086| per_loss: 2.255 | a_loss: 0.714
Train: Epoch [23/3000], Step [150/158]| g_loss: 2.660| d_loss: 0.497| gp_loss: 0.023| r_loss: 0.947| p_loss: 1.461| v_loss: 0.081| per_loss: 2.220 | a_loss: 0.679
Train: Epoch [24/3000], Step [30/158]| g_loss: 2.662| d_loss: 0.501| gp_loss: 0.087| r_loss: 0.941| p_loss: 1.490| v_loss: 0.084| per_loss: 2.264 | a_loss: 0.665
Train: Epoch [24/3000], Step [60/158]| g_loss: 2.609| d_loss: 0.546| gp_loss: 0.022| r_loss: 0.917| p_loss: 1.510| v_loss: 0.080| per_loss: 2.237 | a_loss: 0.633
Train: Epoch [24/3000], Step [90/158]| g_loss: 2.531| d_loss: 0.507| gp_loss: 0.022| r_loss: 0.888| p_loss: 1.386| v_loss: 0.082| per_loss: 2.224 | a_loss: 0.646
Train: Epoch [24/3000], Step [120/158]| g_loss: 2.585| d_loss: 0.437| gp_loss: 0.024| r_loss: 0.889| p_loss: 1.410| v_loss: 0.078| per_loss: 2.204 | a_loss: 0.692
Train: Epoch [24/3000], Step [150/158]| g_loss: 2.568| d_loss: 0.489| gp_loss: 0.024| r_loss: 0.893| p_loss: 1.435| v_loss: 0.082| per_loss: 2.200 | a_loss: 0.655
Train: Epoch [25/3000], Step [30/158]| g_loss: 2.472| d_loss: 0.545| gp_loss: 0.055| r_loss: 0.850| p_loss: 1.365| v_loss: 0.084| per_loss: 2.204 | a_loss: 0.635
Train: Epoch [25/3000], Step [60/158]| g_loss: 2.538| d_loss: 0.384| gp_loss: 0.023| r_loss: 0.831| p_loss: 1.356| v_loss: 0.088| per_loss: 2.300 | a_loss: 0.712
Train: Epoch [25/3000], Step [90/158]| g_loss: 2.493| d_loss: 0.542| gp_loss: 0.021| r_loss: 0.855| p_loss: 1.405| v_loss: 0.088| per_loss: 2.306 | a_loss: 0.617
Train: Epoch [25/3000], Step [120/158]| g_loss: 2.494| d_loss: 0.425| gp_loss: 0.022| r_loss: 0.836| p_loss: 1.294| v_loss: 0.087| per_loss: 2.281 | a_loss: 0.696
Train: Epoch [25/3000], Step [150/158]| g_loss: 2.512| d_loss: 0.450| gp_loss: 0.024| r_loss: 0.850| p_loss: 1.350| v_loss: 0.081| per_loss: 2.263 | a_loss: 0.680
Train: Epoch [26/3000], Step [30/158]| g_loss: 2.565| d_loss: 0.479| gp_loss: 0.060| r_loss: 0.883| p_loss: 1.377| v_loss: 0.082| per_loss: 2.260 | a_loss: 0.685
Train: Epoch [26/3000], Step [60/158]| g_loss: 2.444| d_loss: 0.548| gp_loss: 0.025| r_loss: 0.809| p_loss: 1.410| v_loss: 0.083| per_loss: 2.249 | a_loss: 0.623
Train: Epoch [26/3000], Step [90/158]| g_loss: 2.437| d_loss: 0.532| gp_loss: 0.024| r_loss: 0.831| p_loss: 1.348| v_loss: 0.083| per_loss: 2.336 | a_loss: 0.616
Train: Epoch [26/3000], Step [120/158]| g_loss: 2.499| d_loss: 0.367| gp_loss: 0.025| r_loss: 0.829| p_loss: 1.369| v_loss: 0.082| per_loss: 2.399 | a_loss: 0.664
Train: Epoch [26/3000], Step [150/158]| g_loss: 2.528| d_loss: 0.549| gp_loss: 0.026| r_loss: 0.863| p_loss: 1.405| v_loss: 0.087| per_loss: 2.469 | a_loss: 0.629
Train: Epoch [27/3000], Step [30/158]| g_loss: 2.565| d_loss: 0.529| gp_loss: 0.066| r_loss: 0.885| p_loss: 1.388| v_loss: 0.086| per_loss: 2.552 | a_loss: 0.645
Train: Epoch [27/3000], Step [60/158]| g_loss: 2.573| d_loss: 0.462| gp_loss: 0.025| r_loss: 0.847| p_loss: 1.366| v_loss: 0.090| per_loss: 2.649 | a_loss: 0.688
Train: Epoch [27/3000], Step [90/158]| g_loss: 2.572| d_loss: 0.572| gp_loss: 0.024| r_loss: 0.873| p_loss: 1.414| v_loss: 0.087| per_loss: 2.657 | a_loss: 0.640
Train: Epoch [27/3000], Step [120/158]| g_loss: 2.528| d_loss: 0.527| gp_loss: 0.023| r_loss: 0.841| p_loss: 1.409| v_loss: 0.082| per_loss: 2.655 | a_loss: 0.634
Train: Epoch [27/3000], Step [150/158]| g_loss: 2.513| d_loss: 0.477| gp_loss: 0.024| r_loss: 0.817| p_loss: 1.407| v_loss: 0.084| per_loss: 2.692 | a_loss: 0.639
Train: Epoch [28/3000], Step [30/158]| g_loss: 2.534| d_loss: 0.553| gp_loss: 0.059| r_loss: 0.841| p_loss: 1.408| v_loss: 0.082| per_loss: 2.680 | a_loss: 0.639
Train: Epoch [28/3000], Step [60/158]| g_loss: 2.478| d_loss: 0.441| gp_loss: 0.023| r_loss: 0.789| p_loss: 1.286| v_loss: 0.086| per_loss: 2.689 | a_loss: 0.691
Train: Epoch [28/3000], Step [90/158]| g_loss: 2.541| d_loss: 0.534| gp_loss: 0.024| r_loss: 0.872| p_loss: 1.462| v_loss: 0.082| per_loss: 2.703 | a_loss: 0.585
Train: Epoch [28/3000], Step [120/158]| g_loss: 2.572| d_loss: 0.472| gp_loss: 0.026| r_loss: 0.878| p_loss: 1.391| v_loss: 0.085| per_loss: 2.702 | a_loss: 0.643
Train: Epoch [28/3000], Step [150/158]| g_loss: 2.560| d_loss: 0.579| gp_loss: 0.026| r_loss: 0.892| p_loss: 1.450| v_loss: 0.084| per_loss: 2.726 | a_loss: 0.586
Train: Epoch [29/3000], Step [30/158]| g_loss: 2.537| d_loss: 0.561| gp_loss: 0.064| r_loss: 0.850| p_loss: 1.420| v_loss: 0.088| per_loss: 2.670 | a_loss: 0.622
Train: Epoch [29/3000], Step [60/158]| g_loss: 2.555| d_loss: 0.477| gp_loss: 0.027| r_loss: 0.852| p_loss: 1.395| v_loss: 0.086| per_loss: 2.588 | a_loss: 0.661
Train: Epoch [29/3000], Step [90/158]| g_loss: 2.598| d_loss: 0.552| gp_loss: 0.027| r_loss: 0.874| p_loss: 1.434| v_loss: 0.085| per_loss: 2.538 | a_loss: 0.668
Train: Epoch [29/3000], Step [120/158]| g_loss: 2.527| d_loss: 0.493| gp_loss: 0.026| r_loss: 0.844| p_loss: 1.391| v_loss: 0.082| per_loss: 2.535 | a_loss: 0.653
Train: Epoch [29/3000], Step [150/158]| g_loss: 2.511| d_loss: 0.475| gp_loss: 0.024| r_loss: 0.829| p_loss: 1.379| v_loss: 0.093| per_loss: 2.485 | a_loss: 0.652
Train: Epoch [30/3000], Step [30/158]| g_loss: 2.552| d_loss: 0.534| gp_loss: 0.056| r_loss: 0.889| p_loss: 1.416| v_loss: 0.092| per_loss: 2.479 | a_loss: 0.616
Train: Epoch [30/3000], Step [60/158]| g_loss: 2.482| d_loss: 0.547| gp_loss: 0.027| r_loss: 0.846| p_loss: 1.302| v_loss: 0.089| per_loss: 2.539 | a_loss: 0.643
Train: Epoch [30/3000], Step [90/158]| g_loss: 2.466| d_loss: 0.414| gp_loss: 0.025| r_loss: 0.846| p_loss: 1.250| v_loss: 0.087| per_loss: 2.517 | a_loss: 0.655
Train: Epoch [30/3000], Step [120/158]| g_loss: 2.569| d_loss: 0.509| gp_loss: 0.026| r_loss: 0.899| p_loss: 1.345| v_loss: 0.092| per_loss: 2.431 | a_loss: 0.662
Train: Epoch [30/3000], Step [150/158]| g_loss: 2.544| d_loss: 0.457| gp_loss: 0.027| r_loss: 0.861| p_loss: 1.345| v_loss: 0.084| per_loss: 2.464 | a_loss: 0.679
Train: Epoch [31/3000], Step [30/158]| g_loss: 2.440| d_loss: 0.514| gp_loss: 0.062| r_loss: 0.836| p_loss: 1.294| v_loss: 0.091| per_loss: 2.340 | a_loss: 0.632
Train: Epoch [31/3000], Step [60/158]| g_loss: 2.431| d_loss: 0.528| gp_loss: 0.027| r_loss: 0.844| p_loss: 1.285| v_loss: 0.087| per_loss: 2.402 | a_loss: 0.618
Train: Epoch [31/3000], Step [90/158]| g_loss: 2.365| d_loss: 0.511| gp_loss: 0.027| r_loss: 0.790| p_loss: 1.232| v_loss: 0.083| per_loss: 2.381 | a_loss: 0.639
Train: Epoch [31/3000], Step [120/158]| g_loss: 2.430| d_loss: 0.418| gp_loss: 0.028| r_loss: 0.792| p_loss: 1.257| v_loss: 0.085| per_loss: 2.361 | a_loss: 0.688
Train: Epoch [31/3000], Step [150/158]| g_loss: 2.425| d_loss: 0.516| gp_loss: 0.028| r_loss: 0.833| p_loss: 1.232| v_loss: 0.084| per_loss: 2.413 | a_loss: 0.650
Train: Epoch [32/3000], Step [30/158]| g_loss: 2.399| d_loss: 0.527| gp_loss: 0.084| r_loss: 0.816| p_loss: 1.206| v_loss: 0.087| per_loss: 2.387 | a_loss: 0.653
Train: Epoch [32/3000], Step [60/158]| g_loss: 2.432| d_loss: 0.427| gp_loss: 0.025| r_loss: 0.788| p_loss: 1.196| v_loss: 0.089| per_loss: 2.434 | a_loss: 0.713
Train: Epoch [32/3000], Step [90/158]| g_loss: 2.385| d_loss: 0.449| gp_loss: 0.027| r_loss: 0.811| p_loss: 1.199| v_loss: 0.080| per_loss: 2.369 | a_loss: 0.657
Train: Epoch [32/3000], Step [120/158]| g_loss: 2.341| d_loss: 0.419| gp_loss: 0.027| r_loss: 0.768| p_loss: 1.132| v_loss: 0.083| per_loss: 2.337 | a_loss: 0.690
Train: Epoch [32/3000], Step [150/158]| g_loss: 2.338| d_loss: 0.473| gp_loss: 0.029| r_loss: 0.772| p_loss: 1.231| v_loss: 0.084| per_loss: 2.421 | a_loss: 0.625
Train: Epoch [33/3000], Step [30/158]| g_loss: 2.366| d_loss: 0.487| gp_loss: 0.084| r_loss: 0.767| p_loss: 1.143| v_loss: 0.082| per_loss: 2.340 | a_loss: 0.711
Train: Epoch [33/3000], Step [60/158]| g_loss: 2.305| d_loss: 0.492| gp_loss: 0.027| r_loss: 0.769| p_loss: 1.160| v_loss: 0.086| per_loss: 2.321 | a_loss: 0.638
Train: Epoch [33/3000], Step [90/158]| g_loss: 2.312| d_loss: 0.422| gp_loss: 0.027| r_loss: 0.738| p_loss: 1.153| v_loss: 0.087| per_loss: 2.326 | a_loss: 0.677
Train: Epoch [33/3000], Step [120/158]| g_loss: 2.337| d_loss: 0.424| gp_loss: 0.028| r_loss: 0.743| p_loss: 1.193| v_loss: 0.085| per_loss: 2.395 | a_loss: 0.673
Train: Epoch [33/3000], Step [150/158]| g_loss: 2.360| d_loss: 0.394| gp_loss: 0.026| r_loss: 0.744| p_loss: 1.130| v_loss: 0.088| per_loss: 2.424 | a_loss: 0.721
Train: Epoch [34/3000], Step [30/158]| g_loss: 2.374| d_loss: 0.406| gp_loss: 0.058| r_loss: 0.748| p_loss: 1.171| v_loss: 0.094| per_loss: 2.427 | a_loss: 0.705
Train: Epoch [34/3000], Step [60/158]| g_loss: 2.293| d_loss: 0.498| gp_loss: 0.025| r_loss: 0.711| p_loss: 1.180| v_loss: 0.084| per_loss: 2.325 | a_loss: 0.675
Train: Epoch [34/3000], Step [90/158]| g_loss: 2.362| d_loss: 0.517| gp_loss: 0.028| r_loss: 0.800| p_loss: 1.228| v_loss: 0.086| per_loss: 2.196 | a_loss: 0.643
Train: Epoch [34/3000], Step [120/158]| g_loss: 2.341| d_loss: 0.484| gp_loss: 0.028| r_loss: 0.770| p_loss: 1.205| v_loss: 0.088| per_loss: 2.168 | a_loss: 0.663
Train: Epoch [34/3000], Step [150/158]| g_loss: 2.340| d_loss: 0.461| gp_loss: 0.029| r_loss: 0.750| p_loss: 1.216| v_loss: 0.089| per_loss: 2.213 | a_loss: 0.672
Train: Epoch [35/3000], Step [30/158]| g_loss: 2.245| d_loss: 0.550| gp_loss: 0.057| r_loss: 0.728| p_loss: 1.136| v_loss: 0.080| per_loss: 2.143 | a_loss: 0.655
Train: Epoch [35/3000], Step [60/158]| g_loss: 2.243| d_loss: 0.531| gp_loss: 0.028| r_loss: 0.772| p_loss: 1.091| v_loss: 0.090| per_loss: 2.113 | a_loss: 0.625
Train: Epoch [35/3000], Step [90/158]| g_loss: 2.248| d_loss: 0.406| gp_loss: 0.028| r_loss: 0.722| p_loss: 1.095| v_loss: 0.090| per_loss: 2.121 | a_loss: 0.677
Train: Epoch [35/3000], Step [120/158]| g_loss: 2.275| d_loss: 0.396| gp_loss: 0.028| r_loss: 0.745| p_loss: 1.094| v_loss: 0.086| per_loss: 2.133 | a_loss: 0.684
Train: Epoch [35/3000], Step [150/158]| g_loss: 2.269| d_loss: 0.473| gp_loss: 0.029| r_loss: 0.744| p_loss: 1.125| v_loss: 0.087| per_loss: 2.142 | a_loss: 0.661
Train: Epoch [36/3000], Step [30/158]| g_loss: 2.254| d_loss: 0.467| gp_loss: 0.074| r_loss: 0.690| p_loss: 1.085| v_loss: 0.089| per_loss: 2.153 | a_loss: 0.718
Train: Epoch [36/3000], Step [60/158]| g_loss: 2.287| d_loss: 0.363| gp_loss: 0.029| r_loss: 0.758| p_loss: 1.085| v_loss: 0.090| per_loss: 2.179 | a_loss: 0.678
Train: Epoch [36/3000], Step [90/158]| g_loss: 2.313| d_loss: 0.476| gp_loss: 0.031| r_loss: 0.759| p_loss: 1.129| v_loss: 0.087| per_loss: 2.151 | a_loss: 0.688
Train: Epoch [36/3000], Step [120/158]| g_loss: 2.268| d_loss: 0.458| gp_loss: 0.032| r_loss: 0.751| p_loss: 1.119| v_loss: 0.081| per_loss: 2.134 | a_loss: 0.662
Train: Epoch [36/3000], Step [150/158]| g_loss: 2.271| d_loss: 0.374| gp_loss: 0.032| r_loss: 0.722| p_loss: 1.091| v_loss: 0.088| per_loss: 2.147 | a_loss: 0.700
Train: Epoch [37/3000], Step [30/158]| g_loss: 2.346| d_loss: 0.470| gp_loss: 0.085| r_loss: 0.800| p_loss: 1.156| v_loss: 0.083| per_loss: 2.132 | a_loss: 0.672
Train: Epoch [37/3000], Step [60/158]| g_loss: 2.251| d_loss: 0.428| gp_loss: 0.033| r_loss: 0.708| p_loss: 1.103| v_loss: 0.085| per_loss: 2.102 | a_loss: 0.696
Train: Epoch [37/3000], Step [90/158]| g_loss: 2.221| d_loss: 0.448| gp_loss: 0.033| r_loss: 0.706| p_loss: 1.094| v_loss: 0.082| per_loss: 2.031 | a_loss: 0.683
Train: Epoch [37/3000], Step [120/158]| g_loss: 2.220| d_loss: 0.465| gp_loss: 0.035| r_loss: 0.706| p_loss: 1.071| v_loss: 0.084| per_loss: 1.948 | a_loss: 0.699
Train: Epoch [37/3000], Step [150/158]| g_loss: 2.227| d_loss: 0.428| gp_loss: 0.033| r_loss: 0.667| p_loss: 1.082| v_loss: 0.083| per_loss: 1.937 | a_loss: 0.742
Train: Epoch [38/3000], Step [30/158]| g_loss: 2.160| d_loss: 0.434| gp_loss: 0.084| r_loss: 0.656| p_loss: 1.042| v_loss: 0.083| per_loss: 1.962 | a_loss: 0.703
Train: Epoch [38/3000], Step [60/158]| g_loss: 2.133| d_loss: 0.460| gp_loss: 0.030| r_loss: 0.654| p_loss: 1.028| v_loss: 0.081| per_loss: 1.983 | a_loss: 0.686
Train: Epoch [38/3000], Step [90/158]| g_loss: 2.189| d_loss: 0.425| gp_loss: 0.032| r_loss: 0.693| p_loss: 1.104| v_loss: 0.085| per_loss: 1.964 | a_loss: 0.662
Train: Epoch [38/3000], Step [120/158]| g_loss: 2.171| d_loss: 0.512| gp_loss: 0.032| r_loss: 0.691| p_loss: 1.078| v_loss: 0.085| per_loss: 1.994 | a_loss: 0.656
Train: Epoch [38/3000], Step [150/158]| g_loss: 2.153| d_loss: 0.424| gp_loss: 0.032| r_loss: 0.679| p_loss: 1.000| v_loss: 0.082| per_loss: 1.940 | a_loss: 0.697
Train: Epoch [39/3000], Step [30/158]| g_loss: 2.176| d_loss: 0.520| gp_loss: 0.084| r_loss: 0.683| p_loss: 1.094| v_loss: 0.087| per_loss: 1.934 | a_loss: 0.666
Train: Epoch [39/3000], Step [60/158]| g_loss: 2.160| d_loss: 0.468| gp_loss: 0.031| r_loss: 0.649| p_loss: 1.023| v_loss: 0.083| per_loss: 1.931 | a_loss: 0.723
Train: Epoch [39/3000], Step [90/158]| g_loss: 2.094| d_loss: 0.428| gp_loss: 0.034| r_loss: 0.640| p_loss: 1.006| v_loss: 0.082| per_loss: 1.878 | a_loss: 0.681
Train: Epoch [39/3000], Step [120/158]| g_loss: 2.129| d_loss: 0.438| gp_loss: 0.034| r_loss: 0.686| p_loss: 1.003| v_loss: 0.078| per_loss: 1.931 | a_loss: 0.670
Train: Epoch [39/3000], Step [150/158]| g_loss: 2.165| d_loss: 0.377| gp_loss: 0.035| r_loss: 0.652| p_loss: 1.010| v_loss: 0.088| per_loss: 1.934 | a_loss: 0.727
Train: Epoch [40/3000], Step [30/158]| g_loss: 2.147| d_loss: 0.421| gp_loss: 0.121| r_loss: 0.652| p_loss: 0.961| v_loss: 0.081| per_loss: 1.954 | a_loss: 0.738
Train: Epoch [40/3000], Step [60/158]| g_loss: 2.203| d_loss: 0.432| gp_loss: 0.034| r_loss: 0.684| p_loss: 1.051| v_loss: 0.081| per_loss: 1.998 | a_loss: 0.712
Train: Epoch [40/3000], Step [90/158]| g_loss: 2.198| d_loss: 0.438| gp_loss: 0.035| r_loss: 0.667| p_loss: 1.069| v_loss: 0.081| per_loss: 2.036 | a_loss: 0.712
Train: Epoch [40/3000], Step [120/158]| g_loss: 2.089| d_loss: 0.533| gp_loss: 0.037| r_loss: 0.680| p_loss: 1.071| v_loss: 0.083| per_loss: 2.036 | a_loss: 0.588
Train: Epoch [40/3000], Step [150/158]| g_loss: 2.213| d_loss: 0.427| gp_loss: 0.035| r_loss: 0.679| p_loss: 1.101| v_loss: 0.081| per_loss: 2.035 | a_loss: 0.699
Train: Epoch [41/3000], Step [30/158]| g_loss: 2.213| d_loss: 0.504| gp_loss: 0.083| r_loss: 0.708| p_loss: 1.101| v_loss: 0.082| per_loss: 2.021 | a_loss: 0.670
Train: Epoch [41/3000], Step [60/158]| g_loss: 2.200| d_loss: 0.445| gp_loss: 0.037| r_loss: 0.685| p_loss: 1.135| v_loss: 0.086| per_loss: 1.999 | a_loss: 0.662
Train: Epoch [41/3000], Step [90/158]| g_loss: 2.195| d_loss: 0.540| gp_loss: 0.034| r_loss: 0.705| p_loss: 1.128| v_loss: 0.083| per_loss: 1.949 | a_loss: 0.648
Train: Epoch [41/3000], Step [120/158]| g_loss: 2.204| d_loss: 0.524| gp_loss: 0.034| r_loss: 0.682| p_loss: 1.178| v_loss: 0.085| per_loss: 1.960 | a_loss: 0.651
Train: Epoch [41/3000], Step [150/158]| g_loss: 2.148| d_loss: 0.505| gp_loss: 0.034| r_loss: 0.692| p_loss: 1.139| v_loss: 0.077| per_loss: 1.965 | a_loss: 0.613
Train: Epoch [42/3000], Step [30/158]| g_loss: 2.093| d_loss: 0.715| gp_loss: 0.063| r_loss: 0.703| p_loss: 1.133| v_loss: 0.087| per_loss: 1.920 | a_loss: 0.545
Train: Epoch [42/3000], Step [60/158]| g_loss: 2.065| d_loss: 0.540| gp_loss: 0.031| r_loss: 0.655| p_loss: 1.064| v_loss: 0.087| per_loss: 1.958 | a_loss: 0.596
Train: Epoch [42/3000], Step [90/158]| g_loss: 2.086| d_loss: 0.467| gp_loss: 0.031| r_loss: 0.649| p_loss: 1.058| v_loss: 0.085| per_loss: 1.926 | a_loss: 0.631
Train: Epoch [42/3000], Step [120/158]| g_loss: 2.071| d_loss: 0.535| gp_loss: 0.031| r_loss: 0.650| p_loss: 1.071| v_loss: 0.081| per_loss: 1.965 | a_loss: 0.607
Train: Epoch [42/3000], Step [150/158]| g_loss: 2.168| d_loss: 0.478| gp_loss: 0.033| r_loss: 0.696| p_loss: 1.087| v_loss: 0.084| per_loss: 2.002 | a_loss: 0.645
Train: Epoch [43/3000], Step [30/158]| g_loss: 2.089| d_loss: 0.512| gp_loss: 0.069| r_loss: 0.662| p_loss: 1.029| v_loss: 0.080| per_loss: 1.969 | a_loss: 0.635
Train: Epoch [43/3000], Step [60/158]| g_loss: 2.138| d_loss: 0.475| gp_loss: 0.032| r_loss: 0.650| p_loss: 1.101| v_loss: 0.080| per_loss: 2.117 | a_loss: 0.646
Train: Epoch [43/3000], Step [90/158]| g_loss: 2.199| d_loss: 0.498| gp_loss: 0.033| r_loss: 0.716| p_loss: 1.123| v_loss: 0.086| per_loss: 2.098 | a_loss: 0.625
Train: Epoch [43/3000], Step [120/158]| g_loss: 2.086| d_loss: 0.545| gp_loss: 0.034| r_loss: 0.665| p_loss: 1.044| v_loss: 0.080| per_loss: 2.052 | a_loss: 0.614
Train: Epoch [43/3000], Step [150/158]| g_loss: 2.082| d_loss: 0.501| gp_loss: 0.034| r_loss: 0.640| p_loss: 1.032| v_loss: 0.082| per_loss: 2.071 | a_loss: 0.636
Train: Epoch [44/3000], Step [30/158]| g_loss: 2.091| d_loss: 0.604| gp_loss: 0.100| r_loss: 0.662| p_loss: 1.061| v_loss: 0.083| per_loss: 2.113 | a_loss: 0.605
Train: Epoch [44/3000], Step [60/158]| g_loss: 2.078| d_loss: 0.511| gp_loss: 0.033| r_loss: 0.658| p_loss: 1.025| v_loss: 0.078| per_loss: 2.134 | a_loss: 0.616
Train: Epoch [44/3000], Step [90/158]| g_loss: 2.096| d_loss: 0.462| gp_loss: 0.033| r_loss: 0.631| p_loss: 1.034| v_loss: 0.081| per_loss: 2.102 | a_loss: 0.657
Train: Epoch [44/3000], Step [120/158]| g_loss: 2.089| d_loss: 0.529| gp_loss: 0.034| r_loss: 0.676| p_loss: 1.019| v_loss: 0.083| per_loss: 2.097 | a_loss: 0.610
Train: Epoch [44/3000], Step [150/158]| g_loss: 2.130| d_loss: 0.471| gp_loss: 0.035| r_loss: 0.647| p_loss: 0.995| v_loss: 0.081| per_loss: 2.130 | a_loss: 0.692
Train: Epoch [45/3000], Step [30/158]| g_loss: 2.059| d_loss: 0.538| gp_loss: 0.087| r_loss: 0.642| p_loss: 0.984| v_loss: 0.079| per_loss: 2.090 | a_loss: 0.637
Train: Epoch [45/3000], Step [60/158]| g_loss: 2.076| d_loss: 0.473| gp_loss: 0.032| r_loss: 0.622| p_loss: 0.998| v_loss: 0.083| per_loss: 2.163 | a_loss: 0.656
Train: Epoch [45/3000], Step [90/158]| g_loss: 2.042| d_loss: 0.494| gp_loss: 0.033| r_loss: 0.636| p_loss: 0.996| v_loss: 0.078| per_loss: 2.054 | a_loss: 0.625
Train: Epoch [45/3000], Step [120/158]| g_loss: 2.113| d_loss: 0.487| gp_loss: 0.033| r_loss: 0.668| p_loss: 1.030| v_loss: 0.084| per_loss: 1.998 | a_loss: 0.646
Train: Epoch [45/3000], Step [150/158]| g_loss: 2.061| d_loss: 0.541| gp_loss: 0.035| r_loss: 0.638| p_loss: 0.972| v_loss: 0.079| per_loss: 2.065 | a_loss: 0.651
Train: Epoch [46/3000], Step [30/158]| g_loss: 1.991| d_loss: 0.636| gp_loss: 0.103| r_loss: 0.620| p_loss: 0.965| v_loss: 0.083| per_loss: 2.036 | a_loss: 0.602
Train: Epoch [46/3000], Step [60/158]| g_loss: 2.075| d_loss: 0.494| gp_loss: 0.032| r_loss: 0.633| p_loss: 0.970| v_loss: 0.079| per_loss: 2.187 | a_loss: 0.659
Train: Epoch [46/3000], Step [90/158]| g_loss: 2.017| d_loss: 0.456| gp_loss: 0.032| r_loss: 0.621| p_loss: 0.944| v_loss: 0.084| per_loss: 2.053 | a_loss: 0.636
Train: Epoch [46/3000], Step [120/158]| g_loss: 2.047| d_loss: 0.473| gp_loss: 0.034| r_loss: 0.642| p_loss: 0.927| v_loss: 0.076| per_loss: 2.159 | a_loss: 0.650
Train: Epoch [46/3000], Step [150/158]| g_loss: 2.130| d_loss: 0.429| gp_loss: 0.034| r_loss: 0.652| p_loss: 1.009| v_loss: 0.082| per_loss: 2.192 | a_loss: 0.673
Train: Epoch [47/3000], Step [30/158]| g_loss: 2.007| d_loss: 0.514| gp_loss: 0.073| r_loss: 0.597| p_loss: 0.900| v_loss: 0.076| per_loss: 2.153 | a_loss: 0.669
Train: Epoch [47/3000], Step [60/158]| g_loss: 2.028| d_loss: 0.504| gp_loss: 0.032| r_loss: 0.616| p_loss: 0.980| v_loss: 0.080| per_loss: 2.181 | a_loss: 0.624
Train: Epoch [47/3000], Step [90/158]| g_loss: 2.036| d_loss: 0.473| gp_loss: 0.035| r_loss: 0.638| p_loss: 0.962| v_loss: 0.076| per_loss: 2.202 | a_loss: 0.621
Train: Epoch [47/3000], Step [120/158]| g_loss: 2.061| d_loss: 0.481| gp_loss: 0.034| r_loss: 0.627| p_loss: 0.933| v_loss: 0.077| per_loss: 2.242 | a_loss: 0.667
Train: Epoch [47/3000], Step [150/158]| g_loss: 2.067| d_loss: 0.533| gp_loss: 0.034| r_loss: 0.648| p_loss: 0.986| v_loss: 0.084| per_loss: 2.202 | a_loss: 0.622
Train: Epoch [48/3000], Step [30/158]| g_loss: 2.215| d_loss: 0.592| gp_loss: 0.076| r_loss: 0.712| p_loss: 1.188| v_loss: 0.082| per_loss: 2.225 | a_loss: 0.605
Train: Epoch [48/3000], Step [60/158]| g_loss: 2.218| d_loss: 0.415| gp_loss: 0.032| r_loss: 0.681| p_loss: 1.106| v_loss: 0.085| per_loss: 2.221 | a_loss: 0.677
Train: Epoch [48/3000], Step [90/158]| g_loss: 2.061| d_loss: 0.520| gp_loss: 0.032| r_loss: 0.626| p_loss: 1.047| v_loss: 0.075| per_loss: 2.139 | a_loss: 0.623
Train: Epoch [48/3000], Step [120/158]| g_loss: 2.057| d_loss: 0.478| gp_loss: 0.032| r_loss: 0.639| p_loss: 1.012| v_loss: 0.079| per_loss: 2.123 | a_loss: 0.620
Train: Epoch [48/3000], Step [150/158]| g_loss: 2.068| d_loss: 0.424| gp_loss: 0.035| r_loss: 0.599| p_loss: 0.974| v_loss: 0.081| per_loss: 2.083 | a_loss: 0.693
Train: Epoch [49/3000], Step [30/158]| g_loss: 2.067| d_loss: 0.449| gp_loss: 0.081| r_loss: 0.617| p_loss: 0.966| v_loss: 0.075| per_loss: 2.107 | a_loss: 0.682
Train: Epoch [49/3000], Step [60/158]| g_loss: 2.075| d_loss: 0.441| gp_loss: 0.033| r_loss: 0.641| p_loss: 0.973| v_loss: 0.081| per_loss: 2.057 | a_loss: 0.661
Train: Epoch [49/3000], Step [90/158]| g_loss: 2.045| d_loss: 0.482| gp_loss: 0.034| r_loss: 0.626| p_loss: 0.969| v_loss: 0.074| per_loss: 2.037 | a_loss: 0.657
Train: Epoch [49/3000], Step [120/158]| g_loss: 2.002| d_loss: 0.501| gp_loss: 0.036| r_loss: 0.603| p_loss: 0.960| v_loss: 0.081| per_loss: 2.072 | a_loss: 0.632
Train: Epoch [49/3000], Step [150/158]| g_loss: 2.026| d_loss: 0.459| gp_loss: 0.036| r_loss: 0.632| p_loss: 0.958| v_loss: 0.076| per_loss: 2.036 | a_loss: 0.636
Train: Epoch [50/3000], Step [30/158]| g_loss: 2.078| d_loss: 0.465| gp_loss: 0.082| r_loss: 0.611| p_loss: 0.970| v_loss: 0.080| per_loss: 2.094 | a_loss: 0.693
Train: Epoch [50/3000], Step [60/158]| g_loss: 2.031| d_loss: 0.380| gp_loss: 0.035| r_loss: 0.608| p_loss: 0.914| v_loss: 0.079| per_loss: 2.042 | a_loss: 0.682
Train: Epoch [50/3000], Step [90/158]| g_loss: 2.005| d_loss: 0.516| gp_loss: 0.034| r_loss: 0.601| p_loss: 0.925| v_loss: 0.075| per_loss: 2.013 | a_loss: 0.665
Train: Epoch [50/3000], Step [120/158]| g_loss: 2.022| d_loss: 0.465| gp_loss: 0.032| r_loss: 0.630| p_loss: 0.941| v_loss: 0.082| per_loss: 1.916 | a_loss: 0.649
Train: Epoch [50/3000], Step [150/158]| g_loss: 2.021| d_loss: 0.570| gp_loss: 0.036| r_loss: 0.612| p_loss: 0.990| v_loss: 0.079| per_loss: 2.014 | a_loss: 0.634
Test: Epoch [50/3000]| g_loss: 1.898| r_loss: 1.309| p_loss: 0.844| v_loss: 0.064
Train: Epoch [51/3000], Step [30/158]| g_loss: 2.004| d_loss: 0.431| gp_loss: 0.032| r_loss: 0.609| p_loss: 0.916| v_loss: 0.080| per_loss: 1.975 | a_loss: 0.659
Train: Epoch [51/3000], Step [60/158]| g_loss: 2.013| d_loss: 0.465| gp_loss: 0.031| r_loss: 0.605| p_loss: 0.954| v_loss: 0.079| per_loss: 1.983 | a_loss: 0.653
Train: Epoch [51/3000], Step [90/158]| g_loss: 1.993| d_loss: 0.444| gp_loss: 0.033| r_loss: 0.595| p_loss: 0.913| v_loss: 0.081| per_loss: 1.991 | a_loss: 0.661
Train: Epoch [51/3000], Step [120/158]| g_loss: 1.983| d_loss: 0.438| gp_loss: 0.035| r_loss: 0.589| p_loss: 0.891| v_loss: 0.081| per_loss: 2.011 | a_loss: 0.666
Train: Epoch [51/3000], Step [150/158]| g_loss: 1.984| d_loss: 0.472| gp_loss: 0.034| r_loss: 0.616| p_loss: 0.946| v_loss: 0.071| per_loss: 1.999 | a_loss: 0.624
Train: Epoch [52/3000], Step [30/158]| g_loss: 2.002| d_loss: 0.520| gp_loss: 0.108| r_loss: 0.601| p_loss: 0.901| v_loss: 0.076| per_loss: 1.989 | a_loss: 0.676
Train: Epoch [52/3000], Step [60/158]| g_loss: 1.992| d_loss: 0.390| gp_loss: 0.033| r_loss: 0.571| p_loss: 0.874| v_loss: 0.078| per_loss: 1.945 | a_loss: 0.711
Train: Epoch [52/3000], Step [90/158]| g_loss: 1.952| d_loss: 0.509| gp_loss: 0.035| r_loss: 0.604| p_loss: 0.912| v_loss: 0.072| per_loss: 1.969 | a_loss: 0.623
Train: Epoch [52/3000], Step [120/158]| g_loss: 2.024| d_loss: 0.469| gp_loss: 0.034| r_loss: 0.601| p_loss: 0.912| v_loss: 0.080| per_loss: 1.947 | a_loss: 0.692
Train: Epoch [52/3000], Step [150/158]| g_loss: 2.013| d_loss: 0.426| gp_loss: 0.035| r_loss: 0.605| p_loss: 0.940| v_loss: 0.077| per_loss: 1.937 | a_loss: 0.667
Train: Epoch [53/3000], Step [30/158]| g_loss: 2.023| d_loss: 0.444| gp_loss: 0.091| r_loss: 0.595| p_loss: 0.893| v_loss: 0.076| per_loss: 1.977 | a_loss: 0.708
Train: Epoch [53/3000], Step [60/158]| g_loss: 1.944| d_loss: 0.545| gp_loss: 0.034| r_loss: 0.593| p_loss: 0.904| v_loss: 0.079| per_loss: 1.892 | a_loss: 0.630
Train: Epoch [53/3000], Step [90/158]| g_loss: 1.978| d_loss: 0.441| gp_loss: 0.035| r_loss: 0.605| p_loss: 0.874| v_loss: 0.081| per_loss: 1.861 | a_loss: 0.669
Train: Epoch [53/3000], Step [120/158]| g_loss: 1.973| d_loss: 0.432| gp_loss: 0.036| r_loss: 0.604| p_loss: 0.906| v_loss: 0.077| per_loss: 1.909 | a_loss: 0.649
Train: Epoch [53/3000], Step [150/158]| g_loss: 2.058| d_loss: 0.419| gp_loss: 0.035| r_loss: 0.629| p_loss: 0.924| v_loss: 0.076| per_loss: 1.891 | a_loss: 0.702
Train: Epoch [54/3000], Step [30/158]| g_loss: 1.896| d_loss: 0.582| gp_loss: 0.148| r_loss: 0.577| p_loss: 0.873| v_loss: 0.071| per_loss: 1.908 | a_loss: 0.621
Train: Epoch [54/3000], Step [60/158]| g_loss: 2.004| d_loss: 0.421| gp_loss: 0.035| r_loss: 0.612| p_loss: 0.895| v_loss: 0.077| per_loss: 1.917 | a_loss: 0.676
Train: Epoch [54/3000], Step [90/158]| g_loss: 1.938| d_loss: 0.441| gp_loss: 0.036| r_loss: 0.582| p_loss: 0.875| v_loss: 0.072| per_loss: 1.946 | a_loss: 0.652
Train: Epoch [54/3000], Step [120/158]| g_loss: 1.936| d_loss: 0.432| gp_loss: 0.036| r_loss: 0.591| p_loss: 0.817| v_loss: 0.080| per_loss: 1.831 | a_loss: 0.673
Train: Epoch [54/3000], Step [150/158]| g_loss: 2.017| d_loss: 0.403| gp_loss: 0.035| r_loss: 0.599| p_loss: 0.861| v_loss: 0.079| per_loss: 1.955 | a_loss: 0.713
Train: Epoch [55/3000], Step [30/158]| g_loss: 1.946| d_loss: 0.488| gp_loss: 0.080| r_loss: 0.575| p_loss: 0.832| v_loss: 0.076| per_loss: 1.953 | a_loss: 0.684
Train: Epoch [55/3000], Step [60/158]| g_loss: 1.933| d_loss: 0.442| gp_loss: 0.036| r_loss: 0.582| p_loss: 0.843| v_loss: 0.075| per_loss: 1.967 | a_loss: 0.658
Train: Epoch [55/3000], Step [90/158]| g_loss: 1.956| d_loss: 0.400| gp_loss: 0.037| r_loss: 0.573| p_loss: 0.841| v_loss: 0.074| per_loss: 1.947 | a_loss: 0.694
Train: Epoch [55/3000], Step [120/158]| g_loss: 1.936| d_loss: 0.478| gp_loss: 0.036| r_loss: 0.607| p_loss: 0.847| v_loss: 0.077| per_loss: 1.897 | a_loss: 0.638
Train: Epoch [55/3000], Step [150/158]| g_loss: 1.977| d_loss: 0.475| gp_loss: 0.040| r_loss: 0.605| p_loss: 0.881| v_loss: 0.079| per_loss: 1.945 | a_loss: 0.659
Train: Epoch [56/3000], Step [30/158]| g_loss: 1.955| d_loss: 0.566| gp_loss: 0.105| r_loss: 0.626| p_loss: 0.900| v_loss: 0.076| per_loss: 1.912 | a_loss: 0.611
Train: Epoch [56/3000], Step [60/158]| g_loss: 1.956| d_loss: 0.469| gp_loss: 0.037| r_loss: 0.590| p_loss: 0.842| v_loss: 0.074| per_loss: 1.901 | a_loss: 0.680
Train: Epoch [56/3000], Step [90/158]| g_loss: 1.927| d_loss: 0.383| gp_loss: 0.038| r_loss: 0.575| p_loss: 0.837| v_loss: 0.078| per_loss: 1.862 | a_loss: 0.669
Train: Epoch [56/3000], Step [120/158]| g_loss: 1.942| d_loss: 0.350| gp_loss: 0.038| r_loss: 0.558| p_loss: 0.800| v_loss: 0.076| per_loss: 1.855 | a_loss: 0.723
Train: Epoch [56/3000], Step [150/158]| g_loss: 1.951| d_loss: 0.420| gp_loss: 0.037| r_loss: 0.573| p_loss: 0.838| v_loss: 0.079| per_loss: 1.832 | a_loss: 0.697
Train: Epoch [57/3000], Step [30/158]| g_loss: 1.966| d_loss: 0.490| gp_loss: 0.115| r_loss: 0.594| p_loss: 0.858| v_loss: 0.081| per_loss: 1.860 | a_loss: 0.676
Train: Epoch [57/3000], Step [60/158]| g_loss: 1.919| d_loss: 0.394| gp_loss: 0.036| r_loss: 0.544| p_loss: 0.798| v_loss: 0.075| per_loss: 1.875 | a_loss: 0.713
Train: Epoch [57/3000], Step [90/158]| g_loss: 1.931| d_loss: 0.432| gp_loss: 0.039| r_loss: 0.571| p_loss: 0.834| v_loss: 0.079| per_loss: 1.834 | a_loss: 0.681
Train: Epoch [57/3000], Step [120/158]| g_loss: 1.909| d_loss: 0.499| gp_loss: 0.039| r_loss: 0.585| p_loss: 0.862| v_loss: 0.074| per_loss: 1.832 | a_loss: 0.636
Train: Epoch [57/3000], Step [150/158]| g_loss: 1.911| d_loss: 0.416| gp_loss: 0.040| r_loss: 0.592| p_loss: 0.829| v_loss: 0.074| per_loss: 1.806 | a_loss: 0.649
Train: Epoch [58/3000], Step [30/158]| g_loss: 1.918| d_loss: 0.509| gp_loss: 0.126| r_loss: 0.584| p_loss: 0.835| v_loss: 0.077| per_loss: 1.798 | a_loss: 0.660
Train: Epoch [58/3000], Step [60/158]| g_loss: 1.855| d_loss: 0.492| gp_loss: 0.041| r_loss: 0.554| p_loss: 0.816| v_loss: 0.078| per_loss: 1.795 | a_loss: 0.635
Train: Epoch [58/3000], Step [90/158]| g_loss: 1.903| d_loss: 0.488| gp_loss: 0.040| r_loss: 0.597| p_loss: 0.852| v_loss: 0.075| per_loss: 1.753 | a_loss: 0.630
Train: Epoch [58/3000], Step [120/158]| g_loss: 1.931| d_loss: 0.477| gp_loss: 0.041| r_loss: 0.598| p_loss: 0.849| v_loss: 0.076| per_loss: 1.827 | a_loss: 0.650
Train: Epoch [58/3000], Step [150/158]| g_loss: 1.963| d_loss: 0.370| gp_loss: 0.040| r_loss: 0.566| p_loss: 0.846| v_loss: 0.074| per_loss: 1.771 | a_loss: 0.722
Train: Epoch [59/3000], Step [30/158]| g_loss: 1.928| d_loss: 0.564| gp_loss: 0.112| r_loss: 0.606| p_loss: 0.858| v_loss: 0.071| per_loss: 1.840 | a_loss: 0.638
Train: Epoch [59/3000], Step [60/158]| g_loss: 1.837| d_loss: 0.471| gp_loss: 0.038| r_loss: 0.544| p_loss: 0.823| v_loss: 0.076| per_loss: 1.725 | a_loss: 0.634
Train: Epoch [59/3000], Step [90/158]| g_loss: 1.956| d_loss: 0.407| gp_loss: 0.039| r_loss: 0.587| p_loss: 0.854| v_loss: 0.076| per_loss: 1.764 | a_loss: 0.690
Train: Epoch [59/3000], Step [120/158]| g_loss: 1.893| d_loss: 0.497| gp_loss: 0.039| r_loss: 0.575| p_loss: 0.841| v_loss: 0.075| per_loss: 1.785 | a_loss: 0.643
Train: Epoch [59/3000], Step [150/158]| g_loss: 1.937| d_loss: 0.439| gp_loss: 0.041| r_loss: 0.577| p_loss: 0.832| v_loss: 0.076| per_loss: 1.790 | a_loss: 0.688
Train: Epoch [60/3000], Step [30/158]| g_loss: 1.871| d_loss: 0.527| gp_loss: 0.119| r_loss: 0.550| p_loss: 0.819| v_loss: 0.071| per_loss: 1.828 | a_loss: 0.658
Train: Epoch [60/3000], Step [60/158]| g_loss: 1.895| d_loss: 0.457| gp_loss: 0.038| r_loss: 0.568| p_loss: 0.840| v_loss: 0.075| per_loss: 1.800 | a_loss: 0.652
Train: Epoch [60/3000], Step [90/158]| g_loss: 1.928| d_loss: 0.494| gp_loss: 0.041| r_loss: 0.603| p_loss: 0.861| v_loss: 0.075| per_loss: 1.823 | a_loss: 0.637
Train: Epoch [60/3000], Step [120/158]| g_loss: 1.954| d_loss: 0.387| gp_loss: 0.039| r_loss: 0.564| p_loss: 0.856| v_loss: 0.079| per_loss: 1.796 | a_loss: 0.703
Train: Epoch [60/3000], Step [150/158]| g_loss: 1.913| d_loss: 0.489| gp_loss: 0.040| r_loss: 0.580| p_loss: 0.824| v_loss: 0.078| per_loss: 1.809 | a_loss: 0.663
Train: Epoch [61/3000], Step [30/158]| g_loss: 1.911| d_loss: 0.537| gp_loss: 0.096| r_loss: 0.557| p_loss: 0.862| v_loss: 0.077| per_loss: 1.781 | a_loss: 0.668
Train: Epoch [61/3000], Step [60/158]| g_loss: 1.981| d_loss: 0.435| gp_loss: 0.039| r_loss: 0.617| p_loss: 0.868| v_loss: 0.079| per_loss: 1.803 | a_loss: 0.671
Train: Epoch [61/3000], Step [90/158]| g_loss: 1.923| d_loss: 0.487| gp_loss: 0.039| r_loss: 0.580| p_loss: 0.843| v_loss: 0.076| per_loss: 1.778 | a_loss: 0.667
Train: Epoch [61/3000], Step [120/158]| g_loss: 1.901| d_loss: 0.499| gp_loss: 0.042| r_loss: 0.599| p_loss: 0.852| v_loss: 0.074| per_loss: 1.876 | a_loss: 0.615
Train: Epoch [61/3000], Step [150/158]| g_loss: 1.889| d_loss: 0.468| gp_loss: 0.042| r_loss: 0.565| p_loss: 0.839| v_loss: 0.074| per_loss: 1.801 | a_loss: 0.651
Train: Epoch [62/3000], Step [30/158]| g_loss: 1.873| d_loss: 0.522| gp_loss: 0.142| r_loss: 0.551| p_loss: 0.818| v_loss: 0.076| per_loss: 1.852 | a_loss: 0.652
Train: Epoch [62/3000], Step [60/158]| g_loss: 1.916| d_loss: 0.464| gp_loss: 0.039| r_loss: 0.590| p_loss: 0.873| v_loss: 0.075| per_loss: 1.803 | a_loss: 0.635
Train: Epoch [62/3000], Step [90/158]| g_loss: 1.909| d_loss: 0.497| gp_loss: 0.041| r_loss: 0.598| p_loss: 0.830| v_loss: 0.077| per_loss: 1.786 | a_loss: 0.640
Train: Epoch [62/3000], Step [120/158]| g_loss: 1.916| d_loss: 0.520| gp_loss: 0.042| r_loss: 0.613| p_loss: 0.871| v_loss: 0.076| per_loss: 1.779 | a_loss: 0.614
Train: Epoch [62/3000], Step [150/158]| g_loss: 1.880| d_loss: 0.556| gp_loss: 0.041| r_loss: 0.585| p_loss: 0.880| v_loss: 0.079| per_loss: 1.835 | a_loss: 0.593
Train: Epoch [63/3000], Step [30/158]| g_loss: 1.836| d_loss: 0.656| gp_loss: 0.117| r_loss: 0.557| p_loss: 0.825| v_loss: 0.076| per_loss: 1.809 | a_loss: 0.610
Train: Epoch [63/3000], Step [60/158]| g_loss: 1.869| d_loss: 0.533| gp_loss: 0.040| r_loss: 0.569| p_loss: 0.841| v_loss: 0.079| per_loss: 1.773 | a_loss: 0.623
Train: Epoch [63/3000], Step [90/158]| g_loss: 1.954| d_loss: 0.472| gp_loss: 0.038| r_loss: 0.592| p_loss: 0.853| v_loss: 0.076| per_loss: 1.755 | a_loss: 0.684
Train: Epoch [63/3000], Step [120/158]| g_loss: 1.928| d_loss: 0.448| gp_loss: 0.038| r_loss: 0.579| p_loss: 0.871| v_loss: 0.077| per_loss: 1.812 | a_loss: 0.656
Train: Epoch [63/3000], Step [150/158]| g_loss: 1.860| d_loss: 0.610| gp_loss: 0.038| r_loss: 0.609| p_loss: 0.847| v_loss: 0.076| per_loss: 1.732 | a_loss: 0.579
Train: Epoch [64/3000], Step [30/158]| g_loss: 1.863| d_loss: 0.615| gp_loss: 0.092| r_loss: 0.592| p_loss: 0.848| v_loss: 0.073| per_loss: 1.779 | a_loss: 0.596
Train: Epoch [64/3000], Step [60/158]| g_loss: 1.874| d_loss: 0.546| gp_loss: 0.036| r_loss: 0.583| p_loss: 0.867| v_loss: 0.077| per_loss: 1.756 | a_loss: 0.605
Train: Epoch [64/3000], Step [90/158]| g_loss: 1.858| d_loss: 0.549| gp_loss: 0.036| r_loss: 0.584| p_loss: 0.838| v_loss: 0.080| per_loss: 1.718 | a_loss: 0.603
Train: Epoch [64/3000], Step [120/158]| g_loss: 1.821| d_loss: 0.622| gp_loss: 0.037| r_loss: 0.585| p_loss: 0.830| v_loss: 0.077| per_loss: 1.724 | a_loss: 0.572
Train: Epoch [64/3000], Step [150/158]| g_loss: 1.888| d_loss: 0.484| gp_loss: 0.036| r_loss: 0.574| p_loss: 0.826| v_loss: 0.078| per_loss: 1.781 | a_loss: 0.645
Train: Epoch [65/3000], Step [30/158]| g_loss: 1.867| d_loss: 0.635| gp_loss: 0.061| r_loss: 0.593| p_loss: 0.849| v_loss: 0.082| per_loss: 1.816 | a_loss: 0.586
Train: Epoch [65/3000], Step [60/158]| g_loss: 1.861| d_loss: 0.578| gp_loss: 0.036| r_loss: 0.590| p_loss: 0.850| v_loss: 0.079| per_loss: 1.754 | a_loss: 0.592
Train: Epoch [65/3000], Step [90/158]| g_loss: 1.896| d_loss: 0.501| gp_loss: 0.035| r_loss: 0.603| p_loss: 0.852| v_loss: 0.080| per_loss: 1.714 | a_loss: 0.616
Train: Epoch [65/3000], Step [120/158]| g_loss: 1.859| d_loss: 0.566| gp_loss: 0.034| r_loss: 0.575| p_loss: 0.813| v_loss: 0.077| per_loss: 1.746 | a_loss: 0.626
Train: Epoch [65/3000], Step [150/158]| g_loss: 1.875| d_loss: 0.625| gp_loss: 0.034| r_loss: 0.570| p_loss: 0.862| v_loss: 0.080| per_loss: 1.754 | a_loss: 0.619
Train: Epoch [66/3000], Step [30/158]| g_loss: 1.841| d_loss: 0.662| gp_loss: 0.102| r_loss: 0.598| p_loss: 0.842| v_loss: 0.078| per_loss: 1.728 | a_loss: 0.572
Train: Epoch [66/3000], Step [60/158]| g_loss: 1.914| d_loss: 0.586| gp_loss: 0.031| r_loss: 0.611| p_loss: 0.872| v_loss: 0.081| per_loss: 1.743 | a_loss: 0.611
Train: Epoch [66/3000], Step [90/158]| g_loss: 1.983| d_loss: 0.464| gp_loss: 0.032| r_loss: 0.629| p_loss: 0.915| v_loss: 0.087| per_loss: 1.711 | a_loss: 0.638
Train: Epoch [66/3000], Step [120/158]| g_loss: 1.940| d_loss: 0.544| gp_loss: 0.032| r_loss: 0.613| p_loss: 0.882| v_loss: 0.080| per_loss: 1.709 | a_loss: 0.635
Train: Epoch [66/3000], Step [150/158]| g_loss: 1.866| d_loss: 0.502| gp_loss: 0.034| r_loss: 0.604| p_loss: 0.848| v_loss: 0.076| per_loss: 1.697 | a_loss: 0.593
Train: Epoch [67/3000], Step [30/158]| g_loss: 1.906| d_loss: 0.609| gp_loss: 0.124| r_loss: 0.581| p_loss: 0.832| v_loss: 0.080| per_loss: 1.766 | a_loss: 0.653
Train: Epoch [67/3000], Step [60/158]| g_loss: 1.881| d_loss: 0.592| gp_loss: 0.033| r_loss: 0.602| p_loss: 0.838| v_loss: 0.077| per_loss: 1.778 | a_loss: 0.606
Train: Epoch [67/3000], Step [90/158]| g_loss: 1.849| d_loss: 0.614| gp_loss: 0.032| r_loss: 0.580| p_loss: 0.860| v_loss: 0.080| per_loss: 1.809 | a_loss: 0.578
Train: Epoch [67/3000], Step [120/158]| g_loss: 1.780| d_loss: 0.527| gp_loss: 0.031| r_loss: 0.553| p_loss: 0.780| v_loss: 0.082| per_loss: 1.643 | a_loss: 0.590
Train: Epoch [67/3000], Step [150/158]| g_loss: 1.893| d_loss: 0.459| gp_loss: 0.032| r_loss: 0.575| p_loss: 0.814| v_loss: 0.082| per_loss: 1.766 | a_loss: 0.652
Train: Epoch [68/3000], Step [30/158]| g_loss: 1.880| d_loss: 0.605| gp_loss: 0.107| r_loss: 0.585| p_loss: 0.812| v_loss: 0.079| per_loss: 1.811 | a_loss: 0.629
Train: Epoch [68/3000], Step [60/158]| g_loss: 1.863| d_loss: 0.461| gp_loss: 0.031| r_loss: 0.577| p_loss: 0.797| v_loss: 0.081| per_loss: 1.713 | a_loss: 0.635
Train: Epoch [68/3000], Step [90/158]| g_loss: 1.838| d_loss: 0.547| gp_loss: 0.030| r_loss: 0.586| p_loss: 0.810| v_loss: 0.081| per_loss: 1.742 | a_loss: 0.592
Train: Epoch [68/3000], Step [120/158]| g_loss: 1.857| d_loss: 0.473| gp_loss: 0.031| r_loss: 0.571| p_loss: 0.780| v_loss: 0.086| per_loss: 1.661 | a_loss: 0.644
Train: Epoch [68/3000], Step [150/158]| g_loss: 1.881| d_loss: 0.553| gp_loss: 0.031| r_loss: 0.586| p_loss: 0.820| v_loss: 0.081| per_loss: 1.749 | a_loss: 0.629
Train: Epoch [69/3000], Step [30/158]| g_loss: 1.880| d_loss: 0.633| gp_loss: 0.131| r_loss: 0.589| p_loss: 0.812| v_loss: 0.083| per_loss: 1.687 | a_loss: 0.633
Train: Epoch [69/3000], Step [60/158]| g_loss: 1.842| d_loss: 0.505| gp_loss: 0.031| r_loss: 0.598| p_loss: 0.803| v_loss: 0.079| per_loss: 1.754 | a_loss: 0.588
Train: Epoch [69/3000], Step [90/158]| g_loss: 1.858| d_loss: 0.465| gp_loss: 0.029| r_loss: 0.560| p_loss: 0.819| v_loss: 0.079| per_loss: 1.743 | a_loss: 0.635
Train: Epoch [69/3000], Step [120/158]| g_loss: 1.883| d_loss: 0.463| gp_loss: 0.031| r_loss: 0.561| p_loss: 0.810| v_loss: 0.079| per_loss: 1.759 | a_loss: 0.662
Train: Epoch [69/3000], Step [150/158]| g_loss: 1.842| d_loss: 0.529| gp_loss: 0.032| r_loss: 0.566| p_loss: 0.824| v_loss: 0.072| per_loss: 1.774 | a_loss: 0.615
Train: Epoch [70/3000], Step [30/158]| g_loss: 1.943| d_loss: 0.515| gp_loss: 0.101| r_loss: 0.608| p_loss: 0.820| v_loss: 0.075| per_loss: 1.767 | a_loss: 0.674
Train: Epoch [70/3000], Step [60/158]| g_loss: 1.852| d_loss: 0.576| gp_loss: 0.030| r_loss: 0.596| p_loss: 0.824| v_loss: 0.083| per_loss: 1.821 | a_loss: 0.580
Train: Epoch [70/3000], Step [90/158]| g_loss: 1.843| d_loss: 0.562| gp_loss: 0.032| r_loss: 0.566| p_loss: 0.846| v_loss: 0.079| per_loss: 1.830 | a_loss: 0.591
Train: Epoch [70/3000], Step [120/158]| g_loss: 1.843| d_loss: 0.564| gp_loss: 0.032| r_loss: 0.578| p_loss: 0.841| v_loss: 0.081| per_loss: 1.815 | a_loss: 0.581
Train: Epoch [70/3000], Step [150/158]| g_loss: 1.936| d_loss: 0.400| gp_loss: 0.032| r_loss: 0.561| p_loss: 0.828| v_loss: 0.083| per_loss: 1.722 | a_loss: 0.706
Train: Epoch [71/3000], Step [30/158]| g_loss: 1.893| d_loss: 0.571| gp_loss: 0.075| r_loss: 0.573| p_loss: 0.826| v_loss: 0.080| per_loss: 1.763 | a_loss: 0.651
Train: Epoch [71/3000], Step [60/158]| g_loss: 1.945| d_loss: 0.437| gp_loss: 0.032| r_loss: 0.593| p_loss: 0.842| v_loss: 0.079| per_loss: 1.828 | a_loss: 0.669
Train: Epoch [71/3000], Step [90/158]| g_loss: 1.935| d_loss: 0.434| gp_loss: 0.033| r_loss: 0.584| p_loss: 0.809| v_loss: 0.079| per_loss: 1.812 | a_loss: 0.686
Train: Epoch [71/3000], Step [120/158]| g_loss: 1.822| d_loss: 0.573| gp_loss: 0.034| r_loss: 0.554| p_loss: 0.801| v_loss: 0.078| per_loss: 1.791 | a_loss: 0.610
Train: Epoch [71/3000], Step [150/158]| g_loss: 1.835| d_loss: 0.507| gp_loss: 0.034| r_loss: 0.544| p_loss: 0.792| v_loss: 0.077| per_loss: 1.799 | a_loss: 0.637
Train: Epoch [72/3000], Step [30/158]| g_loss: 1.827| d_loss: 0.619| gp_loss: 0.109| r_loss: 0.552| p_loss: 0.826| v_loss: 0.078| per_loss: 1.772 | a_loss: 0.607
Train: Epoch [72/3000], Step [60/158]| g_loss: 1.781| d_loss: 0.614| gp_loss: 0.032| r_loss: 0.544| p_loss: 0.805| v_loss: 0.072| per_loss: 1.812 | a_loss: 0.581
Train: Epoch [72/3000], Step [90/158]| g_loss: 1.854| d_loss: 0.435| gp_loss: 0.032| r_loss: 0.547| p_loss: 0.808| v_loss: 0.078| per_loss: 1.685 | a_loss: 0.656
Train: Epoch [72/3000], Step [120/158]| g_loss: 1.897| d_loss: 0.427| gp_loss: 0.033| r_loss: 0.563| p_loss: 0.787| v_loss: 0.077| per_loss: 1.772 | a_loss: 0.686
Train: Epoch [72/3000], Step [150/158]| g_loss: 1.818| d_loss: 0.564| gp_loss: 0.033| r_loss: 0.564| p_loss: 0.835| v_loss: 0.077| per_loss: 1.733 | a_loss: 0.586
Train: Epoch [73/3000], Step [30/158]| g_loss: 1.805| d_loss: 0.561| gp_loss: 0.087| r_loss: 0.553| p_loss: 0.779| v_loss: 0.076| per_loss: 1.722 | a_loss: 0.614
Train: Epoch [73/3000], Step [60/158]| g_loss: 1.824| d_loss: 0.474| gp_loss: 0.034| r_loss: 0.532| p_loss: 0.779| v_loss: 0.072| per_loss: 1.743 | a_loss: 0.655
Train: Epoch [73/3000], Step [90/158]| g_loss: 1.799| d_loss: 0.488| gp_loss: 0.036| r_loss: 0.536| p_loss: 0.774| v_loss: 0.073| per_loss: 1.737 | a_loss: 0.629
Train: Epoch [73/3000], Step [120/158]| g_loss: 1.870| d_loss: 0.483| gp_loss: 0.037| r_loss: 0.562| p_loss: 0.815| v_loss: 0.077| per_loss: 1.737 | a_loss: 0.650
Train: Epoch [73/3000], Step [150/158]| g_loss: 1.794| d_loss: 0.496| gp_loss: 0.036| r_loss: 0.523| p_loss: 0.770| v_loss: 0.076| per_loss: 1.671 | a_loss: 0.643
Train: Epoch [74/3000], Step [30/158]| g_loss: 1.851| d_loss: 0.536| gp_loss: 0.096| r_loss: 0.545| p_loss: 0.812| v_loss: 0.075| per_loss: 1.748 | a_loss: 0.650
Train: Epoch [74/3000], Step [60/158]| g_loss: 1.851| d_loss: 0.511| gp_loss: 0.038| r_loss: 0.553| p_loss: 0.808| v_loss: 0.071| per_loss: 1.867 | a_loss: 0.637
Train: Epoch [74/3000], Step [90/158]| g_loss: 1.874| d_loss: 0.454| gp_loss: 0.037| r_loss: 0.570| p_loss: 0.799| v_loss: 0.076| per_loss: 1.716 | a_loss: 0.657
Train: Epoch [74/3000], Step [120/158]| g_loss: 1.820| d_loss: 0.496| gp_loss: 0.038| r_loss: 0.513| p_loss: 0.802| v_loss: 0.076| per_loss: 1.716 | a_loss: 0.659
Train: Epoch [74/3000], Step [150/158]| g_loss: 1.812| d_loss: 0.489| gp_loss: 0.038| r_loss: 0.520| p_loss: 0.797| v_loss: 0.079| per_loss: 1.768 | a_loss: 0.638
Train: Epoch [75/3000], Step [30/158]| g_loss: 1.858| d_loss: 0.571| gp_loss: 0.142| r_loss: 0.545| p_loss: 0.808| v_loss: 0.080| per_loss: 1.700 | a_loss: 0.659
Train: Epoch [75/3000], Step [60/158]| g_loss: 1.814| d_loss: 0.457| gp_loss: 0.035| r_loss: 0.535| p_loss: 0.754| v_loss: 0.075| per_loss: 1.689 | a_loss: 0.657
Train: Epoch [75/3000], Step [90/158]| g_loss: 1.786| d_loss: 0.490| gp_loss: 0.035| r_loss: 0.522| p_loss: 0.775| v_loss: 0.078| per_loss: 1.680 | a_loss: 0.630
Train: Epoch [75/3000], Step [120/158]| g_loss: 1.822| d_loss: 0.461| gp_loss: 0.036| r_loss: 0.533| p_loss: 0.784| v_loss: 0.074| per_loss: 1.680 | a_loss: 0.655
Train: Epoch [75/3000], Step [150/158]| g_loss: 1.859| d_loss: 0.425| gp_loss: 0.035| r_loss: 0.549| p_loss: 0.777| v_loss: 0.075| per_loss: 1.779 | a_loss: 0.669
Train: Epoch [76/3000], Step [30/158]| g_loss: 1.789| d_loss: 0.580| gp_loss: 0.096| r_loss: 0.534| p_loss: 0.785| v_loss: 0.071| per_loss: 1.770 | a_loss: 0.614
Train: Epoch [76/3000], Step [60/158]| g_loss: 1.840| d_loss: 0.387| gp_loss: 0.035| r_loss: 0.535| p_loss: 0.766| v_loss: 0.075| per_loss: 1.818 | a_loss: 0.665
Train: Epoch [76/3000], Step [90/158]| g_loss: 1.915| d_loss: 0.446| gp_loss: 0.032| r_loss: 0.561| p_loss: 0.839| v_loss: 0.076| per_loss: 1.759 | a_loss: 0.683
Train: Epoch [76/3000], Step [120/158]| g_loss: 1.840| d_loss: 0.572| gp_loss: 0.033| r_loss: 0.543| p_loss: 0.812| v_loss: 0.080| per_loss: 1.841 | a_loss: 0.627
Train: Epoch [76/3000], Step [150/158]| g_loss: 1.788| d_loss: 0.524| gp_loss: 0.036| r_loss: 0.528| p_loss: 0.792| v_loss: 0.076| per_loss: 1.864 | a_loss: 0.602
Train: Epoch [77/3000], Step [30/158]| g_loss: 1.777| d_loss: 0.593| gp_loss: 0.089| r_loss: 0.528| p_loss: 0.784| v_loss: 0.074| per_loss: 1.850 | a_loss: 0.598
Train: Epoch [77/3000], Step [60/158]| g_loss: 1.839| d_loss: 0.412| gp_loss: 0.033| r_loss: 0.518| p_loss: 0.767| v_loss: 0.071| per_loss: 1.830 | a_loss: 0.683
Train: Epoch [77/3000], Step [90/158]| g_loss: 1.748| d_loss: 0.517| gp_loss: 0.035| r_loss: 0.529| p_loss: 0.769| v_loss: 0.072| per_loss: 1.752 | a_loss: 0.588
Train: Epoch [77/3000], Step [120/158]| g_loss: 1.809| d_loss: 0.485| gp_loss: 0.037| r_loss: 0.532| p_loss: 0.790| v_loss: 0.079| per_loss: 1.723 | a_loss: 0.631
Train: Epoch [77/3000], Step [150/158]| g_loss: 1.745| d_loss: 0.514| gp_loss: 0.036| r_loss: 0.516| p_loss: 0.762| v_loss: 0.076| per_loss: 1.641 | a_loss: 0.607
Train: Epoch [78/3000], Step [30/158]| g_loss: 1.833| d_loss: 0.446| gp_loss: 0.087| r_loss: 0.532| p_loss: 0.765| v_loss: 0.075| per_loss: 1.730 | a_loss: 0.670
Train: Epoch [78/3000], Step [60/158]| g_loss: 1.778| d_loss: 0.472| gp_loss: 0.035| r_loss: 0.515| p_loss: 0.751| v_loss: 0.075| per_loss: 1.690 | a_loss: 0.644
Train: Epoch [78/3000], Step [90/158]| g_loss: 1.754| d_loss: 0.468| gp_loss: 0.035| r_loss: 0.503| p_loss: 0.749| v_loss: 0.080| per_loss: 1.679 | a_loss: 0.629
Train: Epoch [78/3000], Step [120/158]| g_loss: 1.719| d_loss: 0.519| gp_loss: 0.035| r_loss: 0.491| p_loss: 0.732| v_loss: 0.075| per_loss: 1.699 | a_loss: 0.616
Train: Epoch [78/3000], Step [150/158]| g_loss: 1.776| d_loss: 0.483| gp_loss: 0.037| r_loss: 0.513| p_loss: 0.754| v_loss: 0.077| per_loss: 1.694 | a_loss: 0.641
Train: Epoch [79/3000], Step [30/158]| g_loss: 1.823| d_loss: 0.469| gp_loss: 0.080| r_loss: 0.511| p_loss: 0.750| v_loss: 0.075| per_loss: 1.722 | a_loss: 0.690
Train: Epoch [79/3000], Step [60/158]| g_loss: 1.781| d_loss: 0.433| gp_loss: 0.034| r_loss: 0.510| p_loss: 0.712| v_loss: 0.078| per_loss: 1.774 | a_loss: 0.660
Train: Epoch [79/3000], Step [90/158]| g_loss: 1.826| d_loss: 0.517| gp_loss: 0.036| r_loss: 0.542| p_loss: 0.790| v_loss: 0.077| per_loss: 1.740 | a_loss: 0.638
Train: Epoch [79/3000], Step [120/158]| g_loss: 1.757| d_loss: 0.488| gp_loss: 0.036| r_loss: 0.506| p_loss: 0.751| v_loss: 0.074| per_loss: 1.724 | a_loss: 0.630
Train: Epoch [79/3000], Step [150/158]| g_loss: 1.800| d_loss: 0.470| gp_loss: 0.037| r_loss: 0.527| p_loss: 0.762| v_loss: 0.077| per_loss: 1.773 | a_loss: 0.637
Train: Epoch [80/3000], Step [30/158]| g_loss: 1.774| d_loss: 0.487| gp_loss: 0.090| r_loss: 0.501| p_loss: 0.746| v_loss: 0.075| per_loss: 1.797 | a_loss: 0.645
Train: Epoch [80/3000], Step [60/158]| g_loss: 1.741| d_loss: 0.514| gp_loss: 0.038| r_loss: 0.503| p_loss: 0.724| v_loss: 0.077| per_loss: 1.749 | a_loss: 0.623
Train: Epoch [80/3000], Step [90/158]| g_loss: 1.793| d_loss: 0.460| gp_loss: 0.037| r_loss: 0.513| p_loss: 0.736| v_loss: 0.078| per_loss: 1.772 | a_loss: 0.657
Train: Epoch [80/3000], Step [120/158]| g_loss: 1.790| d_loss: 0.462| gp_loss: 0.039| r_loss: 0.513| p_loss: 0.748| v_loss: 0.073| per_loss: 1.850 | a_loss: 0.645
Train: Epoch [80/3000], Step [150/158]| g_loss: 1.827| d_loss: 0.467| gp_loss: 0.036| r_loss: 0.524| p_loss: 0.771| v_loss: 0.075| per_loss: 1.803 | a_loss: 0.663
Train: Epoch [81/3000], Step [30/158]| g_loss: 1.858| d_loss: 0.488| gp_loss: 0.089| r_loss: 0.536| p_loss: 0.772| v_loss: 0.081| per_loss: 1.807 | a_loss: 0.674
Train: Epoch [81/3000], Step [60/158]| g_loss: 1.795| d_loss: 0.423| gp_loss: 0.039| r_loss: 0.504| p_loss: 0.757| v_loss: 0.075| per_loss: 1.838 | a_loss: 0.654
Train: Epoch [81/3000], Step [90/158]| g_loss: 1.787| d_loss: 0.470| gp_loss: 0.037| r_loss: 0.511| p_loss: 0.758| v_loss: 0.075| per_loss: 1.773 | a_loss: 0.645
Train: Epoch [81/3000], Step [120/158]| g_loss: 1.740| d_loss: 0.534| gp_loss: 0.038| r_loss: 0.513| p_loss: 0.747| v_loss: 0.076| per_loss: 1.817 | a_loss: 0.597
Train: Epoch [81/3000], Step [150/158]| g_loss: 1.790| d_loss: 0.447| gp_loss: 0.039| r_loss: 0.508| p_loss: 0.757| v_loss: 0.078| per_loss: 1.848 | a_loss: 0.640
Train: Epoch [82/3000], Step [30/158]| g_loss: 1.828| d_loss: 0.471| gp_loss: 0.085| r_loss: 0.514| p_loss: 0.749| v_loss: 0.078| per_loss: 1.805 | a_loss: 0.681
Train: Epoch [82/3000], Step [60/158]| g_loss: 1.826| d_loss: 0.442| gp_loss: 0.039| r_loss: 0.505| p_loss: 0.767| v_loss: 0.074| per_loss: 1.854 | a_loss: 0.677
Train: Epoch [82/3000], Step [90/158]| g_loss: 1.798| d_loss: 0.411| gp_loss: 0.038| r_loss: 0.509| p_loss: 0.735| v_loss: 0.076| per_loss: 1.741 | a_loss: 0.671
Train: Epoch [82/3000], Step [120/158]| g_loss: 1.780| d_loss: 0.545| gp_loss: 0.040| r_loss: 0.518| p_loss: 0.781| v_loss: 0.077| per_loss: 1.769 | a_loss: 0.618
Train: Epoch [82/3000], Step [150/158]| g_loss: 1.773| d_loss: 0.517| gp_loss: 0.039| r_loss: 0.507| p_loss: 0.757| v_loss: 0.075| per_loss: 1.837 | a_loss: 0.628
Train: Epoch [83/3000], Step [30/158]| g_loss: 1.830| d_loss: 0.504| gp_loss: 0.082| r_loss: 0.519| p_loss: 0.753| v_loss: 0.080| per_loss: 1.777 | a_loss: 0.677
Train: Epoch [83/3000], Step [60/158]| g_loss: 1.797| d_loss: 0.502| gp_loss: 0.037| r_loss: 0.526| p_loss: 0.779| v_loss: 0.078| per_loss: 1.831 | a_loss: 0.621
Train: Epoch [83/3000], Step [90/158]| g_loss: 1.748| d_loss: 0.542| gp_loss: 0.037| r_loss: 0.514| p_loss: 0.758| v_loss: 0.077| per_loss: 1.833 | a_loss: 0.596
Train: Epoch [83/3000], Step [120/158]| g_loss: 1.742| d_loss: 0.543| gp_loss: 0.038| r_loss: 0.510| p_loss: 0.750| v_loss: 0.078| per_loss: 1.753 | a_loss: 0.603
Train: Epoch [83/3000], Step [150/158]| g_loss: 1.818| d_loss: 0.405| gp_loss: 0.036| r_loss: 0.502| p_loss: 0.763| v_loss: 0.080| per_loss: 1.781 | a_loss: 0.676
Train: Epoch [84/3000], Step [30/158]| g_loss: 1.786| d_loss: 0.519| gp_loss: 0.076| r_loss: 0.507| p_loss: 0.742| v_loss: 0.078| per_loss: 1.706 | a_loss: 0.659
Train: Epoch [84/3000], Step [60/158]| g_loss: 1.787| d_loss: 0.485| gp_loss: 0.037| r_loss: 0.513| p_loss: 0.771| v_loss: 0.077| per_loss: 1.713 | a_loss: 0.640
Train: Epoch [84/3000], Step [90/158]| g_loss: 1.815| d_loss: 0.489| gp_loss: 0.034| r_loss: 0.509| p_loss: 0.757| v_loss: 0.076| per_loss: 1.731 | a_loss: 0.680
Train: Epoch [84/3000], Step [120/158]| g_loss: 1.834| d_loss: 0.501| gp_loss: 0.037| r_loss: 0.532| p_loss: 0.780| v_loss: 0.079| per_loss: 1.798 | a_loss: 0.654
Train: Epoch [84/3000], Step [150/158]| g_loss: 1.880| d_loss: 0.507| gp_loss: 0.037| r_loss: 0.567| p_loss: 0.871| v_loss: 0.077| per_loss: 1.727 | a_loss: 0.628
Train: Epoch [85/3000], Step [30/158]| g_loss: 2.029| d_loss: 0.583| gp_loss: 0.125| r_loss: 0.592| p_loss: 1.001| v_loss: 0.076| per_loss: 1.721 | a_loss: 0.688
Train: Epoch [85/3000], Step [60/158]| g_loss: 1.743| d_loss: 0.475| gp_loss: 0.036| r_loss: 0.511| p_loss: 0.781| v_loss: 0.074| per_loss: 1.654 | a_loss: 0.602
Train: Epoch [85/3000], Step [90/158]| g_loss: 1.793| d_loss: 0.488| gp_loss: 0.033| r_loss: 0.495| p_loss: 0.763| v_loss: 0.075| per_loss: 1.720 | a_loss: 0.669
Train: Epoch [85/3000], Step [120/158]| g_loss: 1.724| d_loss: 0.561| gp_loss: 0.035| r_loss: 0.495| p_loss: 0.729| v_loss: 0.080| per_loss: 1.774 | a_loss: 0.607
Train: Epoch [85/3000], Step [150/158]| g_loss: 1.795| d_loss: 0.488| gp_loss: 0.033| r_loss: 0.517| p_loss: 0.751| v_loss: 0.074| per_loss: 1.751 | a_loss: 0.654
Train: Epoch [86/3000], Step [30/158]| g_loss: 1.762| d_loss: 0.573| gp_loss: 0.080| r_loss: 0.504| p_loss: 0.737| v_loss: 0.074| per_loss: 1.706 | a_loss: 0.644
Train: Epoch [86/3000], Step [60/158]| g_loss: 1.684| d_loss: 0.542| gp_loss: 0.033| r_loss: 0.488| p_loss: 0.729| v_loss: 0.076| per_loss: 1.802 | a_loss: 0.575
Train: Epoch [86/3000], Step [90/158]| g_loss: 1.690| d_loss: 0.501| gp_loss: 0.035| r_loss: 0.469| p_loss: 0.741| v_loss: 0.075| per_loss: 1.711 | a_loss: 0.604
Train: Epoch [86/3000], Step [120/158]| g_loss: 1.823| d_loss: 0.459| gp_loss: 0.033| r_loss: 0.510| p_loss: 0.768| v_loss: 0.081| per_loss: 1.770 | a_loss: 0.671
Train: Epoch [86/3000], Step [150/158]| g_loss: 1.724| d_loss: 0.576| gp_loss: 0.034| r_loss: 0.505| p_loss: 0.744| v_loss: 0.079| per_loss: 1.744 | a_loss: 0.593
Train: Epoch [87/3000], Step [30/158]| g_loss: 1.802| d_loss: 0.529| gp_loss: 0.085| r_loss: 0.520| p_loss: 0.767| v_loss: 0.081| per_loss: 1.808 | a_loss: 0.637
Train: Epoch [87/3000], Step [60/158]| g_loss: 1.718| d_loss: 0.616| gp_loss: 0.033| r_loss: 0.499| p_loss: 0.784| v_loss: 0.081| per_loss: 1.762 | a_loss: 0.570
Train: Epoch [87/3000], Step [90/158]| g_loss: 1.741| d_loss: 0.523| gp_loss: 0.033| r_loss: 0.472| p_loss: 0.755| v_loss: 0.080| per_loss: 1.797 | a_loss: 0.632
Train: Epoch [87/3000], Step [120/158]| g_loss: 1.877| d_loss: 0.497| gp_loss: 0.034| r_loss: 0.548| p_loss: 0.792| v_loss: 0.076| per_loss: 1.844 | a_loss: 0.673
Train: Epoch [87/3000], Step [150/158]| g_loss: 1.756| d_loss: 0.527| gp_loss: 0.033| r_loss: 0.476| p_loss: 0.757| v_loss: 0.078| per_loss: 1.827 | a_loss: 0.641
Train: Epoch [88/3000], Step [30/158]| g_loss: 1.725| d_loss: 0.583| gp_loss: 0.112| r_loss: 0.488| p_loss: 0.751| v_loss: 0.077| per_loss: 1.792 | a_loss: 0.606
Train: Epoch [88/3000], Step [60/158]| g_loss: 1.706| d_loss: 0.528| gp_loss: 0.032| r_loss: 0.453| p_loss: 0.759| v_loss: 0.078| per_loss: 1.813 | a_loss: 0.614
Train: Epoch [88/3000], Step [90/158]| g_loss: 1.785| d_loss: 0.501| gp_loss: 0.035| r_loss: 0.510| p_loss: 0.775| v_loss: 0.076| per_loss: 1.890 | a_loss: 0.623
Train: Epoch [88/3000], Step [120/158]| g_loss: 1.778| d_loss: 0.481| gp_loss: 0.035| r_loss: 0.512| p_loss: 0.760| v_loss: 0.078| per_loss: 1.767 | a_loss: 0.631
Train: Epoch [88/3000], Step [150/158]| g_loss: 1.726| d_loss: 0.515| gp_loss: 0.032| r_loss: 0.505| p_loss: 0.741| v_loss: 0.075| per_loss: 1.740 | a_loss: 0.601
Train: Epoch [89/3000], Step [30/158]| g_loss: 1.707| d_loss: 0.707| gp_loss: 0.132| r_loss: 0.501| p_loss: 0.762| v_loss: 0.075| per_loss: 1.759 | a_loss: 0.574
Train: Epoch [89/3000], Step [60/158]| g_loss: 1.642| d_loss: 0.574| gp_loss: 0.031| r_loss: 0.471| p_loss: 0.719| v_loss: 0.072| per_loss: 1.795 | a_loss: 0.560
Train: Epoch [89/3000], Step [90/158]| g_loss: 1.654| d_loss: 0.588| gp_loss: 0.032| r_loss: 0.466| p_loss: 0.739| v_loss: 0.074| per_loss: 1.788 | a_loss: 0.565
Train: Epoch [89/3000], Step [120/158]| g_loss: 1.713| d_loss: 0.552| gp_loss: 0.032| r_loss: 0.484| p_loss: 0.739| v_loss: 0.077| per_loss: 1.767 | a_loss: 0.606
Train: Epoch [89/3000], Step [150/158]| g_loss: 1.723| d_loss: 0.488| gp_loss: 0.032| r_loss: 0.497| p_loss: 0.742| v_loss: 0.082| per_loss: 1.765 | a_loss: 0.597
Train: Epoch [90/3000], Step [30/158]| g_loss: 1.767| d_loss: 0.541| gp_loss: 0.082| r_loss: 0.499| p_loss: 0.734| v_loss: 0.079| per_loss: 1.792 | a_loss: 0.642
Train: Epoch [90/3000], Step [60/158]| g_loss: 1.726| d_loss: 0.517| gp_loss: 0.032| r_loss: 0.483| p_loss: 0.727| v_loss: 0.079| per_loss: 1.776 | a_loss: 0.622
Train: Epoch [90/3000], Step [90/158]| g_loss: 1.700| d_loss: 0.536| gp_loss: 0.031| r_loss: 0.481| p_loss: 0.755| v_loss: 0.080| per_loss: 1.679 | a_loss: 0.593
Train: Epoch [90/3000], Step [120/158]| g_loss: 1.768| d_loss: 0.566| gp_loss: 0.033| r_loss: 0.518| p_loss: 0.798| v_loss: 0.080| per_loss: 1.827 | a_loss: 0.587
Train: Epoch [90/3000], Step [150/158]| g_loss: 1.679| d_loss: 0.510| gp_loss: 0.032| r_loss: 0.460| p_loss: 0.733| v_loss: 0.075| per_loss: 1.847 | a_loss: 0.593
Train: Epoch [91/3000], Step [30/158]| g_loss: 1.747| d_loss: 0.502| gp_loss: 0.061| r_loss: 0.479| p_loss: 0.730| v_loss: 0.077| per_loss: 1.857 | a_loss: 0.640
Train: Epoch [91/3000], Step [60/158]| g_loss: 1.687| d_loss: 0.506| gp_loss: 0.034| r_loss: 0.481| p_loss: 0.730| v_loss: 0.078| per_loss: 1.754 | a_loss: 0.587
Train: Epoch [91/3000], Step [90/158]| g_loss: 1.715| d_loss: 0.529| gp_loss: 0.033| r_loss: 0.488| p_loss: 0.752| v_loss: 0.079| per_loss: 1.797 | a_loss: 0.592
Train: Epoch [91/3000], Step [120/158]| g_loss: 1.663| d_loss: 0.554| gp_loss: 0.034| r_loss: 0.473| p_loss: 0.730| v_loss: 0.077| per_loss: 1.719 | a_loss: 0.577
Train: Epoch [91/3000], Step [150/158]| g_loss: 1.699| d_loss: 0.563| gp_loss: 0.034| r_loss: 0.495| p_loss: 0.743| v_loss: 0.072| per_loss: 1.830 | a_loss: 0.576
Train: Epoch [92/3000], Step [30/158]| g_loss: 1.732| d_loss: 0.588| gp_loss: 0.096| r_loss: 0.485| p_loss: 0.747| v_loss: 0.081| per_loss: 1.784 | a_loss: 0.613
Train: Epoch [92/3000], Step [60/158]| g_loss: 1.699| d_loss: 0.507| gp_loss: 0.035| r_loss: 0.485| p_loss: 0.734| v_loss: 0.077| per_loss: 1.776 | a_loss: 0.593
Train: Epoch [92/3000], Step [90/158]| g_loss: 1.622| d_loss: 0.579| gp_loss: 0.036| r_loss: 0.443| p_loss: 0.709| v_loss: 0.074| per_loss: 1.797 | a_loss: 0.571
Train: Epoch [92/3000], Step [120/158]| g_loss: 1.792| d_loss: 0.427| gp_loss: 0.036| r_loss: 0.506| p_loss: 0.750| v_loss: 0.075| per_loss: 1.798 | a_loss: 0.656
Train: Epoch [92/3000], Step [150/158]| g_loss: 1.729| d_loss: 0.499| gp_loss: 0.034| r_loss: 0.479| p_loss: 0.710| v_loss: 0.076| per_loss: 1.862 | a_loss: 0.633
Train: Epoch [93/3000], Step [30/158]| g_loss: 1.711| d_loss: 0.554| gp_loss: 0.080| r_loss: 0.482| p_loss: 0.735| v_loss: 0.076| per_loss: 1.724 | a_loss: 0.614
Train: Epoch [93/3000], Step [60/158]| g_loss: 1.651| d_loss: 0.558| gp_loss: 0.034| r_loss: 0.475| p_loss: 0.702| v_loss: 0.073| per_loss: 1.767 | a_loss: 0.574
Train: Epoch [93/3000], Step [90/158]| g_loss: 1.654| d_loss: 0.645| gp_loss: 0.036| r_loss: 0.486| p_loss: 0.757| v_loss: 0.078| per_loss: 1.739 | a_loss: 0.538
Train: Epoch [93/3000], Step [120/158]| g_loss: 1.713| d_loss: 0.499| gp_loss: 0.029| r_loss: 0.455| p_loss: 0.718| v_loss: 0.079| per_loss: 1.730 | a_loss: 0.647
Train: Epoch [93/3000], Step [150/158]| g_loss: 1.697| d_loss: 0.493| gp_loss: 0.033| r_loss: 0.469| p_loss: 0.731| v_loss: 0.076| per_loss: 1.784 | a_loss: 0.608
Train: Epoch [94/3000], Step [30/158]| g_loss: 1.718| d_loss: 0.472| gp_loss: 0.063| r_loss: 0.463| p_loss: 0.687| v_loss: 0.077| per_loss: 1.767 | a_loss: 0.658
Train: Epoch [94/3000], Step [60/158]| g_loss: 1.666| d_loss: 0.531| gp_loss: 0.031| r_loss: 0.468| p_loss: 0.711| v_loss: 0.077| per_loss: 1.748 | a_loss: 0.590
Train: Epoch [94/3000], Step [90/158]| g_loss: 1.711| d_loss: 0.509| gp_loss: 0.034| r_loss: 0.481| p_loss: 0.716| v_loss: 0.076| per_loss: 1.715 | a_loss: 0.623
Train: Epoch [94/3000], Step [120/158]| g_loss: 1.620| d_loss: 0.535| gp_loss: 0.032| r_loss: 0.462| p_loss: 0.702| v_loss: 0.076| per_loss: 1.646 | a_loss: 0.567
Train: Epoch [94/3000], Step [150/158]| g_loss: 1.713| d_loss: 0.495| gp_loss: 0.034| r_loss: 0.462| p_loss: 0.702| v_loss: 0.077| per_loss: 1.742 | a_loss: 0.650
Train: Epoch [95/3000], Step [30/158]| g_loss: 1.646| d_loss: 0.600| gp_loss: 0.086| r_loss: 0.465| p_loss: 0.686| v_loss: 0.077| per_loss: 1.673 | a_loss: 0.594
Train: Epoch [95/3000], Step [60/158]| g_loss: 1.671| d_loss: 0.437| gp_loss: 0.031| r_loss: 0.438| p_loss: 0.657| v_loss: 0.075| per_loss: 1.709 | a_loss: 0.658
Train: Epoch [95/3000], Step [90/158]| g_loss: 1.673| d_loss: 0.485| gp_loss: 0.033| r_loss: 0.440| p_loss: 0.700| v_loss: 0.077| per_loss: 1.808 | a_loss: 0.626
Train: Epoch [95/3000], Step [120/158]| g_loss: 1.729| d_loss: 0.511| gp_loss: 0.034| r_loss: 0.489| p_loss: 0.724| v_loss: 0.080| per_loss: 1.775 | a_loss: 0.621
Train: Epoch [95/3000], Step [150/158]| g_loss: 1.678| d_loss: 0.547| gp_loss: 0.033| r_loss: 0.464| p_loss: 0.705| v_loss: 0.082| per_loss: 1.724 | a_loss: 0.607
Train: Epoch [96/3000], Step [30/158]| g_loss: 1.703| d_loss: 0.606| gp_loss: 0.135| r_loss: 0.467| p_loss: 0.703| v_loss: 0.079| per_loss: 1.795 | a_loss: 0.625
Train: Epoch [96/3000], Step [60/158]| g_loss: 1.687| d_loss: 0.444| gp_loss: 0.030| r_loss: 0.458| p_loss: 0.709| v_loss: 0.078| per_loss: 1.746 | a_loss: 0.622
Train: Epoch [96/3000], Step [90/158]| g_loss: 1.670| d_loss: 0.501| gp_loss: 0.034| r_loss: 0.456| p_loss: 0.707| v_loss: 0.078| per_loss: 1.776 | a_loss: 0.605
Train: Epoch [96/3000], Step [120/158]| g_loss: 1.666| d_loss: 0.535| gp_loss: 0.035| r_loss: 0.464| p_loss: 0.697| v_loss: 0.078| per_loss: 1.797 | a_loss: 0.595
Train: Epoch [96/3000], Step [150/158]| g_loss: 1.710| d_loss: 0.509| gp_loss: 0.034| r_loss: 0.474| p_loss: 0.702| v_loss: 0.077| per_loss: 1.698 | a_loss: 0.639
Train: Epoch [97/3000], Step [30/158]| g_loss: 1.688| d_loss: 0.577| gp_loss: 0.081| r_loss: 0.473| p_loss: 0.728| v_loss: 0.074| per_loss: 1.788 | a_loss: 0.598
Train: Epoch [97/3000], Step [60/158]| g_loss: 1.657| d_loss: 0.524| gp_loss: 0.035| r_loss: 0.463| p_loss: 0.707| v_loss: 0.072| per_loss: 1.750 | a_loss: 0.593
Train: Epoch [97/3000], Step [90/158]| g_loss: 1.722| d_loss: 0.480| gp_loss: 0.033| r_loss: 0.482| p_loss: 0.737| v_loss: 0.082| per_loss: 1.736 | a_loss: 0.616
Train: Epoch [97/3000], Step [120/158]| g_loss: 1.698| d_loss: 0.559| gp_loss: 0.034| r_loss: 0.458| p_loss: 0.742| v_loss: 0.073| per_loss: 1.801 | a_loss: 0.616
Train: Epoch [97/3000], Step [150/158]| g_loss: 1.731| d_loss: 0.512| gp_loss: 0.033| r_loss: 0.468| p_loss: 0.705| v_loss: 0.081| per_loss: 1.704 | a_loss: 0.659
Train: Epoch [98/3000], Step [30/158]| g_loss: 1.682| d_loss: 0.498| gp_loss: 0.075| r_loss: 0.456| p_loss: 0.706| v_loss: 0.075| per_loss: 1.710 | a_loss: 0.627
Train: Epoch [98/3000], Step [60/158]| g_loss: 1.717| d_loss: 0.432| gp_loss: 0.032| r_loss: 0.451| p_loss: 0.698| v_loss: 0.078| per_loss: 1.652 | a_loss: 0.674
Train: Epoch [98/3000], Step [90/158]| g_loss: 1.709| d_loss: 0.474| gp_loss: 0.035| r_loss: 0.434| p_loss: 0.711| v_loss: 0.077| per_loss: 1.735 | a_loss: 0.670
Train: Epoch [98/3000], Step [120/158]| g_loss: 1.697| d_loss: 0.537| gp_loss: 0.035| r_loss: 0.475| p_loss: 0.714| v_loss: 0.078| per_loss: 1.681 | a_loss: 0.619
Train: Epoch [98/3000], Step [150/158]| g_loss: 1.712| d_loss: 0.508| gp_loss: 0.034| r_loss: 0.477| p_loss: 0.710| v_loss: 0.079| per_loss: 1.739 | a_loss: 0.626
Train: Epoch [99/3000], Step [30/158]| g_loss: 1.655| d_loss: 0.553| gp_loss: 0.085| r_loss: 0.459| p_loss: 0.695| v_loss: 0.079| per_loss: 1.626 | a_loss: 0.607
Train: Epoch [99/3000], Step [60/158]| g_loss: 1.641| d_loss: 0.514| gp_loss: 0.034| r_loss: 0.457| p_loss: 0.698| v_loss: 0.074| per_loss: 1.647 | a_loss: 0.596
Train: Epoch [99/3000], Step [90/158]| g_loss: 1.700| d_loss: 0.506| gp_loss: 0.035| r_loss: 0.479| p_loss: 0.708| v_loss: 0.076| per_loss: 1.710 | a_loss: 0.620
Train: Epoch [99/3000], Step [120/158]| g_loss: 1.622| d_loss: 0.520| gp_loss: 0.036| r_loss: 0.436| p_loss: 0.683| v_loss: 0.076| per_loss: 1.735 | a_loss: 0.596
Train: Epoch [99/3000], Step [150/158]| g_loss: 1.624| d_loss: 0.545| gp_loss: 0.035| r_loss: 0.451| p_loss: 0.701| v_loss: 0.079| per_loss: 1.609 | a_loss: 0.583
Train: Epoch [100/3000], Step [30/158]| g_loss: 1.695| d_loss: 0.597| gp_loss: 0.098| r_loss: 0.475| p_loss: 0.739| v_loss: 0.075| per_loss: 1.686 | a_loss: 0.606
Train: Epoch [100/3000], Step [60/158]| g_loss: 1.678| d_loss: 0.487| gp_loss: 0.035| r_loss: 0.461| p_loss: 0.714| v_loss: 0.076| per_loss: 1.770 | a_loss: 0.607
Train: Epoch [100/3000], Step [90/158]| g_loss: 1.717| d_loss: 0.515| gp_loss: 0.035| r_loss: 0.467| p_loss: 0.729| v_loss: 0.078| per_loss: 1.623 | a_loss: 0.646
Train: Epoch [100/3000], Step [120/158]| g_loss: 1.668| d_loss: 0.585| gp_loss: 0.035| r_loss: 0.461| p_loss: 0.723| v_loss: 0.078| per_loss: 1.669 | a_loss: 0.600
Train: Epoch [100/3000], Step [150/158]| g_loss: 1.639| d_loss: 0.582| gp_loss: 0.035| r_loss: 0.469| p_loss: 0.732| v_loss: 0.079| per_loss: 1.568 | a_loss: 0.568
Test: Epoch [100/3000]| g_loss: 1.607| r_loss: 1.064| p_loss: 0.742| v_loss: 0.062
Train: Epoch [101/3000], Step [30/158]| g_loss: 1.640| d_loss: 0.506| gp_loss: 0.034| r_loss: 0.445| p_loss: 0.707| v_loss: 0.079| per_loss: 1.582 | a_loss: 0.605
Train: Epoch [101/3000], Step [60/158]| g_loss: 1.674| d_loss: 0.502| gp_loss: 0.031| r_loss: 0.466| p_loss: 0.715| v_loss: 0.076| per_loss: 1.639 | a_loss: 0.611
Train: Epoch [101/3000], Step [90/158]| g_loss: 1.684| d_loss: 0.535| gp_loss: 0.031| r_loss: 0.449| p_loss: 0.712| v_loss: 0.076| per_loss: 1.726 | a_loss: 0.631
Train: Epoch [101/3000], Step [120/158]| g_loss: 1.655| d_loss: 0.571| gp_loss: 0.034| r_loss: 0.468| p_loss: 0.761| v_loss: 0.076| per_loss: 1.679 | a_loss: 0.563
Train: Epoch [101/3000], Step [150/158]| g_loss: 1.701| d_loss: 0.578| gp_loss: 0.032| r_loss: 0.488| p_loss: 0.720| v_loss: 0.075| per_loss: 1.631 | a_loss: 0.615
Train: Epoch [102/3000], Step [30/158]| g_loss: 1.663| d_loss: 0.535| gp_loss: 0.090| r_loss: 0.435| p_loss: 0.709| v_loss: 0.080| per_loss: 1.711 | a_loss: 0.622
Train: Epoch [102/3000], Step [60/158]| g_loss: 1.630| d_loss: 0.545| gp_loss: 0.031| r_loss: 0.449| p_loss: 0.707| v_loss: 0.076| per_loss: 1.671 | a_loss: 0.585
Train: Epoch [102/3000], Step [90/158]| g_loss: 1.697| d_loss: 0.463| gp_loss: 0.029| r_loss: 0.467| p_loss: 0.690| v_loss: 0.077| per_loss: 1.676 | a_loss: 0.641
Train: Epoch [102/3000], Step [120/158]| g_loss: 1.637| d_loss: 0.540| gp_loss: 0.030| r_loss: 0.457| p_loss: 0.695| v_loss: 0.079| per_loss: 1.576 | a_loss: 0.596
Train: Epoch [102/3000], Step [150/158]| g_loss: 1.631| d_loss: 0.610| gp_loss: 0.032| r_loss: 0.454| p_loss: 0.711| v_loss: 0.078| per_loss: 1.581 | a_loss: 0.585
Train: Epoch [103/3000], Step [30/158]| g_loss: 1.683| d_loss: 0.536| gp_loss: 0.066| r_loss: 0.458| p_loss: 0.712| v_loss: 0.078| per_loss: 1.735 | a_loss: 0.618
Train: Epoch [103/3000], Step [60/158]| g_loss: 1.608| d_loss: 0.505| gp_loss: 0.030| r_loss: 0.436| p_loss: 0.667| v_loss: 0.076| per_loss: 1.595 | a_loss: 0.604
Train: Epoch [103/3000], Step [90/158]| g_loss: 1.605| d_loss: 0.532| gp_loss: 0.032| r_loss: 0.440| p_loss: 0.682| v_loss: 0.076| per_loss: 1.539 | a_loss: 0.594
Train: Epoch [103/3000], Step [120/158]| g_loss: 1.663| d_loss: 0.481| gp_loss: 0.031| r_loss: 0.445| p_loss: 0.708| v_loss: 0.077| per_loss: 1.655 | a_loss: 0.622
Train: Epoch [103/3000], Step [150/158]| g_loss: 1.588| d_loss: 0.585| gp_loss: 0.032| r_loss: 0.454| p_loss: 0.694| v_loss: 0.074| per_loss: 1.585 | a_loss: 0.555
Train: Epoch [104/3000], Step [30/158]| g_loss: 1.590| d_loss: 0.659| gp_loss: 0.085| r_loss: 0.442| p_loss: 0.680| v_loss: 0.074| per_loss: 1.644 | a_loss: 0.569
Train: Epoch [104/3000], Step [60/158]| g_loss: 1.650| d_loss: 0.530| gp_loss: 0.031| r_loss: 0.472| p_loss: 0.699| v_loss: 0.074| per_loss: 1.581 | a_loss: 0.596
Train: Epoch [104/3000], Step [90/158]| g_loss: 1.568| d_loss: 0.539| gp_loss: 0.033| r_loss: 0.416| p_loss: 0.665| v_loss: 0.072| per_loss: 1.621 | a_loss: 0.586
Train: Epoch [104/3000], Step [120/158]| g_loss: 1.594| d_loss: 0.559| gp_loss: 0.033| r_loss: 0.448| p_loss: 0.681| v_loss: 0.072| per_loss: 1.572 | a_loss: 0.576
Train: Epoch [104/3000], Step [150/158]| g_loss: 1.596| d_loss: 0.482| gp_loss: 0.031| r_loss: 0.429| p_loss: 0.683| v_loss: 0.076| per_loss: 1.650 | a_loss: 0.584
Train: Epoch [105/3000], Step [30/158]| g_loss: 1.601| d_loss: 0.611| gp_loss: 0.047| r_loss: 0.433| p_loss: 0.672| v_loss: 0.076| per_loss: 1.574 | a_loss: 0.599
Train: Epoch [105/3000], Step [60/158]| g_loss: 1.630| d_loss: 0.485| gp_loss: 0.031| r_loss: 0.440| p_loss: 0.690| v_loss: 0.080| per_loss: 1.597 | a_loss: 0.606
Train: Epoch [105/3000], Step [90/158]| g_loss: 1.610| d_loss: 0.501| gp_loss: 0.032| r_loss: 0.423| p_loss: 0.660| v_loss: 0.075| per_loss: 1.631 | a_loss: 0.619
Train: Epoch [105/3000], Step [120/158]| g_loss: 1.586| d_loss: 0.621| gp_loss: 0.031| r_loss: 0.430| p_loss: 0.652| v_loss: 0.079| per_loss: 1.606 | a_loss: 0.590
Train: Epoch [105/3000], Step [150/158]| g_loss: 1.674| d_loss: 0.511| gp_loss: 0.033| r_loss: 0.448| p_loss: 0.695| v_loss: 0.078| per_loss: 1.697 | a_loss: 0.631
Train: Epoch [106/3000], Step [30/158]| g_loss: 1.634| d_loss: 0.583| gp_loss: 0.066| r_loss: 0.433| p_loss: 0.699| v_loss: 0.077| per_loss: 1.644 | a_loss: 0.610
Train: Epoch [106/3000], Step [60/158]| g_loss: 1.600| d_loss: 0.477| gp_loss: 0.030| r_loss: 0.437| p_loss: 0.651| v_loss: 0.073| per_loss: 1.626 | a_loss: 0.601
Train: Epoch [106/3000], Step [90/158]| g_loss: 1.612| d_loss: 0.547| gp_loss: 0.030| r_loss: 0.459| p_loss: 0.699| v_loss: 0.080| per_loss: 1.568 | a_loss: 0.566
Train: Epoch [106/3000], Step [120/158]| g_loss: 1.549| d_loss: 0.592| gp_loss: 0.035| r_loss: 0.426| p_loss: 0.636| v_loss: 0.072| per_loss: 1.676 | a_loss: 0.565
Train: Epoch [106/3000], Step [150/158]| g_loss: 1.661| d_loss: 0.475| gp_loss: 0.032| r_loss: 0.434| p_loss: 0.724| v_loss: 0.079| per_loss: 1.546 | a_loss: 0.632
Train: Epoch [107/3000], Step [30/158]| g_loss: 1.557| d_loss: 0.583| gp_loss: 0.111| r_loss: 0.399| p_loss: 0.665| v_loss: 0.073| per_loss: 1.558 | a_loss: 0.597
Train: Epoch [107/3000], Step [60/158]| g_loss: 1.669| d_loss: 0.543| gp_loss: 0.032| r_loss: 0.453| p_loss: 0.681| v_loss: 0.077| per_loss: 1.559 | a_loss: 0.642
Train: Epoch [107/3000], Step [90/158]| g_loss: 1.575| d_loss: 0.562| gp_loss: 0.030| r_loss: 0.418| p_loss: 0.658| v_loss: 0.076| per_loss: 1.584 | a_loss: 0.593
Train: Epoch [107/3000], Step [120/158]| g_loss: 1.625| d_loss: 0.519| gp_loss: 0.030| r_loss: 0.442| p_loss: 0.668| v_loss: 0.076| per_loss: 1.603 | a_loss: 0.613
Train: Epoch [107/3000], Step [150/158]| g_loss: 1.687| d_loss: 0.530| gp_loss: 0.030| r_loss: 0.426| p_loss: 0.692| v_loss: 0.077| per_loss: 1.643 | a_loss: 0.674
Train: Epoch [108/3000], Step [30/158]| g_loss: 1.582| d_loss: 0.545| gp_loss: 0.094| r_loss: 0.419| p_loss: 0.668| v_loss: 0.073| per_loss: 1.594 | a_loss: 0.596
Train: Epoch [108/3000], Step [60/158]| g_loss: 1.563| d_loss: 0.550| gp_loss: 0.029| r_loss: 0.409| p_loss: 0.651| v_loss: 0.075| per_loss: 1.581 | a_loss: 0.596
Train: Epoch [108/3000], Step [90/158]| g_loss: 1.667| d_loss: 0.504| gp_loss: 0.031| r_loss: 0.462| p_loss: 0.692| v_loss: 0.074| per_loss: 1.592 | a_loss: 0.625
Train: Epoch [108/3000], Step [120/158]| g_loss: 1.598| d_loss: 0.427| gp_loss: 0.031| r_loss: 0.433| p_loss: 0.646| v_loss: 0.074| per_loss: 1.501 | a_loss: 0.617
Train: Epoch [108/3000], Step [150/158]| g_loss: 1.549| d_loss: 0.578| gp_loss: 0.032| r_loss: 0.405| p_loss: 0.647| v_loss: 0.074| per_loss: 1.609 | a_loss: 0.586
Train: Epoch [109/3000], Step [30/158]| g_loss: 1.560| d_loss: 0.548| gp_loss: 0.076| r_loss: 0.426| p_loss: 0.663| v_loss: 0.073| per_loss: 1.570 | a_loss: 0.573
Train: Epoch [109/3000], Step [60/158]| g_loss: 1.580| d_loss: 0.523| gp_loss: 0.032| r_loss: 0.417| p_loss: 0.677| v_loss: 0.072| per_loss: 1.539 | a_loss: 0.599
Train: Epoch [109/3000], Step [90/158]| g_loss: 1.594| d_loss: 0.458| gp_loss: 0.033| r_loss: 0.414| p_loss: 0.622| v_loss: 0.068| per_loss: 1.626 | a_loss: 0.639
Train: Epoch [109/3000], Step [120/158]| g_loss: 1.606| d_loss: 0.462| gp_loss: 0.034| r_loss: 0.414| p_loss: 0.657| v_loss: 0.072| per_loss: 1.622 | a_loss: 0.630
Train: Epoch [109/3000], Step [150/158]| g_loss: 1.593| d_loss: 0.602| gp_loss: 0.033| r_loss: 0.450| p_loss: 0.644| v_loss: 0.074| per_loss: 1.507 | a_loss: 0.597
Train: Epoch [110/3000], Step [30/158]| g_loss: 1.538| d_loss: 0.533| gp_loss: 0.091| r_loss: 0.395| p_loss: 0.633| v_loss: 0.073| per_loss: 1.489 | a_loss: 0.604
Train: Epoch [110/3000], Step [60/158]| g_loss: 1.603| d_loss: 0.500| gp_loss: 0.030| r_loss: 0.412| p_loss: 0.674| v_loss: 0.076| per_loss: 1.524 | a_loss: 0.624
Train: Epoch [110/3000], Step [90/158]| g_loss: 1.602| d_loss: 0.446| gp_loss: 0.030| r_loss: 0.412| p_loss: 0.637| v_loss: 0.074| per_loss: 1.499 | a_loss: 0.648
Train: Epoch [110/3000], Step [120/158]| g_loss: 1.655| d_loss: 0.629| gp_loss: 0.034| r_loss: 0.424| p_loss: 0.640| v_loss: 0.070| per_loss: 1.542 | a_loss: 0.687
Train: Epoch [110/3000], Step [150/158]| g_loss: 1.555| d_loss: 0.605| gp_loss: 0.033| r_loss: 0.420| p_loss: 0.656| v_loss: 0.072| per_loss: 1.528 | a_loss: 0.582
Train: Epoch [111/3000], Step [30/158]| g_loss: 1.518| d_loss: 0.582| gp_loss: 0.065| r_loss: 0.417| p_loss: 0.620| v_loss: 0.074| per_loss: 1.508 | a_loss: 0.565
Train: Epoch [111/3000], Step [60/158]| g_loss: 1.538| d_loss: 0.515| gp_loss: 0.032| r_loss: 0.423| p_loss: 0.631| v_loss: 0.075| per_loss: 1.502 | a_loss: 0.574
Train: Epoch [111/3000], Step [90/158]| g_loss: 1.565| d_loss: 0.463| gp_loss: 0.035| r_loss: 0.411| p_loss: 0.624| v_loss: 0.070| per_loss: 1.485 | a_loss: 0.624
Train: Epoch [111/3000], Step [120/158]| g_loss: 1.601| d_loss: 0.394| gp_loss: 0.030| r_loss: 0.403| p_loss: 0.605| v_loss: 0.068| per_loss: 1.505 | a_loss: 0.678
Train: Epoch [111/3000], Step [150/158]| g_loss: 1.509| d_loss: 0.563| gp_loss: 0.036| r_loss: 0.410| p_loss: 0.616| v_loss: 0.068| per_loss: 1.488 | a_loss: 0.574
Train: Epoch [112/3000], Step [30/158]| g_loss: 1.506| d_loss: 0.578| gp_loss: 0.100| r_loss: 0.392| p_loss: 0.613| v_loss: 0.070| per_loss: 1.499 | a_loss: 0.588
Train: Epoch [112/3000], Step [60/158]| g_loss: 1.415| d_loss: 0.662| gp_loss: 0.037| r_loss: 0.393| p_loss: 0.597| v_loss: 0.072| per_loss: 1.388 | a_loss: 0.514
Train: Epoch [112/3000], Step [90/158]| g_loss: 1.577| d_loss: 0.506| gp_loss: 0.033| r_loss: 0.420| p_loss: 0.638| v_loss: 0.070| per_loss: 1.540 | a_loss: 0.614
Train: Epoch [112/3000], Step [120/158]| g_loss: 1.586| d_loss: 0.446| gp_loss: 0.034| r_loss: 0.409| p_loss: 0.602| v_loss: 0.071| per_loss: 1.461 | a_loss: 0.659
Train: Epoch [112/3000], Step [150/158]| g_loss: 1.590| d_loss: 0.422| gp_loss: 0.036| r_loss: 0.418| p_loss: 0.610| v_loss: 0.073| per_loss: 1.420 | a_loss: 0.652
Train: Epoch [113/3000], Step [30/158]| g_loss: 1.607| d_loss: 0.519| gp_loss: 0.089| r_loss: 0.436| p_loss: 0.617| v_loss: 0.069| per_loss: 1.503 | a_loss: 0.643
Train: Epoch [113/3000], Step [60/158]| g_loss: 1.540| d_loss: 0.444| gp_loss: 0.033| r_loss: 0.393| p_loss: 0.606| v_loss: 0.070| per_loss: 1.439 | a_loss: 0.630
Train: Epoch [113/3000], Step [90/158]| g_loss: 1.534| d_loss: 0.518| gp_loss: 0.034| r_loss: 0.397| p_loss: 0.622| v_loss: 0.076| per_loss: 1.500 | a_loss: 0.600
Train: Epoch [113/3000], Step [120/158]| g_loss: 1.476| d_loss: 0.600| gp_loss: 0.035| r_loss: 0.395| p_loss: 0.586| v_loss: 0.067| per_loss: 1.506 | a_loss: 0.570
Train: Epoch [113/3000], Step [150/158]| g_loss: 1.592| d_loss: 0.472| gp_loss: 0.035| r_loss: 0.414| p_loss: 0.636| v_loss: 0.069| per_loss: 1.505 | a_loss: 0.641
Train: Epoch [114/3000], Step [30/158]| g_loss: 1.532| d_loss: 0.566| gp_loss: 0.082| r_loss: 0.419| p_loss: 0.617| v_loss: 0.070| per_loss: 1.421 | a_loss: 0.592
Train: Epoch [114/3000], Step [60/158]| g_loss: 1.500| d_loss: 0.532| gp_loss: 0.036| r_loss: 0.406| p_loss: 0.616| v_loss: 0.068| per_loss: 1.448 | a_loss: 0.573
Train: Epoch [114/3000], Step [90/158]| g_loss: 1.519| d_loss: 0.501| gp_loss: 0.036| r_loss: 0.400| p_loss: 0.602| v_loss: 0.067| per_loss: 1.526 | a_loss: 0.599
Train: Epoch [114/3000], Step [120/158]| g_loss: 1.546| d_loss: 0.494| gp_loss: 0.037| r_loss: 0.397| p_loss: 0.606| v_loss: 0.066| per_loss: 1.489 | a_loss: 0.631
Train: Epoch [114/3000], Step [150/158]| g_loss: 1.552| d_loss: 0.471| gp_loss: 0.035| r_loss: 0.412| p_loss: 0.592| v_loss: 0.068| per_loss: 1.390 | a_loss: 0.638
Train: Epoch [115/3000], Step [30/158]| g_loss: 1.518| d_loss: 0.555| gp_loss: 0.084| r_loss: 0.389| p_loss: 0.606| v_loss: 0.066| per_loss: 1.451 | a_loss: 0.616
Train: Epoch [115/3000], Step [60/158]| g_loss: 1.566| d_loss: 0.405| gp_loss: 0.034| r_loss: 0.398| p_loss: 0.596| v_loss: 0.070| per_loss: 1.425 | a_loss: 0.658
Train: Epoch [115/3000], Step [90/158]| g_loss: 1.549| d_loss: 0.548| gp_loss: 0.039| r_loss: 0.417| p_loss: 0.610| v_loss: 0.067| per_loss: 1.510 | a_loss: 0.609
Train: Epoch [115/3000], Step [120/158]| g_loss: 1.501| d_loss: 0.527| gp_loss: 0.037| r_loss: 0.398| p_loss: 0.607| v_loss: 0.069| per_loss: 1.378 | a_loss: 0.592
Train: Epoch [115/3000], Step [150/158]| g_loss: 1.520| d_loss: 0.544| gp_loss: 0.038| r_loss: 0.401| p_loss: 0.601| v_loss: 0.072| per_loss: 1.452 | a_loss: 0.601
Train: Epoch [116/3000], Step [30/158]| g_loss: 1.561| d_loss: 0.521| gp_loss: 0.096| r_loss: 0.401| p_loss: 0.625| v_loss: 0.070| per_loss: 1.439 | a_loss: 0.633
Train: Epoch [116/3000], Step [60/158]| g_loss: 1.498| d_loss: 0.591| gp_loss: 0.036| r_loss: 0.407| p_loss: 0.587| v_loss: 0.066| per_loss: 1.495 | a_loss: 0.582
Train: Epoch [116/3000], Step [90/158]| g_loss: 1.535| d_loss: 0.483| gp_loss: 0.040| r_loss: 0.402| p_loss: 0.608| v_loss: 0.072| per_loss: 1.393 | a_loss: 0.619
Train: Epoch [116/3000], Step [120/158]| g_loss: 1.524| d_loss: 0.447| gp_loss: 0.039| r_loss: 0.389| p_loss: 0.585| v_loss: 0.067| per_loss: 1.465 | a_loss: 0.628
Train: Epoch [116/3000], Step [150/158]| g_loss: 1.484| d_loss: 0.575| gp_loss: 0.040| r_loss: 0.385| p_loss: 0.583| v_loss: 0.069| per_loss: 1.417 | a_loss: 0.597
Train: Epoch [117/3000], Step [30/158]| g_loss: 1.555| d_loss: 0.517| gp_loss: 0.092| r_loss: 0.413| p_loss: 0.600| v_loss: 0.066| per_loss: 1.409 | a_loss: 0.634
Train: Epoch [117/3000], Step [60/158]| g_loss: 1.528| d_loss: 0.515| gp_loss: 0.038| r_loss: 0.393| p_loss: 0.631| v_loss: 0.070| per_loss: 1.426 | a_loss: 0.608
Train: Epoch [117/3000], Step [90/158]| g_loss: 1.485| d_loss: 0.499| gp_loss: 0.037| r_loss: 0.401| p_loss: 0.583| v_loss: 0.068| per_loss: 1.323 | a_loss: 0.591
Train: Epoch [117/3000], Step [120/158]| g_loss: 1.520| d_loss: 0.520| gp_loss: 0.039| r_loss: 0.390| p_loss: 0.597| v_loss: 0.067| per_loss: 1.424 | a_loss: 0.623
Train: Epoch [117/3000], Step [150/158]| g_loss: 1.530| d_loss: 0.494| gp_loss: 0.035| r_loss: 0.389| p_loss: 0.598| v_loss: 0.067| per_loss: 1.485 | a_loss: 0.626
Train: Epoch [118/3000], Step [30/158]| g_loss: 1.510| d_loss: 0.570| gp_loss: 0.124| r_loss: 0.393| p_loss: 0.594| v_loss: 0.066| per_loss: 1.472 | a_loss: 0.607
Train: Epoch [118/3000], Step [60/158]| g_loss: 1.504| d_loss: 0.479| gp_loss: 0.034| r_loss: 0.377| p_loss: 0.570| v_loss: 0.070| per_loss: 1.439 | a_loss: 0.628
Train: Epoch [118/3000], Step [90/158]| g_loss: 1.530| d_loss: 0.495| gp_loss: 0.038| r_loss: 0.393| p_loss: 0.604| v_loss: 0.067| per_loss: 1.459 | a_loss: 0.622
Train: Epoch [118/3000], Step [120/158]| g_loss: 1.501| d_loss: 0.535| gp_loss: 0.038| r_loss: 0.402| p_loss: 0.593| v_loss: 0.067| per_loss: 1.354 | a_loss: 0.600
Train: Epoch [118/3000], Step [150/158]| g_loss: 1.555| d_loss: 0.449| gp_loss: 0.036| r_loss: 0.400| p_loss: 0.613| v_loss: 0.068| per_loss: 1.415 | a_loss: 0.639
Train: Epoch [119/3000], Step [30/158]| g_loss: 1.510| d_loss: 0.526| gp_loss: 0.079| r_loss: 0.386| p_loss: 0.601| v_loss: 0.069| per_loss: 1.412 | a_loss: 0.614
Train: Epoch [119/3000], Step [60/158]| g_loss: 1.515| d_loss: 0.483| gp_loss: 0.038| r_loss: 0.390| p_loss: 0.584| v_loss: 0.068| per_loss: 1.395 | a_loss: 0.625
Train: Epoch [119/3000], Step [90/158]| g_loss: 1.511| d_loss: 0.498| gp_loss: 0.040| r_loss: 0.393| p_loss: 0.591| v_loss: 0.071| per_loss: 1.392 | a_loss: 0.612
Train: Epoch [119/3000], Step [120/158]| g_loss: 1.513| d_loss: 0.482| gp_loss: 0.041| r_loss: 0.410| p_loss: 0.570| v_loss: 0.067| per_loss: 1.411 | a_loss: 0.610
Train: Epoch [119/3000], Step [150/158]| g_loss: 1.494| d_loss: 0.571| gp_loss: 0.040| r_loss: 0.389| p_loss: 0.593| v_loss: 0.067| per_loss: 1.456 | a_loss: 0.595
Train: Epoch [120/3000], Step [30/158]| g_loss: 1.522| d_loss: 0.508| gp_loss: 0.107| r_loss: 0.386| p_loss: 0.601| v_loss: 0.069| per_loss: 1.399 | a_loss: 0.627
Train: Epoch [120/3000], Step [60/158]| g_loss: 1.471| d_loss: 0.533| gp_loss: 0.038| r_loss: 0.401| p_loss: 0.565| v_loss: 0.065| per_loss: 1.374 | a_loss: 0.585
Train: Epoch [120/3000], Step [90/158]| g_loss: 1.515| d_loss: 0.455| gp_loss: 0.038| r_loss: 0.384| p_loss: 0.600| v_loss: 0.070| per_loss: 1.519 | a_loss: 0.609
Train: Epoch [120/3000], Step [120/158]| g_loss: 1.498| d_loss: 0.588| gp_loss: 0.038| r_loss: 0.405| p_loss: 0.581| v_loss: 0.066| per_loss: 1.465 | a_loss: 0.590
Train: Epoch [120/3000], Step [150/158]| g_loss: 1.514| d_loss: 0.557| gp_loss: 0.038| r_loss: 0.386| p_loss: 0.604| v_loss: 0.068| per_loss: 1.432 | a_loss: 0.614
Train: Epoch [121/3000], Step [30/158]| g_loss: 1.478| d_loss: 0.561| gp_loss: 0.100| r_loss: 0.395| p_loss: 0.591| v_loss: 0.068| per_loss: 1.420 | a_loss: 0.577
Train: Epoch [121/3000], Step [60/158]| g_loss: 1.508| d_loss: 0.506| gp_loss: 0.037| r_loss: 0.400| p_loss: 0.590| v_loss: 0.067| per_loss: 1.372 | a_loss: 0.608
Train: Epoch [121/3000], Step [90/158]| g_loss: 1.553| d_loss: 0.429| gp_loss: 0.037| r_loss: 0.401| p_loss: 0.592| v_loss: 0.068| per_loss: 1.415 | a_loss: 0.646
Train: Epoch [121/3000], Step [120/158]| g_loss: 1.513| d_loss: 0.535| gp_loss: 0.039| r_loss: 0.408| p_loss: 0.599| v_loss: 0.065| per_loss: 1.441 | a_loss: 0.596
Train: Epoch [121/3000], Step [150/158]| g_loss: 1.468| d_loss: 0.525| gp_loss: 0.040| r_loss: 0.389| p_loss: 0.594| v_loss: 0.066| per_loss: 1.441 | a_loss: 0.572
Train: Epoch [122/3000], Step [30/158]| g_loss: 1.456| d_loss: 0.654| gp_loss: 0.087| r_loss: 0.391| p_loss: 0.598| v_loss: 0.068| per_loss: 1.363 | a_loss: 0.561
Train: Epoch [122/3000], Step [60/158]| g_loss: 1.536| d_loss: 0.417| gp_loss: 0.036| r_loss: 0.383| p_loss: 0.596| v_loss: 0.068| per_loss: 1.534 | a_loss: 0.633
Train: Epoch [122/3000], Step [90/158]| g_loss: 1.513| d_loss: 0.537| gp_loss: 0.038| r_loss: 0.399| p_loss: 0.601| v_loss: 0.068| per_loss: 1.460 | a_loss: 0.600
Train: Epoch [122/3000], Step [120/158]| g_loss: 1.472| d_loss: 0.571| gp_loss: 0.038| r_loss: 0.405| p_loss: 0.596| v_loss: 0.066| per_loss: 1.412 | a_loss: 0.561
Train: Epoch [122/3000], Step [150/158]| g_loss: 1.510| d_loss: 0.484| gp_loss: 0.038| r_loss: 0.402| p_loss: 0.590| v_loss: 0.069| per_loss: 1.287 | a_loss: 0.615
Train: Epoch [123/3000], Step [30/158]| g_loss: 1.438| d_loss: 0.651| gp_loss: 0.090| r_loss: 0.401| p_loss: 0.586| v_loss: 0.065| per_loss: 1.434 | a_loss: 0.536
Train: Epoch [123/3000], Step [60/158]| g_loss: 1.466| d_loss: 0.515| gp_loss: 0.036| r_loss: 0.392| p_loss: 0.590| v_loss: 0.071| per_loss: 1.341 | a_loss: 0.575
Train: Epoch [123/3000], Step [90/158]| g_loss: 1.522| d_loss: 0.549| gp_loss: 0.037| r_loss: 0.401| p_loss: 0.600| v_loss: 0.064| per_loss: 1.407 | a_loss: 0.617
Train: Epoch [123/3000], Step [120/158]| g_loss: 1.487| d_loss: 0.516| gp_loss: 0.039| r_loss: 0.388| p_loss: 0.602| v_loss: 0.069| per_loss: 1.403 | a_loss: 0.589
Train: Epoch [123/3000], Step [150/158]| g_loss: 1.478| d_loss: 0.558| gp_loss: 0.036| r_loss: 0.404| p_loss: 0.586| v_loss: 0.065| per_loss: 1.414 | a_loss: 0.574
Train: Epoch [124/3000], Step [30/158]| g_loss: 1.518| d_loss: 0.564| gp_loss: 0.097| r_loss: 0.397| p_loss: 0.600| v_loss: 0.071| per_loss: 1.400 | a_loss: 0.611
Train: Epoch [124/3000], Step [60/158]| g_loss: 1.500| d_loss: 0.526| gp_loss: 0.037| r_loss: 0.408| p_loss: 0.569| v_loss: 0.069| per_loss: 1.330 | a_loss: 0.606
Train: Epoch [124/3000], Step [90/158]| g_loss: 1.469| d_loss: 0.509| gp_loss: 0.041| r_loss: 0.379| p_loss: 0.568| v_loss: 0.068| per_loss: 1.386 | a_loss: 0.600
Train: Epoch [124/3000], Step [120/158]| g_loss: 1.501| d_loss: 0.530| gp_loss: 0.040| r_loss: 0.409| p_loss: 0.600| v_loss: 0.065| per_loss: 1.427 | a_loss: 0.585
Train: Epoch [124/3000], Step [150/158]| g_loss: 1.542| d_loss: 0.536| gp_loss: 0.038| r_loss: 0.384| p_loss: 0.583| v_loss: 0.066| per_loss: 1.486 | a_loss: 0.651
Train: Epoch [125/3000], Step [30/158]| g_loss: 1.422| d_loss: 0.655| gp_loss: 0.102| r_loss: 0.380| p_loss: 0.591| v_loss: 0.069| per_loss: 1.349 | a_loss: 0.543
Train: Epoch [125/3000], Step [60/158]| g_loss: 1.514| d_loss: 0.501| gp_loss: 0.038| r_loss: 0.411| p_loss: 0.598| v_loss: 0.069| per_loss: 1.422 | a_loss: 0.592
Train: Epoch [125/3000], Step [90/158]| g_loss: 1.453| d_loss: 0.586| gp_loss: 0.037| r_loss: 0.415| p_loss: 0.586| v_loss: 0.065| per_loss: 1.341 | a_loss: 0.546
Train: Epoch [125/3000], Step [120/158]| g_loss: 1.520| d_loss: 0.525| gp_loss: 0.038| r_loss: 0.415| p_loss: 0.586| v_loss: 0.065| per_loss: 1.341 | a_loss: 0.613
Train: Epoch [125/3000], Step [150/158]| g_loss: 1.503| d_loss: 0.512| gp_loss: 0.039| r_loss: 0.381| p_loss: 0.592| v_loss: 0.065| per_loss: 1.414 | a_loss: 0.621
Train: Epoch [126/3000], Step [30/158]| g_loss: 1.457| d_loss: 0.597| gp_loss: 0.075| r_loss: 0.400| p_loss: 0.564| v_loss: 0.070| per_loss: 1.328 | a_loss: 0.572
Train: Epoch [126/3000], Step [60/158]| g_loss: 1.495| d_loss: 0.530| gp_loss: 0.041| r_loss: 0.399| p_loss: 0.608| v_loss: 0.069| per_loss: 1.326 | a_loss: 0.590
Train: Epoch [126/3000], Step [90/158]| g_loss: 1.462| d_loss: 0.536| gp_loss: 0.042| r_loss: 0.407| p_loss: 0.582| v_loss: 0.065| per_loss: 1.314 | a_loss: 0.567
Train: Epoch [126/3000], Step [120/158]| g_loss: 1.489| d_loss: 0.482| gp_loss: 0.041| r_loss: 0.385| p_loss: 0.564| v_loss: 0.064| per_loss: 1.311 | a_loss: 0.627
Train: Epoch [126/3000], Step [150/158]| g_loss: 1.529| d_loss: 0.492| gp_loss: 0.040| r_loss: 0.382| p_loss: 0.589| v_loss: 0.067| per_loss: 1.413 | a_loss: 0.644
Train: Epoch [127/3000], Step [30/158]| g_loss: 1.415| d_loss: 0.686| gp_loss: 0.137| r_loss: 0.370| p_loss: 0.587| v_loss: 0.065| per_loss: 1.350 | a_loss: 0.551
Train: Epoch [127/3000], Step [60/158]| g_loss: 1.461| d_loss: 0.523| gp_loss: 0.039| r_loss: 0.374| p_loss: 0.576| v_loss: 0.066| per_loss: 1.372 | a_loss: 0.596
Train: Epoch [127/3000], Step [90/158]| g_loss: 1.523| d_loss: 0.496| gp_loss: 0.041| r_loss: 0.401| p_loss: 0.591| v_loss: 0.069| per_loss: 1.401 | a_loss: 0.617
Train: Epoch [127/3000], Step [120/158]| g_loss: 1.481| d_loss: 0.565| gp_loss: 0.038| r_loss: 0.396| p_loss: 0.577| v_loss: 0.071| per_loss: 1.307 | a_loss: 0.595
Train: Epoch [127/3000], Step [150/158]| g_loss: 1.555| d_loss: 0.546| gp_loss: 0.038| r_loss: 0.407| p_loss: 0.588| v_loss: 0.069| per_loss: 1.410 | a_loss: 0.644
Train: Epoch [128/3000], Step [30/158]| g_loss: 1.493| d_loss: 0.594| gp_loss: 0.079| r_loss: 0.395| p_loss: 0.618| v_loss: 0.073| per_loss: 1.377 | a_loss: 0.579
Train: Epoch [128/3000], Step [60/158]| g_loss: 1.492| d_loss: 0.487| gp_loss: 0.041| r_loss: 0.384| p_loss: 0.578| v_loss: 0.067| per_loss: 1.428 | a_loss: 0.609
Train: Epoch [128/3000], Step [90/158]| g_loss: 1.497| d_loss: 0.521| gp_loss: 0.041| r_loss: 0.398| p_loss: 0.561| v_loss: 0.064| per_loss: 1.354 | a_loss: 0.619
Train: Epoch [128/3000], Step [120/158]| g_loss: 1.416| d_loss: 0.589| gp_loss: 0.043| r_loss: 0.378| p_loss: 0.557| v_loss: 0.067| per_loss: 1.322 | a_loss: 0.560
Train: Epoch [128/3000], Step [150/158]| g_loss: 1.515| d_loss: 0.484| gp_loss: 0.043| r_loss: 0.394| p_loss: 0.602| v_loss: 0.069| per_loss: 1.298 | a_loss: 0.622
Train: Epoch [129/3000], Step [30/158]| g_loss: 1.496| d_loss: 0.517| gp_loss: 0.084| r_loss: 0.378| p_loss: 0.565| v_loss: 0.067| per_loss: 1.361 | a_loss: 0.633
Train: Epoch [129/3000], Step [60/158]| g_loss: 1.466| d_loss: 0.588| gp_loss: 0.038| r_loss: 0.389| p_loss: 0.582| v_loss: 0.067| per_loss: 1.324 | a_loss: 0.586
Train: Epoch [129/3000], Step [90/158]| g_loss: 1.458| d_loss: 0.578| gp_loss: 0.038| r_loss: 0.371| p_loss: 0.536| v_loss: 0.065| per_loss: 1.363 | a_loss: 0.617
Train: Epoch [129/3000], Step [120/158]| g_loss: 1.422| d_loss: 0.522| gp_loss: 0.039| r_loss: 0.360| p_loss: 0.553| v_loss: 0.069| per_loss: 1.348 | a_loss: 0.582
Train: Epoch [129/3000], Step [150/158]| g_loss: 1.519| d_loss: 0.484| gp_loss: 0.041| r_loss: 0.390| p_loss: 0.566| v_loss: 0.066| per_loss: 1.384 | a_loss: 0.641
Train: Epoch [130/3000], Step [30/158]| g_loss: 1.415| d_loss: 0.650| gp_loss: 0.081| r_loss: 0.380| p_loss: 0.546| v_loss: 0.066| per_loss: 1.381 | a_loss: 0.558
Train: Epoch [130/3000], Step [60/158]| g_loss: 1.533| d_loss: 0.464| gp_loss: 0.036| r_loss: 0.386| p_loss: 0.582| v_loss: 0.067| per_loss: 1.342 | a_loss: 0.654
Train: Epoch [130/3000], Step [90/158]| g_loss: 1.455| d_loss: 0.493| gp_loss: 0.040| r_loss: 0.367| p_loss: 0.577| v_loss: 0.066| per_loss: 1.273 | a_loss: 0.606
Train: Epoch [130/3000], Step [120/158]| g_loss: 1.505| d_loss: 0.493| gp_loss: 0.039| r_loss: 0.388| p_loss: 0.579| v_loss: 0.068| per_loss: 1.413 | a_loss: 0.618
Train: Epoch [130/3000], Step [150/158]| g_loss: 1.462| d_loss: 0.549| gp_loss: 0.041| r_loss: 0.395| p_loss: 0.563| v_loss: 0.066| per_loss: 1.314 | a_loss: 0.588
Train: Epoch [131/3000], Step [30/158]| g_loss: 1.443| d_loss: 0.593| gp_loss: 0.113| r_loss: 0.367| p_loss: 0.552| v_loss: 0.064| per_loss: 1.378 | a_loss: 0.599
Train: Epoch [131/3000], Step [60/158]| g_loss: 1.399| d_loss: 0.626| gp_loss: 0.042| r_loss: 0.378| p_loss: 0.564| v_loss: 0.066| per_loss: 1.307 | a_loss: 0.542
Train: Epoch [131/3000], Step [90/158]| g_loss: 1.454| d_loss: 0.566| gp_loss: 0.038| r_loss: 0.395| p_loss: 0.572| v_loss: 0.064| per_loss: 1.362 | a_loss: 0.573
Train: Epoch [131/3000], Step [120/158]| g_loss: 1.427| d_loss: 0.499| gp_loss: 0.041| r_loss: 0.371| p_loss: 0.554| v_loss: 0.067| per_loss: 1.298 | a_loss: 0.582
Train: Epoch [131/3000], Step [150/158]| g_loss: 1.504| d_loss: 0.454| gp_loss: 0.040| r_loss: 0.377| p_loss: 0.548| v_loss: 0.066| per_loss: 1.327 | a_loss: 0.655
Train: Epoch [132/3000], Step [30/158]| g_loss: 1.530| d_loss: 0.591| gp_loss: 0.070| r_loss: 0.419| p_loss: 0.589| v_loss: 0.072| per_loss: 1.286 | a_loss: 0.616
Train: Epoch [132/3000], Step [60/158]| g_loss: 1.470| d_loss: 0.496| gp_loss: 0.040| r_loss: 0.374| p_loss: 0.553| v_loss: 0.069| per_loss: 1.357 | a_loss: 0.614
Train: Epoch [132/3000], Step [90/158]| g_loss: 1.432| d_loss: 0.517| gp_loss: 0.041| r_loss: 0.365| p_loss: 0.542| v_loss: 0.066| per_loss: 1.295 | a_loss: 0.600
Train: Epoch [132/3000], Step [120/158]| g_loss: 1.428| d_loss: 0.530| gp_loss: 0.043| r_loss: 0.370| p_loss: 0.553| v_loss: 0.067| per_loss: 1.333 | a_loss: 0.582
Train: Epoch [132/3000], Step [150/158]| g_loss: 1.460| d_loss: 0.596| gp_loss: 0.042| r_loss: 0.396| p_loss: 0.572| v_loss: 0.070| per_loss: 1.332 | a_loss: 0.574
Train: Epoch [133/3000], Step [30/158]| g_loss: 1.470| d_loss: 0.596| gp_loss: 0.152| r_loss: 0.360| p_loss: 0.569| v_loss: 0.065| per_loss: 1.285 | a_loss: 0.632
Train: Epoch [133/3000], Step [60/158]| g_loss: 1.453| d_loss: 0.540| gp_loss: 0.040| r_loss: 0.358| p_loss: 0.555| v_loss: 0.064| per_loss: 1.345 | a_loss: 0.619
Train: Epoch [133/3000], Step [90/158]| g_loss: 1.432| d_loss: 0.572| gp_loss: 0.040| r_loss: 0.393| p_loss: 0.559| v_loss: 0.066| per_loss: 1.285 | a_loss: 0.565
Train: Epoch [133/3000], Step [120/158]| g_loss: 1.403| d_loss: 0.613| gp_loss: 0.039| r_loss: 0.356| p_loss: 0.558| v_loss: 0.067| per_loss: 1.323 | a_loss: 0.568
Train: Epoch [133/3000], Step [150/158]| g_loss: 1.481| d_loss: 0.538| gp_loss: 0.036| r_loss: 0.389| p_loss: 0.550| v_loss: 0.069| per_loss: 1.328 | a_loss: 0.616
Train: Epoch [134/3000], Step [30/158]| g_loss: 1.512| d_loss: 0.530| gp_loss: 0.080| r_loss: 0.358| p_loss: 0.575| v_loss: 0.070| per_loss: 1.277 | a_loss: 0.669
Train: Epoch [134/3000], Step [60/158]| g_loss: 1.501| d_loss: 0.493| gp_loss: 0.037| r_loss: 0.410| p_loss: 0.572| v_loss: 0.073| per_loss: 1.272 | a_loss: 0.605
Train: Epoch [134/3000], Step [90/158]| g_loss: 1.428| d_loss: 0.579| gp_loss: 0.040| r_loss: 0.383| p_loss: 0.556| v_loss: 0.070| per_loss: 1.299 | a_loss: 0.568
Train: Epoch [134/3000], Step [120/158]| g_loss: 1.431| d_loss: 0.499| gp_loss: 0.038| r_loss: 0.357| p_loss: 0.529| v_loss: 0.066| per_loss: 1.286 | a_loss: 0.614
Train: Epoch [134/3000], Step [150/158]| g_loss: 1.430| d_loss: 0.553| gp_loss: 0.039| r_loss: 0.364| p_loss: 0.544| v_loss: 0.066| per_loss: 1.283 | a_loss: 0.599
Train: Epoch [135/3000], Step [30/158]| g_loss: 1.425| d_loss: 0.581| gp_loss: 0.088| r_loss: 0.371| p_loss: 0.548| v_loss: 0.065| per_loss: 1.226 | a_loss: 0.592
Train: Epoch [135/3000], Step [60/158]| g_loss: 1.394| d_loss: 0.592| gp_loss: 0.041| r_loss: 0.360| p_loss: 0.534| v_loss: 0.061| per_loss: 1.332 | a_loss: 0.572
Train: Epoch [135/3000], Step [90/158]| g_loss: 1.515| d_loss: 0.494| gp_loss: 0.038| r_loss: 0.367| p_loss: 0.551| v_loss: 0.064| per_loss: 1.383 | a_loss: 0.669
Train: Epoch [135/3000], Step [120/158]| g_loss: 1.426| d_loss: 0.470| gp_loss: 0.037| r_loss: 0.384| p_loss: 0.552| v_loss: 0.064| per_loss: 1.297 | a_loss: 0.572
Train: Epoch [135/3000], Step [150/158]| g_loss: 1.453| d_loss: 0.524| gp_loss: 0.039| r_loss: 0.378| p_loss: 0.576| v_loss: 0.067| per_loss: 1.235 | a_loss: 0.596
Train: Epoch [136/3000], Step [30/158]| g_loss: 1.458| d_loss: 0.565| gp_loss: 0.096| r_loss: 0.370| p_loss: 0.539| v_loss: 0.069| per_loss: 1.309 | a_loss: 0.619
Train: Epoch [136/3000], Step [60/158]| g_loss: 1.441| d_loss: 0.521| gp_loss: 0.039| r_loss: 0.369| p_loss: 0.535| v_loss: 0.066| per_loss: 1.320 | a_loss: 0.606
Train: Epoch [136/3000], Step [90/158]| g_loss: 1.423| d_loss: 0.556| gp_loss: 0.038| r_loss: 0.365| p_loss: 0.544| v_loss: 0.067| per_loss: 1.310 | a_loss: 0.588
Train: Epoch [136/3000], Step [120/158]| g_loss: 1.399| d_loss: 0.530| gp_loss: 0.040| r_loss: 0.365| p_loss: 0.523| v_loss: 0.067| per_loss: 1.221 | a_loss: 0.584
Train: Epoch [136/3000], Step [150/158]| g_loss: 1.504| d_loss: 0.463| gp_loss: 0.039| r_loss: 0.384| p_loss: 0.566| v_loss: 0.071| per_loss: 1.301 | a_loss: 0.637
Train: Epoch [137/3000], Step [30/158]| g_loss: 1.436| d_loss: 0.552| gp_loss: 0.098| r_loss: 0.361| p_loss: 0.542| v_loss: 0.070| per_loss: 1.198 | a_loss: 0.614
Train: Epoch [137/3000], Step [60/158]| g_loss: 1.422| d_loss: 0.523| gp_loss: 0.041| r_loss: 0.357| p_loss: 0.549| v_loss: 0.067| per_loss: 1.279 | a_loss: 0.595
Train: Epoch [137/3000], Step [90/158]| g_loss: 1.434| d_loss: 0.502| gp_loss: 0.041| r_loss: 0.369| p_loss: 0.524| v_loss: 0.067| per_loss: 1.324 | a_loss: 0.603
Train: Epoch [137/3000], Step [120/158]| g_loss: 1.444| d_loss: 0.498| gp_loss: 0.043| r_loss: 0.353| p_loss: 0.534| v_loss: 0.066| per_loss: 1.221 | a_loss: 0.636
Train: Epoch [137/3000], Step [150/158]| g_loss: 1.447| d_loss: 0.530| gp_loss: 0.039| r_loss: 0.373| p_loss: 0.524| v_loss: 0.068| per_loss: 1.249 | a_loss: 0.620
Train: Epoch [138/3000], Step [30/158]| g_loss: 1.415| d_loss: 0.703| gp_loss: 0.097| r_loss: 0.344| p_loss: 0.543| v_loss: 0.065| per_loss: 1.372 | a_loss: 0.598
Train: Epoch [138/3000], Step [60/158]| g_loss: 1.422| d_loss: 0.541| gp_loss: 0.039| r_loss: 0.391| p_loss: 0.546| v_loss: 0.066| per_loss: 1.239 | a_loss: 0.568
Train: Epoch [138/3000], Step [90/158]| g_loss: 1.425| d_loss: 0.564| gp_loss: 0.037| r_loss: 0.364| p_loss: 0.547| v_loss: 0.069| per_loss: 1.314 | a_loss: 0.587
Train: Epoch [138/3000], Step [120/158]| g_loss: 1.400| d_loss: 0.533| gp_loss: 0.043| r_loss: 0.374| p_loss: 0.540| v_loss: 0.064| per_loss: 1.230 | a_loss: 0.569
Train: Epoch [138/3000], Step [150/158]| g_loss: 1.474| d_loss: 0.456| gp_loss: 0.039| r_loss: 0.353| p_loss: 0.540| v_loss: 0.066| per_loss: 1.239 | a_loss: 0.661
Train: Epoch [139/3000], Step [30/158]| g_loss: 1.419| d_loss: 0.564| gp_loss: 0.094| r_loss: 0.367| p_loss: 0.536| v_loss: 0.064| per_loss: 1.218 | a_loss: 0.598
Train: Epoch [139/3000], Step [60/158]| g_loss: 1.424| d_loss: 0.560| gp_loss: 0.039| r_loss: 0.361| p_loss: 0.553| v_loss: 0.066| per_loss: 1.228 | a_loss: 0.598
Train: Epoch [139/3000], Step [90/158]| g_loss: 1.434| d_loss: 0.527| gp_loss: 0.038| r_loss: 0.362| p_loss: 0.571| v_loss: 0.068| per_loss: 1.268 | a_loss: 0.592
Train: Epoch [139/3000], Step [120/158]| g_loss: 1.455| d_loss: 0.654| gp_loss: 0.041| r_loss: 0.378| p_loss: 0.565| v_loss: 0.067| per_loss: 1.253 | a_loss: 0.601
Train: Epoch [139/3000], Step [150/158]| g_loss: 1.460| d_loss: 0.571| gp_loss: 0.041| r_loss: 0.380| p_loss: 0.565| v_loss: 0.063| per_loss: 1.225 | a_loss: 0.611
Train: Epoch [140/3000], Step [30/158]| g_loss: 1.416| d_loss: 0.561| gp_loss: 0.101| r_loss: 0.353| p_loss: 0.544| v_loss: 0.068| per_loss: 1.259 | a_loss: 0.598
Train: Epoch [140/3000], Step [60/158]| g_loss: 1.348| d_loss: 0.654| gp_loss: 0.039| r_loss: 0.382| p_loss: 0.535| v_loss: 0.064| per_loss: 1.211 | a_loss: 0.513
Train: Epoch [140/3000], Step [90/158]| g_loss: 1.399| d_loss: 0.538| gp_loss: 0.036| r_loss: 0.368| p_loss: 0.535| v_loss: 0.064| per_loss: 1.180 | a_loss: 0.581
Train: Epoch [140/3000], Step [120/158]| g_loss: 1.386| d_loss: 0.539| gp_loss: 0.039| r_loss: 0.371| p_loss: 0.526| v_loss: 0.065| per_loss: 1.220 | a_loss: 0.565
Train: Epoch [140/3000], Step [150/158]| g_loss: 1.408| d_loss: 0.516| gp_loss: 0.041| r_loss: 0.354| p_loss: 0.542| v_loss: 0.064| per_loss: 1.209 | a_loss: 0.597
Train: Epoch [141/3000], Step [30/158]| g_loss: 1.422| d_loss: 0.572| gp_loss: 0.088| r_loss: 0.356| p_loss: 0.520| v_loss: 0.063| per_loss: 1.216 | a_loss: 0.621
Train: Epoch [141/3000], Step [60/158]| g_loss: 1.461| d_loss: 0.495| gp_loss: 0.039| r_loss: 0.367| p_loss: 0.539| v_loss: 0.065| per_loss: 1.310 | a_loss: 0.628
Train: Epoch [141/3000], Step [90/158]| g_loss: 1.383| d_loss: 0.515| gp_loss: 0.038| r_loss: 0.350| p_loss: 0.508| v_loss: 0.064| per_loss: 1.174 | a_loss: 0.597
Train: Epoch [141/3000], Step [120/158]| g_loss: 1.386| d_loss: 0.523| gp_loss: 0.039| r_loss: 0.353| p_loss: 0.534| v_loss: 0.066| per_loss: 1.128 | a_loss: 0.587
Train: Epoch [141/3000], Step [150/158]| g_loss: 1.373| d_loss: 0.577| gp_loss: 0.042| r_loss: 0.361| p_loss: 0.538| v_loss: 0.065| per_loss: 1.152 | a_loss: 0.563
Train: Epoch [142/3000], Step [30/158]| g_loss: 1.419| d_loss: 0.673| gp_loss: 0.164| r_loss: 0.357| p_loss: 0.532| v_loss: 0.065| per_loss: 1.170 | a_loss: 0.614
Train: Epoch [142/3000], Step [60/158]| g_loss: 1.418| d_loss: 0.493| gp_loss: 0.037| r_loss: 0.347| p_loss: 0.539| v_loss: 0.068| per_loss: 1.143 | a_loss: 0.619
Train: Epoch [142/3000], Step [90/158]| g_loss: 1.356| d_loss: 0.552| gp_loss: 0.038| r_loss: 0.346| p_loss: 0.511| v_loss: 0.067| per_loss: 1.167 | a_loss: 0.571
Train: Epoch [142/3000], Step [120/158]| g_loss: 1.362| d_loss: 0.589| gp_loss: 0.040| r_loss: 0.355| p_loss: 0.513| v_loss: 0.065| per_loss: 1.192 | a_loss: 0.566
Train: Epoch [142/3000], Step [150/158]| g_loss: 1.484| d_loss: 0.477| gp_loss: 0.040| r_loss: 0.374| p_loss: 0.543| v_loss: 0.065| per_loss: 1.237 | a_loss: 0.650
Train: Epoch [143/3000], Step [30/158]| g_loss: 1.326| d_loss: 0.663| gp_loss: 0.110| r_loss: 0.340| p_loss: 0.516| v_loss: 0.064| per_loss: 1.120 | a_loss: 0.552
Train: Epoch [143/3000], Step [60/158]| g_loss: 1.381| d_loss: 0.475| gp_loss: 0.038| r_loss: 0.344| p_loss: 0.517| v_loss: 0.066| per_loss: 1.116 | a_loss: 0.602
Train: Epoch [143/3000], Step [90/158]| g_loss: 1.367| d_loss: 0.542| gp_loss: 0.041| r_loss: 0.341| p_loss: 0.525| v_loss: 0.065| per_loss: 1.190 | a_loss: 0.579
Train: Epoch [143/3000], Step [120/158]| g_loss: 1.425| d_loss: 0.511| gp_loss: 0.037| r_loss: 0.341| p_loss: 0.508| v_loss: 0.062| per_loss: 1.239 | a_loss: 0.644
Train: Epoch [143/3000], Step [150/158]| g_loss: 1.443| d_loss: 0.520| gp_loss: 0.038| r_loss: 0.381| p_loss: 0.519| v_loss: 0.064| per_loss: 1.255 | a_loss: 0.613
Train: Epoch [144/3000], Step [30/158]| g_loss: 1.375| d_loss: 0.598| gp_loss: 0.092| r_loss: 0.375| p_loss: 0.527| v_loss: 0.062| per_loss: 1.112 | a_loss: 0.564
Train: Epoch [144/3000], Step [60/158]| g_loss: 1.414| d_loss: 0.509| gp_loss: 0.038| r_loss: 0.342| p_loss: 0.526| v_loss: 0.065| per_loss: 1.193 | a_loss: 0.624
Train: Epoch [144/3000], Step [90/158]| g_loss: 1.408| d_loss: 0.503| gp_loss: 0.039| r_loss: 0.355| p_loss: 0.525| v_loss: 0.063| per_loss: 1.268 | a_loss: 0.601
Train: Epoch [144/3000], Step [120/158]| g_loss: 1.369| d_loss: 0.561| gp_loss: 0.037| r_loss: 0.335| p_loss: 0.499| v_loss: 0.062| per_loss: 1.186 | a_loss: 0.603
Train: Epoch [144/3000], Step [150/158]| g_loss: 1.421| d_loss: 0.565| gp_loss: 0.039| r_loss: 0.355| p_loss: 0.527| v_loss: 0.064| per_loss: 1.203 | a_loss: 0.617
Train: Epoch [145/3000], Step [30/158]| g_loss: 1.319| d_loss: 0.691| gp_loss: 0.106| r_loss: 0.353| p_loss: 0.509| v_loss: 0.063| per_loss: 1.215 | a_loss: 0.527
Train: Epoch [145/3000], Step [60/158]| g_loss: 1.359| d_loss: 0.503| gp_loss: 0.037| r_loss: 0.344| p_loss: 0.486| v_loss: 0.063| per_loss: 1.153 | a_loss: 0.593
Train: Epoch [145/3000], Step [90/158]| g_loss: 1.372| d_loss: 0.514| gp_loss: 0.038| r_loss: 0.341| p_loss: 0.518| v_loss: 0.063| per_loss: 1.182 | a_loss: 0.592
Train: Epoch [145/3000], Step [120/158]| g_loss: 1.409| d_loss: 0.515| gp_loss: 0.039| r_loss: 0.368| p_loss: 0.517| v_loss: 0.062| per_loss: 1.238 | a_loss: 0.597
Train: Epoch [145/3000], Step [150/158]| g_loss: 1.382| d_loss: 0.531| gp_loss: 0.039| r_loss: 0.344| p_loss: 0.516| v_loss: 0.064| per_loss: 1.163 | a_loss: 0.601
Train: Epoch [146/3000], Step [30/158]| g_loss: 1.398| d_loss: 0.538| gp_loss: 0.101| r_loss: 0.341| p_loss: 0.510| v_loss: 0.061| per_loss: 1.212 | a_loss: 0.619
Train: Epoch [146/3000], Step [60/158]| g_loss: 1.395| d_loss: 0.517| gp_loss: 0.039| r_loss: 0.347| p_loss: 0.532| v_loss: 0.064| per_loss: 1.217 | a_loss: 0.596
Train: Epoch [146/3000], Step [90/158]| g_loss: 1.344| d_loss: 0.618| gp_loss: 0.040| r_loss: 0.362| p_loss: 0.506| v_loss: 0.062| per_loss: 1.106 | a_loss: 0.556
Train: Epoch [146/3000], Step [120/158]| g_loss: 1.416| d_loss: 0.493| gp_loss: 0.039| r_loss: 0.367| p_loss: 0.511| v_loss: 0.066| per_loss: 1.100 | a_loss: 0.618
Train: Epoch [146/3000], Step [150/158]| g_loss: 1.387| d_loss: 0.534| gp_loss: 0.038| r_loss: 0.350| p_loss: 0.495| v_loss: 0.062| per_loss: 1.159 | a_loss: 0.611
Train: Epoch [147/3000], Step [30/158]| g_loss: 1.392| d_loss: 0.601| gp_loss: 0.104| r_loss: 0.382| p_loss: 0.510| v_loss: 0.062| per_loss: 1.183 | a_loss: 0.574
Train: Epoch [147/3000], Step [60/158]| g_loss: 1.373| d_loss: 0.516| gp_loss: 0.040| r_loss: 0.350| p_loss: 0.513| v_loss: 0.064| per_loss: 1.124 | a_loss: 0.591
Train: Epoch [147/3000], Step [90/158]| g_loss: 1.518| d_loss: 0.555| gp_loss: 0.044| r_loss: 0.356| p_loss: 0.588| v_loss: 0.064| per_loss: 1.212 | a_loss: 0.683
Train: Epoch [147/3000], Step [120/158]| g_loss: 1.464| d_loss: 0.507| gp_loss: 0.037| r_loss: 0.362| p_loss: 0.570| v_loss: 0.063| per_loss: 1.153 | a_loss: 0.638
Train: Epoch [147/3000], Step [150/158]| g_loss: 1.389| d_loss: 0.570| gp_loss: 0.040| r_loss: 0.373| p_loss: 0.570| v_loss: 0.063| per_loss: 1.125 | a_loss: 0.556
Train: Epoch [148/3000], Step [30/158]| g_loss: 1.381| d_loss: 0.589| gp_loss: 0.108| r_loss: 0.348| p_loss: 0.531| v_loss: 0.061| per_loss: 1.147 | a_loss: 0.591
Train: Epoch [148/3000], Step [60/158]| g_loss: 1.353| d_loss: 0.545| gp_loss: 0.039| r_loss: 0.344| p_loss: 0.509| v_loss: 0.064| per_loss: 1.118 | a_loss: 0.579
Train: Epoch [148/3000], Step [90/158]| g_loss: 1.410| d_loss: 0.503| gp_loss: 0.037| r_loss: 0.363| p_loss: 0.520| v_loss: 0.066| per_loss: 1.110 | a_loss: 0.610
Train: Epoch [148/3000], Step [120/158]| g_loss: 1.333| d_loss: 0.548| gp_loss: 0.041| r_loss: 0.334| p_loss: 0.502| v_loss: 0.066| per_loss: 1.010 | a_loss: 0.582
Train: Epoch [148/3000], Step [150/158]| g_loss: 1.334| d_loss: 0.568| gp_loss: 0.043| r_loss: 0.346| p_loss: 0.484| v_loss: 0.061| per_loss: 1.112 | a_loss: 0.573
Train: Epoch [149/3000], Step [30/158]| g_loss: 1.306| d_loss: 0.706| gp_loss: 0.136| r_loss: 0.324| p_loss: 0.479| v_loss: 0.059| per_loss: 1.124 | a_loss: 0.571
Train: Epoch [149/3000], Step [60/158]| g_loss: 1.344| d_loss: 0.521| gp_loss: 0.040| r_loss: 0.353| p_loss: 0.507| v_loss: 0.060| per_loss: 1.095 | a_loss: 0.568
Train: Epoch [149/3000], Step [90/158]| g_loss: 1.383| d_loss: 0.463| gp_loss: 0.040| r_loss: 0.342| p_loss: 0.500| v_loss: 0.063| per_loss: 1.114 | a_loss: 0.617
Train: Epoch [149/3000], Step [120/158]| g_loss: 1.388| d_loss: 0.544| gp_loss: 0.040| r_loss: 0.351| p_loss: 0.505| v_loss: 0.060| per_loss: 1.091 | a_loss: 0.616
Train: Epoch [149/3000], Step [150/158]| g_loss: 1.327| d_loss: 0.577| gp_loss: 0.042| r_loss: 0.351| p_loss: 0.496| v_loss: 0.063| per_loss: 1.094 | a_loss: 0.556
Train: Epoch [150/3000], Step [30/158]| g_loss: 1.401| d_loss: 0.512| gp_loss: 0.091| r_loss: 0.346| p_loss: 0.499| v_loss: 0.060| per_loss: 1.049 | a_loss: 0.641
Train: Epoch [150/3000], Step [60/158]| g_loss: 1.425| d_loss: 0.463| gp_loss: 0.039| r_loss: 0.329| p_loss: 0.505| v_loss: 0.063| per_loss: 1.172 | a_loss: 0.663
Train: Epoch [150/3000], Step [90/158]| g_loss: 1.348| d_loss: 0.586| gp_loss: 0.041| r_loss: 0.360| p_loss: 0.525| v_loss: 0.062| per_loss: 1.097 | a_loss: 0.554
Train: Epoch [150/3000], Step [120/158]| g_loss: 1.305| d_loss: 0.686| gp_loss: 0.044| r_loss: 0.344| p_loss: 0.511| v_loss: 0.061| per_loss: 1.069 | a_loss: 0.537
Train: Epoch [150/3000], Step [150/158]| g_loss: 1.367| d_loss: 0.529| gp_loss: 0.041| r_loss: 0.353| p_loss: 0.485| v_loss: 0.062| per_loss: 1.084 | a_loss: 0.601
Test: Epoch [150/3000]| g_loss: 1.309| r_loss: 0.907| p_loss: 0.545| v_loss: 0.047
Train: Epoch [151/3000], Step [30/158]| g_loss: 1.325| d_loss: 0.591| gp_loss: 0.040| r_loss: 0.342| p_loss: 0.512| v_loss: 0.061| per_loss: 1.075 | a_loss: 0.558
Train: Epoch [151/3000], Step [60/158]| g_loss: 1.351| d_loss: 0.550| gp_loss: 0.041| r_loss: 0.346| p_loss: 0.506| v_loss: 0.060| per_loss: 1.105 | a_loss: 0.582
Train: Epoch [151/3000], Step [90/158]| g_loss: 1.300| d_loss: 0.582| gp_loss: 0.042| r_loss: 0.341| p_loss: 0.495| v_loss: 0.060| per_loss: 1.055 | a_loss: 0.545
Train: Epoch [151/3000], Step [120/158]| g_loss: 1.391| d_loss: 0.449| gp_loss: 0.041| r_loss: 0.348| p_loss: 0.484| v_loss: 0.061| per_loss: 1.080 | a_loss: 0.632
Train: Epoch [151/3000], Step [150/158]| g_loss: 1.369| d_loss: 0.514| gp_loss: 0.041| r_loss: 0.336| p_loss: 0.489| v_loss: 0.059| per_loss: 1.148 | a_loss: 0.614
Train: Epoch [152/3000], Step [30/158]| g_loss: 1.368| d_loss: 0.626| gp_loss: 0.088| r_loss: 0.359| p_loss: 0.512| v_loss: 0.063| per_loss: 1.103 | a_loss: 0.580
Train: Epoch [152/3000], Step [60/158]| g_loss: 1.342| d_loss: 0.512| gp_loss: 0.039| r_loss: 0.344| p_loss: 0.491| v_loss: 0.065| per_loss: 1.059 | a_loss: 0.581
Train: Epoch [152/3000], Step [90/158]| g_loss: 1.361| d_loss: 0.527| gp_loss: 0.043| r_loss: 0.348| p_loss: 0.490| v_loss: 0.056| per_loss: 1.125 | a_loss: 0.599
Train: Epoch [152/3000], Step [120/158]| g_loss: 1.376| d_loss: 0.474| gp_loss: 0.043| r_loss: 0.333| p_loss: 0.472| v_loss: 0.062| per_loss: 1.023 | a_loss: 0.644
Train: Epoch [152/3000], Step [150/158]| g_loss: 1.338| d_loss: 0.532| gp_loss: 0.045| r_loss: 0.325| p_loss: 0.491| v_loss: 0.063| per_loss: 1.089 | a_loss: 0.595
Train: Epoch [153/3000], Step [30/158]| g_loss: 1.399| d_loss: 0.648| gp_loss: 0.169| r_loss: 0.326| p_loss: 0.490| v_loss: 0.060| per_loss: 1.212 | a_loss: 0.646
Train: Epoch [153/3000], Step [60/158]| g_loss: 1.290| d_loss: 0.558| gp_loss: 0.040| r_loss: 0.331| p_loss: 0.496| v_loss: 0.060| per_loss: 1.132 | a_loss: 0.538
Train: Epoch [153/3000], Step [90/158]| g_loss: 1.378| d_loss: 0.521| gp_loss: 0.044| r_loss: 0.366| p_loss: 0.506| v_loss: 0.060| per_loss: 1.109 | a_loss: 0.589
Train: Epoch [153/3000], Step [120/158]| g_loss: 1.406| d_loss: 0.491| gp_loss: 0.037| r_loss: 0.355| p_loss: 0.494| v_loss: 0.061| per_loss: 1.065 | a_loss: 0.636
Train: Epoch [153/3000], Step [150/158]| g_loss: 1.342| d_loss: 0.550| gp_loss: 0.039| r_loss: 0.334| p_loss: 0.508| v_loss: 0.061| per_loss: 1.052 | a_loss: 0.587
Train: Epoch [154/3000], Step [30/158]| g_loss: 1.356| d_loss: 0.522| gp_loss: 0.083| r_loss: 0.342| p_loss: 0.496| v_loss: 0.058| per_loss: 1.083 | a_loss: 0.600
Train: Epoch [154/3000], Step [60/158]| g_loss: 1.317| d_loss: 0.577| gp_loss: 0.041| r_loss: 0.334| p_loss: 0.496| v_loss: 0.062| per_loss: 1.082 | a_loss: 0.565
Train: Epoch [154/3000], Step [90/158]| g_loss: 1.313| d_loss: 0.554| gp_loss: 0.043| r_loss: 0.331| p_loss: 0.477| v_loss: 0.057| per_loss: 1.093 | a_loss: 0.577
Train: Epoch [154/3000], Step [120/158]| g_loss: 1.349| d_loss: 0.533| gp_loss: 0.043| r_loss: 0.336| p_loss: 0.494| v_loss: 0.060| per_loss: 1.105 | a_loss: 0.595
Train: Epoch [154/3000], Step [150/158]| g_loss: 1.401| d_loss: 0.482| gp_loss: 0.039| r_loss: 0.343| p_loss: 0.503| v_loss: 0.060| per_loss: 1.130 | a_loss: 0.634
Train: Epoch [155/3000], Step [30/158]| g_loss: 1.381| d_loss: 0.591| gp_loss: 0.118| r_loss: 0.340| p_loss: 0.494| v_loss: 0.060| per_loss: 1.128 | a_loss: 0.622
Train: Epoch [155/3000], Step [60/158]| g_loss: 1.327| d_loss: 0.504| gp_loss: 0.040| r_loss: 0.317| p_loss: 0.488| v_loss: 0.062| per_loss: 1.082 | a_loss: 0.596
Train: Epoch [155/3000], Step [90/158]| g_loss: 1.355| d_loss: 0.571| gp_loss: 0.042| r_loss: 0.336| p_loss: 0.496| v_loss: 0.059| per_loss: 1.154 | a_loss: 0.596
Train: Epoch [155/3000], Step [120/158]| g_loss: 1.405| d_loss: 0.549| gp_loss: 0.041| r_loss: 0.340| p_loss: 0.513| v_loss: 0.062| per_loss: 1.163 | a_loss: 0.631
Train: Epoch [155/3000], Step [150/158]| g_loss: 1.355| d_loss: 0.544| gp_loss: 0.040| r_loss: 0.348| p_loss: 0.491| v_loss: 0.060| per_loss: 1.046 | a_loss: 0.597
Train: Epoch [156/3000], Step [30/158]| g_loss: 1.390| d_loss: 0.553| gp_loss: 0.135| r_loss: 0.345| p_loss: 0.497| v_loss: 0.061| per_loss: 1.116 | a_loss: 0.623
Train: Epoch [156/3000], Step [60/158]| g_loss: 1.298| d_loss: 0.528| gp_loss: 0.041| r_loss: 0.326| p_loss: 0.486| v_loss: 0.061| per_loss: 1.035 | a_loss: 0.564
Train: Epoch [156/3000], Step [90/158]| g_loss: 1.345| d_loss: 0.527| gp_loss: 0.041| r_loss: 0.333| p_loss: 0.493| v_loss: 0.059| per_loss: 1.158 | a_loss: 0.591
Train: Epoch [156/3000], Step [120/158]| g_loss: 1.313| d_loss: 0.576| gp_loss: 0.038| r_loss: 0.327| p_loss: 0.488| v_loss: 0.059| per_loss: 1.128 | a_loss: 0.570
Train: Epoch [156/3000], Step [150/158]| g_loss: 1.387| d_loss: 0.610| gp_loss: 0.041| r_loss: 0.362| p_loss: 0.509| v_loss: 0.060| per_loss: 1.076 | a_loss: 0.603
Train: Epoch [157/3000], Step [30/158]| g_loss: 1.347| d_loss: 0.616| gp_loss: 0.125| r_loss: 0.336| p_loss: 0.494| v_loss: 0.059| per_loss: 1.118 | a_loss: 0.592
Train: Epoch [157/3000], Step [60/158]| g_loss: 1.331| d_loss: 0.573| gp_loss: 0.036| r_loss: 0.359| p_loss: 0.508| v_loss: 0.059| per_loss: 1.081 | a_loss: 0.551
Train: Epoch [157/3000], Step [90/158]| g_loss: 1.303| d_loss: 0.531| gp_loss: 0.040| r_loss: 0.334| p_loss: 0.481| v_loss: 0.061| per_loss: 1.087 | a_loss: 0.559
Train: Epoch [157/3000], Step [120/158]| g_loss: 1.378| d_loss: 0.481| gp_loss: 0.036| r_loss: 0.332| p_loss: 0.478| v_loss: 0.061| per_loss: 1.035 | a_loss: 0.643
Train: Epoch [157/3000], Step [150/158]| g_loss: 1.297| d_loss: 0.559| gp_loss: 0.040| r_loss: 0.316| p_loss: 0.475| v_loss: 0.058| per_loss: 1.121 | a_loss: 0.574
Train: Epoch [158/3000], Step [30/158]| g_loss: 1.352| d_loss: 0.585| gp_loss: 0.106| r_loss: 0.322| p_loss: 0.491| v_loss: 0.060| per_loss: 1.132 | a_loss: 0.611
Train: Epoch [158/3000], Step [60/158]| g_loss: 1.312| d_loss: 0.594| gp_loss: 0.037| r_loss: 0.335| p_loss: 0.504| v_loss: 0.059| per_loss: 1.089 | a_loss: 0.556
Train: Epoch [158/3000], Step [90/158]| g_loss: 1.335| d_loss: 0.548| gp_loss: 0.037| r_loss: 0.326| p_loss: 0.478| v_loss: 0.057| per_loss: 1.080 | a_loss: 0.604
Train: Epoch [158/3000], Step [120/158]| g_loss: 1.306| d_loss: 0.505| gp_loss: 0.039| r_loss: 0.330| p_loss: 0.473| v_loss: 0.062| per_loss: 1.071 | a_loss: 0.570
Train: Epoch [158/3000], Step [150/158]| g_loss: 1.326| d_loss: 0.580| gp_loss: 0.041| r_loss: 0.351| p_loss: 0.470| v_loss: 0.059| per_loss: 1.016 | a_loss: 0.580
Train: Epoch [159/3000], Step [30/158]| g_loss: 1.307| d_loss: 0.620| gp_loss: 0.116| r_loss: 0.323| p_loss: 0.479| v_loss: 0.059| per_loss: 1.106 | a_loss: 0.574
Train: Epoch [159/3000], Step [60/158]| g_loss: 1.341| d_loss: 0.484| gp_loss: 0.038| r_loss: 0.328| p_loss: 0.468| v_loss: 0.059| per_loss: 1.061 | a_loss: 0.613
Train: Epoch [159/3000], Step [90/158]| g_loss: 1.327| d_loss: 0.498| gp_loss: 0.039| r_loss: 0.332| p_loss: 0.466| v_loss: 0.060| per_loss: 1.043 | a_loss: 0.597
Train: Epoch [159/3000], Step [120/158]| g_loss: 1.319| d_loss: 0.560| gp_loss: 0.040| r_loss: 0.324| p_loss: 0.473| v_loss: 0.061| per_loss: 1.044 | a_loss: 0.594
Train: Epoch [159/3000], Step [150/158]| g_loss: 1.344| d_loss: 0.545| gp_loss: 0.041| r_loss: 0.330| p_loss: 0.465| v_loss: 0.058| per_loss: 1.096 | a_loss: 0.613
Train: Epoch [160/3000], Step [30/158]| g_loss: 1.277| d_loss: 0.680| gp_loss: 0.134| r_loss: 0.320| p_loss: 0.477| v_loss: 0.058| per_loss: 1.130 | a_loss: 0.546
Train: Epoch [160/3000], Step [60/158]| g_loss: 1.292| d_loss: 0.537| gp_loss: 0.040| r_loss: 0.311| p_loss: 0.472| v_loss: 0.061| per_loss: 1.079 | a_loss: 0.577
Train: Epoch [160/3000], Step [90/158]| g_loss: 1.350| d_loss: 0.483| gp_loss: 0.041| r_loss: 0.323| p_loss: 0.477| v_loss: 0.058| per_loss: 1.075 | a_loss: 0.622
Train: Epoch [160/3000], Step [120/158]| g_loss: 1.376| d_loss: 0.474| gp_loss: 0.040| r_loss: 0.359| p_loss: 0.482| v_loss: 0.060| per_loss: 1.081 | a_loss: 0.608
Train: Epoch [160/3000], Step [150/158]| g_loss: 1.287| d_loss: 0.595| gp_loss: 0.041| r_loss: 0.334| p_loss: 0.479| v_loss: 0.062| per_loss: 1.081 | a_loss: 0.544
Train: Epoch [161/3000], Step [30/158]| g_loss: 1.316| d_loss: 0.615| gp_loss: 0.147| r_loss: 0.306| p_loss: 0.470| v_loss: 0.059| per_loss: 1.139 | a_loss: 0.602
Train: Epoch [161/3000], Step [60/158]| g_loss: 1.296| d_loss: 0.623| gp_loss: 0.040| r_loss: 0.338| p_loss: 0.486| v_loss: 0.062| per_loss: 1.097 | a_loss: 0.544
Train: Epoch [161/3000], Step [90/158]| g_loss: 1.283| d_loss: 0.643| gp_loss: 0.040| r_loss: 0.334| p_loss: 0.482| v_loss: 0.060| per_loss: 1.073 | a_loss: 0.540
Train: Epoch [161/3000], Step [120/158]| g_loss: 1.282| d_loss: 0.570| gp_loss: 0.039| r_loss: 0.317| p_loss: 0.464| v_loss: 0.061| per_loss: 1.078 | a_loss: 0.564
Train: Epoch [161/3000], Step [150/158]| g_loss: 1.337| d_loss: 0.548| gp_loss: 0.040| r_loss: 0.348| p_loss: 0.479| v_loss: 0.063| per_loss: 1.017 | a_loss: 0.586
Train: Epoch [162/3000], Step [30/158]| g_loss: 1.328| d_loss: 0.599| gp_loss: 0.145| r_loss: 0.322| p_loss: 0.466| v_loss: 0.061| per_loss: 1.043 | a_loss: 0.607
Train: Epoch [162/3000], Step [60/158]| g_loss: 1.344| d_loss: 0.495| gp_loss: 0.037| r_loss: 0.321| p_loss: 0.454| v_loss: 0.064| per_loss: 1.124 | a_loss: 0.620
Train: Epoch [162/3000], Step [90/158]| g_loss: 1.308| d_loss: 0.544| gp_loss: 0.039| r_loss: 0.308| p_loss: 0.467| v_loss: 0.060| per_loss: 1.109 | a_loss: 0.595
Train: Epoch [162/3000], Step [120/158]| g_loss: 1.293| d_loss: 0.612| gp_loss: 0.041| r_loss: 0.346| p_loss: 0.470| v_loss: 0.058| per_loss: 1.072 | a_loss: 0.547
Train: Epoch [162/3000], Step [150/158]| g_loss: 1.274| d_loss: 0.562| gp_loss: 0.040| r_loss: 0.319| p_loss: 0.482| v_loss: 0.058| per_loss: 1.020 | a_loss: 0.555
Train: Epoch [163/3000], Step [30/158]| g_loss: 1.295| d_loss: 0.820| gp_loss: 0.096| r_loss: 0.346| p_loss: 0.475| v_loss: 0.059| per_loss: 1.083 | a_loss: 0.545
Train: Epoch [163/3000], Step [60/158]| g_loss: 1.314| d_loss: 0.510| gp_loss: 0.037| r_loss: 0.328| p_loss: 0.492| v_loss: 0.061| per_loss: 1.035 | a_loss: 0.576
Train: Epoch [163/3000], Step [90/158]| g_loss: 1.283| d_loss: 0.535| gp_loss: 0.034| r_loss: 0.323| p_loss: 0.462| v_loss: 0.055| per_loss: 1.081 | a_loss: 0.567
Train: Epoch [163/3000], Step [120/158]| g_loss: 1.322| d_loss: 0.555| gp_loss: 0.040| r_loss: 0.337| p_loss: 0.470| v_loss: 0.058| per_loss: 1.111 | a_loss: 0.582
Train: Epoch [163/3000], Step [150/158]| g_loss: 1.276| d_loss: 0.584| gp_loss: 0.035| r_loss: 0.301| p_loss: 0.491| v_loss: 0.062| per_loss: 1.093 | a_loss: 0.558
Train: Epoch [164/3000], Step [30/158]| g_loss: 1.279| d_loss: 0.579| gp_loss: 0.062| r_loss: 0.315| p_loss: 0.474| v_loss: 0.059| per_loss: 1.064 | a_loss: 0.561
Train: Epoch [164/3000], Step [60/158]| g_loss: 1.313| d_loss: 0.494| gp_loss: 0.037| r_loss: 0.312| p_loss: 0.450| v_loss: 0.056| per_loss: 1.076 | a_loss: 0.612
Train: Epoch [164/3000], Step [90/158]| g_loss: 1.363| d_loss: 0.535| gp_loss: 0.036| r_loss: 0.340| p_loss: 0.472| v_loss: 0.058| per_loss: 1.116 | a_loss: 0.617
Train: Epoch [164/3000], Step [120/158]| g_loss: 1.239| d_loss: 0.658| gp_loss: 0.042| r_loss: 0.339| p_loss: 0.458| v_loss: 0.058| per_loss: 1.097 | a_loss: 0.504
Train: Epoch [164/3000], Step [150/158]| g_loss: 1.259| d_loss: 0.587| gp_loss: 0.039| r_loss: 0.313| p_loss: 0.475| v_loss: 0.060| per_loss: 1.041 | a_loss: 0.544
Train: Epoch [165/3000], Step [30/158]| g_loss: 1.307| d_loss: 0.537| gp_loss: 0.071| r_loss: 0.314| p_loss: 0.472| v_loss: 0.059| per_loss: 1.020 | a_loss: 0.596
Train: Epoch [165/3000], Step [60/158]| g_loss: 1.341| d_loss: 0.473| gp_loss: 0.040| r_loss: 0.339| p_loss: 0.453| v_loss: 0.059| per_loss: 1.024 | a_loss: 0.615
Train: Epoch [165/3000], Step [90/158]| g_loss: 1.372| d_loss: 0.478| gp_loss: 0.041| r_loss: 0.325| p_loss: 0.466| v_loss: 0.058| per_loss: 1.150 | a_loss: 0.641
Train: Epoch [165/3000], Step [120/158]| g_loss: 1.216| d_loss: 0.624| gp_loss: 0.043| r_loss: 0.295| p_loss: 0.456| v_loss: 0.058| per_loss: 1.070 | a_loss: 0.528
Train: Epoch [165/3000], Step [150/158]| g_loss: 1.283| d_loss: 0.547| gp_loss: 0.042| r_loss: 0.319| p_loss: 0.457| v_loss: 0.057| per_loss: 1.037 | a_loss: 0.575
Train: Epoch [166/3000], Step [30/158]| g_loss: 1.275| d_loss: 0.668| gp_loss: 0.139| r_loss: 0.310| p_loss: 0.459| v_loss: 0.060| per_loss: 1.049 | a_loss: 0.571
Train: Epoch [166/3000], Step [60/158]| g_loss: 1.231| d_loss: 0.574| gp_loss: 0.041| r_loss: 0.303| p_loss: 0.443| v_loss: 0.057| per_loss: 1.092 | a_loss: 0.541
Train: Epoch [166/3000], Step [90/158]| g_loss: 1.268| d_loss: 0.599| gp_loss: 0.042| r_loss: 0.336| p_loss: 0.468| v_loss: 0.057| per_loss: 1.079 | a_loss: 0.535
Train: Epoch [166/3000], Step [120/158]| g_loss: 1.285| d_loss: 0.589| gp_loss: 0.039| r_loss: 0.308| p_loss: 0.468| v_loss: 0.059| per_loss: 1.101 | a_loss: 0.573
Train: Epoch [166/3000], Step [150/158]| g_loss: 1.365| d_loss: 0.459| gp_loss: 0.040| r_loss: 0.324| p_loss: 0.461| v_loss: 0.060| per_loss: 1.141 | a_loss: 0.636
Train: Epoch [167/3000], Step [30/158]| g_loss: 1.258| d_loss: 0.676| gp_loss: 0.093| r_loss: 0.327| p_loss: 0.468| v_loss: 0.061| per_loss: 1.080 | a_loss: 0.528
Train: Epoch [167/3000], Step [60/158]| g_loss: 1.297| d_loss: 0.570| gp_loss: 0.039| r_loss: 0.319| p_loss: 0.455| v_loss: 0.059| per_loss: 1.120 | a_loss: 0.579
Train: Epoch [167/3000], Step [90/158]| g_loss: 1.329| d_loss: 0.527| gp_loss: 0.038| r_loss: 0.328| p_loss: 0.460| v_loss: 0.062| per_loss: 1.101 | a_loss: 0.599
Train: Epoch [167/3000], Step [120/158]| g_loss: 1.349| d_loss: 0.476| gp_loss: 0.042| r_loss: 0.310| p_loss: 0.462| v_loss: 0.059| per_loss: 1.131 | a_loss: 0.635
Train: Epoch [167/3000], Step [150/158]| g_loss: 1.272| d_loss: 0.620| gp_loss: 0.042| r_loss: 0.307| p_loss: 0.456| v_loss: 0.059| per_loss: 1.097 | a_loss: 0.569
Train: Epoch [168/3000], Step [30/158]| g_loss: 1.263| d_loss: 0.724| gp_loss: 0.174| r_loss: 0.321| p_loss: 0.460| v_loss: 0.060| per_loss: 1.078 | a_loss: 0.544
Train: Epoch [168/3000], Step [60/158]| g_loss: 1.285| d_loss: 0.522| gp_loss: 0.038| r_loss: 0.320| p_loss: 0.454| v_loss: 0.061| per_loss: 1.072 | a_loss: 0.569
Train: Epoch [168/3000], Step [90/158]| g_loss: 1.261| d_loss: 0.611| gp_loss: 0.041| r_loss: 0.328| p_loss: 0.454| v_loss: 0.063| per_loss: 1.026 | a_loss: 0.541
Train: Epoch [168/3000], Step [120/158]| g_loss: 1.282| d_loss: 0.509| gp_loss: 0.040| r_loss: 0.299| p_loss: 0.442| v_loss: 0.058| per_loss: 1.063 | a_loss: 0.598
Train: Epoch [168/3000], Step [150/158]| g_loss: 1.294| d_loss: 0.527| gp_loss: 0.040| r_loss: 0.317| p_loss: 0.447| v_loss: 0.058| per_loss: 1.133 | a_loss: 0.583
Train: Epoch [169/3000], Step [30/158]| g_loss: 1.265| d_loss: 0.572| gp_loss: 0.115| r_loss: 0.290| p_loss: 0.435| v_loss: 0.057| per_loss: 1.089 | a_loss: 0.592
Train: Epoch [169/3000], Step [60/158]| g_loss: 1.299| d_loss: 0.593| gp_loss: 0.040| r_loss: 0.328| p_loss: 0.469| v_loss: 0.055| per_loss: 1.117 | a_loss: 0.569
Train: Epoch [169/3000], Step [90/158]| g_loss: 1.285| d_loss: 0.543| gp_loss: 0.040| r_loss: 0.319| p_loss: 0.468| v_loss: 0.061| per_loss: 1.076 | a_loss: 0.564
Train: Epoch [169/3000], Step [120/158]| g_loss: 1.307| d_loss: 0.552| gp_loss: 0.041| r_loss: 0.335| p_loss: 0.454| v_loss: 0.058| per_loss: 1.095 | a_loss: 0.577
Train: Epoch [169/3000], Step [150/158]| g_loss: 1.245| d_loss: 0.595| gp_loss: 0.040| r_loss: 0.296| p_loss: 0.442| v_loss: 0.056| per_loss: 1.128 | a_loss: 0.559
Train: Epoch [170/3000], Step [30/158]| g_loss: 1.240| d_loss: 0.664| gp_loss: 0.114| r_loss: 0.299| p_loss: 0.446| v_loss: 0.057| per_loss: 1.079 | a_loss: 0.554
Train: Epoch [170/3000], Step [60/158]| g_loss: 1.319| d_loss: 0.536| gp_loss: 0.039| r_loss: 0.329| p_loss: 0.456| v_loss: 0.061| per_loss: 1.062 | a_loss: 0.596
Train: Epoch [170/3000], Step [90/158]| g_loss: 1.274| d_loss: 0.534| gp_loss: 0.036| r_loss: 0.318| p_loss: 0.450| v_loss: 0.059| per_loss: 1.031 | a_loss: 0.570
Train: Epoch [170/3000], Step [120/158]| g_loss: 1.329| d_loss: 0.479| gp_loss: 0.038| r_loss: 0.320| p_loss: 0.451| v_loss: 0.059| per_loss: 1.086 | a_loss: 0.616
Train: Epoch [170/3000], Step [150/158]| g_loss: 1.274| d_loss: 0.555| gp_loss: 0.043| r_loss: 0.311| p_loss: 0.449| v_loss: 0.059| per_loss: 1.016 | a_loss: 0.579
Train: Epoch [171/3000], Step [30/158]| g_loss: 1.369| d_loss: 0.480| gp_loss: 0.086| r_loss: 0.316| p_loss: 0.450| v_loss: 0.058| per_loss: 1.005 | a_loss: 0.670
Train: Epoch [171/3000], Step [60/158]| g_loss: 1.265| d_loss: 0.545| gp_loss: 0.040| r_loss: 0.309| p_loss: 0.444| v_loss: 0.058| per_loss: 1.047 | a_loss: 0.572
Train: Epoch [171/3000], Step [90/158]| g_loss: 1.204| d_loss: 0.655| gp_loss: 0.041| r_loss: 0.310| p_loss: 0.448| v_loss: 0.057| per_loss: 1.024 | a_loss: 0.512
Train: Epoch [171/3000], Step [120/158]| g_loss: 1.267| d_loss: 0.534| gp_loss: 0.041| r_loss: 0.324| p_loss: 0.445| v_loss: 0.056| per_loss: 0.983 | a_loss: 0.566
Train: Epoch [171/3000], Step [150/158]| g_loss: 1.291| d_loss: 0.529| gp_loss: 0.042| r_loss: 0.306| p_loss: 0.460| v_loss: 0.060| per_loss: 1.047 | a_loss: 0.590
Train: Epoch [172/3000], Step [30/158]| g_loss: 1.301| d_loss: 0.624| gp_loss: 0.127| r_loss: 0.312| p_loss: 0.464| v_loss: 0.059| per_loss: 1.089 | a_loss: 0.589
Train: Epoch [172/3000], Step [60/158]| g_loss: 1.229| d_loss: 0.584| gp_loss: 0.041| r_loss: 0.290| p_loss: 0.438| v_loss: 0.058| per_loss: 1.010 | a_loss: 0.561
Train: Epoch [172/3000], Step [90/158]| g_loss: 1.239| d_loss: 0.594| gp_loss: 0.039| r_loss: 0.291| p_loss: 0.430| v_loss: 0.056| per_loss: 1.044 | a_loss: 0.572
Train: Epoch [172/3000], Step [120/158]| g_loss: 1.303| d_loss: 0.547| gp_loss: 0.042| r_loss: 0.328| p_loss: 0.465| v_loss: 0.059| per_loss: 1.077 | a_loss: 0.576
Train: Epoch [172/3000], Step [150/158]| g_loss: 1.269| d_loss: 0.595| gp_loss: 0.042| r_loss: 0.320| p_loss: 0.457| v_loss: 0.059| per_loss: 1.044 | a_loss: 0.557
Train: Epoch [173/3000], Step [30/158]| g_loss: 1.284| d_loss: 0.659| gp_loss: 0.126| r_loss: 0.332| p_loss: 0.462| v_loss: 0.061| per_loss: 1.077 | a_loss: 0.551
Train: Epoch [173/3000], Step [60/158]| g_loss: 1.220| d_loss: 0.600| gp_loss: 0.039| r_loss: 0.305| p_loss: 0.442| v_loss: 0.061| per_loss: 0.961 | a_loss: 0.537
Train: Epoch [173/3000], Step [90/158]| g_loss: 1.284| d_loss: 0.497| gp_loss: 0.040| r_loss: 0.299| p_loss: 0.443| v_loss: 0.060| per_loss: 1.065 | a_loss: 0.598
Train: Epoch [173/3000], Step [120/158]| g_loss: 1.256| d_loss: 0.555| gp_loss: 0.043| r_loss: 0.310| p_loss: 0.431| v_loss: 0.057| per_loss: 1.123 | a_loss: 0.561
Train: Epoch [173/3000], Step [150/158]| g_loss: 1.313| d_loss: 0.511| gp_loss: 0.043| r_loss: 0.324| p_loss: 0.448| v_loss: 0.058| per_loss: 1.122 | a_loss: 0.595
Train: Epoch [174/3000], Step [30/158]| g_loss: 1.265| d_loss: 0.641| gp_loss: 0.120| r_loss: 0.310| p_loss: 0.460| v_loss: 0.059| per_loss: 1.077 | a_loss: 0.559
Train: Epoch [174/3000], Step [60/158]| g_loss: 1.252| d_loss: 0.541| gp_loss: 0.043| r_loss: 0.313| p_loss: 0.451| v_loss: 0.058| per_loss: 1.105 | a_loss: 0.544
Train: Epoch [174/3000], Step [90/158]| g_loss: 1.334| d_loss: 0.502| gp_loss: 0.041| r_loss: 0.321| p_loss: 0.448| v_loss: 0.059| per_loss: 1.056 | a_loss: 0.625
Train: Epoch [174/3000], Step [120/158]| g_loss: 1.317| d_loss: 0.530| gp_loss: 0.044| r_loss: 0.312| p_loss: 0.456| v_loss: 0.058| per_loss: 1.112 | a_loss: 0.607
Train: Epoch [174/3000], Step [150/158]| g_loss: 1.300| d_loss: 0.576| gp_loss: 0.045| r_loss: 0.310| p_loss: 0.469| v_loss: 0.061| per_loss: 1.170 | a_loss: 0.577
Train: Epoch [175/3000], Step [30/158]| g_loss: 1.293| d_loss: 0.696| gp_loss: 0.116| r_loss: 0.310| p_loss: 0.466| v_loss: 0.056| per_loss: 1.075 | a_loss: 0.586
Train: Epoch [175/3000], Step [60/158]| g_loss: 1.334| d_loss: 0.506| gp_loss: 0.042| r_loss: 0.333| p_loss: 0.479| v_loss: 0.061| per_loss: 1.160 | a_loss: 0.584
Train: Epoch [175/3000], Step [90/158]| g_loss: 1.322| d_loss: 0.543| gp_loss: 0.043| r_loss: 0.317| p_loss: 0.484| v_loss: 0.061| per_loss: 1.123 | a_loss: 0.590
Train: Epoch [175/3000], Step [120/158]| g_loss: 1.282| d_loss: 0.551| gp_loss: 0.045| r_loss: 0.319| p_loss: 0.460| v_loss: 0.058| per_loss: 1.110 | a_loss: 0.564
Train: Epoch [175/3000], Step [150/158]| g_loss: 1.294| d_loss: 0.543| gp_loss: 0.042| r_loss: 0.314| p_loss: 0.474| v_loss: 0.062| per_loss: 1.100 | a_loss: 0.571
Train: Epoch [176/3000], Step [30/158]| g_loss: 1.353| d_loss: 0.599| gp_loss: 0.106| r_loss: 0.326| p_loss: 0.490| v_loss: 0.061| per_loss: 1.172 | a_loss: 0.604
Train: Epoch [176/3000], Step [60/158]| g_loss: 1.284| d_loss: 0.588| gp_loss: 0.042| r_loss: 0.316| p_loss: 0.464| v_loss: 0.059| per_loss: 1.146 | a_loss: 0.562
Train: Epoch [176/3000], Step [90/158]| g_loss: 1.287| d_loss: 0.595| gp_loss: 0.039| r_loss: 0.313| p_loss: 0.451| v_loss: 0.062| per_loss: 1.129 | a_loss: 0.574
Train: Epoch [176/3000], Step [120/158]| g_loss: 1.344| d_loss: 0.449| gp_loss: 0.043| r_loss: 0.329| p_loss: 0.466| v_loss: 0.060| per_loss: 1.142 | a_loss: 0.608
Train: Epoch [176/3000], Step [150/158]| g_loss: 1.345| d_loss: 0.497| gp_loss: 0.041| r_loss: 0.300| p_loss: 0.464| v_loss: 0.061| per_loss: 1.077 | a_loss: 0.644
Train: Epoch [177/3000], Step [30/158]| g_loss: 1.294| d_loss: 0.693| gp_loss: 0.165| r_loss: 0.331| p_loss: 0.472| v_loss: 0.057| per_loss: 1.128 | a_loss: 0.557
Train: Epoch [177/3000], Step [60/158]| g_loss: 1.275| d_loss: 0.552| gp_loss: 0.039| r_loss: 0.308| p_loss: 0.449| v_loss: 0.059| per_loss: 1.086 | a_loss: 0.575
Train: Epoch [177/3000], Step [90/158]| g_loss: 1.205| d_loss: 0.609| gp_loss: 0.038| r_loss: 0.294| p_loss: 0.456| v_loss: 0.060| per_loss: 1.073 | a_loss: 0.515
Train: Epoch [177/3000], Step [120/158]| g_loss: 1.368| d_loss: 0.468| gp_loss: 0.036| r_loss: 0.315| p_loss: 0.449| v_loss: 0.059| per_loss: 1.188 | a_loss: 0.651
Train: Epoch [177/3000], Step [150/158]| g_loss: 1.263| d_loss: 0.598| gp_loss: 0.040| r_loss: 0.311| p_loss: 0.463| v_loss: 0.058| per_loss: 1.055 | a_loss: 0.557
Train: Epoch [178/3000], Step [30/158]| g_loss: 1.254| d_loss: 0.628| gp_loss: 0.083| r_loss: 0.309| p_loss: 0.457| v_loss: 0.062| per_loss: 1.115 | a_loss: 0.543
Train: Epoch [178/3000], Step [60/158]| g_loss: 1.272| d_loss: 0.589| gp_loss: 0.041| r_loss: 0.313| p_loss: 0.459| v_loss: 0.061| per_loss: 1.134 | a_loss: 0.556
Train: Epoch [178/3000], Step [90/158]| g_loss: 1.292| d_loss: 0.568| gp_loss: 0.037| r_loss: 0.334| p_loss: 0.444| v_loss: 0.058| per_loss: 1.058 | a_loss: 0.572
Train: Epoch [178/3000], Step [120/158]| g_loss: 1.225| d_loss: 0.574| gp_loss: 0.041| r_loss: 0.291| p_loss: 0.443| v_loss: 0.057| per_loss: 1.113 | a_loss: 0.545
Train: Epoch [178/3000], Step [150/158]| g_loss: 1.324| d_loss: 0.504| gp_loss: 0.037| r_loss: 0.308| p_loss: 0.458| v_loss: 0.062| per_loss: 1.091 | a_loss: 0.616
Train: Epoch [179/3000], Step [30/158]| g_loss: 1.286| d_loss: 0.560| gp_loss: 0.075| r_loss: 0.296| p_loss: 0.440| v_loss: 0.058| per_loss: 1.125 | a_loss: 0.599
Train: Epoch [179/3000], Step [60/158]| g_loss: 1.271| d_loss: 0.560| gp_loss: 0.041| r_loss: 0.319| p_loss: 0.445| v_loss: 0.059| per_loss: 1.066 | a_loss: 0.564
Train: Epoch [179/3000], Step [90/158]| g_loss: 1.308| d_loss: 0.577| gp_loss: 0.041| r_loss: 0.322| p_loss: 0.455| v_loss: 0.060| per_loss: 1.082 | a_loss: 0.590
Train: Epoch [179/3000], Step [120/158]| g_loss: 1.316| d_loss: 0.477| gp_loss: 0.038| r_loss: 0.294| p_loss: 0.454| v_loss: 0.062| per_loss: 1.056 | a_loss: 0.627
Train: Epoch [179/3000], Step [150/158]| g_loss: 1.331| d_loss: 0.581| gp_loss: 0.041| r_loss: 0.319| p_loss: 0.459| v_loss: 0.061| per_loss: 1.105 | a_loss: 0.612
Train: Epoch [180/3000], Step [30/158]| g_loss: 1.304| d_loss: 0.624| gp_loss: 0.111| r_loss: 0.312| p_loss: 0.473| v_loss: 0.062| per_loss: 1.135 | a_loss: 0.581
Train: Epoch [180/3000], Step [60/158]| g_loss: 1.249| d_loss: 0.582| gp_loss: 0.040| r_loss: 0.302| p_loss: 0.439| v_loss: 0.058| per_loss: 1.143 | a_loss: 0.555
Train: Epoch [180/3000], Step [90/158]| g_loss: 1.317| d_loss: 0.459| gp_loss: 0.038| r_loss: 0.312| p_loss: 0.442| v_loss: 0.062| per_loss: 1.032 | a_loss: 0.620
Train: Epoch [180/3000], Step [120/158]| g_loss: 1.264| d_loss: 0.537| gp_loss: 0.042| r_loss: 0.295| p_loss: 0.429| v_loss: 0.056| per_loss: 1.086 | a_loss: 0.589
Train: Epoch [180/3000], Step [150/158]| g_loss: 1.315| d_loss: 0.531| gp_loss: 0.041| r_loss: 0.311| p_loss: 0.447| v_loss: 0.058| per_loss: 1.113 | a_loss: 0.611
Train: Epoch [181/3000], Step [30/158]| g_loss: 1.325| d_loss: 0.603| gp_loss: 0.119| r_loss: 0.320| p_loss: 0.447| v_loss: 0.060| per_loss: 1.031 | a_loss: 0.618
Train: Epoch [181/3000], Step [60/158]| g_loss: 1.201| d_loss: 0.594| gp_loss: 0.044| r_loss: 0.297| p_loss: 0.438| v_loss: 0.056| per_loss: 1.104 | a_loss: 0.519
Train: Epoch [181/3000], Step [90/158]| g_loss: 1.309| d_loss: 0.534| gp_loss: 0.040| r_loss: 0.335| p_loss: 0.440| v_loss: 0.060| per_loss: 1.048 | a_loss: 0.589
Train: Epoch [181/3000], Step [120/158]| g_loss: 1.252| d_loss: 0.511| gp_loss: 0.041| r_loss: 0.299| p_loss: 0.439| v_loss: 0.057| per_loss: 1.010 | a_loss: 0.575
Train: Epoch [181/3000], Step [150/158]| g_loss: 1.241| d_loss: 0.595| gp_loss: 0.041| r_loss: 0.279| p_loss: 0.411| v_loss: 0.059| per_loss: 1.112 | a_loss: 0.586
Train: Epoch [182/3000], Step [30/158]| g_loss: 1.260| d_loss: 0.578| gp_loss: 0.110| r_loss: 0.307| p_loss: 0.439| v_loss: 0.060| per_loss: 1.056 | a_loss: 0.569
Train: Epoch [182/3000], Step [60/158]| g_loss: 1.226| d_loss: 0.598| gp_loss: 0.043| r_loss: 0.296| p_loss: 0.432| v_loss: 0.059| per_loss: 1.088 | a_loss: 0.546
Train: Epoch [182/3000], Step [90/158]| g_loss: 1.328| d_loss: 0.497| gp_loss: 0.042| r_loss: 0.321| p_loss: 0.435| v_loss: 0.057| per_loss: 1.104 | a_loss: 0.622
Train: Epoch [182/3000], Step [120/158]| g_loss: 1.283| d_loss: 0.515| gp_loss: 0.039| r_loss: 0.296| p_loss: 0.430| v_loss: 0.060| per_loss: 1.088 | a_loss: 0.603
Train: Epoch [182/3000], Step [150/158]| g_loss: 1.272| d_loss: 0.504| gp_loss: 0.042| r_loss: 0.292| p_loss: 0.437| v_loss: 0.058| per_loss: 1.081 | a_loss: 0.595
Train: Epoch [183/3000], Step [30/158]| g_loss: 1.247| d_loss: 0.628| gp_loss: 0.109| r_loss: 0.291| p_loss: 0.444| v_loss: 0.058| per_loss: 1.076 | a_loss: 0.569
Train: Epoch [183/3000], Step [60/158]| g_loss: 1.269| d_loss: 0.525| gp_loss: 0.044| r_loss: 0.308| p_loss: 0.438| v_loss: 0.059| per_loss: 1.067 | a_loss: 0.577
Train: Epoch [183/3000], Step [90/158]| g_loss: 1.297| d_loss: 0.513| gp_loss: 0.047| r_loss: 0.315| p_loss: 0.428| v_loss: 0.059| per_loss: 1.094 | a_loss: 0.599
Train: Epoch [183/3000], Step [120/158]| g_loss: 1.273| d_loss: 0.531| gp_loss: 0.043| r_loss: 0.291| p_loss: 0.417| v_loss: 0.056| per_loss: 1.029 | a_loss: 0.615
Train: Epoch [183/3000], Step [150/158]| g_loss: 1.265| d_loss: 0.563| gp_loss: 0.046| r_loss: 0.303| p_loss: 0.446| v_loss: 0.057| per_loss: 1.128 | a_loss: 0.569
Train: Epoch [184/3000], Step [30/158]| g_loss: 1.285| d_loss: 0.572| gp_loss: 0.090| r_loss: 0.308| p_loss: 0.427| v_loss: 0.059| per_loss: 1.135 | a_loss: 0.591
Train: Epoch [184/3000], Step [60/158]| g_loss: 1.273| d_loss: 0.516| gp_loss: 0.045| r_loss: 0.287| p_loss: 0.428| v_loss: 0.060| per_loss: 1.097 | a_loss: 0.602
Train: Epoch [184/3000], Step [90/158]| g_loss: 1.285| d_loss: 0.495| gp_loss: 0.044| r_loss: 0.317| p_loss: 0.422| v_loss: 0.058| per_loss: 1.096 | a_loss: 0.590
Train: Epoch [184/3000], Step [120/158]| g_loss: 1.239| d_loss: 0.560| gp_loss: 0.044| r_loss: 0.288| p_loss: 0.415| v_loss: 0.057| per_loss: 1.069 | a_loss: 0.580
Train: Epoch [184/3000], Step [150/158]| g_loss: 1.248| d_loss: 0.527| gp_loss: 0.048| r_loss: 0.290| p_loss: 0.426| v_loss: 0.057| per_loss: 1.064 | a_loss: 0.582
Train: Epoch [185/3000], Step [30/158]| g_loss: 1.275| d_loss: 0.609| gp_loss: 0.102| r_loss: 0.309| p_loss: 0.425| v_loss: 0.058| per_loss: 1.050 | a_loss: 0.591
Train: Epoch [185/3000], Step [60/158]| g_loss: 1.214| d_loss: 0.530| gp_loss: 0.046| r_loss: 0.284| p_loss: 0.391| v_loss: 0.058| per_loss: 1.030 | a_loss: 0.573
Train: Epoch [185/3000], Step [90/158]| g_loss: 1.311| d_loss: 0.484| gp_loss: 0.047| r_loss: 0.308| p_loss: 0.434| v_loss: 0.061| per_loss: 1.066 | a_loss: 0.619
Train: Epoch [185/3000], Step [120/158]| g_loss: 1.338| d_loss: 0.467| gp_loss: 0.043| r_loss: 0.294| p_loss: 0.425| v_loss: 0.060| per_loss: 1.040 | a_loss: 0.667
Train: Epoch [185/3000], Step [150/158]| g_loss: 1.216| d_loss: 0.581| gp_loss: 0.047| r_loss: 0.289| p_loss: 0.426| v_loss: 0.057| per_loss: 1.030 | a_loss: 0.553
Train: Epoch [186/3000], Step [30/158]| g_loss: 1.246| d_loss: 0.674| gp_loss: 0.081| r_loss: 0.313| p_loss: 0.435| v_loss: 0.060| per_loss: 1.006 | a_loss: 0.555
Train: Epoch [186/3000], Step [60/158]| g_loss: 1.254| d_loss: 0.536| gp_loss: 0.042| r_loss: 0.302| p_loss: 0.432| v_loss: 0.059| per_loss: 1.049 | a_loss: 0.572
Train: Epoch [186/3000], Step [90/158]| g_loss: 1.228| d_loss: 0.579| gp_loss: 0.048| r_loss: 0.305| p_loss: 0.422| v_loss: 0.057| per_loss: 1.055 | a_loss: 0.549
Train: Epoch [186/3000], Step [120/158]| g_loss: 1.243| d_loss: 0.461| gp_loss: 0.047| r_loss: 0.276| p_loss: 0.399| v_loss: 0.056| per_loss: 1.101 | a_loss: 0.602
Train: Epoch [186/3000], Step [150/158]| g_loss: 1.311| d_loss: 0.488| gp_loss: 0.047| r_loss: 0.311| p_loss: 0.421| v_loss: 0.054| per_loss: 0.984 | a_loss: 0.637
Train: Epoch [187/3000], Step [30/158]| g_loss: 1.260| d_loss: 0.590| gp_loss: 0.101| r_loss: 0.303| p_loss: 0.417| v_loss: 0.059| per_loss: 1.060 | a_loss: 0.584
Train: Epoch [187/3000], Step [60/158]| g_loss: 1.273| d_loss: 0.545| gp_loss: 0.043| r_loss: 0.301| p_loss: 0.418| v_loss: 0.057| per_loss: 1.048 | a_loss: 0.601
Train: Epoch [187/3000], Step [90/158]| g_loss: 1.349| d_loss: 0.446| gp_loss: 0.043| r_loss: 0.301| p_loss: 0.435| v_loss: 0.060| per_loss: 1.016 | a_loss: 0.669
Train: Epoch [187/3000], Step [120/158]| g_loss: 1.253| d_loss: 0.563| gp_loss: 0.047| r_loss: 0.289| p_loss: 0.419| v_loss: 0.058| per_loss: 1.068 | a_loss: 0.589
Train: Epoch [187/3000], Step [150/158]| g_loss: 1.244| d_loss: 0.582| gp_loss: 0.048| r_loss: 0.286| p_loss: 0.433| v_loss: 0.058| per_loss: 1.059 | a_loss: 0.579
Train: Epoch [188/3000], Step [30/158]| g_loss: 1.242| d_loss: 0.605| gp_loss: 0.102| r_loss: 0.299| p_loss: 0.418| v_loss: 0.056| per_loss: 1.049 | a_loss: 0.573
Train: Epoch [188/3000], Step [60/158]| g_loss: 1.230| d_loss: 0.568| gp_loss: 0.045| r_loss: 0.287| p_loss: 0.411| v_loss: 0.057| per_loss: 1.059 | a_loss: 0.575
Train: Epoch [188/3000], Step [90/158]| g_loss: 1.303| d_loss: 0.456| gp_loss: 0.042| r_loss: 0.293| p_loss: 0.428| v_loss: 0.057| per_loss: 1.097 | a_loss: 0.629
Train: Epoch [188/3000], Step [120/158]| g_loss: 1.281| d_loss: 0.538| gp_loss: 0.046| r_loss: 0.316| p_loss: 0.425| v_loss: 0.057| per_loss: 1.105 | a_loss: 0.585
Train: Epoch [188/3000], Step [150/158]| g_loss: 1.219| d_loss: 0.593| gp_loss: 0.047| r_loss: 0.281| p_loss: 0.425| v_loss: 0.056| per_loss: 1.056 | a_loss: 0.565
Train: Epoch [189/3000], Step [30/158]| g_loss: 1.310| d_loss: 0.555| gp_loss: 0.100| r_loss: 0.334| p_loss: 0.441| v_loss: 0.060| per_loss: 1.054 | a_loss: 0.590
Train: Epoch [189/3000], Step [60/158]| g_loss: 1.263| d_loss: 0.541| gp_loss: 0.047| r_loss: 0.302| p_loss: 0.437| v_loss: 0.056| per_loss: 1.117 | a_loss: 0.575
Train: Epoch [189/3000], Step [90/158]| g_loss: 1.239| d_loss: 0.598| gp_loss: 0.048| r_loss: 0.301| p_loss: 0.422| v_loss: 0.057| per_loss: 1.067 | a_loss: 0.563
Train: Epoch [189/3000], Step [120/158]| g_loss: 1.240| d_loss: 0.549| gp_loss: 0.048| r_loss: 0.289| p_loss: 0.424| v_loss: 0.056| per_loss: 1.076 | a_loss: 0.575
Train: Epoch [189/3000], Step [150/158]| g_loss: 1.270| d_loss: 0.472| gp_loss: 0.049| r_loss: 0.305| p_loss: 0.426| v_loss: 0.057| per_loss: 1.064 | a_loss: 0.588
Train: Epoch [190/3000], Step [30/158]| g_loss: 1.320| d_loss: 0.493| gp_loss: 0.091| r_loss: 0.303| p_loss: 0.431| v_loss: 0.059| per_loss: 1.113 | a_loss: 0.632
Train: Epoch [190/3000], Step [60/158]| g_loss: 1.254| d_loss: 0.565| gp_loss: 0.052| r_loss: 0.301| p_loss: 0.428| v_loss: 0.055| per_loss: 1.111 | a_loss: 0.573
Train: Epoch [190/3000], Step [90/158]| g_loss: 1.222| d_loss: 0.530| gp_loss: 0.049| r_loss: 0.285| p_loss: 0.418| v_loss: 0.057| per_loss: 1.096 | a_loss: 0.560
Train: Epoch [190/3000], Step [120/158]| g_loss: 1.299| d_loss: 0.598| gp_loss: 0.050| r_loss: 0.326| p_loss: 0.450| v_loss: 0.057| per_loss: 1.108 | a_loss: 0.581
Train: Epoch [190/3000], Step [150/158]| g_loss: 1.271| d_loss: 0.493| gp_loss: 0.047| r_loss: 0.293| p_loss: 0.433| v_loss: 0.055| per_loss: 1.100 | a_loss: 0.597
Train: Epoch [191/3000], Step [30/158]| g_loss: 1.246| d_loss: 0.636| gp_loss: 0.161| r_loss: 0.281| p_loss: 0.418| v_loss: 0.056| per_loss: 1.047 | a_loss: 0.595
Train: Epoch [191/3000], Step [60/158]| g_loss: 1.188| d_loss: 0.626| gp_loss: 0.046| r_loss: 0.289| p_loss: 0.425| v_loss: 0.054| per_loss: 1.066 | a_loss: 0.527
Train: Epoch [191/3000], Step [90/158]| g_loss: 1.256| d_loss: 0.579| gp_loss: 0.046| r_loss: 0.294| p_loss: 0.430| v_loss: 0.058| per_loss: 1.148 | a_loss: 0.574
Train: Epoch [191/3000], Step [120/158]| g_loss: 1.336| d_loss: 0.461| gp_loss: 0.044| r_loss: 0.317| p_loss: 0.442| v_loss: 0.059| per_loss: 1.091 | a_loss: 0.630
Train: Epoch [191/3000], Step [150/158]| g_loss: 1.282| d_loss: 0.543| gp_loss: 0.047| r_loss: 0.310| p_loss: 0.452| v_loss: 0.057| per_loss: 1.146 | a_loss: 0.574
Train: Epoch [192/3000], Step [30/158]| g_loss: 1.277| d_loss: 0.644| gp_loss: 0.085| r_loss: 0.295| p_loss: 0.443| v_loss: 0.056| per_loss: 1.190 | a_loss: 0.585
Train: Epoch [192/3000], Step [60/158]| g_loss: 1.254| d_loss: 0.564| gp_loss: 0.044| r_loss: 0.301| p_loss: 0.445| v_loss: 0.059| per_loss: 1.083 | a_loss: 0.564
Train: Epoch [192/3000], Step [90/158]| g_loss: 1.278| d_loss: 0.482| gp_loss: 0.045| r_loss: 0.290| p_loss: 0.430| v_loss: 0.057| per_loss: 1.117 | a_loss: 0.604
Train: Epoch [192/3000], Step [120/158]| g_loss: 1.297| d_loss: 0.482| gp_loss: 0.046| r_loss: 0.298| p_loss: 0.434| v_loss: 0.058| per_loss: 1.155 | a_loss: 0.608
Train: Epoch [192/3000], Step [150/158]| g_loss: 1.253| d_loss: 0.565| gp_loss: 0.049| r_loss: 0.305| p_loss: 0.438| v_loss: 0.057| per_loss: 1.021 | a_loss: 0.571
Train: Epoch [193/3000], Step [30/158]| g_loss: 1.284| d_loss: 0.687| gp_loss: 0.155| r_loss: 0.316| p_loss: 0.433| v_loss: 0.055| per_loss: 1.148 | a_loss: 0.582
Train: Epoch [193/3000], Step [60/158]| g_loss: 1.264| d_loss: 0.550| gp_loss: 0.043| r_loss: 0.292| p_loss: 0.439| v_loss: 0.058| per_loss: 1.118 | a_loss: 0.584
Train: Epoch [193/3000], Step [90/158]| g_loss: 1.255| d_loss: 0.547| gp_loss: 0.042| r_loss: 0.297| p_loss: 0.439| v_loss: 0.057| per_loss: 1.019 | a_loss: 0.580
Train: Epoch [193/3000], Step [120/158]| g_loss: 1.274| d_loss: 0.493| gp_loss: 0.043| r_loss: 0.295| p_loss: 0.429| v_loss: 0.057| per_loss: 1.023 | a_loss: 0.606
Train: Epoch [193/3000], Step [150/158]| g_loss: 1.259| d_loss: 0.535| gp_loss: 0.047| r_loss: 0.313| p_loss: 0.440| v_loss: 0.057| per_loss: 0.990 | a_loss: 0.570
Train: Epoch [194/3000], Step [30/158]| g_loss: 1.264| d_loss: 0.652| gp_loss: 0.153| r_loss: 0.307| p_loss: 0.419| v_loss: 0.056| per_loss: 0.991 | a_loss: 0.592
Train: Epoch [194/3000], Step [60/158]| g_loss: 1.253| d_loss: 0.543| gp_loss: 0.041| r_loss: 0.283| p_loss: 0.424| v_loss: 0.057| per_loss: 1.097 | a_loss: 0.591
Train: Epoch [194/3000], Step [90/158]| g_loss: 1.263| d_loss: 0.606| gp_loss: 0.041| r_loss: 0.305| p_loss: 0.443| v_loss: 0.056| per_loss: 1.034 | a_loss: 0.577
Train: Epoch [194/3000], Step [120/158]| g_loss: 1.239| d_loss: 0.499| gp_loss: 0.046| r_loss: 0.284| p_loss: 0.448| v_loss: 0.057| per_loss: 1.063 | a_loss: 0.567
Train: Epoch [194/3000], Step [150/158]| g_loss: 1.267| d_loss: 0.501| gp_loss: 0.043| r_loss: 0.304| p_loss: 0.427| v_loss: 0.054| per_loss: 1.015 | a_loss: 0.593
Train: Epoch [195/3000], Step [30/158]| g_loss: 1.279| d_loss: 0.600| gp_loss: 0.114| r_loss: 0.317| p_loss: 0.437| v_loss: 0.056| per_loss: 1.009 | a_loss: 0.586
Train: Epoch [195/3000], Step [60/158]| g_loss: 1.231| d_loss: 0.546| gp_loss: 0.044| r_loss: 0.288| p_loss: 0.418| v_loss: 0.056| per_loss: 1.036 | a_loss: 0.575
Train: Epoch [195/3000], Step [90/158]| g_loss: 1.329| d_loss: 0.427| gp_loss: 0.041| r_loss: 0.310| p_loss: 0.436| v_loss: 0.059| per_loss: 0.981 | a_loss: 0.644
Train: Epoch [195/3000], Step [120/158]| g_loss: 1.203| d_loss: 0.603| gp_loss: 0.050| r_loss: 0.297| p_loss: 0.434| v_loss: 0.058| per_loss: 1.008 | a_loss: 0.531
Train: Epoch [195/3000], Step [150/158]| g_loss: 1.239| d_loss: 0.574| gp_loss: 0.047| r_loss: 0.294| p_loss: 0.419| v_loss: 0.057| per_loss: 1.053 | a_loss: 0.573
Train: Epoch [196/3000], Step [30/158]| g_loss: 1.235| d_loss: 0.591| gp_loss: 0.117| r_loss: 0.289| p_loss: 0.420| v_loss: 0.058| per_loss: 0.956 | a_loss: 0.583
Train: Epoch [196/3000], Step [60/158]| g_loss: 1.279| d_loss: 0.463| gp_loss: 0.046| r_loss: 0.293| p_loss: 0.415| v_loss: 0.055| per_loss: 0.993 | a_loss: 0.623
Train: Epoch [196/3000], Step [90/158]| g_loss: 1.259| d_loss: 0.516| gp_loss: 0.048| r_loss: 0.304| p_loss: 0.418| v_loss: 0.056| per_loss: 1.013 | a_loss: 0.588
Train: Epoch [196/3000], Step [120/158]| g_loss: 1.249| d_loss: 0.499| gp_loss: 0.048| r_loss: 0.294| p_loss: 0.421| v_loss: 0.058| per_loss: 0.951 | a_loss: 0.592
Train: Epoch [196/3000], Step [150/158]| g_loss: 1.211| d_loss: 0.616| gp_loss: 0.051| r_loss: 0.285| p_loss: 0.427| v_loss: 0.056| per_loss: 1.066 | a_loss: 0.550
Train: Epoch [197/3000], Step [30/158]| g_loss: 1.252| d_loss: 0.656| gp_loss: 0.140| r_loss: 0.297| p_loss: 0.430| v_loss: 0.054| per_loss: 0.975 | a_loss: 0.589
Train: Epoch [197/3000], Step [60/158]| g_loss: 1.233| d_loss: 0.514| gp_loss: 0.049| r_loss: 0.293| p_loss: 0.423| v_loss: 0.055| per_loss: 0.985 | a_loss: 0.575
Train: Epoch [197/3000], Step [90/158]| g_loss: 1.220| d_loss: 0.553| gp_loss: 0.049| r_loss: 0.293| p_loss: 0.402| v_loss: 0.056| per_loss: 0.977 | a_loss: 0.573
Train: Epoch [197/3000], Step [120/158]| g_loss: 1.217| d_loss: 0.537| gp_loss: 0.049| r_loss: 0.277| p_loss: 0.422| v_loss: 0.057| per_loss: 0.930 | a_loss: 0.578
Train: Epoch [197/3000], Step [150/158]| g_loss: 1.246| d_loss: 0.529| gp_loss: 0.047| r_loss: 0.298| p_loss: 0.419| v_loss: 0.058| per_loss: 0.902 | a_loss: 0.590
Train: Epoch [198/3000], Step [30/158]| g_loss: 1.259| d_loss: 0.519| gp_loss: 0.085| r_loss: 0.301| p_loss: 0.418| v_loss: 0.057| per_loss: 0.910 | a_loss: 0.601
Train: Epoch [198/3000], Step [60/158]| g_loss: 1.226| d_loss: 0.530| gp_loss: 0.049| r_loss: 0.289| p_loss: 0.416| v_loss: 0.057| per_loss: 0.937 | a_loss: 0.578
Train: Epoch [198/3000], Step [90/158]| g_loss: 1.213| d_loss: 0.606| gp_loss: 0.047| r_loss: 0.286| p_loss: 0.420| v_loss: 0.056| per_loss: 0.881 | a_loss: 0.574
Train: Epoch [198/3000], Step [120/158]| g_loss: 1.207| d_loss: 0.560| gp_loss: 0.051| r_loss: 0.292| p_loss: 0.426| v_loss: 0.055| per_loss: 0.936 | a_loss: 0.554
Train: Epoch [198/3000], Step [150/158]| g_loss: 1.264| d_loss: 0.481| gp_loss: 0.049| r_loss: 0.304| p_loss: 0.423| v_loss: 0.056| per_loss: 0.939 | a_loss: 0.599
Train: Epoch [199/3000], Step [30/158]| g_loss: 1.228| d_loss: 0.673| gp_loss: 0.126| r_loss: 0.306| p_loss: 0.435| v_loss: 0.056| per_loss: 0.905 | a_loss: 0.558
Train: Epoch [199/3000], Step [60/158]| g_loss: 1.203| d_loss: 0.553| gp_loss: 0.047| r_loss: 0.274| p_loss: 0.419| v_loss: 0.055| per_loss: 0.937 | a_loss: 0.570
Train: Epoch [199/3000], Step [90/158]| g_loss: 1.233| d_loss: 0.529| gp_loss: 0.047| r_loss: 0.299| p_loss: 0.433| v_loss: 0.054| per_loss: 0.937 | a_loss: 0.570
Train: Epoch [199/3000], Step [120/158]| g_loss: 1.228| d_loss: 0.516| gp_loss: 0.045| r_loss: 0.264| p_loss: 0.416| v_loss: 0.057| per_loss: 0.954 | a_loss: 0.604
Train: Epoch [199/3000], Step [150/158]| g_loss: 1.285| d_loss: 0.477| gp_loss: 0.048| r_loss: 0.309| p_loss: 0.423| v_loss: 0.059| per_loss: 0.903 | a_loss: 0.615
Train: Epoch [200/3000], Step [30/158]| g_loss: 1.198| d_loss: 0.674| gp_loss: 0.161| r_loss: 0.278| p_loss: 0.422| v_loss: 0.059| per_loss: 0.884 | a_loss: 0.561
Train: Epoch [200/3000], Step [60/158]| g_loss: 1.248| d_loss: 0.531| gp_loss: 0.046| r_loss: 0.295| p_loss: 0.420| v_loss: 0.059| per_loss: 0.882 | a_loss: 0.596
Train: Epoch [200/3000], Step [90/158]| g_loss: 1.278| d_loss: 0.491| gp_loss: 0.045| r_loss: 0.296| p_loss: 0.416| v_loss: 0.060| per_loss: 0.965 | a_loss: 0.618
Train: Epoch [200/3000], Step [120/158]| g_loss: 1.237| d_loss: 0.541| gp_loss: 0.048| r_loss: 0.282| p_loss: 0.422| v_loss: 0.058| per_loss: 0.927 | a_loss: 0.594
Train: Epoch [200/3000], Step [150/158]| g_loss: 1.197| d_loss: 0.591| gp_loss: 0.046| r_loss: 0.283| p_loss: 0.417| v_loss: 0.055| per_loss: 0.923 | a_loss: 0.558
Test: Epoch [200/3000]| g_loss: 1.179| r_loss: 0.800| p_loss: 0.502| v_loss: 0.043
Train: Epoch [201/3000], Step [30/158]| g_loss: 1.200| d_loss: 0.540| gp_loss: 0.043| r_loss: 0.268| p_loss: 0.407| v_loss: 0.054| per_loss: 0.852 | a_loss: 0.590
Train: Epoch [201/3000], Step [60/158]| g_loss: 1.234| d_loss: 0.550| gp_loss: 0.048| r_loss: 0.302| p_loss: 0.429| v_loss: 0.056| per_loss: 0.943 | a_loss: 0.566
Train: Epoch [201/3000], Step [90/158]| g_loss: 1.270| d_loss: 0.458| gp_loss: 0.044| r_loss: 0.291| p_loss: 0.415| v_loss: 0.056| per_loss: 0.924 | a_loss: 0.624
Train: Epoch [201/3000], Step [120/158]| g_loss: 1.235| d_loss: 0.597| gp_loss: 0.046| r_loss: 0.287| p_loss: 0.430| v_loss: 0.056| per_loss: 0.973 | a_loss: 0.580
Train: Epoch [201/3000], Step [150/158]| g_loss: 1.222| d_loss: 0.607| gp_loss: 0.045| r_loss: 0.293| p_loss: 0.426| v_loss: 0.054| per_loss: 0.844 | a_loss: 0.578
Train: Epoch [202/3000], Step [30/158]| g_loss: 1.213| d_loss: 0.678| gp_loss: 0.129| r_loss: 0.297| p_loss: 0.430| v_loss: 0.055| per_loss: 0.902 | a_loss: 0.555
Train: Epoch [202/3000], Step [60/158]| g_loss: 1.249| d_loss: 0.483| gp_loss: 0.044| r_loss: 0.281| p_loss: 0.419| v_loss: 0.057| per_loss: 0.927 | a_loss: 0.609
Train: Epoch [202/3000], Step [90/158]| g_loss: 1.267| d_loss: 0.531| gp_loss: 0.045| r_loss: 0.269| p_loss: 0.439| v_loss: 0.058| per_loss: 0.899 | a_loss: 0.629
Train: Epoch [202/3000], Step [120/158]| g_loss: 1.207| d_loss: 0.596| gp_loss: 0.049| r_loss: 0.315| p_loss: 0.446| v_loss: 0.054| per_loss: 0.946 | a_loss: 0.519
Train: Epoch [202/3000], Step [150/158]| g_loss: 1.204| d_loss: 0.574| gp_loss: 0.047| r_loss: 0.291| p_loss: 0.424| v_loss: 0.058| per_loss: 0.872 | a_loss: 0.556
Train: Epoch [203/3000], Step [30/158]| g_loss: 1.204| d_loss: 0.626| gp_loss: 0.135| r_loss: 0.274| p_loss: 0.403| v_loss: 0.055| per_loss: 0.889 | a_loss: 0.585
Train: Epoch [203/3000], Step [60/158]| g_loss: 1.184| d_loss: 0.569| gp_loss: 0.044| r_loss: 0.262| p_loss: 0.389| v_loss: 0.054| per_loss: 0.885 | a_loss: 0.585
Train: Epoch [203/3000], Step [90/158]| g_loss: 1.235| d_loss: 0.493| gp_loss: 0.046| r_loss: 0.276| p_loss: 0.419| v_loss: 0.058| per_loss: 0.913 | a_loss: 0.599
Train: Epoch [203/3000], Step [120/158]| g_loss: 1.270| d_loss: 0.476| gp_loss: 0.047| r_loss: 0.300| p_loss: 0.429| v_loss: 0.058| per_loss: 0.902 | a_loss: 0.608
Train: Epoch [203/3000], Step [150/158]| g_loss: 1.240| d_loss: 0.650| gp_loss: 0.046| r_loss: 0.328| p_loss: 0.435| v_loss: 0.057| per_loss: 0.978 | a_loss: 0.541
Train: Epoch [204/3000], Step [30/158]| g_loss: 1.231| d_loss: 0.614| gp_loss: 0.114| r_loss: 0.309| p_loss: 0.418| v_loss: 0.056| per_loss: 0.913 | a_loss: 0.566
Train: Epoch [204/3000], Step [60/158]| g_loss: 1.206| d_loss: 0.502| gp_loss: 0.046| r_loss: 0.257| p_loss: 0.403| v_loss: 0.056| per_loss: 0.911 | a_loss: 0.600
Train: Epoch [204/3000], Step [90/158]| g_loss: 1.215| d_loss: 0.526| gp_loss: 0.049| r_loss: 0.278| p_loss: 0.405| v_loss: 0.054| per_loss: 0.904 | a_loss: 0.589
Train: Epoch [204/3000], Step [120/158]| g_loss: 1.197| d_loss: 0.550| gp_loss: 0.047| r_loss: 0.273| p_loss: 0.403| v_loss: 0.055| per_loss: 0.942 | a_loss: 0.573
Train: Epoch [204/3000], Step [150/158]| g_loss: 1.242| d_loss: 0.556| gp_loss: 0.045| r_loss: 0.293| p_loss: 0.413| v_loss: 0.059| per_loss: 0.871 | a_loss: 0.597
Train: Epoch [205/3000], Step [30/158]| g_loss: 1.221| d_loss: 0.585| gp_loss: 0.107| r_loss: 0.283| p_loss: 0.414| v_loss: 0.057| per_loss: 0.944 | a_loss: 0.579
Train: Epoch [205/3000], Step [60/158]| g_loss: 1.213| d_loss: 0.568| gp_loss: 0.047| r_loss: 0.300| p_loss: 0.415| v_loss: 0.058| per_loss: 0.865 | a_loss: 0.561
Train: Epoch [205/3000], Step [90/158]| g_loss: 1.248| d_loss: 0.559| gp_loss: 0.048| r_loss: 0.303| p_loss: 0.409| v_loss: 0.059| per_loss: 0.909 | a_loss: 0.591
Train: Epoch [205/3000], Step [120/158]| g_loss: 1.232| d_loss: 0.518| gp_loss: 0.044| r_loss: 0.282| p_loss: 0.411| v_loss: 0.059| per_loss: 0.882 | a_loss: 0.598
Train: Epoch [205/3000], Step [150/158]| g_loss: 1.269| d_loss: 0.510| gp_loss: 0.044| r_loss: 0.292| p_loss: 0.410| v_loss: 0.058| per_loss: 0.877 | a_loss: 0.626
Train: Epoch [206/3000], Step [30/158]| g_loss: 1.186| d_loss: 0.694| gp_loss: 0.201| r_loss: 0.268| p_loss: 0.394| v_loss: 0.054| per_loss: 0.896 | a_loss: 0.578
Train: Epoch [206/3000], Step [60/158]| g_loss: 1.180| d_loss: 0.589| gp_loss: 0.043| r_loss: 0.282| p_loss: 0.412| v_loss: 0.058| per_loss: 0.882 | a_loss: 0.546
Train: Epoch [206/3000], Step [90/158]| g_loss: 1.228| d_loss: 0.528| gp_loss: 0.042| r_loss: 0.279| p_loss: 0.421| v_loss: 0.057| per_loss: 0.928 | a_loss: 0.589
Train: Epoch [206/3000], Step [120/158]| g_loss: 1.237| d_loss: 0.515| gp_loss: 0.044| r_loss: 0.286| p_loss: 0.411| v_loss: 0.056| per_loss: 0.934 | a_loss: 0.596
Train: Epoch [206/3000], Step [150/158]| g_loss: 1.219| d_loss: 0.508| gp_loss: 0.046| r_loss: 0.301| p_loss: 0.423| v_loss: 0.056| per_loss: 0.869 | a_loss: 0.564
Train: Epoch [207/3000], Step [30/158]| g_loss: 1.187| d_loss: 0.710| gp_loss: 0.097| r_loss: 0.292| p_loss: 0.411| v_loss: 0.055| per_loss: 0.893 | a_loss: 0.544
Train: Epoch [207/3000], Step [60/158]| g_loss: 1.195| d_loss: 0.565| gp_loss: 0.046| r_loss: 0.278| p_loss: 0.407| v_loss: 0.056| per_loss: 0.898 | a_loss: 0.568
Train: Epoch [207/3000], Step [90/158]| g_loss: 1.228| d_loss: 0.495| gp_loss: 0.044| r_loss: 0.278| p_loss: 0.406| v_loss: 0.057| per_loss: 0.921 | a_loss: 0.598
Train: Epoch [207/3000], Step [120/158]| g_loss: 1.226| d_loss: 0.498| gp_loss: 0.048| r_loss: 0.287| p_loss: 0.410| v_loss: 0.056| per_loss: 0.865 | a_loss: 0.592
Train: Epoch [207/3000], Step [150/158]| g_loss: 1.232| d_loss: 0.569| gp_loss: 0.046| r_loss: 0.284| p_loss: 0.433| v_loss: 0.058| per_loss: 0.897 | a_loss: 0.583
Train: Epoch [208/3000], Step [30/158]| g_loss: 1.140| d_loss: 0.668| gp_loss: 0.122| r_loss: 0.267| p_loss: 0.405| v_loss: 0.056| per_loss: 0.876 | a_loss: 0.527
Train: Epoch [208/3000], Step [60/158]| g_loss: 1.220| d_loss: 0.490| gp_loss: 0.044| r_loss: 0.272| p_loss: 0.417| v_loss: 0.058| per_loss: 0.892 | a_loss: 0.592
Train: Epoch [208/3000], Step [90/158]| g_loss: 1.192| d_loss: 0.709| gp_loss: 0.047| r_loss: 0.298| p_loss: 0.436| v_loss: 0.059| per_loss: 0.877 | a_loss: 0.529
Train: Epoch [208/3000], Step [120/158]| g_loss: 1.211| d_loss: 0.439| gp_loss: 0.039| r_loss: 0.263| p_loss: 0.420| v_loss: 0.058| per_loss: 0.859 | a_loss: 0.594
Train: Epoch [208/3000], Step [150/158]| g_loss: 1.284| d_loss: 0.516| gp_loss: 0.042| r_loss: 0.320| p_loss: 0.424| v_loss: 0.054| per_loss: 0.886 | a_loss: 0.609
Train: Epoch [209/3000], Step [30/158]| g_loss: 1.189| d_loss: 0.680| gp_loss: 0.147| r_loss: 0.287| p_loss: 0.419| v_loss: 0.057| per_loss: 0.861 | a_loss: 0.549
Train: Epoch [209/3000], Step [60/158]| g_loss: 1.162| d_loss: 0.621| gp_loss: 0.046| r_loss: 0.267| p_loss: 0.421| v_loss: 0.057| per_loss: 0.898 | a_loss: 0.537
Train: Epoch [209/3000], Step [90/158]| g_loss: 1.173| d_loss: 0.562| gp_loss: 0.045| r_loss: 0.270| p_loss: 0.402| v_loss: 0.055| per_loss: 0.942 | a_loss: 0.552
Train: Epoch [209/3000], Step [120/158]| g_loss: 1.216| d_loss: 0.513| gp_loss: 0.046| r_loss: 0.291| p_loss: 0.411| v_loss: 0.058| per_loss: 0.892 | a_loss: 0.573
Train: Epoch [209/3000], Step [150/158]| g_loss: 1.254| d_loss: 0.523| gp_loss: 0.047| r_loss: 0.295| p_loss: 0.443| v_loss: 0.061| per_loss: 0.890 | a_loss: 0.588
Train: Epoch [210/3000], Step [30/158]| g_loss: 1.268| d_loss: 0.593| gp_loss: 0.114| r_loss: 0.288| p_loss: 0.409| v_loss: 0.057| per_loss: 0.887 | a_loss: 0.630
Train: Epoch [210/3000], Step [60/158]| g_loss: 1.202| d_loss: 0.604| gp_loss: 0.040| r_loss: 0.309| p_loss: 0.408| v_loss: 0.056| per_loss: 0.916 | a_loss: 0.541
Train: Epoch [210/3000], Step [90/158]| g_loss: 1.217| d_loss: 0.488| gp_loss: 0.043| r_loss: 0.272| p_loss: 0.436| v_loss: 0.061| per_loss: 0.881 | a_loss: 0.578
Train: Epoch [210/3000], Step [120/158]| g_loss: 1.190| d_loss: 0.599| gp_loss: 0.048| r_loss: 0.278| p_loss: 0.425| v_loss: 0.058| per_loss: 0.961 | a_loss: 0.546
Train: Epoch [210/3000], Step [150/158]| g_loss: 1.179| d_loss: 0.632| gp_loss: 0.046| r_loss: 0.276| p_loss: 0.426| v_loss: 0.057| per_loss: 0.947 | a_loss: 0.539
Train: Epoch [211/3000], Step [30/158]| g_loss: 1.254| d_loss: 0.599| gp_loss: 0.124| r_loss: 0.290| p_loss: 0.427| v_loss: 0.057| per_loss: 0.957 | a_loss: 0.597
Train: Epoch [211/3000], Step [60/158]| g_loss: 1.297| d_loss: 0.457| gp_loss: 0.039| r_loss: 0.308| p_loss: 0.422| v_loss: 0.056| per_loss: 0.955 | a_loss: 0.626
Train: Epoch [211/3000], Step [90/158]| g_loss: 1.186| d_loss: 0.573| gp_loss: 0.043| r_loss: 0.274| p_loss: 0.418| v_loss: 0.055| per_loss: 0.862 | a_loss: 0.562
Train: Epoch [211/3000], Step [120/158]| g_loss: 1.209| d_loss: 0.545| gp_loss: 0.042| r_loss: 0.268| p_loss: 0.413| v_loss: 0.058| per_loss: 0.891 | a_loss: 0.587
Train: Epoch [211/3000], Step [150/158]| g_loss: 1.177| d_loss: 0.607| gp_loss: 0.044| r_loss: 0.278| p_loss: 0.407| v_loss: 0.056| per_loss: 0.929 | a_loss: 0.547
Train: Epoch [212/3000], Step [30/158]| g_loss: 1.186| d_loss: 0.617| gp_loss: 0.135| r_loss: 0.267| p_loss: 0.399| v_loss: 0.057| per_loss: 0.866 | a_loss: 0.577
Train: Epoch [212/3000], Step [60/158]| g_loss: 1.169| d_loss: 0.656| gp_loss: 0.041| r_loss: 0.287| p_loss: 0.417| v_loss: 0.060| per_loss: 0.889 | a_loss: 0.525
Train: Epoch [212/3000], Step [90/158]| g_loss: 1.245| d_loss: 0.539| gp_loss: 0.043| r_loss: 0.296| p_loss: 0.421| v_loss: 0.059| per_loss: 0.918 | a_loss: 0.588
Train: Epoch [212/3000], Step [120/158]| g_loss: 1.167| d_loss: 0.583| gp_loss: 0.046| r_loss: 0.267| p_loss: 0.423| v_loss: 0.058| per_loss: 0.885 | a_loss: 0.542
Train: Epoch [212/3000], Step [150/158]| g_loss: 1.245| d_loss: 0.511| gp_loss: 0.047| r_loss: 0.299| p_loss: 0.435| v_loss: 0.057| per_loss: 0.908 | a_loss: 0.581
Train: Epoch [213/3000], Step [30/158]| g_loss: 1.191| d_loss: 0.666| gp_loss: 0.103| r_loss: 0.299| p_loss: 0.430| v_loss: 0.057| per_loss: 0.897 | a_loss: 0.530
Train: Epoch [213/3000], Step [60/158]| g_loss: 1.169| d_loss: 0.551| gp_loss: 0.043| r_loss: 0.273| p_loss: 0.419| v_loss: 0.057| per_loss: 0.898 | a_loss: 0.541
Train: Epoch [213/3000], Step [90/158]| g_loss: 1.233| d_loss: 0.533| gp_loss: 0.045| r_loss: 0.281| p_loss: 0.419| v_loss: 0.058| per_loss: 0.871 | a_loss: 0.597
Train: Epoch [213/3000], Step [120/158]| g_loss: 1.216| d_loss: 0.475| gp_loss: 0.048| r_loss: 0.264| p_loss: 0.404| v_loss: 0.052| per_loss: 0.937 | a_loss: 0.605
Train: Epoch [213/3000], Step [150/158]| g_loss: 1.245| d_loss: 0.517| gp_loss: 0.042| r_loss: 0.290| p_loss: 0.433| v_loss: 0.058| per_loss: 0.844 | a_loss: 0.596
Train: Epoch [214/3000], Step [30/158]| g_loss: 1.195| d_loss: 0.671| gp_loss: 0.114| r_loss: 0.284| p_loss: 0.421| v_loss: 0.057| per_loss: 0.934 | a_loss: 0.550
Train: Epoch [214/3000], Step [60/158]| g_loss: 1.129| d_loss: 0.624| gp_loss: 0.048| r_loss: 0.257| p_loss: 0.424| v_loss: 0.059| per_loss: 0.848 | a_loss: 0.516
Train: Epoch [214/3000], Step [90/158]| g_loss: 1.271| d_loss: 0.455| gp_loss: 0.044| r_loss: 0.279| p_loss: 0.427| v_loss: 0.059| per_loss: 0.874 | a_loss: 0.633
Train: Epoch [214/3000], Step [120/158]| g_loss: 1.190| d_loss: 0.637| gp_loss: 0.046| r_loss: 0.298| p_loss: 0.415| v_loss: 0.055| per_loss: 0.934 | a_loss: 0.536
Train: Epoch [214/3000], Step [150/158]| g_loss: 1.220| d_loss: 0.554| gp_loss: 0.045| r_loss: 0.305| p_loss: 0.426| v_loss: 0.056| per_loss: 0.859 | a_loss: 0.560
Train: Epoch [215/3000], Step [30/158]| g_loss: 1.203| d_loss: 0.662| gp_loss: 0.150| r_loss: 0.285| p_loss: 0.423| v_loss: 0.057| per_loss: 0.873 | a_loss: 0.562
Train: Epoch [215/3000], Step [60/158]| g_loss: 1.178| d_loss: 0.607| gp_loss: 0.046| r_loss: 0.292| p_loss: 0.429| v_loss: 0.056| per_loss: 0.882 | a_loss: 0.527
Train: Epoch [215/3000], Step [90/158]| g_loss: 1.199| d_loss: 0.632| gp_loss: 0.046| r_loss: 0.279| p_loss: 0.447| v_loss: 0.057| per_loss: 0.906 | a_loss: 0.549
Train: Epoch [215/3000], Step [120/158]| g_loss: 1.303| d_loss: 0.443| gp_loss: 0.041| r_loss: 0.292| p_loss: 0.434| v_loss: 0.060| per_loss: 0.899 | a_loss: 0.644
Train: Epoch [215/3000], Step [150/158]| g_loss: 1.176| d_loss: 0.589| gp_loss: 0.047| r_loss: 0.287| p_loss: 0.416| v_loss: 0.055| per_loss: 0.879 | a_loss: 0.538
Train: Epoch [216/3000], Step [30/158]| g_loss: 1.201| d_loss: 0.681| gp_loss: 0.154| r_loss: 0.283| p_loss: 0.421| v_loss: 0.057| per_loss: 0.895 | a_loss: 0.562
Train: Epoch [216/3000], Step [60/158]| g_loss: 1.237| d_loss: 0.533| gp_loss: 0.040| r_loss: 0.277| p_loss: 0.419| v_loss: 0.055| per_loss: 0.943 | a_loss: 0.602
Train: Epoch [216/3000], Step [90/158]| g_loss: 1.209| d_loss: 0.566| gp_loss: 0.043| r_loss: 0.279| p_loss: 0.462| v_loss: 0.057| per_loss: 0.886 | a_loss: 0.553
Train: Epoch [216/3000], Step [120/158]| g_loss: 1.149| d_loss: 0.644| gp_loss: 0.043| r_loss: 0.276| p_loss: 0.419| v_loss: 0.057| per_loss: 0.882 | a_loss: 0.518
Train: Epoch [216/3000], Step [150/158]| g_loss: 1.240| d_loss: 0.505| gp_loss: 0.042| r_loss: 0.284| p_loss: 0.408| v_loss: 0.059| per_loss: 0.893 | a_loss: 0.604
Train: Epoch [217/3000], Step [30/158]| g_loss: 1.256| d_loss: 0.613| gp_loss: 0.130| r_loss: 0.284| p_loss: 0.447| v_loss: 0.056| per_loss: 0.890 | a_loss: 0.604
Train: Epoch [217/3000], Step [60/158]| g_loss: 1.243| d_loss: 0.551| gp_loss: 0.044| r_loss: 0.297| p_loss: 0.425| v_loss: 0.056| per_loss: 0.881 | a_loss: 0.590
Train: Epoch [217/3000], Step [90/158]| g_loss: 1.159| d_loss: 0.627| gp_loss: 0.043| r_loss: 0.282| p_loss: 0.415| v_loss: 0.058| per_loss: 0.939 | a_loss: 0.519
Train: Epoch [217/3000], Step [120/158]| g_loss: 1.191| d_loss: 0.495| gp_loss: 0.043| r_loss: 0.262| p_loss: 0.413| v_loss: 0.057| per_loss: 0.881 | a_loss: 0.577
Train: Epoch [217/3000], Step [150/158]| g_loss: 1.179| d_loss: 0.565| gp_loss: 0.043| r_loss: 0.281| p_loss: 0.412| v_loss: 0.055| per_loss: 0.861 | a_loss: 0.550
Train: Epoch [218/3000], Step [30/158]| g_loss: 1.131| d_loss: 0.675| gp_loss: 0.089| r_loss: 0.271| p_loss: 0.412| v_loss: 0.052| per_loss: 0.897 | a_loss: 0.512
Train: Epoch [218/3000], Step [60/158]| g_loss: 1.160| d_loss: 0.568| gp_loss: 0.045| r_loss: 0.270| p_loss: 0.419| v_loss: 0.055| per_loss: 0.920 | a_loss: 0.534
Train: Epoch [218/3000], Step [90/158]| g_loss: 1.206| d_loss: 0.568| gp_loss: 0.043| r_loss: 0.269| p_loss: 0.412| v_loss: 0.056| per_loss: 0.861 | a_loss: 0.588
Train: Epoch [218/3000], Step [120/158]| g_loss: 1.175| d_loss: 0.595| gp_loss: 0.043| r_loss: 0.283| p_loss: 0.420| v_loss: 0.055| per_loss: 0.856 | a_loss: 0.541
Train: Epoch [218/3000], Step [150/158]| g_loss: 1.237| d_loss: 0.518| gp_loss: 0.044| r_loss: 0.278| p_loss: 0.393| v_loss: 0.058| per_loss: 0.865 | a_loss: 0.617
Train: Epoch [219/3000], Step [30/158]| g_loss: 1.214| d_loss: 0.556| gp_loss: 0.099| r_loss: 0.271| p_loss: 0.399| v_loss: 0.056| per_loss: 0.825 | a_loss: 0.606
Train: Epoch [219/3000], Step [60/158]| g_loss: 1.180| d_loss: 0.581| gp_loss: 0.044| r_loss: 0.289| p_loss: 0.421| v_loss: 0.057| per_loss: 0.829 | a_loss: 0.540
Train: Epoch [219/3000], Step [90/158]| g_loss: 1.198| d_loss: 0.567| gp_loss: 0.046| r_loss: 0.270| p_loss: 0.413| v_loss: 0.054| per_loss: 0.923 | a_loss: 0.575
Train: Epoch [219/3000], Step [120/158]| g_loss: 1.143| d_loss: 0.658| gp_loss: 0.044| r_loss: 0.283| p_loss: 0.427| v_loss: 0.056| per_loss: 0.941 | a_loss: 0.497
Train: Epoch [219/3000], Step [150/158]| g_loss: 1.168| d_loss: 0.545| gp_loss: 0.043| r_loss: 0.270| p_loss: 0.418| v_loss: 0.057| per_loss: 0.870 | a_loss: 0.545
Train: Epoch [220/3000], Step [30/158]| g_loss: 1.157| d_loss: 0.714| gp_loss: 0.157| r_loss: 0.270| p_loss: 0.399| v_loss: 0.056| per_loss: 0.908 | a_loss: 0.540
Train: Epoch [220/3000], Step [60/158]| g_loss: 1.207| d_loss: 0.439| gp_loss: 0.039| r_loss: 0.263| p_loss: 0.391| v_loss: 0.055| per_loss: 0.839 | a_loss: 0.610
Train: Epoch [220/3000], Step [90/158]| g_loss: 1.193| d_loss: 0.589| gp_loss: 0.041| r_loss: 0.277| p_loss: 0.408| v_loss: 0.056| per_loss: 0.911 | a_loss: 0.565
Train: Epoch [220/3000], Step [120/158]| g_loss: 1.148| d_loss: 0.583| gp_loss: 0.045| r_loss: 0.271| p_loss: 0.410| v_loss: 0.052| per_loss: 0.866 | a_loss: 0.534
Train: Epoch [220/3000], Step [150/158]| g_loss: 1.198| d_loss: 0.531| gp_loss: 0.041| r_loss: 0.277| p_loss: 0.405| v_loss: 0.052| per_loss: 0.826 | a_loss: 0.584
Train: Epoch [221/3000], Step [30/158]| g_loss: 1.166| d_loss: 0.692| gp_loss: 0.149| r_loss: 0.278| p_loss: 0.416| v_loss: 0.053| per_loss: 0.833 | a_loss: 0.543
Train: Epoch [221/3000], Step [60/158]| g_loss: 1.143| d_loss: 0.578| gp_loss: 0.040| r_loss: 0.254| p_loss: 0.380| v_loss: 0.055| per_loss: 0.857 | a_loss: 0.559
Train: Epoch [221/3000], Step [90/158]| g_loss: 1.207| d_loss: 0.491| gp_loss: 0.040| r_loss: 0.272| p_loss: 0.389| v_loss: 0.055| per_loss: 0.857 | a_loss: 0.600
Train: Epoch [221/3000], Step [120/158]| g_loss: 1.143| d_loss: 0.602| gp_loss: 0.043| r_loss: 0.278| p_loss: 0.399| v_loss: 0.053| per_loss: 0.838 | a_loss: 0.530
Train: Epoch [221/3000], Step [150/158]| g_loss: 1.155| d_loss: 0.633| gp_loss: 0.044| r_loss: 0.279| p_loss: 0.401| v_loss: 0.055| per_loss: 0.834 | a_loss: 0.537
Train: Epoch [222/3000], Step [30/158]| g_loss: 1.183| d_loss: 0.661| gp_loss: 0.183| r_loss: 0.281| p_loss: 0.402| v_loss: 0.057| per_loss: 0.839 | a_loss: 0.561
Train: Epoch [222/3000], Step [60/158]| g_loss: 1.192| d_loss: 0.574| gp_loss: 0.039| r_loss: 0.271| p_loss: 0.391| v_loss: 0.056| per_loss: 0.883 | a_loss: 0.581
Train: Epoch [222/3000], Step [90/158]| g_loss: 1.088| d_loss: 0.598| gp_loss: 0.041| r_loss: 0.252| p_loss: 0.386| v_loss: 0.051| per_loss: 0.809 | a_loss: 0.511
Train: Epoch [222/3000], Step [120/158]| g_loss: 1.188| d_loss: 0.553| gp_loss: 0.040| r_loss: 0.268| p_loss: 0.400| v_loss: 0.054| per_loss: 0.782 | a_loss: 0.587
Train: Epoch [222/3000], Step [150/158]| g_loss: 1.187| d_loss: 0.529| gp_loss: 0.039| r_loss: 0.271| p_loss: 0.397| v_loss: 0.054| per_loss: 0.860 | a_loss: 0.577
Train: Epoch [223/3000], Step [30/158]| g_loss: 1.145| d_loss: 0.639| gp_loss: 0.095| r_loss: 0.271| p_loss: 0.400| v_loss: 0.053| per_loss: 0.831 | a_loss: 0.537
Train: Epoch [223/3000], Step [60/158]| g_loss: 1.110| d_loss: 0.659| gp_loss: 0.042| r_loss: 0.264| p_loss: 0.400| v_loss: 0.054| per_loss: 0.805 | a_loss: 0.512
Train: Epoch [223/3000], Step [90/158]| g_loss: 1.144| d_loss: 0.603| gp_loss: 0.042| r_loss: 0.270| p_loss: 0.404| v_loss: 0.058| per_loss: 0.842 | a_loss: 0.531
Train: Epoch [223/3000], Step [120/158]| g_loss: 1.207| d_loss: 0.509| gp_loss: 0.040| r_loss: 0.262| p_loss: 0.390| v_loss: 0.055| per_loss: 0.826 | a_loss: 0.613
Train: Epoch [223/3000], Step [150/158]| g_loss: 1.157| d_loss: 0.580| gp_loss: 0.045| r_loss: 0.268| p_loss: 0.403| v_loss: 0.055| per_loss: 0.830 | a_loss: 0.550
Train: Epoch [224/3000], Step [30/158]| g_loss: 1.284| d_loss: 0.628| gp_loss: 0.130| r_loss: 0.299| p_loss: 0.464| v_loss: 0.054| per_loss: 0.900 | a_loss: 0.609
Train: Epoch [224/3000], Step [60/158]| g_loss: 1.180| d_loss: 0.620| gp_loss: 0.042| r_loss: 0.285| p_loss: 0.431| v_loss: 0.055| per_loss: 0.856 | a_loss: 0.539
Train: Epoch [224/3000], Step [90/158]| g_loss: 1.209| d_loss: 0.559| gp_loss: 0.041| r_loss: 0.282| p_loss: 0.425| v_loss: 0.053| per_loss: 0.836 | a_loss: 0.578
Train: Epoch [224/3000], Step [120/158]| g_loss: 1.171| d_loss: 0.596| gp_loss: 0.044| r_loss: 0.281| p_loss: 0.422| v_loss: 0.054| per_loss: 0.800 | a_loss: 0.544
Train: Epoch [224/3000], Step [150/158]| g_loss: 1.174| d_loss: 0.531| gp_loss: 0.041| r_loss: 0.271| p_loss: 0.402| v_loss: 0.052| per_loss: 0.788 | a_loss: 0.570
Train: Epoch [225/3000], Step [30/158]| g_loss: 1.167| d_loss: 0.646| gp_loss: 0.095| r_loss: 0.275| p_loss: 0.414| v_loss: 0.054| per_loss: 0.807 | a_loss: 0.551
Train: Epoch [225/3000], Step [60/158]| g_loss: 1.200| d_loss: 0.533| gp_loss: 0.041| r_loss: 0.282| p_loss: 0.399| v_loss: 0.053| per_loss: 0.804 | a_loss: 0.586
Train: Epoch [225/3000], Step [90/158]| g_loss: 1.131| d_loss: 0.601| gp_loss: 0.046| r_loss: 0.283| p_loss: 0.415| v_loss: 0.054| per_loss: 0.768 | a_loss: 0.509
Train: Epoch [225/3000], Step [120/158]| g_loss: 1.205| d_loss: 0.539| gp_loss: 0.043| r_loss: 0.268| p_loss: 0.392| v_loss: 0.053| per_loss: 0.778 | a_loss: 0.611
Train: Epoch [225/3000], Step [150/158]| g_loss: 1.155| d_loss: 0.563| gp_loss: 0.045| r_loss: 0.275| p_loss: 0.411| v_loss: 0.055| per_loss: 0.773 | a_loss: 0.542
Train: Epoch [226/3000], Step [30/158]| g_loss: 1.142| d_loss: 0.668| gp_loss: 0.105| r_loss: 0.276| p_loss: 0.399| v_loss: 0.056| per_loss: 0.723 | a_loss: 0.538
Train: Epoch [226/3000], Step [60/158]| g_loss: 1.124| d_loss: 0.591| gp_loss: 0.042| r_loss: 0.265| p_loss: 0.397| v_loss: 0.051| per_loss: 0.774 | a_loss: 0.533
Train: Epoch [226/3000], Step [90/158]| g_loss: 1.139| d_loss: 0.623| gp_loss: 0.043| r_loss: 0.271| p_loss: 0.388| v_loss: 0.051| per_loss: 0.863 | a_loss: 0.537
Train: Epoch [226/3000], Step [120/158]| g_loss: 1.099| d_loss: 0.647| gp_loss: 0.044| r_loss: 0.274| p_loss: 0.390| v_loss: 0.053| per_loss: 0.774 | a_loss: 0.500
Train: Epoch [226/3000], Step [150/158]| g_loss: 1.162| d_loss: 0.557| gp_loss: 0.044| r_loss: 0.276| p_loss: 0.410| v_loss: 0.054| per_loss: 0.758 | a_loss: 0.551
Train: Epoch [227/3000], Step [30/158]| g_loss: 1.166| d_loss: 0.595| gp_loss: 0.098| r_loss: 0.262| p_loss: 0.392| v_loss: 0.056| per_loss: 0.823 | a_loss: 0.569
Train: Epoch [227/3000], Step [60/158]| g_loss: 1.197| d_loss: 0.586| gp_loss: 0.042| r_loss: 0.286| p_loss: 0.411| v_loss: 0.054| per_loss: 0.814 | a_loss: 0.570
Train: Epoch [227/3000], Step [90/158]| g_loss: 1.129| d_loss: 0.612| gp_loss: 0.042| r_loss: 0.259| p_loss: 0.396| v_loss: 0.055| per_loss: 0.774 | a_loss: 0.540
Train: Epoch [227/3000], Step [120/158]| g_loss: 1.139| d_loss: 0.571| gp_loss: 0.046| r_loss: 0.277| p_loss: 0.409| v_loss: 0.054| per_loss: 0.730 | a_loss: 0.531
Train: Epoch [227/3000], Step [150/158]| g_loss: 1.150| d_loss: 0.560| gp_loss: 0.045| r_loss: 0.268| p_loss: 0.392| v_loss: 0.051| per_loss: 0.736 | a_loss: 0.562
Train: Epoch [228/3000], Step [30/158]| g_loss: 1.105| d_loss: 0.686| gp_loss: 0.087| r_loss: 0.269| p_loss: 0.393| v_loss: 0.052| per_loss: 0.780 | a_loss: 0.510
Train: Epoch [228/3000], Step [60/158]| g_loss: 1.093| d_loss: 0.643| gp_loss: 0.044| r_loss: 0.258| p_loss: 0.384| v_loss: 0.053| per_loss: 0.774 | a_loss: 0.512
Train: Epoch [228/3000], Step [90/158]| g_loss: 1.118| d_loss: 0.626| gp_loss: 0.046| r_loss: 0.264| p_loss: 0.386| v_loss: 0.051| per_loss: 0.786 | a_loss: 0.532
Train: Epoch [228/3000], Step [120/158]| g_loss: 1.169| d_loss: 0.517| gp_loss: 0.045| r_loss: 0.274| p_loss: 0.404| v_loss: 0.051| per_loss: 0.725 | a_loss: 0.569
Train: Epoch [228/3000], Step [150/158]| g_loss: 1.187| d_loss: 0.501| gp_loss: 0.041| r_loss: 0.268| p_loss: 0.391| v_loss: 0.055| per_loss: 0.770 | a_loss: 0.592
Train: Epoch [229/3000], Step [30/158]| g_loss: 1.146| d_loss: 0.669| gp_loss: 0.127| r_loss: 0.271| p_loss: 0.388| v_loss: 0.054| per_loss: 0.772 | a_loss: 0.550
Train: Epoch [229/3000], Step [60/158]| g_loss: 1.126| d_loss: 0.597| gp_loss: 0.045| r_loss: 0.257| p_loss: 0.388| v_loss: 0.055| per_loss: 0.731 | a_loss: 0.546
Train: Epoch [229/3000], Step [90/158]| g_loss: 1.128| d_loss: 0.594| gp_loss: 0.047| r_loss: 0.277| p_loss: 0.380| v_loss: 0.055| per_loss: 0.751 | a_loss: 0.531
Train: Epoch [229/3000], Step [120/158]| g_loss: 1.168| d_loss: 0.543| gp_loss: 0.044| r_loss: 0.265| p_loss: 0.396| v_loss: 0.053| per_loss: 0.726 | a_loss: 0.579
Train: Epoch [229/3000], Step [150/158]| g_loss: 1.141| d_loss: 0.537| gp_loss: 0.048| r_loss: 0.255| p_loss: 0.390| v_loss: 0.052| per_loss: 0.775 | a_loss: 0.560
Train: Epoch [230/3000], Step [30/158]| g_loss: 1.239| d_loss: 0.539| gp_loss: 0.094| r_loss: 0.289| p_loss: 0.410| v_loss: 0.054| per_loss: 0.790 | a_loss: 0.612
Train: Epoch [230/3000], Step [60/158]| g_loss: 1.089| d_loss: 0.692| gp_loss: 0.046| r_loss: 0.273| p_loss: 0.384| v_loss: 0.053| per_loss: 0.777 | a_loss: 0.494
Train: Epoch [230/3000], Step [90/158]| g_loss: 1.115| d_loss: 0.605| gp_loss: 0.046| r_loss: 0.270| p_loss: 0.379| v_loss: 0.053| per_loss: 0.781 | a_loss: 0.524
Train: Epoch [230/3000], Step [120/158]| g_loss: 1.097| d_loss: 0.629| gp_loss: 0.044| r_loss: 0.254| p_loss: 0.372| v_loss: 0.054| per_loss: 0.723 | a_loss: 0.531
Train: Epoch [230/3000], Step [150/158]| g_loss: 1.150| d_loss: 0.550| gp_loss: 0.045| r_loss: 0.266| p_loss: 0.394| v_loss: 0.053| per_loss: 0.735 | a_loss: 0.561
Train: Epoch [231/3000], Step [30/158]| g_loss: 1.120| d_loss: 0.725| gp_loss: 0.142| r_loss: 0.288| p_loss: 0.394| v_loss: 0.053| per_loss: 0.737 | a_loss: 0.508
Train: Epoch [231/3000], Step [60/158]| g_loss: 1.169| d_loss: 0.508| gp_loss: 0.040| r_loss: 0.246| p_loss: 0.377| v_loss: 0.052| per_loss: 0.773 | a_loss: 0.604
Train: Epoch [231/3000], Step [90/158]| g_loss: 1.046| d_loss: 0.710| gp_loss: 0.046| r_loss: 0.257| p_loss: 0.388| v_loss: 0.052| per_loss: 0.785 | a_loss: 0.465
Train: Epoch [231/3000], Step [120/158]| g_loss: 1.147| d_loss: 0.586| gp_loss: 0.042| r_loss: 0.270| p_loss: 0.385| v_loss: 0.053| per_loss: 0.754 | a_loss: 0.556
Train: Epoch [231/3000], Step [150/158]| g_loss: 1.178| d_loss: 0.562| gp_loss: 0.045| r_loss: 0.266| p_loss: 0.396| v_loss: 0.053| per_loss: 0.767 | a_loss: 0.585
Train: Epoch [232/3000], Step [30/158]| g_loss: 1.127| d_loss: 0.697| gp_loss: 0.168| r_loss: 0.269| p_loss: 0.389| v_loss: 0.055| per_loss: 0.769 | a_loss: 0.532
Train: Epoch [232/3000], Step [60/158]| g_loss: 1.148| d_loss: 0.572| gp_loss: 0.042| r_loss: 0.251| p_loss: 0.384| v_loss: 0.054| per_loss: 0.771 | a_loss: 0.574
Train: Epoch [232/3000], Step [90/158]| g_loss: 1.136| d_loss: 0.574| gp_loss: 0.043| r_loss: 0.266| p_loss: 0.389| v_loss: 0.055| per_loss: 0.783 | a_loss: 0.542
Train: Epoch [232/3000], Step [120/158]| g_loss: 1.162| d_loss: 0.543| gp_loss: 0.043| r_loss: 0.266| p_loss: 0.389| v_loss: 0.054| per_loss: 0.771 | a_loss: 0.570
Train: Epoch [232/3000], Step [150/158]| g_loss: 1.074| d_loss: 0.666| gp_loss: 0.044| r_loss: 0.266| p_loss: 0.375| v_loss: 0.051| per_loss: 0.746 | a_loss: 0.495
Train: Epoch [233/3000], Step [30/158]| g_loss: 1.129| d_loss: 0.612| gp_loss: 0.096| r_loss: 0.262| p_loss: 0.379| v_loss: 0.050| per_loss: 0.799 | a_loss: 0.547
Train: Epoch [233/3000], Step [60/158]| g_loss: 1.146| d_loss: 0.577| gp_loss: 0.041| r_loss: 0.249| p_loss: 0.377| v_loss: 0.055| per_loss: 0.712 | a_loss: 0.582
Train: Epoch [233/3000], Step [90/158]| g_loss: 1.100| d_loss: 0.679| gp_loss: 0.040| r_loss: 0.262| p_loss: 0.376| v_loss: 0.053| per_loss: 0.754 | a_loss: 0.522
Train: Epoch [233/3000], Step [120/158]| g_loss: 1.118| d_loss: 0.615| gp_loss: 0.048| r_loss: 0.273| p_loss: 0.390| v_loss: 0.054| per_loss: 0.772 | a_loss: 0.519
Train: Epoch [233/3000], Step [150/158]| g_loss: 1.170| d_loss: 0.591| gp_loss: 0.046| r_loss: 0.279| p_loss: 0.384| v_loss: 0.053| per_loss: 0.730 | a_loss: 0.573
Train: Epoch [234/3000], Step [30/158]| g_loss: 1.140| d_loss: 0.695| gp_loss: 0.130| r_loss: 0.246| p_loss: 0.379| v_loss: 0.053| per_loss: 0.780 | a_loss: 0.572
Train: Epoch [234/3000], Step [60/158]| g_loss: 1.133| d_loss: 0.595| gp_loss: 0.045| r_loss: 0.276| p_loss: 0.396| v_loss: 0.052| per_loss: 0.741 | a_loss: 0.533
Train: Epoch [234/3000], Step [90/158]| g_loss: 1.119| d_loss: 0.617| gp_loss: 0.043| r_loss: 0.278| p_loss: 0.387| v_loss: 0.054| per_loss: 0.745 | a_loss: 0.519
Train: Epoch [234/3000], Step [120/158]| g_loss: 1.085| d_loss: 0.616| gp_loss: 0.044| r_loss: 0.245| p_loss: 0.382| v_loss: 0.052| per_loss: 0.760 | a_loss: 0.521
Train: Epoch [234/3000], Step [150/158]| g_loss: 1.117| d_loss: 0.622| gp_loss: 0.044| r_loss: 0.266| p_loss: 0.395| v_loss: 0.052| per_loss: 0.720 | a_loss: 0.530
Train: Epoch [235/3000], Step [30/158]| g_loss: 1.138| d_loss: 0.655| gp_loss: 0.108| r_loss: 0.257| p_loss: 0.373| v_loss: 0.052| per_loss: 0.774 | a_loss: 0.566
Train: Epoch [235/3000], Step [60/158]| g_loss: 1.097| d_loss: 0.579| gp_loss: 0.040| r_loss: 0.253| p_loss: 0.381| v_loss: 0.054| per_loss: 0.760 | a_loss: 0.524
Train: Epoch [235/3000], Step [90/158]| g_loss: 1.193| d_loss: 0.522| gp_loss: 0.039| r_loss: 0.254| p_loss: 0.387| v_loss: 0.055| per_loss: 0.709 | a_loss: 0.620
Train: Epoch [235/3000], Step [120/158]| g_loss: 1.093| d_loss: 0.713| gp_loss: 0.043| r_loss: 0.255| p_loss: 0.388| v_loss: 0.056| per_loss: 0.752 | a_loss: 0.513
Train: Epoch [235/3000], Step [150/158]| g_loss: 1.106| d_loss: 0.587| gp_loss: 0.044| r_loss: 0.269| p_loss: 0.377| v_loss: 0.054| per_loss: 0.738 | a_loss: 0.521
Train: Epoch [236/3000], Step [30/158]| g_loss: 1.124| d_loss: 0.652| gp_loss: 0.103| r_loss: 0.264| p_loss: 0.390| v_loss: 0.052| per_loss: 0.720 | a_loss: 0.540
Train: Epoch [236/3000], Step [60/158]| g_loss: 1.117| d_loss: 0.570| gp_loss: 0.042| r_loss: 0.249| p_loss: 0.377| v_loss: 0.051| per_loss: 0.741 | a_loss: 0.554
Train: Epoch [236/3000], Step [90/158]| g_loss: 1.054| d_loss: 0.672| gp_loss: 0.048| r_loss: 0.245| p_loss: 0.377| v_loss: 0.050| per_loss: 0.724 | a_loss: 0.499
Train: Epoch [236/3000], Step [120/158]| g_loss: 1.125| d_loss: 0.590| gp_loss: 0.044| r_loss: 0.264| p_loss: 0.398| v_loss: 0.052| per_loss: 0.686 | a_loss: 0.542
Train: Epoch [236/3000], Step [150/158]| g_loss: 1.095| d_loss: 0.606| gp_loss: 0.043| r_loss: 0.264| p_loss: 0.378| v_loss: 0.053| per_loss: 0.713 | a_loss: 0.518
Train: Epoch [237/3000], Step [30/158]| g_loss: 1.203| d_loss: 0.563| gp_loss: 0.062| r_loss: 0.262| p_loss: 0.391| v_loss: 0.054| per_loss: 0.739 | a_loss: 0.619
Train: Epoch [237/3000], Step [60/158]| g_loss: 1.027| d_loss: 0.698| gp_loss: 0.047| r_loss: 0.251| p_loss: 0.377| v_loss: 0.054| per_loss: 0.692 | a_loss: 0.463
Train: Epoch [237/3000], Step [90/158]| g_loss: 1.126| d_loss: 0.658| gp_loss: 0.045| r_loss: 0.273| p_loss: 0.387| v_loss: 0.052| per_loss: 0.767 | a_loss: 0.530
Train: Epoch [237/3000], Step [120/158]| g_loss: 1.161| d_loss: 0.508| gp_loss: 0.047| r_loss: 0.262| p_loss: 0.378| v_loss: 0.053| per_loss: 0.721 | a_loss: 0.584
Train: Epoch [237/3000], Step [150/158]| g_loss: 1.174| d_loss: 0.553| gp_loss: 0.043| r_loss: 0.250| p_loss: 0.380| v_loss: 0.057| per_loss: 0.739 | a_loss: 0.604
Train: Epoch [238/3000], Step [30/158]| g_loss: 1.132| d_loss: 0.614| gp_loss: 0.069| r_loss: 0.249| p_loss: 0.388| v_loss: 0.055| per_loss: 0.762 | a_loss: 0.558
Train: Epoch [238/3000], Step [60/158]| g_loss: 1.168| d_loss: 0.565| gp_loss: 0.044| r_loss: 0.265| p_loss: 0.390| v_loss: 0.054| per_loss: 0.772 | a_loss: 0.577
Train: Epoch [238/3000], Step [90/158]| g_loss: 1.119| d_loss: 0.533| gp_loss: 0.048| r_loss: 0.249| p_loss: 0.377| v_loss: 0.049| per_loss: 0.721 | a_loss: 0.560
Train: Epoch [238/3000], Step [120/158]| g_loss: 1.161| d_loss: 0.595| gp_loss: 0.043| r_loss: 0.280| p_loss: 0.384| v_loss: 0.052| per_loss: 0.729 | a_loss: 0.564
Train: Epoch [238/3000], Step [150/158]| g_loss: 1.073| d_loss: 0.684| gp_loss: 0.046| r_loss: 0.255| p_loss: 0.375| v_loss: 0.052| per_loss: 0.779 | a_loss: 0.500
Train: Epoch [239/3000], Step [30/158]| g_loss: 1.128| d_loss: 0.592| gp_loss: 0.096| r_loss: 0.244| p_loss: 0.365| v_loss: 0.053| per_loss: 0.741 | a_loss: 0.575
Train: Epoch [239/3000], Step [60/158]| g_loss: 1.052| d_loss: 0.741| gp_loss: 0.047| r_loss: 0.256| p_loss: 0.383| v_loss: 0.053| per_loss: 0.784 | a_loss: 0.473
Train: Epoch [239/3000], Step [90/158]| g_loss: 1.082| d_loss: 0.588| gp_loss: 0.042| r_loss: 0.233| p_loss: 0.380| v_loss: 0.055| per_loss: 0.737 | a_loss: 0.530
Train: Epoch [239/3000], Step [120/158]| g_loss: 1.125| d_loss: 0.613| gp_loss: 0.044| r_loss: 0.255| p_loss: 0.379| v_loss: 0.054| per_loss: 0.706 | a_loss: 0.556
Train: Epoch [239/3000], Step [150/158]| g_loss: 1.204| d_loss: 0.501| gp_loss: 0.040| r_loss: 0.272| p_loss: 0.375| v_loss: 0.054| per_loss: 0.731 | a_loss: 0.618
Train: Epoch [240/3000], Step [30/158]| g_loss: 1.104| d_loss: 0.706| gp_loss: 0.151| r_loss: 0.259| p_loss: 0.386| v_loss: 0.051| per_loss: 0.725 | a_loss: 0.527
Train: Epoch [240/3000], Step [60/158]| g_loss: 1.070| d_loss: 0.643| gp_loss: 0.043| r_loss: 0.244| p_loss: 0.362| v_loss: 0.053| per_loss: 0.768 | a_loss: 0.515
Train: Epoch [240/3000], Step [90/158]| g_loss: 1.172| d_loss: 0.553| gp_loss: 0.039| r_loss: 0.255| p_loss: 0.390| v_loss: 0.052| per_loss: 0.772 | a_loss: 0.593
Train: Epoch [240/3000], Step [120/158]| g_loss: 1.108| d_loss: 0.637| gp_loss: 0.045| r_loss: 0.266| p_loss: 0.390| v_loss: 0.052| per_loss: 0.762 | a_loss: 0.518
Train: Epoch [240/3000], Step [150/158]| g_loss: 1.135| d_loss: 0.570| gp_loss: 0.042| r_loss: 0.272| p_loss: 0.374| v_loss: 0.053| per_loss: 0.771 | a_loss: 0.546
Train: Epoch [241/3000], Step [30/158]| g_loss: 1.089| d_loss: 0.772| gp_loss: 0.185| r_loss: 0.244| p_loss: 0.358| v_loss: 0.052| per_loss: 0.738 | a_loss: 0.540
Train: Epoch [241/3000], Step [60/158]| g_loss: 1.056| d_loss: 0.606| gp_loss: 0.040| r_loss: 0.262| p_loss: 0.376| v_loss: 0.053| per_loss: 0.725 | a_loss: 0.481
Train: Epoch [241/3000], Step [90/158]| g_loss: 1.105| d_loss: 0.602| gp_loss: 0.041| r_loss: 0.254| p_loss: 0.368| v_loss: 0.052| per_loss: 0.753 | a_loss: 0.539
Train: Epoch [241/3000], Step [120/158]| g_loss: 1.100| d_loss: 0.587| gp_loss: 0.043| r_loss: 0.248| p_loss: 0.377| v_loss: 0.051| per_loss: 0.732 | a_loss: 0.540
Train: Epoch [241/3000], Step [150/158]| g_loss: 1.148| d_loss: 0.505| gp_loss: 0.042| r_loss: 0.254| p_loss: 0.363| v_loss: 0.051| per_loss: 0.726 | a_loss: 0.588
Train: Epoch [242/3000], Step [30/158]| g_loss: 1.077| d_loss: 0.718| gp_loss: 0.076| r_loss: 0.268| p_loss: 0.374| v_loss: 0.049| per_loss: 0.763 | a_loss: 0.497
Train: Epoch [242/3000], Step [60/158]| g_loss: 1.067| d_loss: 0.602| gp_loss: 0.042| r_loss: 0.235| p_loss: 0.372| v_loss: 0.051| per_loss: 0.742 | a_loss: 0.520
Train: Epoch [242/3000], Step [90/158]| g_loss: 1.073| d_loss: 0.633| gp_loss: 0.043| r_loss: 0.258| p_loss: 0.368| v_loss: 0.054| per_loss: 0.736 | a_loss: 0.503
Train: Epoch [242/3000], Step [120/158]| g_loss: 1.100| d_loss: 0.591| gp_loss: 0.046| r_loss: 0.256| p_loss: 0.376| v_loss: 0.052| per_loss: 0.738 | a_loss: 0.530
Train: Epoch [242/3000], Step [150/158]| g_loss: 1.132| d_loss: 0.504| gp_loss: 0.041| r_loss: 0.246| p_loss: 0.367| v_loss: 0.053| per_loss: 0.724 | a_loss: 0.577
Train: Epoch [243/3000], Step [30/158]| g_loss: 1.110| d_loss: 0.641| gp_loss: 0.123| r_loss: 0.245| p_loss: 0.366| v_loss: 0.050| per_loss: 0.681 | a_loss: 0.564
Train: Epoch [243/3000], Step [60/158]| g_loss: 1.103| d_loss: 0.586| gp_loss: 0.042| r_loss: 0.249| p_loss: 0.370| v_loss: 0.053| per_loss: 0.749 | a_loss: 0.541
Train: Epoch [243/3000], Step [90/158]| g_loss: 1.140| d_loss: 0.542| gp_loss: 0.046| r_loss: 0.256| p_loss: 0.364| v_loss: 0.051| per_loss: 0.731 | a_loss: 0.578
Train: Epoch [243/3000], Step [120/158]| g_loss: 1.101| d_loss: 0.619| gp_loss: 0.047| r_loss: 0.257| p_loss: 0.367| v_loss: 0.052| per_loss: 0.788 | a_loss: 0.530
Train: Epoch [243/3000], Step [150/158]| g_loss: 1.071| d_loss: 0.648| gp_loss: 0.049| r_loss: 0.244| p_loss: 0.363| v_loss: 0.052| per_loss: 0.729 | a_loss: 0.519
Train: Epoch [244/3000], Step [30/158]| g_loss: 1.151| d_loss: 0.548| gp_loss: 0.091| r_loss: 0.244| p_loss: 0.358| v_loss: 0.052| per_loss: 0.741 | a_loss: 0.602
Train: Epoch [244/3000], Step [60/158]| g_loss: 1.121| d_loss: 0.539| gp_loss: 0.047| r_loss: 0.236| p_loss: 0.356| v_loss: 0.051| per_loss: 0.749 | a_loss: 0.581
Train: Epoch [244/3000], Step [90/158]| g_loss: 1.063| d_loss: 0.644| gp_loss: 0.049| r_loss: 0.262| p_loss: 0.378| v_loss: 0.051| per_loss: 0.743 | a_loss: 0.488
Train: Epoch [244/3000], Step [120/158]| g_loss: 1.094| d_loss: 0.655| gp_loss: 0.048| r_loss: 0.258| p_loss: 0.366| v_loss: 0.053| per_loss: 0.735 | a_loss: 0.527
Train: Epoch [244/3000], Step [150/158]| g_loss: 1.102| d_loss: 0.582| gp_loss: 0.049| r_loss: 0.255| p_loss: 0.371| v_loss: 0.051| per_loss: 0.773 | a_loss: 0.533
Train: Epoch [245/3000], Step [30/158]| g_loss: 1.149| d_loss: 0.635| gp_loss: 0.132| r_loss: 0.275| p_loss: 0.393| v_loss: 0.052| per_loss: 0.736 | a_loss: 0.551
Train: Epoch [245/3000], Step [60/158]| g_loss: 1.105| d_loss: 0.595| gp_loss: 0.043| r_loss: 0.245| p_loss: 0.371| v_loss: 0.053| per_loss: 0.736 | a_loss: 0.548
Train: Epoch [245/3000], Step [90/158]| g_loss: 1.119| d_loss: 0.591| gp_loss: 0.044| r_loss: 0.256| p_loss: 0.371| v_loss: 0.054| per_loss: 0.756 | a_loss: 0.548
Train: Epoch [245/3000], Step [120/158]| g_loss: 1.093| d_loss: 0.572| gp_loss: 0.049| r_loss: 0.245| p_loss: 0.362| v_loss: 0.050| per_loss: 0.774 | a_loss: 0.540
Train: Epoch [245/3000], Step [150/158]| g_loss: 1.107| d_loss: 0.595| gp_loss: 0.046| r_loss: 0.242| p_loss: 0.363| v_loss: 0.051| per_loss: 0.799 | a_loss: 0.552
Train: Epoch [246/3000], Step [30/158]| g_loss: 1.107| d_loss: 0.692| gp_loss: 0.158| r_loss: 0.247| p_loss: 0.362| v_loss: 0.051| per_loss: 0.779 | a_loss: 0.550
Train: Epoch [246/3000], Step [60/158]| g_loss: 1.066| d_loss: 0.588| gp_loss: 0.046| r_loss: 0.242| p_loss: 0.364| v_loss: 0.054| per_loss: 0.758 | a_loss: 0.513
Train: Epoch [246/3000], Step [90/158]| g_loss: 1.083| d_loss: 0.627| gp_loss: 0.045| r_loss: 0.247| p_loss: 0.355| v_loss: 0.049| per_loss: 0.771 | a_loss: 0.533
Train: Epoch [246/3000], Step [120/158]| g_loss: 1.109| d_loss: 0.653| gp_loss: 0.043| r_loss: 0.247| p_loss: 0.366| v_loss: 0.051| per_loss: 0.764 | a_loss: 0.551
Train: Epoch [246/3000], Step [150/158]| g_loss: 1.111| d_loss: 0.588| gp_loss: 0.041| r_loss: 0.251| p_loss: 0.372| v_loss: 0.052| per_loss: 0.746 | a_loss: 0.548
Train: Epoch [247/3000], Step [30/158]| g_loss: 1.136| d_loss: 0.641| gp_loss: 0.149| r_loss: 0.255| p_loss: 0.366| v_loss: 0.052| per_loss: 0.734 | a_loss: 0.572
Train: Epoch [247/3000], Step [60/158]| g_loss: 1.155| d_loss: 0.567| gp_loss: 0.039| r_loss: 0.264| p_loss: 0.376| v_loss: 0.052| per_loss: 0.755 | a_loss: 0.575
Train: Epoch [247/3000], Step [90/158]| g_loss: 1.079| d_loss: 0.574| gp_loss: 0.043| r_loss: 0.226| p_loss: 0.361| v_loss: 0.051| per_loss: 0.781 | a_loss: 0.543
Train: Epoch [247/3000], Step [120/158]| g_loss: 1.095| d_loss: 0.611| gp_loss: 0.044| r_loss: 0.247| p_loss: 0.367| v_loss: 0.054| per_loss: 0.732 | a_loss: 0.537
Train: Epoch [247/3000], Step [150/158]| g_loss: 1.106| d_loss: 0.614| gp_loss: 0.041| r_loss: 0.256| p_loss: 0.372| v_loss: 0.050| per_loss: 0.748 | a_loss: 0.539
Train: Epoch [248/3000], Step [30/158]| g_loss: 1.073| d_loss: 0.691| gp_loss: 0.134| r_loss: 0.232| p_loss: 0.355| v_loss: 0.049| per_loss: 0.751 | a_loss: 0.539
Train: Epoch [248/3000], Step [60/158]| g_loss: 1.013| d_loss: 0.716| gp_loss: 0.042| r_loss: 0.244| p_loss: 0.375| v_loss: 0.048| per_loss: 0.703 | a_loss: 0.464
Train: Epoch [248/3000], Step [90/158]| g_loss: 1.091| d_loss: 0.555| gp_loss: 0.043| r_loss: 0.257| p_loss: 0.373| v_loss: 0.052| per_loss: 0.718 | a_loss: 0.523
Train: Epoch [248/3000], Step [120/158]| g_loss: 1.138| d_loss: 0.588| gp_loss: 0.042| r_loss: 0.254| p_loss: 0.365| v_loss: 0.053| per_loss: 0.763 | a_loss: 0.572
Train: Epoch [248/3000], Step [150/158]| g_loss: 1.077| d_loss: 0.573| gp_loss: 0.042| r_loss: 0.236| p_loss: 0.353| v_loss: 0.050| per_loss: 0.724 | a_loss: 0.542
Train: Epoch [249/3000], Step [30/158]| g_loss: 1.153| d_loss: 0.549| gp_loss: 0.113| r_loss: 0.235| p_loss: 0.356| v_loss: 0.053| per_loss: 0.692 | a_loss: 0.618
Train: Epoch [249/3000], Step [60/158]| g_loss: 1.116| d_loss: 0.654| gp_loss: 0.043| r_loss: 0.267| p_loss: 0.369| v_loss: 0.053| per_loss: 0.769 | a_loss: 0.534
Train: Epoch [249/3000], Step [90/158]| g_loss: 1.097| d_loss: 0.575| gp_loss: 0.040| r_loss: 0.240| p_loss: 0.352| v_loss: 0.053| per_loss: 0.736 | a_loss: 0.555
Train: Epoch [249/3000], Step [120/158]| g_loss: 1.077| d_loss: 0.611| gp_loss: 0.045| r_loss: 0.241| p_loss: 0.376| v_loss: 0.051| per_loss: 0.720 | a_loss: 0.525
Train: Epoch [249/3000], Step [150/158]| g_loss: 1.102| d_loss: 0.569| gp_loss: 0.043| r_loss: 0.244| p_loss: 0.371| v_loss: 0.050| per_loss: 0.705 | a_loss: 0.552
Train: Epoch [250/3000], Step [30/158]| g_loss: 1.079| d_loss: 0.682| gp_loss: 0.155| r_loss: 0.238| p_loss: 0.353| v_loss: 0.050| per_loss: 0.721 | a_loss: 0.542
Train: Epoch [250/3000], Step [60/158]| g_loss: 1.035| d_loss: 0.694| gp_loss: 0.043| r_loss: 0.250| p_loss: 0.357| v_loss: 0.050| per_loss: 0.719 | a_loss: 0.484
Train: Epoch [250/3000], Step [90/158]| g_loss: 1.066| d_loss: 0.610| gp_loss: 0.042| r_loss: 0.243| p_loss: 0.361| v_loss: 0.050| per_loss: 0.671 | a_loss: 0.524
Train: Epoch [250/3000], Step [120/158]| g_loss: 1.121| d_loss: 0.579| gp_loss: 0.041| r_loss: 0.255| p_loss: 0.368| v_loss: 0.052| per_loss: 0.786 | a_loss: 0.551
Train: Epoch [250/3000], Step [150/158]| g_loss: 1.050| d_loss: 0.577| gp_loss: 0.043| r_loss: 0.248| p_loss: 0.359| v_loss: 0.051| per_loss: 0.724 | a_loss: 0.499
Test: Epoch [250/3000]| g_loss: 1.043| r_loss: 0.687| p_loss: 0.438| v_loss: 0.039
Train: Epoch [251/3000], Step [30/158]| g_loss: 1.098| d_loss: 0.620| gp_loss: 0.044| r_loss: 0.243| p_loss: 0.375| v_loss: 0.053| per_loss: 0.726 | a_loss: 0.542
Train: Epoch [251/3000], Step [60/158]| g_loss: 1.113| d_loss: 0.486| gp_loss: 0.043| r_loss: 0.217| p_loss: 0.342| v_loss: 0.051| per_loss: 0.679 | a_loss: 0.607
Train: Epoch [251/3000], Step [90/158]| g_loss: 1.127| d_loss: 0.562| gp_loss: 0.042| r_loss: 0.252| p_loss: 0.351| v_loss: 0.051| per_loss: 0.722 | a_loss: 0.575
Train: Epoch [251/3000], Step [120/158]| g_loss: 1.071| d_loss: 0.635| gp_loss: 0.046| r_loss: 0.251| p_loss: 0.361| v_loss: 0.049| per_loss: 0.726 | a_loss: 0.518
Train: Epoch [251/3000], Step [150/158]| g_loss: 1.100| d_loss: 0.617| gp_loss: 0.043| r_loss: 0.248| p_loss: 0.353| v_loss: 0.052| per_loss: 0.762 | a_loss: 0.547
Train: Epoch [252/3000], Step [30/158]| g_loss: 1.078| d_loss: 0.673| gp_loss: 0.110| r_loss: 0.251| p_loss: 0.358| v_loss: 0.050| per_loss: 0.718 | a_loss: 0.527
Train: Epoch [252/3000], Step [60/158]| g_loss: 1.055| d_loss: 0.598| gp_loss: 0.045| r_loss: 0.233| p_loss: 0.349| v_loss: 0.047| per_loss: 0.698 | a_loss: 0.531
Train: Epoch [252/3000], Step [90/158]| g_loss: 1.033| d_loss: 0.607| gp_loss: 0.045| r_loss: 0.229| p_loss: 0.350| v_loss: 0.052| per_loss: 0.768 | a_loss: 0.500
Train: Epoch [252/3000], Step [120/158]| g_loss: 1.069| d_loss: 0.649| gp_loss: 0.045| r_loss: 0.251| p_loss: 0.350| v_loss: 0.052| per_loss: 0.720 | a_loss: 0.518
Train: Epoch [252/3000], Step [150/158]| g_loss: 1.049| d_loss: 0.588| gp_loss: 0.047| r_loss: 0.235| p_loss: 0.352| v_loss: 0.050| per_loss: 0.704 | a_loss: 0.517
Train: Epoch [253/3000], Step [30/158]| g_loss: 1.112| d_loss: 0.635| gp_loss: 0.088| r_loss: 0.241| p_loss: 0.367| v_loss: 0.051| per_loss: 0.724 | a_loss: 0.564
Train: Epoch [253/3000], Step [60/158]| g_loss: 1.032| d_loss: 0.677| gp_loss: 0.045| r_loss: 0.241| p_loss: 0.363| v_loss: 0.049| per_loss: 0.707 | a_loss: 0.490
Train: Epoch [253/3000], Step [90/158]| g_loss: 1.088| d_loss: 0.505| gp_loss: 0.044| r_loss: 0.225| p_loss: 0.343| v_loss: 0.047| per_loss: 0.674 | a_loss: 0.576
Train: Epoch [253/3000], Step [120/158]| g_loss: 1.103| d_loss: 0.556| gp_loss: 0.046| r_loss: 0.243| p_loss: 0.341| v_loss: 0.054| per_loss: 0.731 | a_loss: 0.562
Train: Epoch [253/3000], Step [150/158]| g_loss: 1.161| d_loss: 0.501| gp_loss: 0.041| r_loss: 0.253| p_loss: 0.351| v_loss: 0.051| per_loss: 0.694 | a_loss: 0.612
Train: Epoch [254/3000], Step [30/158]| g_loss: 1.063| d_loss: 0.713| gp_loss: 0.164| r_loss: 0.232| p_loss: 0.344| v_loss: 0.050| per_loss: 0.688 | a_loss: 0.539
Train: Epoch [254/3000], Step [60/158]| g_loss: 1.053| d_loss: 0.636| gp_loss: 0.044| r_loss: 0.238| p_loss: 0.356| v_loss: 0.053| per_loss: 0.713 | a_loss: 0.512
Train: Epoch [254/3000], Step [90/158]| g_loss: 1.104| d_loss: 0.615| gp_loss: 0.042| r_loss: 0.247| p_loss: 0.368| v_loss: 0.052| per_loss: 0.716 | a_loss: 0.549
Train: Epoch [254/3000], Step [120/158]| g_loss: 1.081| d_loss: 0.518| gp_loss: 0.044| r_loss: 0.234| p_loss: 0.347| v_loss: 0.050| per_loss: 0.697 | a_loss: 0.554
Train: Epoch [254/3000], Step [150/158]| g_loss: 1.105| d_loss: 0.539| gp_loss: 0.045| r_loss: 0.236| p_loss: 0.340| v_loss: 0.049| per_loss: 0.761 | a_loss: 0.574
Train: Epoch [255/3000], Step [30/158]| g_loss: 1.006| d_loss: 0.751| gp_loss: 0.093| r_loss: 0.227| p_loss: 0.351| v_loss: 0.049| per_loss: 0.689 | a_loss: 0.485
Train: Epoch [255/3000], Step [60/158]| g_loss: 1.031| d_loss: 0.630| gp_loss: 0.048| r_loss: 0.236| p_loss: 0.342| v_loss: 0.048| per_loss: 0.699 | a_loss: 0.505
Train: Epoch [255/3000], Step [90/158]| g_loss: 1.142| d_loss: 0.520| gp_loss: 0.043| r_loss: 0.237| p_loss: 0.372| v_loss: 0.052| per_loss: 0.714 | a_loss: 0.596
Train: Epoch [255/3000], Step [120/158]| g_loss: 1.130| d_loss: 0.528| gp_loss: 0.048| r_loss: 0.247| p_loss: 0.339| v_loss: 0.049| per_loss: 0.710 | a_loss: 0.594
Train: Epoch [255/3000], Step [150/158]| g_loss: 1.049| d_loss: 0.606| gp_loss: 0.048| r_loss: 0.245| p_loss: 0.352| v_loss: 0.049| per_loss: 0.697 | a_loss: 0.508
Train: Epoch [256/3000], Step [30/158]| g_loss: 1.054| d_loss: 0.771| gp_loss: 0.195| r_loss: 0.231| p_loss: 0.350| v_loss: 0.049| per_loss: 0.717 | a_loss: 0.527
Train: Epoch [256/3000], Step [60/158]| g_loss: 1.082| d_loss: 0.570| gp_loss: 0.047| r_loss: 0.236| p_loss: 0.342| v_loss: 0.048| per_loss: 0.704 | a_loss: 0.557
Train: Epoch [256/3000], Step [90/158]| g_loss: 1.093| d_loss: 0.593| gp_loss: 0.041| r_loss: 0.239| p_loss: 0.353| v_loss: 0.052| per_loss: 0.686 | a_loss: 0.557
Train: Epoch [256/3000], Step [120/158]| g_loss: 1.090| d_loss: 0.548| gp_loss: 0.045| r_loss: 0.235| p_loss: 0.340| v_loss: 0.052| per_loss: 0.714 | a_loss: 0.562
Train: Epoch [256/3000], Step [150/158]| g_loss: 1.108| d_loss: 0.545| gp_loss: 0.047| r_loss: 0.244| p_loss: 0.357| v_loss: 0.054| per_loss: 0.686 | a_loss: 0.562
Train: Epoch [257/3000], Step [30/158]| g_loss: 1.054| d_loss: 0.710| gp_loss: 0.118| r_loss: 0.237| p_loss: 0.350| v_loss: 0.050| per_loss: 0.721 | a_loss: 0.521
Train: Epoch [257/3000], Step [60/158]| g_loss: 1.111| d_loss: 0.521| gp_loss: 0.041| r_loss: 0.232| p_loss: 0.333| v_loss: 0.050| per_loss: 0.702 | a_loss: 0.592
Train: Epoch [257/3000], Step [90/158]| g_loss: 1.100| d_loss: 0.586| gp_loss: 0.042| r_loss: 0.232| p_loss: 0.355| v_loss: 0.052| per_loss: 0.701 | a_loss: 0.569
Train: Epoch [257/3000], Step [120/158]| g_loss: 1.031| d_loss: 0.624| gp_loss: 0.045| r_loss: 0.244| p_loss: 0.354| v_loss: 0.052| per_loss: 0.687 | a_loss: 0.490
Train: Epoch [257/3000], Step [150/158]| g_loss: 1.078| d_loss: 0.573| gp_loss: 0.044| r_loss: 0.239| p_loss: 0.354| v_loss: 0.048| per_loss: 0.730 | a_loss: 0.541
Train: Epoch [258/3000], Step [30/158]| g_loss: 1.056| d_loss: 0.673| gp_loss: 0.121| r_loss: 0.232| p_loss: 0.343| v_loss: 0.051| per_loss: 0.731 | a_loss: 0.529
Train: Epoch [258/3000], Step [60/158]| g_loss: 1.064| d_loss: 0.591| gp_loss: 0.045| r_loss: 0.234| p_loss: 0.343| v_loss: 0.049| per_loss: 0.689 | a_loss: 0.541
Train: Epoch [258/3000], Step [90/158]| g_loss: 1.084| d_loss: 0.605| gp_loss: 0.048| r_loss: 0.243| p_loss: 0.362| v_loss: 0.050| per_loss: 0.741 | a_loss: 0.536
Train: Epoch [258/3000], Step [120/158]| g_loss: 1.112| d_loss: 0.511| gp_loss: 0.047| r_loss: 0.231| p_loss: 0.337| v_loss: 0.050| per_loss: 0.699 | a_loss: 0.591
Train: Epoch [258/3000], Step [150/158]| g_loss: 1.065| d_loss: 0.558| gp_loss: 0.049| r_loss: 0.227| p_loss: 0.342| v_loss: 0.048| per_loss: 0.657 | a_loss: 0.553
Train: Epoch [259/3000], Step [30/158]| g_loss: 1.041| d_loss: 0.803| gp_loss: 0.196| r_loss: 0.237| p_loss: 0.347| v_loss: 0.048| per_loss: 0.717 | a_loss: 0.512
Train: Epoch [259/3000], Step [60/158]| g_loss: 1.022| d_loss: 0.611| gp_loss: 0.044| r_loss: 0.230| p_loss: 0.338| v_loss: 0.048| per_loss: 0.689 | a_loss: 0.506
Train: Epoch [259/3000], Step [90/158]| g_loss: 1.126| d_loss: 0.457| gp_loss: 0.043| r_loss: 0.226| p_loss: 0.348| v_loss: 0.052| per_loss: 0.678 | a_loss: 0.607
Train: Epoch [259/3000], Step [120/158]| g_loss: 1.012| d_loss: 0.629| gp_loss: 0.046| r_loss: 0.214| p_loss: 0.327| v_loss: 0.049| per_loss: 0.659 | a_loss: 0.520
Train: Epoch [259/3000], Step [150/158]| g_loss: 1.106| d_loss: 0.523| gp_loss: 0.045| r_loss: 0.237| p_loss: 0.332| v_loss: 0.050| per_loss: 0.686 | a_loss: 0.584
Train: Epoch [260/3000], Step [30/158]| g_loss: 1.071| d_loss: 0.705| gp_loss: 0.117| r_loss: 0.245| p_loss: 0.340| v_loss: 0.050| per_loss: 0.713 | a_loss: 0.536
Train: Epoch [260/3000], Step [60/158]| g_loss: 1.082| d_loss: 0.529| gp_loss: 0.043| r_loss: 0.231| p_loss: 0.337| v_loss: 0.051| per_loss: 0.716 | a_loss: 0.560
Train: Epoch [260/3000], Step [90/158]| g_loss: 1.053| d_loss: 0.601| gp_loss: 0.047| r_loss: 0.239| p_loss: 0.350| v_loss: 0.051| per_loss: 0.673 | a_loss: 0.521
Train: Epoch [260/3000], Step [120/158]| g_loss: 1.086| d_loss: 0.572| gp_loss: 0.043| r_loss: 0.237| p_loss: 0.356| v_loss: 0.051| per_loss: 0.684 | a_loss: 0.552
Train: Epoch [260/3000], Step [150/158]| g_loss: 1.080| d_loss: 0.550| gp_loss: 0.046| r_loss: 0.220| p_loss: 0.342| v_loss: 0.050| per_loss: 0.694 | a_loss: 0.570
Train: Epoch [261/3000], Step [30/158]| g_loss: 0.989| d_loss: 0.816| gp_loss: 0.125| r_loss: 0.240| p_loss: 0.349| v_loss: 0.051| per_loss: 0.668 | a_loss: 0.457
Train: Epoch [261/3000], Step [60/158]| g_loss: 1.027| d_loss: 0.607| gp_loss: 0.043| r_loss: 0.225| p_loss: 0.342| v_loss: 0.052| per_loss: 0.710 | a_loss: 0.509
Train: Epoch [261/3000], Step [90/158]| g_loss: 1.144| d_loss: 0.481| gp_loss: 0.043| r_loss: 0.237| p_loss: 0.343| v_loss: 0.051| per_loss: 0.692 | a_loss: 0.616
Train: Epoch [261/3000], Step [120/158]| g_loss: 1.033| d_loss: 0.634| gp_loss: 0.051| r_loss: 0.229| p_loss: 0.344| v_loss: 0.047| per_loss: 0.688 | a_loss: 0.516
Train: Epoch [261/3000], Step [150/158]| g_loss: 1.057| d_loss: 0.609| gp_loss: 0.050| r_loss: 0.227| p_loss: 0.345| v_loss: 0.045| per_loss: 0.711 | a_loss: 0.541
Train: Epoch [262/3000], Step [30/158]| g_loss: 1.120| d_loss: 0.645| gp_loss: 0.147| r_loss: 0.242| p_loss: 0.358| v_loss: 0.050| per_loss: 0.733 | a_loss: 0.576
Train: Epoch [262/3000], Step [60/158]| g_loss: 1.078| d_loss: 0.593| gp_loss: 0.044| r_loss: 0.225| p_loss: 0.351| v_loss: 0.049| per_loss: 0.660 | a_loss: 0.562
Train: Epoch [262/3000], Step [90/158]| g_loss: 1.047| d_loss: 0.582| gp_loss: 0.047| r_loss: 0.226| p_loss: 0.349| v_loss: 0.049| per_loss: 0.702 | a_loss: 0.527
Train: Epoch [262/3000], Step [120/158]| g_loss: 1.040| d_loss: 0.676| gp_loss: 0.046| r_loss: 0.227| p_loss: 0.347| v_loss: 0.051| per_loss: 0.685 | a_loss: 0.520
Train: Epoch [262/3000], Step [150/158]| g_loss: 1.047| d_loss: 0.644| gp_loss: 0.044| r_loss: 0.253| p_loss: 0.358| v_loss: 0.051| per_loss: 0.680 | a_loss: 0.496
Train: Epoch [263/3000], Step [30/158]| g_loss: 1.102| d_loss: 0.607| gp_loss: 0.078| r_loss: 0.246| p_loss: 0.348| v_loss: 0.050| per_loss: 0.711 | a_loss: 0.561
Train: Epoch [263/3000], Step [60/158]| g_loss: 1.029| d_loss: 0.595| gp_loss: 0.049| r_loss: 0.224| p_loss: 0.338| v_loss: 0.046| per_loss: 0.714 | a_loss: 0.519
Train: Epoch [263/3000], Step [90/158]| g_loss: 1.068| d_loss: 0.569| gp_loss: 0.047| r_loss: 0.234| p_loss: 0.349| v_loss: 0.050| per_loss: 0.665 | a_loss: 0.543
Train: Epoch [263/3000], Step [120/158]| g_loss: 1.066| d_loss: 0.597| gp_loss: 0.045| r_loss: 0.223| p_loss: 0.345| v_loss: 0.047| per_loss: 0.698 | a_loss: 0.553
Train: Epoch [263/3000], Step [150/158]| g_loss: 1.045| d_loss: 0.620| gp_loss: 0.049| r_loss: 0.238| p_loss: 0.357| v_loss: 0.050| per_loss: 0.682 | a_loss: 0.510
Train: Epoch [264/3000], Step [30/158]| g_loss: 1.091| d_loss: 0.548| gp_loss: 0.107| r_loss: 0.217| p_loss: 0.341| v_loss: 0.048| per_loss: 0.674 | a_loss: 0.589
Train: Epoch [264/3000], Step [60/158]| g_loss: 1.058| d_loss: 0.650| gp_loss: 0.048| r_loss: 0.238| p_loss: 0.339| v_loss: 0.051| per_loss: 0.710 | a_loss: 0.528
Train: Epoch [264/3000], Step [90/158]| g_loss: 0.991| d_loss: 0.729| gp_loss: 0.051| r_loss: 0.248| p_loss: 0.356| v_loss: 0.049| per_loss: 0.668 | a_loss: 0.450
Train: Epoch [264/3000], Step [120/158]| g_loss: 1.080| d_loss: 0.557| gp_loss: 0.047| r_loss: 0.219| p_loss: 0.349| v_loss: 0.050| per_loss: 0.675 | a_loss: 0.569
Train: Epoch [264/3000], Step [150/158]| g_loss: 1.069| d_loss: 0.591| gp_loss: 0.048| r_loss: 0.237| p_loss: 0.350| v_loss: 0.050| per_loss: 0.690 | a_loss: 0.538
Train: Epoch [265/3000], Step [30/158]| g_loss: 1.114| d_loss: 0.568| gp_loss: 0.093| r_loss: 0.233| p_loss: 0.341| v_loss: 0.050| per_loss: 0.694 | a_loss: 0.591
Train: Epoch [265/3000], Step [60/158]| g_loss: 1.031| d_loss: 0.644| gp_loss: 0.052| r_loss: 0.245| p_loss: 0.351| v_loss: 0.048| per_loss: 0.690 | a_loss: 0.494
Train: Epoch [265/3000], Step [90/158]| g_loss: 1.141| d_loss: 0.514| gp_loss: 0.046| r_loss: 0.232| p_loss: 0.350| v_loss: 0.050| per_loss: 0.662 | a_loss: 0.617
Train: Epoch [265/3000], Step [120/158]| g_loss: 1.031| d_loss: 0.636| gp_loss: 0.053| r_loss: 0.219| p_loss: 0.331| v_loss: 0.051| per_loss: 0.645 | a_loss: 0.530
Train: Epoch [265/3000], Step [150/158]| g_loss: 1.000| d_loss: 0.697| gp_loss: 0.052| r_loss: 0.220| p_loss: 0.347| v_loss: 0.049| per_loss: 0.657 | a_loss: 0.492
Train: Epoch [266/3000], Step [30/158]| g_loss: 1.050| d_loss: 0.719| gp_loss: 0.151| r_loss: 0.235| p_loss: 0.361| v_loss: 0.052| per_loss: 0.685 | a_loss: 0.515
Train: Epoch [266/3000], Step [60/158]| g_loss: 1.069| d_loss: 0.549| gp_loss: 0.047| r_loss: 0.240| p_loss: 0.354| v_loss: 0.051| per_loss: 0.664 | a_loss: 0.535
Train: Epoch [266/3000], Step [90/158]| g_loss: 1.041| d_loss: 0.629| gp_loss: 0.047| r_loss: 0.232| p_loss: 0.346| v_loss: 0.050| per_loss: 0.651 | a_loss: 0.522
Train: Epoch [266/3000], Step [120/158]| g_loss: 1.097| d_loss: 0.574| gp_loss: 0.046| r_loss: 0.231| p_loss: 0.339| v_loss: 0.049| per_loss: 0.650 | a_loss: 0.583
Train: Epoch [266/3000], Step [150/158]| g_loss: 1.039| d_loss: 0.612| gp_loss: 0.052| r_loss: 0.233| p_loss: 0.352| v_loss: 0.049| per_loss: 0.664 | a_loss: 0.514
Train: Epoch [267/3000], Step [30/158]| g_loss: 0.987| d_loss: 0.840| gp_loss: 0.140| r_loss: 0.223| p_loss: 0.357| v_loss: 0.048| per_loss: 0.655 | a_loss: 0.471
Train: Epoch [267/3000], Step [60/158]| g_loss: 1.047| d_loss: 0.551| gp_loss: 0.046| r_loss: 0.226| p_loss: 0.337| v_loss: 0.048| per_loss: 0.679 | a_loss: 0.537
Train: Epoch [267/3000], Step [90/158]| g_loss: 1.074| d_loss: 0.618| gp_loss: 0.043| r_loss: 0.238| p_loss: 0.347| v_loss: 0.048| per_loss: 0.682 | a_loss: 0.546
Train: Epoch [267/3000], Step [120/158]| g_loss: 1.033| d_loss: 0.562| gp_loss: 0.044| r_loss: 0.229| p_loss: 0.332| v_loss: 0.049| per_loss: 0.593 | a_loss: 0.530
Train: Epoch [267/3000], Step [150/158]| g_loss: 1.082| d_loss: 0.532| gp_loss: 0.046| r_loss: 0.224| p_loss: 0.329| v_loss: 0.048| per_loss: 0.673 | a_loss: 0.578
Train: Epoch [268/3000], Step [30/158]| g_loss: 1.071| d_loss: 0.666| gp_loss: 0.113| r_loss: 0.232| p_loss: 0.347| v_loss: 0.051| per_loss: 0.631 | a_loss: 0.552
Train: Epoch [268/3000], Step [60/158]| g_loss: 1.020| d_loss: 0.648| gp_loss: 0.045| r_loss: 0.224| p_loss: 0.337| v_loss: 0.050| per_loss: 0.656 | a_loss: 0.512
Train: Epoch [268/3000], Step [90/158]| g_loss: 1.070| d_loss: 0.638| gp_loss: 0.043| r_loss: 0.238| p_loss: 0.342| v_loss: 0.049| per_loss: 0.640 | a_loss: 0.548
Train: Epoch [268/3000], Step [120/158]| g_loss: 1.053| d_loss: 0.552| gp_loss: 0.045| r_loss: 0.229| p_loss: 0.339| v_loss: 0.049| per_loss: 0.649 | a_loss: 0.542
Train: Epoch [268/3000], Step [150/158]| g_loss: 1.033| d_loss: 0.562| gp_loss: 0.045| r_loss: 0.217| p_loss: 0.344| v_loss: 0.050| per_loss: 0.628 | a_loss: 0.531
Train: Epoch [269/3000], Step [30/158]| g_loss: 1.042| d_loss: 0.756| gp_loss: 0.128| r_loss: 0.245| p_loss: 0.351| v_loss: 0.048| per_loss: 0.651 | a_loss: 0.508
Train: Epoch [269/3000], Step [60/158]| g_loss: 1.143| d_loss: 0.499| gp_loss: 0.041| r_loss: 0.254| p_loss: 0.348| v_loss: 0.049| per_loss: 0.660 | a_loss: 0.599
Train: Epoch [269/3000], Step [90/158]| g_loss: 1.059| d_loss: 0.542| gp_loss: 0.045| r_loss: 0.210| p_loss: 0.336| v_loss: 0.048| per_loss: 0.663 | a_loss: 0.567
Train: Epoch [269/3000], Step [120/158]| g_loss: 1.056| d_loss: 0.626| gp_loss: 0.045| r_loss: 0.224| p_loss: 0.348| v_loss: 0.048| per_loss: 0.676 | a_loss: 0.543
Train: Epoch [269/3000], Step [150/158]| g_loss: 0.998| d_loss: 0.621| gp_loss: 0.046| r_loss: 0.224| p_loss: 0.331| v_loss: 0.047| per_loss: 0.641 | a_loss: 0.497
Train: Epoch [270/3000], Step [30/158]| g_loss: 1.056| d_loss: 0.633| gp_loss: 0.078| r_loss: 0.222| p_loss: 0.355| v_loss: 0.047| per_loss: 0.710 | a_loss: 0.539
Train: Epoch [270/3000], Step [60/158]| g_loss: 1.076| d_loss: 0.577| gp_loss: 0.046| r_loss: 0.246| p_loss: 0.359| v_loss: 0.049| per_loss: 0.647 | a_loss: 0.538
Train: Epoch [270/3000], Step [90/158]| g_loss: 1.123| d_loss: 0.491| gp_loss: 0.043| r_loss: 0.219| p_loss: 0.336| v_loss: 0.048| per_loss: 0.708 | a_loss: 0.618
Train: Epoch [270/3000], Step [120/158]| g_loss: 1.028| d_loss: 0.645| gp_loss: 0.049| r_loss: 0.237| p_loss: 0.344| v_loss: 0.049| per_loss: 0.665 | a_loss: 0.503
Train: Epoch [270/3000], Step [150/158]| g_loss: 0.967| d_loss: 0.739| gp_loss: 0.046| r_loss: 0.214| p_loss: 0.336| v_loss: 0.050| per_loss: 0.676 | a_loss: 0.468
Train: Epoch [271/3000], Step [30/158]| g_loss: 1.099| d_loss: 0.626| gp_loss: 0.102| r_loss: 0.268| p_loss: 0.336| v_loss: 0.048| per_loss: 0.682 | a_loss: 0.547
Train: Epoch [271/3000], Step [60/158]| g_loss: 1.026| d_loss: 0.597| gp_loss: 0.048| r_loss: 0.227| p_loss: 0.331| v_loss: 0.046| per_loss: 0.627 | a_loss: 0.524
Train: Epoch [271/3000], Step [90/158]| g_loss: 1.033| d_loss: 0.604| gp_loss: 0.048| r_loss: 0.221| p_loss: 0.326| v_loss: 0.047| per_loss: 0.665 | a_loss: 0.535
Train: Epoch [271/3000], Step [120/158]| g_loss: 1.087| d_loss: 0.553| gp_loss: 0.041| r_loss: 0.223| p_loss: 0.347| v_loss: 0.049| per_loss: 0.665 | a_loss: 0.575
Train: Epoch [271/3000], Step [150/158]| g_loss: 0.997| d_loss: 0.657| gp_loss: 0.048| r_loss: 0.222| p_loss: 0.329| v_loss: 0.048| per_loss: 0.689 | a_loss: 0.495
Train: Epoch [272/3000], Step [30/158]| g_loss: 1.061| d_loss: 0.593| gp_loss: 0.097| r_loss: 0.212| p_loss: 0.334| v_loss: 0.049| per_loss: 0.693 | a_loss: 0.564
Train: Epoch [272/3000], Step [60/158]| g_loss: 1.082| d_loss: 0.588| gp_loss: 0.046| r_loss: 0.225| p_loss: 0.327| v_loss: 0.048| per_loss: 0.749 | a_loss: 0.570
Train: Epoch [272/3000], Step [90/158]| g_loss: 1.028| d_loss: 0.649| gp_loss: 0.046| r_loss: 0.228| p_loss: 0.338| v_loss: 0.049| per_loss: 0.658 | a_loss: 0.516
Train: Epoch [272/3000], Step [120/158]| g_loss: 1.071| d_loss: 0.496| gp_loss: 0.047| r_loss: 0.216| p_loss: 0.321| v_loss: 0.048| per_loss: 0.660 | a_loss: 0.581
Train: Epoch [272/3000], Step [150/158]| g_loss: 1.043| d_loss: 0.659| gp_loss: 0.050| r_loss: 0.240| p_loss: 0.355| v_loss: 0.048| per_loss: 0.633 | a_loss: 0.514
Train: Epoch [273/3000], Step [30/158]| g_loss: 1.105| d_loss: 0.608| gp_loss: 0.075| r_loss: 0.233| p_loss: 0.345| v_loss: 0.051| per_loss: 0.660 | a_loss: 0.583
Train: Epoch [273/3000], Step [60/158]| g_loss: 0.994| d_loss: 0.682| gp_loss: 0.050| r_loss: 0.208| p_loss: 0.338| v_loss: 0.047| per_loss: 0.664 | a_loss: 0.504
Train: Epoch [273/3000], Step [90/158]| g_loss: 1.032| d_loss: 0.595| gp_loss: 0.049| r_loss: 0.217| p_loss: 0.344| v_loss: 0.048| per_loss: 0.670 | a_loss: 0.528
Train: Epoch [273/3000], Step [120/158]| g_loss: 1.072| d_loss: 0.562| gp_loss: 0.050| r_loss: 0.237| p_loss: 0.330| v_loss: 0.046| per_loss: 0.730 | a_loss: 0.552
Train: Epoch [273/3000], Step [150/158]| g_loss: 1.101| d_loss: 0.477| gp_loss: 0.048| r_loss: 0.220| p_loss: 0.328| v_loss: 0.048| per_loss: 0.699 | a_loss: 0.600
Train: Epoch [274/3000], Step [30/158]| g_loss: 1.116| d_loss: 0.661| gp_loss: 0.127| r_loss: 0.220| p_loss: 0.335| v_loss: 0.050| per_loss: 0.706 | a_loss: 0.609
Train: Epoch [274/3000], Step [60/158]| g_loss: 1.027| d_loss: 0.671| gp_loss: 0.045| r_loss: 0.238| p_loss: 0.340| v_loss: 0.048| per_loss: 0.676 | a_loss: 0.504
Train: Epoch [274/3000], Step [90/158]| g_loss: 1.036| d_loss: 0.535| gp_loss: 0.045| r_loss: 0.208| p_loss: 0.323| v_loss: 0.051| per_loss: 0.639 | a_loss: 0.552
Train: Epoch [274/3000], Step [120/158]| g_loss: 1.007| d_loss: 0.619| gp_loss: 0.051| r_loss: 0.217| p_loss: 0.327| v_loss: 0.048| per_loss: 0.639 | a_loss: 0.515
Train: Epoch [274/3000], Step [150/158]| g_loss: 1.090| d_loss: 0.577| gp_loss: 0.047| r_loss: 0.230| p_loss: 0.331| v_loss: 0.047| per_loss: 0.677 | a_loss: 0.580
Train: Epoch [275/3000], Step [30/158]| g_loss: 1.103| d_loss: 0.611| gp_loss: 0.173| r_loss: 0.221| p_loss: 0.329| v_loss: 0.047| per_loss: 0.623 | a_loss: 0.607
Train: Epoch [275/3000], Step [60/158]| g_loss: 1.008| d_loss: 0.617| gp_loss: 0.046| r_loss: 0.231| p_loss: 0.321| v_loss: 0.048| per_loss: 0.665 | a_loss: 0.502
Train: Epoch [275/3000], Step [90/158]| g_loss: 1.050| d_loss: 0.595| gp_loss: 0.045| r_loss: 0.201| p_loss: 0.314| v_loss: 0.046| per_loss: 0.720 | a_loss: 0.574
Train: Epoch [275/3000], Step [120/158]| g_loss: 1.028| d_loss: 0.642| gp_loss: 0.044| r_loss: 0.228| p_loss: 0.337| v_loss: 0.049| per_loss: 0.679 | a_loss: 0.515
Train: Epoch [275/3000], Step [150/158]| g_loss: 1.008| d_loss: 0.649| gp_loss: 0.043| r_loss: 0.212| p_loss: 0.322| v_loss: 0.047| per_loss: 0.714 | a_loss: 0.516
Train: Epoch [276/3000], Step [30/158]| g_loss: 1.020| d_loss: 0.702| gp_loss: 0.099| r_loss: 0.231| p_loss: 0.332| v_loss: 0.049| per_loss: 0.718 | a_loss: 0.502
Train: Epoch [276/3000], Step [60/158]| g_loss: 1.048| d_loss: 0.610| gp_loss: 0.043| r_loss: 0.226| p_loss: 0.331| v_loss: 0.047| per_loss: 0.663 | a_loss: 0.543
Train: Epoch [276/3000], Step [90/158]| g_loss: 1.013| d_loss: 0.637| gp_loss: 0.051| r_loss: 0.232| p_loss: 0.325| v_loss: 0.047| per_loss: 0.650 | a_loss: 0.506
Train: Epoch [276/3000], Step [120/158]| g_loss: 1.077| d_loss: 0.556| gp_loss: 0.046| r_loss: 0.204| p_loss: 0.322| v_loss: 0.049| per_loss: 0.678 | a_loss: 0.595
Train: Epoch [276/3000], Step [150/158]| g_loss: 1.083| d_loss: 0.536| gp_loss: 0.047| r_loss: 0.205| p_loss: 0.315| v_loss: 0.050| per_loss: 0.661 | a_loss: 0.604
Train: Epoch [277/3000], Step [30/158]| g_loss: 1.072| d_loss: 0.623| gp_loss: 0.146| r_loss: 0.211| p_loss: 0.326| v_loss: 0.051| per_loss: 0.689 | a_loss: 0.578
Train: Epoch [277/3000], Step [60/158]| g_loss: 1.072| d_loss: 0.540| gp_loss: 0.043| r_loss: 0.228| p_loss: 0.335| v_loss: 0.047| per_loss: 0.629 | a_loss: 0.567
Train: Epoch [277/3000], Step [90/158]| g_loss: 1.014| d_loss: 0.654| gp_loss: 0.048| r_loss: 0.233| p_loss: 0.329| v_loss: 0.047| per_loss: 0.648 | a_loss: 0.505
Train: Epoch [277/3000], Step [120/158]| g_loss: 1.103| d_loss: 0.496| gp_loss: 0.044| r_loss: 0.219| p_loss: 0.316| v_loss: 0.047| per_loss: 0.714 | a_loss: 0.607
Train: Epoch [277/3000], Step [150/158]| g_loss: 1.026| d_loss: 0.604| gp_loss: 0.048| r_loss: 0.213| p_loss: 0.324| v_loss: 0.048| per_loss: 0.686 | a_loss: 0.535
Train: Epoch [278/3000], Step [30/158]| g_loss: 1.033| d_loss: 0.668| gp_loss: 0.118| r_loss: 0.211| p_loss: 0.325| v_loss: 0.048| per_loss: 0.646 | a_loss: 0.547
Train: Epoch [278/3000], Step [60/158]| g_loss: 1.015| d_loss: 0.583| gp_loss: 0.045| r_loss: 0.207| p_loss: 0.321| v_loss: 0.048| per_loss: 0.689 | a_loss: 0.530
Train: Epoch [278/3000], Step [90/158]| g_loss: 1.046| d_loss: 0.620| gp_loss: 0.046| r_loss: 0.220| p_loss: 0.327| v_loss: 0.049| per_loss: 0.691 | a_loss: 0.546
Train: Epoch [278/3000], Step [120/158]| g_loss: 1.074| d_loss: 0.571| gp_loss: 0.047| r_loss: 0.244| p_loss: 0.333| v_loss: 0.049| per_loss: 0.713 | a_loss: 0.543
Train: Epoch [278/3000], Step [150/158]| g_loss: 1.059| d_loss: 0.592| gp_loss: 0.043| r_loss: 0.213| p_loss: 0.317| v_loss: 0.047| per_loss: 0.669 | a_loss: 0.574
Train: Epoch [279/3000], Step [30/158]| g_loss: 1.088| d_loss: 0.598| gp_loss: 0.109| r_loss: 0.218| p_loss: 0.318| v_loss: 0.049| per_loss: 0.651 | a_loss: 0.596
Train: Epoch [279/3000], Step [60/158]| g_loss: 1.007| d_loss: 0.573| gp_loss: 0.044| r_loss: 0.214| p_loss: 0.319| v_loss: 0.047| per_loss: 0.638 | a_loss: 0.524
Train: Epoch [279/3000], Step [90/158]| g_loss: 1.023| d_loss: 0.640| gp_loss: 0.047| r_loss: 0.215| p_loss: 0.333| v_loss: 0.047| per_loss: 0.671 | a_loss: 0.527
Train: Epoch [279/3000], Step [120/158]| g_loss: 1.047| d_loss: 0.613| gp_loss: 0.046| r_loss: 0.228| p_loss: 0.334| v_loss: 0.047| per_loss: 0.707 | a_loss: 0.535
Train: Epoch [279/3000], Step [150/158]| g_loss: 1.109| d_loss: 0.526| gp_loss: 0.044| r_loss: 0.232| p_loss: 0.326| v_loss: 0.047| per_loss: 0.729 | a_loss: 0.595
Train: Epoch [280/3000], Step [30/158]| g_loss: 1.058| d_loss: 0.657| gp_loss: 0.156| r_loss: 0.223| p_loss: 0.321| v_loss: 0.047| per_loss: 0.656 | a_loss: 0.561
Train: Epoch [280/3000], Step [60/158]| g_loss: 1.026| d_loss: 0.584| gp_loss: 0.042| r_loss: 0.222| p_loss: 0.315| v_loss: 0.049| per_loss: 0.662 | a_loss: 0.531
Train: Epoch [280/3000], Step [90/158]| g_loss: 1.072| d_loss: 0.578| gp_loss: 0.043| r_loss: 0.214| p_loss: 0.322| v_loss: 0.048| per_loss: 0.659 | a_loss: 0.583
Train: Epoch [280/3000], Step [120/158]| g_loss: 1.042| d_loss: 0.554| gp_loss: 0.044| r_loss: 0.223| p_loss: 0.316| v_loss: 0.047| per_loss: 0.673 | a_loss: 0.546
Train: Epoch [280/3000], Step [150/158]| g_loss: 1.090| d_loss: 0.582| gp_loss: 0.043| r_loss: 0.219| p_loss: 0.329| v_loss: 0.050| per_loss: 0.692 | a_loss: 0.588
Train: Epoch [281/3000], Step [30/158]| g_loss: 1.024| d_loss: 0.685| gp_loss: 0.155| r_loss: 0.207| p_loss: 0.314| v_loss: 0.046| per_loss: 0.621 | a_loss: 0.552
Train: Epoch [281/3000], Step [60/158]| g_loss: 1.047| d_loss: 0.589| gp_loss: 0.044| r_loss: 0.226| p_loss: 0.322| v_loss: 0.046| per_loss: 0.672 | a_loss: 0.546
Train: Epoch [281/3000], Step [90/158]| g_loss: 1.050| d_loss: 0.586| gp_loss: 0.041| r_loss: 0.210| p_loss: 0.306| v_loss: 0.050| per_loss: 0.696 | a_loss: 0.567
Train: Epoch [281/3000], Step [120/158]| g_loss: 1.037| d_loss: 0.540| gp_loss: 0.045| r_loss: 0.221| p_loss: 0.315| v_loss: 0.049| per_loss: 0.672 | a_loss: 0.543
Train: Epoch [281/3000], Step [150/158]| g_loss: 1.053| d_loss: 0.551| gp_loss: 0.045| r_loss: 0.215| p_loss: 0.324| v_loss: 0.047| per_loss: 0.682 | a_loss: 0.560
Train: Epoch [282/3000], Step [30/158]| g_loss: 1.083| d_loss: 0.580| gp_loss: 0.100| r_loss: 0.217| p_loss: 0.315| v_loss: 0.050| per_loss: 0.665 | a_loss: 0.592
Train: Epoch [282/3000], Step [60/158]| g_loss: 0.988| d_loss: 0.652| gp_loss: 0.044| r_loss: 0.221| p_loss: 0.309| v_loss: 0.048| per_loss: 0.652 | a_loss: 0.500
Train: Epoch [282/3000], Step [90/158]| g_loss: 1.032| d_loss: 0.555| gp_loss: 0.046| r_loss: 0.204| p_loss: 0.310| v_loss: 0.049| per_loss: 0.674 | a_loss: 0.558
Train: Epoch [282/3000], Step [120/158]| g_loss: 1.027| d_loss: 0.592| gp_loss: 0.049| r_loss: 0.214| p_loss: 0.327| v_loss: 0.046| per_loss: 0.678 | a_loss: 0.536
Train: Epoch [282/3000], Step [150/158]| g_loss: 1.106| d_loss: 0.530| gp_loss: 0.044| r_loss: 0.221| p_loss: 0.322| v_loss: 0.047| per_loss: 0.706 | a_loss: 0.606
Train: Epoch [283/3000], Step [30/158]| g_loss: 1.094| d_loss: 0.574| gp_loss: 0.090| r_loss: 0.231| p_loss: 0.326| v_loss: 0.048| per_loss: 0.668 | a_loss: 0.584
Train: Epoch [283/3000], Step [60/158]| g_loss: 1.064| d_loss: 0.575| gp_loss: 0.049| r_loss: 0.216| p_loss: 0.313| v_loss: 0.048| per_loss: 0.645 | a_loss: 0.578
Train: Epoch [283/3000], Step [90/158]| g_loss: 0.956| d_loss: 0.650| gp_loss: 0.048| r_loss: 0.208| p_loss: 0.309| v_loss: 0.046| per_loss: 0.666 | a_loss: 0.482
Train: Epoch [283/3000], Step [120/158]| g_loss: 1.038| d_loss: 0.590| gp_loss: 0.045| r_loss: 0.223| p_loss: 0.320| v_loss: 0.046| per_loss: 0.678 | a_loss: 0.540
Train: Epoch [283/3000], Step [150/158]| g_loss: 1.093| d_loss: 0.533| gp_loss: 0.044| r_loss: 0.209| p_loss: 0.314| v_loss: 0.047| per_loss: 0.670 | a_loss: 0.613
Train: Epoch [284/3000], Step [30/158]| g_loss: 1.017| d_loss: 0.675| gp_loss: 0.101| r_loss: 0.216| p_loss: 0.319| v_loss: 0.049| per_loss: 0.659 | a_loss: 0.527
Train: Epoch [284/3000], Step [60/158]| g_loss: 1.099| d_loss: 0.451| gp_loss: 0.046| r_loss: 0.221| p_loss: 0.312| v_loss: 0.050| per_loss: 0.644 | a_loss: 0.608
Train: Epoch [284/3000], Step [90/158]| g_loss: 1.117| d_loss: 0.552| gp_loss: 0.045| r_loss: 0.225| p_loss: 0.323| v_loss: 0.047| per_loss: 0.648 | a_loss: 0.618
Train: Epoch [284/3000], Step [120/158]| g_loss: 1.036| d_loss: 0.613| gp_loss: 0.047| r_loss: 0.222| p_loss: 0.318| v_loss: 0.048| per_loss: 0.689 | a_loss: 0.538
Train: Epoch [284/3000], Step [150/158]| g_loss: 1.019| d_loss: 0.557| gp_loss: 0.047| r_loss: 0.195| p_loss: 0.307| v_loss: 0.047| per_loss: 0.669 | a_loss: 0.556
Train: Epoch [285/3000], Step [30/158]| g_loss: 1.048| d_loss: 0.626| gp_loss: 0.138| r_loss: 0.218| p_loss: 0.310| v_loss: 0.046| per_loss: 0.667 | a_loss: 0.562
Train: Epoch [285/3000], Step [60/158]| g_loss: 1.092| d_loss: 0.552| gp_loss: 0.045| r_loss: 0.215| p_loss: 0.306| v_loss: 0.049| per_loss: 0.635 | a_loss: 0.611
Train: Epoch [285/3000], Step [90/158]| g_loss: 0.998| d_loss: 0.618| gp_loss: 0.047| r_loss: 0.206| p_loss: 0.305| v_loss: 0.046| per_loss: 0.652 | a_loss: 0.528
Train: Epoch [285/3000], Step [120/158]| g_loss: 0.986| d_loss: 0.606| gp_loss: 0.048| r_loss: 0.200| p_loss: 0.303| v_loss: 0.048| per_loss: 0.660 | a_loss: 0.521
Train: Epoch [285/3000], Step [150/158]| g_loss: 1.037| d_loss: 0.550| gp_loss: 0.048| r_loss: 0.211| p_loss: 0.319| v_loss: 0.047| per_loss: 0.629 | a_loss: 0.557
Train: Epoch [286/3000], Step [30/158]| g_loss: 1.018| d_loss: 0.723| gp_loss: 0.099| r_loss: 0.228| p_loss: 0.316| v_loss: 0.045| per_loss: 0.731 | a_loss: 0.514
Train: Epoch [286/3000], Step [60/158]| g_loss: 1.084| d_loss: 0.509| gp_loss: 0.042| r_loss: 0.213| p_loss: 0.310| v_loss: 0.049| per_loss: 0.681 | a_loss: 0.600
Train: Epoch [286/3000], Step [90/158]| g_loss: 0.991| d_loss: 0.600| gp_loss: 0.046| r_loss: 0.197| p_loss: 0.317| v_loss: 0.047| per_loss: 0.663 | a_loss: 0.522
Train: Epoch [286/3000], Step [120/158]| g_loss: 1.044| d_loss: 0.556| gp_loss: 0.048| r_loss: 0.216| p_loss: 0.319| v_loss: 0.047| per_loss: 0.688 | a_loss: 0.553
Train: Epoch [286/3000], Step [150/158]| g_loss: 1.037| d_loss: 0.602| gp_loss: 0.048| r_loss: 0.212| p_loss: 0.321| v_loss: 0.048| per_loss: 0.674 | a_loss: 0.550
Train: Epoch [287/3000], Step [30/158]| g_loss: 1.080| d_loss: 0.644| gp_loss: 0.162| r_loss: 0.208| p_loss: 0.312| v_loss: 0.047| per_loss: 0.670 | a_loss: 0.601
Train: Epoch [287/3000], Step [60/158]| g_loss: 1.063| d_loss: 0.538| gp_loss: 0.045| r_loss: 0.200| p_loss: 0.320| v_loss: 0.050| per_loss: 0.686 | a_loss: 0.584
Train: Epoch [287/3000], Step [90/158]| g_loss: 1.051| d_loss: 0.609| gp_loss: 0.047| r_loss: 0.226| p_loss: 0.319| v_loss: 0.047| per_loss: 0.702 | a_loss: 0.548
Train: Epoch [287/3000], Step [120/158]| g_loss: 0.951| d_loss: 0.698| gp_loss: 0.049| r_loss: 0.210| p_loss: 0.318| v_loss: 0.046| per_loss: 0.634 | a_loss: 0.472
Train: Epoch [287/3000], Step [150/158]| g_loss: 1.088| d_loss: 0.488| gp_loss: 0.045| r_loss: 0.223| p_loss: 0.311| v_loss: 0.047| per_loss: 0.668 | a_loss: 0.596
Train: Epoch [288/3000], Step [30/158]| g_loss: 1.042| d_loss: 0.655| gp_loss: 0.087| r_loss: 0.220| p_loss: 0.332| v_loss: 0.052| per_loss: 0.694 | a_loss: 0.535
Train: Epoch [288/3000], Step [60/158]| g_loss: 1.045| d_loss: 0.554| gp_loss: 0.049| r_loss: 0.207| p_loss: 0.315| v_loss: 0.046| per_loss: 0.656 | a_loss: 0.569
Train: Epoch [288/3000], Step [90/158]| g_loss: 1.089| d_loss: 0.484| gp_loss: 0.047| r_loss: 0.218| p_loss: 0.311| v_loss: 0.048| per_loss: 0.674 | a_loss: 0.600
Train: Epoch [288/3000], Step [120/158]| g_loss: 1.040| d_loss: 0.596| gp_loss: 0.047| r_loss: 0.202| p_loss: 0.314| v_loss: 0.047| per_loss: 0.621 | a_loss: 0.572
Train: Epoch [288/3000], Step [150/158]| g_loss: 1.008| d_loss: 0.634| gp_loss: 0.051| r_loss: 0.216| p_loss: 0.321| v_loss: 0.048| per_loss: 0.662 | a_loss: 0.517
Train: Epoch [289/3000], Step [30/158]| g_loss: 1.061| d_loss: 0.626| gp_loss: 0.177| r_loss: 0.210| p_loss: 0.312| v_loss: 0.048| per_loss: 0.676 | a_loss: 0.579
Train: Epoch [289/3000], Step [60/158]| g_loss: 1.067| d_loss: 0.609| gp_loss: 0.043| r_loss: 0.211| p_loss: 0.318| v_loss: 0.046| per_loss: 0.682 | a_loss: 0.582
Train: Epoch [289/3000], Step [90/158]| g_loss: 0.996| d_loss: 0.586| gp_loss: 0.046| r_loss: 0.203| p_loss: 0.317| v_loss: 0.048| per_loss: 0.665 | a_loss: 0.520
Train: Epoch [289/3000], Step [120/158]| g_loss: 1.051| d_loss: 0.560| gp_loss: 0.047| r_loss: 0.221| p_loss: 0.323| v_loss: 0.048| per_loss: 0.710 | a_loss: 0.550
Train: Epoch [289/3000], Step [150/158]| g_loss: 1.084| d_loss: 0.576| gp_loss: 0.047| r_loss: 0.221| p_loss: 0.316| v_loss: 0.046| per_loss: 0.663 | a_loss: 0.592
Train: Epoch [290/3000], Step [30/158]| g_loss: 0.980| d_loss: 0.755| gp_loss: 0.131| r_loss: 0.200| p_loss: 0.319| v_loss: 0.047| per_loss: 0.686 | a_loss: 0.505
Train: Epoch [290/3000], Step [60/158]| g_loss: 1.055| d_loss: 0.564| gp_loss: 0.045| r_loss: 0.227| p_loss: 0.310| v_loss: 0.048| per_loss: 0.707 | a_loss: 0.554
Train: Epoch [290/3000], Step [90/158]| g_loss: 1.063| d_loss: 0.525| gp_loss: 0.046| r_loss: 0.211| p_loss: 0.318| v_loss: 0.048| per_loss: 0.667 | a_loss: 0.578
Train: Epoch [290/3000], Step [120/158]| g_loss: 1.068| d_loss: 0.551| gp_loss: 0.046| r_loss: 0.206| p_loss: 0.320| v_loss: 0.048| per_loss: 0.699 | a_loss: 0.584
Train: Epoch [290/3000], Step [150/158]| g_loss: 1.046| d_loss: 0.547| gp_loss: 0.046| r_loss: 0.213| p_loss: 0.320| v_loss: 0.048| per_loss: 0.663 | a_loss: 0.559
Train: Epoch [291/3000], Step [30/158]| g_loss: 1.093| d_loss: 0.615| gp_loss: 0.155| r_loss: 0.222| p_loss: 0.321| v_loss: 0.050| per_loss: 0.641 | a_loss: 0.596
Train: Epoch [291/3000], Step [60/158]| g_loss: 1.045| d_loss: 0.584| gp_loss: 0.043| r_loss: 0.210| p_loss: 0.325| v_loss: 0.048| per_loss: 0.657 | a_loss: 0.559
Train: Epoch [291/3000], Step [90/158]| g_loss: 1.043| d_loss: 0.524| gp_loss: 0.044| r_loss: 0.200| p_loss: 0.305| v_loss: 0.047| per_loss: 0.709 | a_loss: 0.573
Train: Epoch [291/3000], Step [120/158]| g_loss: 1.015| d_loss: 0.606| gp_loss: 0.048| r_loss: 0.204| p_loss: 0.306| v_loss: 0.047| per_loss: 0.632 | a_loss: 0.547
Train: Epoch [291/3000], Step [150/158]| g_loss: 1.058| d_loss: 0.546| gp_loss: 0.045| r_loss: 0.214| p_loss: 0.312| v_loss: 0.047| per_loss: 0.675 | a_loss: 0.574
Train: Epoch [292/3000], Step [30/158]| g_loss: 1.045| d_loss: 0.727| gp_loss: 0.210| r_loss: 0.208| p_loss: 0.312| v_loss: 0.048| per_loss: 0.668 | a_loss: 0.566
Train: Epoch [292/3000], Step [60/158]| g_loss: 1.057| d_loss: 0.517| gp_loss: 0.041| r_loss: 0.206| p_loss: 0.310| v_loss: 0.047| per_loss: 0.636 | a_loss: 0.584
Train: Epoch [292/3000], Step [90/158]| g_loss: 1.058| d_loss: 0.566| gp_loss: 0.044| r_loss: 0.219| p_loss: 0.324| v_loss: 0.048| per_loss: 0.659 | a_loss: 0.563
Train: Epoch [292/3000], Step [120/158]| g_loss: 0.987| d_loss: 0.587| gp_loss: 0.047| r_loss: 0.207| p_loss: 0.308| v_loss: 0.046| per_loss: 0.683 | a_loss: 0.511
Train: Epoch [292/3000], Step [150/158]| g_loss: 1.015| d_loss: 0.571| gp_loss: 0.045| r_loss: 0.202| p_loss: 0.312| v_loss: 0.049| per_loss: 0.653 | a_loss: 0.543
Train: Epoch [293/3000], Step [30/158]| g_loss: 1.028| d_loss: 0.662| gp_loss: 0.129| r_loss: 0.202| p_loss: 0.310| v_loss: 0.047| per_loss: 0.635 | a_loss: 0.560
Train: Epoch [293/3000], Step [60/158]| g_loss: 1.020| d_loss: 0.591| gp_loss: 0.045| r_loss: 0.208| p_loss: 0.299| v_loss: 0.048| per_loss: 0.641 | a_loss: 0.551
Train: Epoch [293/3000], Step [90/158]| g_loss: 1.038| d_loss: 0.559| gp_loss: 0.045| r_loss: 0.215| p_loss: 0.300| v_loss: 0.046| per_loss: 0.664 | a_loss: 0.561
Train: Epoch [293/3000], Step [120/158]| g_loss: 1.035| d_loss: 0.581| gp_loss: 0.043| r_loss: 0.216| p_loss: 0.311| v_loss: 0.048| per_loss: 0.669 | a_loss: 0.549
Train: Epoch [293/3000], Step [150/158]| g_loss: 1.030| d_loss: 0.536| gp_loss: 0.044| r_loss: 0.192| p_loss: 0.305| v_loss: 0.048| per_loss: 0.618 | a_loss: 0.576
Train: Epoch [294/3000], Step [30/158]| g_loss: 1.092| d_loss: 0.547| gp_loss: 0.100| r_loss: 0.244| p_loss: 0.302| v_loss: 0.049| per_loss: 0.642 | a_loss: 0.584
Train: Epoch [294/3000], Step [60/158]| g_loss: 1.062| d_loss: 0.522| gp_loss: 0.045| r_loss: 0.211| p_loss: 0.308| v_loss: 0.049| per_loss: 0.672 | a_loss: 0.580
Train: Epoch [294/3000], Step [90/158]| g_loss: 1.020| d_loss: 0.562| gp_loss: 0.047| r_loss: 0.194| p_loss: 0.298| v_loss: 0.048| per_loss: 0.654 | a_loss: 0.564
Train: Epoch [294/3000], Step [120/158]| g_loss: 0.949| d_loss: 0.633| gp_loss: 0.047| r_loss: 0.198| p_loss: 0.308| v_loss: 0.046| per_loss: 0.645 | a_loss: 0.486
Train: Epoch [294/3000], Step [150/158]| g_loss: 1.029| d_loss: 0.605| gp_loss: 0.046| r_loss: 0.222| p_loss: 0.307| v_loss: 0.046| per_loss: 0.686 | a_loss: 0.538
Train: Epoch [295/3000], Step [30/158]| g_loss: 1.104| d_loss: 0.539| gp_loss: 0.085| r_loss: 0.213| p_loss: 0.312| v_loss: 0.048| per_loss: 0.680 | a_loss: 0.619
Train: Epoch [295/3000], Step [60/158]| g_loss: 1.013| d_loss: 0.571| gp_loss: 0.048| r_loss: 0.204| p_loss: 0.295| v_loss: 0.046| per_loss: 0.646 | a_loss: 0.551
Train: Epoch [295/3000], Step [90/158]| g_loss: 1.007| d_loss: 0.610| gp_loss: 0.050| r_loss: 0.211| p_loss: 0.312| v_loss: 0.048| per_loss: 0.662 | a_loss: 0.526
Train: Epoch [295/3000], Step [120/158]| g_loss: 1.104| d_loss: 0.461| gp_loss: 0.043| r_loss: 0.215| p_loss: 0.309| v_loss: 0.046| per_loss: 0.665 | a_loss: 0.622
Train: Epoch [295/3000], Step [150/158]| g_loss: 0.975| d_loss: 0.654| gp_loss: 0.052| r_loss: 0.195| p_loss: 0.297| v_loss: 0.045| per_loss: 0.633 | a_loss: 0.524
Train: Epoch [296/3000], Step [30/158]| g_loss: 1.017| d_loss: 0.658| gp_loss: 0.159| r_loss: 0.206| p_loss: 0.314| v_loss: 0.046| per_loss: 0.642 | a_loss: 0.544
Train: Epoch [296/3000], Step [60/158]| g_loss: 0.971| d_loss: 0.614| gp_loss: 0.046| r_loss: 0.206| p_loss: 0.300| v_loss: 0.046| per_loss: 0.646 | a_loss: 0.504
Train: Epoch [296/3000], Step [90/158]| g_loss: 1.059| d_loss: 0.551| gp_loss: 0.046| r_loss: 0.212| p_loss: 0.306| v_loss: 0.046| per_loss: 0.639 | a_loss: 0.584
Train: Epoch [296/3000], Step [120/158]| g_loss: 1.076| d_loss: 0.493| gp_loss: 0.045| r_loss: 0.208| p_loss: 0.309| v_loss: 0.047| per_loss: 0.700 | a_loss: 0.597
Train: Epoch [296/3000], Step [150/158]| g_loss: 1.045| d_loss: 0.551| gp_loss: 0.048| r_loss: 0.197| p_loss: 0.300| v_loss: 0.046| per_loss: 0.684 | a_loss: 0.583
Train: Epoch [297/3000], Step [30/158]| g_loss: 0.981| d_loss: 0.768| gp_loss: 0.199| r_loss: 0.198| p_loss: 0.299| v_loss: 0.047| per_loss: 0.662 | a_loss: 0.521
Train: Epoch [297/3000], Step [60/158]| g_loss: 1.001| d_loss: 0.575| gp_loss: 0.044| r_loss: 0.206| p_loss: 0.306| v_loss: 0.047| per_loss: 0.692 | a_loss: 0.527
Train: Epoch [297/3000], Step [90/158]| g_loss: 1.019| d_loss: 0.591| gp_loss: 0.044| r_loss: 0.217| p_loss: 0.302| v_loss: 0.046| per_loss: 0.655 | a_loss: 0.539
Train: Epoch [297/3000], Step [120/158]| g_loss: 1.018| d_loss: 0.566| gp_loss: 0.048| r_loss: 0.200| p_loss: 0.294| v_loss: 0.047| per_loss: 0.655 | a_loss: 0.559
Train: Epoch [297/3000], Step [150/158]| g_loss: 1.092| d_loss: 0.475| gp_loss: 0.044| r_loss: 0.199| p_loss: 0.310| v_loss: 0.047| per_loss: 0.675 | a_loss: 0.623
Train: Epoch [298/3000], Step [30/158]| g_loss: 1.087| d_loss: 0.593| gp_loss: 0.116| r_loss: 0.221| p_loss: 0.315| v_loss: 0.046| per_loss: 0.675 | a_loss: 0.594
Train: Epoch [298/3000], Step [60/158]| g_loss: 1.017| d_loss: 0.570| gp_loss: 0.045| r_loss: 0.190| p_loss: 0.298| v_loss: 0.046| per_loss: 0.685 | a_loss: 0.563
Train: Epoch [298/3000], Step [90/158]| g_loss: 1.029| d_loss: 0.558| gp_loss: 0.042| r_loss: 0.193| p_loss: 0.296| v_loss: 0.047| per_loss: 0.669 | a_loss: 0.573
Train: Epoch [298/3000], Step [120/158]| g_loss: 1.007| d_loss: 0.541| gp_loss: 0.050| r_loss: 0.202| p_loss: 0.305| v_loss: 0.044| per_loss: 0.636 | a_loss: 0.545
Train: Epoch [298/3000], Step [150/158]| g_loss: 1.071| d_loss: 0.540| gp_loss: 0.047| r_loss: 0.217| p_loss: 0.309| v_loss: 0.046| per_loss: 0.638 | a_loss: 0.590
Train: Epoch [299/3000], Step [30/158]| g_loss: 0.998| d_loss: 0.690| gp_loss: 0.121| r_loss: 0.193| p_loss: 0.302| v_loss: 0.045| per_loss: 0.653 | a_loss: 0.543
Train: Epoch [299/3000], Step [60/158]| g_loss: 1.057| d_loss: 0.549| gp_loss: 0.046| r_loss: 0.212| p_loss: 0.302| v_loss: 0.044| per_loss: 0.672 | a_loss: 0.583
Train: Epoch [299/3000], Step [90/158]| g_loss: 1.035| d_loss: 0.564| gp_loss: 0.045| r_loss: 0.203| p_loss: 0.297| v_loss: 0.046| per_loss: 0.675 | a_loss: 0.571
Train: Epoch [299/3000], Step [120/158]| g_loss: 1.038| d_loss: 0.576| gp_loss: 0.048| r_loss: 0.198| p_loss: 0.295| v_loss: 0.046| per_loss: 0.686 | a_loss: 0.578
Train: Epoch [299/3000], Step [150/158]| g_loss: 1.041| d_loss: 0.583| gp_loss: 0.048| r_loss: 0.212| p_loss: 0.308| v_loss: 0.048| per_loss: 0.686 | a_loss: 0.559
Train: Epoch [300/3000], Step [30/158]| g_loss: 1.027| d_loss: 0.586| gp_loss: 0.136| r_loss: 0.198| p_loss: 0.294| v_loss: 0.046| per_loss: 0.651 | a_loss: 0.570
Train: Epoch [300/3000], Step [60/158]| g_loss: 1.042| d_loss: 0.564| gp_loss: 0.047| r_loss: 0.196| p_loss: 0.304| v_loss: 0.045| per_loss: 0.644 | a_loss: 0.584
Train: Epoch [300/3000], Step [90/158]| g_loss: 1.023| d_loss: 0.527| gp_loss: 0.046| r_loss: 0.201| p_loss: 0.294| v_loss: 0.046| per_loss: 0.683 | a_loss: 0.561
Train: Epoch [300/3000], Step [120/158]| g_loss: 1.079| d_loss: 0.559| gp_loss: 0.047| r_loss: 0.219| p_loss: 0.318| v_loss: 0.046| per_loss: 0.688 | a_loss: 0.587
Train: Epoch [300/3000], Step [150/158]| g_loss: 1.002| d_loss: 0.585| gp_loss: 0.048| r_loss: 0.199| p_loss: 0.288| v_loss: 0.046| per_loss: 0.736 | a_loss: 0.539
Test: Epoch [300/3000]| g_loss: 0.950| r_loss: 0.654| p_loss: 0.393| v_loss: 0.034
Train: Epoch [301/3000], Step [30/158]| g_loss: 1.087| d_loss: 0.534| gp_loss: 0.044| r_loss: 0.221| p_loss: 0.313| v_loss: 0.046| per_loss: 0.689 | a_loss: 0.595
Train: Epoch [301/3000], Step [60/158]| g_loss: 1.049| d_loss: 0.541| gp_loss: 0.046| r_loss: 0.212| p_loss: 0.296| v_loss: 0.047| per_loss: 0.672 | a_loss: 0.575
Train: Epoch [301/3000], Step [90/158]| g_loss: 0.990| d_loss: 0.600| gp_loss: 0.047| r_loss: 0.184| p_loss: 0.286| v_loss: 0.045| per_loss: 0.682 | a_loss: 0.550
Train: Epoch [301/3000], Step [120/158]| g_loss: 1.036| d_loss: 0.567| gp_loss: 0.045| r_loss: 0.196| p_loss: 0.313| v_loss: 0.045| per_loss: 0.695 | a_loss: 0.568
Train: Epoch [301/3000], Step [150/158]| g_loss: 1.060| d_loss: 0.533| gp_loss: 0.041| r_loss: 0.210| p_loss: 0.305| v_loss: 0.048| per_loss: 0.668 | a_loss: 0.584
Train: Epoch [302/3000], Step [30/158]| g_loss: 1.048| d_loss: 0.615| gp_loss: 0.133| r_loss: 0.190| p_loss: 0.304| v_loss: 0.044| per_loss: 0.721 | a_loss: 0.589
Train: Epoch [302/3000], Step [60/158]| g_loss: 1.064| d_loss: 0.547| gp_loss: 0.042| r_loss: 0.215| p_loss: 0.316| v_loss: 0.047| per_loss: 0.693 | a_loss: 0.574
Train: Epoch [302/3000], Step [90/158]| g_loss: 1.050| d_loss: 0.513| gp_loss: 0.045| r_loss: 0.203| p_loss: 0.306| v_loss: 0.044| per_loss: 0.682 | a_loss: 0.582
Train: Epoch [302/3000], Step [120/158]| g_loss: 1.008| d_loss: 0.613| gp_loss: 0.045| r_loss: 0.206| p_loss: 0.303| v_loss: 0.046| per_loss: 0.691 | a_loss: 0.535
Train: Epoch [302/3000], Step [150/158]| g_loss: 0.994| d_loss: 0.596| gp_loss: 0.047| r_loss: 0.205| p_loss: 0.308| v_loss: 0.044| per_loss: 0.685 | a_loss: 0.523
Train: Epoch [303/3000], Step [30/158]| g_loss: 1.038| d_loss: 0.644| gp_loss: 0.148| r_loss: 0.209| p_loss: 0.305| v_loss: 0.044| per_loss: 0.664 | a_loss: 0.566
Train: Epoch [303/3000], Step [60/158]| g_loss: 0.998| d_loss: 0.641| gp_loss: 0.046| r_loss: 0.214| p_loss: 0.312| v_loss: 0.044| per_loss: 0.746 | a_loss: 0.509
Train: Epoch [303/3000], Step [90/158]| g_loss: 1.029| d_loss: 0.582| gp_loss: 0.043| r_loss: 0.200| p_loss: 0.309| v_loss: 0.045| per_loss: 0.698 | a_loss: 0.560
Train: Epoch [303/3000], Step [120/158]| g_loss: 1.025| d_loss: 0.558| gp_loss: 0.048| r_loss: 0.198| p_loss: 0.315| v_loss: 0.050| per_loss: 0.736 | a_loss: 0.546
Train: Epoch [303/3000], Step [150/158]| g_loss: 1.068| d_loss: 0.513| gp_loss: 0.044| r_loss: 0.219| p_loss: 0.302| v_loss: 0.046| per_loss: 0.749 | a_loss: 0.578
Train: Epoch [304/3000], Step [30/158]| g_loss: 1.017| d_loss: 0.643| gp_loss: 0.127| r_loss: 0.202| p_loss: 0.324| v_loss: 0.047| per_loss: 0.764 | a_loss: 0.529
Train: Epoch [304/3000], Step [60/158]| g_loss: 1.063| d_loss: 0.542| gp_loss: 0.043| r_loss: 0.211| p_loss: 0.297| v_loss: 0.046| per_loss: 0.719 | a_loss: 0.585
Train: Epoch [304/3000], Step [90/158]| g_loss: 1.040| d_loss: 0.509| gp_loss: 0.045| r_loss: 0.194| p_loss: 0.299| v_loss: 0.045| per_loss: 0.687 | a_loss: 0.583
Train: Epoch [304/3000], Step [120/158]| g_loss: 1.009| d_loss: 0.575| gp_loss: 0.048| r_loss: 0.200| p_loss: 0.310| v_loss: 0.044| per_loss: 0.718 | a_loss: 0.538
Train: Epoch [304/3000], Step [150/158]| g_loss: 1.079| d_loss: 0.508| gp_loss: 0.046| r_loss: 0.212| p_loss: 0.297| v_loss: 0.045| per_loss: 0.739 | a_loss: 0.600
Train: Epoch [305/3000], Step [30/158]| g_loss: 1.040| d_loss: 0.634| gp_loss: 0.135| r_loss: 0.213| p_loss: 0.307| v_loss: 0.045| per_loss: 0.744 | a_loss: 0.554
Train: Epoch [305/3000], Step [60/158]| g_loss: 1.062| d_loss: 0.535| gp_loss: 0.044| r_loss: 0.198| p_loss: 0.302| v_loss: 0.045| per_loss: 0.702 | a_loss: 0.597
Train: Epoch [305/3000], Step [90/158]| g_loss: 1.006| d_loss: 0.574| gp_loss: 0.047| r_loss: 0.204| p_loss: 0.309| v_loss: 0.047| per_loss: 0.704 | a_loss: 0.531
Train: Epoch [305/3000], Step [120/158]| g_loss: 1.067| d_loss: 0.517| gp_loss: 0.045| r_loss: 0.201| p_loss: 0.297| v_loss: 0.046| per_loss: 0.732 | a_loss: 0.598
Train: Epoch [305/3000], Step [150/158]| g_loss: 0.995| d_loss: 0.603| gp_loss: 0.052| r_loss: 0.208| p_loss: 0.303| v_loss: 0.045| per_loss: 0.760 | a_loss: 0.514
Train: Epoch [306/3000], Step [30/158]| g_loss: 1.050| d_loss: 0.667| gp_loss: 0.112| r_loss: 0.208| p_loss: 0.302| v_loss: 0.043| per_loss: 0.759 | a_loss: 0.572
Train: Epoch [306/3000], Step [60/158]| g_loss: 1.037| d_loss: 0.505| gp_loss: 0.044| r_loss: 0.197| p_loss: 0.296| v_loss: 0.047| per_loss: 0.721 | a_loss: 0.572
Train: Epoch [306/3000], Step [90/158]| g_loss: 1.049| d_loss: 0.554| gp_loss: 0.045| r_loss: 0.213| p_loss: 0.305| v_loss: 0.047| per_loss: 0.690 | a_loss: 0.568
Train: Epoch [306/3000], Step [120/158]| g_loss: 1.030| d_loss: 0.502| gp_loss: 0.049| r_loss: 0.193| p_loss: 0.297| v_loss: 0.045| per_loss: 0.707 | a_loss: 0.572
Train: Epoch [306/3000], Step [150/158]| g_loss: 1.096| d_loss: 0.563| gp_loss: 0.051| r_loss: 0.213| p_loss: 0.307| v_loss: 0.044| per_loss: 0.735 | a_loss: 0.612
Train: Epoch [307/3000], Step [30/158]| g_loss: 1.086| d_loss: 0.608| gp_loss: 0.177| r_loss: 0.218| p_loss: 0.306| v_loss: 0.045| per_loss: 0.747 | a_loss: 0.595
Train: Epoch [307/3000], Step [60/158]| g_loss: 1.014| d_loss: 0.619| gp_loss: 0.044| r_loss: 0.192| p_loss: 0.303| v_loss: 0.045| per_loss: 0.698 | a_loss: 0.556
Train: Epoch [307/3000], Step [90/158]| g_loss: 1.015| d_loss: 0.596| gp_loss: 0.046| r_loss: 0.205| p_loss: 0.304| v_loss: 0.045| per_loss: 0.737 | a_loss: 0.539
Train: Epoch [307/3000], Step [120/158]| g_loss: 1.040| d_loss: 0.529| gp_loss: 0.044| r_loss: 0.204| p_loss: 0.314| v_loss: 0.047| per_loss: 0.800 | a_loss: 0.552
Train: Epoch [307/3000], Step [150/158]| g_loss: 1.077| d_loss: 0.585| gp_loss: 0.047| r_loss: 0.212| p_loss: 0.316| v_loss: 0.046| per_loss: 0.800 | a_loss: 0.581
Train: Epoch [308/3000], Step [30/158]| g_loss: 1.076| d_loss: 0.628| gp_loss: 0.141| r_loss: 0.221| p_loss: 0.309| v_loss: 0.045| per_loss: 0.832 | a_loss: 0.572
Train: Epoch [308/3000], Step [60/158]| g_loss: 1.062| d_loss: 0.593| gp_loss: 0.043| r_loss: 0.218| p_loss: 0.313| v_loss: 0.048| per_loss: 0.841 | a_loss: 0.556
Train: Epoch [308/3000], Step [90/158]| g_loss: 1.087| d_loss: 0.580| gp_loss: 0.042| r_loss: 0.214| p_loss: 0.317| v_loss: 0.048| per_loss: 0.867 | a_loss: 0.580
Train: Epoch [308/3000], Step [120/158]| g_loss: 1.042| d_loss: 0.560| gp_loss: 0.041| r_loss: 0.200| p_loss: 0.306| v_loss: 0.048| per_loss: 0.833 | a_loss: 0.558
Train: Epoch [308/3000], Step [150/158]| g_loss: 1.047| d_loss: 0.590| gp_loss: 0.046| r_loss: 0.215| p_loss: 0.317| v_loss: 0.049| per_loss: 0.927 | a_loss: 0.532
Train: Epoch [309/3000], Step [30/158]| g_loss: 1.056| d_loss: 0.698| gp_loss: 0.101| r_loss: 0.214| p_loss: 0.322| v_loss: 0.050| per_loss: 0.973 | a_loss: 0.534
Train: Epoch [309/3000], Step [60/158]| g_loss: 1.045| d_loss: 0.552| gp_loss: 0.043| r_loss: 0.200| p_loss: 0.311| v_loss: 0.045| per_loss: 0.815 | a_loss: 0.563
Train: Epoch [309/3000], Step [90/158]| g_loss: 1.048| d_loss: 0.525| gp_loss: 0.050| r_loss: 0.206| p_loss: 0.307| v_loss: 0.048| per_loss: 0.892 | a_loss: 0.551
Train: Epoch [309/3000], Step [120/158]| g_loss: 1.069| d_loss: 0.575| gp_loss: 0.044| r_loss: 0.211| p_loss: 0.325| v_loss: 0.047| per_loss: 0.848 | a_loss: 0.564
Train: Epoch [309/3000], Step [150/158]| g_loss: 1.049| d_loss: 0.566| gp_loss: 0.043| r_loss: 0.211| p_loss: 0.309| v_loss: 0.048| per_loss: 0.887 | a_loss: 0.547
Train: Epoch [310/3000], Step [30/158]| g_loss: 1.089| d_loss: 0.574| gp_loss: 0.105| r_loss: 0.213| p_loss: 0.306| v_loss: 0.046| per_loss: 0.797 | a_loss: 0.598
Train: Epoch [310/3000], Step [60/158]| g_loss: 1.060| d_loss: 0.552| gp_loss: 0.045| r_loss: 0.200| p_loss: 0.303| v_loss: 0.050| per_loss: 0.763 | a_loss: 0.582
Train: Epoch [310/3000], Step [90/158]| g_loss: 1.051| d_loss: 0.542| gp_loss: 0.048| r_loss: 0.197| p_loss: 0.299| v_loss: 0.048| per_loss: 0.820 | a_loss: 0.574
Train: Epoch [310/3000], Step [120/158]| g_loss: 1.014| d_loss: 0.603| gp_loss: 0.048| r_loss: 0.209| p_loss: 0.302| v_loss: 0.048| per_loss: 0.772 | a_loss: 0.529
Train: Epoch [310/3000], Step [150/158]| g_loss: 1.025| d_loss: 0.595| gp_loss: 0.050| r_loss: 0.211| p_loss: 0.310| v_loss: 0.045| per_loss: 0.714 | a_loss: 0.542
Train: Epoch [311/3000], Step [30/158]| g_loss: 1.109| d_loss: 0.609| gp_loss: 0.174| r_loss: 0.206| p_loss: 0.299| v_loss: 0.047| per_loss: 0.725 | a_loss: 0.634
Train: Epoch [311/3000], Step [60/158]| g_loss: 0.951| d_loss: 0.637| gp_loss: 0.048| r_loss: 0.204| p_loss: 0.291| v_loss: 0.044| per_loss: 0.642 | a_loss: 0.494
Train: Epoch [311/3000], Step [90/158]| g_loss: 1.009| d_loss: 0.649| gp_loss: 0.044| r_loss: 0.211| p_loss: 0.293| v_loss: 0.046| per_loss: 0.729 | a_loss: 0.533
Train: Epoch [311/3000], Step [120/158]| g_loss: 0.974| d_loss: 0.619| gp_loss: 0.047| r_loss: 0.196| p_loss: 0.293| v_loss: 0.046| per_loss: 0.677 | a_loss: 0.519
Train: Epoch [311/3000], Step [150/158]| g_loss: 1.055| d_loss: 0.485| gp_loss: 0.044| r_loss: 0.204| p_loss: 0.300| v_loss: 0.047| per_loss: 0.756 | a_loss: 0.579
Train: Epoch [312/3000], Step [30/158]| g_loss: 1.078| d_loss: 0.660| gp_loss: 0.164| r_loss: 0.214| p_loss: 0.322| v_loss: 0.047| per_loss: 0.709 | a_loss: 0.585
Train: Epoch [312/3000], Step [60/158]| g_loss: 1.031| d_loss: 0.540| gp_loss: 0.044| r_loss: 0.207| p_loss: 0.314| v_loss: 0.044| per_loss: 0.702 | a_loss: 0.553
Train: Epoch [312/3000], Step [90/158]| g_loss: 1.020| d_loss: 0.581| gp_loss: 0.044| r_loss: 0.197| p_loss: 0.299| v_loss: 0.045| per_loss: 0.726 | a_loss: 0.557
Train: Epoch [312/3000], Step [120/158]| g_loss: 1.046| d_loss: 0.562| gp_loss: 0.046| r_loss: 0.219| p_loss: 0.302| v_loss: 0.046| per_loss: 0.681 | a_loss: 0.562
Train: Epoch [312/3000], Step [150/158]| g_loss: 1.030| d_loss: 0.582| gp_loss: 0.048| r_loss: 0.202| p_loss: 0.299| v_loss: 0.045| per_loss: 0.734 | a_loss: 0.560
Train: Epoch [313/3000], Step [30/158]| g_loss: 1.033| d_loss: 0.653| gp_loss: 0.149| r_loss: 0.209| p_loss: 0.300| v_loss: 0.047| per_loss: 0.681 | a_loss: 0.559
Train: Epoch [313/3000], Step [60/158]| g_loss: 1.017| d_loss: 0.535| gp_loss: 0.042| r_loss: 0.195| p_loss: 0.289| v_loss: 0.046| per_loss: 0.723 | a_loss: 0.559
Train: Epoch [313/3000], Step [90/158]| g_loss: 1.027| d_loss: 0.630| gp_loss: 0.044| r_loss: 0.211| p_loss: 0.311| v_loss: 0.046| per_loss: 0.693 | a_loss: 0.545
Train: Epoch [313/3000], Step [120/158]| g_loss: 1.026| d_loss: 0.587| gp_loss: 0.044| r_loss: 0.206| p_loss: 0.306| v_loss: 0.046| per_loss: 0.734 | a_loss: 0.547
Train: Epoch [313/3000], Step [150/158]| g_loss: 1.012| d_loss: 0.546| gp_loss: 0.046| r_loss: 0.206| p_loss: 0.297| v_loss: 0.044| per_loss: 0.700 | a_loss: 0.544
Train: Epoch [314/3000], Step [30/158]| g_loss: 1.053| d_loss: 0.569| gp_loss: 0.109| r_loss: 0.197| p_loss: 0.294| v_loss: 0.046| per_loss: 0.714 | a_loss: 0.592
Train: Epoch [314/3000], Step [60/158]| g_loss: 1.041| d_loss: 0.559| gp_loss: 0.046| r_loss: 0.200| p_loss: 0.301| v_loss: 0.045| per_loss: 0.682 | a_loss: 0.577
Train: Epoch [314/3000], Step [90/158]| g_loss: 1.004| d_loss: 0.645| gp_loss: 0.048| r_loss: 0.210| p_loss: 0.304| v_loss: 0.046| per_loss: 0.721 | a_loss: 0.524
Train: Epoch [314/3000], Step [120/158]| g_loss: 1.039| d_loss: 0.606| gp_loss: 0.048| r_loss: 0.217| p_loss: 0.311| v_loss: 0.046| per_loss: 0.724 | a_loss: 0.548
Train: Epoch [314/3000], Step [150/158]| g_loss: 1.027| d_loss: 0.561| gp_loss: 0.044| r_loss: 0.199| p_loss: 0.306| v_loss: 0.046| per_loss: 0.765 | a_loss: 0.553
Train: Epoch [315/3000], Step [30/158]| g_loss: 0.990| d_loss: 0.671| gp_loss: 0.080| r_loss: 0.211| p_loss: 0.308| v_loss: 0.046| per_loss: 0.748 | a_loss: 0.504
Train: Epoch [315/3000], Step [60/158]| g_loss: 1.055| d_loss: 0.558| gp_loss: 0.046| r_loss: 0.213| p_loss: 0.311| v_loss: 0.044| per_loss: 0.712 | a_loss: 0.571
Train: Epoch [315/3000], Step [90/158]| g_loss: 1.029| d_loss: 0.588| gp_loss: 0.047| r_loss: 0.210| p_loss: 0.302| v_loss: 0.045| per_loss: 0.714 | a_loss: 0.552
Train: Epoch [315/3000], Step [120/158]| g_loss: 1.009| d_loss: 0.586| gp_loss: 0.044| r_loss: 0.195| p_loss: 0.309| v_loss: 0.046| per_loss: 0.741 | a_loss: 0.539
Train: Epoch [315/3000], Step [150/158]| g_loss: 1.028| d_loss: 0.632| gp_loss: 0.047| r_loss: 0.213| p_loss: 0.304| v_loss: 0.046| per_loss: 0.682 | a_loss: 0.549
Train: Epoch [316/3000], Step [30/158]| g_loss: 1.007| d_loss: 0.756| gp_loss: 0.155| r_loss: 0.208| p_loss: 0.312| v_loss: 0.048| per_loss: 0.724 | a_loss: 0.523
Train: Epoch [316/3000], Step [60/158]| g_loss: 1.034| d_loss: 0.582| gp_loss: 0.042| r_loss: 0.218| p_loss: 0.306| v_loss: 0.047| per_loss: 0.705 | a_loss: 0.546
Train: Epoch [316/3000], Step [90/158]| g_loss: 1.029| d_loss: 0.551| gp_loss: 0.047| r_loss: 0.199| p_loss: 0.289| v_loss: 0.045| per_loss: 0.719 | a_loss: 0.568
Train: Epoch [316/3000], Step [120/158]| g_loss: 1.037| d_loss: 0.533| gp_loss: 0.046| r_loss: 0.199| p_loss: 0.310| v_loss: 0.043| per_loss: 0.696 | a_loss: 0.570
Train: Epoch [316/3000], Step [150/158]| g_loss: 1.040| d_loss: 0.563| gp_loss: 0.046| r_loss: 0.203| p_loss: 0.296| v_loss: 0.044| per_loss: 0.749 | a_loss: 0.570
Train: Epoch [317/3000], Step [30/158]| g_loss: 1.000| d_loss: 0.735| gp_loss: 0.212| r_loss: 0.200| p_loss: 0.292| v_loss: 0.043| per_loss: 0.678 | a_loss: 0.544
Train: Epoch [317/3000], Step [60/158]| g_loss: 1.055| d_loss: 0.495| gp_loss: 0.044| r_loss: 0.192| p_loss: 0.298| v_loss: 0.046| per_loss: 0.673 | a_loss: 0.602
Train: Epoch [317/3000], Step [90/158]| g_loss: 1.007| d_loss: 0.611| gp_loss: 0.046| r_loss: 0.192| p_loss: 0.299| v_loss: 0.046| per_loss: 0.680 | a_loss: 0.550
Train: Epoch [317/3000], Step [120/158]| g_loss: 1.052| d_loss: 0.547| gp_loss: 0.046| r_loss: 0.222| p_loss: 0.306| v_loss: 0.048| per_loss: 0.693 | a_loss: 0.561
Train: Epoch [317/3000], Step [150/158]| g_loss: 0.986| d_loss: 0.638| gp_loss: 0.043| r_loss: 0.207| p_loss: 0.301| v_loss: 0.046| per_loss: 0.633 | a_loss: 0.519
Train: Epoch [318/3000], Step [30/158]| g_loss: 0.990| d_loss: 0.680| gp_loss: 0.118| r_loss: 0.203| p_loss: 0.308| v_loss: 0.048| per_loss: 0.663 | a_loss: 0.519
Train: Epoch [318/3000], Step [60/158]| g_loss: 1.003| d_loss: 0.588| gp_loss: 0.042| r_loss: 0.204| p_loss: 0.296| v_loss: 0.044| per_loss: 0.688 | a_loss: 0.538
Train: Epoch [318/3000], Step [90/158]| g_loss: 1.033| d_loss: 0.529| gp_loss: 0.042| r_loss: 0.200| p_loss: 0.285| v_loss: 0.045| per_loss: 0.684 | a_loss: 0.578
Train: Epoch [318/3000], Step [120/158]| g_loss: 0.997| d_loss: 0.600| gp_loss: 0.048| r_loss: 0.205| p_loss: 0.289| v_loss: 0.043| per_loss: 0.642 | a_loss: 0.539
Train: Epoch [318/3000], Step [150/158]| g_loss: 1.037| d_loss: 0.553| gp_loss: 0.047| r_loss: 0.199| p_loss: 0.292| v_loss: 0.046| per_loss: 0.661 | a_loss: 0.579
Train: Epoch [319/3000], Step [30/158]| g_loss: 1.009| d_loss: 0.659| gp_loss: 0.132| r_loss: 0.210| p_loss: 0.293| v_loss: 0.046| per_loss: 0.632 | a_loss: 0.544
Train: Epoch [319/3000], Step [60/158]| g_loss: 0.987| d_loss: 0.640| gp_loss: 0.045| r_loss: 0.193| p_loss: 0.294| v_loss: 0.046| per_loss: 0.654 | a_loss: 0.535
Train: Epoch [319/3000], Step [90/158]| g_loss: 1.056| d_loss: 0.572| gp_loss: 0.044| r_loss: 0.209| p_loss: 0.314| v_loss: 0.047| per_loss: 0.686 | a_loss: 0.574
Train: Epoch [319/3000], Step [120/158]| g_loss: 1.035| d_loss: 0.537| gp_loss: 0.045| r_loss: 0.198| p_loss: 0.304| v_loss: 0.047| per_loss: 0.640 | a_loss: 0.574
Train: Epoch [319/3000], Step [150/158]| g_loss: 1.025| d_loss: 0.537| gp_loss: 0.049| r_loss: 0.202| p_loss: 0.297| v_loss: 0.045| per_loss: 0.622 | a_loss: 0.567
Train: Epoch [320/3000], Step [30/158]| g_loss: 1.080| d_loss: 0.568| gp_loss: 0.100| r_loss: 0.203| p_loss: 0.296| v_loss: 0.046| per_loss: 0.652 | a_loss: 0.617
Train: Epoch [320/3000], Step [60/158]| g_loss: 1.039| d_loss: 0.461| gp_loss: 0.044| r_loss: 0.189| p_loss: 0.293| v_loss: 0.044| per_loss: 0.650 | a_loss: 0.594
Train: Epoch [320/3000], Step [90/158]| g_loss: 1.090| d_loss: 0.577| gp_loss: 0.046| r_loss: 0.215| p_loss: 0.310| v_loss: 0.046| per_loss: 0.643 | a_loss: 0.610
Train: Epoch [320/3000], Step [120/158]| g_loss: 0.971| d_loss: 0.615| gp_loss: 0.048| r_loss: 0.202| p_loss: 0.300| v_loss: 0.045| per_loss: 0.686 | a_loss: 0.505
Train: Epoch [320/3000], Step [150/158]| g_loss: 0.999| d_loss: 0.606| gp_loss: 0.048| r_loss: 0.195| p_loss: 0.298| v_loss: 0.044| per_loss: 0.651 | a_loss: 0.546
Train: Epoch [321/3000], Step [30/158]| g_loss: 0.985| d_loss: 0.723| gp_loss: 0.178| r_loss: 0.191| p_loss: 0.289| v_loss: 0.046| per_loss: 0.669 | a_loss: 0.537
Train: Epoch [321/3000], Step [60/158]| g_loss: 1.041| d_loss: 0.543| gp_loss: 0.047| r_loss: 0.214| p_loss: 0.289| v_loss: 0.045| per_loss: 0.637 | a_loss: 0.574
Train: Epoch [321/3000], Step [90/158]| g_loss: 0.955| d_loss: 0.643| gp_loss: 0.046| r_loss: 0.195| p_loss: 0.295| v_loss: 0.045| per_loss: 0.651 | a_loss: 0.502
Train: Epoch [321/3000], Step [120/158]| g_loss: 1.040| d_loss: 0.558| gp_loss: 0.043| r_loss: 0.202| p_loss: 0.305| v_loss: 0.046| per_loss: 0.677 | a_loss: 0.572
Train: Epoch [321/3000], Step [150/158]| g_loss: 1.046| d_loss: 0.509| gp_loss: 0.047| r_loss: 0.201| p_loss: 0.298| v_loss: 0.047| per_loss: 0.631 | a_loss: 0.586
Train: Epoch [322/3000], Step [30/158]| g_loss: 1.035| d_loss: 0.576| gp_loss: 0.081| r_loss: 0.192| p_loss: 0.294| v_loss: 0.045| per_loss: 0.666 | a_loss: 0.585
Train: Epoch [322/3000], Step [60/158]| g_loss: 1.057| d_loss: 0.547| gp_loss: 0.046| r_loss: 0.219| p_loss: 0.312| v_loss: 0.046| per_loss: 0.679 | a_loss: 0.568
Train: Epoch [322/3000], Step [90/158]| g_loss: 1.016| d_loss: 0.625| gp_loss: 0.045| r_loss: 0.202| p_loss: 0.307| v_loss: 0.045| per_loss: 0.703 | a_loss: 0.546
Train: Epoch [322/3000], Step [120/158]| g_loss: 1.040| d_loss: 0.603| gp_loss: 0.048| r_loss: 0.217| p_loss: 0.309| v_loss: 0.048| per_loss: 0.717 | a_loss: 0.548
Train: Epoch [322/3000], Step [150/158]| g_loss: 1.031| d_loss: 0.528| gp_loss: 0.048| r_loss: 0.199| p_loss: 0.309| v_loss: 0.048| per_loss: 0.667 | a_loss: 0.563
Train: Epoch [323/3000], Step [30/158]| g_loss: 1.037| d_loss: 0.644| gp_loss: 0.080| r_loss: 0.200| p_loss: 0.317| v_loss: 0.046| per_loss: 0.696 | a_loss: 0.563
Train: Epoch [323/3000], Step [60/158]| g_loss: 0.974| d_loss: 0.626| gp_loss: 0.049| r_loss: 0.195| p_loss: 0.299| v_loss: 0.047| per_loss: 0.670 | a_loss: 0.516
Train: Epoch [323/3000], Step [90/158]| g_loss: 0.990| d_loss: 0.559| gp_loss: 0.049| r_loss: 0.198| p_loss: 0.288| v_loss: 0.047| per_loss: 0.654 | a_loss: 0.536
Train: Epoch [323/3000], Step [120/158]| g_loss: 1.044| d_loss: 0.508| gp_loss: 0.049| r_loss: 0.197| p_loss: 0.290| v_loss: 0.045| per_loss: 0.656 | a_loss: 0.592
Train: Epoch [323/3000], Step [150/158]| g_loss: 0.992| d_loss: 0.610| gp_loss: 0.054| r_loss: 0.211| p_loss: 0.300| v_loss: 0.044| per_loss: 0.656 | a_loss: 0.520
Train: Epoch [324/3000], Step [30/158]| g_loss: 1.010| d_loss: 0.651| gp_loss: 0.129| r_loss: 0.193| p_loss: 0.293| v_loss: 0.044| per_loss: 0.653 | a_loss: 0.561
Train: Epoch [324/3000], Step [60/158]| g_loss: 1.016| d_loss: 0.570| gp_loss: 0.043| r_loss: 0.190| p_loss: 0.291| v_loss: 0.046| per_loss: 0.639 | a_loss: 0.572
Train: Epoch [324/3000], Step [90/158]| g_loss: 1.032| d_loss: 0.517| gp_loss: 0.048| r_loss: 0.191| p_loss: 0.289| v_loss: 0.046| per_loss: 0.643 | a_loss: 0.587
Train: Epoch [324/3000], Step [120/158]| g_loss: 1.006| d_loss: 0.612| gp_loss: 0.046| r_loss: 0.208| p_loss: 0.300| v_loss: 0.043| per_loss: 0.637 | a_loss: 0.541
Train: Epoch [324/3000], Step [150/158]| g_loss: 1.019| d_loss: 0.599| gp_loss: 0.047| r_loss: 0.195| p_loss: 0.290| v_loss: 0.046| per_loss: 0.647 | a_loss: 0.569
Train: Epoch [325/3000], Step [30/158]| g_loss: 1.011| d_loss: 0.629| gp_loss: 0.078| r_loss: 0.213| p_loss: 0.295| v_loss: 0.044| per_loss: 0.689 | a_loss: 0.538
Train: Epoch [325/3000], Step [60/158]| g_loss: 1.023| d_loss: 0.550| gp_loss: 0.050| r_loss: 0.201| p_loss: 0.294| v_loss: 0.044| per_loss: 0.643 | a_loss: 0.566
Train: Epoch [325/3000], Step [90/158]| g_loss: 1.017| d_loss: 0.598| gp_loss: 0.045| r_loss: 0.190| p_loss: 0.290| v_loss: 0.042| per_loss: 0.617 | a_loss: 0.577
Train: Epoch [325/3000], Step [120/158]| g_loss: 0.940| d_loss: 0.579| gp_loss: 0.050| r_loss: 0.185| p_loss: 0.283| v_loss: 0.046| per_loss: 0.659 | a_loss: 0.501
Train: Epoch [325/3000], Step [150/158]| g_loss: 1.067| d_loss: 0.552| gp_loss: 0.049| r_loss: 0.209| p_loss: 0.284| v_loss: 0.045| per_loss: 0.612 | a_loss: 0.609
Train: Epoch [326/3000], Step [30/158]| g_loss: 0.978| d_loss: 0.643| gp_loss: 0.092| r_loss: 0.193| p_loss: 0.298| v_loss: 0.046| per_loss: 0.641 | a_loss: 0.526
Train: Epoch [326/3000], Step [60/158]| g_loss: 1.114| d_loss: 0.464| gp_loss: 0.044| r_loss: 0.202| p_loss: 0.290| v_loss: 0.047| per_loss: 0.680 | a_loss: 0.652
Train: Epoch [326/3000], Step [90/158]| g_loss: 0.956| d_loss: 0.643| gp_loss: 0.052| r_loss: 0.191| p_loss: 0.301| v_loss: 0.046| per_loss: 0.611 | a_loss: 0.508
Train: Epoch [326/3000], Step [120/158]| g_loss: 0.975| d_loss: 0.632| gp_loss: 0.051| r_loss: 0.199| p_loss: 0.298| v_loss: 0.044| per_loss: 0.604 | a_loss: 0.522
Train: Epoch [326/3000], Step [150/158]| g_loss: 0.978| d_loss: 0.596| gp_loss: 0.050| r_loss: 0.186| p_loss: 0.272| v_loss: 0.044| per_loss: 0.613 | a_loss: 0.550
Train: Epoch [327/3000], Step [30/158]| g_loss: 1.002| d_loss: 0.645| gp_loss: 0.127| r_loss: 0.196| p_loss: 0.275| v_loss: 0.043| per_loss: 0.653 | a_loss: 0.560
Train: Epoch [327/3000], Step [60/158]| g_loss: 0.930| d_loss: 0.662| gp_loss: 0.049| r_loss: 0.193| p_loss: 0.287| v_loss: 0.044| per_loss: 0.662 | a_loss: 0.483
Train: Epoch [327/3000], Step [90/158]| g_loss: 1.032| d_loss: 0.543| gp_loss: 0.045| r_loss: 0.191| p_loss: 0.287| v_loss: 0.047| per_loss: 0.626 | a_loss: 0.589
Train: Epoch [327/3000], Step [120/158]| g_loss: 0.981| d_loss: 0.622| gp_loss: 0.048| r_loss: 0.205| p_loss: 0.292| v_loss: 0.046| per_loss: 0.633 | a_loss: 0.522
Train: Epoch [327/3000], Step [150/158]| g_loss: 1.090| d_loss: 0.388| gp_loss: 0.047| r_loss: 0.179| p_loss: 0.266| v_loss: 0.042| per_loss: 0.591 | a_loss: 0.677
Train: Epoch [328/3000], Step [30/158]| g_loss: 1.015| d_loss: 0.590| gp_loss: 0.106| r_loss: 0.182| p_loss: 0.273| v_loss: 0.045| per_loss: 0.657 | a_loss: 0.585
Train: Epoch [328/3000], Step [60/158]| g_loss: 0.986| d_loss: 0.644| gp_loss: 0.048| r_loss: 0.200| p_loss: 0.294| v_loss: 0.047| per_loss: 0.663 | a_loss: 0.526
Train: Epoch [328/3000], Step [90/158]| g_loss: 1.025| d_loss: 0.573| gp_loss: 0.044| r_loss: 0.182| p_loss: 0.281| v_loss: 0.045| per_loss: 0.620 | a_loss: 0.596
Train: Epoch [328/3000], Step [120/158]| g_loss: 0.988| d_loss: 0.561| gp_loss: 0.047| r_loss: 0.189| p_loss: 0.284| v_loss: 0.045| per_loss: 0.650 | a_loss: 0.547
Train: Epoch [328/3000], Step [150/158]| g_loss: 0.977| d_loss: 0.609| gp_loss: 0.048| r_loss: 0.203| p_loss: 0.278| v_loss: 0.044| per_loss: 0.622 | a_loss: 0.529
Train: Epoch [329/3000], Step [30/158]| g_loss: 1.066| d_loss: 0.566| gp_loss: 0.173| r_loss: 0.188| p_loss: 0.275| v_loss: 0.046| per_loss: 0.644 | a_loss: 0.630
Train: Epoch [329/3000], Step [60/158]| g_loss: 0.945| d_loss: 0.671| gp_loss: 0.049| r_loss: 0.186| p_loss: 0.290| v_loss: 0.043| per_loss: 0.597 | a_loss: 0.511
Train: Epoch [329/3000], Step [90/158]| g_loss: 1.047| d_loss: 0.470| gp_loss: 0.047| r_loss: 0.198| p_loss: 0.298| v_loss: 0.046| per_loss: 0.624 | a_loss: 0.593
Train: Epoch [329/3000], Step [120/158]| g_loss: 1.012| d_loss: 0.603| gp_loss: 0.049| r_loss: 0.207| p_loss: 0.293| v_loss: 0.045| per_loss: 0.687 | a_loss: 0.545
Train: Epoch [329/3000], Step [150/158]| g_loss: 1.006| d_loss: 0.634| gp_loss: 0.048| r_loss: 0.188| p_loss: 0.300| v_loss: 0.044| per_loss: 0.694 | a_loss: 0.554
Train: Epoch [330/3000], Step [30/158]| g_loss: 1.009| d_loss: 0.723| gp_loss: 0.124| r_loss: 0.239| p_loss: 0.313| v_loss: 0.047| per_loss: 0.657 | a_loss: 0.501
Train: Epoch [330/3000], Step [60/158]| g_loss: 1.013| d_loss: 0.560| gp_loss: 0.046| r_loss: 0.198| p_loss: 0.303| v_loss: 0.045| per_loss: 0.617 | a_loss: 0.556
Train: Epoch [330/3000], Step [90/158]| g_loss: 0.967| d_loss: 0.611| gp_loss: 0.048| r_loss: 0.193| p_loss: 0.290| v_loss: 0.045| per_loss: 0.634 | a_loss: 0.521
Train: Epoch [330/3000], Step [120/158]| g_loss: 1.035| d_loss: 0.565| gp_loss: 0.047| r_loss: 0.204| p_loss: 0.299| v_loss: 0.044| per_loss: 0.606 | a_loss: 0.577
Train: Epoch [330/3000], Step [150/158]| g_loss: 0.961| d_loss: 0.615| gp_loss: 0.048| r_loss: 0.188| p_loss: 0.290| v_loss: 0.044| per_loss: 0.635 | a_loss: 0.521
Train: Epoch [331/3000], Step [30/158]| g_loss: 1.009| d_loss: 0.670| gp_loss: 0.148| r_loss: 0.191| p_loss: 0.281| v_loss: 0.045| per_loss: 0.603 | a_loss: 0.572
Train: Epoch [331/3000], Step [60/158]| g_loss: 0.951| d_loss: 0.613| gp_loss: 0.047| r_loss: 0.184| p_loss: 0.287| v_loss: 0.042| per_loss: 0.636 | a_loss: 0.517
Train: Epoch [331/3000], Step [90/158]| g_loss: 1.055| d_loss: 0.519| gp_loss: 0.041| r_loss: 0.207| p_loss: 0.298| v_loss: 0.045| per_loss: 0.629 | a_loss: 0.591
Train: Epoch [331/3000], Step [120/158]| g_loss: 0.957| d_loss: 0.670| gp_loss: 0.047| r_loss: 0.191| p_loss: 0.288| v_loss: 0.044| per_loss: 0.627 | a_loss: 0.515
Train: Epoch [331/3000], Step [150/158]| g_loss: 0.983| d_loss: 0.574| gp_loss: 0.046| r_loss: 0.175| p_loss: 0.279| v_loss: 0.045| per_loss: 0.630 | a_loss: 0.560
Train: Epoch [332/3000], Step [30/158]| g_loss: 0.938| d_loss: 0.804| gp_loss: 0.178| r_loss: 0.217| p_loss: 0.305| v_loss: 0.045| per_loss: 0.629 | a_loss: 0.460
Train: Epoch [332/3000], Step [60/158]| g_loss: 1.036| d_loss: 0.520| gp_loss: 0.042| r_loss: 0.193| p_loss: 0.288| v_loss: 0.045| per_loss: 0.617 | a_loss: 0.593
Train: Epoch [332/3000], Step [90/158]| g_loss: 0.975| d_loss: 0.621| gp_loss: 0.046| r_loss: 0.188| p_loss: 0.286| v_loss: 0.044| per_loss: 0.638 | a_loss: 0.536
Train: Epoch [332/3000], Step [120/158]| g_loss: 0.970| d_loss: 0.586| gp_loss: 0.047| r_loss: 0.192| p_loss: 0.286| v_loss: 0.044| per_loss: 0.620 | a_loss: 0.528
Train: Epoch [332/3000], Step [150/158]| g_loss: 1.019| d_loss: 0.564| gp_loss: 0.048| r_loss: 0.199| p_loss: 0.286| v_loss: 0.044| per_loss: 0.643 | a_loss: 0.569
Train: Epoch [333/3000], Step [30/158]| g_loss: 0.970| d_loss: 0.702| gp_loss: 0.154| r_loss: 0.180| p_loss: 0.281| v_loss: 0.044| per_loss: 0.608 | a_loss: 0.545
Train: Epoch [333/3000], Step [60/158]| g_loss: 0.966| d_loss: 0.575| gp_loss: 0.046| r_loss: 0.194| p_loss: 0.276| v_loss: 0.044| per_loss: 0.615 | a_loss: 0.529
Train: Epoch [333/3000], Step [90/158]| g_loss: 1.041| d_loss: 0.567| gp_loss: 0.045| r_loss: 0.215| p_loss: 0.290| v_loss: 0.044| per_loss: 0.616 | a_loss: 0.575
Train: Epoch [333/3000], Step [120/158]| g_loss: 1.008| d_loss: 0.546| gp_loss: 0.048| r_loss: 0.186| p_loss: 0.286| v_loss: 0.047| per_loss: 0.700 | a_loss: 0.562
Train: Epoch [333/3000], Step [150/158]| g_loss: 0.974| d_loss: 0.628| gp_loss: 0.047| r_loss: 0.184| p_loss: 0.286| v_loss: 0.043| per_loss: 0.623 | a_loss: 0.542
Train: Epoch [334/3000], Step [30/158]| g_loss: 0.927| d_loss: 0.756| gp_loss: 0.110| r_loss: 0.182| p_loss: 0.310| v_loss: 0.044| per_loss: 0.617 | a_loss: 0.485
Train: Epoch [334/3000], Step [60/158]| g_loss: 1.053| d_loss: 0.514| gp_loss: 0.045| r_loss: 0.210| p_loss: 0.285| v_loss: 0.045| per_loss: 0.651 | a_loss: 0.590
Train: Epoch [334/3000], Step [90/158]| g_loss: 1.008| d_loss: 0.544| gp_loss: 0.046| r_loss: 0.196| p_loss: 0.286| v_loss: 0.046| per_loss: 0.652 | a_loss: 0.557
Train: Epoch [334/3000], Step [120/158]| g_loss: 0.917| d_loss: 0.653| gp_loss: 0.047| r_loss: 0.181| p_loss: 0.274| v_loss: 0.043| per_loss: 0.594 | a_loss: 0.496
Train: Epoch [334/3000], Step [150/158]| g_loss: 1.002| d_loss: 0.605| gp_loss: 0.045| r_loss: 0.192| p_loss: 0.295| v_loss: 0.046| per_loss: 0.649 | a_loss: 0.552
Train: Epoch [335/3000], Step [30/158]| g_loss: 0.995| d_loss: 0.613| gp_loss: 0.117| r_loss: 0.192| p_loss: 0.281| v_loss: 0.044| per_loss: 0.620 | a_loss: 0.555
Train: Epoch [335/3000], Step [60/158]| g_loss: 0.966| d_loss: 0.617| gp_loss: 0.046| r_loss: 0.199| p_loss: 0.284| v_loss: 0.044| per_loss: 0.653 | a_loss: 0.516
Train: Epoch [335/3000], Step [90/158]| g_loss: 0.965| d_loss: 0.636| gp_loss: 0.046| r_loss: 0.185| p_loss: 0.279| v_loss: 0.045| per_loss: 0.579 | a_loss: 0.538
Train: Epoch [335/3000], Step [120/158]| g_loss: 0.948| d_loss: 0.658| gp_loss: 0.046| r_loss: 0.193| p_loss: 0.294| v_loss: 0.045| per_loss: 0.627 | a_loss: 0.500
Train: Epoch [335/3000], Step [150/158]| g_loss: 0.986| d_loss: 0.541| gp_loss: 0.047| r_loss: 0.185| p_loss: 0.277| v_loss: 0.044| per_loss: 0.609 | a_loss: 0.558
Train: Epoch [336/3000], Step [30/158]| g_loss: 0.998| d_loss: 0.659| gp_loss: 0.135| r_loss: 0.185| p_loss: 0.282| v_loss: 0.045| per_loss: 0.582 | a_loss: 0.569
Train: Epoch [336/3000], Step [60/158]| g_loss: 0.966| d_loss: 0.584| gp_loss: 0.048| r_loss: 0.195| p_loss: 0.284| v_loss: 0.043| per_loss: 0.589 | a_loss: 0.527
Train: Epoch [336/3000], Step [90/158]| g_loss: 1.033| d_loss: 0.495| gp_loss: 0.046| r_loss: 0.191| p_loss: 0.280| v_loss: 0.045| per_loss: 0.628 | a_loss: 0.594
Train: Epoch [336/3000], Step [120/158]| g_loss: 0.903| d_loss: 0.719| gp_loss: 0.050| r_loss: 0.184| p_loss: 0.278| v_loss: 0.042| per_loss: 0.625 | a_loss: 0.476
Train: Epoch [336/3000], Step [150/158]| g_loss: 1.039| d_loss: 0.569| gp_loss: 0.042| r_loss: 0.201| p_loss: 0.289| v_loss: 0.044| per_loss: 0.664 | a_loss: 0.583
Train: Epoch [337/3000], Step [30/158]| g_loss: 0.965| d_loss: 0.699| gp_loss: 0.142| r_loss: 0.186| p_loss: 0.280| v_loss: 0.043| per_loss: 0.616 | a_loss: 0.534
Train: Epoch [337/3000], Step [60/158]| g_loss: 0.952| d_loss: 0.595| gp_loss: 0.044| r_loss: 0.190| p_loss: 0.281| v_loss: 0.045| per_loss: 0.636 | a_loss: 0.514
Train: Epoch [337/3000], Step [90/158]| g_loss: 1.047| d_loss: 0.487| gp_loss: 0.046| r_loss: 0.180| p_loss: 0.279| v_loss: 0.045| per_loss: 0.622 | a_loss: 0.620
Train: Epoch [337/3000], Step [120/158]| g_loss: 0.961| d_loss: 0.695| gp_loss: 0.045| r_loss: 0.192| p_loss: 0.286| v_loss: 0.042| per_loss: 0.625 | a_loss: 0.521
Train: Epoch [337/3000], Step [150/158]| g_loss: 0.973| d_loss: 0.529| gp_loss: 0.047| r_loss: 0.200| p_loss: 0.283| v_loss: 0.043| per_loss: 0.626 | a_loss: 0.525
Train: Epoch [338/3000], Step [30/158]| g_loss: 0.963| d_loss: 0.715| gp_loss: 0.099| r_loss: 0.188| p_loss: 0.279| v_loss: 0.045| per_loss: 0.606 | a_loss: 0.529
Train: Epoch [338/3000], Step [60/158]| g_loss: 1.066| d_loss: 0.500| gp_loss: 0.042| r_loss: 0.194| p_loss: 0.288| v_loss: 0.043| per_loss: 0.656 | a_loss: 0.620
Train: Epoch [338/3000], Step [90/158]| g_loss: 0.928| d_loss: 0.653| gp_loss: 0.047| r_loss: 0.190| p_loss: 0.285| v_loss: 0.043| per_loss: 0.588 | a_loss: 0.493
Train: Epoch [338/3000], Step [120/158]| g_loss: 0.944| d_loss: 0.630| gp_loss: 0.044| r_loss: 0.182| p_loss: 0.265| v_loss: 0.042| per_loss: 0.632 | a_loss: 0.524
Train: Epoch [338/3000], Step [150/158]| g_loss: 0.977| d_loss: 0.613| gp_loss: 0.046| r_loss: 0.196| p_loss: 0.284| v_loss: 0.046| per_loss: 0.670 | a_loss: 0.526
Train: Epoch [339/3000], Step [30/158]| g_loss: 0.943| d_loss: 0.749| gp_loss: 0.171| r_loss: 0.186| p_loss: 0.286| v_loss: 0.044| per_loss: 0.587 | a_loss: 0.512
Train: Epoch [339/3000], Step [60/158]| g_loss: 0.937| d_loss: 0.592| gp_loss: 0.042| r_loss: 0.187| p_loss: 0.265| v_loss: 0.044| per_loss: 0.622 | a_loss: 0.511
Train: Epoch [339/3000], Step [90/158]| g_loss: 0.942| d_loss: 0.616| gp_loss: 0.044| r_loss: 0.192| p_loss: 0.273| v_loss: 0.043| per_loss: 0.613 | a_loss: 0.509
Train: Epoch [339/3000], Step [120/158]| g_loss: 1.001| d_loss: 0.572| gp_loss: 0.042| r_loss: 0.190| p_loss: 0.277| v_loss: 0.043| per_loss: 0.590 | a_loss: 0.571
Train: Epoch [339/3000], Step [150/158]| g_loss: 1.018| d_loss: 0.518| gp_loss: 0.040| r_loss: 0.190| p_loss: 0.275| v_loss: 0.043| per_loss: 0.668 | a_loss: 0.580
Train: Epoch [340/3000], Step [30/158]| g_loss: 0.961| d_loss: 0.692| gp_loss: 0.151| r_loss: 0.177| p_loss: 0.265| v_loss: 0.043| per_loss: 0.585 | a_loss: 0.551
Train: Epoch [340/3000], Step [60/158]| g_loss: 0.995| d_loss: 0.529| gp_loss: 0.042| r_loss: 0.189| p_loss: 0.273| v_loss: 0.044| per_loss: 0.672 | a_loss: 0.557
Train: Epoch [340/3000], Step [90/158]| g_loss: 0.943| d_loss: 0.659| gp_loss: 0.043| r_loss: 0.196| p_loss: 0.270| v_loss: 0.043| per_loss: 0.638 | a_loss: 0.505
Train: Epoch [340/3000], Step [120/158]| g_loss: 0.928| d_loss: 0.626| gp_loss: 0.045| r_loss: 0.184| p_loss: 0.273| v_loss: 0.042| per_loss: 0.567 | a_loss: 0.508
Train: Epoch [340/3000], Step [150/158]| g_loss: 1.016| d_loss: 0.535| gp_loss: 0.045| r_loss: 0.193| p_loss: 0.280| v_loss: 0.044| per_loss: 0.629 | a_loss: 0.576
Train: Epoch [341/3000], Step [30/158]| g_loss: 0.980| d_loss: 0.640| gp_loss: 0.107| r_loss: 0.182| p_loss: 0.268| v_loss: 0.043| per_loss: 0.620 | a_loss: 0.558
Train: Epoch [341/3000], Step [60/158]| g_loss: 0.916| d_loss: 0.616| gp_loss: 0.044| r_loss: 0.185| p_loss: 0.274| v_loss: 0.043| per_loss: 0.610 | a_loss: 0.490
Train: Epoch [341/3000], Step [90/158]| g_loss: 0.976| d_loss: 0.577| gp_loss: 0.044| r_loss: 0.191| p_loss: 0.272| v_loss: 0.044| per_loss: 0.611 | a_loss: 0.544
Train: Epoch [341/3000], Step [120/158]| g_loss: 0.959| d_loss: 0.641| gp_loss: 0.045| r_loss: 0.183| p_loss: 0.268| v_loss: 0.043| per_loss: 0.652 | a_loss: 0.534
Train: Epoch [341/3000], Step [150/158]| g_loss: 0.959| d_loss: 0.566| gp_loss: 0.046| r_loss: 0.193| p_loss: 0.273| v_loss: 0.044| per_loss: 0.611 | a_loss: 0.524
Train: Epoch [342/3000], Step [30/158]| g_loss: 1.007| d_loss: 0.562| gp_loss: 0.097| r_loss: 0.181| p_loss: 0.272| v_loss: 0.045| per_loss: 0.662 | a_loss: 0.579
Train: Epoch [342/3000], Step [60/158]| g_loss: 0.892| d_loss: 0.716| gp_loss: 0.047| r_loss: 0.174| p_loss: 0.269| v_loss: 0.042| per_loss: 0.592 | a_loss: 0.483
Train: Epoch [342/3000], Step [90/158]| g_loss: 0.956| d_loss: 0.564| gp_loss: 0.044| r_loss: 0.183| p_loss: 0.278| v_loss: 0.042| per_loss: 0.592 | a_loss: 0.533
Train: Epoch [342/3000], Step [120/158]| g_loss: 1.018| d_loss: 0.515| gp_loss: 0.044| r_loss: 0.193| p_loss: 0.275| v_loss: 0.044| per_loss: 0.603 | a_loss: 0.584
Train: Epoch [342/3000], Step [150/158]| g_loss: 0.913| d_loss: 0.680| gp_loss: 0.049| r_loss: 0.194| p_loss: 0.274| v_loss: 0.042| per_loss: 0.600 | a_loss: 0.480
Train: Epoch [343/3000], Step [30/158]| g_loss: 1.050| d_loss: 0.567| gp_loss: 0.106| r_loss: 0.183| p_loss: 0.284| v_loss: 0.042| per_loss: 0.603 | a_loss: 0.622
Train: Epoch [343/3000], Step [60/158]| g_loss: 0.950| d_loss: 0.627| gp_loss: 0.044| r_loss: 0.198| p_loss: 0.273| v_loss: 0.042| per_loss: 0.628 | a_loss: 0.510
Train: Epoch [343/3000], Step [90/158]| g_loss: 0.992| d_loss: 0.580| gp_loss: 0.046| r_loss: 0.177| p_loss: 0.280| v_loss: 0.043| per_loss: 0.616 | a_loss: 0.570
Train: Epoch [343/3000], Step [120/158]| g_loss: 0.958| d_loss: 0.622| gp_loss: 0.047| r_loss: 0.182| p_loss: 0.280| v_loss: 0.044| per_loss: 0.597 | a_loss: 0.532
Train: Epoch [343/3000], Step [150/158]| g_loss: 0.957| d_loss: 0.617| gp_loss: 0.048| r_loss: 0.194| p_loss: 0.283| v_loss: 0.043| per_loss: 0.601 | a_loss: 0.519
Train: Epoch [344/3000], Step [30/158]| g_loss: 1.019| d_loss: 0.581| gp_loss: 0.105| r_loss: 0.177| p_loss: 0.277| v_loss: 0.045| per_loss: 0.645 | a_loss: 0.594
Train: Epoch [344/3000], Step [60/158]| g_loss: 0.934| d_loss: 0.634| gp_loss: 0.046| r_loss: 0.178| p_loss: 0.278| v_loss: 0.043| per_loss: 0.663 | a_loss: 0.507
Train: Epoch [344/3000], Step [90/158]| g_loss: 0.959| d_loss: 0.594| gp_loss: 0.046| r_loss: 0.179| p_loss: 0.267| v_loss: 0.043| per_loss: 0.619 | a_loss: 0.541
Train: Epoch [344/3000], Step [120/158]| g_loss: 0.970| d_loss: 0.593| gp_loss: 0.047| r_loss: 0.198| p_loss: 0.278| v_loss: 0.045| per_loss: 0.628 | a_loss: 0.526
Train: Epoch [344/3000], Step [150/158]| g_loss: 0.953| d_loss: 0.623| gp_loss: 0.047| r_loss: 0.195| p_loss: 0.275| v_loss: 0.044| per_loss: 0.593 | a_loss: 0.517
Train: Epoch [345/3000], Step [30/158]| g_loss: 0.973| d_loss: 0.664| gp_loss: 0.128| r_loss: 0.201| p_loss: 0.272| v_loss: 0.043| per_loss: 0.637 | a_loss: 0.530
Train: Epoch [345/3000], Step [60/158]| g_loss: 0.943| d_loss: 0.630| gp_loss: 0.048| r_loss: 0.192| p_loss: 0.279| v_loss: 0.041| per_loss: 0.595 | a_loss: 0.512
Train: Epoch [345/3000], Step [90/158]| g_loss: 0.937| d_loss: 0.617| gp_loss: 0.051| r_loss: 0.183| p_loss: 0.280| v_loss: 0.043| per_loss: 0.594 | a_loss: 0.512
Train: Epoch [345/3000], Step [120/158]| g_loss: 0.941| d_loss: 0.603| gp_loss: 0.048| r_loss: 0.175| p_loss: 0.267| v_loss: 0.043| per_loss: 0.585 | a_loss: 0.532
Train: Epoch [345/3000], Step [150/158]| g_loss: 1.006| d_loss: 0.556| gp_loss: 0.046| r_loss: 0.190| p_loss: 0.270| v_loss: 0.045| per_loss: 0.633 | a_loss: 0.572
Train: Epoch [346/3000], Step [30/158]| g_loss: 1.012| d_loss: 0.569| gp_loss: 0.082| r_loss: 0.183| p_loss: 0.282| v_loss: 0.046| per_loss: 0.625 | a_loss: 0.578
Train: Epoch [346/3000], Step [60/158]| g_loss: 1.011| d_loss: 0.577| gp_loss: 0.047| r_loss: 0.200| p_loss: 0.278| v_loss: 0.045| per_loss: 0.633 | a_loss: 0.564
Train: Epoch [346/3000], Step [90/158]| g_loss: 1.029| d_loss: 0.533| gp_loss: 0.048| r_loss: 0.177| p_loss: 0.267| v_loss: 0.047| per_loss: 0.661 | a_loss: 0.605
Train: Epoch [346/3000], Step [120/158]| g_loss: 0.972| d_loss: 0.598| gp_loss: 0.052| r_loss: 0.186| p_loss: 0.275| v_loss: 0.043| per_loss: 0.612 | a_loss: 0.545
Train: Epoch [346/3000], Step [150/158]| g_loss: 0.885| d_loss: 0.727| gp_loss: 0.047| r_loss: 0.193| p_loss: 0.286| v_loss: 0.041| per_loss: 0.627 | a_loss: 0.445
Train: Epoch [347/3000], Step [30/158]| g_loss: 0.957| d_loss: 0.626| gp_loss: 0.123| r_loss: 0.176| p_loss: 0.264| v_loss: 0.043| per_loss: 0.613 | a_loss: 0.544
Train: Epoch [347/3000], Step [60/158]| g_loss: 0.957| d_loss: 0.542| gp_loss: 0.047| r_loss: 0.182| p_loss: 0.270| v_loss: 0.040| per_loss: 0.617 | a_loss: 0.539
Train: Epoch [347/3000], Step [90/158]| g_loss: 0.968| d_loss: 0.607| gp_loss: 0.048| r_loss: 0.184| p_loss: 0.267| v_loss: 0.041| per_loss: 0.596 | a_loss: 0.550
Train: Epoch [347/3000], Step [120/158]| g_loss: 0.972| d_loss: 0.598| gp_loss: 0.056| r_loss: 0.197| p_loss: 0.274| v_loss: 0.044| per_loss: 0.611 | a_loss: 0.533
Train: Epoch [347/3000], Step [150/158]| g_loss: 0.949| d_loss: 0.656| gp_loss: 0.054| r_loss: 0.190| p_loss: 0.288| v_loss: 0.044| per_loss: 0.602 | a_loss: 0.511
Train: Epoch [348/3000], Step [30/158]| g_loss: 0.947| d_loss: 0.682| gp_loss: 0.076| r_loss: 0.193| p_loss: 0.278| v_loss: 0.044| per_loss: 0.624 | a_loss: 0.509
Train: Epoch [348/3000], Step [60/158]| g_loss: 1.005| d_loss: 0.563| gp_loss: 0.050| r_loss: 0.183| p_loss: 0.277| v_loss: 0.043| per_loss: 0.599 | a_loss: 0.581
Train: Epoch [348/3000], Step [90/158]| g_loss: 0.957| d_loss: 0.587| gp_loss: 0.053| r_loss: 0.197| p_loss: 0.276| v_loss: 0.043| per_loss: 0.601 | a_loss: 0.518
Train: Epoch [348/3000], Step [120/158]| g_loss: 1.004| d_loss: 0.528| gp_loss: 0.049| r_loss: 0.176| p_loss: 0.266| v_loss: 0.044| per_loss: 0.624 | a_loss: 0.589
Train: Epoch [348/3000], Step [150/158]| g_loss: 0.915| d_loss: 0.723| gp_loss: 0.052| r_loss: 0.177| p_loss: 0.267| v_loss: 0.043| per_loss: 0.622 | a_loss: 0.498
Train: Epoch [349/3000], Step [30/158]| g_loss: 1.012| d_loss: 0.616| gp_loss: 0.156| r_loss: 0.197| p_loss: 0.278| v_loss: 0.045| per_loss: 0.628 | a_loss: 0.569
Train: Epoch [349/3000], Step [60/158]| g_loss: 0.873| d_loss: 0.723| gp_loss: 0.048| r_loss: 0.176| p_loss: 0.265| v_loss: 0.041| per_loss: 0.632 | a_loss: 0.460
Train: Epoch [349/3000], Step [90/158]| g_loss: 0.957| d_loss: 0.566| gp_loss: 0.048| r_loss: 0.178| p_loss: 0.267| v_loss: 0.045| per_loss: 0.596 | a_loss: 0.542
Train: Epoch [349/3000], Step [120/158]| g_loss: 0.951| d_loss: 0.615| gp_loss: 0.048| r_loss: 0.185| p_loss: 0.275| v_loss: 0.044| per_loss: 0.565 | a_loss: 0.528
Train: Epoch [349/3000], Step [150/158]| g_loss: 0.951| d_loss: 0.600| gp_loss: 0.050| r_loss: 0.181| p_loss: 0.277| v_loss: 0.043| per_loss: 0.618 | a_loss: 0.527
Train: Epoch [350/3000], Step [30/158]| g_loss: 0.997| d_loss: 0.696| gp_loss: 0.177| r_loss: 0.190| p_loss: 0.267| v_loss: 0.043| per_loss: 0.658 | a_loss: 0.564
Train: Epoch [350/3000], Step [60/158]| g_loss: 0.929| d_loss: 0.689| gp_loss: 0.045| r_loss: 0.185| p_loss: 0.280| v_loss: 0.046| per_loss: 0.627 | a_loss: 0.495
Train: Epoch [350/3000], Step [90/158]| g_loss: 0.990| d_loss: 0.514| gp_loss: 0.045| r_loss: 0.177| p_loss: 0.269| v_loss: 0.042| per_loss: 0.639 | a_loss: 0.572
Train: Epoch [350/3000], Step [120/158]| g_loss: 0.918| d_loss: 0.658| gp_loss: 0.051| r_loss: 0.186| p_loss: 0.275| v_loss: 0.041| per_loss: 0.613 | a_loss: 0.492
Train: Epoch [350/3000], Step [150/158]| g_loss: 1.000| d_loss: 0.536| gp_loss: 0.048| r_loss: 0.177| p_loss: 0.276| v_loss: 0.042| per_loss: 0.589 | a_loss: 0.584
Test: Epoch [350/3000]| g_loss: 0.873| r_loss: 0.576| p_loss: 0.373| v_loss: 0.032
Train: Epoch [351/3000], Step [30/158]| g_loss: 0.981| d_loss: 0.558| gp_loss: 0.045| r_loss: 0.183| p_loss: 0.264| v_loss: 0.040| per_loss: 0.588 | a_loss: 0.567
Train: Epoch [351/3000], Step [60/158]| g_loss: 0.958| d_loss: 0.610| gp_loss: 0.045| r_loss: 0.188| p_loss: 0.268| v_loss: 0.043| per_loss: 0.591 | a_loss: 0.535
Train: Epoch [351/3000], Step [90/158]| g_loss: 0.980| d_loss: 0.618| gp_loss: 0.046| r_loss: 0.175| p_loss: 0.286| v_loss: 0.045| per_loss: 0.641 | a_loss: 0.552
Train: Epoch [351/3000], Step [120/158]| g_loss: 0.967| d_loss: 0.651| gp_loss: 0.046| r_loss: 0.194| p_loss: 0.291| v_loss: 0.045| per_loss: 0.661 | a_loss: 0.516
Train: Epoch [351/3000], Step [150/158]| g_loss: 1.007| d_loss: 0.559| gp_loss: 0.043| r_loss: 0.181| p_loss: 0.275| v_loss: 0.044| per_loss: 0.645 | a_loss: 0.579
Train: Epoch [352/3000], Step [30/158]| g_loss: 0.962| d_loss: 0.712| gp_loss: 0.168| r_loss: 0.185| p_loss: 0.280| v_loss: 0.043| per_loss: 0.631 | a_loss: 0.530
Train: Epoch [352/3000], Step [60/158]| g_loss: 0.949| d_loss: 0.593| gp_loss: 0.042| r_loss: 0.179| p_loss: 0.271| v_loss: 0.044| per_loss: 0.595 | a_loss: 0.531
Train: Epoch [352/3000], Step [90/158]| g_loss: 0.967| d_loss: 0.579| gp_loss: 0.043| r_loss: 0.181| p_loss: 0.276| v_loss: 0.043| per_loss: 0.601 | a_loss: 0.545
Train: Epoch [352/3000], Step [120/158]| g_loss: 0.943| d_loss: 0.585| gp_loss: 0.042| r_loss: 0.181| p_loss: 0.270| v_loss: 0.043| per_loss: 0.610 | a_loss: 0.524
Train: Epoch [352/3000], Step [150/158]| g_loss: 0.972| d_loss: 0.629| gp_loss: 0.044| r_loss: 0.186| p_loss: 0.272| v_loss: 0.041| per_loss: 0.585 | a_loss: 0.552
Train: Epoch [353/3000], Step [30/158]| g_loss: 0.962| d_loss: 0.636| gp_loss: 0.103| r_loss: 0.192| p_loss: 0.284| v_loss: 0.042| per_loss: 0.589 | a_loss: 0.526
Train: Epoch [353/3000], Step [60/158]| g_loss: 0.999| d_loss: 0.514| gp_loss: 0.042| r_loss: 0.173| p_loss: 0.271| v_loss: 0.042| per_loss: 0.598 | a_loss: 0.590
Train: Epoch [353/3000], Step [90/158]| g_loss: 0.953| d_loss: 0.578| gp_loss: 0.046| r_loss: 0.176| p_loss: 0.262| v_loss: 0.042| per_loss: 0.613 | a_loss: 0.543
Train: Epoch [353/3000], Step [120/158]| g_loss: 0.928| d_loss: 0.647| gp_loss: 0.045| r_loss: 0.183| p_loss: 0.274| v_loss: 0.043| per_loss: 0.565 | a_loss: 0.509
Train: Epoch [353/3000], Step [150/158]| g_loss: 0.908| d_loss: 0.653| gp_loss: 0.049| r_loss: 0.176| p_loss: 0.267| v_loss: 0.041| per_loss: 0.597 | a_loss: 0.497
Train: Epoch [354/3000], Step [30/158]| g_loss: 1.005| d_loss: 0.650| gp_loss: 0.130| r_loss: 0.200| p_loss: 0.279| v_loss: 0.046| per_loss: 0.569 | a_loss: 0.562
Train: Epoch [354/3000], Step [60/158]| g_loss: 0.953| d_loss: 0.598| gp_loss: 0.047| r_loss: 0.187| p_loss: 0.282| v_loss: 0.044| per_loss: 0.589 | a_loss: 0.522
Train: Epoch [354/3000], Step [90/158]| g_loss: 0.949| d_loss: 0.614| gp_loss: 0.048| r_loss: 0.188| p_loss: 0.282| v_loss: 0.042| per_loss: 0.627 | a_loss: 0.516
Train: Epoch [354/3000], Step [120/158]| g_loss: 0.960| d_loss: 0.618| gp_loss: 0.050| r_loss: 0.175| p_loss: 0.277| v_loss: 0.041| per_loss: 0.606 | a_loss: 0.545
Train: Epoch [354/3000], Step [150/158]| g_loss: 0.983| d_loss: 0.584| gp_loss: 0.049| r_loss: 0.196| p_loss: 0.278| v_loss: 0.041| per_loss: 0.619 | a_loss: 0.546
Train: Epoch [355/3000], Step [30/158]| g_loss: 0.921| d_loss: 0.752| gp_loss: 0.107| r_loss: 0.192| p_loss: 0.293| v_loss: 0.043| per_loss: 0.624 | a_loss: 0.476
Train: Epoch [355/3000], Step [60/158]| g_loss: 0.965| d_loss: 0.635| gp_loss: 0.047| r_loss: 0.189| p_loss: 0.277| v_loss: 0.042| per_loss: 0.647 | a_loss: 0.532
Train: Epoch [355/3000], Step [90/158]| g_loss: 0.949| d_loss: 0.623| gp_loss: 0.049| r_loss: 0.182| p_loss: 0.279| v_loss: 0.042| per_loss: 0.616 | a_loss: 0.523
Train: Epoch [355/3000], Step [120/158]| g_loss: 0.933| d_loss: 0.583| gp_loss: 0.048| r_loss: 0.186| p_loss: 0.277| v_loss: 0.042| per_loss: 0.613 | a_loss: 0.506
Train: Epoch [355/3000], Step [150/158]| g_loss: 0.980| d_loss: 0.529| gp_loss: 0.049| r_loss: 0.186| p_loss: 0.269| v_loss: 0.043| per_loss: 0.615 | a_loss: 0.555
Train: Epoch [356/3000], Step [30/158]| g_loss: 0.990| d_loss: 0.664| gp_loss: 0.124| r_loss: 0.183| p_loss: 0.268| v_loss: 0.042| per_loss: 0.618 | a_loss: 0.569
Train: Epoch [356/3000], Step [60/158]| g_loss: 0.976| d_loss: 0.615| gp_loss: 0.046| r_loss: 0.189| p_loss: 0.294| v_loss: 0.040| per_loss: 0.619 | a_loss: 0.538
Train: Epoch [356/3000], Step [90/158]| g_loss: 0.992| d_loss: 0.566| gp_loss: 0.049| r_loss: 0.202| p_loss: 0.285| v_loss: 0.043| per_loss: 0.622 | a_loss: 0.543
Train: Epoch [356/3000], Step [120/158]| g_loss: 0.965| d_loss: 0.606| gp_loss: 0.047| r_loss: 0.181| p_loss: 0.274| v_loss: 0.042| per_loss: 0.614 | a_loss: 0.544
Train: Epoch [356/3000], Step [150/158]| g_loss: 0.879| d_loss: 0.685| gp_loss: 0.050| r_loss: 0.171| p_loss: 0.270| v_loss: 0.040| per_loss: 0.625 | a_loss: 0.471
Train: Epoch [357/3000], Step [30/158]| g_loss: 1.028| d_loss: 0.645| gp_loss: 0.131| r_loss: 0.200| p_loss: 0.287| v_loss: 0.043| per_loss: 0.620 | a_loss: 0.580
Train: Epoch [357/3000], Step [60/158]| g_loss: 0.981| d_loss: 0.651| gp_loss: 0.047| r_loss: 0.191| p_loss: 0.288| v_loss: 0.042| per_loss: 0.598 | a_loss: 0.545
Train: Epoch [357/3000], Step [90/158]| g_loss: 0.939| d_loss: 0.605| gp_loss: 0.042| r_loss: 0.174| p_loss: 0.268| v_loss: 0.040| per_loss: 0.595 | a_loss: 0.531
Train: Epoch [357/3000], Step [120/158]| g_loss: 0.975| d_loss: 0.564| gp_loss: 0.047| r_loss: 0.181| p_loss: 0.280| v_loss: 0.044| per_loss: 0.645 | a_loss: 0.546
Train: Epoch [357/3000], Step [150/158]| g_loss: 0.918| d_loss: 0.606| gp_loss: 0.047| r_loss: 0.193| p_loss: 0.271| v_loss: 0.043| per_loss: 0.597 | a_loss: 0.487
Train: Epoch [358/3000], Step [30/158]| g_loss: 1.029| d_loss: 0.520| gp_loss: 0.088| r_loss: 0.174| p_loss: 0.265| v_loss: 0.043| per_loss: 0.635 | a_loss: 0.617
Train: Epoch [358/3000], Step [60/158]| g_loss: 0.935| d_loss: 0.677| gp_loss: 0.049| r_loss: 0.187| p_loss: 0.279| v_loss: 0.041| per_loss: 0.610 | a_loss: 0.507
Train: Epoch [358/3000], Step [90/158]| g_loss: 0.988| d_loss: 0.548| gp_loss: 0.046| r_loss: 0.198| p_loss: 0.269| v_loss: 0.042| per_loss: 0.638 | a_loss: 0.550
Train: Epoch [358/3000], Step [120/158]| g_loss: 0.912| d_loss: 0.676| gp_loss: 0.045| r_loss: 0.177| p_loss: 0.264| v_loss: 0.041| per_loss: 0.634 | a_loss: 0.498
Train: Epoch [358/3000], Step [150/158]| g_loss: 0.924| d_loss: 0.586| gp_loss: 0.049| r_loss: 0.180| p_loss: 0.272| v_loss: 0.042| per_loss: 0.615 | a_loss: 0.505
Train: Epoch [359/3000], Step [30/158]| g_loss: 0.924| d_loss: 0.703| gp_loss: 0.128| r_loss: 0.174| p_loss: 0.262| v_loss: 0.041| per_loss: 0.626 | a_loss: 0.516
Train: Epoch [359/3000], Step [60/158]| g_loss: 0.993| d_loss: 0.538| gp_loss: 0.046| r_loss: 0.178| p_loss: 0.273| v_loss: 0.042| per_loss: 0.610 | a_loss: 0.576
Train: Epoch [359/3000], Step [90/158]| g_loss: 0.972| d_loss: 0.557| gp_loss: 0.047| r_loss: 0.172| p_loss: 0.262| v_loss: 0.041| per_loss: 0.593 | a_loss: 0.568
Train: Epoch [359/3000], Step [120/158]| g_loss: 0.979| d_loss: 0.620| gp_loss: 0.050| r_loss: 0.196| p_loss: 0.284| v_loss: 0.043| per_loss: 0.638 | a_loss: 0.534
Train: Epoch [359/3000], Step [150/158]| g_loss: 0.988| d_loss: 0.565| gp_loss: 0.048| r_loss: 0.181| p_loss: 0.269| v_loss: 0.041| per_loss: 0.646 | a_loss: 0.568
Train: Epoch [360/3000], Step [30/158]| g_loss: 0.914| d_loss: 0.758| gp_loss: 0.138| r_loss: 0.182| p_loss: 0.267| v_loss: 0.043| per_loss: 0.610 | a_loss: 0.494
Train: Epoch [360/3000], Step [60/158]| g_loss: 0.944| d_loss: 0.594| gp_loss: 0.049| r_loss: 0.189| p_loss: 0.276| v_loss: 0.042| per_loss: 0.667 | a_loss: 0.509
Train: Epoch [360/3000], Step [90/158]| g_loss: 1.069| d_loss: 0.464| gp_loss: 0.046| r_loss: 0.176| p_loss: 0.276| v_loss: 0.044| per_loss: 0.613 | a_loss: 0.650
Train: Epoch [360/3000], Step [120/158]| g_loss: 0.981| d_loss: 0.564| gp_loss: 0.047| r_loss: 0.186| p_loss: 0.267| v_loss: 0.041| per_loss: 0.598 | a_loss: 0.559
Train: Epoch [360/3000], Step [150/158]| g_loss: 0.890| d_loss: 0.662| gp_loss: 0.052| r_loss: 0.173| p_loss: 0.266| v_loss: 0.041| per_loss: 0.634 | a_loss: 0.480
Train: Epoch [361/3000], Step [30/158]| g_loss: 0.963| d_loss: 0.652| gp_loss: 0.119| r_loss: 0.180| p_loss: 0.272| v_loss: 0.044| per_loss: 0.611 | a_loss: 0.541
Train: Epoch [361/3000], Step [60/158]| g_loss: 0.961| d_loss: 0.586| gp_loss: 0.049| r_loss: 0.171| p_loss: 0.266| v_loss: 0.042| per_loss: 0.660 | a_loss: 0.549
Train: Epoch [361/3000], Step [90/158]| g_loss: 0.935| d_loss: 0.611| gp_loss: 0.049| r_loss: 0.181| p_loss: 0.270| v_loss: 0.043| per_loss: 0.583 | a_loss: 0.518
Train: Epoch [361/3000], Step [120/158]| g_loss: 0.938| d_loss: 0.659| gp_loss: 0.046| r_loss: 0.179| p_loss: 0.288| v_loss: 0.039| per_loss: 0.593 | a_loss: 0.516
Train: Epoch [361/3000], Step [150/158]| g_loss: 1.018| d_loss: 0.544| gp_loss: 0.048| r_loss: 0.198| p_loss: 0.272| v_loss: 0.041| per_loss: 0.641 | a_loss: 0.579
Train: Epoch [362/3000], Step [30/158]| g_loss: 0.952| d_loss: 0.639| gp_loss: 0.134| r_loss: 0.192| p_loss: 0.278| v_loss: 0.042| per_loss: 0.649 | a_loss: 0.515
Train: Epoch [362/3000], Step [60/158]| g_loss: 1.031| d_loss: 0.569| gp_loss: 0.044| r_loss: 0.186| p_loss: 0.285| v_loss: 0.043| per_loss: 0.609 | a_loss: 0.599
Train: Epoch [362/3000], Step [90/158]| g_loss: 0.949| d_loss: 0.650| gp_loss: 0.050| r_loss: 0.183| p_loss: 0.279| v_loss: 0.044| per_loss: 0.602 | a_loss: 0.523
Train: Epoch [362/3000], Step [120/158]| g_loss: 0.960| d_loss: 0.614| gp_loss: 0.048| r_loss: 0.177| p_loss: 0.276| v_loss: 0.043| per_loss: 0.613 | a_loss: 0.540
Train: Epoch [362/3000], Step [150/158]| g_loss: 0.966| d_loss: 0.558| gp_loss: 0.045| r_loss: 0.186| p_loss: 0.276| v_loss: 0.042| per_loss: 0.624 | a_loss: 0.537
Train: Epoch [363/3000], Step [30/158]| g_loss: 0.935| d_loss: 0.744| gp_loss: 0.167| r_loss: 0.183| p_loss: 0.270| v_loss: 0.042| per_loss: 0.618 | a_loss: 0.513
Train: Epoch [363/3000], Step [60/158]| g_loss: 0.933| d_loss: 0.632| gp_loss: 0.043| r_loss: 0.188| p_loss: 0.271| v_loss: 0.041| per_loss: 0.625 | a_loss: 0.507
Train: Epoch [363/3000], Step [90/158]| g_loss: 0.983| d_loss: 0.526| gp_loss: 0.042| r_loss: 0.172| p_loss: 0.272| v_loss: 0.041| per_loss: 0.612 | a_loss: 0.573
Train: Epoch [363/3000], Step [120/158]| g_loss: 0.932| d_loss: 0.681| gp_loss: 0.049| r_loss: 0.185| p_loss: 0.287| v_loss: 0.042| per_loss: 0.651 | a_loss: 0.496
Train: Epoch [363/3000], Step [150/158]| g_loss: 0.911| d_loss: 0.632| gp_loss: 0.046| r_loss: 0.195| p_loss: 0.284| v_loss: 0.042| per_loss: 0.619 | a_loss: 0.470
Train: Epoch [364/3000], Step [30/158]| g_loss: 0.950| d_loss: 0.707| gp_loss: 0.100| r_loss: 0.193| p_loss: 0.284| v_loss: 0.042| per_loss: 0.657 | a_loss: 0.508
Train: Epoch [364/3000], Step [60/158]| g_loss: 0.950| d_loss: 0.577| gp_loss: 0.046| r_loss: 0.175| p_loss: 0.276| v_loss: 0.043| per_loss: 0.603 | a_loss: 0.534
Train: Epoch [364/3000], Step [90/158]| g_loss: 0.943| d_loss: 0.608| gp_loss: 0.045| r_loss: 0.178| p_loss: 0.273| v_loss: 0.043| per_loss: 0.612 | a_loss: 0.525
Train: Epoch [364/3000], Step [120/158]| g_loss: 0.906| d_loss: 0.629| gp_loss: 0.048| r_loss: 0.169| p_loss: 0.266| v_loss: 0.040| per_loss: 0.615 | a_loss: 0.502
Train: Epoch [364/3000], Step [150/158]| g_loss: 1.049| d_loss: 0.491| gp_loss: 0.049| r_loss: 0.196| p_loss: 0.284| v_loss: 0.044| per_loss: 0.643 | a_loss: 0.604
Train: Epoch [365/3000], Step [30/158]| g_loss: 1.003| d_loss: 0.626| gp_loss: 0.131| r_loss: 0.180| p_loss: 0.265| v_loss: 0.041| per_loss: 0.646 | a_loss: 0.585
Train: Epoch [365/3000], Step [60/158]| g_loss: 0.952| d_loss: 0.699| gp_loss: 0.043| r_loss: 0.199| p_loss: 0.290| v_loss: 0.042| per_loss: 0.623 | a_loss: 0.503
Train: Epoch [365/3000], Step [90/158]| g_loss: 0.905| d_loss: 0.661| gp_loss: 0.049| r_loss: 0.179| p_loss: 0.289| v_loss: 0.042| per_loss: 0.648 | a_loss: 0.475
Train: Epoch [365/3000], Step [120/158]| g_loss: 0.951| d_loss: 0.575| gp_loss: 0.047| r_loss: 0.181| p_loss: 0.267| v_loss: 0.042| per_loss: 0.642 | a_loss: 0.530
Train: Epoch [365/3000], Step [150/158]| g_loss: 1.024| d_loss: 0.526| gp_loss: 0.045| r_loss: 0.179| p_loss: 0.261| v_loss: 0.041| per_loss: 0.609 | a_loss: 0.612
Train: Epoch [366/3000], Step [30/158]| g_loss: 0.966| d_loss: 0.631| gp_loss: 0.128| r_loss: 0.185| p_loss: 0.273| v_loss: 0.043| per_loss: 0.602 | a_loss: 0.542
Train: Epoch [366/3000], Step [60/158]| g_loss: 0.899| d_loss: 0.718| gp_loss: 0.044| r_loss: 0.186| p_loss: 0.274| v_loss: 0.041| per_loss: 0.619 | a_loss: 0.472
Train: Epoch [366/3000], Step [90/158]| g_loss: 0.940| d_loss: 0.625| gp_loss: 0.046| r_loss: 0.180| p_loss: 0.278| v_loss: 0.042| per_loss: 0.618 | a_loss: 0.517
Train: Epoch [366/3000], Step [120/158]| g_loss: 0.971| d_loss: 0.542| gp_loss: 0.048| r_loss: 0.166| p_loss: 0.266| v_loss: 0.040| per_loss: 0.666 | a_loss: 0.564
Train: Epoch [366/3000], Step [150/158]| g_loss: 1.023| d_loss: 0.541| gp_loss: 0.044| r_loss: 0.195| p_loss: 0.275| v_loss: 0.042| per_loss: 0.597 | a_loss: 0.589
Train: Epoch [367/3000], Step [30/158]| g_loss: 0.931| d_loss: 0.709| gp_loss: 0.129| r_loss: 0.178| p_loss: 0.274| v_loss: 0.040| per_loss: 0.619 | a_loss: 0.515
Train: Epoch [367/3000], Step [60/158]| g_loss: 0.897| d_loss: 0.697| gp_loss: 0.047| r_loss: 0.189| p_loss: 0.285| v_loss: 0.043| per_loss: 0.614 | a_loss: 0.461
Train: Epoch [367/3000], Step [90/158]| g_loss: 0.975| d_loss: 0.589| gp_loss: 0.046| r_loss: 0.193| p_loss: 0.276| v_loss: 0.044| per_loss: 0.641 | a_loss: 0.537
Train: Epoch [367/3000], Step [120/158]| g_loss: 0.929| d_loss: 0.618| gp_loss: 0.047| r_loss: 0.182| p_loss: 0.274| v_loss: 0.041| per_loss: 0.597 | a_loss: 0.509
Train: Epoch [367/3000], Step [150/158]| g_loss: 1.025| d_loss: 0.485| gp_loss: 0.047| r_loss: 0.171| p_loss: 0.272| v_loss: 0.042| per_loss: 0.595 | a_loss: 0.616
Train: Epoch [368/3000], Step [30/158]| g_loss: 0.983| d_loss: 0.691| gp_loss: 0.163| r_loss: 0.195| p_loss: 0.281| v_loss: 0.044| per_loss: 0.577 | a_loss: 0.546
Train: Epoch [368/3000], Step [60/158]| g_loss: 0.957| d_loss: 0.632| gp_loss: 0.049| r_loss: 0.187| p_loss: 0.276| v_loss: 0.043| per_loss: 0.622 | a_loss: 0.527
Train: Epoch [368/3000], Step [90/158]| g_loss: 0.942| d_loss: 0.640| gp_loss: 0.049| r_loss: 0.184| p_loss: 0.289| v_loss: 0.043| per_loss: 0.622 | a_loss: 0.508
Train: Epoch [368/3000], Step [120/158]| g_loss: 0.974| d_loss: 0.554| gp_loss: 0.044| r_loss: 0.179| p_loss: 0.279| v_loss: 0.042| per_loss: 0.612 | a_loss: 0.553
Train: Epoch [368/3000], Step [150/158]| g_loss: 0.990| d_loss: 0.560| gp_loss: 0.045| r_loss: 0.176| p_loss: 0.268| v_loss: 0.041| per_loss: 0.625 | a_loss: 0.577
Train: Epoch [369/3000], Step [30/158]| g_loss: 0.899| d_loss: 0.764| gp_loss: 0.115| r_loss: 0.184| p_loss: 0.285| v_loss: 0.042| per_loss: 0.604 | a_loss: 0.470
Train: Epoch [369/3000], Step [60/158]| g_loss: 0.971| d_loss: 0.559| gp_loss: 0.042| r_loss: 0.170| p_loss: 0.271| v_loss: 0.043| per_loss: 0.611 | a_loss: 0.561
Train: Epoch [369/3000], Step [90/158]| g_loss: 0.909| d_loss: 0.691| gp_loss: 0.047| r_loss: 0.186| p_loss: 0.273| v_loss: 0.040| per_loss: 0.653 | a_loss: 0.482
Train: Epoch [369/3000], Step [120/158]| g_loss: 1.004| d_loss: 0.539| gp_loss: 0.040| r_loss: 0.186| p_loss: 0.271| v_loss: 0.042| per_loss: 0.629 | a_loss: 0.577
Train: Epoch [369/3000], Step [150/158]| g_loss: 0.960| d_loss: 0.560| gp_loss: 0.047| r_loss: 0.177| p_loss: 0.268| v_loss: 0.042| per_loss: 0.605 | a_loss: 0.547
Train: Epoch [370/3000], Step [30/158]| g_loss: 0.937| d_loss: 0.735| gp_loss: 0.134| r_loss: 0.173| p_loss: 0.273| v_loss: 0.043| per_loss: 0.621 | a_loss: 0.522
Train: Epoch [370/3000], Step [60/158]| g_loss: 0.972| d_loss: 0.581| gp_loss: 0.043| r_loss: 0.178| p_loss: 0.270| v_loss: 0.044| per_loss: 0.635 | a_loss: 0.551
Train: Epoch [370/3000], Step [90/158]| g_loss: 0.967| d_loss: 0.578| gp_loss: 0.045| r_loss: 0.182| p_loss: 0.265| v_loss: 0.042| per_loss: 0.591 | a_loss: 0.552
Train: Epoch [370/3000], Step [120/158]| g_loss: 0.937| d_loss: 0.603| gp_loss: 0.047| r_loss: 0.184| p_loss: 0.264| v_loss: 0.041| per_loss: 0.616 | a_loss: 0.518
Train: Epoch [370/3000], Step [150/158]| g_loss: 0.981| d_loss: 0.586| gp_loss: 0.044| r_loss: 0.186| p_loss: 0.273| v_loss: 0.042| per_loss: 0.600 | a_loss: 0.557
Train: Epoch [371/3000], Step [30/158]| g_loss: 0.948| d_loss: 0.691| gp_loss: 0.134| r_loss: 0.174| p_loss: 0.264| v_loss: 0.041| per_loss: 0.610 | a_loss: 0.540
Train: Epoch [371/3000], Step [60/158]| g_loss: 0.950| d_loss: 0.548| gp_loss: 0.045| r_loss: 0.180| p_loss: 0.269| v_loss: 0.043| per_loss: 0.580 | a_loss: 0.535
Train: Epoch [371/3000], Step [90/158]| g_loss: 0.923| d_loss: 0.643| gp_loss: 0.043| r_loss: 0.175| p_loss: 0.258| v_loss: 0.041| per_loss: 0.610 | a_loss: 0.517
Train: Epoch [371/3000], Step [120/158]| g_loss: 0.915| d_loss: 0.555| gp_loss: 0.042| r_loss: 0.168| p_loss: 0.251| v_loss: 0.042| per_loss: 0.578 | a_loss: 0.522
Train: Epoch [371/3000], Step [150/158]| g_loss: 0.970| d_loss: 0.610| gp_loss: 0.045| r_loss: 0.183| p_loss: 0.260| v_loss: 0.042| per_loss: 0.621 | a_loss: 0.553
Train: Epoch [372/3000], Step [30/158]| g_loss: 0.920| d_loss: 0.703| gp_loss: 0.090| r_loss: 0.177| p_loss: 0.263| v_loss: 0.041| per_loss: 0.572 | a_loss: 0.513
Train: Epoch [372/3000], Step [60/158]| g_loss: 0.939| d_loss: 0.612| gp_loss: 0.051| r_loss: 0.186| p_loss: 0.276| v_loss: 0.042| per_loss: 0.615 | a_loss: 0.511
Train: Epoch [372/3000], Step [90/158]| g_loss: 0.929| d_loss: 0.609| gp_loss: 0.045| r_loss: 0.170| p_loss: 0.250| v_loss: 0.043| per_loss: 0.599 | a_loss: 0.531
Train: Epoch [372/3000], Step [120/158]| g_loss: 0.994| d_loss: 0.543| gp_loss: 0.045| r_loss: 0.185| p_loss: 0.269| v_loss: 0.043| per_loss: 0.634 | a_loss: 0.568
Train: Epoch [372/3000], Step [150/158]| g_loss: 0.937| d_loss: 0.609| gp_loss: 0.049| r_loss: 0.168| p_loss: 0.263| v_loss: 0.040| per_loss: 0.616 | a_loss: 0.535
Train: Epoch [373/3000], Step [30/158]| g_loss: 0.929| d_loss: 0.705| gp_loss: 0.118| r_loss: 0.184| p_loss: 0.270| v_loss: 0.041| per_loss: 0.621 | a_loss: 0.506
Train: Epoch [373/3000], Step [60/158]| g_loss: 0.938| d_loss: 0.606| gp_loss: 0.046| r_loss: 0.164| p_loss: 0.256| v_loss: 0.042| per_loss: 0.580 | a_loss: 0.546
Train: Epoch [373/3000], Step [90/158]| g_loss: 0.901| d_loss: 0.674| gp_loss: 0.047| r_loss: 0.179| p_loss: 0.263| v_loss: 0.041| per_loss: 0.633 | a_loss: 0.487
Train: Epoch [373/3000], Step [120/158]| g_loss: 0.902| d_loss: 0.628| gp_loss: 0.051| r_loss: 0.183| p_loss: 0.272| v_loss: 0.041| per_loss: 0.618 | a_loss: 0.480
Train: Epoch [373/3000], Step [150/158]| g_loss: 1.037| d_loss: 0.490| gp_loss: 0.048| r_loss: 0.175| p_loss: 0.264| v_loss: 0.042| per_loss: 0.604 | a_loss: 0.628
Train: Epoch [374/3000], Step [30/158]| g_loss: 1.008| d_loss: 0.597| gp_loss: 0.125| r_loss: 0.180| p_loss: 0.269| v_loss: 0.043| per_loss: 0.583 | a_loss: 0.591
Train: Epoch [374/3000], Step [60/158]| g_loss: 0.968| d_loss: 0.586| gp_loss: 0.044| r_loss: 0.177| p_loss: 0.262| v_loss: 0.042| per_loss: 0.593 | a_loss: 0.558
Train: Epoch [374/3000], Step [90/158]| g_loss: 0.987| d_loss: 0.512| gp_loss: 0.047| r_loss: 0.171| p_loss: 0.254| v_loss: 0.041| per_loss: 0.627 | a_loss: 0.586
Train: Epoch [374/3000], Step [120/158]| g_loss: 0.928| d_loss: 0.640| gp_loss: 0.052| r_loss: 0.179| p_loss: 0.259| v_loss: 0.042| per_loss: 0.571 | a_loss: 0.520
Train: Epoch [374/3000], Step [150/158]| g_loss: 0.912| d_loss: 0.629| gp_loss: 0.050| r_loss: 0.179| p_loss: 0.274| v_loss: 0.042| per_loss: 0.571 | a_loss: 0.498
Train: Epoch [375/3000], Step [30/158]| g_loss: 0.962| d_loss: 0.604| gp_loss: 0.125| r_loss: 0.181| p_loss: 0.266| v_loss: 0.043| per_loss: 0.640 | a_loss: 0.542
Train: Epoch [375/3000], Step [60/158]| g_loss: 0.994| d_loss: 0.588| gp_loss: 0.047| r_loss: 0.173| p_loss: 0.264| v_loss: 0.042| per_loss: 0.593 | a_loss: 0.588
Train: Epoch [375/3000], Step [90/158]| g_loss: 0.932| d_loss: 0.600| gp_loss: 0.048| r_loss: 0.174| p_loss: 0.265| v_loss: 0.042| per_loss: 0.607 | a_loss: 0.523
Train: Epoch [375/3000], Step [120/158]| g_loss: 0.930| d_loss: 0.642| gp_loss: 0.052| r_loss: 0.172| p_loss: 0.261| v_loss: 0.043| per_loss: 0.601 | a_loss: 0.526
Train: Epoch [375/3000], Step [150/158]| g_loss: 0.901| d_loss: 0.679| gp_loss: 0.049| r_loss: 0.187| p_loss: 0.272| v_loss: 0.043| per_loss: 0.570 | a_loss: 0.478
Train: Epoch [376/3000], Step [30/158]| g_loss: 0.965| d_loss: 0.636| gp_loss: 0.140| r_loss: 0.176| p_loss: 0.261| v_loss: 0.042| per_loss: 0.610 | a_loss: 0.556
Train: Epoch [376/3000], Step [60/158]| g_loss: 0.929| d_loss: 0.633| gp_loss: 0.047| r_loss: 0.186| p_loss: 0.269| v_loss: 0.043| per_loss: 0.585 | a_loss: 0.507
Train: Epoch [376/3000], Step [90/158]| g_loss: 0.876| d_loss: 0.668| gp_loss: 0.048| r_loss: 0.167| p_loss: 0.254| v_loss: 0.041| per_loss: 0.588 | a_loss: 0.483
Train: Epoch [376/3000], Step [120/158]| g_loss: 1.001| d_loss: 0.594| gp_loss: 0.043| r_loss: 0.182| p_loss: 0.277| v_loss: 0.043| per_loss: 0.597 | a_loss: 0.578
Train: Epoch [376/3000], Step [150/158]| g_loss: 0.958| d_loss: 0.540| gp_loss: 0.048| r_loss: 0.176| p_loss: 0.269| v_loss: 0.042| per_loss: 0.549 | a_loss: 0.551
Train: Epoch [377/3000], Step [30/158]| g_loss: 0.972| d_loss: 0.674| gp_loss: 0.171| r_loss: 0.174| p_loss: 0.259| v_loss: 0.042| per_loss: 0.621 | a_loss: 0.565
Train: Epoch [377/3000], Step [60/158]| g_loss: 0.913| d_loss: 0.625| gp_loss: 0.048| r_loss: 0.171| p_loss: 0.251| v_loss: 0.041| per_loss: 0.561 | a_loss: 0.520
Train: Epoch [377/3000], Step [90/158]| g_loss: 0.919| d_loss: 0.619| gp_loss: 0.047| r_loss: 0.179| p_loss: 0.263| v_loss: 0.043| per_loss: 0.594 | a_loss: 0.507
Train: Epoch [377/3000], Step [120/158]| g_loss: 0.877| d_loss: 0.670| gp_loss: 0.049| r_loss: 0.166| p_loss: 0.257| v_loss: 0.041| per_loss: 0.555 | a_loss: 0.485
Train: Epoch [377/3000], Step [150/158]| g_loss: 0.982| d_loss: 0.567| gp_loss: 0.047| r_loss: 0.184| p_loss: 0.272| v_loss: 0.043| per_loss: 0.585 | a_loss: 0.562
Train: Epoch [378/3000], Step [30/158]| g_loss: 0.901| d_loss: 0.732| gp_loss: 0.109| r_loss: 0.179| p_loss: 0.273| v_loss: 0.042| per_loss: 0.582 | a_loss: 0.485
Train: Epoch [378/3000], Step [60/158]| g_loss: 0.947| d_loss: 0.523| gp_loss: 0.045| r_loss: 0.159| p_loss: 0.249| v_loss: 0.043| per_loss: 0.611 | a_loss: 0.559
Train: Epoch [378/3000], Step [90/158]| g_loss: 0.938| d_loss: 0.587| gp_loss: 0.047| r_loss: 0.178| p_loss: 0.258| v_loss: 0.041| per_loss: 0.563 | a_loss: 0.534
Train: Epoch [378/3000], Step [120/158]| g_loss: 1.005| d_loss: 0.567| gp_loss: 0.045| r_loss: 0.174| p_loss: 0.257| v_loss: 0.043| per_loss: 0.586 | a_loss: 0.600
Train: Epoch [378/3000], Step [150/158]| g_loss: 0.868| d_loss: 0.655| gp_loss: 0.052| r_loss: 0.181| p_loss: 0.267| v_loss: 0.041| per_loss: 0.568 | a_loss: 0.456
Train: Epoch [379/3000], Step [30/158]| g_loss: 0.954| d_loss: 0.690| gp_loss: 0.132| r_loss: 0.177| p_loss: 0.256| v_loss: 0.042| per_loss: 0.574 | a_loss: 0.549
Train: Epoch [379/3000], Step [60/158]| g_loss: 0.943| d_loss: 0.632| gp_loss: 0.045| r_loss: 0.173| p_loss: 0.261| v_loss: 0.041| per_loss: 0.581 | a_loss: 0.540
Train: Epoch [379/3000], Step [90/158]| g_loss: 0.855| d_loss: 0.629| gp_loss: 0.047| r_loss: 0.166| p_loss: 0.254| v_loss: 0.041| per_loss: 0.566 | a_loss: 0.465
Train: Epoch [379/3000], Step [120/158]| g_loss: 0.932| d_loss: 0.577| gp_loss: 0.045| r_loss: 0.182| p_loss: 0.255| v_loss: 0.041| per_loss: 0.581 | a_loss: 0.523
Train: Epoch [379/3000], Step [150/158]| g_loss: 0.952| d_loss: 0.575| gp_loss: 0.046| r_loss: 0.172| p_loss: 0.256| v_loss: 0.042| per_loss: 0.567 | a_loss: 0.553
Train: Epoch [380/3000], Step [30/158]| g_loss: 0.914| d_loss: 0.679| gp_loss: 0.093| r_loss: 0.176| p_loss: 0.256| v_loss: 0.042| per_loss: 0.567 | a_loss: 0.511
Train: Epoch [380/3000], Step [60/158]| g_loss: 0.910| d_loss: 0.656| gp_loss: 0.048| r_loss: 0.171| p_loss: 0.253| v_loss: 0.041| per_loss: 0.551 | a_loss: 0.516
Train: Epoch [380/3000], Step [90/158]| g_loss: 0.889| d_loss: 0.637| gp_loss: 0.045| r_loss: 0.171| p_loss: 0.251| v_loss: 0.041| per_loss: 0.584 | a_loss: 0.493
Train: Epoch [380/3000], Step [120/158]| g_loss: 0.926| d_loss: 0.637| gp_loss: 0.052| r_loss: 0.170| p_loss: 0.257| v_loss: 0.041| per_loss: 0.580 | a_loss: 0.529
Train: Epoch [380/3000], Step [150/158]| g_loss: 0.992| d_loss: 0.519| gp_loss: 0.042| r_loss: 0.173| p_loss: 0.266| v_loss: 0.040| per_loss: 0.576 | a_loss: 0.588
Train: Epoch [381/3000], Step [30/158]| g_loss: 0.893| d_loss: 0.704| gp_loss: 0.099| r_loss: 0.173| p_loss: 0.274| v_loss: 0.042| per_loss: 0.578 | a_loss: 0.482
Train: Epoch [381/3000], Step [60/158]| g_loss: 0.933| d_loss: 0.624| gp_loss: 0.043| r_loss: 0.170| p_loss: 0.260| v_loss: 0.042| per_loss: 0.558 | a_loss: 0.536
Train: Epoch [381/3000], Step [90/158]| g_loss: 0.968| d_loss: 0.564| gp_loss: 0.048| r_loss: 0.171| p_loss: 0.262| v_loss: 0.043| per_loss: 0.599 | a_loss: 0.563
Train: Epoch [381/3000], Step [120/158]| g_loss: 0.937| d_loss: 0.622| gp_loss: 0.052| r_loss: 0.181| p_loss: 0.264| v_loss: 0.040| per_loss: 0.586 | a_loss: 0.525
Train: Epoch [381/3000], Step [150/158]| g_loss: 0.929| d_loss: 0.580| gp_loss: 0.051| r_loss: 0.172| p_loss: 0.263| v_loss: 0.041| per_loss: 0.578 | a_loss: 0.526
Train: Epoch [382/3000], Step [30/158]| g_loss: 0.893| d_loss: 0.754| gp_loss: 0.117| r_loss: 0.162| p_loss: 0.259| v_loss: 0.041| per_loss: 0.625 | a_loss: 0.497
Train: Epoch [382/3000], Step [60/158]| g_loss: 0.908| d_loss: 0.641| gp_loss: 0.045| r_loss: 0.168| p_loss: 0.265| v_loss: 0.040| per_loss: 0.559 | a_loss: 0.511
Train: Epoch [382/3000], Step [90/158]| g_loss: 0.993| d_loss: 0.522| gp_loss: 0.042| r_loss: 0.174| p_loss: 0.260| v_loss: 0.042| per_loss: 0.560 | a_loss: 0.591
Train: Epoch [382/3000], Step [120/158]| g_loss: 0.878| d_loss: 0.645| gp_loss: 0.052| r_loss: 0.168| p_loss: 0.252| v_loss: 0.044| per_loss: 0.570 | a_loss: 0.484
Train: Epoch [382/3000], Step [150/158]| g_loss: 0.989| d_loss: 0.515| gp_loss: 0.046| r_loss: 0.183| p_loss: 0.260| v_loss: 0.041| per_loss: 0.585 | a_loss: 0.576
Train: Epoch [383/3000], Step [30/158]| g_loss: 0.990| d_loss: 0.591| gp_loss: 0.090| r_loss: 0.175| p_loss: 0.258| v_loss: 0.041| per_loss: 0.576 | a_loss: 0.587
Train: Epoch [383/3000], Step [60/158]| g_loss: 0.895| d_loss: 0.647| gp_loss: 0.047| r_loss: 0.168| p_loss: 0.257| v_loss: 0.040| per_loss: 0.544 | a_loss: 0.504
Train: Epoch [383/3000], Step [90/158]| g_loss: 0.933| d_loss: 0.581| gp_loss: 0.050| r_loss: 0.171| p_loss: 0.256| v_loss: 0.041| per_loss: 0.605 | a_loss: 0.533
Train: Epoch [383/3000], Step [120/158]| g_loss: 0.958| d_loss: 0.578| gp_loss: 0.046| r_loss: 0.167| p_loss: 0.247| v_loss: 0.043| per_loss: 0.570 | a_loss: 0.568
Train: Epoch [383/3000], Step [150/158]| g_loss: 0.939| d_loss: 0.665| gp_loss: 0.053| r_loss: 0.187| p_loss: 0.257| v_loss: 0.041| per_loss: 0.593 | a_loss: 0.523
Train: Epoch [384/3000], Step [30/158]| g_loss: 0.960| d_loss: 0.657| gp_loss: 0.134| r_loss: 0.167| p_loss: 0.257| v_loss: 0.042| per_loss: 0.600 | a_loss: 0.563
Train: Epoch [384/3000], Step [60/158]| g_loss: 0.920| d_loss: 0.642| gp_loss: 0.047| r_loss: 0.169| p_loss: 0.258| v_loss: 0.042| per_loss: 0.623 | a_loss: 0.519
Train: Epoch [384/3000], Step [90/158]| g_loss: 0.928| d_loss: 0.635| gp_loss: 0.049| r_loss: 0.184| p_loss: 0.253| v_loss: 0.041| per_loss: 0.586 | a_loss: 0.518
Train: Epoch [384/3000], Step [120/158]| g_loss: 0.938| d_loss: 0.577| gp_loss: 0.046| r_loss: 0.171| p_loss: 0.257| v_loss: 0.042| per_loss: 0.578 | a_loss: 0.539
Train: Epoch [384/3000], Step [150/158]| g_loss: 0.962| d_loss: 0.553| gp_loss: 0.046| r_loss: 0.177| p_loss: 0.261| v_loss: 0.041| per_loss: 0.564 | a_loss: 0.557
Train: Epoch [385/3000], Step [30/158]| g_loss: 0.959| d_loss: 0.647| gp_loss: 0.130| r_loss: 0.165| p_loss: 0.250| v_loss: 0.041| per_loss: 0.579 | a_loss: 0.570
Train: Epoch [385/3000], Step [60/158]| g_loss: 0.893| d_loss: 0.639| gp_loss: 0.047| r_loss: 0.172| p_loss: 0.252| v_loss: 0.041| per_loss: 0.546 | a_loss: 0.499
Train: Epoch [385/3000], Step [90/158]| g_loss: 0.944| d_loss: 0.587| gp_loss: 0.046| r_loss: 0.171| p_loss: 0.262| v_loss: 0.041| per_loss: 0.554 | a_loss: 0.545
Train: Epoch [385/3000], Step [120/158]| g_loss: 0.872| d_loss: 0.644| gp_loss: 0.050| r_loss: 0.172| p_loss: 0.251| v_loss: 0.041| per_loss: 0.558 | a_loss: 0.478
Train: Epoch [385/3000], Step [150/158]| g_loss: 0.993| d_loss: 0.480| gp_loss: 0.047| r_loss: 0.170| p_loss: 0.254| v_loss: 0.042| per_loss: 0.552 | a_loss: 0.598
Train: Epoch [386/3000], Step [30/158]| g_loss: 0.939| d_loss: 0.711| gp_loss: 0.140| r_loss: 0.170| p_loss: 0.257| v_loss: 0.040| per_loss: 0.591 | a_loss: 0.540
Train: Epoch [386/3000], Step [60/158]| g_loss: 0.911| d_loss: 0.649| gp_loss: 0.049| r_loss: 0.176| p_loss: 0.263| v_loss: 0.042| per_loss: 0.570 | a_loss: 0.505
Train: Epoch [386/3000], Step [90/158]| g_loss: 0.976| d_loss: 0.578| gp_loss: 0.046| r_loss: 0.184| p_loss: 0.258| v_loss: 0.040| per_loss: 0.553 | a_loss: 0.567
Train: Epoch [386/3000], Step [120/158]| g_loss: 0.916| d_loss: 0.585| gp_loss: 0.050| r_loss: 0.160| p_loss: 0.238| v_loss: 0.041| per_loss: 0.547 | a_loss: 0.542
Train: Epoch [386/3000], Step [150/158]| g_loss: 0.916| d_loss: 0.625| gp_loss: 0.047| r_loss: 0.158| p_loss: 0.243| v_loss: 0.040| per_loss: 0.580 | a_loss: 0.538
Train: Epoch [387/3000], Step [30/158]| g_loss: 0.893| d_loss: 0.709| gp_loss: 0.093| r_loss: 0.165| p_loss: 0.247| v_loss: 0.040| per_loss: 0.550 | a_loss: 0.509
Train: Epoch [387/3000], Step [60/158]| g_loss: 0.885| d_loss: 0.642| gp_loss: 0.042| r_loss: 0.169| p_loss: 0.246| v_loss: 0.040| per_loss: 0.567 | a_loss: 0.496
Train: Epoch [387/3000], Step [90/158]| g_loss: 0.898| d_loss: 0.589| gp_loss: 0.048| r_loss: 0.166| p_loss: 0.246| v_loss: 0.040| per_loss: 0.594 | a_loss: 0.509
Train: Epoch [387/3000], Step [120/158]| g_loss: 0.990| d_loss: 0.524| gp_loss: 0.041| r_loss: 0.175| p_loss: 0.255| v_loss: 0.043| per_loss: 0.564 | a_loss: 0.588
Train: Epoch [387/3000], Step [150/158]| g_loss: 0.937| d_loss: 0.631| gp_loss: 0.049| r_loss: 0.174| p_loss: 0.248| v_loss: 0.042| per_loss: 0.565 | a_loss: 0.541
Train: Epoch [388/3000], Step [30/158]| g_loss: 0.976| d_loss: 0.579| gp_loss: 0.083| r_loss: 0.174| p_loss: 0.277| v_loss: 0.042| per_loss: 0.564 | a_loss: 0.565
Train: Epoch [388/3000], Step [60/158]| g_loss: 0.993| d_loss: 0.576| gp_loss: 0.048| r_loss: 0.208| p_loss: 0.299| v_loss: 0.041| per_loss: 0.587 | a_loss: 0.535
Train: Epoch [388/3000], Step [90/158]| g_loss: 0.924| d_loss: 0.573| gp_loss: 0.050| r_loss: 0.163| p_loss: 0.248| v_loss: 0.039| per_loss: 0.562 | a_loss: 0.541
Train: Epoch [388/3000], Step [120/158]| g_loss: 0.989| d_loss: 0.501| gp_loss: 0.048| r_loss: 0.172| p_loss: 0.264| v_loss: 0.041| per_loss: 0.558 | a_loss: 0.588
Train: Epoch [388/3000], Step [150/158]| g_loss: 0.926| d_loss: 0.687| gp_loss: 0.047| r_loss: 0.173| p_loss: 0.266| v_loss: 0.042| per_loss: 0.546 | a_loss: 0.523
Train: Epoch [389/3000], Step [30/158]| g_loss: 0.916| d_loss: 0.715| gp_loss: 0.160| r_loss: 0.174| p_loss: 0.247| v_loss: 0.041| per_loss: 0.530 | a_loss: 0.525
Train: Epoch [389/3000], Step [60/158]| g_loss: 0.883| d_loss: 0.627| gp_loss: 0.046| r_loss: 0.164| p_loss: 0.258| v_loss: 0.040| per_loss: 0.566 | a_loss: 0.492
Train: Epoch [389/3000], Step [90/158]| g_loss: 0.950| d_loss: 0.547| gp_loss: 0.043| r_loss: 0.173| p_loss: 0.251| v_loss: 0.040| per_loss: 0.588 | a_loss: 0.554
Train: Epoch [389/3000], Step [120/158]| g_loss: 0.973| d_loss: 0.608| gp_loss: 0.048| r_loss: 0.172| p_loss: 0.255| v_loss: 0.042| per_loss: 0.567 | a_loss: 0.576
Train: Epoch [389/3000], Step [150/158]| g_loss: 0.880| d_loss: 0.697| gp_loss: 0.049| r_loss: 0.167| p_loss: 0.250| v_loss: 0.041| per_loss: 0.560 | a_loss: 0.491
Train: Epoch [390/3000], Step [30/158]| g_loss: 0.913| d_loss: 0.697| gp_loss: 0.129| r_loss: 0.173| p_loss: 0.255| v_loss: 0.041| per_loss: 0.559 | a_loss: 0.516
Train: Epoch [390/3000], Step [60/158]| g_loss: 0.917| d_loss: 0.575| gp_loss: 0.047| r_loss: 0.166| p_loss: 0.258| v_loss: 0.041| per_loss: 0.555 | a_loss: 0.526
Train: Epoch [390/3000], Step [90/158]| g_loss: 0.941| d_loss: 0.604| gp_loss: 0.044| r_loss: 0.176| p_loss: 0.249| v_loss: 0.042| per_loss: 0.594 | a_loss: 0.539
Train: Epoch [390/3000], Step [120/158]| g_loss: 0.900| d_loss: 0.570| gp_loss: 0.048| r_loss: 0.165| p_loss: 0.236| v_loss: 0.039| per_loss: 0.534 | a_loss: 0.524
Train: Epoch [390/3000], Step [150/158]| g_loss: 0.935| d_loss: 0.542| gp_loss: 0.046| r_loss: 0.158| p_loss: 0.245| v_loss: 0.041| per_loss: 0.542 | a_loss: 0.559
Train: Epoch [391/3000], Step [30/158]| g_loss: 0.883| d_loss: 0.752| gp_loss: 0.095| r_loss: 0.174| p_loss: 0.250| v_loss: 0.040| per_loss: 0.532 | a_loss: 0.490
Train: Epoch [391/3000], Step [60/158]| g_loss: 0.896| d_loss: 0.690| gp_loss: 0.048| r_loss: 0.185| p_loss: 0.256| v_loss: 0.040| per_loss: 0.576 | a_loss: 0.485
Train: Epoch [391/3000], Step [90/158]| g_loss: 0.911| d_loss: 0.555| gp_loss: 0.047| r_loss: 0.160| p_loss: 0.247| v_loss: 0.039| per_loss: 0.546 | a_loss: 0.533
Train: Epoch [391/3000], Step [120/158]| g_loss: 0.977| d_loss: 0.507| gp_loss: 0.048| r_loss: 0.163| p_loss: 0.250| v_loss: 0.042| per_loss: 0.564 | a_loss: 0.592
Train: Epoch [391/3000], Step [150/158]| g_loss: 0.945| d_loss: 0.582| gp_loss: 0.049| r_loss: 0.167| p_loss: 0.249| v_loss: 0.041| per_loss: 0.580 | a_loss: 0.555
Train: Epoch [392/3000], Step [30/158]| g_loss: 0.938| d_loss: 0.666| gp_loss: 0.119| r_loss: 0.172| p_loss: 0.249| v_loss: 0.040| per_loss: 0.550 | a_loss: 0.547
Train: Epoch [392/3000], Step [60/158]| g_loss: 0.854| d_loss: 0.680| gp_loss: 0.050| r_loss: 0.158| p_loss: 0.245| v_loss: 0.039| per_loss: 0.586 | a_loss: 0.476
Train: Epoch [392/3000], Step [90/158]| g_loss: 1.003| d_loss: 0.516| gp_loss: 0.045| r_loss: 0.171| p_loss: 0.250| v_loss: 0.043| per_loss: 0.551 | a_loss: 0.608
Train: Epoch [392/3000], Step [120/158]| g_loss: 0.894| d_loss: 0.604| gp_loss: 0.049| r_loss: 0.166| p_loss: 0.241| v_loss: 0.039| per_loss: 0.575 | a_loss: 0.511
Train: Epoch [392/3000], Step [150/158]| g_loss: 0.935| d_loss: 0.542| gp_loss: 0.048| r_loss: 0.161| p_loss: 0.243| v_loss: 0.041| per_loss: 0.567 | a_loss: 0.555
Train: Epoch [393/3000], Step [30/158]| g_loss: 0.954| d_loss: 0.627| gp_loss: 0.111| r_loss: 0.166| p_loss: 0.249| v_loss: 0.040| per_loss: 0.563 | a_loss: 0.567
Train: Epoch [393/3000], Step [60/158]| g_loss: 0.842| d_loss: 0.723| gp_loss: 0.051| r_loss: 0.169| p_loss: 0.248| v_loss: 0.039| per_loss: 0.601 | a_loss: 0.450
Train: Epoch [393/3000], Step [90/158]| g_loss: 0.953| d_loss: 0.597| gp_loss: 0.045| r_loss: 0.172| p_loss: 0.249| v_loss: 0.040| per_loss: 0.540 | a_loss: 0.562
Train: Epoch [393/3000], Step [120/158]| g_loss: 0.951| d_loss: 0.579| gp_loss: 0.048| r_loss: 0.178| p_loss: 0.250| v_loss: 0.042| per_loss: 0.580 | a_loss: 0.548
Train: Epoch [393/3000], Step [150/158]| g_loss: 0.934| d_loss: 0.524| gp_loss: 0.050| r_loss: 0.155| p_loss: 0.250| v_loss: 0.040| per_loss: 0.579 | a_loss: 0.557
Train: Epoch [394/3000], Step [30/158]| g_loss: 0.920| d_loss: 0.732| gp_loss: 0.148| r_loss: 0.172| p_loss: 0.255| v_loss: 0.040| per_loss: 0.552 | a_loss: 0.525
Train: Epoch [394/3000], Step [60/158]| g_loss: 0.958| d_loss: 0.483| gp_loss: 0.047| r_loss: 0.174| p_loss: 0.238| v_loss: 0.040| per_loss: 0.566 | a_loss: 0.567
Train: Epoch [394/3000], Step [90/158]| g_loss: 0.899| d_loss: 0.660| gp_loss: 0.047| r_loss: 0.154| p_loss: 0.237| v_loss: 0.038| per_loss: 0.580 | a_loss: 0.530
Train: Epoch [394/3000], Step [120/158]| g_loss: 0.914| d_loss: 0.618| gp_loss: 0.046| r_loss: 0.171| p_loss: 0.264| v_loss: 0.040| per_loss: 0.534 | a_loss: 0.517
Train: Epoch [394/3000], Step [150/158]| g_loss: 0.907| d_loss: 0.576| gp_loss: 0.048| r_loss: 0.167| p_loss: 0.249| v_loss: 0.040| per_loss: 0.580 | a_loss: 0.519
Train: Epoch [395/3000], Step [30/158]| g_loss: 0.926| d_loss: 0.741| gp_loss: 0.177| r_loss: 0.160| p_loss: 0.241| v_loss: 0.038| per_loss: 0.603 | a_loss: 0.547
Train: Epoch [395/3000], Step [60/158]| g_loss: 0.885| d_loss: 0.642| gp_loss: 0.047| r_loss: 0.181| p_loss: 0.252| v_loss: 0.041| per_loss: 0.570 | a_loss: 0.480
Train: Epoch [395/3000], Step [90/158]| g_loss: 0.900| d_loss: 0.588| gp_loss: 0.047| r_loss: 0.165| p_loss: 0.244| v_loss: 0.040| per_loss: 0.566 | a_loss: 0.517
Train: Epoch [395/3000], Step [120/158]| g_loss: 1.004| d_loss: 0.536| gp_loss: 0.047| r_loss: 0.168| p_loss: 0.249| v_loss: 0.042| per_loss: 0.552 | a_loss: 0.613
Train: Epoch [395/3000], Step [150/158]| g_loss: 0.925| d_loss: 0.567| gp_loss: 0.045| r_loss: 0.157| p_loss: 0.238| v_loss: 0.038| per_loss: 0.543 | a_loss: 0.556
Train: Epoch [396/3000], Step [30/158]| g_loss: 0.846| d_loss: 0.790| gp_loss: 0.139| r_loss: 0.165| p_loss: 0.244| v_loss: 0.040| per_loss: 0.589 | a_loss: 0.459
Train: Epoch [396/3000], Step [60/158]| g_loss: 0.913| d_loss: 0.568| gp_loss: 0.042| r_loss: 0.172| p_loss: 0.255| v_loss: 0.041| per_loss: 0.587 | a_loss: 0.513
Train: Epoch [396/3000], Step [90/158]| g_loss: 0.968| d_loss: 0.551| gp_loss: 0.045| r_loss: 0.170| p_loss: 0.240| v_loss: 0.039| per_loss: 0.545 | a_loss: 0.584
Train: Epoch [396/3000], Step [120/158]| g_loss: 0.975| d_loss: 0.560| gp_loss: 0.047| r_loss: 0.158| p_loss: 0.245| v_loss: 0.039| per_loss: 0.561 | a_loss: 0.600
Train: Epoch [396/3000], Step [150/158]| g_loss: 0.936| d_loss: 0.558| gp_loss: 0.048| r_loss: 0.176| p_loss: 0.263| v_loss: 0.042| per_loss: 0.603 | a_loss: 0.526
Train: Epoch [397/3000], Step [30/158]| g_loss: 0.924| d_loss: 0.693| gp_loss: 0.151| r_loss: 0.159| p_loss: 0.237| v_loss: 0.039| per_loss: 0.535 | a_loss: 0.554
Train: Epoch [397/3000], Step [60/158]| g_loss: 0.957| d_loss: 0.569| gp_loss: 0.042| r_loss: 0.170| p_loss: 0.248| v_loss: 0.042| per_loss: 0.574 | a_loss: 0.564
Train: Epoch [397/3000], Step [90/158]| g_loss: 0.954| d_loss: 0.586| gp_loss: 0.044| r_loss: 0.168| p_loss: 0.247| v_loss: 0.041| per_loss: 0.561 | a_loss: 0.565
Train: Epoch [397/3000], Step [120/158]| g_loss: 0.882| d_loss: 0.604| gp_loss: 0.049| r_loss: 0.160| p_loss: 0.237| v_loss: 0.040| per_loss: 0.589 | a_loss: 0.505
Train: Epoch [397/3000], Step [150/158]| g_loss: 0.907| d_loss: 0.592| gp_loss: 0.048| r_loss: 0.167| p_loss: 0.243| v_loss: 0.039| per_loss: 0.585 | a_loss: 0.521
Train: Epoch [398/3000], Step [30/158]| g_loss: 0.905| d_loss: 0.719| gp_loss: 0.153| r_loss: 0.166| p_loss: 0.248| v_loss: 0.039| per_loss: 0.555 | a_loss: 0.521
Train: Epoch [398/3000], Step [60/158]| g_loss: 0.892| d_loss: 0.641| gp_loss: 0.048| r_loss: 0.166| p_loss: 0.247| v_loss: 0.040| per_loss: 0.566 | a_loss: 0.506
Train: Epoch [398/3000], Step [90/158]| g_loss: 0.935| d_loss: 0.592| gp_loss: 0.046| r_loss: 0.173| p_loss: 0.253| v_loss: 0.041| per_loss: 0.541 | a_loss: 0.540
Train: Epoch [398/3000], Step [120/158]| g_loss: 0.920| d_loss: 0.636| gp_loss: 0.046| r_loss: 0.161| p_loss: 0.247| v_loss: 0.041| per_loss: 0.591 | a_loss: 0.535
Train: Epoch [398/3000], Step [150/158]| g_loss: 0.873| d_loss: 0.620| gp_loss: 0.048| r_loss: 0.164| p_loss: 0.257| v_loss: 0.041| per_loss: 0.541 | a_loss: 0.486
Train: Epoch [399/3000], Step [30/158]| g_loss: 0.975| d_loss: 0.646| gp_loss: 0.153| r_loss: 0.173| p_loss: 0.266| v_loss: 0.042| per_loss: 0.593 | a_loss: 0.568
Train: Epoch [399/3000], Step [60/158]| g_loss: 0.915| d_loss: 0.663| gp_loss: 0.043| r_loss: 0.173| p_loss: 0.264| v_loss: 0.038| per_loss: 0.582 | a_loss: 0.513
Train: Epoch [399/3000], Step [90/158]| g_loss: 0.962| d_loss: 0.541| gp_loss: 0.044| r_loss: 0.173| p_loss: 0.257| v_loss: 0.040| per_loss: 0.559 | a_loss: 0.564
Train: Epoch [399/3000], Step [120/158]| g_loss: 0.908| d_loss: 0.590| gp_loss: 0.045| r_loss: 0.158| p_loss: 0.254| v_loss: 0.041| per_loss: 0.572 | a_loss: 0.524
Train: Epoch [399/3000], Step [150/158]| g_loss: 0.956| d_loss: 0.635| gp_loss: 0.044| r_loss: 0.187| p_loss: 0.275| v_loss: 0.041| per_loss: 0.587 | a_loss: 0.532
Train: Epoch [400/3000], Step [30/158]| g_loss: 0.910| d_loss: 0.675| gp_loss: 0.122| r_loss: 0.166| p_loss: 0.259| v_loss: 0.040| per_loss: 0.604 | a_loss: 0.513
Train: Epoch [400/3000], Step [60/158]| g_loss: 0.864| d_loss: 0.693| gp_loss: 0.047| r_loss: 0.162| p_loss: 0.254| v_loss: 0.041| per_loss: 0.525 | a_loss: 0.482
Train: Epoch [400/3000], Step [90/158]| g_loss: 0.929| d_loss: 0.582| gp_loss: 0.046| r_loss: 0.167| p_loss: 0.249| v_loss: 0.040| per_loss: 0.584 | a_loss: 0.540
Train: Epoch [400/3000], Step [120/158]| g_loss: 1.028| d_loss: 0.542| gp_loss: 0.049| r_loss: 0.180| p_loss: 0.267| v_loss: 0.042| per_loss: 0.591 | a_loss: 0.614
Train: Epoch [400/3000], Step [150/158]| g_loss: 0.953| d_loss: 0.540| gp_loss: 0.047| r_loss: 0.172| p_loss: 0.258| v_loss: 0.040| per_loss: 0.611 | a_loss: 0.551
Test: Epoch [400/3000]| g_loss: 0.799| r_loss: 0.527| p_loss: 0.351| v_loss: 0.031
Train: Epoch [401/3000], Step [30/158]| g_loss: 0.918| d_loss: 0.586| gp_loss: 0.046| r_loss: 0.167| p_loss: 0.258| v_loss: 0.043| per_loss: 0.569 | a_loss: 0.522
Train: Epoch [401/3000], Step [60/158]| g_loss: 0.933| d_loss: 0.628| gp_loss: 0.041| r_loss: 0.174| p_loss: 0.261| v_loss: 0.040| per_loss: 0.546 | a_loss: 0.534
Train: Epoch [401/3000], Step [90/158]| g_loss: 0.880| d_loss: 0.592| gp_loss: 0.048| r_loss: 0.155| p_loss: 0.243| v_loss: 0.040| per_loss: 0.535 | a_loss: 0.510
Train: Epoch [401/3000], Step [120/158]| g_loss: 0.916| d_loss: 0.591| gp_loss: 0.049| r_loss: 0.172| p_loss: 0.256| v_loss: 0.039| per_loss: 0.597 | a_loss: 0.517
Train: Epoch [401/3000], Step [150/158]| g_loss: 0.931| d_loss: 0.649| gp_loss: 0.051| r_loss: 0.169| p_loss: 0.256| v_loss: 0.039| per_loss: 0.636 | a_loss: 0.531
Train: Epoch [402/3000], Step [30/158]| g_loss: 0.974| d_loss: 0.606| gp_loss: 0.099| r_loss: 0.161| p_loss: 0.252| v_loss: 0.041| per_loss: 0.611 | a_loss: 0.584
Train: Epoch [402/3000], Step [60/158]| g_loss: 0.938| d_loss: 0.653| gp_loss: 0.049| r_loss: 0.181| p_loss: 0.262| v_loss: 0.040| per_loss: 0.580 | a_loss: 0.527
Train: Epoch [402/3000], Step [90/158]| g_loss: 0.932| d_loss: 0.535| gp_loss: 0.047| r_loss: 0.164| p_loss: 0.255| v_loss: 0.042| per_loss: 0.579 | a_loss: 0.541
Train: Epoch [402/3000], Step [120/158]| g_loss: 0.927| d_loss: 0.608| gp_loss: 0.051| r_loss: 0.163| p_loss: 0.248| v_loss: 0.041| per_loss: 0.629 | a_loss: 0.536
Train: Epoch [402/3000], Step [150/158]| g_loss: 0.921| d_loss: 0.559| gp_loss: 0.052| r_loss: 0.166| p_loss: 0.247| v_loss: 0.041| per_loss: 0.534 | a_loss: 0.537
Train: Epoch [403/3000], Step [30/158]| g_loss: 0.977| d_loss: 0.544| gp_loss: 0.111| r_loss: 0.161| p_loss: 0.244| v_loss: 0.041| per_loss: 0.581 | a_loss: 0.595
Train: Epoch [403/3000], Step [60/158]| g_loss: 0.945| d_loss: 0.589| gp_loss: 0.049| r_loss: 0.175| p_loss: 0.250| v_loss: 0.042| per_loss: 0.606 | a_loss: 0.542
Train: Epoch [403/3000], Step [90/158]| g_loss: 0.913| d_loss: 0.642| gp_loss: 0.051| r_loss: 0.167| p_loss: 0.246| v_loss: 0.040| per_loss: 0.582 | a_loss: 0.525
Train: Epoch [403/3000], Step [120/158]| g_loss: 0.913| d_loss: 0.683| gp_loss: 0.055| r_loss: 0.170| p_loss: 0.264| v_loss: 0.041| per_loss: 0.555 | a_loss: 0.514
Train: Epoch [403/3000], Step [150/158]| g_loss: 0.890| d_loss: 0.617| gp_loss: 0.048| r_loss: 0.152| p_loss: 0.242| v_loss: 0.041| per_loss: 0.594 | a_loss: 0.516
Train: Epoch [404/3000], Step [30/158]| g_loss: 0.973| d_loss: 0.584| gp_loss: 0.108| r_loss: 0.172| p_loss: 0.258| v_loss: 0.041| per_loss: 0.579 | a_loss: 0.572
Train: Epoch [404/3000], Step [60/158]| g_loss: 0.905| d_loss: 0.643| gp_loss: 0.053| r_loss: 0.161| p_loss: 0.249| v_loss: 0.041| per_loss: 0.587 | a_loss: 0.519
Train: Epoch [404/3000], Step [90/158]| g_loss: 0.945| d_loss: 0.557| gp_loss: 0.051| r_loss: 0.158| p_loss: 0.249| v_loss: 0.040| per_loss: 0.586 | a_loss: 0.564
Train: Epoch [404/3000], Step [120/158]| g_loss: 0.936| d_loss: 0.606| gp_loss: 0.053| r_loss: 0.180| p_loss: 0.265| v_loss: 0.042| per_loss: 0.603 | a_loss: 0.522
Train: Epoch [404/3000], Step [150/158]| g_loss: 0.965| d_loss: 0.588| gp_loss: 0.053| r_loss: 0.176| p_loss: 0.264| v_loss: 0.042| per_loss: 0.635 | a_loss: 0.552
Train: Epoch [405/3000], Step [30/158]| g_loss: 0.940| d_loss: 0.642| gp_loss: 0.112| r_loss: 0.176| p_loss: 0.260| v_loss: 0.041| per_loss: 0.609 | a_loss: 0.532
Train: Epoch [405/3000], Step [60/158]| g_loss: 0.901| d_loss: 0.634| gp_loss: 0.053| r_loss: 0.171| p_loss: 0.249| v_loss: 0.041| per_loss: 0.640 | a_loss: 0.501
Train: Epoch [405/3000], Step [90/158]| g_loss: 0.924| d_loss: 0.592| gp_loss: 0.052| r_loss: 0.167| p_loss: 0.260| v_loss: 0.042| per_loss: 0.602 | a_loss: 0.525
Train: Epoch [405/3000], Step [120/158]| g_loss: 0.954| d_loss: 0.564| gp_loss: 0.051| r_loss: 0.163| p_loss: 0.251| v_loss: 0.041| per_loss: 0.575 | a_loss: 0.568
Train: Epoch [405/3000], Step [150/158]| g_loss: 0.938| d_loss: 0.620| gp_loss: 0.053| r_loss: 0.167| p_loss: 0.248| v_loss: 0.042| per_loss: 0.572 | a_loss: 0.549
Train: Epoch [406/3000], Step [30/158]| g_loss: 0.950| d_loss: 0.607| gp_loss: 0.135| r_loss: 0.164| p_loss: 0.248| v_loss: 0.042| per_loss: 0.571 | a_loss: 0.562
Train: Epoch [406/3000], Step [60/158]| g_loss: 0.870| d_loss: 0.718| gp_loss: 0.049| r_loss: 0.170| p_loss: 0.252| v_loss: 0.040| per_loss: 0.583 | a_loss: 0.477
Train: Epoch [406/3000], Step [90/158]| g_loss: 0.900| d_loss: 0.572| gp_loss: 0.048| r_loss: 0.170| p_loss: 0.247| v_loss: 0.042| per_loss: 0.608 | a_loss: 0.504
Train: Epoch [406/3000], Step [120/158]| g_loss: 0.996| d_loss: 0.514| gp_loss: 0.052| r_loss: 0.172| p_loss: 0.258| v_loss: 0.042| per_loss: 0.550 | a_loss: 0.598
Train: Epoch [406/3000], Step [150/158]| g_loss: 0.933| d_loss: 0.600| gp_loss: 0.054| r_loss: 0.159| p_loss: 0.248| v_loss: 0.042| per_loss: 0.570 | a_loss: 0.550
Train: Epoch [407/3000], Step [30/158]| g_loss: 0.953| d_loss: 0.660| gp_loss: 0.141| r_loss: 0.166| p_loss: 0.248| v_loss: 0.041| per_loss: 0.567 | a_loss: 0.566
Train: Epoch [407/3000], Step [60/158]| g_loss: 0.917| d_loss: 0.613| gp_loss: 0.051| r_loss: 0.165| p_loss: 0.251| v_loss: 0.040| per_loss: 0.556 | a_loss: 0.530
Train: Epoch [407/3000], Step [90/158]| g_loss: 0.972| d_loss: 0.567| gp_loss: 0.047| r_loss: 0.173| p_loss: 0.259| v_loss: 0.042| per_loss: 0.621 | a_loss: 0.565
Train: Epoch [407/3000], Step [120/158]| g_loss: 0.865| d_loss: 0.689| gp_loss: 0.055| r_loss: 0.155| p_loss: 0.250| v_loss: 0.041| per_loss: 0.557 | a_loss: 0.488
Train: Epoch [407/3000], Step [150/158]| g_loss: 0.979| d_loss: 0.539| gp_loss: 0.052| r_loss: 0.169| p_loss: 0.266| v_loss: 0.043| per_loss: 0.548 | a_loss: 0.579
Train: Epoch [408/3000], Step [30/158]| g_loss: 0.930| d_loss: 0.678| gp_loss: 0.130| r_loss: 0.168| p_loss: 0.255| v_loss: 0.042| per_loss: 0.566 | a_loss: 0.536
Train: Epoch [408/3000], Step [60/158]| g_loss: 0.923| d_loss: 0.576| gp_loss: 0.049| r_loss: 0.170| p_loss: 0.249| v_loss: 0.041| per_loss: 0.568 | a_loss: 0.531
Train: Epoch [408/3000], Step [90/158]| g_loss: 0.954| d_loss: 0.566| gp_loss: 0.048| r_loss: 0.159| p_loss: 0.244| v_loss: 0.041| per_loss: 0.527 | a_loss: 0.578
Train: Epoch [408/3000], Step [120/158]| g_loss: 0.908| d_loss: 0.625| gp_loss: 0.048| r_loss: 0.166| p_loss: 0.253| v_loss: 0.042| per_loss: 0.578 | a_loss: 0.516
Train: Epoch [408/3000], Step [150/158]| g_loss: 0.908| d_loss: 0.604| gp_loss: 0.046| r_loss: 0.164| p_loss: 0.249| v_loss: 0.041| per_loss: 0.566 | a_loss: 0.521
Train: Epoch [409/3000], Step [30/158]| g_loss: 0.959| d_loss: 0.679| gp_loss: 0.164| r_loss: 0.169| p_loss: 0.252| v_loss: 0.040| per_loss: 0.573 | a_loss: 0.567
Train: Epoch [409/3000], Step [60/158]| g_loss: 0.910| d_loss: 0.592| gp_loss: 0.047| r_loss: 0.167| p_loss: 0.251| v_loss: 0.042| per_loss: 0.527 | a_loss: 0.522
Train: Epoch [409/3000], Step [90/158]| g_loss: 0.868| d_loss: 0.690| gp_loss: 0.046| r_loss: 0.163| p_loss: 0.236| v_loss: 0.041| per_loss: 0.571 | a_loss: 0.488
Train: Epoch [409/3000], Step [120/158]| g_loss: 0.880| d_loss: 0.618| gp_loss: 0.049| r_loss: 0.162| p_loss: 0.238| v_loss: 0.039| per_loss: 0.572 | a_loss: 0.503
Train: Epoch [409/3000], Step [150/158]| g_loss: 0.879| d_loss: 0.564| gp_loss: 0.048| r_loss: 0.154| p_loss: 0.234| v_loss: 0.041| per_loss: 0.548 | a_loss: 0.511
Train: Epoch [410/3000], Step [30/158]| g_loss: 1.009| d_loss: 0.575| gp_loss: 0.138| r_loss: 0.168| p_loss: 0.251| v_loss: 0.041| per_loss: 0.536 | a_loss: 0.620
Train: Epoch [410/3000], Step [60/158]| g_loss: 1.008| d_loss: 0.484| gp_loss: 0.046| r_loss: 0.163| p_loss: 0.237| v_loss: 0.040| per_loss: 0.571 | a_loss: 0.630
Train: Epoch [410/3000], Step [90/158]| g_loss: 0.921| d_loss: 0.638| gp_loss: 0.048| r_loss: 0.162| p_loss: 0.240| v_loss: 0.040| per_loss: 0.581 | a_loss: 0.542
Train: Epoch [410/3000], Step [120/158]| g_loss: 0.851| d_loss: 0.658| gp_loss: 0.048| r_loss: 0.168| p_loss: 0.248| v_loss: 0.042| per_loss: 0.525 | a_loss: 0.465
Train: Epoch [410/3000], Step [150/158]| g_loss: 0.885| d_loss: 0.627| gp_loss: 0.050| r_loss: 0.155| p_loss: 0.237| v_loss: 0.041| per_loss: 0.552 | a_loss: 0.515
Train: Epoch [411/3000], Step [30/158]| g_loss: 0.856| d_loss: 0.793| gp_loss: 0.162| r_loss: 0.160| p_loss: 0.239| v_loss: 0.040| per_loss: 0.531 | a_loss: 0.484
Train: Epoch [411/3000], Step [60/158]| g_loss: 0.914| d_loss: 0.526| gp_loss: 0.047| r_loss: 0.163| p_loss: 0.239| v_loss: 0.039| per_loss: 0.571 | a_loss: 0.535
Train: Epoch [411/3000], Step [90/158]| g_loss: 0.942| d_loss: 0.526| gp_loss: 0.045| r_loss: 0.152| p_loss: 0.241| v_loss: 0.039| per_loss: 0.567 | a_loss: 0.574
Train: Epoch [411/3000], Step [120/158]| g_loss: 0.955| d_loss: 0.587| gp_loss: 0.050| r_loss: 0.175| p_loss: 0.244| v_loss: 0.040| per_loss: 0.553 | a_loss: 0.563
Train: Epoch [411/3000], Step [150/158]| g_loss: 0.918| d_loss: 0.662| gp_loss: 0.047| r_loss: 0.168| p_loss: 0.249| v_loss: 0.041| per_loss: 0.589 | a_loss: 0.526
Train: Epoch [412/3000], Step [30/158]| g_loss: 0.940| d_loss: 0.626| gp_loss: 0.107| r_loss: 0.163| p_loss: 0.252| v_loss: 0.040| per_loss: 0.589 | a_loss: 0.553
Train: Epoch [412/3000], Step [60/158]| g_loss: 0.911| d_loss: 0.608| gp_loss: 0.045| r_loss: 0.159| p_loss: 0.243| v_loss: 0.040| per_loss: 0.588 | a_loss: 0.532
Train: Epoch [412/3000], Step [90/158]| g_loss: 0.851| d_loss: 0.655| gp_loss: 0.048| r_loss: 0.152| p_loss: 0.235| v_loss: 0.041| per_loss: 0.608 | a_loss: 0.480
Train: Epoch [412/3000], Step [120/158]| g_loss: 0.911| d_loss: 0.616| gp_loss: 0.046| r_loss: 0.171| p_loss: 0.255| v_loss: 0.039| per_loss: 0.583 | a_loss: 0.514
Train: Epoch [412/3000], Step [150/158]| g_loss: 0.949| d_loss: 0.498| gp_loss: 0.048| r_loss: 0.164| p_loss: 0.239| v_loss: 0.038| per_loss: 0.564 | a_loss: 0.572
Train: Epoch [413/3000], Step [30/158]| g_loss: 0.923| d_loss: 0.659| gp_loss: 0.132| r_loss: 0.149| p_loss: 0.238| v_loss: 0.040| per_loss: 0.568 | a_loss: 0.559
Train: Epoch [413/3000], Step [60/158]| g_loss: 0.874| d_loss: 0.685| gp_loss: 0.046| r_loss: 0.168| p_loss: 0.237| v_loss: 0.039| per_loss: 0.571 | a_loss: 0.491
Train: Epoch [413/3000], Step [90/158]| g_loss: 0.915| d_loss: 0.595| gp_loss: 0.048| r_loss: 0.167| p_loss: 0.248| v_loss: 0.040| per_loss: 0.587 | a_loss: 0.526
Train: Epoch [413/3000], Step [120/158]| g_loss: 0.954| d_loss: 0.569| gp_loss: 0.050| r_loss: 0.174| p_loss: 0.237| v_loss: 0.040| per_loss: 0.559 | a_loss: 0.566
Train: Epoch [413/3000], Step [150/158]| g_loss: 0.935| d_loss: 0.594| gp_loss: 0.049| r_loss: 0.154| p_loss: 0.246| v_loss: 0.041| per_loss: 0.563 | a_loss: 0.561
Train: Epoch [414/3000], Step [30/158]| g_loss: 0.894| d_loss: 0.660| gp_loss: 0.098| r_loss: 0.167| p_loss: 0.248| v_loss: 0.041| per_loss: 0.593 | a_loss: 0.503
Train: Epoch [414/3000], Step [60/158]| g_loss: 0.931| d_loss: 0.557| gp_loss: 0.047| r_loss: 0.162| p_loss: 0.245| v_loss: 0.039| per_loss: 0.566 | a_loss: 0.550
Train: Epoch [414/3000], Step [90/158]| g_loss: 0.923| d_loss: 0.614| gp_loss: 0.048| r_loss: 0.155| p_loss: 0.237| v_loss: 0.039| per_loss: 0.585 | a_loss: 0.553
Train: Epoch [414/3000], Step [120/158]| g_loss: 0.893| d_loss: 0.591| gp_loss: 0.052| r_loss: 0.153| p_loss: 0.237| v_loss: 0.037| per_loss: 0.560 | a_loss: 0.528
Train: Epoch [414/3000], Step [150/158]| g_loss: 0.934| d_loss: 0.636| gp_loss: 0.049| r_loss: 0.164| p_loss: 0.251| v_loss: 0.040| per_loss: 0.581 | a_loss: 0.546
Train: Epoch [415/3000], Step [30/158]| g_loss: 0.941| d_loss: 0.628| gp_loss: 0.132| r_loss: 0.161| p_loss: 0.239| v_loss: 0.040| per_loss: 0.541 | a_loss: 0.565
Train: Epoch [415/3000], Step [60/158]| g_loss: 0.874| d_loss: 0.640| gp_loss: 0.046| r_loss: 0.169| p_loss: 0.245| v_loss: 0.039| per_loss: 0.568 | a_loss: 0.487
Train: Epoch [415/3000], Step [90/158]| g_loss: 0.915| d_loss: 0.593| gp_loss: 0.048| r_loss: 0.158| p_loss: 0.236| v_loss: 0.039| per_loss: 0.580 | a_loss: 0.542
Train: Epoch [415/3000], Step [120/158]| g_loss: 0.914| d_loss: 0.554| gp_loss: 0.046| r_loss: 0.156| p_loss: 0.238| v_loss: 0.038| per_loss: 0.534 | a_loss: 0.549
Train: Epoch [415/3000], Step [150/158]| g_loss: 0.939| d_loss: 0.592| gp_loss: 0.049| r_loss: 0.153| p_loss: 0.240| v_loss: 0.041| per_loss: 0.544 | a_loss: 0.571
Train: Epoch [416/3000], Step [30/158]| g_loss: 0.973| d_loss: 0.630| gp_loss: 0.136| r_loss: 0.155| p_loss: 0.253| v_loss: 0.041| per_loss: 0.600 | a_loss: 0.591
Train: Epoch [416/3000], Step [60/158]| g_loss: 0.876| d_loss: 0.706| gp_loss: 0.047| r_loss: 0.165| p_loss: 0.249| v_loss: 0.040| per_loss: 0.566 | a_loss: 0.489
Train: Epoch [416/3000], Step [90/158]| g_loss: 0.878| d_loss: 0.601| gp_loss: 0.051| r_loss: 0.163| p_loss: 0.239| v_loss: 0.040| per_loss: 0.522 | a_loss: 0.504
Train: Epoch [416/3000], Step [120/158]| g_loss: 0.858| d_loss: 0.697| gp_loss: 0.050| r_loss: 0.161| p_loss: 0.239| v_loss: 0.040| per_loss: 0.552 | a_loss: 0.483
Train: Epoch [416/3000], Step [150/158]| g_loss: 0.943| d_loss: 0.501| gp_loss: 0.047| r_loss: 0.166| p_loss: 0.238| v_loss: 0.038| per_loss: 0.525 | a_loss: 0.568
Train: Epoch [417/3000], Step [30/158]| g_loss: 0.962| d_loss: 0.601| gp_loss: 0.116| r_loss: 0.159| p_loss: 0.228| v_loss: 0.039| per_loss: 0.557 | a_loss: 0.595
Train: Epoch [417/3000], Step [60/158]| g_loss: 0.924| d_loss: 0.524| gp_loss: 0.047| r_loss: 0.156| p_loss: 0.233| v_loss: 0.039| per_loss: 0.526 | a_loss: 0.561
Train: Epoch [417/3000], Step [90/158]| g_loss: 0.949| d_loss: 0.550| gp_loss: 0.046| r_loss: 0.157| p_loss: 0.234| v_loss: 0.040| per_loss: 0.540 | a_loss: 0.581
Train: Epoch [417/3000], Step [120/158]| g_loss: 0.871| d_loss: 0.663| gp_loss: 0.049| r_loss: 0.154| p_loss: 0.235| v_loss: 0.040| per_loss: 0.568 | a_loss: 0.503
Train: Epoch [417/3000], Step [150/158]| g_loss: 0.900| d_loss: 0.655| gp_loss: 0.048| r_loss: 0.172| p_loss: 0.251| v_loss: 0.042| per_loss: 0.560 | a_loss: 0.505
Train: Epoch [418/3000], Step [30/158]| g_loss: 0.923| d_loss: 0.658| gp_loss: 0.154| r_loss: 0.160| p_loss: 0.236| v_loss: 0.042| per_loss: 0.556 | a_loss: 0.547
Train: Epoch [418/3000], Step [60/158]| g_loss: 0.902| d_loss: 0.655| gp_loss: 0.044| r_loss: 0.161| p_loss: 0.238| v_loss: 0.039| per_loss: 0.567 | a_loss: 0.527
Train: Epoch [418/3000], Step [90/158]| g_loss: 0.888| d_loss: 0.633| gp_loss: 0.045| r_loss: 0.163| p_loss: 0.243| v_loss: 0.039| per_loss: 0.561 | a_loss: 0.509
Train: Epoch [418/3000], Step [120/158]| g_loss: 0.906| d_loss: 0.555| gp_loss: 0.047| r_loss: 0.155| p_loss: 0.230| v_loss: 0.040| per_loss: 0.559 | a_loss: 0.540
Train: Epoch [418/3000], Step [150/158]| g_loss: 0.908| d_loss: 0.634| gp_loss: 0.047| r_loss: 0.156| p_loss: 0.236| v_loss: 0.038| per_loss: 0.537 | a_loss: 0.543
Train: Epoch [419/3000], Step [30/158]| g_loss: 0.895| d_loss: 0.675| gp_loss: 0.126| r_loss: 0.159| p_loss: 0.237| v_loss: 0.040| per_loss: 0.559 | a_loss: 0.521
Train: Epoch [419/3000], Step [60/158]| g_loss: 0.926| d_loss: 0.556| gp_loss: 0.047| r_loss: 0.156| p_loss: 0.230| v_loss: 0.040| per_loss: 0.564 | a_loss: 0.558
Train: Epoch [419/3000], Step [90/158]| g_loss: 0.897| d_loss: 0.603| gp_loss: 0.046| r_loss: 0.157| p_loss: 0.232| v_loss: 0.040| per_loss: 0.535 | a_loss: 0.531
Train: Epoch [419/3000], Step [120/158]| g_loss: 0.914| d_loss: 0.568| gp_loss: 0.050| r_loss: 0.158| p_loss: 0.246| v_loss: 0.041| per_loss: 0.561 | a_loss: 0.535
Train: Epoch [419/3000], Step [150/158]| g_loss: 0.904| d_loss: 0.600| gp_loss: 0.054| r_loss: 0.155| p_loss: 0.239| v_loss: 0.039| per_loss: 0.557 | a_loss: 0.535
Train: Epoch [420/3000], Step [30/158]| g_loss: 0.929| d_loss: 0.645| gp_loss: 0.096| r_loss: 0.165| p_loss: 0.247| v_loss: 0.041| per_loss: 0.524 | a_loss: 0.547
Train: Epoch [420/3000], Step [60/158]| g_loss: 0.939| d_loss: 0.559| gp_loss: 0.050| r_loss: 0.162| p_loss: 0.233| v_loss: 0.038| per_loss: 0.563 | a_loss: 0.567
Train: Epoch [420/3000], Step [90/158]| g_loss: 0.901| d_loss: 0.616| gp_loss: 0.052| r_loss: 0.159| p_loss: 0.241| v_loss: 0.041| per_loss: 0.547 | a_loss: 0.525
Train: Epoch [420/3000], Step [120/158]| g_loss: 0.893| d_loss: 0.628| gp_loss: 0.051| r_loss: 0.157| p_loss: 0.232| v_loss: 0.043| per_loss: 0.562 | a_loss: 0.522
Train: Epoch [420/3000], Step [150/158]| g_loss: 0.966| d_loss: 0.517| gp_loss: 0.048| r_loss: 0.159| p_loss: 0.241| v_loss: 0.041| per_loss: 0.540 | a_loss: 0.592
Train: Epoch [421/3000], Step [30/158]| g_loss: 0.872| d_loss: 0.735| gp_loss: 0.120| r_loss: 0.160| p_loss: 0.248| v_loss: 0.039| per_loss: 0.557 | a_loss: 0.493
Train: Epoch [421/3000], Step [60/158]| g_loss: 0.996| d_loss: 0.499| gp_loss: 0.047| r_loss: 0.157| p_loss: 0.237| v_loss: 0.040| per_loss: 0.560 | a_loss: 0.625
Train: Epoch [421/3000], Step [90/158]| g_loss: 0.920| d_loss: 0.594| gp_loss: 0.049| r_loss: 0.161| p_loss: 0.236| v_loss: 0.039| per_loss: 0.525 | a_loss: 0.549
Train: Epoch [421/3000], Step [120/158]| g_loss: 0.917| d_loss: 0.585| gp_loss: 0.049| r_loss: 0.162| p_loss: 0.238| v_loss: 0.040| per_loss: 0.552 | a_loss: 0.541
Train: Epoch [421/3000], Step [150/158]| g_loss: 0.934| d_loss: 0.591| gp_loss: 0.049| r_loss: 0.163| p_loss: 0.237| v_loss: 0.042| per_loss: 0.556 | a_loss: 0.554
Train: Epoch [422/3000], Step [30/158]| g_loss: 0.848| d_loss: 0.734| gp_loss: 0.143| r_loss: 0.151| p_loss: 0.228| v_loss: 0.041| per_loss: 0.541 | a_loss: 0.487
Train: Epoch [422/3000], Step [60/158]| g_loss: 0.912| d_loss: 0.503| gp_loss: 0.048| r_loss: 0.154| p_loss: 0.235| v_loss: 0.042| per_loss: 0.563 | a_loss: 0.543
Train: Epoch [422/3000], Step [90/158]| g_loss: 0.960| d_loss: 0.551| gp_loss: 0.047| r_loss: 0.156| p_loss: 0.228| v_loss: 0.039| per_loss: 0.563 | a_loss: 0.594
Train: Epoch [422/3000], Step [120/158]| g_loss: 0.920| d_loss: 0.612| gp_loss: 0.051| r_loss: 0.164| p_loss: 0.233| v_loss: 0.041| per_loss: 0.530 | a_loss: 0.546
Train: Epoch [422/3000], Step [150/158]| g_loss: 0.879| d_loss: 0.689| gp_loss: 0.050| r_loss: 0.157| p_loss: 0.237| v_loss: 0.040| per_loss: 0.564 | a_loss: 0.507
Train: Epoch [423/3000], Step [30/158]| g_loss: 0.921| d_loss: 0.625| gp_loss: 0.113| r_loss: 0.160| p_loss: 0.242| v_loss: 0.041| per_loss: 0.541 | a_loss: 0.545
Train: Epoch [423/3000], Step [60/158]| g_loss: 0.911| d_loss: 0.657| gp_loss: 0.050| r_loss: 0.162| p_loss: 0.236| v_loss: 0.040| per_loss: 0.559 | a_loss: 0.535
Train: Epoch [423/3000], Step [90/158]| g_loss: 0.850| d_loss: 0.643| gp_loss: 0.050| r_loss: 0.162| p_loss: 0.235| v_loss: 0.040| per_loss: 0.568 | a_loss: 0.473
Train: Epoch [423/3000], Step [120/158]| g_loss: 0.936| d_loss: 0.523| gp_loss: 0.043| r_loss: 0.157| p_loss: 0.228| v_loss: 0.040| per_loss: 0.541 | a_loss: 0.571
Train: Epoch [423/3000], Step [150/158]| g_loss: 0.901| d_loss: 0.602| gp_loss: 0.048| r_loss: 0.158| p_loss: 0.238| v_loss: 0.040| per_loss: 0.556 | a_loss: 0.528
Train: Epoch [424/3000], Step [30/158]| g_loss: 0.949| d_loss: 0.667| gp_loss: 0.103| r_loss: 0.159| p_loss: 0.234| v_loss: 0.040| per_loss: 0.560 | a_loss: 0.577
Train: Epoch [424/3000], Step [60/158]| g_loss: 0.847| d_loss: 0.612| gp_loss: 0.047| r_loss: 0.151| p_loss: 0.225| v_loss: 0.038| per_loss: 0.526 | a_loss: 0.493
Train: Epoch [424/3000], Step [90/158]| g_loss: 0.923| d_loss: 0.643| gp_loss: 0.046| r_loss: 0.161| p_loss: 0.241| v_loss: 0.041| per_loss: 0.553 | a_loss: 0.545
Train: Epoch [424/3000], Step [120/158]| g_loss: 0.923| d_loss: 0.539| gp_loss: 0.046| r_loss: 0.154| p_loss: 0.239| v_loss: 0.041| per_loss: 0.575 | a_loss: 0.551
Train: Epoch [424/3000], Step [150/158]| g_loss: 0.926| d_loss: 0.613| gp_loss: 0.052| r_loss: 0.164| p_loss: 0.248| v_loss: 0.041| per_loss: 0.557 | a_loss: 0.542
Train: Epoch [425/3000], Step [30/158]| g_loss: 0.925| d_loss: 0.677| gp_loss: 0.143| r_loss: 0.157| p_loss: 0.232| v_loss: 0.039| per_loss: 0.572 | a_loss: 0.556
Train: Epoch [425/3000], Step [60/158]| g_loss: 0.893| d_loss: 0.640| gp_loss: 0.045| r_loss: 0.156| p_loss: 0.240| v_loss: 0.040| per_loss: 0.566 | a_loss: 0.520
Train: Epoch [425/3000], Step [90/158]| g_loss: 0.949| d_loss: 0.546| gp_loss: 0.047| r_loss: 0.164| p_loss: 0.245| v_loss: 0.037| per_loss: 0.562 | a_loss: 0.568
Train: Epoch [425/3000], Step [120/158]| g_loss: 0.913| d_loss: 0.618| gp_loss: 0.047| r_loss: 0.171| p_loss: 0.246| v_loss: 0.039| per_loss: 0.570 | a_loss: 0.524
Train: Epoch [425/3000], Step [150/158]| g_loss: 0.894| d_loss: 0.631| gp_loss: 0.046| r_loss: 0.153| p_loss: 0.249| v_loss: 0.041| per_loss: 0.571 | a_loss: 0.518
Train: Epoch [426/3000], Step [30/158]| g_loss: 0.885| d_loss: 0.718| gp_loss: 0.142| r_loss: 0.160| p_loss: 0.242| v_loss: 0.038| per_loss: 0.568 | a_loss: 0.509
Train: Epoch [426/3000], Step [60/158]| g_loss: 0.896| d_loss: 0.593| gp_loss: 0.041| r_loss: 0.151| p_loss: 0.235| v_loss: 0.039| per_loss: 0.544 | a_loss: 0.534
Train: Epoch [426/3000], Step [90/158]| g_loss: 0.883| d_loss: 0.580| gp_loss: 0.047| r_loss: 0.154| p_loss: 0.231| v_loss: 0.040| per_loss: 0.521 | a_loss: 0.522
Train: Epoch [426/3000], Step [120/158]| g_loss: 0.898| d_loss: 0.661| gp_loss: 0.047| r_loss: 0.162| p_loss: 0.239| v_loss: 0.039| per_loss: 0.579 | a_loss: 0.519
Train: Epoch [426/3000], Step [150/158]| g_loss: 0.952| d_loss: 0.539| gp_loss: 0.044| r_loss: 0.171| p_loss: 0.247| v_loss: 0.040| per_loss: 0.566 | a_loss: 0.561
Train: Epoch [427/3000], Step [30/158]| g_loss: 0.922| d_loss: 0.671| gp_loss: 0.123| r_loss: 0.148| p_loss: 0.241| v_loss: 0.039| per_loss: 0.535 | a_loss: 0.562
Train: Epoch [427/3000], Step [60/158]| g_loss: 0.920| d_loss: 0.606| gp_loss: 0.045| r_loss: 0.159| p_loss: 0.260| v_loss: 0.041| per_loss: 0.581 | a_loss: 0.532
Train: Epoch [427/3000], Step [90/158]| g_loss: 0.904| d_loss: 0.610| gp_loss: 0.044| r_loss: 0.160| p_loss: 0.260| v_loss: 0.040| per_loss: 0.569 | a_loss: 0.517
Train: Epoch [427/3000], Step [120/158]| g_loss: 0.999| d_loss: 0.577| gp_loss: 0.043| r_loss: 0.167| p_loss: 0.259| v_loss: 0.041| per_loss: 0.591 | a_loss: 0.603
Train: Epoch [427/3000], Step [150/158]| g_loss: 0.835| d_loss: 0.696| gp_loss: 0.046| r_loss: 0.174| p_loss: 0.247| v_loss: 0.038| per_loss: 0.551 | a_loss: 0.444
Train: Epoch [428/3000], Step [30/158]| g_loss: 0.932| d_loss: 0.664| gp_loss: 0.137| r_loss: 0.148| p_loss: 0.239| v_loss: 0.040| per_loss: 0.572 | a_loss: 0.566
Train: Epoch [428/3000], Step [60/158]| g_loss: 0.871| d_loss: 0.654| gp_loss: 0.043| r_loss: 0.162| p_loss: 0.235| v_loss: 0.038| per_loss: 0.555 | a_loss: 0.498
Train: Epoch [428/3000], Step [90/158]| g_loss: 0.934| d_loss: 0.542| gp_loss: 0.043| r_loss: 0.150| p_loss: 0.232| v_loss: 0.040| per_loss: 0.503 | a_loss: 0.577
Train: Epoch [428/3000], Step [120/158]| g_loss: 0.907| d_loss: 0.590| gp_loss: 0.047| r_loss: 0.162| p_loss: 0.232| v_loss: 0.039| per_loss: 0.597 | a_loss: 0.531
Train: Epoch [428/3000], Step [150/158]| g_loss: 0.925| d_loss: 0.592| gp_loss: 0.045| r_loss: 0.163| p_loss: 0.243| v_loss: 0.040| per_loss: 0.589 | a_loss: 0.541
Train: Epoch [429/3000], Step [30/158]| g_loss: 0.868| d_loss: 0.683| gp_loss: 0.112| r_loss: 0.148| p_loss: 0.228| v_loss: 0.039| per_loss: 0.537 | a_loss: 0.512
Train: Epoch [429/3000], Step [60/158]| g_loss: 0.861| d_loss: 0.668| gp_loss: 0.046| r_loss: 0.144| p_loss: 0.226| v_loss: 0.037| per_loss: 0.537 | a_loss: 0.513
Train: Epoch [429/3000], Step [90/158]| g_loss: 0.938| d_loss: 0.530| gp_loss: 0.045| r_loss: 0.170| p_loss: 0.242| v_loss: 0.041| per_loss: 0.575 | a_loss: 0.549
Train: Epoch [429/3000], Step [120/158]| g_loss: 0.923| d_loss: 0.589| gp_loss: 0.048| r_loss: 0.161| p_loss: 0.239| v_loss: 0.040| per_loss: 0.542 | a_loss: 0.548
Train: Epoch [429/3000], Step [150/158]| g_loss: 0.932| d_loss: 0.572| gp_loss: 0.048| r_loss: 0.157| p_loss: 0.239| v_loss: 0.040| per_loss: 0.543 | a_loss: 0.561
Train: Epoch [430/3000], Step [30/158]| g_loss: 0.906| d_loss: 0.662| gp_loss: 0.100| r_loss: 0.162| p_loss: 0.250| v_loss: 0.041| per_loss: 0.533 | a_loss: 0.525
Train: Epoch [430/3000], Step [60/158]| g_loss: 0.945| d_loss: 0.538| gp_loss: 0.046| r_loss: 0.157| p_loss: 0.231| v_loss: 0.040| per_loss: 0.548 | a_loss: 0.579
Train: Epoch [430/3000], Step [90/158]| g_loss: 0.912| d_loss: 0.611| gp_loss: 0.045| r_loss: 0.155| p_loss: 0.228| v_loss: 0.040| per_loss: 0.524 | a_loss: 0.550
Train: Epoch [430/3000], Step [120/158]| g_loss: 0.844| d_loss: 0.628| gp_loss: 0.047| r_loss: 0.151| p_loss: 0.231| v_loss: 0.040| per_loss: 0.536 | a_loss: 0.484
Train: Epoch [430/3000], Step [150/158]| g_loss: 0.902| d_loss: 0.592| gp_loss: 0.045| r_loss: 0.162| p_loss: 0.231| v_loss: 0.037| per_loss: 0.533 | a_loss: 0.534
Train: Epoch [431/3000], Step [30/158]| g_loss: 0.873| d_loss: 0.721| gp_loss: 0.172| r_loss: 0.144| p_loss: 0.228| v_loss: 0.039| per_loss: 0.517 | a_loss: 0.526
Train: Epoch [431/3000], Step [60/158]| g_loss: 0.945| d_loss: 0.520| gp_loss: 0.049| r_loss: 0.167| p_loss: 0.228| v_loss: 0.038| per_loss: 0.544 | a_loss: 0.571
Train: Epoch [431/3000], Step [90/158]| g_loss: 0.910| d_loss: 0.580| gp_loss: 0.049| r_loss: 0.152| p_loss: 0.225| v_loss: 0.039| per_loss: 0.531 | a_loss: 0.553
Train: Epoch [431/3000], Step [120/158]| g_loss: 0.876| d_loss: 0.632| gp_loss: 0.051| r_loss: 0.154| p_loss: 0.233| v_loss: 0.040| per_loss: 0.521 | a_loss: 0.513
Train: Epoch [431/3000], Step [150/158]| g_loss: 0.885| d_loss: 0.636| gp_loss: 0.049| r_loss: 0.160| p_loss: 0.235| v_loss: 0.039| per_loss: 0.543 | a_loss: 0.514
Train: Epoch [432/3000], Step [30/158]| g_loss: 0.875| d_loss: 0.666| gp_loss: 0.104| r_loss: 0.151| p_loss: 0.231| v_loss: 0.041| per_loss: 0.517 | a_loss: 0.516
Train: Epoch [432/3000], Step [60/158]| g_loss: 0.874| d_loss: 0.621| gp_loss: 0.046| r_loss: 0.153| p_loss: 0.232| v_loss: 0.039| per_loss: 0.505 | a_loss: 0.515
Train: Epoch [432/3000], Step [90/158]| g_loss: 0.873| d_loss: 0.635| gp_loss: 0.049| r_loss: 0.157| p_loss: 0.229| v_loss: 0.039| per_loss: 0.556 | a_loss: 0.507
Train: Epoch [432/3000], Step [120/158]| g_loss: 0.895| d_loss: 0.591| gp_loss: 0.048| r_loss: 0.165| p_loss: 0.229| v_loss: 0.039| per_loss: 0.516 | a_loss: 0.525
Train: Epoch [432/3000], Step [150/158]| g_loss: 0.928| d_loss: 0.557| gp_loss: 0.051| r_loss: 0.144| p_loss: 0.219| v_loss: 0.037| per_loss: 0.549 | a_loss: 0.583
Train: Epoch [433/3000], Step [30/158]| g_loss: 0.872| d_loss: 0.754| gp_loss: 0.203| r_loss: 0.151| p_loss: 0.229| v_loss: 0.040| per_loss: 0.546 | a_loss: 0.511
Train: Epoch [433/3000], Step [60/158]| g_loss: 0.880| d_loss: 0.592| gp_loss: 0.046| r_loss: 0.153| p_loss: 0.220| v_loss: 0.039| per_loss: 0.527 | a_loss: 0.524
Train: Epoch [433/3000], Step [90/158]| g_loss: 0.918| d_loss: 0.552| gp_loss: 0.045| r_loss: 0.154| p_loss: 0.231| v_loss: 0.039| per_loss: 0.507 | a_loss: 0.559
Train: Epoch [433/3000], Step [120/158]| g_loss: 0.945| d_loss: 0.569| gp_loss: 0.043| r_loss: 0.162| p_loss: 0.239| v_loss: 0.037| per_loss: 0.515 | a_loss: 0.575
Train: Epoch [433/3000], Step [150/158]| g_loss: 0.905| d_loss: 0.571| gp_loss: 0.051| r_loss: 0.159| p_loss: 0.228| v_loss: 0.038| per_loss: 0.526 | a_loss: 0.541
Train: Epoch [434/3000], Step [30/158]| g_loss: 0.864| d_loss: 0.771| gp_loss: 0.150| r_loss: 0.157| p_loss: 0.233| v_loss: 0.039| per_loss: 0.515 | a_loss: 0.500
Train: Epoch [434/3000], Step [60/158]| g_loss: 0.967| d_loss: 0.517| gp_loss: 0.047| r_loss: 0.161| p_loss: 0.237| v_loss: 0.040| per_loss: 0.553 | a_loss: 0.592
Train: Epoch [434/3000], Step [90/158]| g_loss: 0.918| d_loss: 0.563| gp_loss: 0.044| r_loss: 0.162| p_loss: 0.226| v_loss: 0.040| per_loss: 0.514 | a_loss: 0.552
Train: Epoch [434/3000], Step [120/158]| g_loss: 0.883| d_loss: 0.597| gp_loss: 0.046| r_loss: 0.145| p_loss: 0.217| v_loss: 0.038| per_loss: 0.544 | a_loss: 0.537
Train: Epoch [434/3000], Step [150/158]| g_loss: 0.904| d_loss: 0.594| gp_loss: 0.044| r_loss: 0.150| p_loss: 0.223| v_loss: 0.038| per_loss: 0.542 | a_loss: 0.550
Train: Epoch [435/3000], Step [30/158]| g_loss: 0.881| d_loss: 0.730| gp_loss: 0.132| r_loss: 0.161| p_loss: 0.229| v_loss: 0.036| per_loss: 0.512 | a_loss: 0.518
Train: Epoch [435/3000], Step [60/158]| g_loss: 0.856| d_loss: 0.620| gp_loss: 0.044| r_loss: 0.157| p_loss: 0.227| v_loss: 0.039| per_loss: 0.548 | a_loss: 0.492
Train: Epoch [435/3000], Step [90/158]| g_loss: 0.918| d_loss: 0.563| gp_loss: 0.041| r_loss: 0.154| p_loss: 0.233| v_loss: 0.040| per_loss: 0.583 | a_loss: 0.549
Train: Epoch [435/3000], Step [120/158]| g_loss: 0.963| d_loss: 0.497| gp_loss: 0.045| r_loss: 0.146| p_loss: 0.219| v_loss: 0.039| per_loss: 0.558 | a_loss: 0.614
Train: Epoch [435/3000], Step [150/158]| g_loss: 0.879| d_loss: 0.645| gp_loss: 0.043| r_loss: 0.154| p_loss: 0.226| v_loss: 0.038| per_loss: 0.539 | a_loss: 0.520
Train: Epoch [436/3000], Step [30/158]| g_loss: 0.814| d_loss: 0.751| gp_loss: 0.121| r_loss: 0.148| p_loss: 0.232| v_loss: 0.039| per_loss: 0.526 | a_loss: 0.458
Train: Epoch [436/3000], Step [60/158]| g_loss: 0.885| d_loss: 0.576| gp_loss: 0.043| r_loss: 0.156| p_loss: 0.215| v_loss: 0.039| per_loss: 0.529 | a_loss: 0.531
Train: Epoch [436/3000], Step [90/158]| g_loss: 0.888| d_loss: 0.586| gp_loss: 0.044| r_loss: 0.147| p_loss: 0.221| v_loss: 0.038| per_loss: 0.513 | a_loss: 0.541
Train: Epoch [436/3000], Step [120/158]| g_loss: 0.880| d_loss: 0.592| gp_loss: 0.045| r_loss: 0.151| p_loss: 0.219| v_loss: 0.036| per_loss: 0.541 | a_loss: 0.528
Train: Epoch [436/3000], Step [150/158]| g_loss: 0.892| d_loss: 0.567| gp_loss: 0.049| r_loss: 0.153| p_loss: 0.220| v_loss: 0.040| per_loss: 0.534 | a_loss: 0.536
Train: Epoch [437/3000], Step [30/158]| g_loss: 0.904| d_loss: 0.668| gp_loss: 0.139| r_loss: 0.150| p_loss: 0.234| v_loss: 0.039| per_loss: 0.528 | a_loss: 0.545
Train: Epoch [437/3000], Step [60/158]| g_loss: 0.934| d_loss: 0.542| gp_loss: 0.044| r_loss: 0.148| p_loss: 0.222| v_loss: 0.041| per_loss: 0.523 | a_loss: 0.582
Train: Epoch [437/3000], Step [90/158]| g_loss: 0.893| d_loss: 0.546| gp_loss: 0.046| r_loss: 0.147| p_loss: 0.223| v_loss: 0.039| per_loss: 0.529 | a_loss: 0.543
Train: Epoch [437/3000], Step [120/158]| g_loss: 0.914| d_loss: 0.587| gp_loss: 0.045| r_loss: 0.162| p_loss: 0.230| v_loss: 0.038| per_loss: 0.535 | a_loss: 0.546
Train: Epoch [437/3000], Step [150/158]| g_loss: 0.831| d_loss: 0.697| gp_loss: 0.050| r_loss: 0.158| p_loss: 0.230| v_loss: 0.039| per_loss: 0.552 | a_loss: 0.464
Train: Epoch [438/3000], Step [30/158]| g_loss: 0.874| d_loss: 0.736| gp_loss: 0.147| r_loss: 0.149| p_loss: 0.225| v_loss: 0.039| per_loss: 0.522 | a_loss: 0.521
Train: Epoch [438/3000], Step [60/158]| g_loss: 0.858| d_loss: 0.689| gp_loss: 0.045| r_loss: 0.151| p_loss: 0.229| v_loss: 0.038| per_loss: 0.526 | a_loss: 0.501
Train: Epoch [438/3000], Step [90/158]| g_loss: 0.901| d_loss: 0.578| gp_loss: 0.047| r_loss: 0.158| p_loss: 0.227| v_loss: 0.037| per_loss: 0.537 | a_loss: 0.538
Train: Epoch [438/3000], Step [120/158]| g_loss: 0.895| d_loss: 0.584| gp_loss: 0.046| r_loss: 0.158| p_loss: 0.230| v_loss: 0.037| per_loss: 0.537 | a_loss: 0.532
Train: Epoch [438/3000], Step [150/158]| g_loss: 0.944| d_loss: 0.508| gp_loss: 0.046| r_loss: 0.149| p_loss: 0.219| v_loss: 0.039| per_loss: 0.509 | a_loss: 0.596
Train: Epoch [439/3000], Step [30/158]| g_loss: 0.913| d_loss: 0.654| gp_loss: 0.078| r_loss: 0.163| p_loss: 0.224| v_loss: 0.038| per_loss: 0.584 | a_loss: 0.541
Train: Epoch [439/3000], Step [60/158]| g_loss: 0.934| d_loss: 0.560| gp_loss: 0.047| r_loss: 0.159| p_loss: 0.230| v_loss: 0.042| per_loss: 0.528 | a_loss: 0.566
Train: Epoch [439/3000], Step [90/158]| g_loss: 0.891| d_loss: 0.613| gp_loss: 0.044| r_loss: 0.151| p_loss: 0.231| v_loss: 0.039| per_loss: 0.510 | a_loss: 0.535
Train: Epoch [439/3000], Step [120/158]| g_loss: 0.874| d_loss: 0.659| gp_loss: 0.047| r_loss: 0.144| p_loss: 0.223| v_loss: 0.038| per_loss: 0.536 | a_loss: 0.526
Train: Epoch [439/3000], Step [150/158]| g_loss: 0.861| d_loss: 0.615| gp_loss: 0.051| r_loss: 0.156| p_loss: 0.229| v_loss: 0.039| per_loss: 0.531 | a_loss: 0.500
Train: Epoch [440/3000], Step [30/158]| g_loss: 0.939| d_loss: 0.586| gp_loss: 0.084| r_loss: 0.154| p_loss: 0.239| v_loss: 0.039| per_loss: 0.535 | a_loss: 0.573
Train: Epoch [440/3000], Step [60/158]| g_loss: 0.904| d_loss: 0.577| gp_loss: 0.050| r_loss: 0.157| p_loss: 0.224| v_loss: 0.038| per_loss: 0.584 | a_loss: 0.538
Train: Epoch [440/3000], Step [90/158]| g_loss: 0.879| d_loss: 0.575| gp_loss: 0.052| r_loss: 0.150| p_loss: 0.221| v_loss: 0.040| per_loss: 0.550 | a_loss: 0.524
Train: Epoch [440/3000], Step [120/158]| g_loss: 0.906| d_loss: 0.580| gp_loss: 0.048| r_loss: 0.144| p_loss: 0.211| v_loss: 0.036| per_loss: 0.532 | a_loss: 0.567
Train: Epoch [440/3000], Step [150/158]| g_loss: 0.872| d_loss: 0.618| gp_loss: 0.051| r_loss: 0.153| p_loss: 0.232| v_loss: 0.038| per_loss: 0.504 | a_loss: 0.515
Train: Epoch [441/3000], Step [30/158]| g_loss: 0.838| d_loss: 0.735| gp_loss: 0.143| r_loss: 0.142| p_loss: 0.223| v_loss: 0.037| per_loss: 0.517 | a_loss: 0.496
Train: Epoch [441/3000], Step [60/158]| g_loss: 0.944| d_loss: 0.573| gp_loss: 0.051| r_loss: 0.149| p_loss: 0.232| v_loss: 0.040| per_loss: 0.525 | a_loss: 0.587
Train: Epoch [441/3000], Step [90/158]| g_loss: 0.859| d_loss: 0.572| gp_loss: 0.052| r_loss: 0.151| p_loss: 0.227| v_loss: 0.038| per_loss: 0.528 | a_loss: 0.504
Train: Epoch [441/3000], Step [120/158]| g_loss: 0.893| d_loss: 0.603| gp_loss: 0.047| r_loss: 0.153| p_loss: 0.221| v_loss: 0.039| per_loss: 0.531 | a_loss: 0.537
Train: Epoch [441/3000], Step [150/158]| g_loss: 0.907| d_loss: 0.602| gp_loss: 0.048| r_loss: 0.159| p_loss: 0.230| v_loss: 0.039| per_loss: 0.539 | a_loss: 0.540
Train: Epoch [442/3000], Step [30/158]| g_loss: 0.887| d_loss: 0.700| gp_loss: 0.097| r_loss: 0.164| p_loss: 0.249| v_loss: 0.038| per_loss: 0.527 | a_loss: 0.509
Train: Epoch [442/3000], Step [60/158]| g_loss: 0.953| d_loss: 0.517| gp_loss: 0.046| r_loss: 0.150| p_loss: 0.223| v_loss: 0.037| per_loss: 0.572 | a_loss: 0.597
Train: Epoch [442/3000], Step [90/158]| g_loss: 0.929| d_loss: 0.596| gp_loss: 0.048| r_loss: 0.150| p_loss: 0.224| v_loss: 0.037| per_loss: 0.494 | a_loss: 0.580
Train: Epoch [442/3000], Step [120/158]| g_loss: 0.867| d_loss: 0.645| gp_loss: 0.051| r_loss: 0.151| p_loss: 0.226| v_loss: 0.037| per_loss: 0.517 | a_loss: 0.514
Train: Epoch [442/3000], Step [150/158]| g_loss: 0.884| d_loss: 0.588| gp_loss: 0.051| r_loss: 0.145| p_loss: 0.220| v_loss: 0.039| per_loss: 0.509 | a_loss: 0.539
Train: Epoch [443/3000], Step [30/158]| g_loss: 0.885| d_loss: 0.601| gp_loss: 0.104| r_loss: 0.154| p_loss: 0.224| v_loss: 0.038| per_loss: 0.530 | a_loss: 0.528
Train: Epoch [443/3000], Step [60/158]| g_loss: 0.935| d_loss: 0.540| gp_loss: 0.048| r_loss: 0.148| p_loss: 0.216| v_loss: 0.038| per_loss: 0.490 | a_loss: 0.592
Train: Epoch [443/3000], Step [90/158]| g_loss: 0.877| d_loss: 0.599| gp_loss: 0.050| r_loss: 0.143| p_loss: 0.217| v_loss: 0.040| per_loss: 0.518 | a_loss: 0.534
Train: Epoch [443/3000], Step [120/158]| g_loss: 0.841| d_loss: 0.695| gp_loss: 0.051| r_loss: 0.154| p_loss: 0.225| v_loss: 0.037| per_loss: 0.508 | a_loss: 0.487
Train: Epoch [443/3000], Step [150/158]| g_loss: 0.879| d_loss: 0.583| gp_loss: 0.052| r_loss: 0.153| p_loss: 0.227| v_loss: 0.037| per_loss: 0.530 | a_loss: 0.522
Train: Epoch [444/3000], Step [30/158]| g_loss: 0.914| d_loss: 0.665| gp_loss: 0.104| r_loss: 0.156| p_loss: 0.235| v_loss: 0.037| per_loss: 0.516 | a_loss: 0.551
Train: Epoch [444/3000], Step [60/158]| g_loss: 0.900| d_loss: 0.573| gp_loss: 0.047| r_loss: 0.152| p_loss: 0.224| v_loss: 0.037| per_loss: 0.547 | a_loss: 0.545
Train: Epoch [444/3000], Step [90/158]| g_loss: 0.878| d_loss: 0.595| gp_loss: 0.052| r_loss: 0.158| p_loss: 0.233| v_loss: 0.038| per_loss: 0.531 | a_loss: 0.513
Train: Epoch [444/3000], Step [120/158]| g_loss: 0.861| d_loss: 0.639| gp_loss: 0.053| r_loss: 0.138| p_loss: 0.224| v_loss: 0.038| per_loss: 0.536 | a_loss: 0.520
Train: Epoch [444/3000], Step [150/158]| g_loss: 0.922| d_loss: 0.540| gp_loss: 0.052| r_loss: 0.156| p_loss: 0.241| v_loss: 0.038| per_loss: 0.542 | a_loss: 0.554
Train: Epoch [445/3000], Step [30/158]| g_loss: 0.870| d_loss: 0.734| gp_loss: 0.101| r_loss: 0.152| p_loss: 0.242| v_loss: 0.038| per_loss: 0.536 | a_loss: 0.505
Train: Epoch [445/3000], Step [60/158]| g_loss: 0.859| d_loss: 0.599| gp_loss: 0.051| r_loss: 0.151| p_loss: 0.220| v_loss: 0.038| per_loss: 0.528 | a_loss: 0.507
Train: Epoch [445/3000], Step [90/158]| g_loss: 0.909| d_loss: 0.562| gp_loss: 0.049| r_loss: 0.147| p_loss: 0.223| v_loss: 0.039| per_loss: 0.514 | a_loss: 0.559
Train: Epoch [445/3000], Step [120/158]| g_loss: 0.919| d_loss: 0.552| gp_loss: 0.053| r_loss: 0.149| p_loss: 0.223| v_loss: 0.038| per_loss: 0.534 | a_loss: 0.568
Train: Epoch [445/3000], Step [150/158]| g_loss: 0.902| d_loss: 0.641| gp_loss: 0.052| r_loss: 0.152| p_loss: 0.227| v_loss: 0.037| per_loss: 0.538 | a_loss: 0.546
Train: Epoch [446/3000], Step [30/158]| g_loss: 0.905| d_loss: 0.689| gp_loss: 0.174| r_loss: 0.151| p_loss: 0.226| v_loss: 0.038| per_loss: 0.541 | a_loss: 0.549
Train: Epoch [446/3000], Step [60/158]| g_loss: 0.828| d_loss: 0.638| gp_loss: 0.049| r_loss: 0.144| p_loss: 0.230| v_loss: 0.038| per_loss: 0.518 | a_loss: 0.480
Train: Epoch [446/3000], Step [90/158]| g_loss: 0.876| d_loss: 0.601| gp_loss: 0.050| r_loss: 0.141| p_loss: 0.234| v_loss: 0.039| per_loss: 0.526 | a_loss: 0.526
Train: Epoch [446/3000], Step [120/158]| g_loss: 0.980| d_loss: 0.543| gp_loss: 0.046| r_loss: 0.172| p_loss: 0.238| v_loss: 0.039| per_loss: 0.524 | a_loss: 0.598
Train: Epoch [446/3000], Step [150/158]| g_loss: 0.881| d_loss: 0.601| gp_loss: 0.050| r_loss: 0.152| p_loss: 0.232| v_loss: 0.039| per_loss: 0.542 | a_loss: 0.520
Train: Epoch [447/3000], Step [30/158]| g_loss: 0.856| d_loss: 0.714| gp_loss: 0.087| r_loss: 0.157| p_loss: 0.231| v_loss: 0.038| per_loss: 0.559 | a_loss: 0.490
Train: Epoch [447/3000], Step [60/158]| g_loss: 0.916| d_loss: 0.601| gp_loss: 0.046| r_loss: 0.152| p_loss: 0.235| v_loss: 0.039| per_loss: 0.490 | a_loss: 0.559
Train: Epoch [447/3000], Step [90/158]| g_loss: 0.909| d_loss: 0.548| gp_loss: 0.045| r_loss: 0.159| p_loss: 0.232| v_loss: 0.037| per_loss: 0.543 | a_loss: 0.543
Train: Epoch [447/3000], Step [120/158]| g_loss: 0.880| d_loss: 0.639| gp_loss: 0.050| r_loss: 0.150| p_loss: 0.228| v_loss: 0.039| per_loss: 0.525 | a_loss: 0.525
Train: Epoch [447/3000], Step [150/158]| g_loss: 0.883| d_loss: 0.564| gp_loss: 0.053| r_loss: 0.147| p_loss: 0.220| v_loss: 0.036| per_loss: 0.533 | a_loss: 0.536
Train: Epoch [448/3000], Step [30/158]| g_loss: 0.896| d_loss: 0.622| gp_loss: 0.111| r_loss: 0.147| p_loss: 0.222| v_loss: 0.039| per_loss: 0.505 | a_loss: 0.550
Train: Epoch [448/3000], Step [60/158]| g_loss: 0.902| d_loss: 0.609| gp_loss: 0.048| r_loss: 0.162| p_loss: 0.228| v_loss: 0.040| per_loss: 0.480 | a_loss: 0.538
Train: Epoch [448/3000], Step [90/158]| g_loss: 0.909| d_loss: 0.561| gp_loss: 0.050| r_loss: 0.150| p_loss: 0.220| v_loss: 0.039| per_loss: 0.512 | a_loss: 0.557
Train: Epoch [448/3000], Step [120/158]| g_loss: 0.869| d_loss: 0.595| gp_loss: 0.047| r_loss: 0.146| p_loss: 0.220| v_loss: 0.039| per_loss: 0.523 | a_loss: 0.522
Train: Epoch [448/3000], Step [150/158]| g_loss: 0.881| d_loss: 0.609| gp_loss: 0.054| r_loss: 0.136| p_loss: 0.217| v_loss: 0.037| per_loss: 0.541 | a_loss: 0.545
Train: Epoch [449/3000], Step [30/158]| g_loss: 0.825| d_loss: 0.736| gp_loss: 0.079| r_loss: 0.145| p_loss: 0.221| v_loss: 0.037| per_loss: 0.521 | a_loss: 0.480
Train: Epoch [449/3000], Step [60/158]| g_loss: 0.925| d_loss: 0.483| gp_loss: 0.047| r_loss: 0.137| p_loss: 0.217| v_loss: 0.038| per_loss: 0.505 | a_loss: 0.592
Train: Epoch [449/3000], Step [90/158]| g_loss: 0.847| d_loss: 0.655| gp_loss: 0.056| r_loss: 0.153| p_loss: 0.224| v_loss: 0.036| per_loss: 0.533 | a_loss: 0.493
Train: Epoch [449/3000], Step [120/158]| g_loss: 0.890| d_loss: 0.595| gp_loss: 0.053| r_loss: 0.163| p_loss: 0.225| v_loss: 0.037| per_loss: 0.513 | a_loss: 0.527
Train: Epoch [449/3000], Step [150/158]| g_loss: 0.900| d_loss: 0.613| gp_loss: 0.054| r_loss: 0.148| p_loss: 0.225| v_loss: 0.039| per_loss: 0.527 | a_loss: 0.548
Train: Epoch [450/3000], Step [30/158]| g_loss: 0.882| d_loss: 0.703| gp_loss: 0.190| r_loss: 0.144| p_loss: 0.218| v_loss: 0.039| per_loss: 0.513 | a_loss: 0.539
Train: Epoch [450/3000], Step [60/158]| g_loss: 0.905| d_loss: 0.575| gp_loss: 0.046| r_loss: 0.156| p_loss: 0.225| v_loss: 0.041| per_loss: 0.527 | a_loss: 0.542
Train: Epoch [450/3000], Step [90/158]| g_loss: 0.902| d_loss: 0.537| gp_loss: 0.050| r_loss: 0.155| p_loss: 0.231| v_loss: 0.037| per_loss: 0.552 | a_loss: 0.539
Train: Epoch [450/3000], Step [120/158]| g_loss: 0.909| d_loss: 0.570| gp_loss: 0.052| r_loss: 0.146| p_loss: 0.225| v_loss: 0.037| per_loss: 0.501 | a_loss: 0.564
Train: Epoch [450/3000], Step [150/158]| g_loss: 0.857| d_loss: 0.652| gp_loss: 0.052| r_loss: 0.142| p_loss: 0.222| v_loss: 0.034| per_loss: 0.527 | a_loss: 0.517
Test: Epoch [450/3000]| g_loss: 0.766| r_loss: 0.503| p_loss: 0.342| v_loss: 0.029
Train: Epoch [451/3000], Step [30/158]| g_loss: 0.897| d_loss: 0.527| gp_loss: 0.045| r_loss: 0.139| p_loss: 0.222| v_loss: 0.037| per_loss: 0.535 | a_loss: 0.557
Train: Epoch [451/3000], Step [60/158]| g_loss: 0.893| d_loss: 0.585| gp_loss: 0.049| r_loss: 0.150| p_loss: 0.221| v_loss: 0.037| per_loss: 0.547 | a_loss: 0.541
Train: Epoch [451/3000], Step [90/158]| g_loss: 0.877| d_loss: 0.606| gp_loss: 0.051| r_loss: 0.157| p_loss: 0.223| v_loss: 0.040| per_loss: 0.481 | a_loss: 0.520
Train: Epoch [451/3000], Step [120/158]| g_loss: 0.850| d_loss: 0.654| gp_loss: 0.051| r_loss: 0.140| p_loss: 0.227| v_loss: 0.036| per_loss: 0.531 | a_loss: 0.507
Train: Epoch [451/3000], Step [150/158]| g_loss: 0.894| d_loss: 0.584| gp_loss: 0.050| r_loss: 0.161| p_loss: 0.231| v_loss: 0.039| per_loss: 0.544 | a_loss: 0.523
Train: Epoch [452/3000], Step [30/158]| g_loss: 0.916| d_loss: 0.650| gp_loss: 0.116| r_loss: 0.150| p_loss: 0.232| v_loss: 0.038| per_loss: 0.545 | a_loss: 0.557
Train: Epoch [452/3000], Step [60/158]| g_loss: 0.874| d_loss: 0.622| gp_loss: 0.048| r_loss: 0.153| p_loss: 0.232| v_loss: 0.038| per_loss: 0.496 | a_loss: 0.518
Train: Epoch [452/3000], Step [90/158]| g_loss: 0.920| d_loss: 0.539| gp_loss: 0.047| r_loss: 0.139| p_loss: 0.214| v_loss: 0.038| per_loss: 0.528 | a_loss: 0.584
Train: Epoch [452/3000], Step [120/158]| g_loss: 0.870| d_loss: 0.664| gp_loss: 0.053| r_loss: 0.164| p_loss: 0.226| v_loss: 0.037| per_loss: 0.548 | a_loss: 0.501
Train: Epoch [452/3000], Step [150/158]| g_loss: 0.869| d_loss: 0.582| gp_loss: 0.050| r_loss: 0.144| p_loss: 0.228| v_loss: 0.037| per_loss: 0.492 | a_loss: 0.525
Train: Epoch [453/3000], Step [30/158]| g_loss: 0.917| d_loss: 0.618| gp_loss: 0.130| r_loss: 0.154| p_loss: 0.225| v_loss: 0.039| per_loss: 0.517 | a_loss: 0.559
Train: Epoch [453/3000], Step [60/158]| g_loss: 0.823| d_loss: 0.686| gp_loss: 0.050| r_loss: 0.140| p_loss: 0.228| v_loss: 0.037| per_loss: 0.545 | a_loss: 0.478
Train: Epoch [453/3000], Step [90/158]| g_loss: 0.871| d_loss: 0.587| gp_loss: 0.048| r_loss: 0.154| p_loss: 0.232| v_loss: 0.037| per_loss: 0.510 | a_loss: 0.513
Train: Epoch [453/3000], Step [120/158]| g_loss: 0.981| d_loss: 0.502| gp_loss: 0.047| r_loss: 0.148| p_loss: 0.222| v_loss: 0.036| per_loss: 0.549 | a_loss: 0.632
Train: Epoch [453/3000], Step [150/158]| g_loss: 0.876| d_loss: 0.688| gp_loss: 0.052| r_loss: 0.153| p_loss: 0.228| v_loss: 0.039| per_loss: 0.489 | a_loss: 0.521
Train: Epoch [454/3000], Step [30/158]| g_loss: 0.882| d_loss: 0.619| gp_loss: 0.122| r_loss: 0.160| p_loss: 0.232| v_loss: 0.039| per_loss: 0.531 | a_loss: 0.514
Train: Epoch [454/3000], Step [60/158]| g_loss: 0.915| d_loss: 0.578| gp_loss: 0.047| r_loss: 0.139| p_loss: 0.221| v_loss: 0.037| per_loss: 0.521 | a_loss: 0.577
Train: Epoch [454/3000], Step [90/158]| g_loss: 0.890| d_loss: 0.621| gp_loss: 0.050| r_loss: 0.145| p_loss: 0.232| v_loss: 0.039| per_loss: 0.509 | a_loss: 0.539
Train: Epoch [454/3000], Step [120/158]| g_loss: 0.880| d_loss: 0.537| gp_loss: 0.049| r_loss: 0.144| p_loss: 0.222| v_loss: 0.037| per_loss: 0.517 | a_loss: 0.536
Train: Epoch [454/3000], Step [150/158]| g_loss: 0.927| d_loss: 0.618| gp_loss: 0.049| r_loss: 0.156| p_loss: 0.230| v_loss: 0.041| per_loss: 0.531 | a_loss: 0.562
Train: Epoch [455/3000], Step [30/158]| g_loss: 0.903| d_loss: 0.645| gp_loss: 0.108| r_loss: 0.166| p_loss: 0.235| v_loss: 0.039| per_loss: 0.519 | a_loss: 0.529
Train: Epoch [455/3000], Step [60/158]| g_loss: 0.883| d_loss: 0.570| gp_loss: 0.045| r_loss: 0.138| p_loss: 0.218| v_loss: 0.038| per_loss: 0.479 | a_loss: 0.550
Train: Epoch [455/3000], Step [90/158]| g_loss: 0.843| d_loss: 0.649| gp_loss: 0.051| r_loss: 0.140| p_loss: 0.228| v_loss: 0.038| per_loss: 0.513 | a_loss: 0.501
Train: Epoch [455/3000], Step [120/158]| g_loss: 0.906| d_loss: 0.624| gp_loss: 0.049| r_loss: 0.163| p_loss: 0.235| v_loss: 0.038| per_loss: 0.537 | a_loss: 0.534
Train: Epoch [455/3000], Step [150/158]| g_loss: 0.910| d_loss: 0.558| gp_loss: 0.051| r_loss: 0.139| p_loss: 0.224| v_loss: 0.038| per_loss: 0.523 | a_loss: 0.568
Train: Epoch [456/3000], Step [30/158]| g_loss: 0.879| d_loss: 0.662| gp_loss: 0.129| r_loss: 0.147| p_loss: 0.226| v_loss: 0.040| per_loss: 0.543 | a_loss: 0.525
Train: Epoch [456/3000], Step [60/158]| g_loss: 0.890| d_loss: 0.643| gp_loss: 0.049| r_loss: 0.151| p_loss: 0.233| v_loss: 0.036| per_loss: 0.487 | a_loss: 0.538
Train: Epoch [456/3000], Step [90/158]| g_loss: 0.881| d_loss: 0.619| gp_loss: 0.047| r_loss: 0.144| p_loss: 0.226| v_loss: 0.037| per_loss: 0.545 | a_loss: 0.532
Train: Epoch [456/3000], Step [120/158]| g_loss: 0.854| d_loss: 0.624| gp_loss: 0.051| r_loss: 0.157| p_loss: 0.233| v_loss: 0.036| per_loss: 0.531 | a_loss: 0.491
Train: Epoch [456/3000], Step [150/158]| g_loss: 0.933| d_loss: 0.585| gp_loss: 0.045| r_loss: 0.161| p_loss: 0.234| v_loss: 0.037| per_loss: 0.521 | a_loss: 0.566
Train: Epoch [457/3000], Step [30/158]| g_loss: 0.890| d_loss: 0.668| gp_loss: 0.116| r_loss: 0.151| p_loss: 0.242| v_loss: 0.039| per_loss: 0.498 | a_loss: 0.529
Train: Epoch [457/3000], Step [60/158]| g_loss: 0.880| d_loss: 0.532| gp_loss: 0.046| r_loss: 0.140| p_loss: 0.218| v_loss: 0.039| per_loss: 0.503 | a_loss: 0.541
Train: Epoch [457/3000], Step [90/158]| g_loss: 0.898| d_loss: 0.625| gp_loss: 0.046| r_loss: 0.153| p_loss: 0.226| v_loss: 0.039| per_loss: 0.525 | a_loss: 0.541
Train: Epoch [457/3000], Step [120/158]| g_loss: 0.869| d_loss: 0.645| gp_loss: 0.048| r_loss: 0.147| p_loss: 0.224| v_loss: 0.037| per_loss: 0.557 | a_loss: 0.518
Train: Epoch [457/3000], Step [150/158]| g_loss: 0.891| d_loss: 0.627| gp_loss: 0.049| r_loss: 0.159| p_loss: 0.229| v_loss: 0.037| per_loss: 0.536 | a_loss: 0.527
Train: Epoch [458/3000], Step [30/158]| g_loss: 0.859| d_loss: 0.657| gp_loss: 0.115| r_loss: 0.148| p_loss: 0.223| v_loss: 0.035| per_loss: 0.528 | a_loss: 0.511
Train: Epoch [458/3000], Step [60/158]| g_loss: 0.926| d_loss: 0.549| gp_loss: 0.050| r_loss: 0.150| p_loss: 0.226| v_loss: 0.038| per_loss: 0.513 | a_loss: 0.573
Train: Epoch [458/3000], Step [90/158]| g_loss: 0.893| d_loss: 0.635| gp_loss: 0.051| r_loss: 0.146| p_loss: 0.224| v_loss: 0.037| per_loss: 0.534 | a_loss: 0.545
Train: Epoch [458/3000], Step [120/158]| g_loss: 0.901| d_loss: 0.545| gp_loss: 0.052| r_loss: 0.146| p_loss: 0.226| v_loss: 0.038| per_loss: 0.514 | a_loss: 0.553
Train: Epoch [458/3000], Step [150/158]| g_loss: 0.893| d_loss: 0.647| gp_loss: 0.045| r_loss: 0.153| p_loss: 0.222| v_loss: 0.039| per_loss: 0.534 | a_loss: 0.537
Train: Epoch [459/3000], Step [30/158]| g_loss: 0.871| d_loss: 0.683| gp_loss: 0.145| r_loss: 0.137| p_loss: 0.216| v_loss: 0.037| per_loss: 0.530 | a_loss: 0.535
Train: Epoch [459/3000], Step [60/158]| g_loss: 0.864| d_loss: 0.612| gp_loss: 0.048| r_loss: 0.158| p_loss: 0.228| v_loss: 0.039| per_loss: 0.508 | a_loss: 0.502
Train: Epoch [459/3000], Step [90/158]| g_loss: 0.881| d_loss: 0.578| gp_loss: 0.047| r_loss: 0.151| p_loss: 0.222| v_loss: 0.037| per_loss: 0.534 | a_loss: 0.528
Train: Epoch [459/3000], Step [120/158]| g_loss: 0.906| d_loss: 0.562| gp_loss: 0.045| r_loss: 0.147| p_loss: 0.231| v_loss: 0.037| per_loss: 0.526 | a_loss: 0.554
Train: Epoch [459/3000], Step [150/158]| g_loss: 0.868| d_loss: 0.689| gp_loss: 0.050| r_loss: 0.146| p_loss: 0.224| v_loss: 0.038| per_loss: 0.513 | a_loss: 0.520
Train: Epoch [460/3000], Step [30/158]| g_loss: 0.853| d_loss: 0.642| gp_loss: 0.115| r_loss: 0.154| p_loss: 0.234| v_loss: 0.038| per_loss: 0.508 | a_loss: 0.493
Train: Epoch [460/3000], Step [60/158]| g_loss: 0.978| d_loss: 0.525| gp_loss: 0.043| r_loss: 0.143| p_loss: 0.224| v_loss: 0.038| per_loss: 0.536 | a_loss: 0.632
Train: Epoch [460/3000], Step [90/158]| g_loss: 0.915| d_loss: 0.572| gp_loss: 0.045| r_loss: 0.146| p_loss: 0.218| v_loss: 0.038| per_loss: 0.522 | a_loss: 0.570
Train: Epoch [460/3000], Step [120/158]| g_loss: 0.852| d_loss: 0.610| gp_loss: 0.050| r_loss: 0.147| p_loss: 0.230| v_loss: 0.039| per_loss: 0.553 | a_loss: 0.495
Train: Epoch [460/3000], Step [150/158]| g_loss: 0.869| d_loss: 0.672| gp_loss: 0.050| r_loss: 0.149| p_loss: 0.232| v_loss: 0.038| per_loss: 0.526 | a_loss: 0.513
Train: Epoch [461/3000], Step [30/158]| g_loss: 0.866| d_loss: 0.709| gp_loss: 0.148| r_loss: 0.150| p_loss: 0.225| v_loss: 0.037| per_loss: 0.504 | a_loss: 0.516
Train: Epoch [461/3000], Step [60/158]| g_loss: 0.874| d_loss: 0.556| gp_loss: 0.049| r_loss: 0.152| p_loss: 0.236| v_loss: 0.038| per_loss: 0.510 | a_loss: 0.515
Train: Epoch [461/3000], Step [90/158]| g_loss: 0.937| d_loss: 0.578| gp_loss: 0.047| r_loss: 0.147| p_loss: 0.220| v_loss: 0.038| per_loss: 0.556 | a_loss: 0.586
Train: Epoch [461/3000], Step [120/158]| g_loss: 0.895| d_loss: 0.589| gp_loss: 0.046| r_loss: 0.144| p_loss: 0.226| v_loss: 0.038| per_loss: 0.510 | a_loss: 0.549
Train: Epoch [461/3000], Step [150/158]| g_loss: 0.865| d_loss: 0.652| gp_loss: 0.051| r_loss: 0.143| p_loss: 0.220| v_loss: 0.038| per_loss: 0.559 | a_loss: 0.518
Train: Epoch [462/3000], Step [30/158]| g_loss: 0.849| d_loss: 0.781| gp_loss: 0.177| r_loss: 0.153| p_loss: 0.223| v_loss: 0.038| per_loss: 0.533 | a_loss: 0.494
Train: Epoch [462/3000], Step [60/158]| g_loss: 0.819| d_loss: 0.643| gp_loss: 0.046| r_loss: 0.151| p_loss: 0.234| v_loss: 0.038| per_loss: 0.526 | a_loss: 0.461
Train: Epoch [462/3000], Step [90/158]| g_loss: 0.904| d_loss: 0.571| gp_loss: 0.046| r_loss: 0.147| p_loss: 0.222| v_loss: 0.038| per_loss: 0.548 | a_loss: 0.553
Train: Epoch [462/3000], Step [120/158]| g_loss: 0.898| d_loss: 0.587| gp_loss: 0.050| r_loss: 0.146| p_loss: 0.220| v_loss: 0.039| per_loss: 0.540 | a_loss: 0.550
Train: Epoch [462/3000], Step [150/158]| g_loss: 0.877| d_loss: 0.569| gp_loss: 0.046| r_loss: 0.139| p_loss: 0.224| v_loss: 0.038| per_loss: 0.529 | a_loss: 0.535
Train: Epoch [463/3000], Step [30/158]| g_loss: 0.921| d_loss: 0.599| gp_loss: 0.089| r_loss: 0.151| p_loss: 0.241| v_loss: 0.038| per_loss: 0.540 | a_loss: 0.557
Train: Epoch [463/3000], Step [60/158]| g_loss: 0.907| d_loss: 0.619| gp_loss: 0.048| r_loss: 0.142| p_loss: 0.231| v_loss: 0.038| per_loss: 0.503 | a_loss: 0.560
Train: Epoch [463/3000], Step [90/158]| g_loss: 0.903| d_loss: 0.577| gp_loss: 0.046| r_loss: 0.152| p_loss: 0.217| v_loss: 0.037| per_loss: 0.548 | a_loss: 0.551
Train: Epoch [463/3000], Step [120/158]| g_loss: 0.890| d_loss: 0.638| gp_loss: 0.047| r_loss: 0.153| p_loss: 0.230| v_loss: 0.038| per_loss: 0.534 | a_loss: 0.530
Train: Epoch [463/3000], Step [150/158]| g_loss: 0.918| d_loss: 0.518| gp_loss: 0.049| r_loss: 0.148| p_loss: 0.223| v_loss: 0.040| per_loss: 0.603 | a_loss: 0.558
Train: Epoch [464/3000], Step [30/158]| g_loss: 0.898| d_loss: 0.720| gp_loss: 0.218| r_loss: 0.152| p_loss: 0.225| v_loss: 0.039| per_loss: 0.520 | a_loss: 0.541
Train: Epoch [464/3000], Step [60/158]| g_loss: 0.902| d_loss: 0.597| gp_loss: 0.042| r_loss: 0.144| p_loss: 0.219| v_loss: 0.037| per_loss: 0.528 | a_loss: 0.558
Train: Epoch [464/3000], Step [90/158]| g_loss: 0.855| d_loss: 0.609| gp_loss: 0.044| r_loss: 0.141| p_loss: 0.221| v_loss: 0.037| per_loss: 0.522 | a_loss: 0.515
Train: Epoch [464/3000], Step [120/158]| g_loss: 0.843| d_loss: 0.650| gp_loss: 0.045| r_loss: 0.153| p_loss: 0.223| v_loss: 0.037| per_loss: 0.540 | a_loss: 0.487
Train: Epoch [464/3000], Step [150/158]| g_loss: 0.876| d_loss: 0.559| gp_loss: 0.046| r_loss: 0.149| p_loss: 0.226| v_loss: 0.039| per_loss: 0.552 | a_loss: 0.521
Train: Epoch [465/3000], Step [30/158]| g_loss: 0.897| d_loss: 0.710| gp_loss: 0.183| r_loss: 0.139| p_loss: 0.225| v_loss: 0.039| per_loss: 0.512 | a_loss: 0.556
Train: Epoch [465/3000], Step [60/158]| g_loss: 0.858| d_loss: 0.629| gp_loss: 0.048| r_loss: 0.140| p_loss: 0.220| v_loss: 0.039| per_loss: 0.560 | a_loss: 0.513
Train: Epoch [465/3000], Step [90/158]| g_loss: 0.916| d_loss: 0.537| gp_loss: 0.046| r_loss: 0.152| p_loss: 0.223| v_loss: 0.039| per_loss: 0.533 | a_loss: 0.561
Train: Epoch [465/3000], Step [120/158]| g_loss: 0.890| d_loss: 0.573| gp_loss: 0.047| r_loss: 0.149| p_loss: 0.224| v_loss: 0.039| per_loss: 0.520 | a_loss: 0.538
Train: Epoch [465/3000], Step [150/158]| g_loss: 0.905| d_loss: 0.622| gp_loss: 0.046| r_loss: 0.155| p_loss: 0.225| v_loss: 0.036| per_loss: 0.519 | a_loss: 0.548
Train: Epoch [466/3000], Step [30/158]| g_loss: 0.865| d_loss: 0.657| gp_loss: 0.111| r_loss: 0.139| p_loss: 0.225| v_loss: 0.036| per_loss: 0.526 | a_loss: 0.526
Train: Epoch [466/3000], Step [60/158]| g_loss: 0.829| d_loss: 0.731| gp_loss: 0.049| r_loss: 0.165| p_loss: 0.239| v_loss: 0.038| per_loss: 0.506 | a_loss: 0.456
Train: Epoch [466/3000], Step [90/158]| g_loss: 0.901| d_loss: 0.590| gp_loss: 0.046| r_loss: 0.149| p_loss: 0.225| v_loss: 0.037| per_loss: 0.535 | a_loss: 0.550
Train: Epoch [466/3000], Step [120/158]| g_loss: 0.882| d_loss: 0.591| gp_loss: 0.050| r_loss: 0.148| p_loss: 0.225| v_loss: 0.040| per_loss: 0.534 | a_loss: 0.529
Train: Epoch [466/3000], Step [150/158]| g_loss: 0.929| d_loss: 0.533| gp_loss: 0.049| r_loss: 0.139| p_loss: 0.214| v_loss: 0.038| per_loss: 0.531 | a_loss: 0.591
Train: Epoch [467/3000], Step [30/158]| g_loss: 0.907| d_loss: 0.660| gp_loss: 0.170| r_loss: 0.137| p_loss: 0.218| v_loss: 0.037| per_loss: 0.544 | a_loss: 0.569
Train: Epoch [467/3000], Step [60/158]| g_loss: 0.909| d_loss: 0.553| gp_loss: 0.042| r_loss: 0.147| p_loss: 0.221| v_loss: 0.038| per_loss: 0.537 | a_loss: 0.560
Train: Epoch [467/3000], Step [90/158]| g_loss: 0.852| d_loss: 0.614| gp_loss: 0.046| r_loss: 0.149| p_loss: 0.223| v_loss: 0.039| per_loss: 0.541 | a_loss: 0.498
Train: Epoch [467/3000], Step [120/158]| g_loss: 0.904| d_loss: 0.638| gp_loss: 0.045| r_loss: 0.159| p_loss: 0.240| v_loss: 0.037| per_loss: 0.500 | a_loss: 0.538
Train: Epoch [467/3000], Step [150/158]| g_loss: 0.872| d_loss: 0.622| gp_loss: 0.052| r_loss: 0.142| p_loss: 0.231| v_loss: 0.038| per_loss: 0.546 | a_loss: 0.522
Train: Epoch [468/3000], Step [30/158]| g_loss: 0.893| d_loss: 0.642| gp_loss: 0.117| r_loss: 0.147| p_loss: 0.230| v_loss: 0.039| per_loss: 0.532 | a_loss: 0.539
Train: Epoch [468/3000], Step [60/158]| g_loss: 0.942| d_loss: 0.598| gp_loss: 0.050| r_loss: 0.154| p_loss: 0.233| v_loss: 0.040| per_loss: 0.602 | a_loss: 0.572
Train: Epoch [468/3000], Step [90/158]| g_loss: 0.862| d_loss: 0.574| gp_loss: 0.049| r_loss: 0.158| p_loss: 0.242| v_loss: 0.040| per_loss: 0.506 | a_loss: 0.493
Train: Epoch [468/3000], Step [120/158]| g_loss: 0.902| d_loss: 0.640| gp_loss: 0.051| r_loss: 0.150| p_loss: 0.244| v_loss: 0.038| per_loss: 0.536 | a_loss: 0.538
Train: Epoch [468/3000], Step [150/158]| g_loss: 0.884| d_loss: 0.636| gp_loss: 0.050| r_loss: 0.144| p_loss: 0.226| v_loss: 0.038| per_loss: 0.525 | a_loss: 0.537
Train: Epoch [469/3000], Step [30/158]| g_loss: 0.888| d_loss: 0.741| gp_loss: 0.159| r_loss: 0.157| p_loss: 0.236| v_loss: 0.038| per_loss: 0.532 | a_loss: 0.520
Train: Epoch [469/3000], Step [60/158]| g_loss: 0.888| d_loss: 0.537| gp_loss: 0.045| r_loss: 0.136| p_loss: 0.227| v_loss: 0.039| per_loss: 0.515 | a_loss: 0.548
Train: Epoch [469/3000], Step [90/158]| g_loss: 0.943| d_loss: 0.586| gp_loss: 0.045| r_loss: 0.153| p_loss: 0.224| v_loss: 0.039| per_loss: 0.545 | a_loss: 0.584
Train: Epoch [469/3000], Step [120/158]| g_loss: 0.855| d_loss: 0.621| gp_loss: 0.051| r_loss: 0.148| p_loss: 0.233| v_loss: 0.038| per_loss: 0.509 | a_loss: 0.501
Train: Epoch [469/3000], Step [150/158]| g_loss: 0.850| d_loss: 0.599| gp_loss: 0.047| r_loss: 0.144| p_loss: 0.229| v_loss: 0.039| per_loss: 0.556 | a_loss: 0.498
Train: Epoch [470/3000], Step [30/158]| g_loss: 0.870| d_loss: 0.671| gp_loss: 0.098| r_loss: 0.142| p_loss: 0.211| v_loss: 0.038| per_loss: 0.535 | a_loss: 0.532
Train: Epoch [470/3000], Step [60/158]| g_loss: 0.895| d_loss: 0.528| gp_loss: 0.046| r_loss: 0.140| p_loss: 0.213| v_loss: 0.037| per_loss: 0.481 | a_loss: 0.563
Train: Epoch [470/3000], Step [90/158]| g_loss: 0.871| d_loss: 0.585| gp_loss: 0.046| r_loss: 0.148| p_loss: 0.217| v_loss: 0.039| per_loss: 0.507 | a_loss: 0.524
Train: Epoch [470/3000], Step [120/158]| g_loss: 0.859| d_loss: 0.642| gp_loss: 0.046| r_loss: 0.137| p_loss: 0.213| v_loss: 0.037| per_loss: 0.558 | a_loss: 0.523
Train: Epoch [470/3000], Step [150/158]| g_loss: 0.887| d_loss: 0.602| gp_loss: 0.050| r_loss: 0.146| p_loss: 0.219| v_loss: 0.037| per_loss: 0.502 | a_loss: 0.544
Train: Epoch [471/3000], Step [30/158]| g_loss: 0.865| d_loss: 0.679| gp_loss: 0.169| r_loss: 0.148| p_loss: 0.211| v_loss: 0.039| per_loss: 0.519 | a_loss: 0.520
Train: Epoch [471/3000], Step [60/158]| g_loss: 0.847| d_loss: 0.620| gp_loss: 0.048| r_loss: 0.140| p_loss: 0.205| v_loss: 0.037| per_loss: 0.496 | a_loss: 0.518
Train: Epoch [471/3000], Step [90/158]| g_loss: 0.953| d_loss: 0.497| gp_loss: 0.047| r_loss: 0.133| p_loss: 0.201| v_loss: 0.037| per_loss: 0.531 | a_loss: 0.630
Train: Epoch [471/3000], Step [120/158]| g_loss: 0.861| d_loss: 0.599| gp_loss: 0.047| r_loss: 0.143| p_loss: 0.207| v_loss: 0.038| per_loss: 0.519 | a_loss: 0.524
Train: Epoch [471/3000], Step [150/158]| g_loss: 0.806| d_loss: 0.663| gp_loss: 0.050| r_loss: 0.146| p_loss: 0.213| v_loss: 0.037| per_loss: 0.481 | a_loss: 0.469
Train: Epoch [472/3000], Step [30/158]| g_loss: 0.808| d_loss: 0.791| gp_loss: 0.132| r_loss: 0.134| p_loss: 0.204| v_loss: 0.037| per_loss: 0.504 | a_loss: 0.485
Train: Epoch [472/3000], Step [60/158]| g_loss: 0.896| d_loss: 0.584| gp_loss: 0.045| r_loss: 0.134| p_loss: 0.210| v_loss: 0.037| per_loss: 0.518 | a_loss: 0.568
Train: Epoch [472/3000], Step [90/158]| g_loss: 0.848| d_loss: 0.628| gp_loss: 0.043| r_loss: 0.146| p_loss: 0.227| v_loss: 0.038| per_loss: 0.521 | a_loss: 0.498
Train: Epoch [472/3000], Step [120/158]| g_loss: 0.948| d_loss: 0.515| gp_loss: 0.040| r_loss: 0.146| p_loss: 0.216| v_loss: 0.038| per_loss: 0.537 | a_loss: 0.602
Train: Epoch [472/3000], Step [150/158]| g_loss: 0.867| d_loss: 0.658| gp_loss: 0.046| r_loss: 0.153| p_loss: 0.227| v_loss: 0.038| per_loss: 0.537 | a_loss: 0.508
Train: Epoch [473/3000], Step [30/158]| g_loss: 0.858| d_loss: 0.623| gp_loss: 0.122| r_loss: 0.135| p_loss: 0.210| v_loss: 0.038| per_loss: 0.533 | a_loss: 0.527
Train: Epoch [473/3000], Step [60/158]| g_loss: 0.877| d_loss: 0.628| gp_loss: 0.044| r_loss: 0.149| p_loss: 0.217| v_loss: 0.038| per_loss: 0.534 | a_loss: 0.528
Train: Epoch [473/3000], Step [90/158]| g_loss: 0.891| d_loss: 0.528| gp_loss: 0.045| r_loss: 0.144| p_loss: 0.215| v_loss: 0.038| per_loss: 0.513 | a_loss: 0.551
Train: Epoch [473/3000], Step [120/158]| g_loss: 0.829| d_loss: 0.671| gp_loss: 0.046| r_loss: 0.138| p_loss: 0.212| v_loss: 0.037| per_loss: 0.524 | a_loss: 0.496
Train: Epoch [473/3000], Step [150/158]| g_loss: 0.921| d_loss: 0.571| gp_loss: 0.045| r_loss: 0.148| p_loss: 0.217| v_loss: 0.038| per_loss: 0.524 | a_loss: 0.574
Train: Epoch [474/3000], Step [30/158]| g_loss: 0.825| d_loss: 0.757| gp_loss: 0.175| r_loss: 0.144| p_loss: 0.227| v_loss: 0.037| per_loss: 0.585 | a_loss: 0.472
Train: Epoch [474/3000], Step [60/158]| g_loss: 0.898| d_loss: 0.557| gp_loss: 0.043| r_loss: 0.139| p_loss: 0.209| v_loss: 0.037| per_loss: 0.532 | a_loss: 0.565
Train: Epoch [474/3000], Step [90/158]| g_loss: 0.866| d_loss: 0.583| gp_loss: 0.042| r_loss: 0.146| p_loss: 0.220| v_loss: 0.039| per_loss: 0.543 | a_loss: 0.517
Train: Epoch [474/3000], Step [120/158]| g_loss: 0.926| d_loss: 0.558| gp_loss: 0.046| r_loss: 0.146| p_loss: 0.217| v_loss: 0.037| per_loss: 0.512 | a_loss: 0.584
Train: Epoch [474/3000], Step [150/158]| g_loss: 0.872| d_loss: 0.566| gp_loss: 0.045| r_loss: 0.141| p_loss: 0.216| v_loss: 0.038| per_loss: 0.512 | a_loss: 0.533
Train: Epoch [475/3000], Step [30/158]| g_loss: 0.805| d_loss: 0.776| gp_loss: 0.083| r_loss: 0.138| p_loss: 0.219| v_loss: 0.037| per_loss: 0.539 | a_loss: 0.466
Train: Epoch [475/3000], Step [60/158]| g_loss: 0.922| d_loss: 0.613| gp_loss: 0.043| r_loss: 0.144| p_loss: 0.228| v_loss: 0.037| per_loss: 0.539 | a_loss: 0.573
Train: Epoch [475/3000], Step [90/158]| g_loss: 0.840| d_loss: 0.552| gp_loss: 0.044| r_loss: 0.137| p_loss: 0.221| v_loss: 0.036| per_loss: 0.568 | a_loss: 0.500
Train: Epoch [475/3000], Step [120/158]| g_loss: 0.856| d_loss: 0.622| gp_loss: 0.048| r_loss: 0.143| p_loss: 0.217| v_loss: 0.037| per_loss: 0.508 | a_loss: 0.517
Train: Epoch [475/3000], Step [150/158]| g_loss: 0.850| d_loss: 0.677| gp_loss: 0.049| r_loss: 0.153| p_loss: 0.223| v_loss: 0.038| per_loss: 0.539 | a_loss: 0.494
Train: Epoch [476/3000], Step [30/158]| g_loss: 0.903| d_loss: 0.602| gp_loss: 0.090| r_loss: 0.146| p_loss: 0.219| v_loss: 0.038| per_loss: 0.578 | a_loss: 0.551
Train: Epoch [476/3000], Step [60/158]| g_loss: 0.848| d_loss: 0.680| gp_loss: 0.049| r_loss: 0.133| p_loss: 0.218| v_loss: 0.038| per_loss: 0.548 | a_loss: 0.513
Train: Epoch [476/3000], Step [90/158]| g_loss: 0.819| d_loss: 0.614| gp_loss: 0.050| r_loss: 0.141| p_loss: 0.221| v_loss: 0.038| per_loss: 0.544 | a_loss: 0.476
Train: Epoch [476/3000], Step [120/158]| g_loss: 0.892| d_loss: 0.579| gp_loss: 0.049| r_loss: 0.135| p_loss: 0.220| v_loss: 0.036| per_loss: 0.568 | a_loss: 0.554
Train: Epoch [476/3000], Step [150/158]| g_loss: 0.912| d_loss: 0.569| gp_loss: 0.050| r_loss: 0.149| p_loss: 0.220| v_loss: 0.036| per_loss: 0.556 | a_loss: 0.561
Train: Epoch [477/3000], Step [30/158]| g_loss: 0.907| d_loss: 0.664| gp_loss: 0.154| r_loss: 0.151| p_loss: 0.220| v_loss: 0.038| per_loss: 0.546 | a_loss: 0.554
Train: Epoch [477/3000], Step [60/158]| g_loss: 0.910| d_loss: 0.619| gp_loss: 0.047| r_loss: 0.143| p_loss: 0.226| v_loss: 0.038| per_loss: 0.565 | a_loss: 0.560
Train: Epoch [477/3000], Step [90/158]| g_loss: 0.889| d_loss: 0.605| gp_loss: 0.046| r_loss: 0.140| p_loss: 0.223| v_loss: 0.038| per_loss: 0.565 | a_loss: 0.543
Train: Epoch [477/3000], Step [120/158]| g_loss: 0.879| d_loss: 0.597| gp_loss: 0.048| r_loss: 0.143| p_loss: 0.224| v_loss: 0.037| per_loss: 0.543 | a_loss: 0.532
Train: Epoch [477/3000], Step [150/158]| g_loss: 0.876| d_loss: 0.563| gp_loss: 0.048| r_loss: 0.145| p_loss: 0.234| v_loss: 0.039| per_loss: 0.533 | a_loss: 0.522
Train: Epoch [478/3000], Step [30/158]| g_loss: 0.892| d_loss: 0.670| gp_loss: 0.132| r_loss: 0.145| p_loss: 0.218| v_loss: 0.037| per_loss: 0.550 | a_loss: 0.545
Train: Epoch [478/3000], Step [60/158]| g_loss: 0.860| d_loss: 0.627| gp_loss: 0.047| r_loss: 0.145| p_loss: 0.226| v_loss: 0.038| per_loss: 0.542 | a_loss: 0.511
Train: Epoch [478/3000], Step [90/158]| g_loss: 0.901| d_loss: 0.569| gp_loss: 0.050| r_loss: 0.138| p_loss: 0.236| v_loss: 0.040| per_loss: 0.561 | a_loss: 0.549
Train: Epoch [478/3000], Step [120/158]| g_loss: 0.887| d_loss: 0.591| gp_loss: 0.049| r_loss: 0.139| p_loss: 0.231| v_loss: 0.036| per_loss: 0.561 | a_loss: 0.541
Train: Epoch [478/3000], Step [150/158]| g_loss: 0.932| d_loss: 0.646| gp_loss: 0.048| r_loss: 0.155| p_loss: 0.246| v_loss: 0.037| per_loss: 0.558 | a_loss: 0.562
Train: Epoch [479/3000], Step [30/158]| g_loss: 0.873| d_loss: 0.649| gp_loss: 0.109| r_loss: 0.140| p_loss: 0.229| v_loss: 0.039| per_loss: 0.541 | a_loss: 0.526
Train: Epoch [479/3000], Step [60/158]| g_loss: 0.937| d_loss: 0.520| gp_loss: 0.047| r_loss: 0.135| p_loss: 0.219| v_loss: 0.037| per_loss: 0.550 | a_loss: 0.600
Train: Epoch [479/3000], Step [90/158]| g_loss: 0.878| d_loss: 0.631| gp_loss: 0.050| r_loss: 0.148| p_loss: 0.226| v_loss: 0.039| per_loss: 0.553 | a_loss: 0.523
Train: Epoch [479/3000], Step [120/158]| g_loss: 0.866| d_loss: 0.618| gp_loss: 0.053| r_loss: 0.149| p_loss: 0.223| v_loss: 0.040| per_loss: 0.519 | a_loss: 0.514
Train: Epoch [479/3000], Step [150/158]| g_loss: 0.911| d_loss: 0.555| gp_loss: 0.050| r_loss: 0.153| p_loss: 0.224| v_loss: 0.037| per_loss: 0.549 | a_loss: 0.554
Train: Epoch [480/3000], Step [30/158]| g_loss: 0.905| d_loss: 0.621| gp_loss: 0.115| r_loss: 0.141| p_loss: 0.220| v_loss: 0.038| per_loss: 0.559 | a_loss: 0.560
Train: Epoch [480/3000], Step [60/158]| g_loss: 0.906| d_loss: 0.525| gp_loss: 0.049| r_loss: 0.145| p_loss: 0.230| v_loss: 0.038| per_loss: 0.526 | a_loss: 0.555
Train: Epoch [480/3000], Step [90/158]| g_loss: 0.835| d_loss: 0.710| gp_loss: 0.047| r_loss: 0.144| p_loss: 0.215| v_loss: 0.036| per_loss: 0.537 | a_loss: 0.493
Train: Epoch [480/3000], Step [120/158]| g_loss: 0.929| d_loss: 0.557| gp_loss: 0.043| r_loss: 0.144| p_loss: 0.222| v_loss: 0.035| per_loss: 0.544 | a_loss: 0.584
Train: Epoch [480/3000], Step [150/158]| g_loss: 0.884| d_loss: 0.655| gp_loss: 0.051| r_loss: 0.154| p_loss: 0.233| v_loss: 0.038| per_loss: 0.549 | a_loss: 0.520
Train: Epoch [481/3000], Step [30/158]| g_loss: 0.916| d_loss: 0.648| gp_loss: 0.117| r_loss: 0.148| p_loss: 0.230| v_loss: 0.038| per_loss: 0.559 | a_loss: 0.559
Train: Epoch [481/3000], Step [60/158]| g_loss: 0.859| d_loss: 0.562| gp_loss: 0.051| r_loss: 0.147| p_loss: 0.223| v_loss: 0.039| per_loss: 0.524 | a_loss: 0.509
Train: Epoch [481/3000], Step [90/158]| g_loss: 0.935| d_loss: 0.495| gp_loss: 0.049| r_loss: 0.148| p_loss: 0.226| v_loss: 0.038| per_loss: 0.530 | a_loss: 0.583
Train: Epoch [481/3000], Step [120/158]| g_loss: 0.922| d_loss: 0.582| gp_loss: 0.050| r_loss: 0.137| p_loss: 0.224| v_loss: 0.038| per_loss: 0.548 | a_loss: 0.580
Train: Epoch [481/3000], Step [150/158]| g_loss: 0.837| d_loss: 0.617| gp_loss: 0.053| r_loss: 0.138| p_loss: 0.212| v_loss: 0.036| per_loss: 0.535 | a_loss: 0.504
Train: Epoch [482/3000], Step [30/158]| g_loss: 0.919| d_loss: 0.631| gp_loss: 0.169| r_loss: 0.138| p_loss: 0.216| v_loss: 0.040| per_loss: 0.537 | a_loss: 0.580
Train: Epoch [482/3000], Step [60/158]| g_loss: 0.911| d_loss: 0.584| gp_loss: 0.047| r_loss: 0.137| p_loss: 0.217| v_loss: 0.038| per_loss: 0.533 | a_loss: 0.574
Train: Epoch [482/3000], Step [90/158]| g_loss: 0.843| d_loss: 0.646| gp_loss: 0.048| r_loss: 0.140| p_loss: 0.223| v_loss: 0.037| per_loss: 0.535 | a_loss: 0.501
Train: Epoch [482/3000], Step [120/158]| g_loss: 0.859| d_loss: 0.589| gp_loss: 0.046| r_loss: 0.154| p_loss: 0.222| v_loss: 0.038| per_loss: 0.530 | a_loss: 0.503
Train: Epoch [482/3000], Step [150/158]| g_loss: 0.882| d_loss: 0.593| gp_loss: 0.051| r_loss: 0.142| p_loss: 0.219| v_loss: 0.038| per_loss: 0.533 | a_loss: 0.540
Train: Epoch [483/3000], Step [30/158]| g_loss: 0.850| d_loss: 0.784| gp_loss: 0.189| r_loss: 0.149| p_loss: 0.221| v_loss: 0.037| per_loss: 0.560 | a_loss: 0.497
Train: Epoch [483/3000], Step [60/158]| g_loss: 0.822| d_loss: 0.619| gp_loss: 0.047| r_loss: 0.139| p_loss: 0.214| v_loss: 0.036| per_loss: 0.511 | a_loss: 0.489
Train: Epoch [483/3000], Step [90/158]| g_loss: 0.876| d_loss: 0.657| gp_loss: 0.049| r_loss: 0.154| p_loss: 0.230| v_loss: 0.036| per_loss: 0.514 | a_loss: 0.519
Train: Epoch [483/3000], Step [120/158]| g_loss: 0.851| d_loss: 0.556| gp_loss: 0.050| r_loss: 0.141| p_loss: 0.225| v_loss: 0.038| per_loss: 0.563 | a_loss: 0.504
Train: Epoch [483/3000], Step [150/158]| g_loss: 0.941| d_loss: 0.584| gp_loss: 0.047| r_loss: 0.132| p_loss: 0.219| v_loss: 0.037| per_loss: 0.509 | a_loss: 0.612
Train: Epoch [484/3000], Step [30/158]| g_loss: 0.873| d_loss: 0.674| gp_loss: 0.099| r_loss: 0.143| p_loss: 0.217| v_loss: 0.037| per_loss: 0.544 | a_loss: 0.530
Train: Epoch [484/3000], Step [60/158]| g_loss: 0.850| d_loss: 0.650| gp_loss: 0.050| r_loss: 0.139| p_loss: 0.218| v_loss: 0.036| per_loss: 0.547 | a_loss: 0.510
Train: Epoch [484/3000], Step [90/158]| g_loss: 0.922| d_loss: 0.550| gp_loss: 0.051| r_loss: 0.142| p_loss: 0.224| v_loss: 0.038| per_loss: 0.584 | a_loss: 0.572
Train: Epoch [484/3000], Step [120/158]| g_loss: 0.908| d_loss: 0.546| gp_loss: 0.052| r_loss: 0.140| p_loss: 0.220| v_loss: 0.037| per_loss: 0.535 | a_loss: 0.567
Train: Epoch [484/3000], Step [150/158]| g_loss: 0.906| d_loss: 0.611| gp_loss: 0.052| r_loss: 0.147| p_loss: 0.225| v_loss: 0.037| per_loss: 0.519 | a_loss: 0.558
Train: Epoch [485/3000], Step [30/158]| g_loss: 0.925| d_loss: 0.606| gp_loss: 0.139| r_loss: 0.148| p_loss: 0.226| v_loss: 0.039| per_loss: 0.528 | a_loss: 0.572
Train: Epoch [485/3000], Step [60/158]| g_loss: 0.951| d_loss: 0.527| gp_loss: 0.048| r_loss: 0.147| p_loss: 0.215| v_loss: 0.038| per_loss: 0.545 | a_loss: 0.604
Train: Epoch [485/3000], Step [90/158]| g_loss: 0.877| d_loss: 0.549| gp_loss: 0.046| r_loss: 0.131| p_loss: 0.212| v_loss: 0.036| per_loss: 0.521 | a_loss: 0.551
Train: Epoch [485/3000], Step [120/158]| g_loss: 0.798| d_loss: 0.697| gp_loss: 0.053| r_loss: 0.138| p_loss: 0.212| v_loss: 0.036| per_loss: 0.501 | a_loss: 0.468
Train: Epoch [485/3000], Step [150/158]| g_loss: 0.829| d_loss: 0.646| gp_loss: 0.049| r_loss: 0.142| p_loss: 0.215| v_loss: 0.038| per_loss: 0.525 | a_loss: 0.490
Train: Epoch [486/3000], Step [30/158]| g_loss: 0.865| d_loss: 0.652| gp_loss: 0.099| r_loss: 0.144| p_loss: 0.223| v_loss: 0.038| per_loss: 0.525 | a_loss: 0.519
Train: Epoch [486/3000], Step [60/158]| g_loss: 0.917| d_loss: 0.531| gp_loss: 0.047| r_loss: 0.132| p_loss: 0.208| v_loss: 0.036| per_loss: 0.509 | a_loss: 0.594
Train: Epoch [486/3000], Step [90/158]| g_loss: 0.824| d_loss: 0.672| gp_loss: 0.048| r_loss: 0.139| p_loss: 0.213| v_loss: 0.036| per_loss: 0.500 | a_loss: 0.492
Train: Epoch [486/3000], Step [120/158]| g_loss: 0.889| d_loss: 0.540| gp_loss: 0.049| r_loss: 0.143| p_loss: 0.208| v_loss: 0.037| per_loss: 0.533 | a_loss: 0.551
Train: Epoch [486/3000], Step [150/158]| g_loss: 0.881| d_loss: 0.559| gp_loss: 0.051| r_loss: 0.139| p_loss: 0.214| v_loss: 0.039| per_loss: 0.509 | a_loss: 0.545
Train: Epoch [487/3000], Step [30/158]| g_loss: 0.854| d_loss: 0.697| gp_loss: 0.136| r_loss: 0.137| p_loss: 0.206| v_loss: 0.038| per_loss: 0.532 | a_loss: 0.523
Train: Epoch [487/3000], Step [60/158]| g_loss: 0.834| d_loss: 0.689| gp_loss: 0.047| r_loss: 0.136| p_loss: 0.216| v_loss: 0.036| per_loss: 0.496 | a_loss: 0.505
Train: Epoch [487/3000], Step [90/158]| g_loss: 0.818| d_loss: 0.617| gp_loss: 0.048| r_loss: 0.133| p_loss: 0.202| v_loss: 0.035| per_loss: 0.502 | a_loss: 0.499
Train: Epoch [487/3000], Step [120/158]| g_loss: 0.870| d_loss: 0.524| gp_loss: 0.049| r_loss: 0.137| p_loss: 0.201| v_loss: 0.037| per_loss: 0.534 | a_loss: 0.542
Train: Epoch [487/3000], Step [150/158]| g_loss: 0.903| d_loss: 0.560| gp_loss: 0.048| r_loss: 0.145| p_loss: 0.207| v_loss: 0.037| per_loss: 0.494 | a_loss: 0.568
Train: Epoch [488/3000], Step [30/158]| g_loss: 0.906| d_loss: 0.651| gp_loss: 0.119| r_loss: 0.135| p_loss: 0.202| v_loss: 0.036| per_loss: 0.488 | a_loss: 0.585
Train: Epoch [488/3000], Step [60/158]| g_loss: 0.882| d_loss: 0.549| gp_loss: 0.047| r_loss: 0.146| p_loss: 0.207| v_loss: 0.039| per_loss: 0.483 | a_loss: 0.546
Train: Epoch [488/3000], Step [90/158]| g_loss: 0.854| d_loss: 0.598| gp_loss: 0.049| r_loss: 0.136| p_loss: 0.220| v_loss: 0.038| per_loss: 0.495 | a_loss: 0.521
Train: Epoch [488/3000], Step [120/158]| g_loss: 0.860| d_loss: 0.622| gp_loss: 0.055| r_loss: 0.141| p_loss: 0.211| v_loss: 0.036| per_loss: 0.529 | a_loss: 0.525
Train: Epoch [488/3000], Step [150/158]| g_loss: 0.895| d_loss: 0.617| gp_loss: 0.052| r_loss: 0.138| p_loss: 0.217| v_loss: 0.034| per_loss: 0.518 | a_loss: 0.563
Train: Epoch [489/3000], Step [30/158]| g_loss: 0.855| d_loss: 0.654| gp_loss: 0.142| r_loss: 0.133| p_loss: 0.214| v_loss: 0.036| per_loss: 0.514 | a_loss: 0.527
Train: Epoch [489/3000], Step [60/158]| g_loss: 0.867| d_loss: 0.626| gp_loss: 0.048| r_loss: 0.143| p_loss: 0.218| v_loss: 0.037| per_loss: 0.511 | a_loss: 0.526
Train: Epoch [489/3000], Step [90/158]| g_loss: 0.887| d_loss: 0.596| gp_loss: 0.052| r_loss: 0.142| p_loss: 0.215| v_loss: 0.036| per_loss: 0.544 | a_loss: 0.547
Train: Epoch [489/3000], Step [120/158]| g_loss: 0.870| d_loss: 0.590| gp_loss: 0.048| r_loss: 0.147| p_loss: 0.219| v_loss: 0.037| per_loss: 0.502 | a_loss: 0.527
Train: Epoch [489/3000], Step [150/158]| g_loss: 0.857| d_loss: 0.611| gp_loss: 0.047| r_loss: 0.139| p_loss: 0.206| v_loss: 0.038| per_loss: 0.482 | a_loss: 0.529
Train: Epoch [490/3000], Step [30/158]| g_loss: 0.832| d_loss: 0.792| gp_loss: 0.182| r_loss: 0.135| p_loss: 0.210| v_loss: 0.034| per_loss: 0.493 | a_loss: 0.508
Train: Epoch [490/3000], Step [60/158]| g_loss: 0.823| d_loss: 0.659| gp_loss: 0.042| r_loss: 0.133| p_loss: 0.208| v_loss: 0.035| per_loss: 0.486 | a_loss: 0.502
Train: Epoch [490/3000], Step [90/158]| g_loss: 0.897| d_loss: 0.517| gp_loss: 0.048| r_loss: 0.136| p_loss: 0.208| v_loss: 0.037| per_loss: 0.522 | a_loss: 0.568
Train: Epoch [490/3000], Step [120/158]| g_loss: 0.882| d_loss: 0.498| gp_loss: 0.049| r_loss: 0.143| p_loss: 0.206| v_loss: 0.036| per_loss: 0.481 | a_loss: 0.552
Train: Epoch [490/3000], Step [150/158]| g_loss: 0.940| d_loss: 0.618| gp_loss: 0.047| r_loss: 0.145| p_loss: 0.216| v_loss: 0.036| per_loss: 0.526 | a_loss: 0.598
Train: Epoch [491/3000], Step [30/158]| g_loss: 0.866| d_loss: 0.650| gp_loss: 0.124| r_loss: 0.137| p_loss: 0.211| v_loss: 0.036| per_loss: 0.540 | a_loss: 0.534
Train: Epoch [491/3000], Step [60/158]| g_loss: 0.877| d_loss: 0.547| gp_loss: 0.045| r_loss: 0.141| p_loss: 0.203| v_loss: 0.037| per_loss: 0.481 | a_loss: 0.550
Train: Epoch [491/3000], Step [90/158]| g_loss: 0.862| d_loss: 0.620| gp_loss: 0.048| r_loss: 0.140| p_loss: 0.208| v_loss: 0.035| per_loss: 0.476 | a_loss: 0.535
Train: Epoch [491/3000], Step [120/158]| g_loss: 0.879| d_loss: 0.540| gp_loss: 0.045| r_loss: 0.128| p_loss: 0.206| v_loss: 0.037| per_loss: 0.500 | a_loss: 0.561
Train: Epoch [491/3000], Step [150/158]| g_loss: 0.830| d_loss: 0.680| gp_loss: 0.052| r_loss: 0.144| p_loss: 0.212| v_loss: 0.036| per_loss: 0.516 | a_loss: 0.491
Train: Epoch [492/3000], Step [30/158]| g_loss: 0.870| d_loss: 0.641| gp_loss: 0.151| r_loss: 0.131| p_loss: 0.207| v_loss: 0.039| per_loss: 0.500 | a_loss: 0.547
Train: Epoch [492/3000], Step [60/158]| g_loss: 0.909| d_loss: 0.595| gp_loss: 0.042| r_loss: 0.148| p_loss: 0.218| v_loss: 0.036| per_loss: 0.540 | a_loss: 0.562
Train: Epoch [492/3000], Step [90/158]| g_loss: 0.822| d_loss: 0.656| gp_loss: 0.045| r_loss: 0.141| p_loss: 0.211| v_loss: 0.037| per_loss: 0.507 | a_loss: 0.487
Train: Epoch [492/3000], Step [120/158]| g_loss: 0.860| d_loss: 0.496| gp_loss: 0.044| r_loss: 0.130| p_loss: 0.201| v_loss: 0.034| per_loss: 0.502 | a_loss: 0.545
Train: Epoch [492/3000], Step [150/158]| g_loss: 0.838| d_loss: 0.696| gp_loss: 0.046| r_loss: 0.137| p_loss: 0.206| v_loss: 0.034| per_loss: 0.484 | a_loss: 0.516
Train: Epoch [493/3000], Step [30/158]| g_loss: 0.873| d_loss: 0.657| gp_loss: 0.146| r_loss: 0.137| p_loss: 0.200| v_loss: 0.037| per_loss: 0.503 | a_loss: 0.548
Train: Epoch [493/3000], Step [60/158]| g_loss: 0.821| d_loss: 0.639| gp_loss: 0.044| r_loss: 0.124| p_loss: 0.196| v_loss: 0.035| per_loss: 0.481 | a_loss: 0.515
Train: Epoch [493/3000], Step [90/158]| g_loss: 0.827| d_loss: 0.586| gp_loss: 0.045| r_loss: 0.134| p_loss: 0.203| v_loss: 0.037| per_loss: 0.497 | a_loss: 0.506
Train: Epoch [493/3000], Step [120/158]| g_loss: 0.934| d_loss: 0.551| gp_loss: 0.043| r_loss: 0.146| p_loss: 0.210| v_loss: 0.037| per_loss: 0.516 | a_loss: 0.595
Train: Epoch [493/3000], Step [150/158]| g_loss: 0.836| d_loss: 0.612| gp_loss: 0.048| r_loss: 0.134| p_loss: 0.206| v_loss: 0.035| per_loss: 0.514 | a_loss: 0.513
Train: Epoch [494/3000], Step [30/158]| g_loss: 0.867| d_loss: 0.708| gp_loss: 0.140| r_loss: 0.153| p_loss: 0.211| v_loss: 0.035| per_loss: 0.518 | a_loss: 0.521
Train: Epoch [494/3000], Step [60/158]| g_loss: 0.851| d_loss: 0.578| gp_loss: 0.047| r_loss: 0.132| p_loss: 0.204| v_loss: 0.036| per_loss: 0.516 | a_loss: 0.529
Train: Epoch [494/3000], Step [90/158]| g_loss: 0.867| d_loss: 0.631| gp_loss: 0.042| r_loss: 0.134| p_loss: 0.211| v_loss: 0.037| per_loss: 0.504 | a_loss: 0.541
Train: Epoch [494/3000], Step [120/158]| g_loss: 0.844| d_loss: 0.596| gp_loss: 0.048| r_loss: 0.144| p_loss: 0.216| v_loss: 0.035| per_loss: 0.551 | a_loss: 0.501
Train: Epoch [494/3000], Step [150/158]| g_loss: 0.885| d_loss: 0.589| gp_loss: 0.047| r_loss: 0.135| p_loss: 0.208| v_loss: 0.036| per_loss: 0.488 | a_loss: 0.561
Train: Epoch [495/3000], Step [30/158]| g_loss: 0.851| d_loss: 0.783| gp_loss: 0.174| r_loss: 0.132| p_loss: 0.202| v_loss: 0.036| per_loss: 0.534 | a_loss: 0.528
Train: Epoch [495/3000], Step [60/158]| g_loss: 0.869| d_loss: 0.485| gp_loss: 0.049| r_loss: 0.135| p_loss: 0.204| v_loss: 0.035| per_loss: 0.483 | a_loss: 0.548
Train: Epoch [495/3000], Step [90/158]| g_loss: 0.904| d_loss: 0.565| gp_loss: 0.040| r_loss: 0.136| p_loss: 0.207| v_loss: 0.035| per_loss: 0.502 | a_loss: 0.579
Train: Epoch [495/3000], Step [120/158]| g_loss: 0.878| d_loss: 0.566| gp_loss: 0.048| r_loss: 0.143| p_loss: 0.202| v_loss: 0.036| per_loss: 0.524 | a_loss: 0.546
Train: Epoch [495/3000], Step [150/158]| g_loss: 0.883| d_loss: 0.541| gp_loss: 0.044| r_loss: 0.131| p_loss: 0.197| v_loss: 0.036| per_loss: 0.517 | a_loss: 0.565
Train: Epoch [496/3000], Step [30/158]| g_loss: 0.792| d_loss: 0.832| gp_loss: 0.152| r_loss: 0.144| p_loss: 0.214| v_loss: 0.037| per_loss: 0.498 | a_loss: 0.454
Train: Epoch [496/3000], Step [60/158]| g_loss: 0.841| d_loss: 0.624| gp_loss: 0.043| r_loss: 0.133| p_loss: 0.207| v_loss: 0.036| per_loss: 0.512 | a_loss: 0.518
Train: Epoch [496/3000], Step [90/158]| g_loss: 0.819| d_loss: 0.579| gp_loss: 0.043| r_loss: 0.141| p_loss: 0.206| v_loss: 0.036| per_loss: 0.487 | a_loss: 0.490
Train: Epoch [496/3000], Step [120/158]| g_loss: 0.891| d_loss: 0.525| gp_loss: 0.044| r_loss: 0.129| p_loss: 0.199| v_loss: 0.035| per_loss: 0.510 | a_loss: 0.578
Train: Epoch [496/3000], Step [150/158]| g_loss: 0.891| d_loss: 0.535| gp_loss: 0.045| r_loss: 0.132| p_loss: 0.203| v_loss: 0.036| per_loss: 0.493 | a_loss: 0.572
Train: Epoch [497/3000], Step [30/158]| g_loss: 0.815| d_loss: 0.683| gp_loss: 0.091| r_loss: 0.130| p_loss: 0.197| v_loss: 0.034| per_loss: 0.523 | a_loss: 0.500
Train: Epoch [497/3000], Step [60/158]| g_loss: 0.858| d_loss: 0.605| gp_loss: 0.045| r_loss: 0.140| p_loss: 0.215| v_loss: 0.037| per_loss: 0.483 | a_loss: 0.524
Train: Epoch [497/3000], Step [90/158]| g_loss: 0.830| d_loss: 0.637| gp_loss: 0.048| r_loss: 0.136| p_loss: 0.203| v_loss: 0.037| per_loss: 0.467 | a_loss: 0.509
Train: Epoch [497/3000], Step [120/158]| g_loss: 0.861| d_loss: 0.546| gp_loss: 0.048| r_loss: 0.138| p_loss: 0.205| v_loss: 0.036| per_loss: 0.536 | a_loss: 0.531
Train: Epoch [497/3000], Step [150/158]| g_loss: 0.873| d_loss: 0.597| gp_loss: 0.053| r_loss: 0.127| p_loss: 0.201| v_loss: 0.034| per_loss: 0.523 | a_loss: 0.560
Train: Epoch [498/3000], Step [30/158]| g_loss: 0.934| d_loss: 0.666| gp_loss: 0.136| r_loss: 0.158| p_loss: 0.216| v_loss: 0.038| per_loss: 0.509 | a_loss: 0.579
Train: Epoch [498/3000], Step [60/158]| g_loss: 0.909| d_loss: 0.611| gp_loss: 0.046| r_loss: 0.145| p_loss: 0.218| v_loss: 0.039| per_loss: 0.517 | a_loss: 0.564
Train: Epoch [498/3000], Step [90/158]| g_loss: 0.805| d_loss: 0.624| gp_loss: 0.045| r_loss: 0.138| p_loss: 0.211| v_loss: 0.035| per_loss: 0.508 | a_loss: 0.476
Train: Epoch [498/3000], Step [120/158]| g_loss: 0.880| d_loss: 0.525| gp_loss: 0.046| r_loss: 0.131| p_loss: 0.203| v_loss: 0.035| per_loss: 0.527 | a_loss: 0.560
Train: Epoch [498/3000], Step [150/158]| g_loss: 0.858| d_loss: 0.548| gp_loss: 0.050| r_loss: 0.134| p_loss: 0.199| v_loss: 0.036| per_loss: 0.524 | a_loss: 0.537
Train: Epoch [499/3000], Step [30/158]| g_loss: 0.934| d_loss: 0.635| gp_loss: 0.124| r_loss: 0.133| p_loss: 0.203| v_loss: 0.037| per_loss: 0.533 | a_loss: 0.609
Train: Epoch [499/3000], Step [60/158]| g_loss: 0.778| d_loss: 0.670| gp_loss: 0.047| r_loss: 0.130| p_loss: 0.204| v_loss: 0.033| per_loss: 0.535 | a_loss: 0.460
Train: Epoch [499/3000], Step [90/158]| g_loss: 0.847| d_loss: 0.619| gp_loss: 0.044| r_loss: 0.133| p_loss: 0.206| v_loss: 0.036| per_loss: 0.512 | a_loss: 0.524
Train: Epoch [499/3000], Step [120/158]| g_loss: 0.851| d_loss: 0.548| gp_loss: 0.051| r_loss: 0.139| p_loss: 0.202| v_loss: 0.036| per_loss: 0.523 | a_loss: 0.523
Train: Epoch [499/3000], Step [150/158]| g_loss: 0.859| d_loss: 0.617| gp_loss: 0.049| r_loss: 0.136| p_loss: 0.210| v_loss: 0.035| per_loss: 0.486 | a_loss: 0.534
Train: Epoch [500/3000], Step [30/158]| g_loss: 0.938| d_loss: 0.614| gp_loss: 0.146| r_loss: 0.146| p_loss: 0.214| v_loss: 0.037| per_loss: 0.506 | a_loss: 0.597
Train: Epoch [500/3000], Step [60/158]| g_loss: 0.879| d_loss: 0.562| gp_loss: 0.046| r_loss: 0.134| p_loss: 0.203| v_loss: 0.034| per_loss: 0.477 | a_loss: 0.561
Train: Epoch [500/3000], Step [90/158]| g_loss: 0.839| d_loss: 0.655| gp_loss: 0.047| r_loss: 0.139| p_loss: 0.201| v_loss: 0.035| per_loss: 0.568 | a_loss: 0.508
Train: Epoch [500/3000], Step [120/158]| g_loss: 0.828| d_loss: 0.587| gp_loss: 0.048| r_loss: 0.133| p_loss: 0.203| v_loss: 0.037| per_loss: 0.526 | a_loss: 0.504
Train: Epoch [500/3000], Step [150/158]| g_loss: 0.822| d_loss: 0.645| gp_loss: 0.046| r_loss: 0.134| p_loss: 0.209| v_loss: 0.034| per_loss: 0.495 | a_loss: 0.499
Test: Epoch [500/3000]| g_loss: 0.739| r_loss: 0.474| p_loss: 0.323| v_loss: 0.026
Train: Epoch [501/3000], Step [30/158]| g_loss: 0.931| d_loss: 0.519| gp_loss: 0.043| r_loss: 0.146| p_loss: 0.212| v_loss: 0.035| per_loss: 0.528 | a_loss: 0.592
Train: Epoch [501/3000], Step [60/158]| g_loss: 0.876| d_loss: 0.569| gp_loss: 0.044| r_loss: 0.134| p_loss: 0.207| v_loss: 0.035| per_loss: 0.490 | a_loss: 0.554
Train: Epoch [501/3000], Step [90/158]| g_loss: 0.824| d_loss: 0.611| gp_loss: 0.050| r_loss: 0.134| p_loss: 0.210| v_loss: 0.036| per_loss: 0.487 | a_loss: 0.501
Train: Epoch [501/3000], Step [120/158]| g_loss: 0.858| d_loss: 0.632| gp_loss: 0.049| r_loss: 0.132| p_loss: 0.208| v_loss: 0.035| per_loss: 0.531 | a_loss: 0.533
Train: Epoch [501/3000], Step [150/158]| g_loss: 0.864| d_loss: 0.644| gp_loss: 0.049| r_loss: 0.136| p_loss: 0.213| v_loss: 0.035| per_loss: 0.511 | a_loss: 0.535
Train: Epoch [502/3000], Step [30/158]| g_loss: 0.858| d_loss: 0.686| gp_loss: 0.125| r_loss: 0.128| p_loss: 0.212| v_loss: 0.035| per_loss: 0.502 | a_loss: 0.539
Train: Epoch [502/3000], Step [60/158]| g_loss: 0.778| d_loss: 0.683| gp_loss: 0.050| r_loss: 0.132| p_loss: 0.208| v_loss: 0.035| per_loss: 0.511 | a_loss: 0.456
Train: Epoch [502/3000], Step [90/158]| g_loss: 0.820| d_loss: 0.638| gp_loss: 0.046| r_loss: 0.141| p_loss: 0.211| v_loss: 0.036| per_loss: 0.509 | a_loss: 0.487
Train: Epoch [502/3000], Step [120/158]| g_loss: 0.897| d_loss: 0.509| gp_loss: 0.048| r_loss: 0.140| p_loss: 0.211| v_loss: 0.038| per_loss: 0.490 | a_loss: 0.564
Train: Epoch [502/3000], Step [150/158]| g_loss: 0.881| d_loss: 0.522| gp_loss: 0.047| r_loss: 0.135| p_loss: 0.206| v_loss: 0.036| per_loss: 0.492 | a_loss: 0.557
Train: Epoch [503/3000], Step [30/158]| g_loss: 0.876| d_loss: 0.610| gp_loss: 0.110| r_loss: 0.134| p_loss: 0.204| v_loss: 0.035| per_loss: 0.498 | a_loss: 0.555
Train: Epoch [503/3000], Step [60/158]| g_loss: 0.903| d_loss: 0.627| gp_loss: 0.049| r_loss: 0.138| p_loss: 0.206| v_loss: 0.037| per_loss: 0.504 | a_loss: 0.575
Train: Epoch [503/3000], Step [90/158]| g_loss: 0.841| d_loss: 0.537| gp_loss: 0.048| r_loss: 0.134| p_loss: 0.199| v_loss: 0.036| per_loss: 0.490 | a_loss: 0.522
Train: Epoch [503/3000], Step [120/158]| g_loss: 0.883| d_loss: 0.656| gp_loss: 0.047| r_loss: 0.131| p_loss: 0.208| v_loss: 0.036| per_loss: 0.471 | a_loss: 0.565
Train: Epoch [503/3000], Step [150/158]| g_loss: 0.732| d_loss: 0.664| gp_loss: 0.054| r_loss: 0.132| p_loss: 0.199| v_loss: 0.035| per_loss: 0.485 | a_loss: 0.417
Train: Epoch [504/3000], Step [30/158]| g_loss: 0.927| d_loss: 0.642| gp_loss: 0.159| r_loss: 0.136| p_loss: 0.204| v_loss: 0.036| per_loss: 0.479 | a_loss: 0.605
Train: Epoch [504/3000], Step [60/158]| g_loss: 0.806| d_loss: 0.646| gp_loss: 0.051| r_loss: 0.136| p_loss: 0.206| v_loss: 0.037| per_loss: 0.506 | a_loss: 0.480
Train: Epoch [504/3000], Step [90/158]| g_loss: 0.874| d_loss: 0.559| gp_loss: 0.048| r_loss: 0.132| p_loss: 0.206| v_loss: 0.036| per_loss: 0.498 | a_loss: 0.553
Train: Epoch [504/3000], Step [120/158]| g_loss: 0.888| d_loss: 0.551| gp_loss: 0.047| r_loss: 0.130| p_loss: 0.202| v_loss: 0.035| per_loss: 0.516 | a_loss: 0.570
Train: Epoch [504/3000], Step [150/158]| g_loss: 0.827| d_loss: 0.672| gp_loss: 0.048| r_loss: 0.139| p_loss: 0.214| v_loss: 0.035| per_loss: 0.482 | a_loss: 0.498
Train: Epoch [505/3000], Step [30/158]| g_loss: 0.847| d_loss: 0.639| gp_loss: 0.120| r_loss: 0.139| p_loss: 0.205| v_loss: 0.035| per_loss: 0.475 | a_loss: 0.523
Train: Epoch [505/3000], Step [60/158]| g_loss: 0.841| d_loss: 0.658| gp_loss: 0.050| r_loss: 0.132| p_loss: 0.205| v_loss: 0.035| per_loss: 0.485 | a_loss: 0.523
Train: Epoch [505/3000], Step [90/158]| g_loss: 0.894| d_loss: 0.543| gp_loss: 0.048| r_loss: 0.132| p_loss: 0.215| v_loss: 0.036| per_loss: 0.533 | a_loss: 0.564
Train: Epoch [505/3000], Step [120/158]| g_loss: 0.856| d_loss: 0.606| gp_loss: 0.048| r_loss: 0.134| p_loss: 0.219| v_loss: 0.037| per_loss: 0.523 | a_loss: 0.523
Train: Epoch [505/3000], Step [150/158]| g_loss: 0.848| d_loss: 0.642| gp_loss: 0.053| r_loss: 0.144| p_loss: 0.217| v_loss: 0.037| per_loss: 0.506 | a_loss: 0.508
Train: Epoch [506/3000], Step [30/158]| g_loss: 0.862| d_loss: 0.662| gp_loss: 0.105| r_loss: 0.135| p_loss: 0.208| v_loss: 0.034| per_loss: 0.496 | a_loss: 0.539
Train: Epoch [506/3000], Step [60/158]| g_loss: 0.809| d_loss: 0.640| gp_loss: 0.052| r_loss: 0.136| p_loss: 0.207| v_loss: 0.035| per_loss: 0.500 | a_loss: 0.485
Train: Epoch [506/3000], Step [90/158]| g_loss: 0.889| d_loss: 0.561| gp_loss: 0.051| r_loss: 0.148| p_loss: 0.217| v_loss: 0.037| per_loss: 0.535 | a_loss: 0.543
Train: Epoch [506/3000], Step [120/158]| g_loss: 0.863| d_loss: 0.581| gp_loss: 0.047| r_loss: 0.137| p_loss: 0.216| v_loss: 0.036| per_loss: 0.498 | a_loss: 0.532
Train: Epoch [506/3000], Step [150/158]| g_loss: 0.898| d_loss: 0.601| gp_loss: 0.050| r_loss: 0.134| p_loss: 0.216| v_loss: 0.036| per_loss: 0.490 | a_loss: 0.571
Train: Epoch [507/3000], Step [30/158]| g_loss: 0.884| d_loss: 0.618| gp_loss: 0.129| r_loss: 0.125| p_loss: 0.201| v_loss: 0.036| per_loss: 0.532 | a_loss: 0.570
Train: Epoch [507/3000], Step [60/158]| g_loss: 0.873| d_loss: 0.541| gp_loss: 0.049| r_loss: 0.141| p_loss: 0.196| v_loss: 0.034| per_loss: 0.513 | a_loss: 0.548
Train: Epoch [507/3000], Step [90/158]| g_loss: 0.910| d_loss: 0.638| gp_loss: 0.048| r_loss: 0.155| p_loss: 0.268| v_loss: 0.038| per_loss: 0.496 | a_loss: 0.534
Train: Epoch [507/3000], Step [120/158]| g_loss: 1.132| d_loss: 0.620| gp_loss: 0.048| r_loss: 0.271| p_loss: 0.406| v_loss: 0.036| per_loss: 0.589 | a_loss: 0.563
Train: Epoch [507/3000], Step [150/158]| g_loss: 0.903| d_loss: 0.580| gp_loss: 0.046| r_loss: 0.156| p_loss: 0.265| v_loss: 0.037| per_loss: 0.549 | a_loss: 0.522
Train: Epoch [508/3000], Step [30/158]| g_loss: 0.864| d_loss: 0.722| gp_loss: 0.106| r_loss: 0.140| p_loss: 0.226| v_loss: 0.037| per_loss: 0.532 | a_loss: 0.522
Train: Epoch [508/3000], Step [60/158]| g_loss: 0.844| d_loss: 0.580| gp_loss: 0.046| r_loss: 0.137| p_loss: 0.215| v_loss: 0.037| per_loss: 0.524 | a_loss: 0.509
Train: Epoch [508/3000], Step [90/158]| g_loss: 0.873| d_loss: 0.556| gp_loss: 0.050| r_loss: 0.142| p_loss: 0.214| v_loss: 0.035| per_loss: 0.504 | a_loss: 0.539
Train: Epoch [508/3000], Step [120/158]| g_loss: 0.934| d_loss: 0.547| gp_loss: 0.049| r_loss: 0.141| p_loss: 0.212| v_loss: 0.037| per_loss: 0.526 | a_loss: 0.596
Train: Epoch [508/3000], Step [150/158]| g_loss: 0.889| d_loss: 0.607| gp_loss: 0.045| r_loss: 0.146| p_loss: 0.229| v_loss: 0.036| per_loss: 0.538 | a_loss: 0.539
Train: Epoch [509/3000], Step [30/158]| g_loss: 0.822| d_loss: 0.679| gp_loss: 0.077| r_loss: 0.134| p_loss: 0.208| v_loss: 0.037| per_loss: 0.504 | a_loss: 0.497
Train: Epoch [509/3000], Step [60/158]| g_loss: 0.926| d_loss: 0.516| gp_loss: 0.047| r_loss: 0.139| p_loss: 0.212| v_loss: 0.036| per_loss: 0.533 | a_loss: 0.592
Train: Epoch [509/3000], Step [90/158]| g_loss: 0.855| d_loss: 0.615| gp_loss: 0.052| r_loss: 0.135| p_loss: 0.203| v_loss: 0.036| per_loss: 0.483 | a_loss: 0.534
Train: Epoch [509/3000], Step [120/158]| g_loss: 0.830| d_loss: 0.654| gp_loss: 0.053| r_loss: 0.138| p_loss: 0.210| v_loss: 0.034| per_loss: 0.529 | a_loss: 0.500
Train: Epoch [509/3000], Step [150/158]| g_loss: 0.895| d_loss: 0.534| gp_loss: 0.052| r_loss: 0.134| p_loss: 0.208| v_loss: 0.036| per_loss: 0.526 | a_loss: 0.568
Train: Epoch [510/3000], Step [30/158]| g_loss: 0.885| d_loss: 0.638| gp_loss: 0.155| r_loss: 0.136| p_loss: 0.203| v_loss: 0.036| per_loss: 0.516 | a_loss: 0.561
Train: Epoch [510/3000], Step [60/158]| g_loss: 0.861| d_loss: 0.589| gp_loss: 0.049| r_loss: 0.136| p_loss: 0.200| v_loss: 0.037| per_loss: 0.525 | a_loss: 0.536
Train: Epoch [510/3000], Step [90/158]| g_loss: 0.812| d_loss: 0.690| gp_loss: 0.050| r_loss: 0.134| p_loss: 0.206| v_loss: 0.036| per_loss: 0.477 | a_loss: 0.490
Train: Epoch [510/3000], Step [120/158]| g_loss: 0.875| d_loss: 0.579| gp_loss: 0.050| r_loss: 0.135| p_loss: 0.208| v_loss: 0.037| per_loss: 0.523 | a_loss: 0.547
Train: Epoch [510/3000], Step [150/158]| g_loss: 0.887| d_loss: 0.564| gp_loss: 0.047| r_loss: 0.132| p_loss: 0.209| v_loss: 0.036| per_loss: 0.528 | a_loss: 0.562
Train: Epoch [511/3000], Step [30/158]| g_loss: 0.859| d_loss: 0.663| gp_loss: 0.154| r_loss: 0.133| p_loss: 0.206| v_loss: 0.036| per_loss: 0.520 | a_loss: 0.534
Train: Epoch [511/3000], Step [60/158]| g_loss: 0.819| d_loss: 0.623| gp_loss: 0.050| r_loss: 0.138| p_loss: 0.199| v_loss: 0.034| per_loss: 0.487 | a_loss: 0.499
Train: Epoch [511/3000], Step [90/158]| g_loss: 0.880| d_loss: 0.594| gp_loss: 0.049| r_loss: 0.137| p_loss: 0.206| v_loss: 0.037| per_loss: 0.509 | a_loss: 0.552
Train: Epoch [511/3000], Step [120/158]| g_loss: 0.816| d_loss: 0.610| gp_loss: 0.049| r_loss: 0.127| p_loss: 0.197| v_loss: 0.035| per_loss: 0.517 | a_loss: 0.505
Train: Epoch [511/3000], Step [150/158]| g_loss: 0.877| d_loss: 0.562| gp_loss: 0.050| r_loss: 0.136| p_loss: 0.211| v_loss: 0.037| per_loss: 0.511 | a_loss: 0.548
Train: Epoch [512/3000], Step [30/158]| g_loss: 0.866| d_loss: 0.719| gp_loss: 0.185| r_loss: 0.130| p_loss: 0.201| v_loss: 0.036| per_loss: 0.484 | a_loss: 0.551
Train: Epoch [512/3000], Step [60/158]| g_loss: 0.880| d_loss: 0.555| gp_loss: 0.048| r_loss: 0.130| p_loss: 0.214| v_loss: 0.035| per_loss: 0.511 | a_loss: 0.557
Train: Epoch [512/3000], Step [90/158]| g_loss: 0.815| d_loss: 0.627| gp_loss: 0.050| r_loss: 0.130| p_loss: 0.207| v_loss: 0.037| per_loss: 0.539 | a_loss: 0.491
Train: Epoch [512/3000], Step [120/158]| g_loss: 0.917| d_loss: 0.570| gp_loss: 0.048| r_loss: 0.136| p_loss: 0.216| v_loss: 0.036| per_loss: 0.506 | a_loss: 0.587
Train: Epoch [512/3000], Step [150/158]| g_loss: 0.890| d_loss: 0.585| gp_loss: 0.052| r_loss: 0.140| p_loss: 0.212| v_loss: 0.037| per_loss: 0.515 | a_loss: 0.554
Train: Epoch [513/3000], Step [30/158]| g_loss: 0.867| d_loss: 0.661| gp_loss: 0.133| r_loss: 0.132| p_loss: 0.212| v_loss: 0.036| per_loss: 0.499 | a_loss: 0.542
Train: Epoch [513/3000], Step [60/158]| g_loss: 0.862| d_loss: 0.582| gp_loss: 0.045| r_loss: 0.139| p_loss: 0.214| v_loss: 0.037| per_loss: 0.511 | a_loss: 0.528
Train: Epoch [513/3000], Step [90/158]| g_loss: 0.844| d_loss: 0.621| gp_loss: 0.049| r_loss: 0.137| p_loss: 0.219| v_loss: 0.037| per_loss: 0.559 | a_loss: 0.504
Train: Epoch [513/3000], Step [120/158]| g_loss: 0.859| d_loss: 0.598| gp_loss: 0.047| r_loss: 0.127| p_loss: 0.212| v_loss: 0.037| per_loss: 0.532 | a_loss: 0.536
Train: Epoch [513/3000], Step [150/158]| g_loss: 0.844| d_loss: 0.662| gp_loss: 0.053| r_loss: 0.142| p_loss: 0.216| v_loss: 0.035| per_loss: 0.522 | a_loss: 0.507
Train: Epoch [514/3000], Step [30/158]| g_loss: 0.896| d_loss: 0.705| gp_loss: 0.139| r_loss: 0.155| p_loss: 0.230| v_loss: 0.039| per_loss: 0.518 | a_loss: 0.536
Train: Epoch [514/3000], Step [60/158]| g_loss: 0.847| d_loss: 0.654| gp_loss: 0.048| r_loss: 0.139| p_loss: 0.217| v_loss: 0.036| per_loss: 0.574 | a_loss: 0.505
Train: Epoch [514/3000], Step [90/158]| g_loss: 0.810| d_loss: 0.617| gp_loss: 0.049| r_loss: 0.125| p_loss: 0.201| v_loss: 0.035| per_loss: 0.516 | a_loss: 0.498
Train: Epoch [514/3000], Step [120/158]| g_loss: 0.873| d_loss: 0.563| gp_loss: 0.048| r_loss: 0.140| p_loss: 0.213| v_loss: 0.035| per_loss: 0.523 | a_loss: 0.539
Train: Epoch [514/3000], Step [150/158]| g_loss: 0.904| d_loss: 0.559| gp_loss: 0.049| r_loss: 0.125| p_loss: 0.198| v_loss: 0.035| per_loss: 0.540 | a_loss: 0.591
Train: Epoch [515/3000], Step [30/158]| g_loss: 0.908| d_loss: 0.670| gp_loss: 0.136| r_loss: 0.133| p_loss: 0.216| v_loss: 0.038| per_loss: 0.536 | a_loss: 0.576
Train: Epoch [515/3000], Step [60/158]| g_loss: 0.819| d_loss: 0.567| gp_loss: 0.048| r_loss: 0.132| p_loss: 0.203| v_loss: 0.037| per_loss: 0.543 | a_loss: 0.493
Train: Epoch [515/3000], Step [90/158]| g_loss: 0.863| d_loss: 0.553| gp_loss: 0.047| r_loss: 0.126| p_loss: 0.202| v_loss: 0.037| per_loss: 0.550 | a_loss: 0.544
Train: Epoch [515/3000], Step [120/158]| g_loss: 0.856| d_loss: 0.631| gp_loss: 0.052| r_loss: 0.136| p_loss: 0.207| v_loss: 0.036| per_loss: 0.520 | a_loss: 0.528
Train: Epoch [515/3000], Step [150/158]| g_loss: 0.903| d_loss: 0.566| gp_loss: 0.052| r_loss: 0.143| p_loss: 0.206| v_loss: 0.037| per_loss: 0.556 | a_loss: 0.565
Train: Epoch [516/3000], Step [30/158]| g_loss: 0.814| d_loss: 0.766| gp_loss: 0.135| r_loss: 0.133| p_loss: 0.205| v_loss: 0.034| per_loss: 0.531 | a_loss: 0.491
Train: Epoch [516/3000], Step [60/158]| g_loss: 0.742| d_loss: 0.745| gp_loss: 0.047| r_loss: 0.133| p_loss: 0.210| v_loss: 0.036| per_loss: 0.516 | a_loss: 0.416
Train: Epoch [516/3000], Step [90/158]| g_loss: 0.892| d_loss: 0.532| gp_loss: 0.051| r_loss: 0.133| p_loss: 0.201| v_loss: 0.037| per_loss: 0.504 | a_loss: 0.570
Train: Epoch [516/3000], Step [120/158]| g_loss: 0.934| d_loss: 0.503| gp_loss: 0.051| r_loss: 0.130| p_loss: 0.200| v_loss: 0.037| per_loss: 0.545 | a_loss: 0.613
Train: Epoch [516/3000], Step [150/158]| g_loss: 0.915| d_loss: 0.516| gp_loss: 0.050| r_loss: 0.133| p_loss: 0.206| v_loss: 0.037| per_loss: 0.516 | a_loss: 0.590
Train: Epoch [517/3000], Step [30/158]| g_loss: 0.865| d_loss: 0.760| gp_loss: 0.169| r_loss: 0.135| p_loss: 0.219| v_loss: 0.035| per_loss: 0.503 | a_loss: 0.534
Train: Epoch [517/3000], Step [60/158]| g_loss: 0.841| d_loss: 0.598| gp_loss: 0.047| r_loss: 0.135| p_loss: 0.201| v_loss: 0.038| per_loss: 0.502 | a_loss: 0.518
Train: Epoch [517/3000], Step [90/158]| g_loss: 0.865| d_loss: 0.599| gp_loss: 0.045| r_loss: 0.137| p_loss: 0.203| v_loss: 0.037| per_loss: 0.525 | a_loss: 0.537
Train: Epoch [517/3000], Step [120/158]| g_loss: 0.846| d_loss: 0.607| gp_loss: 0.047| r_loss: 0.135| p_loss: 0.204| v_loss: 0.035| per_loss: 0.500 | a_loss: 0.524
Train: Epoch [517/3000], Step [150/158]| g_loss: 0.878| d_loss: 0.541| gp_loss: 0.050| r_loss: 0.128| p_loss: 0.197| v_loss: 0.035| per_loss: 0.503 | a_loss: 0.567
Train: Epoch [518/3000], Step [30/158]| g_loss: 0.872| d_loss: 0.682| gp_loss: 0.161| r_loss: 0.134| p_loss: 0.195| v_loss: 0.036| per_loss: 0.502 | a_loss: 0.554
Train: Epoch [518/3000], Step [60/158]| g_loss: 0.856| d_loss: 0.618| gp_loss: 0.045| r_loss: 0.146| p_loss: 0.206| v_loss: 0.038| per_loss: 0.512 | a_loss: 0.519
Train: Epoch [518/3000], Step [90/158]| g_loss: 0.856| d_loss: 0.522| gp_loss: 0.045| r_loss: 0.125| p_loss: 0.196| v_loss: 0.037| per_loss: 0.495 | a_loss: 0.547
Train: Epoch [518/3000], Step [120/158]| g_loss: 0.846| d_loss: 0.638| gp_loss: 0.047| r_loss: 0.122| p_loss: 0.194| v_loss: 0.036| per_loss: 0.518 | a_loss: 0.539
Train: Epoch [518/3000], Step [150/158]| g_loss: 0.805| d_loss: 0.625| gp_loss: 0.047| r_loss: 0.124| p_loss: 0.196| v_loss: 0.036| per_loss: 0.532 | a_loss: 0.493
Train: Epoch [519/3000], Step [30/158]| g_loss: 0.911| d_loss: 0.615| gp_loss: 0.105| r_loss: 0.132| p_loss: 0.203| v_loss: 0.037| per_loss: 0.501 | a_loss: 0.590
Train: Epoch [519/3000], Step [60/158]| g_loss: 0.818| d_loss: 0.651| gp_loss: 0.045| r_loss: 0.133| p_loss: 0.196| v_loss: 0.034| per_loss: 0.529 | a_loss: 0.500
Train: Epoch [519/3000], Step [90/158]| g_loss: 0.833| d_loss: 0.563| gp_loss: 0.046| r_loss: 0.130| p_loss: 0.199| v_loss: 0.037| per_loss: 0.519 | a_loss: 0.516
Train: Epoch [519/3000], Step [120/158]| g_loss: 0.893| d_loss: 0.566| gp_loss: 0.046| r_loss: 0.134| p_loss: 0.199| v_loss: 0.036| per_loss: 0.502 | a_loss: 0.573
Train: Epoch [519/3000], Step [150/158]| g_loss: 0.862| d_loss: 0.615| gp_loss: 0.047| r_loss: 0.130| p_loss: 0.204| v_loss: 0.036| per_loss: 0.532 | a_loss: 0.542
Train: Epoch [520/3000], Step [30/158]| g_loss: 0.875| d_loss: 0.614| gp_loss: 0.097| r_loss: 0.141| p_loss: 0.212| v_loss: 0.038| per_loss: 0.540 | a_loss: 0.535
Train: Epoch [520/3000], Step [60/158]| g_loss: 0.827| d_loss: 0.617| gp_loss: 0.048| r_loss: 0.132| p_loss: 0.199| v_loss: 0.036| per_loss: 0.553 | a_loss: 0.504
Train: Epoch [520/3000], Step [90/158]| g_loss: 0.883| d_loss: 0.609| gp_loss: 0.048| r_loss: 0.136| p_loss: 0.207| v_loss: 0.036| per_loss: 0.533 | a_loss: 0.554
Train: Epoch [520/3000], Step [120/158]| g_loss: 0.883| d_loss: 0.532| gp_loss: 0.049| r_loss: 0.126| p_loss: 0.200| v_loss: 0.037| per_loss: 0.531 | a_loss: 0.568
Train: Epoch [520/3000], Step [150/158]| g_loss: 0.859| d_loss: 0.526| gp_loss: 0.046| r_loss: 0.126| p_loss: 0.199| v_loss: 0.035| per_loss: 0.481 | a_loss: 0.551
Train: Epoch [521/3000], Step [30/158]| g_loss: 0.856| d_loss: 0.734| gp_loss: 0.151| r_loss: 0.132| p_loss: 0.204| v_loss: 0.034| per_loss: 0.519 | a_loss: 0.536
Train: Epoch [521/3000], Step [60/158]| g_loss: 0.814| d_loss: 0.530| gp_loss: 0.049| r_loss: 0.124| p_loss: 0.195| v_loss: 0.037| per_loss: 0.502 | a_loss: 0.505
Train: Epoch [521/3000], Step [90/158]| g_loss: 0.923| d_loss: 0.569| gp_loss: 0.045| r_loss: 0.130| p_loss: 0.195| v_loss: 0.035| per_loss: 0.500 | a_loss: 0.611
Train: Epoch [521/3000], Step [120/158]| g_loss: 0.816| d_loss: 0.653| gp_loss: 0.047| r_loss: 0.139| p_loss: 0.206| v_loss: 0.036| per_loss: 0.522 | a_loss: 0.487
Train: Epoch [521/3000], Step [150/158]| g_loss: 0.893| d_loss: 0.542| gp_loss: 0.049| r_loss: 0.135| p_loss: 0.214| v_loss: 0.037| per_loss: 0.492 | a_loss: 0.564
Train: Epoch [522/3000], Step [30/158]| g_loss: 0.882| d_loss: 0.704| gp_loss: 0.135| r_loss: 0.136| p_loss: 0.215| v_loss: 0.036| per_loss: 0.519 | a_loss: 0.550
Train: Epoch [522/3000], Step [60/158]| g_loss: 0.900| d_loss: 0.488| gp_loss: 0.046| r_loss: 0.130| p_loss: 0.206| v_loss: 0.036| per_loss: 0.523 | a_loss: 0.578
Train: Epoch [522/3000], Step [90/158]| g_loss: 0.927| d_loss: 0.526| gp_loss: 0.046| r_loss: 0.133| p_loss: 0.211| v_loss: 0.036| per_loss: 0.550 | a_loss: 0.598
Train: Epoch [522/3000], Step [120/158]| g_loss: 0.863| d_loss: 0.653| gp_loss: 0.049| r_loss: 0.145| p_loss: 0.220| v_loss: 0.037| per_loss: 0.529 | a_loss: 0.519
Train: Epoch [522/3000], Step [150/158]| g_loss: 0.878| d_loss: 0.626| gp_loss: 0.049| r_loss: 0.135| p_loss: 0.211| v_loss: 0.037| per_loss: 0.538 | a_loss: 0.547
Train: Epoch [523/3000], Step [30/158]| g_loss: 0.803| d_loss: 0.716| gp_loss: 0.115| r_loss: 0.135| p_loss: 0.205| v_loss: 0.036| per_loss: 0.528 | a_loss: 0.476
Train: Epoch [523/3000], Step [60/158]| g_loss: 0.837| d_loss: 0.664| gp_loss: 0.048| r_loss: 0.134| p_loss: 0.213| v_loss: 0.036| per_loss: 0.528 | a_loss: 0.507
Train: Epoch [523/3000], Step [90/158]| g_loss: 0.827| d_loss: 0.632| gp_loss: 0.049| r_loss: 0.137| p_loss: 0.217| v_loss: 0.036| per_loss: 0.517 | a_loss: 0.494
Train: Epoch [523/3000], Step [120/158]| g_loss: 0.928| d_loss: 0.554| gp_loss: 0.053| r_loss: 0.135| p_loss: 0.214| v_loss: 0.037| per_loss: 0.566 | a_loss: 0.593
Train: Epoch [523/3000], Step [150/158]| g_loss: 0.894| d_loss: 0.582| gp_loss: 0.048| r_loss: 0.142| p_loss: 0.233| v_loss: 0.037| per_loss: 0.576 | a_loss: 0.540
Train: Epoch [524/3000], Step [30/158]| g_loss: 0.916| d_loss: 0.668| gp_loss: 0.162| r_loss: 0.136| p_loss: 0.222| v_loss: 0.037| per_loss: 0.569 | a_loss: 0.575
Train: Epoch [524/3000], Step [60/158]| g_loss: 0.844| d_loss: 0.645| gp_loss: 0.047| r_loss: 0.133| p_loss: 0.212| v_loss: 0.036| per_loss: 0.552 | a_loss: 0.513
Train: Epoch [524/3000], Step [90/158]| g_loss: 0.867| d_loss: 0.534| gp_loss: 0.047| r_loss: 0.134| p_loss: 0.220| v_loss: 0.039| per_loss: 0.511 | a_loss: 0.532
Train: Epoch [524/3000], Step [120/158]| g_loss: 0.881| d_loss: 0.678| gp_loss: 0.046| r_loss: 0.134| p_loss: 0.218| v_loss: 0.035| per_loss: 0.531 | a_loss: 0.550
Train: Epoch [524/3000], Step [150/158]| g_loss: 0.848| d_loss: 0.538| gp_loss: 0.050| r_loss: 0.137| p_loss: 0.208| v_loss: 0.037| per_loss: 0.558 | a_loss: 0.514
Train: Epoch [525/3000], Step [30/158]| g_loss: 0.924| d_loss: 0.608| gp_loss: 0.119| r_loss: 0.136| p_loss: 0.210| v_loss: 0.039| per_loss: 0.531 | a_loss: 0.591
Train: Epoch [525/3000], Step [60/158]| g_loss: 0.921| d_loss: 0.476| gp_loss: 0.049| r_loss: 0.135| p_loss: 0.200| v_loss: 0.037| per_loss: 0.535 | a_loss: 0.595
Train: Epoch [525/3000], Step [90/158]| g_loss: 0.854| d_loss: 0.614| gp_loss: 0.046| r_loss: 0.135| p_loss: 0.211| v_loss: 0.037| per_loss: 0.522 | a_loss: 0.524
Train: Epoch [525/3000], Step [120/158]| g_loss: 0.824| d_loss: 0.648| gp_loss: 0.048| r_loss: 0.130| p_loss: 0.204| v_loss: 0.037| per_loss: 0.502 | a_loss: 0.505
Train: Epoch [525/3000], Step [150/158]| g_loss: 0.872| d_loss: 0.636| gp_loss: 0.055| r_loss: 0.138| p_loss: 0.215| v_loss: 0.037| per_loss: 0.505 | a_loss: 0.539
Train: Epoch [526/3000], Step [30/158]| g_loss: 0.838| d_loss: 0.712| gp_loss: 0.131| r_loss: 0.132| p_loss: 0.205| v_loss: 0.035| per_loss: 0.527 | a_loss: 0.517
Train: Epoch [526/3000], Step [60/158]| g_loss: 0.827| d_loss: 0.663| gp_loss: 0.051| r_loss: 0.134| p_loss: 0.206| v_loss: 0.036| per_loss: 0.505 | a_loss: 0.503
Train: Epoch [526/3000], Step [90/158]| g_loss: 0.868| d_loss: 0.567| gp_loss: 0.047| r_loss: 0.138| p_loss: 0.211| v_loss: 0.038| per_loss: 0.505 | a_loss: 0.536
Train: Epoch [526/3000], Step [120/158]| g_loss: 0.881| d_loss: 0.560| gp_loss: 0.048| r_loss: 0.129| p_loss: 0.208| v_loss: 0.037| per_loss: 0.494 | a_loss: 0.562
Train: Epoch [526/3000], Step [150/158]| g_loss: 0.901| d_loss: 0.546| gp_loss: 0.049| r_loss: 0.139| p_loss: 0.206| v_loss: 0.038| per_loss: 0.529 | a_loss: 0.568
Train: Epoch [527/3000], Step [30/158]| g_loss: 0.839| d_loss: 0.727| gp_loss: 0.148| r_loss: 0.134| p_loss: 0.211| v_loss: 0.038| per_loss: 0.500 | a_loss: 0.511
Train: Epoch [527/3000], Step [60/158]| g_loss: 0.909| d_loss: 0.522| gp_loss: 0.049| r_loss: 0.139| p_loss: 0.201| v_loss: 0.039| per_loss: 0.496 | a_loss: 0.581
Train: Epoch [527/3000], Step [90/158]| g_loss: 0.883| d_loss: 0.590| gp_loss: 0.049| r_loss: 0.137| p_loss: 0.209| v_loss: 0.038| per_loss: 0.511 | a_loss: 0.553
Train: Epoch [527/3000], Step [120/158]| g_loss: 0.827| d_loss: 0.599| gp_loss: 0.050| r_loss: 0.130| p_loss: 0.201| v_loss: 0.035| per_loss: 0.521 | a_loss: 0.509
Train: Epoch [527/3000], Step [150/158]| g_loss: 0.907| d_loss: 0.545| gp_loss: 0.050| r_loss: 0.132| p_loss: 0.203| v_loss: 0.036| per_loss: 0.520 | a_loss: 0.585
Train: Epoch [528/3000], Step [30/158]| g_loss: 0.897| d_loss: 0.631| gp_loss: 0.139| r_loss: 0.134| p_loss: 0.202| v_loss: 0.037| per_loss: 0.553 | a_loss: 0.569
Train: Epoch [528/3000], Step [60/158]| g_loss: 0.889| d_loss: 0.531| gp_loss: 0.047| r_loss: 0.122| p_loss: 0.190| v_loss: 0.037| per_loss: 0.520 | a_loss: 0.583
Train: Epoch [528/3000], Step [90/158]| g_loss: 0.914| d_loss: 0.594| gp_loss: 0.046| r_loss: 0.141| p_loss: 0.201| v_loss: 0.035| per_loss: 0.524 | a_loss: 0.585
Train: Epoch [528/3000], Step [120/158]| g_loss: 0.865| d_loss: 0.586| gp_loss: 0.048| r_loss: 0.126| p_loss: 0.199| v_loss: 0.037| per_loss: 0.518 | a_loss: 0.551
Train: Epoch [528/3000], Step [150/158]| g_loss: 0.815| d_loss: 0.636| gp_loss: 0.047| r_loss: 0.141| p_loss: 0.213| v_loss: 0.038| per_loss: 0.533 | a_loss: 0.477
Train: Epoch [529/3000], Step [30/158]| g_loss: 0.872| d_loss: 0.675| gp_loss: 0.144| r_loss: 0.124| p_loss: 0.195| v_loss: 0.034| per_loss: 0.527 | a_loss: 0.564
Train: Epoch [529/3000], Step [60/158]| g_loss: 0.855| d_loss: 0.577| gp_loss: 0.045| r_loss: 0.140| p_loss: 0.204| v_loss: 0.037| per_loss: 0.515 | a_loss: 0.524
Train: Epoch [529/3000], Step [90/158]| g_loss: 0.837| d_loss: 0.581| gp_loss: 0.048| r_loss: 0.136| p_loss: 0.197| v_loss: 0.035| per_loss: 0.509 | a_loss: 0.517
Train: Epoch [529/3000], Step [120/158]| g_loss: 0.922| d_loss: 0.524| gp_loss: 0.051| r_loss: 0.130| p_loss: 0.193| v_loss: 0.038| per_loss: 0.527 | a_loss: 0.605
Train: Epoch [529/3000], Step [150/158]| g_loss: 0.851| d_loss: 0.587| gp_loss: 0.051| r_loss: 0.128| p_loss: 0.189| v_loss: 0.036| per_loss: 0.524 | a_loss: 0.539
Train: Epoch [530/3000], Step [30/158]| g_loss: 0.848| d_loss: 0.705| gp_loss: 0.157| r_loss: 0.131| p_loss: 0.195| v_loss: 0.036| per_loss: 0.528 | a_loss: 0.530
Train: Epoch [530/3000], Step [60/158]| g_loss: 0.825| d_loss: 0.632| gp_loss: 0.049| r_loss: 0.126| p_loss: 0.194| v_loss: 0.035| per_loss: 0.522 | a_loss: 0.514
Train: Epoch [530/3000], Step [90/158]| g_loss: 0.876| d_loss: 0.584| gp_loss: 0.050| r_loss: 0.137| p_loss: 0.203| v_loss: 0.037| per_loss: 0.539 | a_loss: 0.546
Train: Epoch [530/3000], Step [120/158]| g_loss: 0.843| d_loss: 0.564| gp_loss: 0.047| r_loss: 0.130| p_loss: 0.203| v_loss: 0.037| per_loss: 0.488 | a_loss: 0.525
Train: Epoch [530/3000], Step [150/158]| g_loss: 0.922| d_loss: 0.464| gp_loss: 0.051| r_loss: 0.125| p_loss: 0.196| v_loss: 0.035| per_loss: 0.524 | a_loss: 0.611
Train: Epoch [531/3000], Step [30/158]| g_loss: 0.926| d_loss: 0.537| gp_loss: 0.103| r_loss: 0.130| p_loss: 0.199| v_loss: 0.036| per_loss: 0.537 | a_loss: 0.607
Train: Epoch [531/3000], Step [60/158]| g_loss: 0.891| d_loss: 0.596| gp_loss: 0.048| r_loss: 0.134| p_loss: 0.206| v_loss: 0.036| per_loss: 0.511 | a_loss: 0.566
Train: Epoch [531/3000], Step [90/158]| g_loss: 0.835| d_loss: 0.596| gp_loss: 0.054| r_loss: 0.122| p_loss: 0.194| v_loss: 0.035| per_loss: 0.514 | a_loss: 0.529
Train: Epoch [531/3000], Step [120/158]| g_loss: 0.888| d_loss: 0.535| gp_loss: 0.050| r_loss: 0.127| p_loss: 0.199| v_loss: 0.036| per_loss: 0.518 | a_loss: 0.574
Train: Epoch [531/3000], Step [150/158]| g_loss: 0.824| d_loss: 0.651| gp_loss: 0.052| r_loss: 0.132| p_loss: 0.196| v_loss: 0.035| per_loss: 0.505 | a_loss: 0.508
Train: Epoch [532/3000], Step [30/158]| g_loss: 0.870| d_loss: 0.668| gp_loss: 0.159| r_loss: 0.126| p_loss: 0.201| v_loss: 0.036| per_loss: 0.469 | a_loss: 0.561
Train: Epoch [532/3000], Step [60/158]| g_loss: 0.831| d_loss: 0.625| gp_loss: 0.049| r_loss: 0.131| p_loss: 0.192| v_loss: 0.037| per_loss: 0.540 | a_loss: 0.513
Train: Epoch [532/3000], Step [90/158]| g_loss: 0.930| d_loss: 0.463| gp_loss: 0.050| r_loss: 0.137| p_loss: 0.201| v_loss: 0.037| per_loss: 0.538 | a_loss: 0.602
Train: Epoch [532/3000], Step [120/158]| g_loss: 0.846| d_loss: 0.638| gp_loss: 0.052| r_loss: 0.124| p_loss: 0.199| v_loss: 0.035| per_loss: 0.526 | a_loss: 0.534
Train: Epoch [532/3000], Step [150/158]| g_loss: 0.908| d_loss: 0.502| gp_loss: 0.052| r_loss: 0.129| p_loss: 0.203| v_loss: 0.035| per_loss: 0.491 | a_loss: 0.594
Train: Epoch [533/3000], Step [30/158]| g_loss: 0.872| d_loss: 0.621| gp_loss: 0.134| r_loss: 0.123| p_loss: 0.192| v_loss: 0.036| per_loss: 0.527 | a_loss: 0.566
Train: Epoch [533/3000], Step [60/158]| g_loss: 0.906| d_loss: 0.547| gp_loss: 0.049| r_loss: 0.130| p_loss: 0.199| v_loss: 0.035| per_loss: 0.538 | a_loss: 0.588
Train: Epoch [533/3000], Step [90/158]| g_loss: 0.852| d_loss: 0.599| gp_loss: 0.046| r_loss: 0.131| p_loss: 0.198| v_loss: 0.036| per_loss: 0.509 | a_loss: 0.535
Train: Epoch [533/3000], Step [120/158]| g_loss: 0.874| d_loss: 0.571| gp_loss: 0.050| r_loss: 0.134| p_loss: 0.202| v_loss: 0.035| per_loss: 0.517 | a_loss: 0.552
Train: Epoch [533/3000], Step [150/158]| g_loss: 0.901| d_loss: 0.579| gp_loss: 0.049| r_loss: 0.139| p_loss: 0.217| v_loss: 0.037| per_loss: 0.546 | a_loss: 0.562
Train: Epoch [534/3000], Step [30/158]| g_loss: 0.847| d_loss: 0.797| gp_loss: 0.194| r_loss: 0.135| p_loss: 0.220| v_loss: 0.035| per_loss: 0.548 | a_loss: 0.513
Train: Epoch [534/3000], Step [60/158]| g_loss: 0.952| d_loss: 0.478| gp_loss: 0.046| r_loss: 0.135| p_loss: 0.217| v_loss: 0.038| per_loss: 0.523 | a_loss: 0.619
Train: Epoch [534/3000], Step [90/158]| g_loss: 0.851| d_loss: 0.582| gp_loss: 0.048| r_loss: 0.132| p_loss: 0.203| v_loss: 0.036| per_loss: 0.537 | a_loss: 0.529
Train: Epoch [534/3000], Step [120/158]| g_loss: 0.900| d_loss: 0.538| gp_loss: 0.044| r_loss: 0.130| p_loss: 0.200| v_loss: 0.035| per_loss: 0.517 | a_loss: 0.583
Train: Epoch [534/3000], Step [150/158]| g_loss: 0.862| d_loss: 0.556| gp_loss: 0.050| r_loss: 0.129| p_loss: 0.197| v_loss: 0.035| per_loss: 0.544 | a_loss: 0.546
Train: Epoch [535/3000], Step [30/158]| g_loss: 0.929| d_loss: 0.644| gp_loss: 0.152| r_loss: 0.135| p_loss: 0.206| v_loss: 0.038| per_loss: 0.532 | a_loss: 0.600
Train: Epoch [535/3000], Step [60/158]| g_loss: 0.864| d_loss: 0.593| gp_loss: 0.046| r_loss: 0.133| p_loss: 0.196| v_loss: 0.036| per_loss: 0.548 | a_loss: 0.542
Train: Epoch [535/3000], Step [90/158]| g_loss: 0.824| d_loss: 0.641| gp_loss: 0.046| r_loss: 0.133| p_loss: 0.205| v_loss: 0.037| per_loss: 0.512 | a_loss: 0.500
Train: Epoch [535/3000], Step [120/158]| g_loss: 0.897| d_loss: 0.514| gp_loss: 0.049| r_loss: 0.124| p_loss: 0.195| v_loss: 0.036| per_loss: 0.520 | a_loss: 0.588
Train: Epoch [535/3000], Step [150/158]| g_loss: 0.927| d_loss: 0.496| gp_loss: 0.049| r_loss: 0.124| p_loss: 0.194| v_loss: 0.035| per_loss: 0.546 | a_loss: 0.616
Train: Epoch [536/3000], Step [30/158]| g_loss: 0.856| d_loss: 0.706| gp_loss: 0.145| r_loss: 0.134| p_loss: 0.197| v_loss: 0.035| per_loss: 0.514 | a_loss: 0.537
Train: Epoch [536/3000], Step [60/158]| g_loss: 0.839| d_loss: 0.525| gp_loss: 0.047| r_loss: 0.125| p_loss: 0.193| v_loss: 0.035| per_loss: 0.542 | a_loss: 0.528
Train: Epoch [536/3000], Step [90/158]| g_loss: 0.934| d_loss: 0.517| gp_loss: 0.049| r_loss: 0.135| p_loss: 0.193| v_loss: 0.036| per_loss: 0.553 | a_loss: 0.612
Train: Epoch [536/3000], Step [120/158]| g_loss: 0.853| d_loss: 0.599| gp_loss: 0.050| r_loss: 0.127| p_loss: 0.198| v_loss: 0.035| per_loss: 0.536 | a_loss: 0.538
Train: Epoch [536/3000], Step [150/158]| g_loss: 0.863| d_loss: 0.554| gp_loss: 0.050| r_loss: 0.128| p_loss: 0.206| v_loss: 0.038| per_loss: 0.545 | a_loss: 0.540
Train: Epoch [537/3000], Step [30/158]| g_loss: 0.921| d_loss: 0.684| gp_loss: 0.170| r_loss: 0.144| p_loss: 0.223| v_loss: 0.036| per_loss: 0.521 | a_loss: 0.577
Train: Epoch [537/3000], Step [60/158]| g_loss: 0.941| d_loss: 0.506| gp_loss: 0.050| r_loss: 0.130| p_loss: 0.221| v_loss: 0.037| per_loss: 0.558 | a_loss: 0.607
Train: Epoch [537/3000], Step [90/158]| g_loss: 0.915| d_loss: 0.486| gp_loss: 0.050| r_loss: 0.142| p_loss: 0.205| v_loss: 0.035| per_loss: 0.524 | a_loss: 0.584
Train: Epoch [537/3000], Step [120/158]| g_loss: 0.917| d_loss: 0.587| gp_loss: 0.048| r_loss: 0.133| p_loss: 0.209| v_loss: 0.037| per_loss: 0.529 | a_loss: 0.590
Train: Epoch [537/3000], Step [150/158]| g_loss: 0.859| d_loss: 0.624| gp_loss: 0.051| r_loss: 0.130| p_loss: 0.213| v_loss: 0.035| per_loss: 0.569 | a_loss: 0.530
Train: Epoch [538/3000], Step [30/158]| g_loss: 0.942| d_loss: 0.593| gp_loss: 0.082| r_loss: 0.141| p_loss: 0.221| v_loss: 0.036| per_loss: 0.585 | a_loss: 0.596
Train: Epoch [538/3000], Step [60/158]| g_loss: 0.876| d_loss: 0.572| gp_loss: 0.047| r_loss: 0.138| p_loss: 0.217| v_loss: 0.037| per_loss: 0.541 | a_loss: 0.539
Train: Epoch [538/3000], Step [90/158]| g_loss: 0.846| d_loss: 0.630| gp_loss: 0.049| r_loss: 0.129| p_loss: 0.209| v_loss: 0.035| per_loss: 0.540 | a_loss: 0.523
Train: Epoch [538/3000], Step [120/158]| g_loss: 0.879| d_loss: 0.524| gp_loss: 0.051| r_loss: 0.124| p_loss: 0.194| v_loss: 0.033| per_loss: 0.551 | a_loss: 0.569
Train: Epoch [538/3000], Step [150/158]| g_loss: 0.911| d_loss: 0.597| gp_loss: 0.050| r_loss: 0.130| p_loss: 0.197| v_loss: 0.034| per_loss: 0.569 | a_loss: 0.591
Train: Epoch [539/3000], Step [30/158]| g_loss: 0.873| d_loss: 0.703| gp_loss: 0.176| r_loss: 0.130| p_loss: 0.195| v_loss: 0.035| per_loss: 0.524 | a_loss: 0.558
Train: Epoch [539/3000], Step [60/158]| g_loss: 0.854| d_loss: 0.533| gp_loss: 0.047| r_loss: 0.128| p_loss: 0.199| v_loss: 0.034| per_loss: 0.557 | a_loss: 0.538
Train: Epoch [539/3000], Step [90/158]| g_loss: 0.910| d_loss: 0.589| gp_loss: 0.047| r_loss: 0.138| p_loss: 0.201| v_loss: 0.034| per_loss: 0.575 | a_loss: 0.580
Train: Epoch [539/3000], Step [120/158]| g_loss: 0.823| d_loss: 0.599| gp_loss: 0.053| r_loss: 0.128| p_loss: 0.201| v_loss: 0.035| per_loss: 0.560 | a_loss: 0.503
Train: Epoch [539/3000], Step [150/158]| g_loss: 0.938| d_loss: 0.534| gp_loss: 0.050| r_loss: 0.135| p_loss: 0.203| v_loss: 0.037| per_loss: 0.579 | a_loss: 0.607
Train: Epoch [540/3000], Step [30/158]| g_loss: 0.866| d_loss: 0.683| gp_loss: 0.147| r_loss: 0.132| p_loss: 0.204| v_loss: 0.035| per_loss: 0.517 | a_loss: 0.546
Train: Epoch [540/3000], Step [60/158]| g_loss: 0.887| d_loss: 0.482| gp_loss: 0.050| r_loss: 0.127| p_loss: 0.196| v_loss: 0.035| per_loss: 0.542 | a_loss: 0.573
Train: Epoch [540/3000], Step [90/158]| g_loss: 0.942| d_loss: 0.536| gp_loss: 0.048| r_loss: 0.127| p_loss: 0.197| v_loss: 0.035| per_loss: 0.527 | a_loss: 0.629
Train: Epoch [540/3000], Step [120/158]| g_loss: 0.900| d_loss: 0.543| gp_loss: 0.051| r_loss: 0.137| p_loss: 0.207| v_loss: 0.037| per_loss: 0.566 | a_loss: 0.567
Train: Epoch [540/3000], Step [150/158]| g_loss: 0.879| d_loss: 0.629| gp_loss: 0.052| r_loss: 0.132| p_loss: 0.211| v_loss: 0.034| per_loss: 0.598 | a_loss: 0.546
Train: Epoch [541/3000], Step [30/158]| g_loss: 0.903| d_loss: 0.681| gp_loss: 0.187| r_loss: 0.136| p_loss: 0.217| v_loss: 0.038| per_loss: 0.576 | a_loss: 0.563
Train: Epoch [541/3000], Step [60/158]| g_loss: 0.930| d_loss: 0.499| gp_loss: 0.044| r_loss: 0.126| p_loss: 0.202| v_loss: 0.036| per_loss: 0.567 | a_loss: 0.610
Train: Epoch [541/3000], Step [90/158]| g_loss: 0.816| d_loss: 0.661| gp_loss: 0.047| r_loss: 0.130| p_loss: 0.210| v_loss: 0.032| per_loss: 0.583 | a_loss: 0.489
Train: Epoch [541/3000], Step [120/158]| g_loss: 0.892| d_loss: 0.519| gp_loss: 0.046| r_loss: 0.132| p_loss: 0.200| v_loss: 0.035| per_loss: 0.542 | a_loss: 0.571
Train: Epoch [541/3000], Step [150/158]| g_loss: 0.956| d_loss: 0.542| gp_loss: 0.047| r_loss: 0.147| p_loss: 0.215| v_loss: 0.036| per_loss: 0.595 | a_loss: 0.605
Train: Epoch [542/3000], Step [30/158]| g_loss: 0.859| d_loss: 0.646| gp_loss: 0.128| r_loss: 0.127| p_loss: 0.203| v_loss: 0.035| per_loss: 0.559 | a_loss: 0.538
Train: Epoch [542/3000], Step [60/158]| g_loss: 0.900| d_loss: 0.562| gp_loss: 0.044| r_loss: 0.143| p_loss: 0.220| v_loss: 0.037| per_loss: 0.529 | a_loss: 0.557
Train: Epoch [542/3000], Step [90/158]| g_loss: 0.850| d_loss: 0.613| gp_loss: 0.047| r_loss: 0.131| p_loss: 0.202| v_loss: 0.035| per_loss: 0.582 | a_loss: 0.526
Train: Epoch [542/3000], Step [120/158]| g_loss: 0.901| d_loss: 0.559| gp_loss: 0.049| r_loss: 0.145| p_loss: 0.214| v_loss: 0.037| per_loss: 0.556 | a_loss: 0.557
Train: Epoch [542/3000], Step [150/158]| g_loss: 0.906| d_loss: 0.523| gp_loss: 0.049| r_loss: 0.132| p_loss: 0.209| v_loss: 0.034| per_loss: 0.567 | a_loss: 0.579
Train: Epoch [543/3000], Step [30/158]| g_loss: 0.908| d_loss: 0.598| gp_loss: 0.115| r_loss: 0.136| p_loss: 0.215| v_loss: 0.036| per_loss: 0.614 | a_loss: 0.567
Train: Epoch [543/3000], Step [60/158]| g_loss: 0.921| d_loss: 0.526| gp_loss: 0.049| r_loss: 0.132| p_loss: 0.210| v_loss: 0.035| per_loss: 0.573 | a_loss: 0.592
Train: Epoch [543/3000], Step [90/158]| g_loss: 0.933| d_loss: 0.515| gp_loss: 0.047| r_loss: 0.143| p_loss: 0.208| v_loss: 0.038| per_loss: 0.581 | a_loss: 0.591
Train: Epoch [543/3000], Step [120/158]| g_loss: 0.914| d_loss: 0.553| gp_loss: 0.054| r_loss: 0.125| p_loss: 0.206| v_loss: 0.035| per_loss: 0.561 | a_loss: 0.595
Train: Epoch [543/3000], Step [150/158]| g_loss: 0.824| d_loss: 0.686| gp_loss: 0.051| r_loss: 0.132| p_loss: 0.210| v_loss: 0.034| per_loss: 0.527 | a_loss: 0.500
Train: Epoch [544/3000], Step [30/158]| g_loss: 0.950| d_loss: 0.599| gp_loss: 0.133| r_loss: 0.133| p_loss: 0.214| v_loss: 0.036| per_loss: 0.594 | a_loss: 0.614
Train: Epoch [544/3000], Step [60/158]| g_loss: 0.910| d_loss: 0.511| gp_loss: 0.047| r_loss: 0.136| p_loss: 0.207| v_loss: 0.036| per_loss: 0.581 | a_loss: 0.576
Train: Epoch [544/3000], Step [90/158]| g_loss: 0.849| d_loss: 0.678| gp_loss: 0.051| r_loss: 0.136| p_loss: 0.212| v_loss: 0.034| per_loss: 0.553 | a_loss: 0.517
Train: Epoch [544/3000], Step [120/158]| g_loss: 0.865| d_loss: 0.567| gp_loss: 0.049| r_loss: 0.134| p_loss: 0.202| v_loss: 0.035| per_loss: 0.545 | a_loss: 0.541
Train: Epoch [544/3000], Step [150/158]| g_loss: 0.924| d_loss: 0.549| gp_loss: 0.049| r_loss: 0.123| p_loss: 0.206| v_loss: 0.033| per_loss: 0.568 | a_loss: 0.609
Train: Epoch [545/3000], Step [30/158]| g_loss: 0.886| d_loss: 0.614| gp_loss: 0.138| r_loss: 0.134| p_loss: 0.206| v_loss: 0.037| per_loss: 0.538 | a_loss: 0.558
Train: Epoch [545/3000], Step [60/158]| g_loss: 0.914| d_loss: 0.594| gp_loss: 0.046| r_loss: 0.131| p_loss: 0.202| v_loss: 0.035| per_loss: 0.542 | a_loss: 0.592
Train: Epoch [545/3000], Step [90/158]| g_loss: 0.870| d_loss: 0.527| gp_loss: 0.047| r_loss: 0.128| p_loss: 0.195| v_loss: 0.037| per_loss: 0.570 | a_loss: 0.551
Train: Epoch [545/3000], Step [120/158]| g_loss: 0.840| d_loss: 0.645| gp_loss: 0.051| r_loss: 0.126| p_loss: 0.207| v_loss: 0.034| per_loss: 0.512 | a_loss: 0.526
Train: Epoch [545/3000], Step [150/158]| g_loss: 0.905| d_loss: 0.476| gp_loss: 0.052| r_loss: 0.131| p_loss: 0.202| v_loss: 0.036| per_loss: 0.533 | a_loss: 0.583
Train: Epoch [546/3000], Step [30/158]| g_loss: 0.946| d_loss: 0.598| gp_loss: 0.143| r_loss: 0.129| p_loss: 0.200| v_loss: 0.035| per_loss: 0.542 | a_loss: 0.629
Train: Epoch [546/3000], Step [60/158]| g_loss: 0.875| d_loss: 0.583| gp_loss: 0.046| r_loss: 0.140| p_loss: 0.207| v_loss: 0.037| per_loss: 0.589 | a_loss: 0.536
Train: Epoch [546/3000], Step [90/158]| g_loss: 0.853| d_loss: 0.573| gp_loss: 0.046| r_loss: 0.123| p_loss: 0.186| v_loss: 0.035| per_loss: 0.540 | a_loss: 0.548
Train: Epoch [546/3000], Step [120/158]| g_loss: 0.881| d_loss: 0.603| gp_loss: 0.045| r_loss: 0.126| p_loss: 0.201| v_loss: 0.036| per_loss: 0.521 | a_loss: 0.566
Train: Epoch [546/3000], Step [150/158]| g_loss: 0.861| d_loss: 0.567| gp_loss: 0.048| r_loss: 0.129| p_loss: 0.204| v_loss: 0.035| per_loss: 0.501 | a_loss: 0.545
Train: Epoch [547/3000], Step [30/158]| g_loss: 0.885| d_loss: 0.625| gp_loss: 0.122| r_loss: 0.140| p_loss: 0.201| v_loss: 0.036| per_loss: 0.521 | a_loss: 0.556
Train: Epoch [547/3000], Step [60/158]| g_loss: 0.817| d_loss: 0.673| gp_loss: 0.048| r_loss: 0.128| p_loss: 0.195| v_loss: 0.035| per_loss: 0.547 | a_loss: 0.502
Train: Epoch [547/3000], Step [90/158]| g_loss: 0.869| d_loss: 0.545| gp_loss: 0.050| r_loss: 0.121| p_loss: 0.193| v_loss: 0.034| per_loss: 0.519 | a_loss: 0.565
Train: Epoch [547/3000], Step [120/158]| g_loss: 0.874| d_loss: 0.505| gp_loss: 0.049| r_loss: 0.129| p_loss: 0.199| v_loss: 0.036| per_loss: 0.530 | a_loss: 0.557
Train: Epoch [547/3000], Step [150/158]| g_loss: 0.945| d_loss: 0.488| gp_loss: 0.050| r_loss: 0.129| p_loss: 0.201| v_loss: 0.037| per_loss: 0.558 | a_loss: 0.623
Train: Epoch [548/3000], Step [30/158]| g_loss: 0.813| d_loss: 0.749| gp_loss: 0.057| r_loss: 0.126| p_loss: 0.212| v_loss: 0.037| per_loss: 0.539 | a_loss: 0.489
Train: Epoch [548/3000], Step [60/158]| g_loss: 0.912| d_loss: 0.567| gp_loss: 0.051| r_loss: 0.142| p_loss: 0.209| v_loss: 0.039| per_loss: 0.560 | a_loss: 0.571
Train: Epoch [548/3000], Step [90/158]| g_loss: 0.893| d_loss: 0.637| gp_loss: 0.054| r_loss: 0.140| p_loss: 0.224| v_loss: 0.036| per_loss: 0.568 | a_loss: 0.548
Train: Epoch [548/3000], Step [120/158]| g_loss: 0.878| d_loss: 0.566| gp_loss: 0.053| r_loss: 0.134| p_loss: 0.204| v_loss: 0.034| per_loss: 0.553 | a_loss: 0.552
Train: Epoch [548/3000], Step [150/158]| g_loss: 0.908| d_loss: 0.515| gp_loss: 0.050| r_loss: 0.131| p_loss: 0.203| v_loss: 0.036| per_loss: 0.559 | a_loss: 0.584
Train: Epoch [549/3000], Step [30/158]| g_loss: 0.889| d_loss: 0.591| gp_loss: 0.107| r_loss: 0.128| p_loss: 0.200| v_loss: 0.037| per_loss: 0.553 | a_loss: 0.569
Train: Epoch [549/3000], Step [60/158]| g_loss: 0.928| d_loss: 0.543| gp_loss: 0.050| r_loss: 0.139| p_loss: 0.216| v_loss: 0.040| per_loss: 0.578 | a_loss: 0.584
Train: Epoch [549/3000], Step [90/158]| g_loss: 0.862| d_loss: 0.587| gp_loss: 0.052| r_loss: 0.135| p_loss: 0.204| v_loss: 0.038| per_loss: 0.564 | a_loss: 0.530
Train: Epoch [549/3000], Step [120/158]| g_loss: 0.902| d_loss: 0.599| gp_loss: 0.053| r_loss: 0.139| p_loss: 0.214| v_loss: 0.038| per_loss: 0.585 | a_loss: 0.560
Train: Epoch [549/3000], Step [150/158]| g_loss: 0.890| d_loss: 0.553| gp_loss: 0.056| r_loss: 0.137| p_loss: 0.197| v_loss: 0.038| per_loss: 0.580 | a_loss: 0.557
Train: Epoch [550/3000], Step [30/158]| g_loss: 0.901| d_loss: 0.690| gp_loss: 0.110| r_loss: 0.145| p_loss: 0.223| v_loss: 0.039| per_loss: 0.592 | a_loss: 0.547
Train: Epoch [550/3000], Step [60/158]| g_loss: 0.922| d_loss: 0.538| gp_loss: 0.054| r_loss: 0.149| p_loss: 0.227| v_loss: 0.039| per_loss: 0.623 | a_loss: 0.558
Train: Epoch [550/3000], Step [90/158]| g_loss: 0.903| d_loss: 0.574| gp_loss: 0.051| r_loss: 0.139| p_loss: 0.217| v_loss: 0.039| per_loss: 0.623 | a_loss: 0.554
Train: Epoch [550/3000], Step [120/158]| g_loss: 0.879| d_loss: 0.632| gp_loss: 0.055| r_loss: 0.140| p_loss: 0.222| v_loss: 0.039| per_loss: 0.623 | a_loss: 0.527
Train: Epoch [550/3000], Step [150/158]| g_loss: 0.913| d_loss: 0.555| gp_loss: 0.056| r_loss: 0.144| p_loss: 0.216| v_loss: 0.039| per_loss: 0.604 | a_loss: 0.562
Test: Epoch [550/3000]| g_loss: 0.772| r_loss: 0.485| p_loss: 0.363| v_loss: 0.030
Train: Epoch [551/3000], Step [30/158]| g_loss: 0.898| d_loss: 0.593| gp_loss: 0.055| r_loss: 0.143| p_loss: 0.217| v_loss: 0.039| per_loss: 0.651 | a_loss: 0.542
Train: Epoch [551/3000], Step [60/158]| g_loss: 0.861| d_loss: 0.624| gp_loss: 0.055| r_loss: 0.143| p_loss: 0.226| v_loss: 0.040| per_loss: 0.634 | a_loss: 0.502
Train: Epoch [551/3000], Step [90/158]| g_loss: 0.865| d_loss: 0.560| gp_loss: 0.056| r_loss: 0.132| p_loss: 0.203| v_loss: 0.038| per_loss: 0.587 | a_loss: 0.535
Train: Epoch [551/3000], Step [120/158]| g_loss: 0.885| d_loss: 0.568| gp_loss: 0.059| r_loss: 0.135| p_loss: 0.206| v_loss: 0.036| per_loss: 0.592 | a_loss: 0.552
Train: Epoch [551/3000], Step [150/158]| g_loss: 0.973| d_loss: 0.553| gp_loss: 0.059| r_loss: 0.140| p_loss: 0.207| v_loss: 0.038| per_loss: 0.643 | a_loss: 0.628
Train: Epoch [552/3000], Step [30/158]| g_loss: 0.874| d_loss: 0.610| gp_loss: 0.106| r_loss: 0.130| p_loss: 0.209| v_loss: 0.038| per_loss: 0.569 | a_loss: 0.545
Train: Epoch [552/3000], Step [60/158]| g_loss: 0.901| d_loss: 0.573| gp_loss: 0.058| r_loss: 0.143| p_loss: 0.213| v_loss: 0.038| per_loss: 0.595 | a_loss: 0.554
Train: Epoch [552/3000], Step [90/158]| g_loss: 0.893| d_loss: 0.551| gp_loss: 0.059| r_loss: 0.148| p_loss: 0.213| v_loss: 0.036| per_loss: 0.577 | a_loss: 0.544
Train: Epoch [552/3000], Step [120/158]| g_loss: 0.951| d_loss: 0.548| gp_loss: 0.059| r_loss: 0.144| p_loss: 0.216| v_loss: 0.039| per_loss: 0.591 | a_loss: 0.602
Train: Epoch [552/3000], Step [150/158]| g_loss: 0.828| d_loss: 0.631| gp_loss: 0.061| r_loss: 0.134| p_loss: 0.209| v_loss: 0.038| per_loss: 0.575 | a_loss: 0.494
Train: Epoch [553/3000], Step [30/158]| g_loss: 0.877| d_loss: 0.713| gp_loss: 0.148| r_loss: 0.136| p_loss: 0.225| v_loss: 0.038| per_loss: 0.596 | a_loss: 0.530
Train: Epoch [553/3000], Step [60/158]| g_loss: 0.902| d_loss: 0.524| gp_loss: 0.058| r_loss: 0.147| p_loss: 0.215| v_loss: 0.038| per_loss: 0.585 | a_loss: 0.551
Train: Epoch [553/3000], Step [90/158]| g_loss: 0.961| d_loss: 0.517| gp_loss: 0.057| r_loss: 0.144| p_loss: 0.211| v_loss: 0.039| per_loss: 0.601 | a_loss: 0.612
Train: Epoch [553/3000], Step [120/158]| g_loss: 0.849| d_loss: 0.681| gp_loss: 0.060| r_loss: 0.138| p_loss: 0.218| v_loss: 0.039| per_loss: 0.567 | a_loss: 0.506
Train: Epoch [553/3000], Step [150/158]| g_loss: 0.870| d_loss: 0.671| gp_loss: 0.059| r_loss: 0.137| p_loss: 0.211| v_loss: 0.039| per_loss: 0.544 | a_loss: 0.535
Train: Epoch [554/3000], Step [30/158]| g_loss: 0.891| d_loss: 0.651| gp_loss: 0.176| r_loss: 0.139| p_loss: 0.209| v_loss: 0.039| per_loss: 0.574 | a_loss: 0.551
Train: Epoch [554/3000], Step [60/158]| g_loss: 0.914| d_loss: 0.541| gp_loss: 0.054| r_loss: 0.146| p_loss: 0.208| v_loss: 0.038| per_loss: 0.614 | a_loss: 0.564
Train: Epoch [554/3000], Step [90/158]| g_loss: 0.905| d_loss: 0.602| gp_loss: 0.050| r_loss: 0.140| p_loss: 0.208| v_loss: 0.037| per_loss: 0.603 | a_loss: 0.564
Train: Epoch [554/3000], Step [120/158]| g_loss: 0.865| d_loss: 0.634| gp_loss: 0.056| r_loss: 0.134| p_loss: 0.209| v_loss: 0.037| per_loss: 0.571 | a_loss: 0.532
Train: Epoch [554/3000], Step [150/158]| g_loss: 0.877| d_loss: 0.567| gp_loss: 0.056| r_loss: 0.131| p_loss: 0.212| v_loss: 0.038| per_loss: 0.544 | a_loss: 0.547
Train: Epoch [555/3000], Step [30/158]| g_loss: 0.914| d_loss: 0.650| gp_loss: 0.169| r_loss: 0.135| p_loss: 0.207| v_loss: 0.040| per_loss: 0.569 | a_loss: 0.578
Train: Epoch [555/3000], Step [60/158]| g_loss: 0.877| d_loss: 0.623| gp_loss: 0.053| r_loss: 0.142| p_loss: 0.224| v_loss: 0.040| per_loss: 0.565 | a_loss: 0.528
Train: Epoch [555/3000], Step [90/158]| g_loss: 0.856| d_loss: 0.590| gp_loss: 0.055| r_loss: 0.132| p_loss: 0.205| v_loss: 0.038| per_loss: 0.569 | a_loss: 0.527
Train: Epoch [555/3000], Step [120/158]| g_loss: 0.882| d_loss: 0.616| gp_loss: 0.057| r_loss: 0.152| p_loss: 0.216| v_loss: 0.037| per_loss: 0.588 | a_loss: 0.526
Train: Epoch [555/3000], Step [150/158]| g_loss: 0.936| d_loss: 0.542| gp_loss: 0.054| r_loss: 0.133| p_loss: 0.219| v_loss: 0.038| per_loss: 0.569 | a_loss: 0.599
Train: Epoch [556/3000], Step [30/158]| g_loss: 0.929| d_loss: 0.650| gp_loss: 0.174| r_loss: 0.131| p_loss: 0.207| v_loss: 0.038| per_loss: 0.636 | a_loss: 0.593
Train: Epoch [556/3000], Step [60/158]| g_loss: 0.912| d_loss: 0.618| gp_loss: 0.051| r_loss: 0.150| p_loss: 0.219| v_loss: 0.041| per_loss: 0.572 | a_loss: 0.555
Train: Epoch [556/3000], Step [90/158]| g_loss: 0.847| d_loss: 0.627| gp_loss: 0.053| r_loss: 0.134| p_loss: 0.213| v_loss: 0.038| per_loss: 0.572 | a_loss: 0.512
Train: Epoch [556/3000], Step [120/158]| g_loss: 0.944| d_loss: 0.557| gp_loss: 0.054| r_loss: 0.138| p_loss: 0.217| v_loss: 0.039| per_loss: 0.601 | a_loss: 0.598
Train: Epoch [556/3000], Step [150/158]| g_loss: 0.872| d_loss: 0.624| gp_loss: 0.053| r_loss: 0.145| p_loss: 0.226| v_loss: 0.039| per_loss: 0.640 | a_loss: 0.511
Train: Epoch [557/3000], Step [30/158]| g_loss: 0.953| d_loss: 0.602| gp_loss: 0.143| r_loss: 0.136| p_loss: 0.215| v_loss: 0.038| per_loss: 0.630 | a_loss: 0.609
Train: Epoch [557/3000], Step [60/158]| g_loss: 0.899| d_loss: 0.602| gp_loss: 0.052| r_loss: 0.147| p_loss: 0.214| v_loss: 0.036| per_loss: 0.607 | a_loss: 0.548
Train: Epoch [557/3000], Step [90/158]| g_loss: 0.869| d_loss: 0.625| gp_loss: 0.053| r_loss: 0.141| p_loss: 0.212| v_loss: 0.038| per_loss: 0.645 | a_loss: 0.520
Train: Epoch [557/3000], Step [120/158]| g_loss: 0.898| d_loss: 0.623| gp_loss: 0.050| r_loss: 0.138| p_loss: 0.214| v_loss: 0.039| per_loss: 0.597 | a_loss: 0.554
Train: Epoch [557/3000], Step [150/158]| g_loss: 0.812| d_loss: 0.563| gp_loss: 0.060| r_loss: 0.136| p_loss: 0.212| v_loss: 0.037| per_loss: 0.617 | a_loss: 0.471
Train: Epoch [558/3000], Step [30/158]| g_loss: 1.039| d_loss: 0.458| gp_loss: 0.125| r_loss: 0.133| p_loss: 0.213| v_loss: 0.040| per_loss: 0.596 | a_loss: 0.700
Train: Epoch [558/3000], Step [60/158]| g_loss: 0.864| d_loss: 0.675| gp_loss: 0.053| r_loss: 0.149| p_loss: 0.219| v_loss: 0.038| per_loss: 0.642 | a_loss: 0.504
Train: Epoch [558/3000], Step [90/158]| g_loss: 0.890| d_loss: 0.620| gp_loss: 0.057| r_loss: 0.144| p_loss: 0.218| v_loss: 0.036| per_loss: 0.610 | a_loss: 0.540
Train: Epoch [558/3000], Step [120/158]| g_loss: 0.863| d_loss: 0.578| gp_loss: 0.053| r_loss: 0.134| p_loss: 0.210| v_loss: 0.039| per_loss: 0.581 | a_loss: 0.527
Train: Epoch [558/3000], Step [150/158]| g_loss: 0.894| d_loss: 0.592| gp_loss: 0.054| r_loss: 0.129| p_loss: 0.205| v_loss: 0.037| per_loss: 0.543 | a_loss: 0.571
Train: Epoch [559/3000], Step [30/158]| g_loss: 0.913| d_loss: 0.658| gp_loss: 0.181| r_loss: 0.137| p_loss: 0.213| v_loss: 0.039| per_loss: 0.547 | a_loss: 0.576
Train: Epoch [559/3000], Step [60/158]| g_loss: 0.851| d_loss: 0.626| gp_loss: 0.051| r_loss: 0.139| p_loss: 0.216| v_loss: 0.038| per_loss: 0.574 | a_loss: 0.510
Train: Epoch [559/3000], Step [90/158]| g_loss: 0.944| d_loss: 0.517| gp_loss: 0.052| r_loss: 0.140| p_loss: 0.219| v_loss: 0.038| per_loss: 0.564 | a_loss: 0.600
Train: Epoch [559/3000], Step [120/158]| g_loss: 0.873| d_loss: 0.566| gp_loss: 0.055| r_loss: 0.135| p_loss: 0.209| v_loss: 0.038| per_loss: 0.556 | a_loss: 0.540
Train: Epoch [559/3000], Step [150/158]| g_loss: 0.869| d_loss: 0.623| gp_loss: 0.054| r_loss: 0.134| p_loss: 0.211| v_loss: 0.036| per_loss: 0.592 | a_loss: 0.534
Train: Epoch [560/3000], Step [30/158]| g_loss: 0.877| d_loss: 0.621| gp_loss: 0.089| r_loss: 0.127| p_loss: 0.205| v_loss: 0.038| per_loss: 0.538 | a_loss: 0.556
Train: Epoch [560/3000], Step [60/158]| g_loss: 0.874| d_loss: 0.674| gp_loss: 0.051| r_loss: 0.140| p_loss: 0.211| v_loss: 0.036| per_loss: 0.533 | a_loss: 0.540
Train: Epoch [560/3000], Step [90/158]| g_loss: 0.852| d_loss: 0.614| gp_loss: 0.054| r_loss: 0.130| p_loss: 0.211| v_loss: 0.037| per_loss: 0.583 | a_loss: 0.521
Train: Epoch [560/3000], Step [120/158]| g_loss: 0.906| d_loss: 0.534| gp_loss: 0.051| r_loss: 0.129| p_loss: 0.203| v_loss: 0.038| per_loss: 0.564 | a_loss: 0.581
Train: Epoch [560/3000], Step [150/158]| g_loss: 0.911| d_loss: 0.607| gp_loss: 0.049| r_loss: 0.144| p_loss: 0.206| v_loss: 0.038| per_loss: 0.576 | a_loss: 0.569
Train: Epoch [561/3000], Step [30/158]| g_loss: 0.884| d_loss: 0.611| gp_loss: 0.132| r_loss: 0.130| p_loss: 0.201| v_loss: 0.036| per_loss: 0.547 | a_loss: 0.563
Train: Epoch [561/3000], Step [60/158]| g_loss: 0.914| d_loss: 0.556| gp_loss: 0.050| r_loss: 0.136| p_loss: 0.197| v_loss: 0.037| per_loss: 0.570 | a_loss: 0.586
Train: Epoch [561/3000], Step [90/158]| g_loss: 0.843| d_loss: 0.632| gp_loss: 0.050| r_loss: 0.126| p_loss: 0.203| v_loss: 0.037| per_loss: 0.525 | a_loss: 0.527
Train: Epoch [561/3000], Step [120/158]| g_loss: 0.877| d_loss: 0.541| gp_loss: 0.055| r_loss: 0.137| p_loss: 0.210| v_loss: 0.037| per_loss: 0.557 | a_loss: 0.543
Train: Epoch [561/3000], Step [150/158]| g_loss: 0.879| d_loss: 0.583| gp_loss: 0.055| r_loss: 0.139| p_loss: 0.215| v_loss: 0.036| per_loss: 0.504 | a_loss: 0.546
Train: Epoch [562/3000], Step [30/158]| g_loss: 0.874| d_loss: 0.748| gp_loss: 0.179| r_loss: 0.134| p_loss: 0.209| v_loss: 0.035| per_loss: 0.555 | a_loss: 0.544
Train: Epoch [562/3000], Step [60/158]| g_loss: 0.852| d_loss: 0.617| gp_loss: 0.049| r_loss: 0.137| p_loss: 0.208| v_loss: 0.035| per_loss: 0.543 | a_loss: 0.522
Train: Epoch [562/3000], Step [90/158]| g_loss: 0.843| d_loss: 0.615| gp_loss: 0.052| r_loss: 0.133| p_loss: 0.208| v_loss: 0.036| per_loss: 0.559 | a_loss: 0.514
Train: Epoch [562/3000], Step [120/158]| g_loss: 0.878| d_loss: 0.555| gp_loss: 0.056| r_loss: 0.133| p_loss: 0.204| v_loss: 0.036| per_loss: 0.560 | a_loss: 0.551
Train: Epoch [562/3000], Step [150/158]| g_loss: 0.885| d_loss: 0.556| gp_loss: 0.055| r_loss: 0.127| p_loss: 0.201| v_loss: 0.035| per_loss: 0.564 | a_loss: 0.565
Train: Epoch [563/3000], Step [30/158]| g_loss: 0.887| d_loss: 0.657| gp_loss: 0.149| r_loss: 0.130| p_loss: 0.204| v_loss: 0.037| per_loss: 0.554 | a_loss: 0.562
Train: Epoch [563/3000], Step [60/158]| g_loss: 0.902| d_loss: 0.568| gp_loss: 0.049| r_loss: 0.139| p_loss: 0.215| v_loss: 0.037| per_loss: 0.583 | a_loss: 0.560
Train: Epoch [563/3000], Step [90/158]| g_loss: 0.941| d_loss: 0.514| gp_loss: 0.053| r_loss: 0.134| p_loss: 0.214| v_loss: 0.037| per_loss: 0.570 | a_loss: 0.606
Train: Epoch [563/3000], Step [120/158]| g_loss: 0.925| d_loss: 0.595| gp_loss: 0.051| r_loss: 0.132| p_loss: 0.215| v_loss: 0.037| per_loss: 0.545 | a_loss: 0.594
Train: Epoch [563/3000], Step [150/158]| g_loss: 0.783| d_loss: 0.709| gp_loss: 0.053| r_loss: 0.130| p_loss: 0.212| v_loss: 0.035| per_loss: 0.539 | a_loss: 0.457
Train: Epoch [564/3000], Step [30/158]| g_loss: 0.905| d_loss: 0.632| gp_loss: 0.115| r_loss: 0.140| p_loss: 0.223| v_loss: 0.037| per_loss: 0.598 | a_loss: 0.556
Train: Epoch [564/3000], Step [60/158]| g_loss: 0.909| d_loss: 0.569| gp_loss: 0.053| r_loss: 0.143| p_loss: 0.221| v_loss: 0.036| per_loss: 0.599 | a_loss: 0.560
Train: Epoch [564/3000], Step [90/158]| g_loss: 0.816| d_loss: 0.740| gp_loss: 0.052| r_loss: 0.144| p_loss: 0.223| v_loss: 0.035| per_loss: 0.535 | a_loss: 0.472
Train: Epoch [564/3000], Step [120/158]| g_loss: 0.824| d_loss: 0.584| gp_loss: 0.053| r_loss: 0.132| p_loss: 0.217| v_loss: 0.038| per_loss: 0.508 | a_loss: 0.494
Train: Epoch [564/3000], Step [150/158]| g_loss: 0.925| d_loss: 0.563| gp_loss: 0.049| r_loss: 0.134| p_loss: 0.216| v_loss: 0.037| per_loss: 0.542 | a_loss: 0.592
Train: Epoch [565/3000], Step [30/158]| g_loss: 0.835| d_loss: 0.688| gp_loss: 0.070| r_loss: 0.135| p_loss: 0.214| v_loss: 0.036| per_loss: 0.559 | a_loss: 0.502
Train: Epoch [565/3000], Step [60/158]| g_loss: 0.889| d_loss: 0.613| gp_loss: 0.045| r_loss: 0.131| p_loss: 0.211| v_loss: 0.038| per_loss: 0.534 | a_loss: 0.562
Train: Epoch [565/3000], Step [90/158]| g_loss: 0.878| d_loss: 0.569| gp_loss: 0.051| r_loss: 0.135| p_loss: 0.211| v_loss: 0.037| per_loss: 0.542 | a_loss: 0.547
Train: Epoch [565/3000], Step [120/158]| g_loss: 0.835| d_loss: 0.696| gp_loss: 0.051| r_loss: 0.140| p_loss: 0.215| v_loss: 0.037| per_loss: 0.554 | a_loss: 0.495
Train: Epoch [565/3000], Step [150/158]| g_loss: 0.859| d_loss: 0.528| gp_loss: 0.053| r_loss: 0.130| p_loss: 0.206| v_loss: 0.036| per_loss: 0.562 | a_loss: 0.534
Train: Epoch [566/3000], Step [30/158]| g_loss: 0.880| d_loss: 0.665| gp_loss: 0.101| r_loss: 0.141| p_loss: 0.224| v_loss: 0.036| per_loss: 0.546 | a_loss: 0.537
Train: Epoch [566/3000], Step [60/158]| g_loss: 0.899| d_loss: 0.536| gp_loss: 0.053| r_loss: 0.134| p_loss: 0.211| v_loss: 0.036| per_loss: 0.560 | a_loss: 0.568
Train: Epoch [566/3000], Step [90/158]| g_loss: 0.880| d_loss: 0.627| gp_loss: 0.051| r_loss: 0.127| p_loss: 0.211| v_loss: 0.037| per_loss: 0.485 | a_loss: 0.562
Train: Epoch [566/3000], Step [120/158]| g_loss: 0.800| d_loss: 0.671| gp_loss: 0.055| r_loss: 0.141| p_loss: 0.216| v_loss: 0.037| per_loss: 0.560 | a_loss: 0.459
Train: Epoch [566/3000], Step [150/158]| g_loss: 0.900| d_loss: 0.593| gp_loss: 0.055| r_loss: 0.130| p_loss: 0.200| v_loss: 0.036| per_loss: 0.588 | a_loss: 0.575
Train: Epoch [567/3000], Step [30/158]| g_loss: 0.853| d_loss: 0.718| gp_loss: 0.173| r_loss: 0.132| p_loss: 0.209| v_loss: 0.036| per_loss: 0.592 | a_loss: 0.521
Train: Epoch [567/3000], Step [60/158]| g_loss: 0.856| d_loss: 0.610| gp_loss: 0.049| r_loss: 0.132| p_loss: 0.200| v_loss: 0.035| per_loss: 0.542 | a_loss: 0.534
Train: Epoch [567/3000], Step [90/158]| g_loss: 0.852| d_loss: 0.531| gp_loss: 0.051| r_loss: 0.126| p_loss: 0.198| v_loss: 0.037| per_loss: 0.556 | a_loss: 0.534
Train: Epoch [567/3000], Step [120/158]| g_loss: 0.832| d_loss: 0.736| gp_loss: 0.051| r_loss: 0.137| p_loss: 0.203| v_loss: 0.036| per_loss: 0.543 | a_loss: 0.504
Train: Epoch [567/3000], Step [150/158]| g_loss: 0.884| d_loss: 0.486| gp_loss: 0.049| r_loss: 0.131| p_loss: 0.196| v_loss: 0.037| per_loss: 0.531 | a_loss: 0.565
Train: Epoch [568/3000], Step [30/158]| g_loss: 0.902| d_loss: 0.655| gp_loss: 0.120| r_loss: 0.135| p_loss: 0.200| v_loss: 0.035| per_loss: 0.534 | a_loss: 0.579
Train: Epoch [568/3000], Step [60/158]| g_loss: 0.927| d_loss: 0.496| gp_loss: 0.045| r_loss: 0.138| p_loss: 0.204| v_loss: 0.037| per_loss: 0.588 | a_loss: 0.591
Train: Epoch [568/3000], Step [90/158]| g_loss: 0.843| d_loss: 0.647| gp_loss: 0.049| r_loss: 0.125| p_loss: 0.198| v_loss: 0.035| per_loss: 0.543 | a_loss: 0.530
Train: Epoch [568/3000], Step [120/158]| g_loss: 0.810| d_loss: 0.626| gp_loss: 0.052| r_loss: 0.121| p_loss: 0.194| v_loss: 0.035| per_loss: 0.509 | a_loss: 0.505
Train: Epoch [568/3000], Step [150/158]| g_loss: 0.864| d_loss: 0.592| gp_loss: 0.049| r_loss: 0.135| p_loss: 0.209| v_loss: 0.037| per_loss: 0.520 | a_loss: 0.535
Train: Epoch [569/3000], Step [30/158]| g_loss: 0.817| d_loss: 0.727| gp_loss: 0.129| r_loss: 0.126| p_loss: 0.197| v_loss: 0.035| per_loss: 0.506 | a_loss: 0.507
Train: Epoch [569/3000], Step [60/158]| g_loss: 0.855| d_loss: 0.596| gp_loss: 0.048| r_loss: 0.134| p_loss: 0.202| v_loss: 0.035| per_loss: 0.545 | a_loss: 0.530
Train: Epoch [569/3000], Step [90/158]| g_loss: 0.907| d_loss: 0.566| gp_loss: 0.046| r_loss: 0.133| p_loss: 0.195| v_loss: 0.036| per_loss: 0.534 | a_loss: 0.587
Train: Epoch [569/3000], Step [120/158]| g_loss: 0.798| d_loss: 0.631| gp_loss: 0.053| r_loss: 0.128| p_loss: 0.195| v_loss: 0.035| per_loss: 0.543 | a_loss: 0.484
Train: Epoch [569/3000], Step [150/158]| g_loss: 0.861| d_loss: 0.597| gp_loss: 0.052| r_loss: 0.119| p_loss: 0.187| v_loss: 0.034| per_loss: 0.562 | a_loss: 0.558
Train: Epoch [570/3000], Step [30/158]| g_loss: 0.876| d_loss: 0.645| gp_loss: 0.122| r_loss: 0.128| p_loss: 0.201| v_loss: 0.036| per_loss: 0.536 | a_loss: 0.558
Train: Epoch [570/3000], Step [60/158]| g_loss: 0.850| d_loss: 0.550| gp_loss: 0.051| r_loss: 0.128| p_loss: 0.195| v_loss: 0.036| per_loss: 0.536 | a_loss: 0.534
Train: Epoch [570/3000], Step [90/158]| g_loss: 0.861| d_loss: 0.623| gp_loss: 0.049| r_loss: 0.134| p_loss: 0.201| v_loss: 0.035| per_loss: 0.472 | a_loss: 0.545
Train: Epoch [570/3000], Step [120/158]| g_loss: 0.877| d_loss: 0.522| gp_loss: 0.050| r_loss: 0.125| p_loss: 0.191| v_loss: 0.037| per_loss: 0.558 | a_loss: 0.563
Train: Epoch [570/3000], Step [150/158]| g_loss: 0.825| d_loss: 0.711| gp_loss: 0.053| r_loss: 0.128| p_loss: 0.203| v_loss: 0.035| per_loss: 0.518 | a_loss: 0.509
Train: Epoch [571/3000], Step [30/158]| g_loss: 0.819| d_loss: 0.708| gp_loss: 0.117| r_loss: 0.132| p_loss: 0.197| v_loss: 0.034| per_loss: 0.484 | a_loss: 0.506
Train: Epoch [571/3000], Step [60/158]| g_loss: 0.821| d_loss: 0.678| gp_loss: 0.048| r_loss: 0.126| p_loss: 0.203| v_loss: 0.036| per_loss: 0.518 | a_loss: 0.506
Train: Epoch [571/3000], Step [90/158]| g_loss: 0.823| d_loss: 0.617| gp_loss: 0.051| r_loss: 0.128| p_loss: 0.201| v_loss: 0.035| per_loss: 0.548 | a_loss: 0.505
Train: Epoch [571/3000], Step [120/158]| g_loss: 0.840| d_loss: 0.600| gp_loss: 0.050| r_loss: 0.133| p_loss: 0.202| v_loss: 0.036| per_loss: 0.501 | a_loss: 0.520
Train: Epoch [571/3000], Step [150/158]| g_loss: 0.883| d_loss: 0.529| gp_loss: 0.051| r_loss: 0.128| p_loss: 0.197| v_loss: 0.035| per_loss: 0.514 | a_loss: 0.570
Train: Epoch [572/3000], Step [30/158]| g_loss: 0.901| d_loss: 0.633| gp_loss: 0.146| r_loss: 0.135| p_loss: 0.198| v_loss: 0.036| per_loss: 0.479 | a_loss: 0.584
Train: Epoch [572/3000], Step [60/158]| g_loss: 0.818| d_loss: 0.690| gp_loss: 0.047| r_loss: 0.130| p_loss: 0.199| v_loss: 0.036| per_loss: 0.532 | a_loss: 0.500
Train: Epoch [572/3000], Step [90/158]| g_loss: 0.804| d_loss: 0.639| gp_loss: 0.048| r_loss: 0.126| p_loss: 0.199| v_loss: 0.036| per_loss: 0.497 | a_loss: 0.493
Train: Epoch [572/3000], Step [120/158]| g_loss: 0.844| d_loss: 0.613| gp_loss: 0.049| r_loss: 0.121| p_loss: 0.189| v_loss: 0.033| per_loss: 0.519 | a_loss: 0.543
Train: Epoch [572/3000], Step [150/158]| g_loss: 0.889| d_loss: 0.494| gp_loss: 0.052| r_loss: 0.125| p_loss: 0.198| v_loss: 0.035| per_loss: 0.526 | a_loss: 0.577
Train: Epoch [573/3000], Step [30/158]| g_loss: 0.836| d_loss: 0.700| gp_loss: 0.112| r_loss: 0.125| p_loss: 0.194| v_loss: 0.034| per_loss: 0.518 | a_loss: 0.527
Train: Epoch [573/3000], Step [60/158]| g_loss: 0.836| d_loss: 0.600| gp_loss: 0.049| r_loss: 0.127| p_loss: 0.194| v_loss: 0.034| per_loss: 0.503 | a_loss: 0.528
Train: Epoch [573/3000], Step [90/158]| g_loss: 0.814| d_loss: 0.577| gp_loss: 0.050| r_loss: 0.121| p_loss: 0.194| v_loss: 0.034| per_loss: 0.541 | a_loss: 0.508
Train: Epoch [573/3000], Step [120/158]| g_loss: 0.904| d_loss: 0.526| gp_loss: 0.050| r_loss: 0.134| p_loss: 0.196| v_loss: 0.035| per_loss: 0.529 | a_loss: 0.584
Train: Epoch [573/3000], Step [150/158]| g_loss: 0.831| d_loss: 0.615| gp_loss: 0.049| r_loss: 0.123| p_loss: 0.191| v_loss: 0.035| per_loss: 0.487 | a_loss: 0.529
Train: Epoch [574/3000], Step [30/158]| g_loss: 0.827| d_loss: 0.758| gp_loss: 0.141| r_loss: 0.127| p_loss: 0.203| v_loss: 0.035| per_loss: 0.468 | a_loss: 0.517
Train: Epoch [574/3000], Step [60/158]| g_loss: 0.890| d_loss: 0.574| gp_loss: 0.045| r_loss: 0.121| p_loss: 0.194| v_loss: 0.034| per_loss: 0.523 | a_loss: 0.585
Train: Epoch [574/3000], Step [90/158]| g_loss: 0.831| d_loss: 0.543| gp_loss: 0.047| r_loss: 0.119| p_loss: 0.196| v_loss: 0.034| per_loss: 0.509 | a_loss: 0.529
Train: Epoch [574/3000], Step [120/158]| g_loss: 0.815| d_loss: 0.675| gp_loss: 0.048| r_loss: 0.124| p_loss: 0.196| v_loss: 0.034| per_loss: 0.549 | a_loss: 0.504
Train: Epoch [574/3000], Step [150/158]| g_loss: 0.846| d_loss: 0.629| gp_loss: 0.050| r_loss: 0.142| p_loss: 0.207| v_loss: 0.034| per_loss: 0.532 | a_loss: 0.513
Train: Epoch [575/3000], Step [30/158]| g_loss: 0.899| d_loss: 0.544| gp_loss: 0.098| r_loss: 0.119| p_loss: 0.186| v_loss: 0.033| per_loss: 0.500 | a_loss: 0.603
Train: Epoch [575/3000], Step [60/158]| g_loss: 0.787| d_loss: 0.633| gp_loss: 0.052| r_loss: 0.126| p_loss: 0.191| v_loss: 0.034| per_loss: 0.487 | a_loss: 0.483
Train: Epoch [575/3000], Step [90/158]| g_loss: 0.852| d_loss: 0.556| gp_loss: 0.051| r_loss: 0.117| p_loss: 0.179| v_loss: 0.034| per_loss: 0.509 | a_loss: 0.560
Train: Epoch [575/3000], Step [120/158]| g_loss: 0.878| d_loss: 0.634| gp_loss: 0.049| r_loss: 0.134| p_loss: 0.197| v_loss: 0.035| per_loss: 0.543 | a_loss: 0.556
Train: Epoch [575/3000], Step [150/158]| g_loss: 0.837| d_loss: 0.610| gp_loss: 0.052| r_loss: 0.125| p_loss: 0.202| v_loss: 0.034| per_loss: 0.517 | a_loss: 0.525
Train: Epoch [576/3000], Step [30/158]| g_loss: 0.824| d_loss: 0.672| gp_loss: 0.108| r_loss: 0.125| p_loss: 0.191| v_loss: 0.034| per_loss: 0.498 | a_loss: 0.520
Train: Epoch [576/3000], Step [60/158]| g_loss: 0.826| d_loss: 0.634| gp_loss: 0.050| r_loss: 0.127| p_loss: 0.193| v_loss: 0.034| per_loss: 0.534 | a_loss: 0.515
Train: Epoch [576/3000], Step [90/158]| g_loss: 0.840| d_loss: 0.564| gp_loss: 0.053| r_loss: 0.122| p_loss: 0.191| v_loss: 0.034| per_loss: 0.512 | a_loss: 0.538
Train: Epoch [576/3000], Step [120/158]| g_loss: 0.889| d_loss: 0.615| gp_loss: 0.050| r_loss: 0.122| p_loss: 0.194| v_loss: 0.034| per_loss: 0.545 | a_loss: 0.582
Train: Epoch [576/3000], Step [150/158]| g_loss: 0.776| d_loss: 0.649| gp_loss: 0.052| r_loss: 0.126| p_loss: 0.191| v_loss: 0.033| per_loss: 0.503 | a_loss: 0.471
Train: Epoch [577/3000], Step [30/158]| g_loss: 0.906| d_loss: 0.584| gp_loss: 0.117| r_loss: 0.125| p_loss: 0.197| v_loss: 0.035| per_loss: 0.558 | a_loss: 0.591
Train: Epoch [577/3000], Step [60/158]| g_loss: 0.860| d_loss: 0.580| gp_loss: 0.046| r_loss: 0.119| p_loss: 0.186| v_loss: 0.034| per_loss: 0.526 | a_loss: 0.561
Train: Epoch [577/3000], Step [90/158]| g_loss: 0.789| d_loss: 0.703| gp_loss: 0.047| r_loss: 0.127| p_loss: 0.201| v_loss: 0.034| per_loss: 0.517 | a_loss: 0.476
Train: Epoch [577/3000], Step [120/158]| g_loss: 0.780| d_loss: 0.604| gp_loss: 0.050| r_loss: 0.126| p_loss: 0.189| v_loss: 0.033| per_loss: 0.480 | a_loss: 0.478
Train: Epoch [577/3000], Step [150/158]| g_loss: 0.882| d_loss: 0.573| gp_loss: 0.052| r_loss: 0.137| p_loss: 0.198| v_loss: 0.034| per_loss: 0.506 | a_loss: 0.562
Train: Epoch [578/3000], Step [30/158]| g_loss: 0.858| d_loss: 0.716| gp_loss: 0.188| r_loss: 0.118| p_loss: 0.186| v_loss: 0.034| per_loss: 0.533 | a_loss: 0.560
Train: Epoch [578/3000], Step [60/158]| g_loss: 0.876| d_loss: 0.494| gp_loss: 0.046| r_loss: 0.124| p_loss: 0.188| v_loss: 0.033| per_loss: 0.513 | a_loss: 0.574
Train: Epoch [578/3000], Step [90/158]| g_loss: 0.842| d_loss: 0.637| gp_loss: 0.043| r_loss: 0.127| p_loss: 0.190| v_loss: 0.034| per_loss: 0.478 | a_loss: 0.538
Train: Epoch [578/3000], Step [120/158]| g_loss: 0.803| d_loss: 0.625| gp_loss: 0.050| r_loss: 0.121| p_loss: 0.190| v_loss: 0.035| per_loss: 0.543 | a_loss: 0.498
Train: Epoch [578/3000], Step [150/158]| g_loss: 0.815| d_loss: 0.661| gp_loss: 0.049| r_loss: 0.127| p_loss: 0.195| v_loss: 0.034| per_loss: 0.504 | a_loss: 0.506
Train: Epoch [579/3000], Step [30/158]| g_loss: 0.858| d_loss: 0.665| gp_loss: 0.142| r_loss: 0.124| p_loss: 0.199| v_loss: 0.035| per_loss: 0.534 | a_loss: 0.547
Train: Epoch [579/3000], Step [60/158]| g_loss: 0.829| d_loss: 0.582| gp_loss: 0.048| r_loss: 0.123| p_loss: 0.187| v_loss: 0.034| per_loss: 0.500 | a_loss: 0.529
Train: Epoch [579/3000], Step [90/158]| g_loss: 0.865| d_loss: 0.535| gp_loss: 0.047| r_loss: 0.123| p_loss: 0.193| v_loss: 0.035| per_loss: 0.472 | a_loss: 0.562
Train: Epoch [579/3000], Step [120/158]| g_loss: 0.894| d_loss: 0.587| gp_loss: 0.046| r_loss: 0.128| p_loss: 0.196| v_loss: 0.035| per_loss: 0.517 | a_loss: 0.582
Train: Epoch [579/3000], Step [150/158]| g_loss: 0.784| d_loss: 0.664| gp_loss: 0.051| r_loss: 0.117| p_loss: 0.180| v_loss: 0.033| per_loss: 0.511 | a_loss: 0.494
Train: Epoch [580/3000], Step [30/158]| g_loss: 0.833| d_loss: 0.654| gp_loss: 0.109| r_loss: 0.131| p_loss: 0.196| v_loss: 0.033| per_loss: 0.506 | a_loss: 0.520
Train: Epoch [580/3000], Step [60/158]| g_loss: 0.891| d_loss: 0.527| gp_loss: 0.048| r_loss: 0.127| p_loss: 0.194| v_loss: 0.034| per_loss: 0.493 | a_loss: 0.584
Train: Epoch [580/3000], Step [90/158]| g_loss: 0.838| d_loss: 0.617| gp_loss: 0.049| r_loss: 0.123| p_loss: 0.196| v_loss: 0.034| per_loss: 0.509 | a_loss: 0.532
Train: Epoch [580/3000], Step [120/158]| g_loss: 0.803| d_loss: 0.647| gp_loss: 0.049| r_loss: 0.124| p_loss: 0.191| v_loss: 0.035| per_loss: 0.501 | a_loss: 0.498
Train: Epoch [580/3000], Step [150/158]| g_loss: 0.812| d_loss: 0.590| gp_loss: 0.054| r_loss: 0.112| p_loss: 0.188| v_loss: 0.033| per_loss: 0.511 | a_loss: 0.522
Train: Epoch [581/3000], Step [30/158]| g_loss: 0.901| d_loss: 0.614| gp_loss: 0.142| r_loss: 0.123| p_loss: 0.193| v_loss: 0.033| per_loss: 0.509 | a_loss: 0.596
Train: Epoch [581/3000], Step [60/158]| g_loss: 0.789| d_loss: 0.685| gp_loss: 0.047| r_loss: 0.126| p_loss: 0.192| v_loss: 0.035| per_loss: 0.497 | a_loss: 0.483
Train: Epoch [581/3000], Step [90/158]| g_loss: 0.758| d_loss: 0.688| gp_loss: 0.050| r_loss: 0.120| p_loss: 0.198| v_loss: 0.032| per_loss: 0.461 | a_loss: 0.462
Train: Epoch [581/3000], Step [120/158]| g_loss: 0.831| d_loss: 0.613| gp_loss: 0.050| r_loss: 0.117| p_loss: 0.186| v_loss: 0.034| per_loss: 0.460 | a_loss: 0.542
Train: Epoch [581/3000], Step [150/158]| g_loss: 0.888| d_loss: 0.488| gp_loss: 0.052| r_loss: 0.123| p_loss: 0.189| v_loss: 0.035| per_loss: 0.530 | a_loss: 0.583
Train: Epoch [582/3000], Step [30/158]| g_loss: 0.876| d_loss: 0.666| gp_loss: 0.180| r_loss: 0.120| p_loss: 0.179| v_loss: 0.034| per_loss: 0.478 | a_loss: 0.584
Train: Epoch [582/3000], Step [60/158]| g_loss: 0.841| d_loss: 0.653| gp_loss: 0.046| r_loss: 0.124| p_loss: 0.193| v_loss: 0.034| per_loss: 0.506 | a_loss: 0.536
Train: Epoch [582/3000], Step [90/158]| g_loss: 0.799| d_loss: 0.603| gp_loss: 0.046| r_loss: 0.121| p_loss: 0.187| v_loss: 0.033| per_loss: 0.477 | a_loss: 0.504
Train: Epoch [582/3000], Step [120/158]| g_loss: 0.804| d_loss: 0.592| gp_loss: 0.049| r_loss: 0.122| p_loss: 0.195| v_loss: 0.033| per_loss: 0.481 | a_loss: 0.504
Train: Epoch [582/3000], Step [150/158]| g_loss: 0.856| d_loss: 0.559| gp_loss: 0.049| r_loss: 0.126| p_loss: 0.192| v_loss: 0.032| per_loss: 0.524 | a_loss: 0.549
Train: Epoch [583/3000], Step [30/158]| g_loss: 0.861| d_loss: 0.717| gp_loss: 0.191| r_loss: 0.119| p_loss: 0.188| v_loss: 0.033| per_loss: 0.485 | a_loss: 0.568
Train: Epoch [583/3000], Step [60/158]| g_loss: 0.836| d_loss: 0.540| gp_loss: 0.047| r_loss: 0.117| p_loss: 0.181| v_loss: 0.033| per_loss: 0.489 | a_loss: 0.547
Train: Epoch [583/3000], Step [90/158]| g_loss: 0.876| d_loss: 0.552| gp_loss: 0.047| r_loss: 0.122| p_loss: 0.191| v_loss: 0.033| per_loss: 0.513 | a_loss: 0.574
Train: Epoch [583/3000], Step [120/158]| g_loss: 0.823| d_loss: 0.609| gp_loss: 0.048| r_loss: 0.122| p_loss: 0.196| v_loss: 0.035| per_loss: 0.468 | a_loss: 0.522
Train: Epoch [583/3000], Step [150/158]| g_loss: 0.839| d_loss: 0.644| gp_loss: 0.047| r_loss: 0.128| p_loss: 0.196| v_loss: 0.034| per_loss: 0.498 | a_loss: 0.529
Train: Epoch [584/3000], Step [30/158]| g_loss: 0.788| d_loss: 0.692| gp_loss: 0.091| r_loss: 0.119| p_loss: 0.197| v_loss: 0.033| per_loss: 0.482 | a_loss: 0.490
Train: Epoch [584/3000], Step [60/158]| g_loss: 0.844| d_loss: 0.600| gp_loss: 0.045| r_loss: 0.128| p_loss: 0.199| v_loss: 0.033| per_loss: 0.494 | a_loss: 0.535
Train: Epoch [584/3000], Step [90/158]| g_loss: 0.832| d_loss: 0.594| gp_loss: 0.047| r_loss: 0.124| p_loss: 0.190| v_loss: 0.033| per_loss: 0.465 | a_loss: 0.534
Train: Epoch [584/3000], Step [120/158]| g_loss: 0.850| d_loss: 0.568| gp_loss: 0.045| r_loss: 0.120| p_loss: 0.194| v_loss: 0.034| per_loss: 0.519 | a_loss: 0.547
Train: Epoch [584/3000], Step [150/158]| g_loss: 0.818| d_loss: 0.633| gp_loss: 0.052| r_loss: 0.130| p_loss: 0.195| v_loss: 0.034| per_loss: 0.512 | a_loss: 0.505
Train: Epoch [585/3000], Step [30/158]| g_loss: 0.853| d_loss: 0.626| gp_loss: 0.116| r_loss: 0.119| p_loss: 0.187| v_loss: 0.034| per_loss: 0.453 | a_loss: 0.561
Train: Epoch [585/3000], Step [60/158]| g_loss: 0.823| d_loss: 0.578| gp_loss: 0.049| r_loss: 0.124| p_loss: 0.193| v_loss: 0.033| per_loss: 0.511 | a_loss: 0.519
Train: Epoch [585/3000], Step [90/158]| g_loss: 0.792| d_loss: 0.660| gp_loss: 0.048| r_loss: 0.123| p_loss: 0.188| v_loss: 0.034| per_loss: 0.504 | a_loss: 0.491
Train: Epoch [585/3000], Step [120/158]| g_loss: 0.825| d_loss: 0.624| gp_loss: 0.049| r_loss: 0.120| p_loss: 0.190| v_loss: 0.033| per_loss: 0.521 | a_loss: 0.526
Train: Epoch [585/3000], Step [150/158]| g_loss: 0.842| d_loss: 0.558| gp_loss: 0.053| r_loss: 0.118| p_loss: 0.188| v_loss: 0.034| per_loss: 0.528 | a_loss: 0.543
Train: Epoch [586/3000], Step [30/158]| g_loss: 0.810| d_loss: 0.805| gp_loss: 0.127| r_loss: 0.120| p_loss: 0.196| v_loss: 0.033| per_loss: 0.501 | a_loss: 0.509
Train: Epoch [586/3000], Step [60/158]| g_loss: 0.823| d_loss: 0.654| gp_loss: 0.042| r_loss: 0.127| p_loss: 0.205| v_loss: 0.036| per_loss: 0.513 | a_loss: 0.506
Train: Epoch [586/3000], Step [90/158]| g_loss: 0.859| d_loss: 0.568| gp_loss: 0.049| r_loss: 0.119| p_loss: 0.194| v_loss: 0.033| per_loss: 0.531 | a_loss: 0.557
Train: Epoch [586/3000], Step [120/158]| g_loss: 0.819| d_loss: 0.607| gp_loss: 0.047| r_loss: 0.125| p_loss: 0.186| v_loss: 0.033| per_loss: 0.510 | a_loss: 0.517
Train: Epoch [586/3000], Step [150/158]| g_loss: 0.836| d_loss: 0.577| gp_loss: 0.047| r_loss: 0.119| p_loss: 0.185| v_loss: 0.033| per_loss: 0.489 | a_loss: 0.542
Train: Epoch [587/3000], Step [30/158]| g_loss: 0.867| d_loss: 0.599| gp_loss: 0.076| r_loss: 0.129| p_loss: 0.204| v_loss: 0.035| per_loss: 0.525 | a_loss: 0.549
Train: Epoch [587/3000], Step [60/158]| g_loss: 0.879| d_loss: 0.619| gp_loss: 0.046| r_loss: 0.127| p_loss: 0.197| v_loss: 0.033| per_loss: 0.472 | a_loss: 0.574
Train: Epoch [587/3000], Step [90/158]| g_loss: 0.755| d_loss: 0.714| gp_loss: 0.049| r_loss: 0.122| p_loss: 0.191| v_loss: 0.033| per_loss: 0.513 | a_loss: 0.453
Train: Epoch [587/3000], Step [120/158]| g_loss: 0.844| d_loss: 0.568| gp_loss: 0.048| r_loss: 0.121| p_loss: 0.188| v_loss: 0.035| per_loss: 0.536 | a_loss: 0.540
Train: Epoch [587/3000], Step [150/158]| g_loss: 0.820| d_loss: 0.639| gp_loss: 0.048| r_loss: 0.119| p_loss: 0.189| v_loss: 0.034| per_loss: 0.474 | a_loss: 0.525
Train: Epoch [588/3000], Step [30/158]| g_loss: 0.743| d_loss: 0.745| gp_loss: 0.131| r_loss: 0.115| p_loss: 0.182| v_loss: 0.033| per_loss: 0.477 | a_loss: 0.457
Train: Epoch [588/3000], Step [60/158]| g_loss: 0.797| d_loss: 0.573| gp_loss: 0.053| r_loss: 0.121| p_loss: 0.191| v_loss: 0.034| per_loss: 0.459 | a_loss: 0.501
Train: Epoch [588/3000], Step [90/158]| g_loss: 0.875| d_loss: 0.587| gp_loss: 0.052| r_loss: 0.126| p_loss: 0.197| v_loss: 0.034| per_loss: 0.488 | a_loss: 0.568
Train: Epoch [588/3000], Step [120/158]| g_loss: 0.816| d_loss: 0.606| gp_loss: 0.049| r_loss: 0.122| p_loss: 0.196| v_loss: 0.033| per_loss: 0.496 | a_loss: 0.513
Train: Epoch [588/3000], Step [150/158]| g_loss: 0.895| d_loss: 0.544| gp_loss: 0.051| r_loss: 0.125| p_loss: 0.194| v_loss: 0.035| per_loss: 0.544 | a_loss: 0.584
Train: Epoch [589/3000], Step [30/158]| g_loss: 0.878| d_loss: 0.614| gp_loss: 0.166| r_loss: 0.111| p_loss: 0.180| v_loss: 0.034| per_loss: 0.515 | a_loss: 0.592
Train: Epoch [589/3000], Step [60/158]| g_loss: 0.806| d_loss: 0.657| gp_loss: 0.049| r_loss: 0.126| p_loss: 0.180| v_loss: 0.034| per_loss: 0.480 | a_loss: 0.508
Train: Epoch [589/3000], Step [90/158]| g_loss: 0.842| d_loss: 0.572| gp_loss: 0.050| r_loss: 0.119| p_loss: 0.189| v_loss: 0.035| per_loss: 0.480 | a_loss: 0.546
Train: Epoch [589/3000], Step [120/158]| g_loss: 0.802| d_loss: 0.611| gp_loss: 0.048| r_loss: 0.119| p_loss: 0.183| v_loss: 0.034| per_loss: 0.520 | a_loss: 0.506
Train: Epoch [589/3000], Step [150/158]| g_loss: 0.767| d_loss: 0.683| gp_loss: 0.050| r_loss: 0.120| p_loss: 0.178| v_loss: 0.033| per_loss: 0.470 | a_loss: 0.478
Train: Epoch [590/3000], Step [30/158]| g_loss: 0.815| d_loss: 0.648| gp_loss: 0.088| r_loss: 0.118| p_loss: 0.193| v_loss: 0.034| per_loss: 0.499 | a_loss: 0.516
Train: Epoch [590/3000], Step [60/158]| g_loss: 0.817| d_loss: 0.619| gp_loss: 0.052| r_loss: 0.118| p_loss: 0.177| v_loss: 0.033| per_loss: 0.483 | a_loss: 0.528
Train: Epoch [590/3000], Step [90/158]| g_loss: 0.827| d_loss: 0.614| gp_loss: 0.054| r_loss: 0.116| p_loss: 0.183| v_loss: 0.035| per_loss: 0.478 | a_loss: 0.537
Train: Epoch [590/3000], Step [120/158]| g_loss: 0.831| d_loss: 0.611| gp_loss: 0.051| r_loss: 0.112| p_loss: 0.178| v_loss: 0.034| per_loss: 0.499 | a_loss: 0.546
Train: Epoch [590/3000], Step [150/158]| g_loss: 0.848| d_loss: 0.571| gp_loss: 0.051| r_loss: 0.131| p_loss: 0.189| v_loss: 0.036| per_loss: 0.499 | a_loss: 0.537
Train: Epoch [591/3000], Step [30/158]| g_loss: 0.882| d_loss: 0.600| gp_loss: 0.138| r_loss: 0.118| p_loss: 0.180| v_loss: 0.034| per_loss: 0.486 | a_loss: 0.592
Train: Epoch [591/3000], Step [60/158]| g_loss: 0.809| d_loss: 0.587| gp_loss: 0.047| r_loss: 0.108| p_loss: 0.172| v_loss: 0.034| per_loss: 0.512 | a_loss: 0.531
Train: Epoch [591/3000], Step [90/158]| g_loss: 0.818| d_loss: 0.635| gp_loss: 0.050| r_loss: 0.120| p_loss: 0.180| v_loss: 0.033| per_loss: 0.486 | a_loss: 0.525
Train: Epoch [591/3000], Step [120/158]| g_loss: 0.773| d_loss: 0.667| gp_loss: 0.054| r_loss: 0.123| p_loss: 0.181| v_loss: 0.035| per_loss: 0.521 | a_loss: 0.473
Train: Epoch [591/3000], Step [150/158]| g_loss: 0.876| d_loss: 0.500| gp_loss: 0.051| r_loss: 0.120| p_loss: 0.188| v_loss: 0.035| per_loss: 0.449 | a_loss: 0.581
Train: Epoch [592/3000], Step [30/158]| g_loss: 0.821| d_loss: 0.733| gp_loss: 0.132| r_loss: 0.124| p_loss: 0.186| v_loss: 0.034| per_loss: 0.513 | a_loss: 0.518
Train: Epoch [592/3000], Step [60/158]| g_loss: 0.859| d_loss: 0.541| gp_loss: 0.051| r_loss: 0.115| p_loss: 0.173| v_loss: 0.034| per_loss: 0.490 | a_loss: 0.574
Train: Epoch [592/3000], Step [90/158]| g_loss: 0.819| d_loss: 0.579| gp_loss: 0.051| r_loss: 0.116| p_loss: 0.176| v_loss: 0.034| per_loss: 0.493 | a_loss: 0.532
Train: Epoch [592/3000], Step [120/158]| g_loss: 0.811| d_loss: 0.647| gp_loss: 0.051| r_loss: 0.123| p_loss: 0.186| v_loss: 0.035| per_loss: 0.501 | a_loss: 0.509
Train: Epoch [592/3000], Step [150/158]| g_loss: 0.819| d_loss: 0.597| gp_loss: 0.054| r_loss: 0.115| p_loss: 0.176| v_loss: 0.033| per_loss: 0.468 | a_loss: 0.536
Train: Epoch [593/3000], Step [30/158]| g_loss: 0.794| d_loss: 0.721| gp_loss: 0.128| r_loss: 0.115| p_loss: 0.180| v_loss: 0.033| per_loss: 0.498 | a_loss: 0.506
Train: Epoch [593/3000], Step [60/158]| g_loss: 0.814| d_loss: 0.562| gp_loss: 0.048| r_loss: 0.117| p_loss: 0.184| v_loss: 0.034| per_loss: 0.479 | a_loss: 0.523
Train: Epoch [593/3000], Step [90/158]| g_loss: 0.866| d_loss: 0.553| gp_loss: 0.049| r_loss: 0.125| p_loss: 0.185| v_loss: 0.035| per_loss: 0.478 | a_loss: 0.565
Train: Epoch [593/3000], Step [120/158]| g_loss: 0.809| d_loss: 0.643| gp_loss: 0.055| r_loss: 0.115| p_loss: 0.176| v_loss: 0.032| per_loss: 0.506 | a_loss: 0.523
Train: Epoch [593/3000], Step [150/158]| g_loss: 0.860| d_loss: 0.558| gp_loss: 0.053| r_loss: 0.123| p_loss: 0.189| v_loss: 0.035| per_loss: 0.510 | a_loss: 0.556
Train: Epoch [594/3000], Step [30/158]| g_loss: 0.826| d_loss: 0.676| gp_loss: 0.131| r_loss: 0.120| p_loss: 0.182| v_loss: 0.034| per_loss: 0.507 | a_loss: 0.529
Train: Epoch [594/3000], Step [60/158]| g_loss: 0.738| d_loss: 0.642| gp_loss: 0.050| r_loss: 0.109| p_loss: 0.172| v_loss: 0.032| per_loss: 0.493 | a_loss: 0.461
Train: Epoch [594/3000], Step [90/158]| g_loss: 0.855| d_loss: 0.636| gp_loss: 0.054| r_loss: 0.126| p_loss: 0.185| v_loss: 0.034| per_loss: 0.486 | a_loss: 0.554
Train: Epoch [594/3000], Step [120/158]| g_loss: 0.811| d_loss: 0.610| gp_loss: 0.057| r_loss: 0.120| p_loss: 0.189| v_loss: 0.033| per_loss: 0.521 | a_loss: 0.512
Train: Epoch [594/3000], Step [150/158]| g_loss: 0.870| d_loss: 0.489| gp_loss: 0.054| r_loss: 0.116| p_loss: 0.174| v_loss: 0.034| per_loss: 0.500 | a_loss: 0.583
Train: Epoch [595/3000], Step [30/158]| g_loss: 0.827| d_loss: 0.704| gp_loss: 0.181| r_loss: 0.111| p_loss: 0.177| v_loss: 0.033| per_loss: 0.482 | a_loss: 0.546
Train: Epoch [595/3000], Step [60/158]| g_loss: 0.823| d_loss: 0.572| gp_loss: 0.051| r_loss: 0.118| p_loss: 0.178| v_loss: 0.033| per_loss: 0.511 | a_loss: 0.532
Train: Epoch [595/3000], Step [90/158]| g_loss: 0.812| d_loss: 0.637| gp_loss: 0.053| r_loss: 0.118| p_loss: 0.184| v_loss: 0.035| per_loss: 0.513 | a_loss: 0.516
Train: Epoch [595/3000], Step [120/158]| g_loss: 0.845| d_loss: 0.620| gp_loss: 0.049| r_loss: 0.132| p_loss: 0.189| v_loss: 0.034| per_loss: 0.529 | a_loss: 0.531
Train: Epoch [595/3000], Step [150/158]| g_loss: 0.818| d_loss: 0.561| gp_loss: 0.054| r_loss: 0.115| p_loss: 0.181| v_loss: 0.034| per_loss: 0.483 | a_loss: 0.531
Train: Epoch [596/3000], Step [30/158]| g_loss: 0.852| d_loss: 0.712| gp_loss: 0.180| r_loss: 0.125| p_loss: 0.192| v_loss: 0.033| per_loss: 0.486 | a_loss: 0.548
Train: Epoch [596/3000], Step [60/158]| g_loss: 0.750| d_loss: 0.707| gp_loss: 0.052| r_loss: 0.118| p_loss: 0.187| v_loss: 0.034| per_loss: 0.496 | a_loss: 0.455
Train: Epoch [596/3000], Step [90/158]| g_loss: 0.865| d_loss: 0.561| gp_loss: 0.048| r_loss: 0.121| p_loss: 0.189| v_loss: 0.034| per_loss: 0.499 | a_loss: 0.566
Train: Epoch [596/3000], Step [120/158]| g_loss: 0.873| d_loss: 0.539| gp_loss: 0.049| r_loss: 0.115| p_loss: 0.181| v_loss: 0.033| per_loss: 0.515 | a_loss: 0.583
Train: Epoch [596/3000], Step [150/158]| g_loss: 0.860| d_loss: 0.631| gp_loss: 0.049| r_loss: 0.125| p_loss: 0.197| v_loss: 0.034| per_loss: 0.497 | a_loss: 0.553
Train: Epoch [597/3000], Step [30/158]| g_loss: 0.780| d_loss: 0.717| gp_loss: 0.115| r_loss: 0.121| p_loss: 0.192| v_loss: 0.033| per_loss: 0.493 | a_loss: 0.481
Train: Epoch [597/3000], Step [60/158]| g_loss: 0.823| d_loss: 0.661| gp_loss: 0.042| r_loss: 0.121| p_loss: 0.200| v_loss: 0.035| per_loss: 0.465 | a_loss: 0.521
Train: Epoch [597/3000], Step [90/158]| g_loss: 0.796| d_loss: 0.603| gp_loss: 0.048| r_loss: 0.121| p_loss: 0.186| v_loss: 0.035| per_loss: 0.528 | a_loss: 0.494
Train: Epoch [597/3000], Step [120/158]| g_loss: 0.884| d_loss: 0.597| gp_loss: 0.044| r_loss: 0.115| p_loss: 0.194| v_loss: 0.034| per_loss: 0.511 | a_loss: 0.587
Train: Epoch [597/3000], Step [150/158]| g_loss: 0.809| d_loss: 0.605| gp_loss: 0.054| r_loss: 0.129| p_loss: 0.196| v_loss: 0.033| per_loss: 0.456 | a_loss: 0.502
Train: Epoch [598/3000], Step [30/158]| g_loss: 0.866| d_loss: 0.678| gp_loss: 0.145| r_loss: 0.123| p_loss: 0.192| v_loss: 0.034| per_loss: 0.510 | a_loss: 0.562
Train: Epoch [598/3000], Step [60/158]| g_loss: 0.816| d_loss: 0.575| gp_loss: 0.046| r_loss: 0.113| p_loss: 0.181| v_loss: 0.034| per_loss: 0.442 | a_loss: 0.534
Train: Epoch [598/3000], Step [90/158]| g_loss: 0.816| d_loss: 0.624| gp_loss: 0.047| r_loss: 0.117| p_loss: 0.183| v_loss: 0.033| per_loss: 0.483 | a_loss: 0.526
Train: Epoch [598/3000], Step [120/158]| g_loss: 0.824| d_loss: 0.601| gp_loss: 0.052| r_loss: 0.123| p_loss: 0.193| v_loss: 0.034| per_loss: 0.456 | a_loss: 0.524
Train: Epoch [598/3000], Step [150/158]| g_loss: 0.824| d_loss: 0.625| gp_loss: 0.050| r_loss: 0.119| p_loss: 0.189| v_loss: 0.035| per_loss: 0.511 | a_loss: 0.525
Train: Epoch [599/3000], Step [30/158]| g_loss: 0.850| d_loss: 0.636| gp_loss: 0.128| r_loss: 0.122| p_loss: 0.186| v_loss: 0.034| per_loss: 0.469 | a_loss: 0.555
Train: Epoch [599/3000], Step [60/158]| g_loss: 0.832| d_loss: 0.583| gp_loss: 0.050| r_loss: 0.124| p_loss: 0.189| v_loss: 0.034| per_loss: 0.453 | a_loss: 0.534
Train: Epoch [599/3000], Step [90/158]| g_loss: 0.856| d_loss: 0.561| gp_loss: 0.049| r_loss: 0.113| p_loss: 0.185| v_loss: 0.034| per_loss: 0.499 | a_loss: 0.567
Train: Epoch [599/3000], Step [120/158]| g_loss: 0.808| d_loss: 0.590| gp_loss: 0.050| r_loss: 0.120| p_loss: 0.179| v_loss: 0.033| per_loss: 0.471 | a_loss: 0.517
Train: Epoch [599/3000], Step [150/158]| g_loss: 0.809| d_loss: 0.687| gp_loss: 0.051| r_loss: 0.115| p_loss: 0.187| v_loss: 0.034| per_loss: 0.482 | a_loss: 0.519
Train: Epoch [600/3000], Step [30/158]| g_loss: 0.859| d_loss: 0.616| gp_loss: 0.118| r_loss: 0.119| p_loss: 0.187| v_loss: 0.034| per_loss: 0.493 | a_loss: 0.563
Train: Epoch [600/3000], Step [60/158]| g_loss: 0.820| d_loss: 0.589| gp_loss: 0.049| r_loss: 0.122| p_loss: 0.184| v_loss: 0.033| per_loss: 0.501 | a_loss: 0.523
Train: Epoch [600/3000], Step [90/158]| g_loss: 0.838| d_loss: 0.592| gp_loss: 0.049| r_loss: 0.122| p_loss: 0.180| v_loss: 0.035| per_loss: 0.489 | a_loss: 0.542
Train: Epoch [600/3000], Step [120/158]| g_loss: 0.745| d_loss: 0.702| gp_loss: 0.052| r_loss: 0.116| p_loss: 0.179| v_loss: 0.033| per_loss: 0.467 | a_loss: 0.460
Train: Epoch [600/3000], Step [150/158]| g_loss: 0.865| d_loss: 0.516| gp_loss: 0.048| r_loss: 0.115| p_loss: 0.180| v_loss: 0.033| per_loss: 0.462 | a_loss: 0.580
Test: Epoch [600/3000]| g_loss: 0.689| r_loss: 0.431| p_loss: 0.314| v_loss: 0.026
Train: Epoch [601/3000], Step [30/158]| g_loss: 0.854| d_loss: 0.534| gp_loss: 0.048| r_loss: 0.122| p_loss: 0.177| v_loss: 0.033| per_loss: 0.474 | a_loss: 0.564
Train: Epoch [601/3000], Step [60/158]| g_loss: 0.850| d_loss: 0.557| gp_loss: 0.048| r_loss: 0.128| p_loss: 0.190| v_loss: 0.035| per_loss: 0.484 | a_loss: 0.544
Train: Epoch [601/3000], Step [90/158]| g_loss: 0.837| d_loss: 0.647| gp_loss: 0.048| r_loss: 0.115| p_loss: 0.181| v_loss: 0.035| per_loss: 0.505 | a_loss: 0.546
Train: Epoch [601/3000], Step [120/158]| g_loss: 0.750| d_loss: 0.701| gp_loss: 0.049| r_loss: 0.109| p_loss: 0.175| v_loss: 0.033| per_loss: 0.474 | a_loss: 0.474
Train: Epoch [601/3000], Step [150/158]| g_loss: 0.795| d_loss: 0.560| gp_loss: 0.054| r_loss: 0.111| p_loss: 0.170| v_loss: 0.033| per_loss: 0.451 | a_loss: 0.521
Train: Epoch [602/3000], Step [30/158]| g_loss: 0.848| d_loss: 0.566| gp_loss: 0.097| r_loss: 0.116| p_loss: 0.170| v_loss: 0.033| per_loss: 0.486 | a_loss: 0.565
Train: Epoch [602/3000], Step [60/158]| g_loss: 0.808| d_loss: 0.662| gp_loss: 0.050| r_loss: 0.122| p_loss: 0.182| v_loss: 0.033| per_loss: 0.492 | a_loss: 0.512
Train: Epoch [602/3000], Step [90/158]| g_loss: 0.777| d_loss: 0.614| gp_loss: 0.053| r_loss: 0.117| p_loss: 0.180| v_loss: 0.033| per_loss: 0.457 | a_loss: 0.492
Train: Epoch [602/3000], Step [120/158]| g_loss: 0.873| d_loss: 0.584| gp_loss: 0.056| r_loss: 0.124| p_loss: 0.185| v_loss: 0.035| per_loss: 0.484 | a_loss: 0.574
Train: Epoch [602/3000], Step [150/158]| g_loss: 0.838| d_loss: 0.582| gp_loss: 0.049| r_loss: 0.114| p_loss: 0.182| v_loss: 0.033| per_loss: 0.484 | a_loss: 0.552
Train: Epoch [603/3000], Step [30/158]| g_loss: 0.796| d_loss: 0.760| gp_loss: 0.154| r_loss: 0.117| p_loss: 0.184| v_loss: 0.032| per_loss: 0.482 | a_loss: 0.507
Train: Epoch [603/3000], Step [60/158]| g_loss: 0.786| d_loss: 0.654| gp_loss: 0.048| r_loss: 0.109| p_loss: 0.173| v_loss: 0.033| per_loss: 0.462 | a_loss: 0.512
Train: Epoch [603/3000], Step [90/158]| g_loss: 0.821| d_loss: 0.585| gp_loss: 0.052| r_loss: 0.124| p_loss: 0.176| v_loss: 0.032| per_loss: 0.472 | a_loss: 0.530
Train: Epoch [603/3000], Step [120/158]| g_loss: 0.819| d_loss: 0.594| gp_loss: 0.049| r_loss: 0.114| p_loss: 0.178| v_loss: 0.032| per_loss: 0.473 | a_loss: 0.536
Train: Epoch [603/3000], Step [150/158]| g_loss: 0.840| d_loss: 0.502| gp_loss: 0.051| r_loss: 0.120| p_loss: 0.182| v_loss: 0.035| per_loss: 0.489 | a_loss: 0.546
Train: Epoch [604/3000], Step [30/158]| g_loss: 0.856| d_loss: 0.647| gp_loss: 0.125| r_loss: 0.120| p_loss: 0.181| v_loss: 0.032| per_loss: 0.466 | a_loss: 0.568
Train: Epoch [604/3000], Step [60/158]| g_loss: 0.795| d_loss: 0.647| gp_loss: 0.052| r_loss: 0.121| p_loss: 0.180| v_loss: 0.034| per_loss: 0.459 | a_loss: 0.504
Train: Epoch [604/3000], Step [90/158]| g_loss: 0.849| d_loss: 0.602| gp_loss: 0.049| r_loss: 0.121| p_loss: 0.187| v_loss: 0.033| per_loss: 0.500 | a_loss: 0.551
Train: Epoch [604/3000], Step [120/158]| g_loss: 0.764| d_loss: 0.638| gp_loss: 0.056| r_loss: 0.113| p_loss: 0.178| v_loss: 0.033| per_loss: 0.494 | a_loss: 0.480
Train: Epoch [604/3000], Step [150/158]| g_loss: 0.838| d_loss: 0.533| gp_loss: 0.053| r_loss: 0.115| p_loss: 0.186| v_loss: 0.034| per_loss: 0.506 | a_loss: 0.546
Train: Epoch [605/3000], Step [30/158]| g_loss: 0.898| d_loss: 0.690| gp_loss: 0.190| r_loss: 0.126| p_loss: 0.195| v_loss: 0.034| per_loss: 0.502 | a_loss: 0.591
Train: Epoch [605/3000], Step [60/158]| g_loss: 0.778| d_loss: 0.744| gp_loss: 0.048| r_loss: 0.121| p_loss: 0.195| v_loss: 0.033| per_loss: 0.481 | a_loss: 0.479
Train: Epoch [605/3000], Step [90/158]| g_loss: 0.845| d_loss: 0.589| gp_loss: 0.050| r_loss: 0.134| p_loss: 0.202| v_loss: 0.035| per_loss: 0.508 | a_loss: 0.524
Train: Epoch [605/3000], Step [120/158]| g_loss: 0.825| d_loss: 0.595| gp_loss: 0.053| r_loss: 0.115| p_loss: 0.193| v_loss: 0.034| per_loss: 0.490 | a_loss: 0.531
Train: Epoch [605/3000], Step [150/158]| g_loss: 0.871| d_loss: 0.535| gp_loss: 0.046| r_loss: 0.112| p_loss: 0.183| v_loss: 0.034| per_loss: 0.500 | a_loss: 0.584
Train: Epoch [606/3000], Step [30/158]| g_loss: 0.917| d_loss: 0.518| gp_loss: 0.100| r_loss: 0.126| p_loss: 0.195| v_loss: 0.035| per_loss: 0.483 | a_loss: 0.609
Train: Epoch [606/3000], Step [60/158]| g_loss: 0.874| d_loss: 0.535| gp_loss: 0.052| r_loss: 0.113| p_loss: 0.178| v_loss: 0.033| per_loss: 0.469 | a_loss: 0.592
Train: Epoch [606/3000], Step [90/158]| g_loss: 0.853| d_loss: 0.611| gp_loss: 0.048| r_loss: 0.123| p_loss: 0.187| v_loss: 0.034| per_loss: 0.500 | a_loss: 0.554
Train: Epoch [606/3000], Step [120/158]| g_loss: 0.802| d_loss: 0.602| gp_loss: 0.052| r_loss: 0.114| p_loss: 0.184| v_loss: 0.035| per_loss: 0.457 | a_loss: 0.515
Train: Epoch [606/3000], Step [150/158]| g_loss: 0.759| d_loss: 0.702| gp_loss: 0.051| r_loss: 0.116| p_loss: 0.184| v_loss: 0.033| per_loss: 0.475 | a_loss: 0.470
Train: Epoch [607/3000], Step [30/158]| g_loss: 0.767| d_loss: 0.742| gp_loss: 0.126| r_loss: 0.113| p_loss: 0.178| v_loss: 0.032| per_loss: 0.475 | a_loss: 0.486
Train: Epoch [607/3000], Step [60/158]| g_loss: 0.818| d_loss: 0.565| gp_loss: 0.049| r_loss: 0.120| p_loss: 0.186| v_loss: 0.034| per_loss: 0.437 | a_loss: 0.528
Train: Epoch [607/3000], Step [90/158]| g_loss: 0.898| d_loss: 0.519| gp_loss: 0.046| r_loss: 0.120| p_loss: 0.181| v_loss: 0.035| per_loss: 0.456 | a_loss: 0.607
Train: Epoch [607/3000], Step [120/158]| g_loss: 0.796| d_loss: 0.711| gp_loss: 0.049| r_loss: 0.114| p_loss: 0.194| v_loss: 0.034| per_loss: 0.513 | a_loss: 0.499
Train: Epoch [607/3000], Step [150/158]| g_loss: 0.891| d_loss: 0.522| gp_loss: 0.053| r_loss: 0.121| p_loss: 0.188| v_loss: 0.035| per_loss: 0.485 | a_loss: 0.593
Train: Epoch [608/3000], Step [30/158]| g_loss: 0.763| d_loss: 0.672| gp_loss: 0.085| r_loss: 0.126| p_loss: 0.206| v_loss: 0.036| per_loss: 0.463 | a_loss: 0.452
Train: Epoch [608/3000], Step [60/158]| g_loss: 0.851| d_loss: 0.624| gp_loss: 0.055| r_loss: 0.117| p_loss: 0.186| v_loss: 0.034| per_loss: 0.468 | a_loss: 0.560
Train: Epoch [608/3000], Step [90/158]| g_loss: 0.861| d_loss: 0.573| gp_loss: 0.054| r_loss: 0.123| p_loss: 0.186| v_loss: 0.035| per_loss: 0.481 | a_loss: 0.562
Train: Epoch [608/3000], Step [120/158]| g_loss: 0.870| d_loss: 0.566| gp_loss: 0.050| r_loss: 0.116| p_loss: 0.182| v_loss: 0.034| per_loss: 0.480 | a_loss: 0.581
Train: Epoch [608/3000], Step [150/158]| g_loss: 0.822| d_loss: 0.641| gp_loss: 0.053| r_loss: 0.126| p_loss: 0.193| v_loss: 0.034| per_loss: 0.486 | a_loss: 0.518
Train: Epoch [609/3000], Step [30/158]| g_loss: 0.829| d_loss: 0.689| gp_loss: 0.137| r_loss: 0.115| p_loss: 0.183| v_loss: 0.033| per_loss: 0.472 | a_loss: 0.542
Train: Epoch [609/3000], Step [60/158]| g_loss: 0.795| d_loss: 0.656| gp_loss: 0.052| r_loss: 0.122| p_loss: 0.182| v_loss: 0.035| per_loss: 0.482 | a_loss: 0.498
Train: Epoch [609/3000], Step [90/158]| g_loss: 0.877| d_loss: 0.542| gp_loss: 0.049| r_loss: 0.127| p_loss: 0.183| v_loss: 0.035| per_loss: 0.479 | a_loss: 0.576
Train: Epoch [609/3000], Step [120/158]| g_loss: 0.812| d_loss: 0.552| gp_loss: 0.051| r_loss: 0.109| p_loss: 0.171| v_loss: 0.032| per_loss: 0.446 | a_loss: 0.541
Train: Epoch [609/3000], Step [150/158]| g_loss: 0.883| d_loss: 0.553| gp_loss: 0.048| r_loss: 0.116| p_loss: 0.182| v_loss: 0.033| per_loss: 0.516 | a_loss: 0.591
Train: Epoch [610/3000], Step [30/158]| g_loss: 0.800| d_loss: 0.687| gp_loss: 0.139| r_loss: 0.111| p_loss: 0.175| v_loss: 0.035| per_loss: 0.464 | a_loss: 0.520
Train: Epoch [610/3000], Step [60/158]| g_loss: 0.854| d_loss: 0.524| gp_loss: 0.052| r_loss: 0.114| p_loss: 0.179| v_loss: 0.033| per_loss: 0.468 | a_loss: 0.572
Train: Epoch [610/3000], Step [90/158]| g_loss: 0.806| d_loss: 0.650| gp_loss: 0.050| r_loss: 0.119| p_loss: 0.181| v_loss: 0.033| per_loss: 0.493 | a_loss: 0.515
Train: Epoch [610/3000], Step [120/158]| g_loss: 0.812| d_loss: 0.631| gp_loss: 0.051| r_loss: 0.118| p_loss: 0.179| v_loss: 0.035| per_loss: 0.473 | a_loss: 0.523
Train: Epoch [610/3000], Step [150/158]| g_loss: 0.857| d_loss: 0.535| gp_loss: 0.050| r_loss: 0.117| p_loss: 0.182| v_loss: 0.034| per_loss: 0.486 | a_loss: 0.567
Train: Epoch [611/3000], Step [30/158]| g_loss: 0.783| d_loss: 0.736| gp_loss: 0.139| r_loss: 0.115| p_loss: 0.174| v_loss: 0.033| per_loss: 0.461 | a_loss: 0.503
Train: Epoch [611/3000], Step [60/158]| g_loss: 0.821| d_loss: 0.594| gp_loss: 0.051| r_loss: 0.113| p_loss: 0.176| v_loss: 0.035| per_loss: 0.520 | a_loss: 0.534
Train: Epoch [611/3000], Step [90/158]| g_loss: 0.799| d_loss: 0.612| gp_loss: 0.052| r_loss: 0.123| p_loss: 0.186| v_loss: 0.034| per_loss: 0.457 | a_loss: 0.504
Train: Epoch [611/3000], Step [120/158]| g_loss: 0.894| d_loss: 0.537| gp_loss: 0.051| r_loss: 0.113| p_loss: 0.174| v_loss: 0.035| per_loss: 0.487 | a_loss: 0.610
Train: Epoch [611/3000], Step [150/158]| g_loss: 0.792| d_loss: 0.637| gp_loss: 0.051| r_loss: 0.114| p_loss: 0.180| v_loss: 0.034| per_loss: 0.489 | a_loss: 0.505
Train: Epoch [612/3000], Step [30/158]| g_loss: 0.846| d_loss: 0.629| gp_loss: 0.117| r_loss: 0.113| p_loss: 0.174| v_loss: 0.035| per_loss: 0.504 | a_loss: 0.562
Train: Epoch [612/3000], Step [60/158]| g_loss: 0.860| d_loss: 0.587| gp_loss: 0.048| r_loss: 0.121| p_loss: 0.191| v_loss: 0.034| per_loss: 0.435 | a_loss: 0.566
Train: Epoch [612/3000], Step [90/158]| g_loss: 0.771| d_loss: 0.666| gp_loss: 0.049| r_loss: 0.117| p_loss: 0.192| v_loss: 0.034| per_loss: 0.506 | a_loss: 0.473
Train: Epoch [612/3000], Step [120/158]| g_loss: 0.887| d_loss: 0.567| gp_loss: 0.051| r_loss: 0.119| p_loss: 0.189| v_loss: 0.034| per_loss: 0.493 | a_loss: 0.591
Train: Epoch [612/3000], Step [150/158]| g_loss: 0.798| d_loss: 0.623| gp_loss: 0.051| r_loss: 0.121| p_loss: 0.191| v_loss: 0.034| per_loss: 0.488 | a_loss: 0.499
Train: Epoch [613/3000], Step [30/158]| g_loss: 0.809| d_loss: 0.752| gp_loss: 0.125| r_loss: 0.117| p_loss: 0.195| v_loss: 0.033| per_loss: 0.482 | a_loss: 0.514
Train: Epoch [613/3000], Step [60/158]| g_loss: 0.841| d_loss: 0.591| gp_loss: 0.050| r_loss: 0.119| p_loss: 0.192| v_loss: 0.035| per_loss: 0.498 | a_loss: 0.542
Train: Epoch [613/3000], Step [90/158]| g_loss: 0.881| d_loss: 0.521| gp_loss: 0.048| r_loss: 0.114| p_loss: 0.186| v_loss: 0.034| per_loss: 0.517 | a_loss: 0.588
Train: Epoch [613/3000], Step [120/158]| g_loss: 0.917| d_loss: 0.594| gp_loss: 0.049| r_loss: 0.142| p_loss: 0.242| v_loss: 0.035| per_loss: 0.507 | a_loss: 0.568
Train: Epoch [613/3000], Step [150/158]| g_loss: 0.826| d_loss: 0.630| gp_loss: 0.053| r_loss: 0.127| p_loss: 0.197| v_loss: 0.033| per_loss: 0.496 | a_loss: 0.518
Train: Epoch [614/3000], Step [30/158]| g_loss: 0.872| d_loss: 0.663| gp_loss: 0.192| r_loss: 0.118| p_loss: 0.195| v_loss: 0.035| per_loss: 0.474 | a_loss: 0.575
Train: Epoch [614/3000], Step [60/158]| g_loss: 0.774| d_loss: 0.708| gp_loss: 0.046| r_loss: 0.123| p_loss: 0.181| v_loss: 0.032| per_loss: 0.490 | a_loss: 0.479
Train: Epoch [614/3000], Step [90/158]| g_loss: 0.783| d_loss: 0.686| gp_loss: 0.049| r_loss: 0.118| p_loss: 0.186| v_loss: 0.032| per_loss: 0.491 | a_loss: 0.491
Train: Epoch [614/3000], Step [120/158]| g_loss: 0.872| d_loss: 0.539| gp_loss: 0.049| r_loss: 0.124| p_loss: 0.201| v_loss: 0.035| per_loss: 0.513 | a_loss: 0.560
Train: Epoch [614/3000], Step [150/158]| g_loss: 0.875| d_loss: 0.570| gp_loss: 0.047| r_loss: 0.116| p_loss: 0.188| v_loss: 0.034| per_loss: 0.483 | a_loss: 0.582
Train: Epoch [615/3000], Step [30/158]| g_loss: 0.840| d_loss: 0.709| gp_loss: 0.127| r_loss: 0.118| p_loss: 0.183| v_loss: 0.034| per_loss: 0.480 | a_loss: 0.548
Train: Epoch [615/3000], Step [60/158]| g_loss: 0.780| d_loss: 0.630| gp_loss: 0.048| r_loss: 0.111| p_loss: 0.182| v_loss: 0.035| per_loss: 0.500 | a_loss: 0.494
Train: Epoch [615/3000], Step [90/158]| g_loss: 0.852| d_loss: 0.530| gp_loss: 0.048| r_loss: 0.121| p_loss: 0.187| v_loss: 0.033| per_loss: 0.496 | a_loss: 0.554
Train: Epoch [615/3000], Step [120/158]| g_loss: 0.809| d_loss: 0.657| gp_loss: 0.049| r_loss: 0.120| p_loss: 0.189| v_loss: 0.033| per_loss: 0.509 | a_loss: 0.510
Train: Epoch [615/3000], Step [150/158]| g_loss: 0.814| d_loss: 0.606| gp_loss: 0.047| r_loss: 0.118| p_loss: 0.182| v_loss: 0.033| per_loss: 0.464 | a_loss: 0.525
Train: Epoch [616/3000], Step [30/158]| g_loss: 0.827| d_loss: 0.706| gp_loss: 0.127| r_loss: 0.115| p_loss: 0.195| v_loss: 0.033| per_loss: 0.497 | a_loss: 0.532
Train: Epoch [616/3000], Step [60/158]| g_loss: 0.798| d_loss: 0.559| gp_loss: 0.049| r_loss: 0.121| p_loss: 0.183| v_loss: 0.033| per_loss: 0.494 | a_loss: 0.503
Train: Epoch [616/3000], Step [90/158]| g_loss: 0.819| d_loss: 0.612| gp_loss: 0.047| r_loss: 0.112| p_loss: 0.174| v_loss: 0.033| per_loss: 0.483 | a_loss: 0.539
Train: Epoch [616/3000], Step [120/158]| g_loss: 0.799| d_loss: 0.589| gp_loss: 0.049| r_loss: 0.112| p_loss: 0.183| v_loss: 0.033| per_loss: 0.479 | a_loss: 0.515
Train: Epoch [616/3000], Step [150/158]| g_loss: 0.851| d_loss: 0.558| gp_loss: 0.051| r_loss: 0.112| p_loss: 0.174| v_loss: 0.032| per_loss: 0.464 | a_loss: 0.574
Train: Epoch [617/3000], Step [30/158]| g_loss: 0.799| d_loss: 0.714| gp_loss: 0.153| r_loss: 0.114| p_loss: 0.179| v_loss: 0.033| per_loss: 0.479 | a_loss: 0.515
Train: Epoch [617/3000], Step [60/158]| g_loss: 0.798| d_loss: 0.593| gp_loss: 0.046| r_loss: 0.120| p_loss: 0.182| v_loss: 0.035| per_loss: 0.493 | a_loss: 0.503
Train: Epoch [617/3000], Step [90/158]| g_loss: 0.905| d_loss: 0.513| gp_loss: 0.048| r_loss: 0.118| p_loss: 0.180| v_loss: 0.033| per_loss: 0.502 | a_loss: 0.614
Train: Epoch [617/3000], Step [120/158]| g_loss: 0.767| d_loss: 0.632| gp_loss: 0.048| r_loss: 0.115| p_loss: 0.174| v_loss: 0.033| per_loss: 0.499 | a_loss: 0.482
Train: Epoch [617/3000], Step [150/158]| g_loss: 0.821| d_loss: 0.574| gp_loss: 0.050| r_loss: 0.115| p_loss: 0.174| v_loss: 0.034| per_loss: 0.487 | a_loss: 0.537
Train: Epoch [618/3000], Step [30/158]| g_loss: 0.812| d_loss: 0.709| gp_loss: 0.138| r_loss: 0.111| p_loss: 0.179| v_loss: 0.033| per_loss: 0.462 | a_loss: 0.532
Train: Epoch [618/3000], Step [60/158]| g_loss: 0.764| d_loss: 0.702| gp_loss: 0.048| r_loss: 0.111| p_loss: 0.177| v_loss: 0.033| per_loss: 0.477 | a_loss: 0.485
Train: Epoch [618/3000], Step [90/158]| g_loss: 0.790| d_loss: 0.586| gp_loss: 0.048| r_loss: 0.113| p_loss: 0.176| v_loss: 0.034| per_loss: 0.504 | a_loss: 0.505
Train: Epoch [618/3000], Step [120/158]| g_loss: 0.906| d_loss: 0.493| gp_loss: 0.046| r_loss: 0.127| p_loss: 0.183| v_loss: 0.034| per_loss: 0.475 | a_loss: 0.606
Train: Epoch [618/3000], Step [150/158]| g_loss: 0.845| d_loss: 0.615| gp_loss: 0.047| r_loss: 0.116| p_loss: 0.183| v_loss: 0.032| per_loss: 0.504 | a_loss: 0.554
Train: Epoch [619/3000], Step [30/158]| g_loss: 0.873| d_loss: 0.623| gp_loss: 0.140| r_loss: 0.108| p_loss: 0.178| v_loss: 0.034| per_loss: 0.498 | a_loss: 0.592
Train: Epoch [619/3000], Step [60/158]| g_loss: 0.810| d_loss: 0.620| gp_loss: 0.044| r_loss: 0.114| p_loss: 0.184| v_loss: 0.034| per_loss: 0.446 | a_loss: 0.526
Train: Epoch [619/3000], Step [90/158]| g_loss: 0.811| d_loss: 0.552| gp_loss: 0.046| r_loss: 0.117| p_loss: 0.177| v_loss: 0.034| per_loss: 0.492 | a_loss: 0.523
Train: Epoch [619/3000], Step [120/158]| g_loss: 0.817| d_loss: 0.614| gp_loss: 0.046| r_loss: 0.114| p_loss: 0.177| v_loss: 0.032| per_loss: 0.482 | a_loss: 0.535
Train: Epoch [619/3000], Step [150/158]| g_loss: 0.751| d_loss: 0.697| gp_loss: 0.053| r_loss: 0.117| p_loss: 0.174| v_loss: 0.032| per_loss: 0.481 | a_loss: 0.467
Train: Epoch [620/3000], Step [30/158]| g_loss: 0.839| d_loss: 0.607| gp_loss: 0.130| r_loss: 0.113| p_loss: 0.172| v_loss: 0.033| per_loss: 0.481 | a_loss: 0.559
Train: Epoch [620/3000], Step [60/158]| g_loss: 0.887| d_loss: 0.526| gp_loss: 0.049| r_loss: 0.116| p_loss: 0.178| v_loss: 0.035| per_loss: 0.491 | a_loss: 0.598
Train: Epoch [620/3000], Step [90/158]| g_loss: 0.812| d_loss: 0.606| gp_loss: 0.045| r_loss: 0.119| p_loss: 0.177| v_loss: 0.034| per_loss: 0.509 | a_loss: 0.520
Train: Epoch [620/3000], Step [120/158]| g_loss: 0.794| d_loss: 0.641| gp_loss: 0.050| r_loss: 0.114| p_loss: 0.177| v_loss: 0.033| per_loss: 0.482 | a_loss: 0.510
Train: Epoch [620/3000], Step [150/158]| g_loss: 0.766| d_loss: 0.656| gp_loss: 0.047| r_loss: 0.117| p_loss: 0.182| v_loss: 0.033| per_loss: 0.486 | a_loss: 0.477
Train: Epoch [621/3000], Step [30/158]| g_loss: 0.839| d_loss: 0.662| gp_loss: 0.144| r_loss: 0.111| p_loss: 0.181| v_loss: 0.033| per_loss: 0.497 | a_loss: 0.554
Train: Epoch [621/3000], Step [60/158]| g_loss: 0.816| d_loss: 0.566| gp_loss: 0.050| r_loss: 0.114| p_loss: 0.173| v_loss: 0.032| per_loss: 0.490 | a_loss: 0.534
Train: Epoch [621/3000], Step [90/158]| g_loss: 0.823| d_loss: 0.586| gp_loss: 0.050| r_loss: 0.120| p_loss: 0.181| v_loss: 0.034| per_loss: 0.506 | a_loss: 0.529
Train: Epoch [621/3000], Step [120/158]| g_loss: 0.800| d_loss: 0.648| gp_loss: 0.050| r_loss: 0.113| p_loss: 0.173| v_loss: 0.032| per_loss: 0.474 | a_loss: 0.521
Train: Epoch [621/3000], Step [150/158]| g_loss: 0.843| d_loss: 0.572| gp_loss: 0.054| r_loss: 0.114| p_loss: 0.180| v_loss: 0.032| per_loss: 0.478 | a_loss: 0.559
Train: Epoch [622/3000], Step [30/158]| g_loss: 0.850| d_loss: 0.579| gp_loss: 0.143| r_loss: 0.110| p_loss: 0.174| v_loss: 0.033| per_loss: 0.471 | a_loss: 0.573
Train: Epoch [622/3000], Step [60/158]| g_loss: 0.879| d_loss: 0.604| gp_loss: 0.050| r_loss: 0.109| p_loss: 0.172| v_loss: 0.033| per_loss: 0.516 | a_loss: 0.600
Train: Epoch [622/3000], Step [90/158]| g_loss: 0.772| d_loss: 0.622| gp_loss: 0.049| r_loss: 0.112| p_loss: 0.175| v_loss: 0.033| per_loss: 0.461 | a_loss: 0.493
Train: Epoch [622/3000], Step [120/158]| g_loss: 0.838| d_loss: 0.570| gp_loss: 0.043| r_loss: 0.115| p_loss: 0.180| v_loss: 0.033| per_loss: 0.512 | a_loss: 0.548
Train: Epoch [622/3000], Step [150/158]| g_loss: 0.834| d_loss: 0.678| gp_loss: 0.048| r_loss: 0.123| p_loss: 0.190| v_loss: 0.032| per_loss: 0.519 | a_loss: 0.532
Train: Epoch [623/3000], Step [30/158]| g_loss: 0.697| d_loss: 0.793| gp_loss: 0.118| r_loss: 0.111| p_loss: 0.172| v_loss: 0.031| per_loss: 0.467 | a_loss: 0.422
Train: Epoch [623/3000], Step [60/158]| g_loss: 0.803| d_loss: 0.610| gp_loss: 0.050| r_loss: 0.116| p_loss: 0.176| v_loss: 0.033| per_loss: 0.517 | a_loss: 0.514
Train: Epoch [623/3000], Step [90/158]| g_loss: 0.841| d_loss: 0.543| gp_loss: 0.051| r_loss: 0.118| p_loss: 0.174| v_loss: 0.033| per_loss: 0.487 | a_loss: 0.554
Train: Epoch [623/3000], Step [120/158]| g_loss: 0.835| d_loss: 0.624| gp_loss: 0.051| r_loss: 0.116| p_loss: 0.179| v_loss: 0.035| per_loss: 0.514 | a_loss: 0.543
Train: Epoch [623/3000], Step [150/158]| g_loss: 0.870| d_loss: 0.490| gp_loss: 0.047| r_loss: 0.112| p_loss: 0.174| v_loss: 0.033| per_loss: 0.456 | a_loss: 0.592
Train: Epoch [624/3000], Step [30/158]| g_loss: 0.789| d_loss: 0.646| gp_loss: 0.082| r_loss: 0.112| p_loss: 0.169| v_loss: 0.033| per_loss: 0.489 | a_loss: 0.511
Train: Epoch [624/3000], Step [60/158]| g_loss: 0.842| d_loss: 0.542| gp_loss: 0.052| r_loss: 0.109| p_loss: 0.167| v_loss: 0.031| per_loss: 0.471 | a_loss: 0.572
Train: Epoch [624/3000], Step [90/158]| g_loss: 0.816| d_loss: 0.602| gp_loss: 0.051| r_loss: 0.116| p_loss: 0.177| v_loss: 0.032| per_loss: 0.489 | a_loss: 0.531
Train: Epoch [624/3000], Step [120/158]| g_loss: 0.803| d_loss: 0.606| gp_loss: 0.054| r_loss: 0.119| p_loss: 0.184| v_loss: 0.033| per_loss: 0.528 | a_loss: 0.505
Train: Epoch [624/3000], Step [150/158]| g_loss: 0.872| d_loss: 0.574| gp_loss: 0.054| r_loss: 0.120| p_loss: 0.184| v_loss: 0.034| per_loss: 0.502 | a_loss: 0.576
Train: Epoch [625/3000], Step [30/158]| g_loss: 0.835| d_loss: 0.662| gp_loss: 0.146| r_loss: 0.120| p_loss: 0.188| v_loss: 0.033| per_loss: 0.496 | a_loss: 0.538
Train: Epoch [625/3000], Step [60/158]| g_loss: 0.837| d_loss: 0.556| gp_loss: 0.054| r_loss: 0.116| p_loss: 0.179| v_loss: 0.034| per_loss: 0.495 | a_loss: 0.547
Train: Epoch [625/3000], Step [90/158]| g_loss: 0.806| d_loss: 0.640| gp_loss: 0.054| r_loss: 0.108| p_loss: 0.169| v_loss: 0.032| per_loss: 0.507 | a_loss: 0.530
Train: Epoch [625/3000], Step [120/158]| g_loss: 0.816| d_loss: 0.610| gp_loss: 0.051| r_loss: 0.124| p_loss: 0.182| v_loss: 0.033| per_loss: 0.491 | a_loss: 0.518
Train: Epoch [625/3000], Step [150/158]| g_loss: 0.813| d_loss: 0.600| gp_loss: 0.054| r_loss: 0.120| p_loss: 0.182| v_loss: 0.032| per_loss: 0.489 | a_loss: 0.522
Train: Epoch [626/3000], Step [30/158]| g_loss: 0.796| d_loss: 0.680| gp_loss: 0.126| r_loss: 0.110| p_loss: 0.174| v_loss: 0.031| per_loss: 0.508 | a_loss: 0.517
Train: Epoch [626/3000], Step [60/158]| g_loss: 0.780| d_loss: 0.678| gp_loss: 0.050| r_loss: 0.110| p_loss: 0.174| v_loss: 0.034| per_loss: 0.496 | a_loss: 0.499
Train: Epoch [626/3000], Step [90/158]| g_loss: 0.814| d_loss: 0.543| gp_loss: 0.056| r_loss: 0.114| p_loss: 0.187| v_loss: 0.034| per_loss: 0.503 | a_loss: 0.523
Train: Epoch [626/3000], Step [120/158]| g_loss: 0.859| d_loss: 0.627| gp_loss: 0.053| r_loss: 0.131| p_loss: 0.198| v_loss: 0.033| per_loss: 0.491 | a_loss: 0.547
Train: Epoch [626/3000], Step [150/158]| g_loss: 0.879| d_loss: 0.561| gp_loss: 0.058| r_loss: 0.116| p_loss: 0.186| v_loss: 0.033| per_loss: 0.515 | a_loss: 0.586
Train: Epoch [627/3000], Step [30/158]| g_loss: 0.858| d_loss: 0.689| gp_loss: 0.189| r_loss: 0.118| p_loss: 0.187| v_loss: 0.035| per_loss: 0.518 | a_loss: 0.560
Train: Epoch [627/3000], Step [60/158]| g_loss: 0.851| d_loss: 0.554| gp_loss: 0.052| r_loss: 0.112| p_loss: 0.184| v_loss: 0.033| per_loss: 0.540 | a_loss: 0.560
Train: Epoch [627/3000], Step [90/158]| g_loss: 0.769| d_loss: 0.708| gp_loss: 0.051| r_loss: 0.117| p_loss: 0.184| v_loss: 0.032| per_loss: 0.513 | a_loss: 0.476
Train: Epoch [627/3000], Step [120/158]| g_loss: 0.799| d_loss: 0.623| gp_loss: 0.051| r_loss: 0.116| p_loss: 0.175| v_loss: 0.032| per_loss: 0.495 | a_loss: 0.514
Train: Epoch [627/3000], Step [150/158]| g_loss: 0.829| d_loss: 0.538| gp_loss: 0.052| r_loss: 0.118| p_loss: 0.178| v_loss: 0.032| per_loss: 0.476 | a_loss: 0.542
Train: Epoch [628/3000], Step [30/158]| g_loss: 0.885| d_loss: 0.585| gp_loss: 0.111| r_loss: 0.119| p_loss: 0.184| v_loss: 0.035| per_loss: 0.494 | a_loss: 0.590
Train: Epoch [628/3000], Step [60/158]| g_loss: 0.814| d_loss: 0.645| gp_loss: 0.048| r_loss: 0.108| p_loss: 0.179| v_loss: 0.032| per_loss: 0.522 | a_loss: 0.532
Train: Epoch [628/3000], Step [90/158]| g_loss: 0.851| d_loss: 0.586| gp_loss: 0.049| r_loss: 0.118| p_loss: 0.181| v_loss: 0.034| per_loss: 0.539 | a_loss: 0.555
Train: Epoch [628/3000], Step [120/158]| g_loss: 0.807| d_loss: 0.643| gp_loss: 0.050| r_loss: 0.115| p_loss: 0.178| v_loss: 0.034| per_loss: 0.487 | a_loss: 0.520
Train: Epoch [628/3000], Step [150/158]| g_loss: 0.780| d_loss: 0.625| gp_loss: 0.051| r_loss: 0.111| p_loss: 0.177| v_loss: 0.034| per_loss: 0.484 | a_loss: 0.499
Train: Epoch [629/3000], Step [30/158]| g_loss: 0.835| d_loss: 0.636| gp_loss: 0.134| r_loss: 0.120| p_loss: 0.182| v_loss: 0.033| per_loss: 0.506 | a_loss: 0.540
Train: Epoch [629/3000], Step [60/158]| g_loss: 0.859| d_loss: 0.610| gp_loss: 0.047| r_loss: 0.115| p_loss: 0.185| v_loss: 0.032| per_loss: 0.513 | a_loss: 0.568
Train: Epoch [629/3000], Step [90/158]| g_loss: 0.765| d_loss: 0.619| gp_loss: 0.048| r_loss: 0.111| p_loss: 0.171| v_loss: 0.033| per_loss: 0.501 | a_loss: 0.485
Train: Epoch [629/3000], Step [120/158]| g_loss: 0.813| d_loss: 0.499| gp_loss: 0.051| r_loss: 0.112| p_loss: 0.172| v_loss: 0.033| per_loss: 0.500 | a_loss: 0.532
Train: Epoch [629/3000], Step [150/158]| g_loss: 0.858| d_loss: 0.619| gp_loss: 0.049| r_loss: 0.117| p_loss: 0.175| v_loss: 0.034| per_loss: 0.489 | a_loss: 0.571
Train: Epoch [630/3000], Step [30/158]| g_loss: 0.826| d_loss: 0.662| gp_loss: 0.136| r_loss: 0.116| p_loss: 0.175| v_loss: 0.032| per_loss: 0.495 | a_loss: 0.541
Train: Epoch [630/3000], Step [60/158]| g_loss: 0.765| d_loss: 0.592| gp_loss: 0.050| r_loss: 0.108| p_loss: 0.167| v_loss: 0.033| per_loss: 0.482 | a_loss: 0.492
Train: Epoch [630/3000], Step [90/158]| g_loss: 0.834| d_loss: 0.566| gp_loss: 0.048| r_loss: 0.107| p_loss: 0.172| v_loss: 0.032| per_loss: 0.484 | a_loss: 0.560
Train: Epoch [630/3000], Step [120/158]| g_loss: 0.831| d_loss: 0.604| gp_loss: 0.051| r_loss: 0.114| p_loss: 0.183| v_loss: 0.035| per_loss: 0.543 | a_loss: 0.537
Train: Epoch [630/3000], Step [150/158]| g_loss: 0.826| d_loss: 0.635| gp_loss: 0.050| r_loss: 0.117| p_loss: 0.175| v_loss: 0.032| per_loss: 0.484 | a_loss: 0.540
Train: Epoch [631/3000], Step [30/158]| g_loss: 0.750| d_loss: 0.755| gp_loss: 0.164| r_loss: 0.105| p_loss: 0.171| v_loss: 0.033| per_loss: 0.507 | a_loss: 0.476
Train: Epoch [631/3000], Step [60/158]| g_loss: 0.833| d_loss: 0.558| gp_loss: 0.047| r_loss: 0.120| p_loss: 0.180| v_loss: 0.035| per_loss: 0.517 | a_loss: 0.538
Train: Epoch [631/3000], Step [90/158]| g_loss: 0.830| d_loss: 0.535| gp_loss: 0.047| r_loss: 0.113| p_loss: 0.173| v_loss: 0.032| per_loss: 0.505 | a_loss: 0.549
Train: Epoch [631/3000], Step [120/158]| g_loss: 0.838| d_loss: 0.559| gp_loss: 0.049| r_loss: 0.116| p_loss: 0.171| v_loss: 0.033| per_loss: 0.504 | a_loss: 0.553
Train: Epoch [631/3000], Step [150/158]| g_loss: 0.763| d_loss: 0.644| gp_loss: 0.054| r_loss: 0.109| p_loss: 0.169| v_loss: 0.032| per_loss: 0.497 | a_loss: 0.488
Train: Epoch [632/3000], Step [30/158]| g_loss: 0.814| d_loss: 0.704| gp_loss: 0.156| r_loss: 0.108| p_loss: 0.177| v_loss: 0.033| per_loss: 0.526 | a_loss: 0.532
Train: Epoch [632/3000], Step [60/158]| g_loss: 0.792| d_loss: 0.645| gp_loss: 0.049| r_loss: 0.114| p_loss: 0.175| v_loss: 0.034| per_loss: 0.498 | a_loss: 0.506
Train: Epoch [632/3000], Step [90/158]| g_loss: 0.824| d_loss: 0.599| gp_loss: 0.051| r_loss: 0.116| p_loss: 0.183| v_loss: 0.034| per_loss: 0.489 | a_loss: 0.533
Train: Epoch [632/3000], Step [120/158]| g_loss: 0.826| d_loss: 0.570| gp_loss: 0.050| r_loss: 0.115| p_loss: 0.181| v_loss: 0.033| per_loss: 0.491 | a_loss: 0.539
Train: Epoch [632/3000], Step [150/158]| g_loss: 0.877| d_loss: 0.557| gp_loss: 0.046| r_loss: 0.113| p_loss: 0.174| v_loss: 0.033| per_loss: 0.499 | a_loss: 0.594
Train: Epoch [633/3000], Step [30/158]| g_loss: 0.824| d_loss: 0.728| gp_loss: 0.171| r_loss: 0.119| p_loss: 0.182| v_loss: 0.034| per_loss: 0.488 | a_loss: 0.532
Train: Epoch [633/3000], Step [60/158]| g_loss: 0.785| d_loss: 0.664| gp_loss: 0.046| r_loss: 0.115| p_loss: 0.180| v_loss: 0.033| per_loss: 0.497 | a_loss: 0.496
Train: Epoch [633/3000], Step [90/158]| g_loss: 0.801| d_loss: 0.563| gp_loss: 0.044| r_loss: 0.112| p_loss: 0.177| v_loss: 0.032| per_loss: 0.520 | a_loss: 0.516
Train: Epoch [633/3000], Step [120/158]| g_loss: 0.847| d_loss: 0.547| gp_loss: 0.047| r_loss: 0.111| p_loss: 0.170| v_loss: 0.034| per_loss: 0.496 | a_loss: 0.568
Train: Epoch [633/3000], Step [150/158]| g_loss: 0.820| d_loss: 0.596| gp_loss: 0.049| r_loss: 0.118| p_loss: 0.181| v_loss: 0.033| per_loss: 0.508 | a_loss: 0.527
Train: Epoch [634/3000], Step [30/158]| g_loss: 0.827| d_loss: 0.701| gp_loss: 0.162| r_loss: 0.118| p_loss: 0.179| v_loss: 0.032| per_loss: 0.491 | a_loss: 0.538
Train: Epoch [634/3000], Step [60/158]| g_loss: 0.841| d_loss: 0.581| gp_loss: 0.047| r_loss: 0.117| p_loss: 0.186| v_loss: 0.034| per_loss: 0.489 | a_loss: 0.548
Train: Epoch [634/3000], Step [90/158]| g_loss: 0.790| d_loss: 0.648| gp_loss: 0.048| r_loss: 0.118| p_loss: 0.182| v_loss: 0.034| per_loss: 0.487 | a_loss: 0.499
Train: Epoch [634/3000], Step [120/158]| g_loss: 0.852| d_loss: 0.530| gp_loss: 0.050| r_loss: 0.110| p_loss: 0.168| v_loss: 0.034| per_loss: 0.510 | a_loss: 0.573
Train: Epoch [634/3000], Step [150/158]| g_loss: 0.777| d_loss: 0.618| gp_loss: 0.050| r_loss: 0.106| p_loss: 0.164| v_loss: 0.032| per_loss: 0.495 | a_loss: 0.508
Train: Epoch [635/3000], Step [30/158]| g_loss: 0.820| d_loss: 0.671| gp_loss: 0.143| r_loss: 0.111| p_loss: 0.169| v_loss: 0.032| per_loss: 0.454 | a_loss: 0.548
Train: Epoch [635/3000], Step [60/158]| g_loss: 0.830| d_loss: 0.569| gp_loss: 0.048| r_loss: 0.119| p_loss: 0.170| v_loss: 0.033| per_loss: 0.520 | a_loss: 0.541
Train: Epoch [635/3000], Step [90/158]| g_loss: 0.815| d_loss: 0.558| gp_loss: 0.046| r_loss: 0.110| p_loss: 0.170| v_loss: 0.035| per_loss: 0.526 | a_loss: 0.532
Train: Epoch [635/3000], Step [120/158]| g_loss: 0.832| d_loss: 0.564| gp_loss: 0.047| r_loss: 0.109| p_loss: 0.167| v_loss: 0.033| per_loss: 0.505 | a_loss: 0.556
Train: Epoch [635/3000], Step [150/158]| g_loss: 0.777| d_loss: 0.671| gp_loss: 0.053| r_loss: 0.111| p_loss: 0.172| v_loss: 0.033| per_loss: 0.488 | a_loss: 0.498
Train: Epoch [636/3000], Step [30/158]| g_loss: 0.807| d_loss: 0.714| gp_loss: 0.177| r_loss: 0.111| p_loss: 0.175| v_loss: 0.034| per_loss: 0.489 | a_loss: 0.526
Train: Epoch [636/3000], Step [60/158]| g_loss: 0.886| d_loss: 0.522| gp_loss: 0.044| r_loss: 0.114| p_loss: 0.169| v_loss: 0.033| per_loss: 0.489 | a_loss: 0.605
Train: Epoch [636/3000], Step [90/158]| g_loss: 0.797| d_loss: 0.614| gp_loss: 0.048| r_loss: 0.111| p_loss: 0.176| v_loss: 0.033| per_loss: 0.471 | a_loss: 0.518
Train: Epoch [636/3000], Step [120/158]| g_loss: 0.807| d_loss: 0.610| gp_loss: 0.047| r_loss: 0.116| p_loss: 0.175| v_loss: 0.033| per_loss: 0.549 | a_loss: 0.516
Train: Epoch [636/3000], Step [150/158]| g_loss: 0.790| d_loss: 0.603| gp_loss: 0.050| r_loss: 0.109| p_loss: 0.172| v_loss: 0.033| per_loss: 0.521 | a_loss: 0.509
Train: Epoch [637/3000], Step [30/158]| g_loss: 0.819| d_loss: 0.645| gp_loss: 0.098| r_loss: 0.107| p_loss: 0.170| v_loss: 0.033| per_loss: 0.481 | a_loss: 0.545
Train: Epoch [637/3000], Step [60/158]| g_loss: 0.766| d_loss: 0.609| gp_loss: 0.051| r_loss: 0.111| p_loss: 0.161| v_loss: 0.032| per_loss: 0.521 | a_loss: 0.491
Train: Epoch [637/3000], Step [90/158]| g_loss: 0.812| d_loss: 0.553| gp_loss: 0.049| r_loss: 0.111| p_loss: 0.167| v_loss: 0.033| per_loss: 0.506 | a_loss: 0.534
Train: Epoch [637/3000], Step [120/158]| g_loss: 0.871| d_loss: 0.599| gp_loss: 0.048| r_loss: 0.112| p_loss: 0.175| v_loss: 0.033| per_loss: 0.550 | a_loss: 0.583
Train: Epoch [637/3000], Step [150/158]| g_loss: 0.785| d_loss: 0.613| gp_loss: 0.052| r_loss: 0.117| p_loss: 0.178| v_loss: 0.033| per_loss: 0.489 | a_loss: 0.497
Train: Epoch [638/3000], Step [30/158]| g_loss: 0.854| d_loss: 0.628| gp_loss: 0.138| r_loss: 0.109| p_loss: 0.177| v_loss: 0.034| per_loss: 0.524 | a_loss: 0.571
Train: Epoch [638/3000], Step [60/158]| g_loss: 0.727| d_loss: 0.665| gp_loss: 0.053| r_loss: 0.106| p_loss: 0.168| v_loss: 0.033| per_loss: 0.511 | a_loss: 0.453
Train: Epoch [638/3000], Step [90/158]| g_loss: 0.845| d_loss: 0.561| gp_loss: 0.053| r_loss: 0.113| p_loss: 0.178| v_loss: 0.033| per_loss: 0.521 | a_loss: 0.558
Train: Epoch [638/3000], Step [120/158]| g_loss: 0.853| d_loss: 0.578| gp_loss: 0.052| r_loss: 0.118| p_loss: 0.185| v_loss: 0.032| per_loss: 0.514 | a_loss: 0.559
Train: Epoch [638/3000], Step [150/158]| g_loss: 0.850| d_loss: 0.583| gp_loss: 0.056| r_loss: 0.118| p_loss: 0.183| v_loss: 0.034| per_loss: 0.504 | a_loss: 0.555
Train: Epoch [639/3000], Step [30/158]| g_loss: 0.813| d_loss: 0.672| gp_loss: 0.092| r_loss: 0.122| p_loss: 0.182| v_loss: 0.034| per_loss: 0.521 | a_loss: 0.515
Train: Epoch [639/3000], Step [60/158]| g_loss: 0.747| d_loss: 0.673| gp_loss: 0.053| r_loss: 0.116| p_loss: 0.181| v_loss: 0.034| per_loss: 0.529 | a_loss: 0.454
Train: Epoch [639/3000], Step [90/158]| g_loss: 0.882| d_loss: 0.508| gp_loss: 0.056| r_loss: 0.112| p_loss: 0.186| v_loss: 0.033| per_loss: 0.561 | a_loss: 0.587
Train: Epoch [639/3000], Step [120/158]| g_loss: 0.860| d_loss: 0.638| gp_loss: 0.051| r_loss: 0.118| p_loss: 0.193| v_loss: 0.035| per_loss: 0.532 | a_loss: 0.558
Train: Epoch [639/3000], Step [150/158]| g_loss: 0.809| d_loss: 0.557| gp_loss: 0.058| r_loss: 0.116| p_loss: 0.185| v_loss: 0.034| per_loss: 0.531 | a_loss: 0.514
Train: Epoch [640/3000], Step [30/158]| g_loss: 0.901| d_loss: 0.629| gp_loss: 0.165| r_loss: 0.122| p_loss: 0.191| v_loss: 0.035| per_loss: 0.543 | a_loss: 0.595
Train: Epoch [640/3000], Step [60/158]| g_loss: 0.825| d_loss: 0.624| gp_loss: 0.052| r_loss: 0.117| p_loss: 0.186| v_loss: 0.035| per_loss: 0.520 | a_loss: 0.528
Train: Epoch [640/3000], Step [90/158]| g_loss: 0.832| d_loss: 0.574| gp_loss: 0.054| r_loss: 0.114| p_loss: 0.181| v_loss: 0.034| per_loss: 0.574 | a_loss: 0.535
Train: Epoch [640/3000], Step [120/158]| g_loss: 0.816| d_loss: 0.595| gp_loss: 0.054| r_loss: 0.120| p_loss: 0.189| v_loss: 0.035| per_loss: 0.533 | a_loss: 0.514
Train: Epoch [640/3000], Step [150/158]| g_loss: 0.868| d_loss: 0.554| gp_loss: 0.053| r_loss: 0.111| p_loss: 0.183| v_loss: 0.034| per_loss: 0.545 | a_loss: 0.576
Train: Epoch [641/3000], Step [30/158]| g_loss: 0.839| d_loss: 0.691| gp_loss: 0.152| r_loss: 0.114| p_loss: 0.183| v_loss: 0.034| per_loss: 0.566 | a_loss: 0.543
Train: Epoch [641/3000], Step [60/158]| g_loss: 0.797| d_loss: 0.615| gp_loss: 0.052| r_loss: 0.114| p_loss: 0.182| v_loss: 0.034| per_loss: 0.543 | a_loss: 0.503
Train: Epoch [641/3000], Step [90/158]| g_loss: 0.827| d_loss: 0.589| gp_loss: 0.055| r_loss: 0.117| p_loss: 0.183| v_loss: 0.035| per_loss: 0.547 | a_loss: 0.529
Train: Epoch [641/3000], Step [120/158]| g_loss: 0.836| d_loss: 0.580| gp_loss: 0.053| r_loss: 0.117| p_loss: 0.185| v_loss: 0.034| per_loss: 0.529 | a_loss: 0.540
Train: Epoch [641/3000], Step [150/158]| g_loss: 0.929| d_loss: 0.476| gp_loss: 0.057| r_loss: 0.117| p_loss: 0.193| v_loss: 0.036| per_loss: 0.514 | a_loss: 0.628
Train: Epoch [642/3000], Step [30/158]| g_loss: 0.860| d_loss: 0.652| gp_loss: 0.162| r_loss: 0.116| p_loss: 0.181| v_loss: 0.036| per_loss: 0.515 | a_loss: 0.566
Train: Epoch [642/3000], Step [60/158]| g_loss: 0.922| d_loss: 0.504| gp_loss: 0.052| r_loss: 0.119| p_loss: 0.187| v_loss: 0.036| per_loss: 0.524 | a_loss: 0.622
Train: Epoch [642/3000], Step [90/158]| g_loss: 0.838| d_loss: 0.611| gp_loss: 0.050| r_loss: 0.115| p_loss: 0.182| v_loss: 0.034| per_loss: 0.512 | a_loss: 0.546
Train: Epoch [642/3000], Step [120/158]| g_loss: 0.807| d_loss: 0.551| gp_loss: 0.054| r_loss: 0.109| p_loss: 0.180| v_loss: 0.034| per_loss: 0.528 | a_loss: 0.521
Train: Epoch [642/3000], Step [150/158]| g_loss: 0.875| d_loss: 0.602| gp_loss: 0.052| r_loss: 0.122| p_loss: 0.191| v_loss: 0.036| per_loss: 0.514 | a_loss: 0.570
Train: Epoch [643/3000], Step [30/158]| g_loss: 0.795| d_loss: 0.717| gp_loss: 0.143| r_loss: 0.109| p_loss: 0.175| v_loss: 0.033| per_loss: 0.515 | a_loss: 0.514
Train: Epoch [643/3000], Step [60/158]| g_loss: 0.830| d_loss: 0.637| gp_loss: 0.049| r_loss: 0.119| p_loss: 0.194| v_loss: 0.034| per_loss: 0.573 | a_loss: 0.523
Train: Epoch [643/3000], Step [90/158]| g_loss: 0.813| d_loss: 0.662| gp_loss: 0.051| r_loss: 0.126| p_loss: 0.206| v_loss: 0.036| per_loss: 0.532 | a_loss: 0.495
Train: Epoch [643/3000], Step [120/158]| g_loss: 0.813| d_loss: 0.617| gp_loss: 0.056| r_loss: 0.118| p_loss: 0.186| v_loss: 0.034| per_loss: 0.516 | a_loss: 0.516
Train: Epoch [643/3000], Step [150/158]| g_loss: 0.908| d_loss: 0.514| gp_loss: 0.052| r_loss: 0.115| p_loss: 0.187| v_loss: 0.035| per_loss: 0.509 | a_loss: 0.613
Train: Epoch [644/3000], Step [30/158]| g_loss: 0.815| d_loss: 0.720| gp_loss: 0.114| r_loss: 0.118| p_loss: 0.191| v_loss: 0.034| per_loss: 0.539 | a_loss: 0.513
Train: Epoch [644/3000], Step [60/158]| g_loss: 0.835| d_loss: 0.640| gp_loss: 0.050| r_loss: 0.121| p_loss: 0.189| v_loss: 0.035| per_loss: 0.502 | a_loss: 0.534
Train: Epoch [644/3000], Step [90/158]| g_loss: 0.825| d_loss: 0.549| gp_loss: 0.050| r_loss: 0.114| p_loss: 0.180| v_loss: 0.034| per_loss: 0.489 | a_loss: 0.538
Train: Epoch [644/3000], Step [120/158]| g_loss: 0.822| d_loss: 0.658| gp_loss: 0.052| r_loss: 0.117| p_loss: 0.184| v_loss: 0.034| per_loss: 0.530 | a_loss: 0.527
Train: Epoch [644/3000], Step [150/158]| g_loss: 0.811| d_loss: 0.575| gp_loss: 0.056| r_loss: 0.111| p_loss: 0.186| v_loss: 0.035| per_loss: 0.527 | a_loss: 0.519
Train: Epoch [645/3000], Step [30/158]| g_loss: 0.919| d_loss: 0.615| gp_loss: 0.132| r_loss: 0.114| p_loss: 0.183| v_loss: 0.034| per_loss: 0.527 | a_loss: 0.627
Train: Epoch [645/3000], Step [60/158]| g_loss: 0.796| d_loss: 0.584| gp_loss: 0.051| r_loss: 0.116| p_loss: 0.181| v_loss: 0.035| per_loss: 0.506 | a_loss: 0.504
Train: Epoch [645/3000], Step [90/158]| g_loss: 0.808| d_loss: 0.643| gp_loss: 0.050| r_loss: 0.118| p_loss: 0.183| v_loss: 0.035| per_loss: 0.524 | a_loss: 0.512
Train: Epoch [645/3000], Step [120/158]| g_loss: 0.818| d_loss: 0.632| gp_loss: 0.052| r_loss: 0.119| p_loss: 0.185| v_loss: 0.035| per_loss: 0.496 | a_loss: 0.522
Train: Epoch [645/3000], Step [150/158]| g_loss: 0.838| d_loss: 0.540| gp_loss: 0.056| r_loss: 0.112| p_loss: 0.181| v_loss: 0.035| per_loss: 0.527 | a_loss: 0.548
Train: Epoch [646/3000], Step [30/158]| g_loss: 0.842| d_loss: 0.728| gp_loss: 0.144| r_loss: 0.119| p_loss: 0.197| v_loss: 0.034| per_loss: 0.516 | a_loss: 0.538
Train: Epoch [646/3000], Step [60/158]| g_loss: 0.900| d_loss: 0.522| gp_loss: 0.045| r_loss: 0.120| p_loss: 0.191| v_loss: 0.035| per_loss: 0.504 | a_loss: 0.599
Train: Epoch [646/3000], Step [90/158]| g_loss: 0.829| d_loss: 0.635| gp_loss: 0.050| r_loss: 0.109| p_loss: 0.184| v_loss: 0.033| per_loss: 0.518 | a_loss: 0.544
Train: Epoch [646/3000], Step [120/158]| g_loss: 0.791| d_loss: 0.606| gp_loss: 0.051| r_loss: 0.116| p_loss: 0.179| v_loss: 0.035| per_loss: 0.523 | a_loss: 0.499
Train: Epoch [646/3000], Step [150/158]| g_loss: 0.788| d_loss: 0.624| gp_loss: 0.050| r_loss: 0.120| p_loss: 0.183| v_loss: 0.034| per_loss: 0.492 | a_loss: 0.494
Train: Epoch [647/3000], Step [30/158]| g_loss: 0.782| d_loss: 0.722| gp_loss: 0.135| r_loss: 0.113| p_loss: 0.178| v_loss: 0.034| per_loss: 0.518 | a_loss: 0.494
Train: Epoch [647/3000], Step [60/158]| g_loss: 0.801| d_loss: 0.611| gp_loss: 0.049| r_loss: 0.112| p_loss: 0.178| v_loss: 0.034| per_loss: 0.527 | a_loss: 0.514
Train: Epoch [647/3000], Step [90/158]| g_loss: 0.879| d_loss: 0.514| gp_loss: 0.048| r_loss: 0.113| p_loss: 0.180| v_loss: 0.034| per_loss: 0.520 | a_loss: 0.591
Train: Epoch [647/3000], Step [120/158]| g_loss: 0.773| d_loss: 0.670| gp_loss: 0.051| r_loss: 0.112| p_loss: 0.179| v_loss: 0.033| per_loss: 0.496 | a_loss: 0.489
Train: Epoch [647/3000], Step [150/158]| g_loss: 0.846| d_loss: 0.653| gp_loss: 0.050| r_loss: 0.119| p_loss: 0.187| v_loss: 0.032| per_loss: 0.505 | a_loss: 0.551
Train: Epoch [648/3000], Step [30/158]| g_loss: 0.824| d_loss: 0.676| gp_loss: 0.167| r_loss: 0.121| p_loss: 0.181| v_loss: 0.033| per_loss: 0.474 | a_loss: 0.533
Train: Epoch [648/3000], Step [60/158]| g_loss: 0.765| d_loss: 0.617| gp_loss: 0.047| r_loss: 0.105| p_loss: 0.173| v_loss: 0.033| per_loss: 0.494 | a_loss: 0.492
Train: Epoch [648/3000], Step [90/158]| g_loss: 0.791| d_loss: 0.584| gp_loss: 0.049| r_loss: 0.112| p_loss: 0.178| v_loss: 0.033| per_loss: 0.495 | a_loss: 0.508
Train: Epoch [648/3000], Step [120/158]| g_loss: 0.839| d_loss: 0.652| gp_loss: 0.045| r_loss: 0.121| p_loss: 0.191| v_loss: 0.034| per_loss: 0.504 | a_loss: 0.538
Train: Epoch [648/3000], Step [150/158]| g_loss: 0.828| d_loss: 0.553| gp_loss: 0.047| r_loss: 0.117| p_loss: 0.180| v_loss: 0.033| per_loss: 0.448 | a_loss: 0.544
Train: Epoch [649/3000], Step [30/158]| g_loss: 0.858| d_loss: 0.678| gp_loss: 0.179| r_loss: 0.124| p_loss: 0.184| v_loss: 0.035| per_loss: 0.468 | a_loss: 0.560
Train: Epoch [649/3000], Step [60/158]| g_loss: 0.814| d_loss: 0.641| gp_loss: 0.044| r_loss: 0.119| p_loss: 0.187| v_loss: 0.035| per_loss: 0.488 | a_loss: 0.518
Train: Epoch [649/3000], Step [90/158]| g_loss: 0.768| d_loss: 0.636| gp_loss: 0.046| r_loss: 0.110| p_loss: 0.169| v_loss: 0.031| per_loss: 0.491 | a_loss: 0.494
Train: Epoch [649/3000], Step [120/158]| g_loss: 0.780| d_loss: 0.602| gp_loss: 0.048| r_loss: 0.111| p_loss: 0.170| v_loss: 0.032| per_loss: 0.471 | a_loss: 0.504
Train: Epoch [649/3000], Step [150/158]| g_loss: 0.850| d_loss: 0.591| gp_loss: 0.048| r_loss: 0.115| p_loss: 0.176| v_loss: 0.033| per_loss: 0.507 | a_loss: 0.563
Train: Epoch [650/3000], Step [30/158]| g_loss: 0.792| d_loss: 0.660| gp_loss: 0.134| r_loss: 0.116| p_loss: 0.174| v_loss: 0.033| per_loss: 0.471 | a_loss: 0.509
Train: Epoch [650/3000], Step [60/158]| g_loss: 0.784| d_loss: 0.635| gp_loss: 0.046| r_loss: 0.115| p_loss: 0.176| v_loss: 0.033| per_loss: 0.479 | a_loss: 0.500
Train: Epoch [650/3000], Step [90/158]| g_loss: 0.832| d_loss: 0.594| gp_loss: 0.046| r_loss: 0.110| p_loss: 0.175| v_loss: 0.033| per_loss: 0.481 | a_loss: 0.553
Train: Epoch [650/3000], Step [120/158]| g_loss: 0.802| d_loss: 0.635| gp_loss: 0.048| r_loss: 0.112| p_loss: 0.168| v_loss: 0.033| per_loss: 0.479 | a_loss: 0.525
Train: Epoch [650/3000], Step [150/158]| g_loss: 0.768| d_loss: 0.583| gp_loss: 0.048| r_loss: 0.109| p_loss: 0.170| v_loss: 0.033| per_loss: 0.515 | a_loss: 0.490
Test: Epoch [650/3000]| g_loss: 0.671| r_loss: 0.407| p_loss: 0.305| v_loss: 0.026
Train: Epoch [651/3000], Step [30/158]| g_loss: 0.881| d_loss: 0.559| gp_loss: 0.044| r_loss: 0.120| p_loss: 0.181| v_loss: 0.035| per_loss: 0.506 | a_loss: 0.585
Train: Epoch [651/3000], Step [60/158]| g_loss: 0.738| d_loss: 0.660| gp_loss: 0.047| r_loss: 0.108| p_loss: 0.170| v_loss: 0.034| per_loss: 0.458 | a_loss: 0.466
Train: Epoch [651/3000], Step [90/158]| g_loss: 0.817| d_loss: 0.578| gp_loss: 0.049| r_loss: 0.109| p_loss: 0.166| v_loss: 0.031| per_loss: 0.492 | a_loss: 0.545
Train: Epoch [651/3000], Step [120/158]| g_loss: 0.820| d_loss: 0.541| gp_loss: 0.047| r_loss: 0.104| p_loss: 0.162| v_loss: 0.032| per_loss: 0.482 | a_loss: 0.555
Train: Epoch [651/3000], Step [150/158]| g_loss: 0.826| d_loss: 0.608| gp_loss: 0.051| r_loss: 0.113| p_loss: 0.174| v_loss: 0.033| per_loss: 0.464 | a_loss: 0.547
Train: Epoch [652/3000], Step [30/158]| g_loss: 0.793| d_loss: 0.713| gp_loss: 0.149| r_loss: 0.112| p_loss: 0.167| v_loss: 0.031| per_loss: 0.454 | a_loss: 0.521
Train: Epoch [652/3000], Step [60/158]| g_loss: 0.783| d_loss: 0.596| gp_loss: 0.047| r_loss: 0.111| p_loss: 0.164| v_loss: 0.032| per_loss: 0.496 | a_loss: 0.509
Train: Epoch [652/3000], Step [90/158]| g_loss: 0.835| d_loss: 0.536| gp_loss: 0.049| r_loss: 0.106| p_loss: 0.164| v_loss: 0.032| per_loss: 0.476 | a_loss: 0.567
Train: Epoch [652/3000], Step [120/158]| g_loss: 0.796| d_loss: 0.579| gp_loss: 0.047| r_loss: 0.111| p_loss: 0.171| v_loss: 0.033| per_loss: 0.484 | a_loss: 0.518
Train: Epoch [652/3000], Step [150/158]| g_loss: 0.820| d_loss: 0.624| gp_loss: 0.046| r_loss: 0.110| p_loss: 0.175| v_loss: 0.033| per_loss: 0.462 | a_loss: 0.543
Train: Epoch [653/3000], Step [30/158]| g_loss: 0.788| d_loss: 0.775| gp_loss: 0.156| r_loss: 0.112| p_loss: 0.172| v_loss: 0.032| per_loss: 0.470 | a_loss: 0.511
Train: Epoch [653/3000], Step [60/158]| g_loss: 0.799| d_loss: 0.571| gp_loss: 0.047| r_loss: 0.110| p_loss: 0.173| v_loss: 0.034| per_loss: 0.466 | a_loss: 0.521
Train: Epoch [653/3000], Step [90/158]| g_loss: 0.807| d_loss: 0.588| gp_loss: 0.044| r_loss: 0.117| p_loss: 0.176| v_loss: 0.032| per_loss: 0.489 | a_loss: 0.521
Train: Epoch [653/3000], Step [120/158]| g_loss: 0.845| d_loss: 0.549| gp_loss: 0.046| r_loss: 0.111| p_loss: 0.166| v_loss: 0.032| per_loss: 0.454 | a_loss: 0.573
Train: Epoch [653/3000], Step [150/158]| g_loss: 0.809| d_loss: 0.549| gp_loss: 0.053| r_loss: 0.101| p_loss: 0.167| v_loss: 0.031| per_loss: 0.497 | a_loss: 0.544
Train: Epoch [654/3000], Step [30/158]| g_loss: 0.834| d_loss: 0.640| gp_loss: 0.120| r_loss: 0.109| p_loss: 0.173| v_loss: 0.031| per_loss: 0.463 | a_loss: 0.562
Train: Epoch [654/3000], Step [60/158]| g_loss: 0.754| d_loss: 0.617| gp_loss: 0.047| r_loss: 0.114| p_loss: 0.174| v_loss: 0.032| per_loss: 0.459 | a_loss: 0.475
Train: Epoch [654/3000], Step [90/158]| g_loss: 0.817| d_loss: 0.628| gp_loss: 0.049| r_loss: 0.103| p_loss: 0.174| v_loss: 0.031| per_loss: 0.495 | a_loss: 0.547
Train: Epoch [654/3000], Step [120/158]| g_loss: 0.854| d_loss: 0.596| gp_loss: 0.051| r_loss: 0.117| p_loss: 0.186| v_loss: 0.033| per_loss: 0.522 | a_loss: 0.560
Train: Epoch [654/3000], Step [150/158]| g_loss: 0.790| d_loss: 0.614| gp_loss: 0.049| r_loss: 0.118| p_loss: 0.186| v_loss: 0.034| per_loss: 0.475 | a_loss: 0.497
Train: Epoch [655/3000], Step [30/158]| g_loss: 0.888| d_loss: 0.573| gp_loss: 0.108| r_loss: 0.110| p_loss: 0.182| v_loss: 0.033| per_loss: 0.498 | a_loss: 0.604
Train: Epoch [655/3000], Step [60/158]| g_loss: 0.821| d_loss: 0.594| gp_loss: 0.049| r_loss: 0.113| p_loss: 0.178| v_loss: 0.033| per_loss: 0.494 | a_loss: 0.538
Train: Epoch [655/3000], Step [90/158]| g_loss: 0.814| d_loss: 0.604| gp_loss: 0.049| r_loss: 0.105| p_loss: 0.175| v_loss: 0.033| per_loss: 0.468 | a_loss: 0.541
Train: Epoch [655/3000], Step [120/158]| g_loss: 0.749| d_loss: 0.716| gp_loss: 0.051| r_loss: 0.110| p_loss: 0.183| v_loss: 0.032| per_loss: 0.515 | a_loss: 0.463
Train: Epoch [655/3000], Step [150/158]| g_loss: 0.838| d_loss: 0.556| gp_loss: 0.050| r_loss: 0.117| p_loss: 0.178| v_loss: 0.033| per_loss: 0.514 | a_loss: 0.549
Train: Epoch [656/3000], Step [30/158]| g_loss: 0.804| d_loss: 0.685| gp_loss: 0.100| r_loss: 0.110| p_loss: 0.190| v_loss: 0.033| per_loss: 0.518 | a_loss: 0.513
Train: Epoch [656/3000], Step [60/158]| g_loss: 0.892| d_loss: 0.585| gp_loss: 0.049| r_loss: 0.122| p_loss: 0.208| v_loss: 0.034| per_loss: 0.515 | a_loss: 0.580
Train: Epoch [656/3000], Step [90/158]| g_loss: 0.912| d_loss: 0.511| gp_loss: 0.048| r_loss: 0.123| p_loss: 0.214| v_loss: 0.034| per_loss: 0.496 | a_loss: 0.598
Train: Epoch [656/3000], Step [120/158]| g_loss: 0.917| d_loss: 0.503| gp_loss: 0.051| r_loss: 0.144| p_loss: 0.232| v_loss: 0.034| per_loss: 0.516 | a_loss: 0.571
Train: Epoch [656/3000], Step [150/158]| g_loss: 0.904| d_loss: 0.651| gp_loss: 0.051| r_loss: 0.142| p_loss: 0.245| v_loss: 0.033| per_loss: 0.498 | a_loss: 0.557
Train: Epoch [657/3000], Step [30/158]| g_loss: 0.816| d_loss: 0.700| gp_loss: 0.125| r_loss: 0.120| p_loss: 0.204| v_loss: 0.033| per_loss: 0.489 | a_loss: 0.511
Train: Epoch [657/3000], Step [60/158]| g_loss: 0.794| d_loss: 0.630| gp_loss: 0.051| r_loss: 0.117| p_loss: 0.190| v_loss: 0.033| per_loss: 0.507 | a_loss: 0.497
Train: Epoch [657/3000], Step [90/158]| g_loss: 0.848| d_loss: 0.562| gp_loss: 0.047| r_loss: 0.121| p_loss: 0.196| v_loss: 0.033| per_loss: 0.491 | a_loss: 0.546
Train: Epoch [657/3000], Step [120/158]| g_loss: 0.838| d_loss: 0.529| gp_loss: 0.053| r_loss: 0.120| p_loss: 0.178| v_loss: 0.033| per_loss: 0.487 | a_loss: 0.548
Train: Epoch [657/3000], Step [150/158]| g_loss: 0.808| d_loss: 0.640| gp_loss: 0.051| r_loss: 0.117| p_loss: 0.179| v_loss: 0.032| per_loss: 0.498 | a_loss: 0.520
Train: Epoch [658/3000], Step [30/158]| g_loss: 0.862| d_loss: 0.593| gp_loss: 0.125| r_loss: 0.109| p_loss: 0.167| v_loss: 0.034| per_loss: 0.486 | a_loss: 0.588
Train: Epoch [658/3000], Step [60/158]| g_loss: 0.813| d_loss: 0.598| gp_loss: 0.050| r_loss: 0.109| p_loss: 0.175| v_loss: 0.034| per_loss: 0.459 | a_loss: 0.537
Train: Epoch [658/3000], Step [90/158]| g_loss: 0.756| d_loss: 0.695| gp_loss: 0.053| r_loss: 0.114| p_loss: 0.178| v_loss: 0.030| per_loss: 0.479 | a_loss: 0.475
Train: Epoch [658/3000], Step [120/158]| g_loss: 0.816| d_loss: 0.565| gp_loss: 0.053| r_loss: 0.113| p_loss: 0.174| v_loss: 0.032| per_loss: 0.496 | a_loss: 0.535
Train: Epoch [658/3000], Step [150/158]| g_loss: 0.832| d_loss: 0.545| gp_loss: 0.051| r_loss: 0.109| p_loss: 0.179| v_loss: 0.032| per_loss: 0.462 | a_loss: 0.556
Train: Epoch [659/3000], Step [30/158]| g_loss: 0.831| d_loss: 0.576| gp_loss: 0.086| r_loss: 0.112| p_loss: 0.176| v_loss: 0.034| per_loss: 0.481 | a_loss: 0.549
Train: Epoch [659/3000], Step [60/158]| g_loss: 0.832| d_loss: 0.667| gp_loss: 0.054| r_loss: 0.116| p_loss: 0.184| v_loss: 0.034| per_loss: 0.455 | a_loss: 0.544
Train: Epoch [659/3000], Step [90/158]| g_loss: 0.759| d_loss: 0.698| gp_loss: 0.054| r_loss: 0.110| p_loss: 0.173| v_loss: 0.033| per_loss: 0.484 | a_loss: 0.481
Train: Epoch [659/3000], Step [120/158]| g_loss: 0.828| d_loss: 0.532| gp_loss: 0.055| r_loss: 0.111| p_loss: 0.175| v_loss: 0.034| per_loss: 0.492 | a_loss: 0.547
Train: Epoch [659/3000], Step [150/158]| g_loss: 0.769| d_loss: 0.670| gp_loss: 0.054| r_loss: 0.109| p_loss: 0.172| v_loss: 0.031| per_loss: 0.473 | a_loss: 0.496
Train: Epoch [660/3000], Step [30/158]| g_loss: 0.837| d_loss: 0.658| gp_loss: 0.177| r_loss: 0.113| p_loss: 0.170| v_loss: 0.032| per_loss: 0.481 | a_loss: 0.559
Train: Epoch [660/3000], Step [60/158]| g_loss: 0.832| d_loss: 0.607| gp_loss: 0.051| r_loss: 0.110| p_loss: 0.171| v_loss: 0.033| per_loss: 0.458 | a_loss: 0.558
Train: Epoch [660/3000], Step [90/158]| g_loss: 0.793| d_loss: 0.579| gp_loss: 0.053| r_loss: 0.106| p_loss: 0.164| v_loss: 0.033| per_loss: 0.481 | a_loss: 0.524
Train: Epoch [660/3000], Step [120/158]| g_loss: 0.785| d_loss: 0.635| gp_loss: 0.055| r_loss: 0.107| p_loss: 0.171| v_loss: 0.034| per_loss: 0.474 | a_loss: 0.510
Train: Epoch [660/3000], Step [150/158]| g_loss: 0.809| d_loss: 0.652| gp_loss: 0.055| r_loss: 0.112| p_loss: 0.173| v_loss: 0.031| per_loss: 0.465 | a_loss: 0.533
Train: Epoch [661/3000], Step [30/158]| g_loss: 0.803| d_loss: 0.728| gp_loss: 0.168| r_loss: 0.106| p_loss: 0.172| v_loss: 0.033| per_loss: 0.499 | a_loss: 0.527
Train: Epoch [661/3000], Step [60/158]| g_loss: 0.771| d_loss: 0.570| gp_loss: 0.051| r_loss: 0.101| p_loss: 0.162| v_loss: 0.031| per_loss: 0.452 | a_loss: 0.513
Train: Epoch [661/3000], Step [90/158]| g_loss: 0.834| d_loss: 0.644| gp_loss: 0.049| r_loss: 0.115| p_loss: 0.175| v_loss: 0.033| per_loss: 0.500 | a_loss: 0.549
Train: Epoch [661/3000], Step [120/158]| g_loss: 0.859| d_loss: 0.555| gp_loss: 0.047| r_loss: 0.111| p_loss: 0.170| v_loss: 0.033| per_loss: 0.454 | a_loss: 0.585
Train: Epoch [661/3000], Step [150/158]| g_loss: 0.792| d_loss: 0.577| gp_loss: 0.051| r_loss: 0.112| p_loss: 0.171| v_loss: 0.035| per_loss: 0.454 | a_loss: 0.514
Train: Epoch [662/3000], Step [30/158]| g_loss: 0.785| d_loss: 0.701| gp_loss: 0.116| r_loss: 0.107| p_loss: 0.171| v_loss: 0.032| per_loss: 0.479 | a_loss: 0.512
Train: Epoch [662/3000], Step [60/158]| g_loss: 0.892| d_loss: 0.502| gp_loss: 0.051| r_loss: 0.111| p_loss: 0.171| v_loss: 0.034| per_loss: 0.511 | a_loss: 0.610
Train: Epoch [662/3000], Step [90/158]| g_loss: 0.791| d_loss: 0.618| gp_loss: 0.052| r_loss: 0.108| p_loss: 0.165| v_loss: 0.032| per_loss: 0.440 | a_loss: 0.525
Train: Epoch [662/3000], Step [120/158]| g_loss: 0.756| d_loss: 0.670| gp_loss: 0.050| r_loss: 0.108| p_loss: 0.167| v_loss: 0.032| per_loss: 0.467 | a_loss: 0.486
Train: Epoch [662/3000], Step [150/158]| g_loss: 0.783| d_loss: 0.581| gp_loss: 0.052| r_loss: 0.110| p_loss: 0.170| v_loss: 0.033| per_loss: 0.491 | a_loss: 0.506
Train: Epoch [663/3000], Step [30/158]| g_loss: 0.805| d_loss: 0.685| gp_loss: 0.125| r_loss: 0.105| p_loss: 0.163| v_loss: 0.033| per_loss: 0.498 | a_loss: 0.534
Train: Epoch [663/3000], Step [60/158]| g_loss: 0.805| d_loss: 0.603| gp_loss: 0.049| r_loss: 0.109| p_loss: 0.169| v_loss: 0.032| per_loss: 0.445 | a_loss: 0.534
Train: Epoch [663/3000], Step [90/158]| g_loss: 0.813| d_loss: 0.582| gp_loss: 0.052| r_loss: 0.106| p_loss: 0.168| v_loss: 0.033| per_loss: 0.481 | a_loss: 0.543
Train: Epoch [663/3000], Step [120/158]| g_loss: 0.799| d_loss: 0.624| gp_loss: 0.050| r_loss: 0.110| p_loss: 0.170| v_loss: 0.032| per_loss: 0.446 | a_loss: 0.528
Train: Epoch [663/3000], Step [150/158]| g_loss: 0.854| d_loss: 0.519| gp_loss: 0.053| r_loss: 0.112| p_loss: 0.174| v_loss: 0.034| per_loss: 0.509 | a_loss: 0.569
Train: Epoch [664/3000], Step [30/158]| g_loss: 0.793| d_loss: 0.744| gp_loss: 0.170| r_loss: 0.107| p_loss: 0.170| v_loss: 0.033| per_loss: 0.465 | a_loss: 0.521
Train: Epoch [664/3000], Step [60/158]| g_loss: 0.808| d_loss: 0.561| gp_loss: 0.052| r_loss: 0.104| p_loss: 0.163| v_loss: 0.032| per_loss: 0.469 | a_loss: 0.544
Train: Epoch [664/3000], Step [90/158]| g_loss: 0.799| d_loss: 0.608| gp_loss: 0.049| r_loss: 0.106| p_loss: 0.170| v_loss: 0.034| per_loss: 0.497 | a_loss: 0.525
Train: Epoch [664/3000], Step [120/158]| g_loss: 0.856| d_loss: 0.548| gp_loss: 0.051| r_loss: 0.113| p_loss: 0.167| v_loss: 0.033| per_loss: 0.489 | a_loss: 0.577
Train: Epoch [664/3000], Step [150/158]| g_loss: 0.813| d_loss: 0.602| gp_loss: 0.051| r_loss: 0.108| p_loss: 0.168| v_loss: 0.032| per_loss: 0.475 | a_loss: 0.541
Train: Epoch [665/3000], Step [30/158]| g_loss: 0.865| d_loss: 0.585| gp_loss: 0.141| r_loss: 0.108| p_loss: 0.164| v_loss: 0.032| per_loss: 0.499 | a_loss: 0.593
Train: Epoch [665/3000], Step [60/158]| g_loss: 0.812| d_loss: 0.593| gp_loss: 0.049| r_loss: 0.104| p_loss: 0.167| v_loss: 0.032| per_loss: 0.491 | a_loss: 0.544
Train: Epoch [665/3000], Step [90/158]| g_loss: 0.786| d_loss: 0.594| gp_loss: 0.050| r_loss: 0.106| p_loss: 0.166| v_loss: 0.034| per_loss: 0.504 | a_loss: 0.512
Train: Epoch [665/3000], Step [120/158]| g_loss: 0.815| d_loss: 0.625| gp_loss: 0.052| r_loss: 0.108| p_loss: 0.171| v_loss: 0.033| per_loss: 0.474 | a_loss: 0.540
Train: Epoch [665/3000], Step [150/158]| g_loss: 0.814| d_loss: 0.618| gp_loss: 0.050| r_loss: 0.113| p_loss: 0.177| v_loss: 0.033| per_loss: 0.495 | a_loss: 0.530
Train: Epoch [666/3000], Step [30/158]| g_loss: 0.741| d_loss: 0.723| gp_loss: 0.117| r_loss: 0.110| p_loss: 0.168| v_loss: 0.033| per_loss: 0.463 | a_loss: 0.468
Train: Epoch [666/3000], Step [60/158]| g_loss: 0.820| d_loss: 0.608| gp_loss: 0.051| r_loss: 0.114| p_loss: 0.172| v_loss: 0.032| per_loss: 0.467 | a_loss: 0.542
Train: Epoch [666/3000], Step [90/158]| g_loss: 0.777| d_loss: 0.619| gp_loss: 0.051| r_loss: 0.114| p_loss: 0.175| v_loss: 0.032| per_loss: 0.460 | a_loss: 0.497
Train: Epoch [666/3000], Step [120/158]| g_loss: 0.801| d_loss: 0.571| gp_loss: 0.057| r_loss: 0.105| p_loss: 0.163| v_loss: 0.032| per_loss: 0.494 | a_loss: 0.534
Train: Epoch [666/3000], Step [150/158]| g_loss: 0.893| d_loss: 0.482| gp_loss: 0.055| r_loss: 0.108| p_loss: 0.167| v_loss: 0.033| per_loss: 0.531 | a_loss: 0.615
Train: Epoch [667/3000], Step [30/158]| g_loss: 0.825| d_loss: 0.676| gp_loss: 0.153| r_loss: 0.106| p_loss: 0.167| v_loss: 0.032| per_loss: 0.500 | a_loss: 0.554
Train: Epoch [667/3000], Step [60/158]| g_loss: 0.856| d_loss: 0.542| gp_loss: 0.055| r_loss: 0.117| p_loss: 0.173| v_loss: 0.034| per_loss: 0.502 | a_loss: 0.569
Train: Epoch [667/3000], Step [90/158]| g_loss: 0.770| d_loss: 0.631| gp_loss: 0.054| r_loss: 0.110| p_loss: 0.181| v_loss: 0.034| per_loss: 0.475 | a_loss: 0.488
Train: Epoch [667/3000], Step [120/158]| g_loss: 0.854| d_loss: 0.538| gp_loss: 0.058| r_loss: 0.112| p_loss: 0.169| v_loss: 0.032| per_loss: 0.506 | a_loss: 0.574
Train: Epoch [667/3000], Step [150/158]| g_loss: 0.848| d_loss: 0.568| gp_loss: 0.058| r_loss: 0.111| p_loss: 0.176| v_loss: 0.033| per_loss: 0.515 | a_loss: 0.565
Train: Epoch [668/3000], Step [30/158]| g_loss: 0.853| d_loss: 0.645| gp_loss: 0.143| r_loss: 0.114| p_loss: 0.182| v_loss: 0.033| per_loss: 0.522 | a_loss: 0.563
Train: Epoch [668/3000], Step [60/158]| g_loss: 0.762| d_loss: 0.691| gp_loss: 0.055| r_loss: 0.111| p_loss: 0.181| v_loss: 0.033| per_loss: 0.486 | a_loss: 0.478
Train: Epoch [668/3000], Step [90/158]| g_loss: 0.847| d_loss: 0.595| gp_loss: 0.056| r_loss: 0.121| p_loss: 0.180| v_loss: 0.035| per_loss: 0.522 | a_loss: 0.549
Train: Epoch [668/3000], Step [120/158]| g_loss: 0.772| d_loss: 0.641| gp_loss: 0.060| r_loss: 0.112| p_loss: 0.180| v_loss: 0.032| per_loss: 0.489 | a_loss: 0.488
Train: Epoch [668/3000], Step [150/158]| g_loss: 0.852| d_loss: 0.490| gp_loss: 0.062| r_loss: 0.110| p_loss: 0.171| v_loss: 0.033| per_loss: 0.508 | a_loss: 0.572
Train: Epoch [669/3000], Step [30/158]| g_loss: 0.924| d_loss: 0.570| gp_loss: 0.135| r_loss: 0.112| p_loss: 0.173| v_loss: 0.034| per_loss: 0.535 | a_loss: 0.638
Train: Epoch [669/3000], Step [60/158]| g_loss: 0.827| d_loss: 0.642| gp_loss: 0.054| r_loss: 0.112| p_loss: 0.177| v_loss: 0.034| per_loss: 0.499 | a_loss: 0.542
Train: Epoch [669/3000], Step [90/158]| g_loss: 0.795| d_loss: 0.569| gp_loss: 0.051| r_loss: 0.109| p_loss: 0.174| v_loss: 0.035| per_loss: 0.478 | a_loss: 0.516
Train: Epoch [669/3000], Step [120/158]| g_loss: 0.847| d_loss: 0.604| gp_loss: 0.054| r_loss: 0.115| p_loss: 0.173| v_loss: 0.033| per_loss: 0.509 | a_loss: 0.562
Train: Epoch [669/3000], Step [150/158]| g_loss: 0.829| d_loss: 0.626| gp_loss: 0.053| r_loss: 0.110| p_loss: 0.169| v_loss: 0.034| per_loss: 0.491 | a_loss: 0.552
Train: Epoch [670/3000], Step [30/158]| g_loss: 0.768| d_loss: 0.719| gp_loss: 0.156| r_loss: 0.108| p_loss: 0.169| v_loss: 0.033| per_loss: 0.506 | a_loss: 0.493
Train: Epoch [670/3000], Step [60/158]| g_loss: 0.883| d_loss: 0.486| gp_loss: 0.049| r_loss: 0.106| p_loss: 0.166| v_loss: 0.034| per_loss: 0.513 | a_loss: 0.608
Train: Epoch [670/3000], Step [90/158]| g_loss: 0.780| d_loss: 0.638| gp_loss: 0.051| r_loss: 0.111| p_loss: 0.169| v_loss: 0.034| per_loss: 0.496 | a_loss: 0.501
Train: Epoch [670/3000], Step [120/158]| g_loss: 0.798| d_loss: 0.654| gp_loss: 0.055| r_loss: 0.113| p_loss: 0.171| v_loss: 0.034| per_loss: 0.503 | a_loss: 0.515
Train: Epoch [670/3000], Step [150/158]| g_loss: 0.790| d_loss: 0.580| gp_loss: 0.054| r_loss: 0.109| p_loss: 0.169| v_loss: 0.034| per_loss: 0.505 | a_loss: 0.512
Train: Epoch [671/3000], Step [30/158]| g_loss: 0.794| d_loss: 0.736| gp_loss: 0.101| r_loss: 0.118| p_loss: 0.191| v_loss: 0.035| per_loss: 0.518 | a_loss: 0.494
Train: Epoch [671/3000], Step [60/158]| g_loss: 0.873| d_loss: 0.549| gp_loss: 0.050| r_loss: 0.108| p_loss: 0.169| v_loss: 0.032| per_loss: 0.474 | a_loss: 0.601
Train: Epoch [671/3000], Step [90/158]| g_loss: 0.742| d_loss: 0.658| gp_loss: 0.051| r_loss: 0.106| p_loss: 0.171| v_loss: 0.034| per_loss: 0.468 | a_loss: 0.470
Train: Epoch [671/3000], Step [120/158]| g_loss: 0.829| d_loss: 0.587| gp_loss: 0.056| r_loss: 0.119| p_loss: 0.177| v_loss: 0.034| per_loss: 0.545 | a_loss: 0.532
Train: Epoch [671/3000], Step [150/158]| g_loss: 0.847| d_loss: 0.568| gp_loss: 0.059| r_loss: 0.117| p_loss: 0.168| v_loss: 0.034| per_loss: 0.467 | a_loss: 0.565
Train: Epoch [672/3000], Step [30/158]| g_loss: 0.810| d_loss: 0.717| gp_loss: 0.115| r_loss: 0.112| p_loss: 0.173| v_loss: 0.034| per_loss: 0.526 | a_loss: 0.525
Train: Epoch [672/3000], Step [60/158]| g_loss: 0.811| d_loss: 0.544| gp_loss: 0.052| r_loss: 0.114| p_loss: 0.172| v_loss: 0.033| per_loss: 0.487 | a_loss: 0.529
Train: Epoch [672/3000], Step [90/158]| g_loss: 0.884| d_loss: 0.565| gp_loss: 0.052| r_loss: 0.108| p_loss: 0.170| v_loss: 0.034| per_loss: 0.519 | a_loss: 0.606
Train: Epoch [672/3000], Step [120/158]| g_loss: 0.839| d_loss: 0.570| gp_loss: 0.053| r_loss: 0.113| p_loss: 0.172| v_loss: 0.034| per_loss: 0.489 | a_loss: 0.557
Train: Epoch [672/3000], Step [150/158]| g_loss: 0.795| d_loss: 0.651| gp_loss: 0.052| r_loss: 0.111| p_loss: 0.172| v_loss: 0.032| per_loss: 0.458 | a_loss: 0.521
Train: Epoch [673/3000], Step [30/158]| g_loss: 0.821| d_loss: 0.621| gp_loss: 0.097| r_loss: 0.115| p_loss: 0.175| v_loss: 0.034| per_loss: 0.478 | a_loss: 0.537
Train: Epoch [673/3000], Step [60/158]| g_loss: 0.866| d_loss: 0.590| gp_loss: 0.052| r_loss: 0.114| p_loss: 0.177| v_loss: 0.033| per_loss: 0.495 | a_loss: 0.580
Train: Epoch [673/3000], Step [90/158]| g_loss: 0.808| d_loss: 0.565| gp_loss: 0.054| r_loss: 0.105| p_loss: 0.171| v_loss: 0.032| per_loss: 0.510 | a_loss: 0.535
Train: Epoch [673/3000], Step [120/158]| g_loss: 0.796| d_loss: 0.673| gp_loss: 0.053| r_loss: 0.110| p_loss: 0.180| v_loss: 0.031| per_loss: 0.514 | a_loss: 0.514
Train: Epoch [673/3000], Step [150/158]| g_loss: 0.823| d_loss: 0.572| gp_loss: 0.057| r_loss: 0.112| p_loss: 0.175| v_loss: 0.033| per_loss: 0.467 | a_loss: 0.544
Train: Epoch [674/3000], Step [30/158]| g_loss: 0.865| d_loss: 0.710| gp_loss: 0.190| r_loss: 0.115| p_loss: 0.177| v_loss: 0.033| per_loss: 0.516 | a_loss: 0.577
Train: Epoch [674/3000], Step [60/158]| g_loss: 0.819| d_loss: 0.549| gp_loss: 0.051| r_loss: 0.120| p_loss: 0.179| v_loss: 0.034| per_loss: 0.509 | a_loss: 0.524
Train: Epoch [674/3000], Step [90/158]| g_loss: 0.842| d_loss: 0.610| gp_loss: 0.053| r_loss: 0.110| p_loss: 0.178| v_loss: 0.032| per_loss: 0.486 | a_loss: 0.562
Train: Epoch [674/3000], Step [120/158]| g_loss: 0.761| d_loss: 0.636| gp_loss: 0.054| r_loss: 0.108| p_loss: 0.166| v_loss: 0.032| per_loss: 0.501 | a_loss: 0.488
Train: Epoch [674/3000], Step [150/158]| g_loss: 0.878| d_loss: 0.522| gp_loss: 0.055| r_loss: 0.109| p_loss: 0.170| v_loss: 0.034| per_loss: 0.432 | a_loss: 0.607
Train: Epoch [675/3000], Step [30/158]| g_loss: 0.818| d_loss: 0.704| gp_loss: 0.218| r_loss: 0.105| p_loss: 0.161| v_loss: 0.033| per_loss: 0.496 | a_loss: 0.550
Train: Epoch [675/3000], Step [60/158]| g_loss: 0.829| d_loss: 0.586| gp_loss: 0.050| r_loss: 0.108| p_loss: 0.168| v_loss: 0.032| per_loss: 0.526 | a_loss: 0.553
Train: Epoch [675/3000], Step [90/158]| g_loss: 0.872| d_loss: 0.564| gp_loss: 0.050| r_loss: 0.107| p_loss: 0.170| v_loss: 0.034| per_loss: 0.511 | a_loss: 0.595
Train: Epoch [675/3000], Step [120/158]| g_loss: 0.790| d_loss: 0.642| gp_loss: 0.048| r_loss: 0.110| p_loss: 0.172| v_loss: 0.032| per_loss: 0.472 | a_loss: 0.515
Train: Epoch [675/3000], Step [150/158]| g_loss: 0.790| d_loss: 0.600| gp_loss: 0.051| r_loss: 0.107| p_loss: 0.163| v_loss: 0.032| per_loss: 0.476 | a_loss: 0.522
Train: Epoch [676/3000], Step [30/158]| g_loss: 0.786| d_loss: 0.786| gp_loss: 0.171| r_loss: 0.108| p_loss: 0.173| v_loss: 0.031| per_loss: 0.487 | a_loss: 0.511
Train: Epoch [676/3000], Step [60/158]| g_loss: 0.772| d_loss: 0.629| gp_loss: 0.048| r_loss: 0.118| p_loss: 0.179| v_loss: 0.032| per_loss: 0.463 | a_loss: 0.486
Train: Epoch [676/3000], Step [90/158]| g_loss: 0.809| d_loss: 0.555| gp_loss: 0.052| r_loss: 0.109| p_loss: 0.164| v_loss: 0.032| per_loss: 0.489 | a_loss: 0.537
Train: Epoch [676/3000], Step [120/158]| g_loss: 0.866| d_loss: 0.583| gp_loss: 0.048| r_loss: 0.104| p_loss: 0.165| v_loss: 0.032| per_loss: 0.461 | a_loss: 0.603
Train: Epoch [676/3000], Step [150/158]| g_loss: 0.845| d_loss: 0.471| gp_loss: 0.054| r_loss: 0.109| p_loss: 0.169| v_loss: 0.032| per_loss: 0.509 | a_loss: 0.569
Train: Epoch [677/3000], Step [30/158]| g_loss: 0.850| d_loss: 0.679| gp_loss: 0.121| r_loss: 0.111| p_loss: 0.179| v_loss: 0.033| per_loss: 0.473 | a_loss: 0.569
Train: Epoch [677/3000], Step [60/158]| g_loss: 0.804| d_loss: 0.604| gp_loss: 0.050| r_loss: 0.112| p_loss: 0.180| v_loss: 0.033| per_loss: 0.469 | a_loss: 0.522
Train: Epoch [677/3000], Step [90/158]| g_loss: 0.818| d_loss: 0.596| gp_loss: 0.051| r_loss: 0.113| p_loss: 0.166| v_loss: 0.032| per_loss: 0.499 | a_loss: 0.539
Train: Epoch [677/3000], Step [120/158]| g_loss: 0.867| d_loss: 0.477| gp_loss: 0.053| r_loss: 0.106| p_loss: 0.169| v_loss: 0.033| per_loss: 0.520 | a_loss: 0.592
Train: Epoch [677/3000], Step [150/158]| g_loss: 0.838| d_loss: 0.586| gp_loss: 0.051| r_loss: 0.109| p_loss: 0.175| v_loss: 0.033| per_loss: 0.462 | a_loss: 0.563
Train: Epoch [678/3000], Step [30/158]| g_loss: 0.825| d_loss: 0.650| gp_loss: 0.142| r_loss: 0.105| p_loss: 0.163| v_loss: 0.032| per_loss: 0.495 | a_loss: 0.557
Train: Epoch [678/3000], Step [60/158]| g_loss: 0.752| d_loss: 0.695| gp_loss: 0.051| r_loss: 0.104| p_loss: 0.161| v_loss: 0.031| per_loss: 0.462 | a_loss: 0.490
Train: Epoch [678/3000], Step [90/158]| g_loss: 0.846| d_loss: 0.602| gp_loss: 0.045| r_loss: 0.113| p_loss: 0.179| v_loss: 0.033| per_loss: 0.496 | a_loss: 0.562
Train: Epoch [678/3000], Step [120/158]| g_loss: 0.849| d_loss: 0.490| gp_loss: 0.053| r_loss: 0.111| p_loss: 0.162| v_loss: 0.033| per_loss: 0.495 | a_loss: 0.574
Train: Epoch [678/3000], Step [150/158]| g_loss: 0.840| d_loss: 0.564| gp_loss: 0.052| r_loss: 0.103| p_loss: 0.162| v_loss: 0.032| per_loss: 0.487 | a_loss: 0.575
Train: Epoch [679/3000], Step [30/158]| g_loss: 0.803| d_loss: 0.750| gp_loss: 0.189| r_loss: 0.109| p_loss: 0.172| v_loss: 0.033| per_loss: 0.520 | a_loss: 0.524
Train: Epoch [679/3000], Step [60/158]| g_loss: 0.761| d_loss: 0.650| gp_loss: 0.048| r_loss: 0.106| p_loss: 0.170| v_loss: 0.033| per_loss: 0.484 | a_loss: 0.489
Train: Epoch [679/3000], Step [90/158]| g_loss: 0.807| d_loss: 0.604| gp_loss: 0.047| r_loss: 0.114| p_loss: 0.170| v_loss: 0.031| per_loss: 0.472 | a_loss: 0.530
Train: Epoch [679/3000], Step [120/158]| g_loss: 0.818| d_loss: 0.627| gp_loss: 0.048| r_loss: 0.105| p_loss: 0.164| v_loss: 0.031| per_loss: 0.490 | a_loss: 0.550
Train: Epoch [679/3000], Step [150/158]| g_loss: 0.840| d_loss: 0.469| gp_loss: 0.054| r_loss: 0.102| p_loss: 0.166| v_loss: 0.031| per_loss: 0.465 | a_loss: 0.577
Train: Epoch [680/3000], Step [30/158]| g_loss: 0.844| d_loss: 0.704| gp_loss: 0.146| r_loss: 0.110| p_loss: 0.175| v_loss: 0.031| per_loss: 0.499 | a_loss: 0.565
Train: Epoch [680/3000], Step [60/158]| g_loss: 0.837| d_loss: 0.538| gp_loss: 0.049| r_loss: 0.103| p_loss: 0.158| v_loss: 0.033| per_loss: 0.484 | a_loss: 0.574
Train: Epoch [680/3000], Step [90/158]| g_loss: 0.816| d_loss: 0.594| gp_loss: 0.047| r_loss: 0.107| p_loss: 0.166| v_loss: 0.033| per_loss: 0.472 | a_loss: 0.546
Train: Epoch [680/3000], Step [120/158]| g_loss: 0.829| d_loss: 0.611| gp_loss: 0.046| r_loss: 0.113| p_loss: 0.181| v_loss: 0.032| per_loss: 0.527 | a_loss: 0.540
Train: Epoch [680/3000], Step [150/158]| g_loss: 0.768| d_loss: 0.610| gp_loss: 0.049| r_loss: 0.108| p_loss: 0.171| v_loss: 0.033| per_loss: 0.453 | a_loss: 0.496
Train: Epoch [681/3000], Step [30/158]| g_loss: 0.853| d_loss: 0.735| gp_loss: 0.147| r_loss: 0.151| p_loss: 0.222| v_loss: 0.033| per_loss: 0.544 | a_loss: 0.503
Train: Epoch [681/3000], Step [60/158]| g_loss: 0.812| d_loss: 0.561| gp_loss: 0.050| r_loss: 0.115| p_loss: 0.185| v_loss: 0.032| per_loss: 0.468 | a_loss: 0.526
Train: Epoch [681/3000], Step [90/158]| g_loss: 0.853| d_loss: 0.551| gp_loss: 0.049| r_loss: 0.122| p_loss: 0.185| v_loss: 0.033| per_loss: 0.458 | a_loss: 0.561
Train: Epoch [681/3000], Step [120/158]| g_loss: 0.891| d_loss: 0.576| gp_loss: 0.046| r_loss: 0.117| p_loss: 0.191| v_loss: 0.032| per_loss: 0.482 | a_loss: 0.598
Train: Epoch [681/3000], Step [150/158]| g_loss: 0.777| d_loss: 0.624| gp_loss: 0.048| r_loss: 0.114| p_loss: 0.186| v_loss: 0.034| per_loss: 0.459 | a_loss: 0.491
Train: Epoch [682/3000], Step [30/158]| g_loss: 0.835| d_loss: 0.656| gp_loss: 0.146| r_loss: 0.110| p_loss: 0.170| v_loss: 0.032| per_loss: 0.431 | a_loss: 0.565
Train: Epoch [682/3000], Step [60/158]| g_loss: 0.816| d_loss: 0.624| gp_loss: 0.049| r_loss: 0.107| p_loss: 0.180| v_loss: 0.034| per_loss: 0.497 | a_loss: 0.536
Train: Epoch [682/3000], Step [90/158]| g_loss: 0.822| d_loss: 0.582| gp_loss: 0.052| r_loss: 0.109| p_loss: 0.174| v_loss: 0.033| per_loss: 0.447 | a_loss: 0.548
Train: Epoch [682/3000], Step [120/158]| g_loss: 0.831| d_loss: 0.579| gp_loss: 0.051| r_loss: 0.113| p_loss: 0.168| v_loss: 0.032| per_loss: 0.492 | a_loss: 0.551
Train: Epoch [682/3000], Step [150/158]| g_loss: 0.813| d_loss: 0.626| gp_loss: 0.051| r_loss: 0.108| p_loss: 0.170| v_loss: 0.031| per_loss: 0.486 | a_loss: 0.540
Train: Epoch [683/3000], Step [30/158]| g_loss: 0.771| d_loss: 0.674| gp_loss: 0.104| r_loss: 0.105| p_loss: 0.164| v_loss: 0.032| per_loss: 0.458 | a_loss: 0.506
Train: Epoch [683/3000], Step [60/158]| g_loss: 0.795| d_loss: 0.629| gp_loss: 0.048| r_loss: 0.116| p_loss: 0.168| v_loss: 0.033| per_loss: 0.479 | a_loss: 0.514
Train: Epoch [683/3000], Step [90/158]| g_loss: 0.797| d_loss: 0.594| gp_loss: 0.053| r_loss: 0.107| p_loss: 0.172| v_loss: 0.032| per_loss: 0.463 | a_loss: 0.525
Train: Epoch [683/3000], Step [120/158]| g_loss: 0.853| d_loss: 0.525| gp_loss: 0.052| r_loss: 0.108| p_loss: 0.173| v_loss: 0.034| per_loss: 0.475 | a_loss: 0.577
Train: Epoch [683/3000], Step [150/158]| g_loss: 0.815| d_loss: 0.595| gp_loss: 0.054| r_loss: 0.103| p_loss: 0.162| v_loss: 0.031| per_loss: 0.492 | a_loss: 0.550
Train: Epoch [684/3000], Step [30/158]| g_loss: 0.791| d_loss: 0.630| gp_loss: 0.124| r_loss: 0.107| p_loss: 0.167| v_loss: 0.034| per_loss: 0.449 | a_loss: 0.522
Train: Epoch [684/3000], Step [60/158]| g_loss: 0.813| d_loss: 0.644| gp_loss: 0.055| r_loss: 0.108| p_loss: 0.168| v_loss: 0.033| per_loss: 0.494 | a_loss: 0.539
Train: Epoch [684/3000], Step [90/158]| g_loss: 0.825| d_loss: 0.574| gp_loss: 0.051| r_loss: 0.108| p_loss: 0.164| v_loss: 0.032| per_loss: 0.452 | a_loss: 0.557
Train: Epoch [684/3000], Step [120/158]| g_loss: 0.817| d_loss: 0.520| gp_loss: 0.053| r_loss: 0.109| p_loss: 0.166| v_loss: 0.033| per_loss: 0.461 | a_loss: 0.546
Train: Epoch [684/3000], Step [150/158]| g_loss: 0.826| d_loss: 0.589| gp_loss: 0.057| r_loss: 0.107| p_loss: 0.173| v_loss: 0.032| per_loss: 0.491 | a_loss: 0.551
Train: Epoch [685/3000], Step [30/158]| g_loss: 0.860| d_loss: 0.600| gp_loss: 0.134| r_loss: 0.106| p_loss: 0.163| v_loss: 0.032| per_loss: 0.478 | a_loss: 0.593
Train: Epoch [685/3000], Step [60/158]| g_loss: 0.832| d_loss: 0.545| gp_loss: 0.053| r_loss: 0.111| p_loss: 0.173| v_loss: 0.034| per_loss: 0.498 | a_loss: 0.552
Train: Epoch [685/3000], Step [90/158]| g_loss: 0.839| d_loss: 0.582| gp_loss: 0.053| r_loss: 0.104| p_loss: 0.162| v_loss: 0.033| per_loss: 0.499 | a_loss: 0.570
Train: Epoch [685/3000], Step [120/158]| g_loss: 0.753| d_loss: 0.668| gp_loss: 0.056| r_loss: 0.111| p_loss: 0.170| v_loss: 0.031| per_loss: 0.482 | a_loss: 0.477
Train: Epoch [685/3000], Step [150/158]| g_loss: 0.777| d_loss: 0.625| gp_loss: 0.056| r_loss: 0.106| p_loss: 0.165| v_loss: 0.033| per_loss: 0.495 | a_loss: 0.506
Train: Epoch [686/3000], Step [30/158]| g_loss: 0.874| d_loss: 0.635| gp_loss: 0.185| r_loss: 0.105| p_loss: 0.160| v_loss: 0.033| per_loss: 0.513 | a_loss: 0.604
Train: Epoch [686/3000], Step [60/158]| g_loss: 0.895| d_loss: 0.469| gp_loss: 0.050| r_loss: 0.104| p_loss: 0.159| v_loss: 0.034| per_loss: 0.493 | a_loss: 0.629
Train: Epoch [686/3000], Step [90/158]| g_loss: 0.781| d_loss: 0.682| gp_loss: 0.047| r_loss: 0.110| p_loss: 0.173| v_loss: 0.034| per_loss: 0.444 | a_loss: 0.507
Train: Epoch [686/3000], Step [120/158]| g_loss: 0.799| d_loss: 0.615| gp_loss: 0.052| r_loss: 0.108| p_loss: 0.175| v_loss: 0.035| per_loss: 0.463 | a_loss: 0.523
Train: Epoch [686/3000], Step [150/158]| g_loss: 0.736| d_loss: 0.633| gp_loss: 0.053| r_loss: 0.103| p_loss: 0.162| v_loss: 0.032| per_loss: 0.502 | a_loss: 0.470
Train: Epoch [687/3000], Step [30/158]| g_loss: 0.844| d_loss: 0.636| gp_loss: 0.133| r_loss: 0.110| p_loss: 0.168| v_loss: 0.033| per_loss: 0.554 | a_loss: 0.562
Train: Epoch [687/3000], Step [60/158]| g_loss: 0.849| d_loss: 0.569| gp_loss: 0.050| r_loss: 0.106| p_loss: 0.166| v_loss: 0.033| per_loss: 0.504 | a_loss: 0.577
Train: Epoch [687/3000], Step [90/158]| g_loss: 0.834| d_loss: 0.583| gp_loss: 0.049| r_loss: 0.106| p_loss: 0.166| v_loss: 0.033| per_loss: 0.546 | a_loss: 0.557
Train: Epoch [687/3000], Step [120/158]| g_loss: 0.825| d_loss: 0.578| gp_loss: 0.054| r_loss: 0.110| p_loss: 0.170| v_loss: 0.034| per_loss: 0.471 | a_loss: 0.549
Train: Epoch [687/3000], Step [150/158]| g_loss: 0.783| d_loss: 0.640| gp_loss: 0.055| r_loss: 0.111| p_loss: 0.171| v_loss: 0.033| per_loss: 0.462 | a_loss: 0.507
Train: Epoch [688/3000], Step [30/158]| g_loss: 0.809| d_loss: 0.659| gp_loss: 0.098| r_loss: 0.107| p_loss: 0.173| v_loss: 0.033| per_loss: 0.491 | a_loss: 0.533
Train: Epoch [688/3000], Step [60/158]| g_loss: 0.845| d_loss: 0.497| gp_loss: 0.050| r_loss: 0.105| p_loss: 0.169| v_loss: 0.034| per_loss: 0.474 | a_loss: 0.574
Train: Epoch [688/3000], Step [90/158]| g_loss: 0.883| d_loss: 0.543| gp_loss: 0.054| r_loss: 0.112| p_loss: 0.176| v_loss: 0.033| per_loss: 0.481 | a_loss: 0.601
Train: Epoch [688/3000], Step [120/158]| g_loss: 0.868| d_loss: 0.590| gp_loss: 0.053| r_loss: 0.118| p_loss: 0.175| v_loss: 0.033| per_loss: 0.491 | a_loss: 0.581
Train: Epoch [688/3000], Step [150/158]| g_loss: 0.740| d_loss: 0.713| gp_loss: 0.054| r_loss: 0.105| p_loss: 0.170| v_loss: 0.032| per_loss: 0.469 | a_loss: 0.471
Train: Epoch [689/3000], Step [30/158]| g_loss: 0.831| d_loss: 0.686| gp_loss: 0.103| r_loss: 0.110| p_loss: 0.182| v_loss: 0.034| per_loss: 0.495 | a_loss: 0.546
Train: Epoch [689/3000], Step [60/158]| g_loss: 0.824| d_loss: 0.549| gp_loss: 0.054| r_loss: 0.123| p_loss: 0.188| v_loss: 0.035| per_loss: 0.500 | a_loss: 0.522
Train: Epoch [689/3000], Step [90/158]| g_loss: 0.886| d_loss: 0.555| gp_loss: 0.053| r_loss: 0.110| p_loss: 0.172| v_loss: 0.032| per_loss: 0.497 | a_loss: 0.608
Train: Epoch [689/3000], Step [120/158]| g_loss: 0.767| d_loss: 0.606| gp_loss: 0.053| r_loss: 0.107| p_loss: 0.173| v_loss: 0.033| per_loss: 0.470 | a_loss: 0.494
Train: Epoch [689/3000], Step [150/158]| g_loss: 0.814| d_loss: 0.612| gp_loss: 0.057| r_loss: 0.109| p_loss: 0.173| v_loss: 0.034| per_loss: 0.481 | a_loss: 0.538
Train: Epoch [690/3000], Step [30/158]| g_loss: 0.847| d_loss: 0.690| gp_loss: 0.194| r_loss: 0.111| p_loss: 0.172| v_loss: 0.034| per_loss: 0.466 | a_loss: 0.569
Train: Epoch [690/3000], Step [60/158]| g_loss: 0.826| d_loss: 0.548| gp_loss: 0.051| r_loss: 0.105| p_loss: 0.167| v_loss: 0.033| per_loss: 0.488 | a_loss: 0.555
Train: Epoch [690/3000], Step [90/158]| g_loss: 0.812| d_loss: 0.618| gp_loss: 0.049| r_loss: 0.106| p_loss: 0.171| v_loss: 0.034| per_loss: 0.482 | a_loss: 0.538
Train: Epoch [690/3000], Step [120/158]| g_loss: 0.791| d_loss: 0.604| gp_loss: 0.052| r_loss: 0.106| p_loss: 0.171| v_loss: 0.033| per_loss: 0.481 | a_loss: 0.518
Train: Epoch [690/3000], Step [150/158]| g_loss: 0.842| d_loss: 0.569| gp_loss: 0.055| r_loss: 0.111| p_loss: 0.173| v_loss: 0.032| per_loss: 0.452 | a_loss: 0.568
Train: Epoch [691/3000], Step [30/158]| g_loss: 0.774| d_loss: 0.730| gp_loss: 0.149| r_loss: 0.112| p_loss: 0.170| v_loss: 0.032| per_loss: 0.456 | a_loss: 0.500
Train: Epoch [691/3000], Step [60/158]| g_loss: 0.801| d_loss: 0.557| gp_loss: 0.052| r_loss: 0.101| p_loss: 0.164| v_loss: 0.033| per_loss: 0.447 | a_loss: 0.540
Train: Epoch [691/3000], Step [90/158]| g_loss: 0.790| d_loss: 0.681| gp_loss: 0.050| r_loss: 0.112| p_loss: 0.171| v_loss: 0.033| per_loss: 0.460 | a_loss: 0.514
Train: Epoch [691/3000], Step [120/158]| g_loss: 0.821| d_loss: 0.591| gp_loss: 0.057| r_loss: 0.110| p_loss: 0.173| v_loss: 0.033| per_loss: 0.482 | a_loss: 0.543
Train: Epoch [691/3000], Step [150/158]| g_loss: 0.836| d_loss: 0.534| gp_loss: 0.056| r_loss: 0.106| p_loss: 0.171| v_loss: 0.033| per_loss: 0.532 | a_loss: 0.558
Train: Epoch [692/3000], Step [30/158]| g_loss: 0.854| d_loss: 0.621| gp_loss: 0.147| r_loss: 0.104| p_loss: 0.168| v_loss: 0.033| per_loss: 0.494 | a_loss: 0.584
Train: Epoch [692/3000], Step [60/158]| g_loss: 0.840| d_loss: 0.535| gp_loss: 0.052| r_loss: 0.110| p_loss: 0.169| v_loss: 0.032| per_loss: 0.479 | a_loss: 0.566
Train: Epoch [692/3000], Step [90/158]| g_loss: 0.807| d_loss: 0.601| gp_loss: 0.053| r_loss: 0.107| p_loss: 0.166| v_loss: 0.031| per_loss: 0.474 | a_loss: 0.539
Train: Epoch [692/3000], Step [120/158]| g_loss: 0.835| d_loss: 0.610| gp_loss: 0.052| r_loss: 0.106| p_loss: 0.166| v_loss: 0.032| per_loss: 0.461 | a_loss: 0.568
Train: Epoch [692/3000], Step [150/158]| g_loss: 0.825| d_loss: 0.539| gp_loss: 0.052| r_loss: 0.104| p_loss: 0.167| v_loss: 0.033| per_loss: 0.496 | a_loss: 0.555
Train: Epoch [693/3000], Step [30/158]| g_loss: 0.745| d_loss: 0.707| gp_loss: 0.080| r_loss: 0.113| p_loss: 0.164| v_loss: 0.031| per_loss: 0.425 | a_loss: 0.476
Train: Epoch [693/3000], Step [60/158]| g_loss: 0.853| d_loss: 0.534| gp_loss: 0.056| r_loss: 0.105| p_loss: 0.163| v_loss: 0.034| per_loss: 0.497 | a_loss: 0.582
Train: Epoch [693/3000], Step [90/158]| g_loss: 0.901| d_loss: 0.491| gp_loss: 0.051| r_loss: 0.111| p_loss: 0.171| v_loss: 0.034| per_loss: 0.502 | a_loss: 0.620
Train: Epoch [693/3000], Step [120/158]| g_loss: 0.714| d_loss: 0.690| gp_loss: 0.055| r_loss: 0.101| p_loss: 0.159| v_loss: 0.032| per_loss: 0.459 | a_loss: 0.456
Train: Epoch [693/3000], Step [150/158]| g_loss: 0.826| d_loss: 0.599| gp_loss: 0.057| r_loss: 0.112| p_loss: 0.168| v_loss: 0.031| per_loss: 0.483 | a_loss: 0.551
Train: Epoch [694/3000], Step [30/158]| g_loss: 0.879| d_loss: 0.573| gp_loss: 0.146| r_loss: 0.105| p_loss: 0.166| v_loss: 0.033| per_loss: 0.498 | a_loss: 0.607
Train: Epoch [694/3000], Step [60/158]| g_loss: 0.764| d_loss: 0.661| gp_loss: 0.049| r_loss: 0.108| p_loss: 0.175| v_loss: 0.032| per_loss: 0.462 | a_loss: 0.491
Train: Epoch [694/3000], Step [90/158]| g_loss: 0.862| d_loss: 0.553| gp_loss: 0.052| r_loss: 0.114| p_loss: 0.178| v_loss: 0.033| per_loss: 0.469 | a_loss: 0.579
Train: Epoch [694/3000], Step [120/158]| g_loss: 0.843| d_loss: 0.595| gp_loss: 0.055| r_loss: 0.111| p_loss: 0.175| v_loss: 0.032| per_loss: 0.448 | a_loss: 0.567
Train: Epoch [694/3000], Step [150/158]| g_loss: 0.815| d_loss: 0.543| gp_loss: 0.056| r_loss: 0.112| p_loss: 0.172| v_loss: 0.032| per_loss: 0.494 | a_loss: 0.536
Train: Epoch [695/3000], Step [30/158]| g_loss: 0.933| d_loss: 0.486| gp_loss: 0.121| r_loss: 0.105| p_loss: 0.162| v_loss: 0.033| per_loss: 0.526 | a_loss: 0.662
Train: Epoch [695/3000], Step [60/158]| g_loss: 0.815| d_loss: 0.662| gp_loss: 0.050| r_loss: 0.108| p_loss: 0.171| v_loss: 0.031| per_loss: 0.456 | a_loss: 0.545
Train: Epoch [695/3000], Step [90/158]| g_loss: 0.812| d_loss: 0.542| gp_loss: 0.053| r_loss: 0.105| p_loss: 0.178| v_loss: 0.032| per_loss: 0.478 | a_loss: 0.538
Train: Epoch [695/3000], Step [120/158]| g_loss: 0.807| d_loss: 0.610| gp_loss: 0.053| r_loss: 0.107| p_loss: 0.168| v_loss: 0.031| per_loss: 0.468 | a_loss: 0.538
Train: Epoch [695/3000], Step [150/158]| g_loss: 0.740| d_loss: 0.663| gp_loss: 0.055| r_loss: 0.102| p_loss: 0.166| v_loss: 0.031| per_loss: 0.450 | a_loss: 0.480
Train: Epoch [696/3000], Step [30/158]| g_loss: 0.830| d_loss: 0.691| gp_loss: 0.160| r_loss: 0.103| p_loss: 0.168| v_loss: 0.031| per_loss: 0.433 | a_loss: 0.569
Train: Epoch [696/3000], Step [60/158]| g_loss: 0.774| d_loss: 0.598| gp_loss: 0.054| r_loss: 0.103| p_loss: 0.165| v_loss: 0.031| per_loss: 0.494 | a_loss: 0.508
Train: Epoch [696/3000], Step [90/158]| g_loss: 0.768| d_loss: 0.618| gp_loss: 0.054| r_loss: 0.108| p_loss: 0.174| v_loss: 0.032| per_loss: 0.472 | a_loss: 0.493
Train: Epoch [696/3000], Step [120/158]| g_loss: 0.893| d_loss: 0.491| gp_loss: 0.054| r_loss: 0.113| p_loss: 0.178| v_loss: 0.034| per_loss: 0.470 | a_loss: 0.609
Train: Epoch [696/3000], Step [150/158]| g_loss: 0.833| d_loss: 0.601| gp_loss: 0.053| r_loss: 0.111| p_loss: 0.182| v_loss: 0.032| per_loss: 0.513 | a_loss: 0.548
Train: Epoch [697/3000], Step [30/158]| g_loss: 0.793| d_loss: 0.696| gp_loss: 0.128| r_loss: 0.108| p_loss: 0.175| v_loss: 0.031| per_loss: 0.478 | a_loss: 0.519
Train: Epoch [697/3000], Step [60/158]| g_loss: 0.821| d_loss: 0.588| gp_loss: 0.052| r_loss: 0.107| p_loss: 0.179| v_loss: 0.032| per_loss: 0.474 | a_loss: 0.544
Train: Epoch [697/3000], Step [90/158]| g_loss: 0.799| d_loss: 0.627| gp_loss: 0.052| r_loss: 0.109| p_loss: 0.172| v_loss: 0.032| per_loss: 0.492 | a_loss: 0.523
Train: Epoch [697/3000], Step [120/158]| g_loss: 0.797| d_loss: 0.590| gp_loss: 0.055| r_loss: 0.108| p_loss: 0.176| v_loss: 0.031| per_loss: 0.502 | a_loss: 0.520
Train: Epoch [697/3000], Step [150/158]| g_loss: 0.780| d_loss: 0.641| gp_loss: 0.055| r_loss: 0.110| p_loss: 0.171| v_loss: 0.032| per_loss: 0.456 | a_loss: 0.507
Train: Epoch [698/3000], Step [30/158]| g_loss: 0.849| d_loss: 0.687| gp_loss: 0.175| r_loss: 0.119| p_loss: 0.189| v_loss: 0.033| per_loss: 0.479 | a_loss: 0.554
Train: Epoch [698/3000], Step [60/158]| g_loss: 0.784| d_loss: 0.597| gp_loss: 0.052| r_loss: 0.111| p_loss: 0.179| v_loss: 0.033| per_loss: 0.492 | a_loss: 0.501
Train: Epoch [698/3000], Step [90/158]| g_loss: 0.836| d_loss: 0.612| gp_loss: 0.051| r_loss: 0.107| p_loss: 0.171| v_loss: 0.033| per_loss: 0.458 | a_loss: 0.565
Train: Epoch [698/3000], Step [120/158]| g_loss: 0.797| d_loss: 0.625| gp_loss: 0.049| r_loss: 0.110| p_loss: 0.170| v_loss: 0.033| per_loss: 0.488 | a_loss: 0.520
Train: Epoch [698/3000], Step [150/158]| g_loss: 0.788| d_loss: 0.606| gp_loss: 0.050| r_loss: 0.105| p_loss: 0.172| v_loss: 0.031| per_loss: 0.488 | a_loss: 0.517
Train: Epoch [699/3000], Step [30/158]| g_loss: 0.846| d_loss: 0.657| gp_loss: 0.128| r_loss: 0.110| p_loss: 0.172| v_loss: 0.033| per_loss: 0.492 | a_loss: 0.568
Train: Epoch [699/3000], Step [60/158]| g_loss: 0.777| d_loss: 0.610| gp_loss: 0.046| r_loss: 0.104| p_loss: 0.161| v_loss: 0.032| per_loss: 0.448 | a_loss: 0.515
Train: Epoch [699/3000], Step [90/158]| g_loss: 0.831| d_loss: 0.542| gp_loss: 0.053| r_loss: 0.101| p_loss: 0.162| v_loss: 0.032| per_loss: 0.509 | a_loss: 0.566
Train: Epoch [699/3000], Step [120/158]| g_loss: 0.763| d_loss: 0.599| gp_loss: 0.055| r_loss: 0.107| p_loss: 0.168| v_loss: 0.033| per_loss: 0.438 | a_loss: 0.496
Train: Epoch [699/3000], Step [150/158]| g_loss: 0.822| d_loss: 0.636| gp_loss: 0.048| r_loss: 0.108| p_loss: 0.168| v_loss: 0.032| per_loss: 0.463 | a_loss: 0.552
Train: Epoch [700/3000], Step [30/158]| g_loss: 0.774| d_loss: 0.733| gp_loss: 0.123| r_loss: 0.105| p_loss: 0.164| v_loss: 0.032| per_loss: 0.467 | a_loss: 0.507
Train: Epoch [700/3000], Step [60/158]| g_loss: 0.754| d_loss: 0.679| gp_loss: 0.051| r_loss: 0.105| p_loss: 0.169| v_loss: 0.031| per_loss: 0.465 | a_loss: 0.487
Train: Epoch [700/3000], Step [90/158]| g_loss: 0.833| d_loss: 0.470| gp_loss: 0.052| r_loss: 0.104| p_loss: 0.168| v_loss: 0.032| per_loss: 0.483 | a_loss: 0.565
Train: Epoch [700/3000], Step [120/158]| g_loss: 0.906| d_loss: 0.515| gp_loss: 0.051| r_loss: 0.109| p_loss: 0.167| v_loss: 0.032| per_loss: 0.457 | a_loss: 0.636
Train: Epoch [700/3000], Step [150/158]| g_loss: 0.819| d_loss: 0.556| gp_loss: 0.052| r_loss: 0.103| p_loss: 0.164| v_loss: 0.033| per_loss: 0.460 | a_loss: 0.554
Test: Epoch [700/3000]| g_loss: 0.647| r_loss: 0.401| p_loss: 0.296| v_loss: 0.026
Train: Epoch [701/3000], Step [30/158]| g_loss: 0.839| d_loss: 0.560| gp_loss: 0.046| r_loss: 0.103| p_loss: 0.173| v_loss: 0.032| per_loss: 0.481 | a_loss: 0.569
Train: Epoch [701/3000], Step [60/158]| g_loss: 0.830| d_loss: 0.501| gp_loss: 0.048| r_loss: 0.104| p_loss: 0.166| v_loss: 0.034| per_loss: 0.473 | a_loss: 0.561
Train: Epoch [701/3000], Step [90/158]| g_loss: 0.706| d_loss: 0.744| gp_loss: 0.049| r_loss: 0.109| p_loss: 0.168| v_loss: 0.033| per_loss: 0.461 | a_loss: 0.434
Train: Epoch [701/3000], Step [120/158]| g_loss: 0.835| d_loss: 0.560| gp_loss: 0.051| r_loss: 0.103| p_loss: 0.167| v_loss: 0.033| per_loss: 0.460 | a_loss: 0.569
Train: Epoch [701/3000], Step [150/158]| g_loss: 0.813| d_loss: 0.559| gp_loss: 0.051| r_loss: 0.104| p_loss: 0.160| v_loss: 0.031| per_loss: 0.453 | a_loss: 0.552
Train: Epoch [702/3000], Step [30/158]| g_loss: 0.855| d_loss: 0.599| gp_loss: 0.155| r_loss: 0.102| p_loss: 0.163| v_loss: 0.033| per_loss: 0.476 | a_loss: 0.590
Train: Epoch [702/3000], Step [60/158]| g_loss: 0.844| d_loss: 0.532| gp_loss: 0.049| r_loss: 0.105| p_loss: 0.159| v_loss: 0.032| per_loss: 0.442 | a_loss: 0.584
Train: Epoch [702/3000], Step [90/158]| g_loss: 0.727| d_loss: 0.728| gp_loss: 0.048| r_loss: 0.106| p_loss: 0.167| v_loss: 0.032| per_loss: 0.464 | a_loss: 0.459
Train: Epoch [702/3000], Step [120/158]| g_loss: 0.782| d_loss: 0.657| gp_loss: 0.051| r_loss: 0.111| p_loss: 0.173| v_loss: 0.033| per_loss: 0.495 | a_loss: 0.502
Train: Epoch [702/3000], Step [150/158]| g_loss: 0.806| d_loss: 0.522| gp_loss: 0.050| r_loss: 0.106| p_loss: 0.165| v_loss: 0.033| per_loss: 0.468 | a_loss: 0.538
Train: Epoch [703/3000], Step [30/158]| g_loss: 0.793| d_loss: 0.715| gp_loss: 0.115| r_loss: 0.107| p_loss: 0.169| v_loss: 0.032| per_loss: 0.477 | a_loss: 0.521
Train: Epoch [703/3000], Step [60/158]| g_loss: 0.861| d_loss: 0.525| gp_loss: 0.051| r_loss: 0.107| p_loss: 0.169| v_loss: 0.033| per_loss: 0.497 | a_loss: 0.587
Train: Epoch [703/3000], Step [90/158]| g_loss: 0.766| d_loss: 0.728| gp_loss: 0.051| r_loss: 0.109| p_loss: 0.175| v_loss: 0.031| per_loss: 0.449 | a_loss: 0.494
Train: Epoch [703/3000], Step [120/158]| g_loss: 0.759| d_loss: 0.579| gp_loss: 0.049| r_loss: 0.103| p_loss: 0.167| v_loss: 0.031| per_loss: 0.441 | a_loss: 0.498
Train: Epoch [703/3000], Step [150/158]| g_loss: 0.830| d_loss: 0.563| gp_loss: 0.048| r_loss: 0.105| p_loss: 0.161| v_loss: 0.032| per_loss: 0.457 | a_loss: 0.567
Train: Epoch [704/3000], Step [30/158]| g_loss: 0.816| d_loss: 0.652| gp_loss: 0.128| r_loss: 0.103| p_loss: 0.159| v_loss: 0.031| per_loss: 0.447 | a_loss: 0.558
Train: Epoch [704/3000], Step [60/158]| g_loss: 0.775| d_loss: 0.590| gp_loss: 0.049| r_loss: 0.107| p_loss: 0.168| v_loss: 0.033| per_loss: 0.485 | a_loss: 0.502
Train: Epoch [704/3000], Step [90/158]| g_loss: 0.819| d_loss: 0.628| gp_loss: 0.053| r_loss: 0.106| p_loss: 0.170| v_loss: 0.030| per_loss: 0.442 | a_loss: 0.553
Train: Epoch [704/3000], Step [120/158]| g_loss: 0.763| d_loss: 0.597| gp_loss: 0.055| r_loss: 0.104| p_loss: 0.166| v_loss: 0.031| per_loss: 0.445 | a_loss: 0.500
Train: Epoch [704/3000], Step [150/158]| g_loss: 0.851| d_loss: 0.557| gp_loss: 0.053| r_loss: 0.104| p_loss: 0.168| v_loss: 0.032| per_loss: 0.464 | a_loss: 0.584
Train: Epoch [705/3000], Step [30/158]| g_loss: 0.805| d_loss: 0.695| gp_loss: 0.137| r_loss: 0.105| p_loss: 0.168| v_loss: 0.032| per_loss: 0.450 | a_loss: 0.539
Train: Epoch [705/3000], Step [60/158]| g_loss: 0.789| d_loss: 0.587| gp_loss: 0.051| r_loss: 0.110| p_loss: 0.168| v_loss: 0.032| per_loss: 0.433 | a_loss: 0.520
Train: Epoch [705/3000], Step [90/158]| g_loss: 0.816| d_loss: 0.571| gp_loss: 0.050| r_loss: 0.106| p_loss: 0.168| v_loss: 0.031| per_loss: 0.467 | a_loss: 0.548
Train: Epoch [705/3000], Step [120/158]| g_loss: 0.755| d_loss: 0.621| gp_loss: 0.055| r_loss: 0.097| p_loss: 0.158| v_loss: 0.030| per_loss: 0.451 | a_loss: 0.504
Train: Epoch [705/3000], Step [150/158]| g_loss: 0.847| d_loss: 0.545| gp_loss: 0.055| r_loss: 0.107| p_loss: 0.172| v_loss: 0.035| per_loss: 0.490 | a_loss: 0.570
Train: Epoch [706/3000], Step [30/158]| g_loss: 0.798| d_loss: 0.664| gp_loss: 0.117| r_loss: 0.105| p_loss: 0.165| v_loss: 0.033| per_loss: 0.455 | a_loss: 0.532
Train: Epoch [706/3000], Step [60/158]| g_loss: 0.862| d_loss: 0.571| gp_loss: 0.052| r_loss: 0.105| p_loss: 0.168| v_loss: 0.032| per_loss: 0.472 | a_loss: 0.595
Train: Epoch [706/3000], Step [90/158]| g_loss: 0.799| d_loss: 0.576| gp_loss: 0.055| r_loss: 0.105| p_loss: 0.165| v_loss: 0.032| per_loss: 0.461 | a_loss: 0.532
Train: Epoch [706/3000], Step [120/158]| g_loss: 0.773| d_loss: 0.659| gp_loss: 0.049| r_loss: 0.105| p_loss: 0.164| v_loss: 0.033| per_loss: 0.455 | a_loss: 0.507
Train: Epoch [706/3000], Step [150/158]| g_loss: 0.780| d_loss: 0.677| gp_loss: 0.058| r_loss: 0.098| p_loss: 0.160| v_loss: 0.031| per_loss: 0.428 | a_loss: 0.527
Train: Epoch [707/3000], Step [30/158]| g_loss: 0.801| d_loss: 0.726| gp_loss: 0.173| r_loss: 0.108| p_loss: 0.173| v_loss: 0.032| per_loss: 0.449 | a_loss: 0.529
Train: Epoch [707/3000], Step [60/158]| g_loss: 0.830| d_loss: 0.508| gp_loss: 0.046| r_loss: 0.105| p_loss: 0.160| v_loss: 0.032| per_loss: 0.424 | a_loss: 0.570
Train: Epoch [707/3000], Step [90/158]| g_loss: 0.826| d_loss: 0.562| gp_loss: 0.048| r_loss: 0.101| p_loss: 0.155| v_loss: 0.031| per_loss: 0.459 | a_loss: 0.571
Train: Epoch [707/3000], Step [120/158]| g_loss: 0.771| d_loss: 0.580| gp_loss: 0.048| r_loss: 0.097| p_loss: 0.157| v_loss: 0.031| per_loss: 0.481 | a_loss: 0.516
Train: Epoch [707/3000], Step [150/158]| g_loss: 0.807| d_loss: 0.622| gp_loss: 0.048| r_loss: 0.101| p_loss: 0.157| v_loss: 0.031| per_loss: 0.468 | a_loss: 0.550
Train: Epoch [708/3000], Step [30/158]| g_loss: 0.723| d_loss: 0.767| gp_loss: 0.103| r_loss: 0.108| p_loss: 0.169| v_loss: 0.032| per_loss: 0.477 | a_loss: 0.451
Train: Epoch [708/3000], Step [60/158]| g_loss: 0.811| d_loss: 0.622| gp_loss: 0.051| r_loss: 0.103| p_loss: 0.163| v_loss: 0.032| per_loss: 0.484 | a_loss: 0.547
Train: Epoch [708/3000], Step [90/158]| g_loss: 0.791| d_loss: 0.552| gp_loss: 0.051| r_loss: 0.101| p_loss: 0.161| v_loss: 0.031| per_loss: 0.445 | a_loss: 0.534
Train: Epoch [708/3000], Step [120/158]| g_loss: 0.867| d_loss: 0.565| gp_loss: 0.050| r_loss: 0.110| p_loss: 0.174| v_loss: 0.033| per_loss: 0.494 | a_loss: 0.588
Train: Epoch [708/3000], Step [150/158]| g_loss: 0.780| d_loss: 0.570| gp_loss: 0.049| r_loss: 0.104| p_loss: 0.162| v_loss: 0.031| per_loss: 0.455 | a_loss: 0.518
Train: Epoch [709/3000], Step [30/158]| g_loss: 0.840| d_loss: 0.618| gp_loss: 0.074| r_loss: 0.103| p_loss: 0.167| v_loss: 0.031| per_loss: 0.468 | a_loss: 0.576
Train: Epoch [709/3000], Step [60/158]| g_loss: 0.845| d_loss: 0.583| gp_loss: 0.046| r_loss: 0.109| p_loss: 0.176| v_loss: 0.032| per_loss: 0.450 | a_loss: 0.571
Train: Epoch [709/3000], Step [90/158]| g_loss: 0.784| d_loss: 0.644| gp_loss: 0.051| r_loss: 0.114| p_loss: 0.172| v_loss: 0.031| per_loss: 0.486 | a_loss: 0.504
Train: Epoch [709/3000], Step [120/158]| g_loss: 0.808| d_loss: 0.539| gp_loss: 0.055| r_loss: 0.100| p_loss: 0.160| v_loss: 0.031| per_loss: 0.505 | a_loss: 0.546
Train: Epoch [709/3000], Step [150/158]| g_loss: 0.765| d_loss: 0.640| gp_loss: 0.053| r_loss: 0.104| p_loss: 0.168| v_loss: 0.032| per_loss: 0.441 | a_loss: 0.501
Train: Epoch [710/3000], Step [30/158]| g_loss: 0.729| d_loss: 0.746| gp_loss: 0.099| r_loss: 0.102| p_loss: 0.159| v_loss: 0.030| per_loss: 0.457 | a_loss: 0.471
Train: Epoch [710/3000], Step [60/158]| g_loss: 0.778| d_loss: 0.602| gp_loss: 0.050| r_loss: 0.103| p_loss: 0.162| v_loss: 0.032| per_loss: 0.467 | a_loss: 0.516
Train: Epoch [710/3000], Step [90/158]| g_loss: 0.803| d_loss: 0.614| gp_loss: 0.051| r_loss: 0.106| p_loss: 0.170| v_loss: 0.032| per_loss: 0.479 | a_loss: 0.532
Train: Epoch [710/3000], Step [120/158]| g_loss: 0.843| d_loss: 0.551| gp_loss: 0.056| r_loss: 0.105| p_loss: 0.167| v_loss: 0.031| per_loss: 0.452 | a_loss: 0.579
Train: Epoch [710/3000], Step [150/158]| g_loss: 0.799| d_loss: 0.604| gp_loss: 0.056| r_loss: 0.112| p_loss: 0.176| v_loss: 0.031| per_loss: 0.451 | a_loss: 0.524
Train: Epoch [711/3000], Step [30/158]| g_loss: 0.890| d_loss: 0.592| gp_loss: 0.136| r_loss: 0.127| p_loss: 0.214| v_loss: 0.031| per_loss: 0.484 | a_loss: 0.576
Train: Epoch [711/3000], Step [60/158]| g_loss: 0.806| d_loss: 0.595| gp_loss: 0.052| r_loss: 0.108| p_loss: 0.172| v_loss: 0.031| per_loss: 0.488 | a_loss: 0.532
Train: Epoch [711/3000], Step [90/158]| g_loss: 0.778| d_loss: 0.646| gp_loss: 0.056| r_loss: 0.105| p_loss: 0.174| v_loss: 0.031| per_loss: 0.450 | a_loss: 0.509
Train: Epoch [711/3000], Step [120/158]| g_loss: 0.821| d_loss: 0.545| gp_loss: 0.055| r_loss: 0.104| p_loss: 0.165| v_loss: 0.031| per_loss: 0.489 | a_loss: 0.554
Train: Epoch [711/3000], Step [150/158]| g_loss: 0.812| d_loss: 0.580| gp_loss: 0.055| r_loss: 0.106| p_loss: 0.172| v_loss: 0.031| per_loss: 0.473 | a_loss: 0.542
Train: Epoch [712/3000], Step [30/158]| g_loss: 0.881| d_loss: 0.580| gp_loss: 0.165| r_loss: 0.107| p_loss: 0.165| v_loss: 0.030| per_loss: 0.511 | a_loss: 0.610
Train: Epoch [712/3000], Step [60/158]| g_loss: 0.768| d_loss: 0.687| gp_loss: 0.051| r_loss: 0.107| p_loss: 0.168| v_loss: 0.031| per_loss: 0.434 | a_loss: 0.503
Train: Epoch [712/3000], Step [90/158]| g_loss: 0.790| d_loss: 0.554| gp_loss: 0.056| r_loss: 0.102| p_loss: 0.160| v_loss: 0.032| per_loss: 0.491 | a_loss: 0.527
Train: Epoch [712/3000], Step [120/158]| g_loss: 0.767| d_loss: 0.712| gp_loss: 0.055| r_loss: 0.106| p_loss: 0.174| v_loss: 0.031| per_loss: 0.462 | a_loss: 0.497
Train: Epoch [712/3000], Step [150/158]| g_loss: 0.797| d_loss: 0.555| gp_loss: 0.055| r_loss: 0.105| p_loss: 0.163| v_loss: 0.032| per_loss: 0.480 | a_loss: 0.531
Train: Epoch [713/3000], Step [30/158]| g_loss: 0.841| d_loss: 0.666| gp_loss: 0.151| r_loss: 0.102| p_loss: 0.158| v_loss: 0.031| per_loss: 0.482 | a_loss: 0.581
Train: Epoch [713/3000], Step [60/158]| g_loss: 0.807| d_loss: 0.588| gp_loss: 0.051| r_loss: 0.107| p_loss: 0.168| v_loss: 0.032| per_loss: 0.487 | a_loss: 0.535
Train: Epoch [713/3000], Step [90/158]| g_loss: 0.801| d_loss: 0.607| gp_loss: 0.051| r_loss: 0.105| p_loss: 0.170| v_loss: 0.031| per_loss: 0.468 | a_loss: 0.533
Train: Epoch [713/3000], Step [120/158]| g_loss: 0.822| d_loss: 0.574| gp_loss: 0.052| r_loss: 0.104| p_loss: 0.164| v_loss: 0.032| per_loss: 0.460 | a_loss: 0.558
Train: Epoch [713/3000], Step [150/158]| g_loss: 0.791| d_loss: 0.618| gp_loss: 0.052| r_loss: 0.109| p_loss: 0.168| v_loss: 0.032| per_loss: 0.474 | a_loss: 0.519
Train: Epoch [714/3000], Step [30/158]| g_loss: 0.741| d_loss: 0.710| gp_loss: 0.123| r_loss: 0.103| p_loss: 0.163| v_loss: 0.031| per_loss: 0.469 | a_loss: 0.478
Train: Epoch [714/3000], Step [60/158]| g_loss: 0.818| d_loss: 0.632| gp_loss: 0.050| r_loss: 0.110| p_loss: 0.165| v_loss: 0.030| per_loss: 0.448 | a_loss: 0.551
Train: Epoch [714/3000], Step [90/158]| g_loss: 0.735| d_loss: 0.602| gp_loss: 0.052| r_loss: 0.099| p_loss: 0.154| v_loss: 0.030| per_loss: 0.455 | a_loss: 0.483
Train: Epoch [714/3000], Step [120/158]| g_loss: 0.770| d_loss: 0.634| gp_loss: 0.051| r_loss: 0.105| p_loss: 0.161| v_loss: 0.031| per_loss: 0.480 | a_loss: 0.505
Train: Epoch [714/3000], Step [150/158]| g_loss: 0.880| d_loss: 0.516| gp_loss: 0.052| r_loss: 0.101| p_loss: 0.160| v_loss: 0.032| per_loss: 0.467 | a_loss: 0.620
Train: Epoch [715/3000], Step [30/158]| g_loss: 0.787| d_loss: 0.684| gp_loss: 0.139| r_loss: 0.102| p_loss: 0.163| v_loss: 0.031| per_loss: 0.477 | a_loss: 0.524
Train: Epoch [715/3000], Step [60/158]| g_loss: 0.804| d_loss: 0.625| gp_loss: 0.050| r_loss: 0.110| p_loss: 0.170| v_loss: 0.031| per_loss: 0.455 | a_loss: 0.532
Train: Epoch [715/3000], Step [90/158]| g_loss: 0.794| d_loss: 0.548| gp_loss: 0.054| r_loss: 0.103| p_loss: 0.159| v_loss: 0.032| per_loss: 0.432 | a_loss: 0.537
Train: Epoch [715/3000], Step [120/158]| g_loss: 0.810| d_loss: 0.600| gp_loss: 0.054| r_loss: 0.100| p_loss: 0.155| v_loss: 0.031| per_loss: 0.467 | a_loss: 0.556
Train: Epoch [715/3000], Step [150/158]| g_loss: 0.827| d_loss: 0.528| gp_loss: 0.052| r_loss: 0.101| p_loss: 0.155| v_loss: 0.031| per_loss: 0.509 | a_loss: 0.566
Train: Epoch [716/3000], Step [30/158]| g_loss: 0.843| d_loss: 0.584| gp_loss: 0.142| r_loss: 0.100| p_loss: 0.159| v_loss: 0.032| per_loss: 0.469 | a_loss: 0.585
Train: Epoch [716/3000], Step [60/158]| g_loss: 0.778| d_loss: 0.624| gp_loss: 0.051| r_loss: 0.103| p_loss: 0.155| v_loss: 0.031| per_loss: 0.468 | a_loss: 0.519
Train: Epoch [716/3000], Step [90/158]| g_loss: 0.780| d_loss: 0.596| gp_loss: 0.052| r_loss: 0.099| p_loss: 0.149| v_loss: 0.029| per_loss: 0.468 | a_loss: 0.530
Train: Epoch [716/3000], Step [120/158]| g_loss: 0.821| d_loss: 0.645| gp_loss: 0.051| r_loss: 0.104| p_loss: 0.164| v_loss: 0.031| per_loss: 0.479 | a_loss: 0.556
Train: Epoch [716/3000], Step [150/158]| g_loss: 0.718| d_loss: 0.681| gp_loss: 0.050| r_loss: 0.098| p_loss: 0.159| v_loss: 0.031| per_loss: 0.472 | a_loss: 0.463
Train: Epoch [717/3000], Step [30/158]| g_loss: 0.823| d_loss: 0.628| gp_loss: 0.105| r_loss: 0.106| p_loss: 0.160| v_loss: 0.031| per_loss: 0.472 | a_loss: 0.559
Train: Epoch [717/3000], Step [60/158]| g_loss: 0.743| d_loss: 0.577| gp_loss: 0.053| r_loss: 0.097| p_loss: 0.151| v_loss: 0.030| per_loss: 0.472 | a_loss: 0.493
Train: Epoch [717/3000], Step [90/158]| g_loss: 0.864| d_loss: 0.537| gp_loss: 0.051| r_loss: 0.102| p_loss: 0.153| v_loss: 0.029| per_loss: 0.488 | a_loss: 0.607
Train: Epoch [717/3000], Step [120/158]| g_loss: 0.810| d_loss: 0.602| gp_loss: 0.053| r_loss: 0.108| p_loss: 0.172| v_loss: 0.032| per_loss: 0.454 | a_loss: 0.539
Train: Epoch [717/3000], Step [150/158]| g_loss: 0.750| d_loss: 0.665| gp_loss: 0.053| r_loss: 0.107| p_loss: 0.166| v_loss: 0.032| per_loss: 0.445 | a_loss: 0.483
Train: Epoch [718/3000], Step [30/158]| g_loss: 0.781| d_loss: 0.708| gp_loss: 0.106| r_loss: 0.100| p_loss: 0.164| v_loss: 0.032| per_loss: 0.474 | a_loss: 0.520
Train: Epoch [718/3000], Step [60/158]| g_loss: 0.835| d_loss: 0.564| gp_loss: 0.055| r_loss: 0.106| p_loss: 0.169| v_loss: 0.032| per_loss: 0.480 | a_loss: 0.565
Train: Epoch [718/3000], Step [90/158]| g_loss: 0.778| d_loss: 0.614| gp_loss: 0.052| r_loss: 0.106| p_loss: 0.162| v_loss: 0.031| per_loss: 0.470 | a_loss: 0.513
Train: Epoch [718/3000], Step [120/158]| g_loss: 0.805| d_loss: 0.591| gp_loss: 0.052| r_loss: 0.102| p_loss: 0.156| v_loss: 0.030| per_loss: 0.497 | a_loss: 0.545
Train: Epoch [718/3000], Step [150/158]| g_loss: 0.834| d_loss: 0.525| gp_loss: 0.055| r_loss: 0.102| p_loss: 0.162| v_loss: 0.031| per_loss: 0.447 | a_loss: 0.574
Train: Epoch [719/3000], Step [30/158]| g_loss: 0.808| d_loss: 0.722| gp_loss: 0.156| r_loss: 0.103| p_loss: 0.161| v_loss: 0.031| per_loss: 0.492 | a_loss: 0.545
Train: Epoch [719/3000], Step [60/158]| g_loss: 0.801| d_loss: 0.623| gp_loss: 0.053| r_loss: 0.104| p_loss: 0.159| v_loss: 0.032| per_loss: 0.479 | a_loss: 0.537
Train: Epoch [719/3000], Step [90/158]| g_loss: 0.794| d_loss: 0.591| gp_loss: 0.052| r_loss: 0.103| p_loss: 0.165| v_loss: 0.030| per_loss: 0.467 | a_loss: 0.531
Train: Epoch [719/3000], Step [120/158]| g_loss: 0.837| d_loss: 0.553| gp_loss: 0.054| r_loss: 0.105| p_loss: 0.164| v_loss: 0.032| per_loss: 0.488 | a_loss: 0.568
Train: Epoch [719/3000], Step [150/158]| g_loss: 0.785| d_loss: 0.613| gp_loss: 0.053| r_loss: 0.103| p_loss: 0.162| v_loss: 0.031| per_loss: 0.470 | a_loss: 0.523
Train: Epoch [720/3000], Step [30/158]| g_loss: 0.814| d_loss: 0.665| gp_loss: 0.161| r_loss: 0.105| p_loss: 0.167| v_loss: 0.030| per_loss: 0.481 | a_loss: 0.547
Train: Epoch [720/3000], Step [60/158]| g_loss: 0.819| d_loss: 0.605| gp_loss: 0.048| r_loss: 0.105| p_loss: 0.167| v_loss: 0.032| per_loss: 0.461 | a_loss: 0.552
Train: Epoch [720/3000], Step [90/158]| g_loss: 0.761| d_loss: 0.601| gp_loss: 0.052| r_loss: 0.102| p_loss: 0.160| v_loss: 0.030| per_loss: 0.451 | a_loss: 0.504
Train: Epoch [720/3000], Step [120/158]| g_loss: 0.796| d_loss: 0.584| gp_loss: 0.053| r_loss: 0.098| p_loss: 0.162| v_loss: 0.032| per_loss: 0.490 | a_loss: 0.536
Train: Epoch [720/3000], Step [150/158]| g_loss: 0.810| d_loss: 0.680| gp_loss: 0.052| r_loss: 0.105| p_loss: 0.169| v_loss: 0.031| per_loss: 0.512 | a_loss: 0.539
Train: Epoch [721/3000], Step [30/158]| g_loss: 0.706| d_loss: 0.717| gp_loss: 0.121| r_loss: 0.101| p_loss: 0.164| v_loss: 0.031| per_loss: 0.456 | a_loss: 0.446
Train: Epoch [721/3000], Step [60/158]| g_loss: 0.833| d_loss: 0.588| gp_loss: 0.047| r_loss: 0.107| p_loss: 0.168| v_loss: 0.033| per_loss: 0.476 | a_loss: 0.561
Train: Epoch [721/3000], Step [90/158]| g_loss: 0.816| d_loss: 0.522| gp_loss: 0.053| r_loss: 0.099| p_loss: 0.159| v_loss: 0.031| per_loss: 0.457 | a_loss: 0.560
Train: Epoch [721/3000], Step [120/158]| g_loss: 0.860| d_loss: 0.554| gp_loss: 0.054| r_loss: 0.108| p_loss: 0.173| v_loss: 0.032| per_loss: 0.523 | a_loss: 0.582
Train: Epoch [721/3000], Step [150/158]| g_loss: 0.752| d_loss: 0.657| gp_loss: 0.051| r_loss: 0.099| p_loss: 0.155| v_loss: 0.029| per_loss: 0.511 | a_loss: 0.494
Train: Epoch [722/3000], Step [30/158]| g_loss: 0.788| d_loss: 0.732| gp_loss: 0.151| r_loss: 0.105| p_loss: 0.162| v_loss: 0.031| per_loss: 0.459 | a_loss: 0.524
Train: Epoch [722/3000], Step [60/158]| g_loss: 0.807| d_loss: 0.592| gp_loss: 0.052| r_loss: 0.109| p_loss: 0.167| v_loss: 0.030| per_loss: 0.474 | a_loss: 0.536
Train: Epoch [722/3000], Step [90/158]| g_loss: 0.797| d_loss: 0.522| gp_loss: 0.051| r_loss: 0.102| p_loss: 0.167| v_loss: 0.031| per_loss: 0.474 | a_loss: 0.533
Train: Epoch [722/3000], Step [120/158]| g_loss: 0.789| d_loss: 0.616| gp_loss: 0.055| r_loss: 0.101| p_loss: 0.161| v_loss: 0.031| per_loss: 0.480 | a_loss: 0.529
Train: Epoch [722/3000], Step [150/158]| g_loss: 0.805| d_loss: 0.594| gp_loss: 0.057| r_loss: 0.104| p_loss: 0.165| v_loss: 0.033| per_loss: 0.490 | a_loss: 0.537
Train: Epoch [723/3000], Step [30/158]| g_loss: 0.788| d_loss: 0.700| gp_loss: 0.119| r_loss: 0.103| p_loss: 0.170| v_loss: 0.031| per_loss: 0.534 | a_loss: 0.515
Train: Epoch [723/3000], Step [60/158]| g_loss: 0.841| d_loss: 0.546| gp_loss: 0.050| r_loss: 0.104| p_loss: 0.171| v_loss: 0.033| per_loss: 0.486 | a_loss: 0.570
Train: Epoch [723/3000], Step [90/158]| g_loss: 0.821| d_loss: 0.630| gp_loss: 0.049| r_loss: 0.102| p_loss: 0.166| v_loss: 0.032| per_loss: 0.450 | a_loss: 0.559
Train: Epoch [723/3000], Step [120/158]| g_loss: 0.796| d_loss: 0.533| gp_loss: 0.056| r_loss: 0.097| p_loss: 0.157| v_loss: 0.032| per_loss: 0.472 | a_loss: 0.541
Train: Epoch [723/3000], Step [150/158]| g_loss: 0.767| d_loss: 0.654| gp_loss: 0.057| r_loss: 0.102| p_loss: 0.163| v_loss: 0.030| per_loss: 0.467 | a_loss: 0.507
Train: Epoch [724/3000], Step [30/158]| g_loss: 0.869| d_loss: 0.634| gp_loss: 0.133| r_loss: 0.111| p_loss: 0.170| v_loss: 0.031| per_loss: 0.482 | a_loss: 0.593
Train: Epoch [724/3000], Step [60/158]| g_loss: 0.753| d_loss: 0.638| gp_loss: 0.048| r_loss: 0.100| p_loss: 0.163| v_loss: 0.031| per_loss: 0.475 | a_loss: 0.493
Train: Epoch [724/3000], Step [90/158]| g_loss: 0.802| d_loss: 0.607| gp_loss: 0.052| r_loss: 0.100| p_loss: 0.163| v_loss: 0.032| per_loss: 0.490 | a_loss: 0.540
Train: Epoch [724/3000], Step [120/158]| g_loss: 0.822| d_loss: 0.532| gp_loss: 0.051| r_loss: 0.103| p_loss: 0.160| v_loss: 0.032| per_loss: 0.478 | a_loss: 0.560
Train: Epoch [724/3000], Step [150/158]| g_loss: 0.810| d_loss: 0.616| gp_loss: 0.052| r_loss: 0.108| p_loss: 0.166| v_loss: 0.032| per_loss: 0.480 | a_loss: 0.539
Train: Epoch [725/3000], Step [30/158]| g_loss: 0.752| d_loss: 0.741| gp_loss: 0.114| r_loss: 0.108| p_loss: 0.167| v_loss: 0.031| per_loss: 0.451 | a_loss: 0.485
Train: Epoch [725/3000], Step [60/158]| g_loss: 0.824| d_loss: 0.553| gp_loss: 0.051| r_loss: 0.104| p_loss: 0.168| v_loss: 0.031| per_loss: 0.506 | a_loss: 0.554
Train: Epoch [725/3000], Step [90/158]| g_loss: 0.813| d_loss: 0.607| gp_loss: 0.053| r_loss: 0.110| p_loss: 0.170| v_loss: 0.030| per_loss: 0.448 | a_loss: 0.543
Train: Epoch [725/3000], Step [120/158]| g_loss: 0.770| d_loss: 0.666| gp_loss: 0.052| r_loss: 0.101| p_loss: 0.173| v_loss: 0.031| per_loss: 0.473 | a_loss: 0.504
Train: Epoch [725/3000], Step [150/158]| g_loss: 0.841| d_loss: 0.529| gp_loss: 0.052| r_loss: 0.106| p_loss: 0.169| v_loss: 0.032| per_loss: 0.539 | a_loss: 0.564
Train: Epoch [726/3000], Step [30/158]| g_loss: 0.774| d_loss: 0.652| gp_loss: 0.097| r_loss: 0.103| p_loss: 0.162| v_loss: 0.032| per_loss: 0.441 | a_loss: 0.514
Train: Epoch [726/3000], Step [60/158]| g_loss: 0.818| d_loss: 0.661| gp_loss: 0.051| r_loss: 0.107| p_loss: 0.174| v_loss: 0.032| per_loss: 0.481 | a_loss: 0.544
Train: Epoch [726/3000], Step [90/158]| g_loss: 0.836| d_loss: 0.537| gp_loss: 0.057| r_loss: 0.099| p_loss: 0.159| v_loss: 0.030| per_loss: 0.480 | a_loss: 0.579
Train: Epoch [726/3000], Step [120/158]| g_loss: 0.795| d_loss: 0.600| gp_loss: 0.055| r_loss: 0.098| p_loss: 0.155| v_loss: 0.031| per_loss: 0.478 | a_loss: 0.540
Train: Epoch [726/3000], Step [150/158]| g_loss: 0.761| d_loss: 0.619| gp_loss: 0.053| r_loss: 0.102| p_loss: 0.158| v_loss: 0.031| per_loss: 0.475 | a_loss: 0.501
Train: Epoch [727/3000], Step [30/158]| g_loss: 0.809| d_loss: 0.630| gp_loss: 0.156| r_loss: 0.105| p_loss: 0.162| v_loss: 0.031| per_loss: 0.474 | a_loss: 0.544
Train: Epoch [727/3000], Step [60/158]| g_loss: 0.806| d_loss: 0.636| gp_loss: 0.049| r_loss: 0.098| p_loss: 0.157| v_loss: 0.032| per_loss: 0.480 | a_loss: 0.550
Train: Epoch [727/3000], Step [90/158]| g_loss: 0.825| d_loss: 0.621| gp_loss: 0.054| r_loss: 0.101| p_loss: 0.163| v_loss: 0.030| per_loss: 0.482 | a_loss: 0.565
Train: Epoch [727/3000], Step [120/158]| g_loss: 0.772| d_loss: 0.599| gp_loss: 0.054| r_loss: 0.103| p_loss: 0.166| v_loss: 0.031| per_loss: 0.452 | a_loss: 0.509
Train: Epoch [727/3000], Step [150/158]| g_loss: 0.815| d_loss: 0.598| gp_loss: 0.056| r_loss: 0.106| p_loss: 0.167| v_loss: 0.031| per_loss: 0.460 | a_loss: 0.549
Train: Epoch [728/3000], Step [30/158]| g_loss: 0.799| d_loss: 0.707| gp_loss: 0.122| r_loss: 0.105| p_loss: 0.174| v_loss: 0.032| per_loss: 0.491 | a_loss: 0.527
Train: Epoch [728/3000], Step [60/158]| g_loss: 0.788| d_loss: 0.616| gp_loss: 0.051| r_loss: 0.102| p_loss: 0.164| v_loss: 0.032| per_loss: 0.501 | a_loss: 0.522
Train: Epoch [728/3000], Step [90/158]| g_loss: 0.843| d_loss: 0.507| gp_loss: 0.050| r_loss: 0.101| p_loss: 0.159| v_loss: 0.033| per_loss: 0.464 | a_loss: 0.583
Train: Epoch [728/3000], Step [120/158]| g_loss: 0.765| d_loss: 0.664| gp_loss: 0.050| r_loss: 0.106| p_loss: 0.168| v_loss: 0.032| per_loss: 0.453 | a_loss: 0.499
Train: Epoch [728/3000], Step [150/158]| g_loss: 0.794| d_loss: 0.599| gp_loss: 0.056| r_loss: 0.108| p_loss: 0.160| v_loss: 0.031| per_loss: 0.451 | a_loss: 0.529
Train: Epoch [729/3000], Step [30/158]| g_loss: 0.764| d_loss: 0.716| gp_loss: 0.142| r_loss: 0.105| p_loss: 0.174| v_loss: 0.031| per_loss: 0.440 | a_loss: 0.497
Train: Epoch [729/3000], Step [60/158]| g_loss: 0.870| d_loss: 0.488| gp_loss: 0.052| r_loss: 0.104| p_loss: 0.161| v_loss: 0.032| per_loss: 0.457 | a_loss: 0.608
Train: Epoch [729/3000], Step [90/158]| g_loss: 0.820| d_loss: 0.623| gp_loss: 0.051| r_loss: 0.109| p_loss: 0.165| v_loss: 0.033| per_loss: 0.468 | a_loss: 0.550
Train: Epoch [729/3000], Step [120/158]| g_loss: 0.800| d_loss: 0.596| gp_loss: 0.050| r_loss: 0.102| p_loss: 0.156| v_loss: 0.031| per_loss: 0.512 | a_loss: 0.538
Train: Epoch [729/3000], Step [150/158]| g_loss: 0.798| d_loss: 0.590| gp_loss: 0.054| r_loss: 0.100| p_loss: 0.153| v_loss: 0.031| per_loss: 0.462 | a_loss: 0.544
Train: Epoch [730/3000], Step [30/158]| g_loss: 0.771| d_loss: 0.706| gp_loss: 0.188| r_loss: 0.097| p_loss: 0.155| v_loss: 0.031| per_loss: 0.472 | a_loss: 0.518
Train: Epoch [730/3000], Step [60/158]| g_loss: 0.826| d_loss: 0.560| gp_loss: 0.048| r_loss: 0.100| p_loss: 0.159| v_loss: 0.032| per_loss: 0.477 | a_loss: 0.566
Train: Epoch [730/3000], Step [90/158]| g_loss: 0.826| d_loss: 0.629| gp_loss: 0.050| r_loss: 0.111| p_loss: 0.164| v_loss: 0.032| per_loss: 0.471 | a_loss: 0.554
Train: Epoch [730/3000], Step [120/158]| g_loss: 0.775| d_loss: 0.634| gp_loss: 0.053| r_loss: 0.097| p_loss: 0.152| v_loss: 0.031| per_loss: 0.429 | a_loss: 0.528
Train: Epoch [730/3000], Step [150/158]| g_loss: 0.811| d_loss: 0.552| gp_loss: 0.054| r_loss: 0.099| p_loss: 0.154| v_loss: 0.032| per_loss: 0.469 | a_loss: 0.555
Train: Epoch [731/3000], Step [30/158]| g_loss: 0.784| d_loss: 0.731| gp_loss: 0.135| r_loss: 0.100| p_loss: 0.161| v_loss: 0.031| per_loss: 0.473 | a_loss: 0.526
Train: Epoch [731/3000], Step [60/158]| g_loss: 0.748| d_loss: 0.642| gp_loss: 0.049| r_loss: 0.101| p_loss: 0.154| v_loss: 0.031| per_loss: 0.466 | a_loss: 0.493
Train: Epoch [731/3000], Step [90/158]| g_loss: 0.768| d_loss: 0.637| gp_loss: 0.051| r_loss: 0.104| p_loss: 0.160| v_loss: 0.032| per_loss: 0.463 | a_loss: 0.505
Train: Epoch [731/3000], Step [120/158]| g_loss: 0.815| d_loss: 0.505| gp_loss: 0.053| r_loss: 0.098| p_loss: 0.158| v_loss: 0.031| per_loss: 0.455 | a_loss: 0.561
Train: Epoch [731/3000], Step [150/158]| g_loss: 0.835| d_loss: 0.581| gp_loss: 0.052| r_loss: 0.106| p_loss: 0.168| v_loss: 0.032| per_loss: 0.440 | a_loss: 0.570
Train: Epoch [732/3000], Step [30/158]| g_loss: 0.822| d_loss: 0.633| gp_loss: 0.155| r_loss: 0.100| p_loss: 0.153| v_loss: 0.031| per_loss: 0.488 | a_loss: 0.566
Train: Epoch [732/3000], Step [60/158]| g_loss: 0.709| d_loss: 0.740| gp_loss: 0.049| r_loss: 0.103| p_loss: 0.162| v_loss: 0.031| per_loss: 0.455 | a_loss: 0.449
Train: Epoch [732/3000], Step [90/158]| g_loss: 0.809| d_loss: 0.603| gp_loss: 0.050| r_loss: 0.107| p_loss: 0.164| v_loss: 0.034| per_loss: 0.472 | a_loss: 0.539
Train: Epoch [732/3000], Step [120/158]| g_loss: 0.813| d_loss: 0.528| gp_loss: 0.050| r_loss: 0.100| p_loss: 0.161| v_loss: 0.031| per_loss: 0.420 | a_loss: 0.560
Train: Epoch [732/3000], Step [150/158]| g_loss: 0.833| d_loss: 0.509| gp_loss: 0.054| r_loss: 0.099| p_loss: 0.163| v_loss: 0.032| per_loss: 0.501 | a_loss: 0.570
Train: Epoch [733/3000], Step [30/158]| g_loss: 0.777| d_loss: 0.717| gp_loss: 0.133| r_loss: 0.103| p_loss: 0.165| v_loss: 0.032| per_loss: 0.454 | a_loss: 0.515
Train: Epoch [733/3000], Step [60/158]| g_loss: 0.755| d_loss: 0.596| gp_loss: 0.048| r_loss: 0.104| p_loss: 0.166| v_loss: 0.032| per_loss: 0.440 | a_loss: 0.491
Train: Epoch [733/3000], Step [90/158]| g_loss: 0.870| d_loss: 0.523| gp_loss: 0.049| r_loss: 0.103| p_loss: 0.158| v_loss: 0.030| per_loss: 0.521 | a_loss: 0.605
Train: Epoch [733/3000], Step [120/158]| g_loss: 0.774| d_loss: 0.604| gp_loss: 0.052| r_loss: 0.100| p_loss: 0.160| v_loss: 0.031| per_loss: 0.458 | a_loss: 0.517
Train: Epoch [733/3000], Step [150/158]| g_loss: 0.793| d_loss: 0.635| gp_loss: 0.051| r_loss: 0.103| p_loss: 0.168| v_loss: 0.033| per_loss: 0.475 | a_loss: 0.526
Train: Epoch [734/3000], Step [30/158]| g_loss: 0.787| d_loss: 0.691| gp_loss: 0.167| r_loss: 0.100| p_loss: 0.159| v_loss: 0.030| per_loss: 0.460 | a_loss: 0.532
Train: Epoch [734/3000], Step [60/158]| g_loss: 0.859| d_loss: 0.483| gp_loss: 0.050| r_loss: 0.100| p_loss: 0.158| v_loss: 0.032| per_loss: 0.486 | a_loss: 0.600
Train: Epoch [734/3000], Step [90/158]| g_loss: 0.772| d_loss: 0.589| gp_loss: 0.050| r_loss: 0.101| p_loss: 0.164| v_loss: 0.032| per_loss: 0.466 | a_loss: 0.510
Train: Epoch [734/3000], Step [120/158]| g_loss: 0.834| d_loss: 0.587| gp_loss: 0.051| r_loss: 0.109| p_loss: 0.166| v_loss: 0.032| per_loss: 0.459 | a_loss: 0.564
Train: Epoch [734/3000], Step [150/158]| g_loss: 0.791| d_loss: 0.657| gp_loss: 0.051| r_loss: 0.105| p_loss: 0.162| v_loss: 0.032| per_loss: 0.504 | a_loss: 0.523
Train: Epoch [735/3000], Step [30/158]| g_loss: 0.777| d_loss: 0.715| gp_loss: 0.144| r_loss: 0.108| p_loss: 0.180| v_loss: 0.032| per_loss: 0.494 | a_loss: 0.498
Train: Epoch [735/3000], Step [60/158]| g_loss: 0.783| d_loss: 0.587| gp_loss: 0.050| r_loss: 0.104| p_loss: 0.165| v_loss: 0.033| per_loss: 0.512 | a_loss: 0.513
Train: Epoch [735/3000], Step [90/158]| g_loss: 0.811| d_loss: 0.605| gp_loss: 0.050| r_loss: 0.104| p_loss: 0.169| v_loss: 0.031| per_loss: 0.461 | a_loss: 0.545
Train: Epoch [735/3000], Step [120/158]| g_loss: 0.788| d_loss: 0.606| gp_loss: 0.051| r_loss: 0.098| p_loss: 0.156| v_loss: 0.031| per_loss: 0.457 | a_loss: 0.535
Train: Epoch [735/3000], Step [150/158]| g_loss: 0.812| d_loss: 0.579| gp_loss: 0.054| r_loss: 0.108| p_loss: 0.167| v_loss: 0.031| per_loss: 0.470 | a_loss: 0.541
Train: Epoch [736/3000], Step [30/158]| g_loss: 0.787| d_loss: 0.637| gp_loss: 0.135| r_loss: 0.098| p_loss: 0.154| v_loss: 0.031| per_loss: 0.454 | a_loss: 0.535
Train: Epoch [736/3000], Step [60/158]| g_loss: 0.801| d_loss: 0.586| gp_loss: 0.050| r_loss: 0.100| p_loss: 0.156| v_loss: 0.033| per_loss: 0.472 | a_loss: 0.544
Train: Epoch [736/3000], Step [90/158]| g_loss: 0.795| d_loss: 0.589| gp_loss: 0.055| r_loss: 0.097| p_loss: 0.156| v_loss: 0.032| per_loss: 0.470 | a_loss: 0.541
Train: Epoch [736/3000], Step [120/158]| g_loss: 0.783| d_loss: 0.617| gp_loss: 0.054| r_loss: 0.108| p_loss: 0.166| v_loss: 0.031| per_loss: 0.449 | a_loss: 0.517
Train: Epoch [736/3000], Step [150/158]| g_loss: 0.843| d_loss: 0.539| gp_loss: 0.055| r_loss: 0.101| p_loss: 0.157| v_loss: 0.032| per_loss: 0.505 | a_loss: 0.581
Train: Epoch [737/3000], Step [30/158]| g_loss: 0.799| d_loss: 0.681| gp_loss: 0.105| r_loss: 0.105| p_loss: 0.167| v_loss: 0.032| per_loss: 0.492 | a_loss: 0.529
Train: Epoch [737/3000], Step [60/158]| g_loss: 0.759| d_loss: 0.634| gp_loss: 0.054| r_loss: 0.103| p_loss: 0.162| v_loss: 0.033| per_loss: 0.435 | a_loss: 0.498
Train: Epoch [737/3000], Step [90/158]| g_loss: 0.839| d_loss: 0.569| gp_loss: 0.053| r_loss: 0.101| p_loss: 0.157| v_loss: 0.032| per_loss: 0.496 | a_loss: 0.578
Train: Epoch [737/3000], Step [120/158]| g_loss: 0.770| d_loss: 0.597| gp_loss: 0.059| r_loss: 0.098| p_loss: 0.164| v_loss: 0.032| per_loss: 0.485 | a_loss: 0.509
Train: Epoch [737/3000], Step [150/158]| g_loss: 0.816| d_loss: 0.577| gp_loss: 0.057| r_loss: 0.105| p_loss: 0.165| v_loss: 0.031| per_loss: 0.461 | a_loss: 0.551
Train: Epoch [738/3000], Step [30/158]| g_loss: 0.788| d_loss: 0.681| gp_loss: 0.120| r_loss: 0.102| p_loss: 0.167| v_loss: 0.032| per_loss: 0.458 | a_loss: 0.524
Train: Epoch [738/3000], Step [60/158]| g_loss: 0.853| d_loss: 0.641| gp_loss: 0.053| r_loss: 0.112| p_loss: 0.184| v_loss: 0.033| per_loss: 0.501 | a_loss: 0.566
Train: Epoch [738/3000], Step [90/158]| g_loss: 0.787| d_loss: 0.569| gp_loss: 0.054| r_loss: 0.111| p_loss: 0.177| v_loss: 0.031| per_loss: 0.481 | a_loss: 0.507
Train: Epoch [738/3000], Step [120/158]| g_loss: 0.807| d_loss: 0.605| gp_loss: 0.053| r_loss: 0.105| p_loss: 0.173| v_loss: 0.033| per_loss: 0.453 | a_loss: 0.537
Train: Epoch [738/3000], Step [150/158]| g_loss: 0.801| d_loss: 0.661| gp_loss: 0.053| r_loss: 0.102| p_loss: 0.167| v_loss: 0.031| per_loss: 0.480 | a_loss: 0.536
Train: Epoch [739/3000], Step [30/158]| g_loss: 0.808| d_loss: 0.581| gp_loss: 0.099| r_loss: 0.103| p_loss: 0.161| v_loss: 0.032| per_loss: 0.471 | a_loss: 0.545
Train: Epoch [739/3000], Step [60/158]| g_loss: 0.835| d_loss: 0.556| gp_loss: 0.054| r_loss: 0.102| p_loss: 0.163| v_loss: 0.033| per_loss: 0.484 | a_loss: 0.570
Train: Epoch [739/3000], Step [90/158]| g_loss: 0.784| d_loss: 0.626| gp_loss: 0.055| r_loss: 0.103| p_loss: 0.159| v_loss: 0.032| per_loss: 0.472 | a_loss: 0.522
Train: Epoch [739/3000], Step [120/158]| g_loss: 0.774| d_loss: 0.613| gp_loss: 0.055| r_loss: 0.097| p_loss: 0.160| v_loss: 0.030| per_loss: 0.442 | a_loss: 0.523
Train: Epoch [739/3000], Step [150/158]| g_loss: 0.838| d_loss: 0.567| gp_loss: 0.055| r_loss: 0.105| p_loss: 0.167| v_loss: 0.032| per_loss: 0.478 | a_loss: 0.570
Train: Epoch [740/3000], Step [30/158]| g_loss: 0.809| d_loss: 0.679| gp_loss: 0.121| r_loss: 0.107| p_loss: 0.171| v_loss: 0.033| per_loss: 0.480 | a_loss: 0.535
Train: Epoch [740/3000], Step [60/158]| g_loss: 0.793| d_loss: 0.611| gp_loss: 0.051| r_loss: 0.100| p_loss: 0.164| v_loss: 0.031| per_loss: 0.491 | a_loss: 0.530
Train: Epoch [740/3000], Step [90/158]| g_loss: 0.789| d_loss: 0.608| gp_loss: 0.051| r_loss: 0.105| p_loss: 0.168| v_loss: 0.032| per_loss: 0.446 | a_loss: 0.523
Train: Epoch [740/3000], Step [120/158]| g_loss: 0.857| d_loss: 0.570| gp_loss: 0.057| r_loss: 0.106| p_loss: 0.173| v_loss: 0.032| per_loss: 0.479 | a_loss: 0.585
Train: Epoch [740/3000], Step [150/158]| g_loss: 0.759| d_loss: 0.603| gp_loss: 0.058| r_loss: 0.102| p_loss: 0.169| v_loss: 0.031| per_loss: 0.466 | a_loss: 0.495
Train: Epoch [741/3000], Step [30/158]| g_loss: 0.827| d_loss: 0.641| gp_loss: 0.109| r_loss: 0.105| p_loss: 0.180| v_loss: 0.031| per_loss: 0.473 | a_loss: 0.553
Train: Epoch [741/3000], Step [60/158]| g_loss: 0.832| d_loss: 0.570| gp_loss: 0.056| r_loss: 0.106| p_loss: 0.167| v_loss: 0.032| per_loss: 0.487 | a_loss: 0.562
Train: Epoch [741/3000], Step [90/158]| g_loss: 0.794| d_loss: 0.607| gp_loss: 0.056| r_loss: 0.104| p_loss: 0.169| v_loss: 0.033| per_loss: 0.476 | a_loss: 0.526
Train: Epoch [741/3000], Step [120/158]| g_loss: 0.884| d_loss: 0.574| gp_loss: 0.057| r_loss: 0.108| p_loss: 0.176| v_loss: 0.032| per_loss: 0.477 | a_loss: 0.608
Train: Epoch [741/3000], Step [150/158]| g_loss: 0.756| d_loss: 0.657| gp_loss: 0.057| r_loss: 0.102| p_loss: 0.169| v_loss: 0.032| per_loss: 0.511 | a_loss: 0.486
Train: Epoch [742/3000], Step [30/158]| g_loss: 0.789| d_loss: 0.678| gp_loss: 0.155| r_loss: 0.103| p_loss: 0.167| v_loss: 0.031| per_loss: 0.486 | a_loss: 0.523
Train: Epoch [742/3000], Step [60/158]| g_loss: 0.800| d_loss: 0.608| gp_loss: 0.055| r_loss: 0.106| p_loss: 0.171| v_loss: 0.032| per_loss: 0.489 | a_loss: 0.527
Train: Epoch [742/3000], Step [90/158]| g_loss: 0.817| d_loss: 0.592| gp_loss: 0.056| r_loss: 0.102| p_loss: 0.168| v_loss: 0.032| per_loss: 0.473 | a_loss: 0.552
Train: Epoch [742/3000], Step [120/158]| g_loss: 0.834| d_loss: 0.626| gp_loss: 0.053| r_loss: 0.105| p_loss: 0.169| v_loss: 0.032| per_loss: 0.472 | a_loss: 0.566
Train: Epoch [742/3000], Step [150/158]| g_loss: 0.823| d_loss: 0.573| gp_loss: 0.056| r_loss: 0.101| p_loss: 0.162| v_loss: 0.032| per_loss: 0.501 | a_loss: 0.559
Train: Epoch [743/3000], Step [30/158]| g_loss: 0.817| d_loss: 0.634| gp_loss: 0.133| r_loss: 0.102| p_loss: 0.170| v_loss: 0.032| per_loss: 0.496 | a_loss: 0.548
Train: Epoch [743/3000], Step [60/158]| g_loss: 0.772| d_loss: 0.703| gp_loss: 0.048| r_loss: 0.100| p_loss: 0.168| v_loss: 0.030| per_loss: 0.449 | a_loss: 0.512
Train: Epoch [743/3000], Step [90/158]| g_loss: 0.753| d_loss: 0.688| gp_loss: 0.055| r_loss: 0.108| p_loss: 0.163| v_loss: 0.032| per_loss: 0.479 | a_loss: 0.484
Train: Epoch [743/3000], Step [120/158]| g_loss: 0.816| d_loss: 0.595| gp_loss: 0.053| r_loss: 0.100| p_loss: 0.154| v_loss: 0.031| per_loss: 0.501 | a_loss: 0.558
Train: Epoch [743/3000], Step [150/158]| g_loss: 0.826| d_loss: 0.441| gp_loss: 0.053| r_loss: 0.097| p_loss: 0.152| v_loss: 0.032| per_loss: 0.471 | a_loss: 0.574
Train: Epoch [744/3000], Step [30/158]| g_loss: 0.850| d_loss: 0.626| gp_loss: 0.126| r_loss: 0.105| p_loss: 0.163| v_loss: 0.033| per_loss: 0.474 | a_loss: 0.584
Train: Epoch [744/3000], Step [60/158]| g_loss: 0.798| d_loss: 0.633| gp_loss: 0.050| r_loss: 0.099| p_loss: 0.155| v_loss: 0.031| per_loss: 0.482 | a_loss: 0.542
Train: Epoch [744/3000], Step [90/158]| g_loss: 0.763| d_loss: 0.636| gp_loss: 0.048| r_loss: 0.098| p_loss: 0.155| v_loss: 0.030| per_loss: 0.465 | a_loss: 0.511
Train: Epoch [744/3000], Step [120/158]| g_loss: 0.797| d_loss: 0.513| gp_loss: 0.054| r_loss: 0.102| p_loss: 0.159| v_loss: 0.032| per_loss: 0.483 | a_loss: 0.536
Train: Epoch [744/3000], Step [150/158]| g_loss: 0.802| d_loss: 0.662| gp_loss: 0.052| r_loss: 0.099| p_loss: 0.163| v_loss: 0.030| per_loss: 0.459 | a_loss: 0.545
Train: Epoch [745/3000], Step [30/158]| g_loss: 0.748| d_loss: 0.690| gp_loss: 0.100| r_loss: 0.100| p_loss: 0.158| v_loss: 0.032| per_loss: 0.487 | a_loss: 0.488
Train: Epoch [745/3000], Step [60/158]| g_loss: 0.736| d_loss: 0.687| gp_loss: 0.052| r_loss: 0.099| p_loss: 0.160| v_loss: 0.031| per_loss: 0.491 | a_loss: 0.476
Train: Epoch [745/3000], Step [90/158]| g_loss: 0.830| d_loss: 0.571| gp_loss: 0.056| r_loss: 0.110| p_loss: 0.172| v_loss: 0.032| per_loss: 0.492 | a_loss: 0.553
Train: Epoch [745/3000], Step [120/158]| g_loss: 0.819| d_loss: 0.534| gp_loss: 0.057| r_loss: 0.099| p_loss: 0.164| v_loss: 0.031| per_loss: 0.499 | a_loss: 0.557
Train: Epoch [745/3000], Step [150/158]| g_loss: 0.849| d_loss: 0.563| gp_loss: 0.051| r_loss: 0.099| p_loss: 0.161| v_loss: 0.030| per_loss: 0.477 | a_loss: 0.593
Train: Epoch [746/3000], Step [30/158]| g_loss: 0.787| d_loss: 0.694| gp_loss: 0.155| r_loss: 0.101| p_loss: 0.164| v_loss: 0.030| per_loss: 0.492 | a_loss: 0.524
Train: Epoch [746/3000], Step [60/158]| g_loss: 0.773| d_loss: 0.592| gp_loss: 0.053| r_loss: 0.101| p_loss: 0.158| v_loss: 0.031| per_loss: 0.474 | a_loss: 0.514
Train: Epoch [746/3000], Step [90/158]| g_loss: 0.792| d_loss: 0.603| gp_loss: 0.050| r_loss: 0.099| p_loss: 0.164| v_loss: 0.032| per_loss: 0.469 | a_loss: 0.533
Train: Epoch [746/3000], Step [120/158]| g_loss: 0.817| d_loss: 0.621| gp_loss: 0.052| r_loss: 0.104| p_loss: 0.169| v_loss: 0.032| per_loss: 0.508 | a_loss: 0.546
Train: Epoch [746/3000], Step [150/158]| g_loss: 0.853| d_loss: 0.525| gp_loss: 0.056| r_loss: 0.107| p_loss: 0.165| v_loss: 0.030| per_loss: 0.456 | a_loss: 0.588
Train: Epoch [747/3000], Step [30/158]| g_loss: 0.763| d_loss: 0.750| gp_loss: 0.180| r_loss: 0.101| p_loss: 0.158| v_loss: 0.030| per_loss: 0.456 | a_loss: 0.507
Train: Epoch [747/3000], Step [60/158]| g_loss: 0.734| d_loss: 0.657| gp_loss: 0.049| r_loss: 0.100| p_loss: 0.162| v_loss: 0.031| per_loss: 0.447 | a_loss: 0.477
Train: Epoch [747/3000], Step [90/158]| g_loss: 0.828| d_loss: 0.550| gp_loss: 0.051| r_loss: 0.099| p_loss: 0.157| v_loss: 0.031| per_loss: 0.483 | a_loss: 0.571
Train: Epoch [747/3000], Step [120/158]| g_loss: 0.858| d_loss: 0.517| gp_loss: 0.052| r_loss: 0.104| p_loss: 0.165| v_loss: 0.031| per_loss: 0.472 | a_loss: 0.594
Train: Epoch [747/3000], Step [150/158]| g_loss: 0.797| d_loss: 0.611| gp_loss: 0.054| r_loss: 0.103| p_loss: 0.164| v_loss: 0.030| per_loss: 0.481 | a_loss: 0.533
Train: Epoch [748/3000], Step [30/158]| g_loss: 0.787| d_loss: 0.718| gp_loss: 0.111| r_loss: 0.118| p_loss: 0.199| v_loss: 0.032| per_loss: 0.489 | a_loss: 0.488
Train: Epoch [748/3000], Step [60/158]| g_loss: 0.807| d_loss: 0.585| gp_loss: 0.055| r_loss: 0.115| p_loss: 0.203| v_loss: 0.032| per_loss: 0.514 | a_loss: 0.507
Train: Epoch [748/3000], Step [90/158]| g_loss: 0.872| d_loss: 0.507| gp_loss: 0.055| r_loss: 0.104| p_loss: 0.174| v_loss: 0.030| per_loss: 0.520 | a_loss: 0.598
Train: Epoch [748/3000], Step [120/158]| g_loss: 0.782| d_loss: 0.633| gp_loss: 0.055| r_loss: 0.101| p_loss: 0.163| v_loss: 0.030| per_loss: 0.490 | a_loss: 0.521
Train: Epoch [748/3000], Step [150/158]| g_loss: 0.853| d_loss: 0.546| gp_loss: 0.060| r_loss: 0.112| p_loss: 0.172| v_loss: 0.032| per_loss: 0.461 | a_loss: 0.578
Train: Epoch [749/3000], Step [30/158]| g_loss: 0.783| d_loss: 0.680| gp_loss: 0.155| r_loss: 0.101| p_loss: 0.171| v_loss: 0.032| per_loss: 0.488 | a_loss: 0.516
Train: Epoch [749/3000], Step [60/158]| g_loss: 0.809| d_loss: 0.655| gp_loss: 0.052| r_loss: 0.111| p_loss: 0.175| v_loss: 0.031| per_loss: 0.491 | a_loss: 0.531
Train: Epoch [749/3000], Step [90/158]| g_loss: 0.757| d_loss: 0.620| gp_loss: 0.052| r_loss: 0.106| p_loss: 0.173| v_loss: 0.032| per_loss: 0.449 | a_loss: 0.488
Train: Epoch [749/3000], Step [120/158]| g_loss: 0.809| d_loss: 0.576| gp_loss: 0.055| r_loss: 0.102| p_loss: 0.166| v_loss: 0.031| per_loss: 0.462 | a_loss: 0.548
Train: Epoch [749/3000], Step [150/158]| g_loss: 0.870| d_loss: 0.488| gp_loss: 0.058| r_loss: 0.104| p_loss: 0.156| v_loss: 0.032| per_loss: 0.492 | a_loss: 0.607
Train: Epoch [750/3000], Step [30/158]| g_loss: 0.833| d_loss: 0.612| gp_loss: 0.146| r_loss: 0.096| p_loss: 0.158| v_loss: 0.032| per_loss: 0.484 | a_loss: 0.577
Train: Epoch [750/3000], Step [60/158]| g_loss: 0.831| d_loss: 0.582| gp_loss: 0.053| r_loss: 0.098| p_loss: 0.158| v_loss: 0.032| per_loss: 0.488 | a_loss: 0.573
Train: Epoch [750/3000], Step [90/158]| g_loss: 0.763| d_loss: 0.642| gp_loss: 0.053| r_loss: 0.101| p_loss: 0.160| v_loss: 0.031| per_loss: 0.475 | a_loss: 0.503
Train: Epoch [750/3000], Step [120/158]| g_loss: 0.767| d_loss: 0.666| gp_loss: 0.052| r_loss: 0.104| p_loss: 0.167| v_loss: 0.031| per_loss: 0.488 | a_loss: 0.498
Train: Epoch [750/3000], Step [150/158]| g_loss: 0.811| d_loss: 0.596| gp_loss: 0.053| r_loss: 0.099| p_loss: 0.155| v_loss: 0.030| per_loss: 0.483 | a_loss: 0.555
Test: Epoch [750/3000]| g_loss: 0.641| r_loss: 0.396| p_loss: 0.295| v_loss: 0.024
Train: Epoch [751/3000], Step [30/158]| g_loss: 0.803| d_loss: 0.577| gp_loss: 0.049| r_loss: 0.101| p_loss: 0.157| v_loss: 0.032| per_loss: 0.478 | a_loss: 0.544
Train: Epoch [751/3000], Step [60/158]| g_loss: 0.838| d_loss: 0.526| gp_loss: 0.052| r_loss: 0.101| p_loss: 0.160| v_loss: 0.032| per_loss: 0.455 | a_loss: 0.579
Train: Epoch [751/3000], Step [90/158]| g_loss: 0.775| d_loss: 0.649| gp_loss: 0.051| r_loss: 0.098| p_loss: 0.154| v_loss: 0.029| per_loss: 0.471 | a_loss: 0.524
Train: Epoch [751/3000], Step [120/158]| g_loss: 0.767| d_loss: 0.607| gp_loss: 0.055| r_loss: 0.095| p_loss: 0.155| v_loss: 0.030| per_loss: 0.495 | a_loss: 0.515
Train: Epoch [751/3000], Step [150/158]| g_loss: 0.801| d_loss: 0.563| gp_loss: 0.057| r_loss: 0.099| p_loss: 0.154| v_loss: 0.031| per_loss: 0.478 | a_loss: 0.546
Train: Epoch [752/3000], Step [30/158]| g_loss: 0.775| d_loss: 0.721| gp_loss: 0.120| r_loss: 0.103| p_loss: 0.168| v_loss: 0.032| per_loss: 0.492 | a_loss: 0.507
Train: Epoch [752/3000], Step [60/158]| g_loss: 0.796| d_loss: 0.523| gp_loss: 0.053| r_loss: 0.099| p_loss: 0.160| v_loss: 0.033| per_loss: 0.491 | a_loss: 0.535
Train: Epoch [752/3000], Step [90/158]| g_loss: 0.851| d_loss: 0.554| gp_loss: 0.054| r_loss: 0.104| p_loss: 0.157| v_loss: 0.031| per_loss: 0.514 | a_loss: 0.587
Train: Epoch [752/3000], Step [120/158]| g_loss: 0.743| d_loss: 0.665| gp_loss: 0.054| r_loss: 0.100| p_loss: 0.166| v_loss: 0.030| per_loss: 0.500 | a_loss: 0.480
Train: Epoch [752/3000], Step [150/158]| g_loss: 0.844| d_loss: 0.600| gp_loss: 0.054| r_loss: 0.107| p_loss: 0.175| v_loss: 0.032| per_loss: 0.520 | a_loss: 0.566
Train: Epoch [753/3000], Step [30/158]| g_loss: 0.841| d_loss: 0.622| gp_loss: 0.120| r_loss: 0.103| p_loss: 0.178| v_loss: 0.032| per_loss: 0.493 | a_loss: 0.568
Train: Epoch [753/3000], Step [60/158]| g_loss: 0.748| d_loss: 0.711| gp_loss: 0.050| r_loss: 0.104| p_loss: 0.178| v_loss: 0.032| per_loss: 0.481 | a_loss: 0.474
Train: Epoch [753/3000], Step [90/158]| g_loss: 0.779| d_loss: 0.610| gp_loss: 0.053| r_loss: 0.103| p_loss: 0.170| v_loss: 0.032| per_loss: 0.498 | a_loss: 0.509
Train: Epoch [753/3000], Step [120/158]| g_loss: 0.808| d_loss: 0.595| gp_loss: 0.057| r_loss: 0.101| p_loss: 0.169| v_loss: 0.030| per_loss: 0.496 | a_loss: 0.543
Train: Epoch [753/3000], Step [150/158]| g_loss: 0.835| d_loss: 0.538| gp_loss: 0.056| r_loss: 0.103| p_loss: 0.171| v_loss: 0.032| per_loss: 0.487 | a_loss: 0.565
Train: Epoch [754/3000], Step [30/158]| g_loss: 0.847| d_loss: 0.679| gp_loss: 0.129| r_loss: 0.106| p_loss: 0.176| v_loss: 0.033| per_loss: 0.460 | a_loss: 0.574
Train: Epoch [754/3000], Step [60/158]| g_loss: 0.746| d_loss: 0.613| gp_loss: 0.053| r_loss: 0.101| p_loss: 0.163| v_loss: 0.033| per_loss: 0.490 | a_loss: 0.482
Train: Epoch [754/3000], Step [90/158]| g_loss: 0.869| d_loss: 0.531| gp_loss: 0.052| r_loss: 0.105| p_loss: 0.169| v_loss: 0.033| per_loss: 0.485 | a_loss: 0.597
Train: Epoch [754/3000], Step [120/158]| g_loss: 0.782| d_loss: 0.608| gp_loss: 0.053| r_loss: 0.096| p_loss: 0.165| v_loss: 0.032| per_loss: 0.518 | a_loss: 0.519
Train: Epoch [754/3000], Step [150/158]| g_loss: 0.793| d_loss: 0.601| gp_loss: 0.059| r_loss: 0.105| p_loss: 0.169| v_loss: 0.032| per_loss: 0.503 | a_loss: 0.520
Train: Epoch [755/3000], Step [30/158]| g_loss: 0.831| d_loss: 0.618| gp_loss: 0.127| r_loss: 0.103| p_loss: 0.164| v_loss: 0.032| per_loss: 0.494 | a_loss: 0.565
Train: Epoch [755/3000], Step [60/158]| g_loss: 0.826| d_loss: 0.621| gp_loss: 0.050| r_loss: 0.103| p_loss: 0.170| v_loss: 0.033| per_loss: 0.476 | a_loss: 0.558
Train: Epoch [755/3000], Step [90/158]| g_loss: 0.849| d_loss: 0.587| gp_loss: 0.054| r_loss: 0.105| p_loss: 0.172| v_loss: 0.035| per_loss: 0.538 | a_loss: 0.569
Train: Epoch [755/3000], Step [120/158]| g_loss: 0.798| d_loss: 0.588| gp_loss: 0.059| r_loss: 0.102| p_loss: 0.173| v_loss: 0.032| per_loss: 0.509 | a_loss: 0.526
Train: Epoch [755/3000], Step [150/158]| g_loss: 0.814| d_loss: 0.619| gp_loss: 0.053| r_loss: 0.109| p_loss: 0.179| v_loss: 0.032| per_loss: 0.487 | a_loss: 0.534
Train: Epoch [756/3000], Step [30/158]| g_loss: 0.805| d_loss: 0.658| gp_loss: 0.104| r_loss: 0.104| p_loss: 0.171| v_loss: 0.032| per_loss: 0.475 | a_loss: 0.537
Train: Epoch [756/3000], Step [60/158]| g_loss: 0.878| d_loss: 0.532| gp_loss: 0.051| r_loss: 0.103| p_loss: 0.167| v_loss: 0.031| per_loss: 0.513 | a_loss: 0.608
Train: Epoch [756/3000], Step [90/158]| g_loss: 0.843| d_loss: 0.551| gp_loss: 0.053| r_loss: 0.098| p_loss: 0.160| v_loss: 0.031| per_loss: 0.476 | a_loss: 0.587
Train: Epoch [756/3000], Step [120/158]| g_loss: 0.781| d_loss: 0.660| gp_loss: 0.053| r_loss: 0.099| p_loss: 0.164| v_loss: 0.032| per_loss: 0.467 | a_loss: 0.521
Train: Epoch [756/3000], Step [150/158]| g_loss: 0.807| d_loss: 0.594| gp_loss: 0.056| r_loss: 0.104| p_loss: 0.170| v_loss: 0.033| per_loss: 0.575 | a_loss: 0.527
Train: Epoch [757/3000], Step [30/158]| g_loss: 0.868| d_loss: 0.616| gp_loss: 0.131| r_loss: 0.105| p_loss: 0.169| v_loss: 0.033| per_loss: 0.522 | a_loss: 0.594
Train: Epoch [757/3000], Step [60/158]| g_loss: 0.768| d_loss: 0.641| gp_loss: 0.053| r_loss: 0.107| p_loss: 0.172| v_loss: 0.033| per_loss: 0.494 | a_loss: 0.493
Train: Epoch [757/3000], Step [90/158]| g_loss: 0.847| d_loss: 0.542| gp_loss: 0.053| r_loss: 0.099| p_loss: 0.166| v_loss: 0.032| per_loss: 0.467 | a_loss: 0.586
Train: Epoch [757/3000], Step [120/158]| g_loss: 0.832| d_loss: 0.579| gp_loss: 0.054| r_loss: 0.101| p_loss: 0.166| v_loss: 0.032| per_loss: 0.489 | a_loss: 0.567
Train: Epoch [757/3000], Step [150/158]| g_loss: 0.684| d_loss: 0.714| gp_loss: 0.055| r_loss: 0.099| p_loss: 0.159| v_loss: 0.031| per_loss: 0.434 | a_loss: 0.431
Train: Epoch [758/3000], Step [30/158]| g_loss: 0.788| d_loss: 0.710| gp_loss: 0.109| r_loss: 0.104| p_loss: 0.170| v_loss: 0.032| per_loss: 0.470 | a_loss: 0.520
Train: Epoch [758/3000], Step [60/158]| g_loss: 0.754| d_loss: 0.637| gp_loss: 0.053| r_loss: 0.100| p_loss: 0.163| v_loss: 0.033| per_loss: 0.460 | a_loss: 0.494
Train: Epoch [758/3000], Step [90/158]| g_loss: 0.791| d_loss: 0.594| gp_loss: 0.052| r_loss: 0.099| p_loss: 0.161| v_loss: 0.032| per_loss: 0.464 | a_loss: 0.534
Train: Epoch [758/3000], Step [120/158]| g_loss: 0.791| d_loss: 0.629| gp_loss: 0.057| r_loss: 0.101| p_loss: 0.168| v_loss: 0.031| per_loss: 0.461 | a_loss: 0.529
Train: Epoch [758/3000], Step [150/158]| g_loss: 0.800| d_loss: 0.588| gp_loss: 0.054| r_loss: 0.104| p_loss: 0.166| v_loss: 0.033| per_loss: 0.494 | a_loss: 0.530
Train: Epoch [759/3000], Step [30/158]| g_loss: 0.815| d_loss: 0.667| gp_loss: 0.158| r_loss: 0.099| p_loss: 0.158| v_loss: 0.033| per_loss: 0.439 | a_loss: 0.560
Train: Epoch [759/3000], Step [60/158]| g_loss: 0.860| d_loss: 0.552| gp_loss: 0.048| r_loss: 0.100| p_loss: 0.166| v_loss: 0.032| per_loss: 0.481 | a_loss: 0.597
Train: Epoch [759/3000], Step [90/158]| g_loss: 0.791| d_loss: 0.572| gp_loss: 0.053| r_loss: 0.101| p_loss: 0.165| v_loss: 0.032| per_loss: 0.469 | a_loss: 0.529
Train: Epoch [759/3000], Step [120/158]| g_loss: 0.790| d_loss: 0.636| gp_loss: 0.053| r_loss: 0.099| p_loss: 0.162| v_loss: 0.032| per_loss: 0.489 | a_loss: 0.529
Train: Epoch [759/3000], Step [150/158]| g_loss: 0.797| d_loss: 0.651| gp_loss: 0.053| r_loss: 0.104| p_loss: 0.170| v_loss: 0.032| per_loss: 0.489 | a_loss: 0.528
Train: Epoch [760/3000], Step [30/158]| g_loss: 0.784| d_loss: 0.704| gp_loss: 0.141| r_loss: 0.103| p_loss: 0.160| v_loss: 0.031| per_loss: 0.482 | a_loss: 0.521
Train: Epoch [760/3000], Step [60/158]| g_loss: 0.811| d_loss: 0.575| gp_loss: 0.049| r_loss: 0.099| p_loss: 0.165| v_loss: 0.031| per_loss: 0.469 | a_loss: 0.551
Train: Epoch [760/3000], Step [90/158]| g_loss: 0.800| d_loss: 0.579| gp_loss: 0.049| r_loss: 0.103| p_loss: 0.164| v_loss: 0.033| per_loss: 0.481 | a_loss: 0.534
Train: Epoch [760/3000], Step [120/158]| g_loss: 0.821| d_loss: 0.583| gp_loss: 0.051| r_loss: 0.101| p_loss: 0.160| v_loss: 0.031| per_loss: 0.504 | a_loss: 0.559
Train: Epoch [760/3000], Step [150/158]| g_loss: 0.815| d_loss: 0.576| gp_loss: 0.050| r_loss: 0.107| p_loss: 0.165| v_loss: 0.033| per_loss: 0.469 | a_loss: 0.545
Train: Epoch [761/3000], Step [30/158]| g_loss: 0.797| d_loss: 0.748| gp_loss: 0.155| r_loss: 0.099| p_loss: 0.164| v_loss: 0.032| per_loss: 0.482 | a_loss: 0.536
Train: Epoch [761/3000], Step [60/158]| g_loss: 0.783| d_loss: 0.546| gp_loss: 0.050| r_loss: 0.102| p_loss: 0.160| v_loss: 0.032| per_loss: 0.472 | a_loss: 0.523
Train: Epoch [761/3000], Step [90/158]| g_loss: 0.831| d_loss: 0.572| gp_loss: 0.048| r_loss: 0.100| p_loss: 0.165| v_loss: 0.031| per_loss: 0.488 | a_loss: 0.568
Train: Epoch [761/3000], Step [120/158]| g_loss: 0.825| d_loss: 0.560| gp_loss: 0.050| r_loss: 0.097| p_loss: 0.155| v_loss: 0.031| per_loss: 0.476 | a_loss: 0.571
Train: Epoch [761/3000], Step [150/158]| g_loss: 0.801| d_loss: 0.595| gp_loss: 0.051| r_loss: 0.102| p_loss: 0.161| v_loss: 0.033| per_loss: 0.514 | a_loss: 0.535
Train: Epoch [762/3000], Step [30/158]| g_loss: 0.775| d_loss: 0.720| gp_loss: 0.130| r_loss: 0.101| p_loss: 0.162| v_loss: 0.032| per_loss: 0.502 | a_loss: 0.511
Train: Epoch [762/3000], Step [60/158]| g_loss: 0.754| d_loss: 0.582| gp_loss: 0.053| r_loss: 0.101| p_loss: 0.158| v_loss: 0.032| per_loss: 0.494 | a_loss: 0.493
Train: Epoch [762/3000], Step [90/158]| g_loss: 0.763| d_loss: 0.602| gp_loss: 0.054| r_loss: 0.098| p_loss: 0.150| v_loss: 0.030| per_loss: 0.471 | a_loss: 0.513
Train: Epoch [762/3000], Step [120/158]| g_loss: 0.806| d_loss: 0.571| gp_loss: 0.057| r_loss: 0.096| p_loss: 0.154| v_loss: 0.031| per_loss: 0.500 | a_loss: 0.551
Train: Epoch [762/3000], Step [150/158]| g_loss: 0.867| d_loss: 0.498| gp_loss: 0.058| r_loss: 0.099| p_loss: 0.153| v_loss: 0.032| per_loss: 0.466 | a_loss: 0.614
Train: Epoch [763/3000], Step [30/158]| g_loss: 0.886| d_loss: 0.564| gp_loss: 0.155| r_loss: 0.096| p_loss: 0.152| v_loss: 0.031| per_loss: 0.513 | a_loss: 0.631
Train: Epoch [763/3000], Step [60/158]| g_loss: 0.799| d_loss: 0.624| gp_loss: 0.051| r_loss: 0.098| p_loss: 0.157| v_loss: 0.031| per_loss: 0.465 | a_loss: 0.545
Train: Epoch [763/3000], Step [90/158]| g_loss: 0.795| d_loss: 0.589| gp_loss: 0.054| r_loss: 0.103| p_loss: 0.163| v_loss: 0.033| per_loss: 0.485 | a_loss: 0.529
Train: Epoch [763/3000], Step [120/158]| g_loss: 0.775| d_loss: 0.603| gp_loss: 0.057| r_loss: 0.097| p_loss: 0.155| v_loss: 0.030| per_loss: 0.524 | a_loss: 0.518
Train: Epoch [763/3000], Step [150/158]| g_loss: 0.808| d_loss: 0.620| gp_loss: 0.052| r_loss: 0.105| p_loss: 0.165| v_loss: 0.031| per_loss: 0.496 | a_loss: 0.540
Train: Epoch [764/3000], Step [30/158]| g_loss: 0.776| d_loss: 0.718| gp_loss: 0.143| r_loss: 0.102| p_loss: 0.173| v_loss: 0.030| per_loss: 0.508 | a_loss: 0.507
Train: Epoch [764/3000], Step [60/158]| g_loss: 0.771| d_loss: 0.601| gp_loss: 0.053| r_loss: 0.100| p_loss: 0.167| v_loss: 0.031| per_loss: 0.504 | a_loss: 0.507
Train: Epoch [764/3000], Step [90/158]| g_loss: 0.891| d_loss: 0.543| gp_loss: 0.054| r_loss: 0.106| p_loss: 0.175| v_loss: 0.034| per_loss: 0.530 | a_loss: 0.610
Train: Epoch [764/3000], Step [120/158]| g_loss: 0.761| d_loss: 0.657| gp_loss: 0.056| r_loss: 0.107| p_loss: 0.186| v_loss: 0.033| per_loss: 0.463 | a_loss: 0.482
Train: Epoch [764/3000], Step [150/158]| g_loss: 0.815| d_loss: 0.558| gp_loss: 0.053| r_loss: 0.104| p_loss: 0.171| v_loss: 0.031| per_loss: 0.509 | a_loss: 0.543
Train: Epoch [765/3000], Step [30/158]| g_loss: 0.826| d_loss: 0.709| gp_loss: 0.179| r_loss: 0.102| p_loss: 0.164| v_loss: 0.031| per_loss: 0.492 | a_loss: 0.562
Train: Epoch [765/3000], Step [60/158]| g_loss: 0.737| d_loss: 0.673| gp_loss: 0.054| r_loss: 0.102| p_loss: 0.170| v_loss: 0.032| per_loss: 0.519 | a_loss: 0.467
Train: Epoch [765/3000], Step [90/158]| g_loss: 0.827| d_loss: 0.513| gp_loss: 0.057| r_loss: 0.100| p_loss: 0.166| v_loss: 0.032| per_loss: 0.467 | a_loss: 0.565
Train: Epoch [765/3000], Step [120/158]| g_loss: 0.876| d_loss: 0.581| gp_loss: 0.055| r_loss: 0.107| p_loss: 0.174| v_loss: 0.033| per_loss: 0.532 | a_loss: 0.596
Train: Epoch [765/3000], Step [150/158]| g_loss: 0.807| d_loss: 0.549| gp_loss: 0.058| r_loss: 0.100| p_loss: 0.159| v_loss: 0.032| per_loss: 0.477 | a_loss: 0.548
Train: Epoch [766/3000], Step [30/158]| g_loss: 0.801| d_loss: 0.658| gp_loss: 0.072| r_loss: 0.101| p_loss: 0.167| v_loss: 0.032| per_loss: 0.471 | a_loss: 0.537
Train: Epoch [766/3000], Step [60/158]| g_loss: 0.812| d_loss: 0.515| gp_loss: 0.058| r_loss: 0.099| p_loss: 0.170| v_loss: 0.032| per_loss: 0.505 | a_loss: 0.546
Train: Epoch [766/3000], Step [90/158]| g_loss: 0.861| d_loss: 0.628| gp_loss: 0.056| r_loss: 0.111| p_loss: 0.177| v_loss: 0.031| per_loss: 0.477 | a_loss: 0.582
Train: Epoch [766/3000], Step [120/158]| g_loss: 0.805| d_loss: 0.513| gp_loss: 0.060| r_loss: 0.102| p_loss: 0.167| v_loss: 0.032| per_loss: 0.481 | a_loss: 0.540
Train: Epoch [766/3000], Step [150/158]| g_loss: 0.753| d_loss: 0.709| gp_loss: 0.055| r_loss: 0.103| p_loss: 0.172| v_loss: 0.030| per_loss: 0.497 | a_loss: 0.484
Train: Epoch [767/3000], Step [30/158]| g_loss: 0.832| d_loss: 0.634| gp_loss: 0.157| r_loss: 0.105| p_loss: 0.168| v_loss: 0.031| per_loss: 0.480 | a_loss: 0.563
Train: Epoch [767/3000], Step [60/158]| g_loss: 0.802| d_loss: 0.601| gp_loss: 0.052| r_loss: 0.100| p_loss: 0.162| v_loss: 0.032| per_loss: 0.483 | a_loss: 0.541
Train: Epoch [767/3000], Step [90/158]| g_loss: 0.742| d_loss: 0.647| gp_loss: 0.054| r_loss: 0.101| p_loss: 0.162| v_loss: 0.032| per_loss: 0.475 | a_loss: 0.481
Train: Epoch [767/3000], Step [120/158]| g_loss: 0.812| d_loss: 0.616| gp_loss: 0.056| r_loss: 0.101| p_loss: 0.163| v_loss: 0.031| per_loss: 0.469 | a_loss: 0.552
Train: Epoch [767/3000], Step [150/158]| g_loss: 0.797| d_loss: 0.558| gp_loss: 0.055| r_loss: 0.098| p_loss: 0.164| v_loss: 0.032| per_loss: 0.432 | a_loss: 0.542
Train: Epoch [768/3000], Step [30/158]| g_loss: 0.781| d_loss: 0.722| gp_loss: 0.149| r_loss: 0.112| p_loss: 0.170| v_loss: 0.032| per_loss: 0.455 | a_loss: 0.506
Train: Epoch [768/3000], Step [60/158]| g_loss: 0.774| d_loss: 0.598| gp_loss: 0.053| r_loss: 0.106| p_loss: 0.165| v_loss: 0.032| per_loss: 0.462 | a_loss: 0.508
Train: Epoch [768/3000], Step [90/158]| g_loss: 0.889| d_loss: 0.482| gp_loss: 0.054| r_loss: 0.096| p_loss: 0.155| v_loss: 0.030| per_loss: 0.437 | a_loss: 0.641
Train: Epoch [768/3000], Step [120/158]| g_loss: 0.736| d_loss: 0.704| gp_loss: 0.053| r_loss: 0.097| p_loss: 0.165| v_loss: 0.030| per_loss: 0.501 | a_loss: 0.476
Train: Epoch [768/3000], Step [150/158]| g_loss: 0.798| d_loss: 0.622| gp_loss: 0.055| r_loss: 0.105| p_loss: 0.173| v_loss: 0.033| per_loss: 0.482 | a_loss: 0.525
Train: Epoch [769/3000], Step [30/158]| g_loss: 0.810| d_loss: 0.692| gp_loss: 0.151| r_loss: 0.104| p_loss: 0.161| v_loss: 0.031| per_loss: 0.450 | a_loss: 0.550
Train: Epoch [769/3000], Step [60/158]| g_loss: 0.787| d_loss: 0.539| gp_loss: 0.050| r_loss: 0.102| p_loss: 0.156| v_loss: 0.032| per_loss: 0.481 | a_loss: 0.527
Train: Epoch [769/3000], Step [90/158]| g_loss: 0.810| d_loss: 0.625| gp_loss: 0.052| r_loss: 0.096| p_loss: 0.156| v_loss: 0.030| per_loss: 0.459 | a_loss: 0.561
Train: Epoch [769/3000], Step [120/158]| g_loss: 0.735| d_loss: 0.642| gp_loss: 0.053| r_loss: 0.103| p_loss: 0.161| v_loss: 0.031| per_loss: 0.450 | a_loss: 0.476
Train: Epoch [769/3000], Step [150/158]| g_loss: 0.751| d_loss: 0.587| gp_loss: 0.055| r_loss: 0.101| p_loss: 0.163| v_loss: 0.032| per_loss: 0.450 | a_loss: 0.492
Train: Epoch [770/3000], Step [30/158]| g_loss: 0.822| d_loss: 0.702| gp_loss: 0.126| r_loss: 0.106| p_loss: 0.176| v_loss: 0.032| per_loss: 0.518 | a_loss: 0.544
Train: Epoch [770/3000], Step [60/158]| g_loss: 0.801| d_loss: 0.599| gp_loss: 0.049| r_loss: 0.097| p_loss: 0.162| v_loss: 0.030| per_loss: 0.469 | a_loss: 0.546
Train: Epoch [770/3000], Step [90/158]| g_loss: 0.891| d_loss: 0.505| gp_loss: 0.046| r_loss: 0.106| p_loss: 0.168| v_loss: 0.032| per_loss: 0.492 | a_loss: 0.620
Train: Epoch [770/3000], Step [120/158]| g_loss: 0.803| d_loss: 0.603| gp_loss: 0.049| r_loss: 0.103| p_loss: 0.171| v_loss: 0.031| per_loss: 0.458 | a_loss: 0.538
Train: Epoch [770/3000], Step [150/158]| g_loss: 0.782| d_loss: 0.609| gp_loss: 0.051| r_loss: 0.106| p_loss: 0.168| v_loss: 0.030| per_loss: 0.455 | a_loss: 0.516
Train: Epoch [771/3000], Step [30/158]| g_loss: 0.787| d_loss: 0.710| gp_loss: 0.137| r_loss: 0.107| p_loss: 0.181| v_loss: 0.030| per_loss: 0.481 | a_loss: 0.511
Train: Epoch [771/3000], Step [60/158]| g_loss: 0.820| d_loss: 0.585| gp_loss: 0.051| r_loss: 0.099| p_loss: 0.163| v_loss: 0.030| per_loss: 0.485 | a_loss: 0.561
Train: Epoch [771/3000], Step [90/158]| g_loss: 0.785| d_loss: 0.619| gp_loss: 0.049| r_loss: 0.105| p_loss: 0.164| v_loss: 0.030| per_loss: 0.493 | a_loss: 0.519
Train: Epoch [771/3000], Step [120/158]| g_loss: 0.730| d_loss: 0.653| gp_loss: 0.052| r_loss: 0.100| p_loss: 0.159| v_loss: 0.031| per_loss: 0.506 | a_loss: 0.470
Train: Epoch [771/3000], Step [150/158]| g_loss: 0.831| d_loss: 0.525| gp_loss: 0.055| r_loss: 0.098| p_loss: 0.163| v_loss: 0.031| per_loss: 0.448 | a_loss: 0.576
Train: Epoch [772/3000], Step [30/158]| g_loss: 0.800| d_loss: 0.670| gp_loss: 0.122| r_loss: 0.101| p_loss: 0.158| v_loss: 0.029| per_loss: 0.504 | a_loss: 0.540
Train: Epoch [772/3000], Step [60/158]| g_loss: 0.788| d_loss: 0.569| gp_loss: 0.052| r_loss: 0.096| p_loss: 0.157| v_loss: 0.030| per_loss: 0.491 | a_loss: 0.534
Train: Epoch [772/3000], Step [90/158]| g_loss: 0.756| d_loss: 0.670| gp_loss: 0.051| r_loss: 0.103| p_loss: 0.166| v_loss: 0.031| per_loss: 0.467 | a_loss: 0.493
Train: Epoch [772/3000], Step [120/158]| g_loss: 0.807| d_loss: 0.537| gp_loss: 0.055| r_loss: 0.095| p_loss: 0.160| v_loss: 0.031| per_loss: 0.446 | a_loss: 0.556
Train: Epoch [772/3000], Step [150/158]| g_loss: 0.830| d_loss: 0.548| gp_loss: 0.059| r_loss: 0.104| p_loss: 0.165| v_loss: 0.031| per_loss: 0.532 | a_loss: 0.559
Train: Epoch [773/3000], Step [30/158]| g_loss: 0.845| d_loss: 0.693| gp_loss: 0.173| r_loss: 0.107| p_loss: 0.170| v_loss: 0.033| per_loss: 0.509 | a_loss: 0.570
Train: Epoch [773/3000], Step [60/158]| g_loss: 0.812| d_loss: 0.544| gp_loss: 0.052| r_loss: 0.094| p_loss: 0.155| v_loss: 0.032| per_loss: 0.494 | a_loss: 0.560
Train: Epoch [773/3000], Step [90/158]| g_loss: 0.822| d_loss: 0.569| gp_loss: 0.053| r_loss: 0.099| p_loss: 0.158| v_loss: 0.031| per_loss: 0.504 | a_loss: 0.563
Train: Epoch [773/3000], Step [120/158]| g_loss: 0.737| d_loss: 0.635| gp_loss: 0.054| r_loss: 0.101| p_loss: 0.166| v_loss: 0.032| per_loss: 0.496 | a_loss: 0.472
Train: Epoch [773/3000], Step [150/158]| g_loss: 0.781| d_loss: 0.663| gp_loss: 0.056| r_loss: 0.105| p_loss: 0.178| v_loss: 0.030| per_loss: 0.461 | a_loss: 0.510
Train: Epoch [774/3000], Step [30/158]| g_loss: 0.772| d_loss: 0.710| gp_loss: 0.147| r_loss: 0.102| p_loss: 0.171| v_loss: 0.030| per_loss: 0.484 | a_loss: 0.505
Train: Epoch [774/3000], Step [60/158]| g_loss: 0.850| d_loss: 0.541| gp_loss: 0.053| r_loss: 0.101| p_loss: 0.162| v_loss: 0.031| per_loss: 0.489 | a_loss: 0.589
Train: Epoch [774/3000], Step [90/158]| g_loss: 0.808| d_loss: 0.563| gp_loss: 0.052| r_loss: 0.106| p_loss: 0.164| v_loss: 0.032| per_loss: 0.486 | a_loss: 0.540
Train: Epoch [774/3000], Step [120/158]| g_loss: 0.799| d_loss: 0.658| gp_loss: 0.056| r_loss: 0.101| p_loss: 0.172| v_loss: 0.031| per_loss: 0.454 | a_loss: 0.535
Train: Epoch [774/3000], Step [150/158]| g_loss: 0.784| d_loss: 0.611| gp_loss: 0.055| r_loss: 0.097| p_loss: 0.160| v_loss: 0.030| per_loss: 0.496 | a_loss: 0.527
Train: Epoch [775/3000], Step [30/158]| g_loss: 0.824| d_loss: 0.643| gp_loss: 0.146| r_loss: 0.098| p_loss: 0.168| v_loss: 0.032| per_loss: 0.537 | a_loss: 0.557
Train: Epoch [775/3000], Step [60/158]| g_loss: 0.788| d_loss: 0.629| gp_loss: 0.052| r_loss: 0.099| p_loss: 0.158| v_loss: 0.032| per_loss: 0.466 | a_loss: 0.531
Train: Epoch [775/3000], Step [90/158]| g_loss: 0.792| d_loss: 0.561| gp_loss: 0.051| r_loss: 0.096| p_loss: 0.160| v_loss: 0.031| per_loss: 0.469 | a_loss: 0.539
Train: Epoch [775/3000], Step [120/158]| g_loss: 0.838| d_loss: 0.552| gp_loss: 0.050| r_loss: 0.104| p_loss: 0.164| v_loss: 0.031| per_loss: 0.468 | a_loss: 0.574
Train: Epoch [775/3000], Step [150/158]| g_loss: 0.771| d_loss: 0.595| gp_loss: 0.056| r_loss: 0.099| p_loss: 0.155| v_loss: 0.031| per_loss: 0.477 | a_loss: 0.517
Train: Epoch [776/3000], Step [30/158]| g_loss: 0.787| d_loss: 0.732| gp_loss: 0.155| r_loss: 0.104| p_loss: 0.164| v_loss: 0.033| per_loss: 0.499 | a_loss: 0.518
Train: Epoch [776/3000], Step [60/158]| g_loss: 0.769| d_loss: 0.598| gp_loss: 0.051| r_loss: 0.095| p_loss: 0.156| v_loss: 0.031| per_loss: 0.469 | a_loss: 0.518
Train: Epoch [776/3000], Step [90/158]| g_loss: 0.767| d_loss: 0.572| gp_loss: 0.053| r_loss: 0.097| p_loss: 0.160| v_loss: 0.030| per_loss: 0.518 | a_loss: 0.508
Train: Epoch [776/3000], Step [120/158]| g_loss: 0.887| d_loss: 0.522| gp_loss: 0.054| r_loss: 0.101| p_loss: 0.160| v_loss: 0.030| per_loss: 0.474 | a_loss: 0.628
Train: Epoch [776/3000], Step [150/158]| g_loss: 0.753| d_loss: 0.599| gp_loss: 0.054| r_loss: 0.097| p_loss: 0.152| v_loss: 0.029| per_loss: 0.485 | a_loss: 0.502
Train: Epoch [777/3000], Step [30/158]| g_loss: 0.837| d_loss: 0.675| gp_loss: 0.170| r_loss: 0.101| p_loss: 0.161| v_loss: 0.031| per_loss: 0.486 | a_loss: 0.577
Train: Epoch [777/3000], Step [60/158]| g_loss: 0.816| d_loss: 0.590| gp_loss: 0.047| r_loss: 0.101| p_loss: 0.161| v_loss: 0.031| per_loss: 0.486 | a_loss: 0.554
Train: Epoch [777/3000], Step [90/158]| g_loss: 0.765| d_loss: 0.628| gp_loss: 0.050| r_loss: 0.099| p_loss: 0.160| v_loss: 0.032| per_loss: 0.462 | a_loss: 0.508
Train: Epoch [777/3000], Step [120/158]| g_loss: 0.815| d_loss: 0.622| gp_loss: 0.051| r_loss: 0.104| p_loss: 0.167| v_loss: 0.031| per_loss: 0.499 | a_loss: 0.547
Train: Epoch [777/3000], Step [150/158]| g_loss: 0.741| d_loss: 0.584| gp_loss: 0.057| r_loss: 0.101| p_loss: 0.161| v_loss: 0.031| per_loss: 0.479 | a_loss: 0.482
Train: Epoch [778/3000], Step [30/158]| g_loss: 0.803| d_loss: 0.709| gp_loss: 0.124| r_loss: 0.101| p_loss: 0.159| v_loss: 0.029| per_loss: 0.494 | a_loss: 0.544
Train: Epoch [778/3000], Step [60/158]| g_loss: 0.778| d_loss: 0.632| gp_loss: 0.051| r_loss: 0.103| p_loss: 0.168| v_loss: 0.031| per_loss: 0.518 | a_loss: 0.508
Train: Epoch [778/3000], Step [90/158]| g_loss: 0.812| d_loss: 0.546| gp_loss: 0.054| r_loss: 0.100| p_loss: 0.160| v_loss: 0.030| per_loss: 0.441 | a_loss: 0.558
Train: Epoch [778/3000], Step [120/158]| g_loss: 0.785| d_loss: 0.661| gp_loss: 0.055| r_loss: 0.101| p_loss: 0.166| v_loss: 0.032| per_loss: 0.433 | a_loss: 0.526
Train: Epoch [778/3000], Step [150/158]| g_loss: 0.793| d_loss: 0.616| gp_loss: 0.051| r_loss: 0.102| p_loss: 0.158| v_loss: 0.032| per_loss: 0.487 | a_loss: 0.532
Train: Epoch [779/3000], Step [30/158]| g_loss: 0.790| d_loss: 0.731| gp_loss: 0.188| r_loss: 0.098| p_loss: 0.158| v_loss: 0.031| per_loss: 0.474 | a_loss: 0.535
Train: Epoch [779/3000], Step [60/158]| g_loss: 0.795| d_loss: 0.579| gp_loss: 0.049| r_loss: 0.101| p_loss: 0.157| v_loss: 0.031| per_loss: 0.488 | a_loss: 0.536
Train: Epoch [779/3000], Step [90/158]| g_loss: 0.760| d_loss: 0.589| gp_loss: 0.049| r_loss: 0.096| p_loss: 0.157| v_loss: 0.030| per_loss: 0.467 | a_loss: 0.509
Train: Epoch [779/3000], Step [120/158]| g_loss: 0.748| d_loss: 0.560| gp_loss: 0.051| r_loss: 0.093| p_loss: 0.149| v_loss: 0.030| per_loss: 0.481 | a_loss: 0.503
Train: Epoch [779/3000], Step [150/158]| g_loss: 0.866| d_loss: 0.628| gp_loss: 0.049| r_loss: 0.102| p_loss: 0.160| v_loss: 0.031| per_loss: 0.471 | a_loss: 0.607
Train: Epoch [780/3000], Step [30/158]| g_loss: 0.738| d_loss: 0.722| gp_loss: 0.168| r_loss: 0.099| p_loss: 0.153| v_loss: 0.031| per_loss: 0.478 | a_loss: 0.484
Train: Epoch [780/3000], Step [60/158]| g_loss: 0.842| d_loss: 0.555| gp_loss: 0.050| r_loss: 0.093| p_loss: 0.149| v_loss: 0.031| per_loss: 0.482 | a_loss: 0.595
Train: Epoch [780/3000], Step [90/158]| g_loss: 0.744| d_loss: 0.669| gp_loss: 0.048| r_loss: 0.094| p_loss: 0.154| v_loss: 0.030| per_loss: 0.449 | a_loss: 0.497
Train: Epoch [780/3000], Step [120/158]| g_loss: 0.777| d_loss: 0.548| gp_loss: 0.051| r_loss: 0.099| p_loss: 0.157| v_loss: 0.031| per_loss: 0.485 | a_loss: 0.520
Train: Epoch [780/3000], Step [150/158]| g_loss: 0.835| d_loss: 0.596| gp_loss: 0.050| r_loss: 0.099| p_loss: 0.155| v_loss: 0.031| per_loss: 0.443 | a_loss: 0.583
Train: Epoch [781/3000], Step [30/158]| g_loss: 0.762| d_loss: 0.682| gp_loss: 0.113| r_loss: 0.101| p_loss: 0.154| v_loss: 0.030| per_loss: 0.492 | a_loss: 0.505
Train: Epoch [781/3000], Step [60/158]| g_loss: 0.794| d_loss: 0.599| gp_loss: 0.051| r_loss: 0.097| p_loss: 0.157| v_loss: 0.031| per_loss: 0.451 | a_loss: 0.543
Train: Epoch [781/3000], Step [90/158]| g_loss: 0.723| d_loss: 0.677| gp_loss: 0.053| r_loss: 0.103| p_loss: 0.171| v_loss: 0.032| per_loss: 0.452 | a_loss: 0.457
Train: Epoch [781/3000], Step [120/158]| g_loss: 0.825| d_loss: 0.570| gp_loss: 0.055| r_loss: 0.099| p_loss: 0.156| v_loss: 0.031| per_loss: 0.515 | a_loss: 0.566
Train: Epoch [781/3000], Step [150/158]| g_loss: 0.784| d_loss: 0.618| gp_loss: 0.055| r_loss: 0.098| p_loss: 0.157| v_loss: 0.030| per_loss: 0.450 | a_loss: 0.532
Train: Epoch [782/3000], Step [30/158]| g_loss: 0.825| d_loss: 0.602| gp_loss: 0.138| r_loss: 0.098| p_loss: 0.161| v_loss: 0.030| per_loss: 0.476 | a_loss: 0.569
Train: Epoch [782/3000], Step [60/158]| g_loss: 0.840| d_loss: 0.544| gp_loss: 0.051| r_loss: 0.098| p_loss: 0.155| v_loss: 0.031| per_loss: 0.508 | a_loss: 0.583
Train: Epoch [782/3000], Step [90/158]| g_loss: 0.786| d_loss: 0.659| gp_loss: 0.052| r_loss: 0.096| p_loss: 0.161| v_loss: 0.031| per_loss: 0.480 | a_loss: 0.530
Train: Epoch [782/3000], Step [120/158]| g_loss: 0.794| d_loss: 0.595| gp_loss: 0.053| r_loss: 0.098| p_loss: 0.156| v_loss: 0.031| per_loss: 0.450 | a_loss: 0.542
Train: Epoch [782/3000], Step [150/158]| g_loss: 0.749| d_loss: 0.606| gp_loss: 0.054| r_loss: 0.100| p_loss: 0.163| v_loss: 0.032| per_loss: 0.460 | a_loss: 0.490
Train: Epoch [783/3000], Step [30/158]| g_loss: 0.816| d_loss: 0.696| gp_loss: 0.141| r_loss: 0.100| p_loss: 0.161| v_loss: 0.030| per_loss: 0.479 | a_loss: 0.558
Train: Epoch [783/3000], Step [60/158]| g_loss: 0.802| d_loss: 0.575| gp_loss: 0.052| r_loss: 0.102| p_loss: 0.161| v_loss: 0.030| per_loss: 0.458 | a_loss: 0.543
Train: Epoch [783/3000], Step [90/158]| g_loss: 0.782| d_loss: 0.577| gp_loss: 0.052| r_loss: 0.096| p_loss: 0.160| v_loss: 0.030| per_loss: 0.467 | a_loss: 0.529
Train: Epoch [783/3000], Step [120/158]| g_loss: 0.766| d_loss: 0.634| gp_loss: 0.051| r_loss: 0.096| p_loss: 0.154| v_loss: 0.031| per_loss: 0.486 | a_loss: 0.513
Train: Epoch [783/3000], Step [150/158]| g_loss: 0.772| d_loss: 0.610| gp_loss: 0.056| r_loss: 0.103| p_loss: 0.160| v_loss: 0.031| per_loss: 0.490 | a_loss: 0.509
Train: Epoch [784/3000], Step [30/158]| g_loss: 0.842| d_loss: 0.610| gp_loss: 0.169| r_loss: 0.098| p_loss: 0.159| v_loss: 0.032| per_loss: 0.486 | a_loss: 0.583
Train: Epoch [784/3000], Step [60/158]| g_loss: 0.770| d_loss: 0.595| gp_loss: 0.050| r_loss: 0.096| p_loss: 0.156| v_loss: 0.031| per_loss: 0.491 | a_loss: 0.517
Train: Epoch [784/3000], Step [90/158]| g_loss: 0.743| d_loss: 0.684| gp_loss: 0.052| r_loss: 0.101| p_loss: 0.166| v_loss: 0.032| per_loss: 0.472 | a_loss: 0.480
Train: Epoch [784/3000], Step [120/158]| g_loss: 0.807| d_loss: 0.583| gp_loss: 0.052| r_loss: 0.102| p_loss: 0.160| v_loss: 0.031| per_loss: 0.488 | a_loss: 0.545
Train: Epoch [784/3000], Step [150/158]| g_loss: 0.824| d_loss: 0.561| gp_loss: 0.055| r_loss: 0.098| p_loss: 0.157| v_loss: 0.031| per_loss: 0.499 | a_loss: 0.567
Train: Epoch [785/3000], Step [30/158]| g_loss: 0.781| d_loss: 0.671| gp_loss: 0.146| r_loss: 0.098| p_loss: 0.159| v_loss: 0.033| per_loss: 0.488 | a_loss: 0.521
Train: Epoch [785/3000], Step [60/158]| g_loss: 0.818| d_loss: 0.576| gp_loss: 0.049| r_loss: 0.098| p_loss: 0.155| v_loss: 0.031| per_loss: 0.475 | a_loss: 0.564
Train: Epoch [785/3000], Step [90/158]| g_loss: 0.779| d_loss: 0.596| gp_loss: 0.054| r_loss: 0.099| p_loss: 0.154| v_loss: 0.031| per_loss: 0.477 | a_loss: 0.524
Train: Epoch [785/3000], Step [120/158]| g_loss: 0.796| d_loss: 0.610| gp_loss: 0.055| r_loss: 0.098| p_loss: 0.157| v_loss: 0.030| per_loss: 0.492 | a_loss: 0.540
Train: Epoch [785/3000], Step [150/158]| g_loss: 0.774| d_loss: 0.603| gp_loss: 0.055| r_loss: 0.100| p_loss: 0.160| v_loss: 0.031| per_loss: 0.522 | a_loss: 0.510
Train: Epoch [786/3000], Step [30/158]| g_loss: 0.840| d_loss: 0.611| gp_loss: 0.147| r_loss: 0.096| p_loss: 0.157| v_loss: 0.032| per_loss: 0.498 | a_loss: 0.584
Train: Epoch [786/3000], Step [60/158]| g_loss: 0.877| d_loss: 0.579| gp_loss: 0.054| r_loss: 0.105| p_loss: 0.162| v_loss: 0.033| per_loss: 0.468 | a_loss: 0.611
Train: Epoch [786/3000], Step [90/158]| g_loss: 0.769| d_loss: 0.616| gp_loss: 0.051| r_loss: 0.105| p_loss: 0.164| v_loss: 0.031| per_loss: 0.513 | a_loss: 0.500
Train: Epoch [786/3000], Step [120/158]| g_loss: 0.832| d_loss: 0.580| gp_loss: 0.053| r_loss: 0.101| p_loss: 0.166| v_loss: 0.032| per_loss: 0.477 | a_loss: 0.568
Train: Epoch [786/3000], Step [150/158]| g_loss: 0.782| d_loss: 0.643| gp_loss: 0.054| r_loss: 0.101| p_loss: 0.173| v_loss: 0.031| per_loss: 0.491 | a_loss: 0.515
Train: Epoch [787/3000], Step [30/158]| g_loss: 0.781| d_loss: 0.724| gp_loss: 0.154| r_loss: 0.103| p_loss: 0.174| v_loss: 0.031| per_loss: 0.465 | a_loss: 0.512
Train: Epoch [787/3000], Step [60/158]| g_loss: 0.808| d_loss: 0.621| gp_loss: 0.051| r_loss: 0.098| p_loss: 0.165| v_loss: 0.030| per_loss: 0.532 | a_loss: 0.544
Train: Epoch [787/3000], Step [90/158]| g_loss: 0.810| d_loss: 0.632| gp_loss: 0.052| r_loss: 0.102| p_loss: 0.172| v_loss: 0.032| per_loss: 0.469 | a_loss: 0.544
Train: Epoch [787/3000], Step [120/158]| g_loss: 0.797| d_loss: 0.615| gp_loss: 0.052| r_loss: 0.101| p_loss: 0.162| v_loss: 0.034| per_loss: 0.474 | a_loss: 0.534
Train: Epoch [787/3000], Step [150/158]| g_loss: 0.835| d_loss: 0.532| gp_loss: 0.052| r_loss: 0.100| p_loss: 0.165| v_loss: 0.031| per_loss: 0.462 | a_loss: 0.575
Train: Epoch [788/3000], Step [30/158]| g_loss: 0.791| d_loss: 0.682| gp_loss: 0.123| r_loss: 0.098| p_loss: 0.162| v_loss: 0.031| per_loss: 0.443 | a_loss: 0.536
Train: Epoch [788/3000], Step [60/158]| g_loss: 0.757| d_loss: 0.598| gp_loss: 0.051| r_loss: 0.097| p_loss: 0.151| v_loss: 0.031| per_loss: 0.472 | a_loss: 0.507
Train: Epoch [788/3000], Step [90/158]| g_loss: 0.875| d_loss: 0.565| gp_loss: 0.049| r_loss: 0.100| p_loss: 0.159| v_loss: 0.031| per_loss: 0.509 | a_loss: 0.615
Train: Epoch [788/3000], Step [120/158]| g_loss: 0.769| d_loss: 0.567| gp_loss: 0.053| r_loss: 0.099| p_loss: 0.156| v_loss: 0.030| per_loss: 0.498 | a_loss: 0.512
Train: Epoch [788/3000], Step [150/158]| g_loss: 0.821| d_loss: 0.600| gp_loss: 0.052| r_loss: 0.097| p_loss: 0.152| v_loss: 0.032| per_loss: 0.464 | a_loss: 0.569
Train: Epoch [789/3000], Step [30/158]| g_loss: 0.785| d_loss: 0.721| gp_loss: 0.148| r_loss: 0.103| p_loss: 0.159| v_loss: 0.031| per_loss: 0.483 | a_loss: 0.523
Train: Epoch [789/3000], Step [60/158]| g_loss: 0.784| d_loss: 0.544| gp_loss: 0.048| r_loss: 0.099| p_loss: 0.158| v_loss: 0.032| per_loss: 0.446 | a_loss: 0.530
Train: Epoch [789/3000], Step [90/158]| g_loss: 0.829| d_loss: 0.546| gp_loss: 0.051| r_loss: 0.098| p_loss: 0.155| v_loss: 0.032| per_loss: 0.485 | a_loss: 0.573
Train: Epoch [789/3000], Step [120/158]| g_loss: 0.767| d_loss: 0.617| gp_loss: 0.052| r_loss: 0.098| p_loss: 0.155| v_loss: 0.030| per_loss: 0.461 | a_loss: 0.515
Train: Epoch [789/3000], Step [150/158]| g_loss: 0.803| d_loss: 0.536| gp_loss: 0.054| r_loss: 0.098| p_loss: 0.155| v_loss: 0.031| per_loss: 0.498 | a_loss: 0.547
Train: Epoch [790/3000], Step [30/158]| g_loss: 0.844| d_loss: 0.668| gp_loss: 0.183| r_loss: 0.102| p_loss: 0.160| v_loss: 0.031| per_loss: 0.463 | a_loss: 0.584
Train: Epoch [790/3000], Step [60/158]| g_loss: 0.804| d_loss: 0.653| gp_loss: 0.049| r_loss: 0.106| p_loss: 0.161| v_loss: 0.031| per_loss: 0.481 | a_loss: 0.538
Train: Epoch [790/3000], Step [90/158]| g_loss: 0.725| d_loss: 0.651| gp_loss: 0.051| r_loss: 0.095| p_loss: 0.152| v_loss: 0.030| per_loss: 0.470 | a_loss: 0.477
Train: Epoch [790/3000], Step [120/158]| g_loss: 0.833| d_loss: 0.545| gp_loss: 0.053| r_loss: 0.094| p_loss: 0.153| v_loss: 0.032| per_loss: 0.469 | a_loss: 0.583
Train: Epoch [790/3000], Step [150/158]| g_loss: 0.803| d_loss: 0.557| gp_loss: 0.055| r_loss: 0.097| p_loss: 0.156| v_loss: 0.032| per_loss: 0.518 | a_loss: 0.544
Train: Epoch [791/3000], Step [30/158]| g_loss: 0.833| d_loss: 0.706| gp_loss: 0.189| r_loss: 0.095| p_loss: 0.159| v_loss: 0.031| per_loss: 0.560 | a_loss: 0.571
Train: Epoch [791/3000], Step [60/158]| g_loss: 0.835| d_loss: 0.568| gp_loss: 0.049| r_loss: 0.100| p_loss: 0.159| v_loss: 0.032| per_loss: 0.556 | a_loss: 0.568
Train: Epoch [791/3000], Step [90/158]| g_loss: 0.794| d_loss: 0.654| gp_loss: 0.050| r_loss: 0.106| p_loss: 0.167| v_loss: 0.031| per_loss: 0.517 | a_loss: 0.522
Train: Epoch [791/3000], Step [120/158]| g_loss: 0.742| d_loss: 0.664| gp_loss: 0.049| r_loss: 0.102| p_loss: 0.170| v_loss: 0.031| per_loss: 0.506 | a_loss: 0.473
Train: Epoch [791/3000], Step [150/158]| g_loss: 0.814| d_loss: 0.535| gp_loss: 0.052| r_loss: 0.099| p_loss: 0.165| v_loss: 0.031| per_loss: 0.437 | a_loss: 0.557
Train: Epoch [792/3000], Step [30/158]| g_loss: 0.833| d_loss: 0.628| gp_loss: 0.127| r_loss: 0.102| p_loss: 0.163| v_loss: 0.032| per_loss: 0.506 | a_loss: 0.567
Train: Epoch [792/3000], Step [60/158]| g_loss: 0.836| d_loss: 0.603| gp_loss: 0.049| r_loss: 0.098| p_loss: 0.168| v_loss: 0.032| per_loss: 0.504 | a_loss: 0.571
Train: Epoch [792/3000], Step [90/158]| g_loss: 0.800| d_loss: 0.603| gp_loss: 0.050| r_loss: 0.100| p_loss: 0.167| v_loss: 0.032| per_loss: 0.498 | a_loss: 0.535
Train: Epoch [792/3000], Step [120/158]| g_loss: 0.834| d_loss: 0.588| gp_loss: 0.051| r_loss: 0.100| p_loss: 0.169| v_loss: 0.033| per_loss: 0.529 | a_loss: 0.564
Train: Epoch [792/3000], Step [150/158]| g_loss: 0.809| d_loss: 0.603| gp_loss: 0.054| r_loss: 0.100| p_loss: 0.165| v_loss: 0.032| per_loss: 0.447 | a_loss: 0.549
Train: Epoch [793/3000], Step [30/158]| g_loss: 0.791| d_loss: 0.736| gp_loss: 0.163| r_loss: 0.104| p_loss: 0.173| v_loss: 0.031| per_loss: 0.525 | a_loss: 0.517
Train: Epoch [793/3000], Step [60/158]| g_loss: 0.820| d_loss: 0.629| gp_loss: 0.050| r_loss: 0.106| p_loss: 0.179| v_loss: 0.031| per_loss: 0.525 | a_loss: 0.540
Train: Epoch [793/3000], Step [90/158]| g_loss: 0.865| d_loss: 0.488| gp_loss: 0.051| r_loss: 0.104| p_loss: 0.168| v_loss: 0.032| per_loss: 0.513 | a_loss: 0.593
Train: Epoch [793/3000], Step [120/158]| g_loss: 0.811| d_loss: 0.661| gp_loss: 0.048| r_loss: 0.102| p_loss: 0.170| v_loss: 0.031| per_loss: 0.514 | a_loss: 0.542
Train: Epoch [793/3000], Step [150/158]| g_loss: 0.832| d_loss: 0.564| gp_loss: 0.053| r_loss: 0.102| p_loss: 0.165| v_loss: 0.032| per_loss: 0.461 | a_loss: 0.569
Train: Epoch [794/3000], Step [30/158]| g_loss: 0.780| d_loss: 0.677| gp_loss: 0.127| r_loss: 0.107| p_loss: 0.170| v_loss: 0.032| per_loss: 0.489 | a_loss: 0.507
Train: Epoch [794/3000], Step [60/158]| g_loss: 0.807| d_loss: 0.570| gp_loss: 0.052| r_loss: 0.102| p_loss: 0.164| v_loss: 0.032| per_loss: 0.498 | a_loss: 0.541
Train: Epoch [794/3000], Step [90/158]| g_loss: 0.748| d_loss: 0.648| gp_loss: 0.050| r_loss: 0.104| p_loss: 0.167| v_loss: 0.031| per_loss: 0.495 | a_loss: 0.480
Train: Epoch [794/3000], Step [120/158]| g_loss: 0.897| d_loss: 0.477| gp_loss: 0.053| r_loss: 0.101| p_loss: 0.164| v_loss: 0.030| per_loss: 0.522 | a_loss: 0.632
Train: Epoch [794/3000], Step [150/158]| g_loss: 0.792| d_loss: 0.612| gp_loss: 0.053| r_loss: 0.101| p_loss: 0.167| v_loss: 0.031| per_loss: 0.507 | a_loss: 0.526
Train: Epoch [795/3000], Step [30/158]| g_loss: 0.809| d_loss: 0.695| gp_loss: 0.167| r_loss: 0.101| p_loss: 0.170| v_loss: 0.031| per_loss: 0.494 | a_loss: 0.543
Train: Epoch [795/3000], Step [60/158]| g_loss: 0.815| d_loss: 0.540| gp_loss: 0.050| r_loss: 0.097| p_loss: 0.154| v_loss: 0.030| per_loss: 0.492 | a_loss: 0.562
Train: Epoch [795/3000], Step [90/158]| g_loss: 0.840| d_loss: 0.527| gp_loss: 0.049| r_loss: 0.102| p_loss: 0.164| v_loss: 0.032| per_loss: 0.503 | a_loss: 0.573
Train: Epoch [795/3000], Step [120/158]| g_loss: 0.854| d_loss: 0.593| gp_loss: 0.052| r_loss: 0.104| p_loss: 0.165| v_loss: 0.031| per_loss: 0.461 | a_loss: 0.590
Train: Epoch [795/3000], Step [150/158]| g_loss: 0.737| d_loss: 0.632| gp_loss: 0.054| r_loss: 0.102| p_loss: 0.166| v_loss: 0.031| per_loss: 0.507 | a_loss: 0.470
Train: Epoch [796/3000], Step [30/158]| g_loss: 0.743| d_loss: 0.708| gp_loss: 0.097| r_loss: 0.100| p_loss: 0.164| v_loss: 0.031| per_loss: 0.501 | a_loss: 0.480
Train: Epoch [796/3000], Step [60/158]| g_loss: 0.815| d_loss: 0.604| gp_loss: 0.052| r_loss: 0.103| p_loss: 0.164| v_loss: 0.032| per_loss: 0.501 | a_loss: 0.548
Train: Epoch [796/3000], Step [90/158]| g_loss: 0.791| d_loss: 0.613| gp_loss: 0.053| r_loss: 0.102| p_loss: 0.171| v_loss: 0.032| per_loss: 0.474 | a_loss: 0.525
Train: Epoch [796/3000], Step [120/158]| g_loss: 0.795| d_loss: 0.594| gp_loss: 0.051| r_loss: 0.102| p_loss: 0.167| v_loss: 0.031| per_loss: 0.486 | a_loss: 0.530
Train: Epoch [796/3000], Step [150/158]| g_loss: 0.775| d_loss: 0.650| gp_loss: 0.054| r_loss: 0.099| p_loss: 0.153| v_loss: 0.031| per_loss: 0.485 | a_loss: 0.520
Train: Epoch [797/3000], Step [30/158]| g_loss: 0.808| d_loss: 0.646| gp_loss: 0.142| r_loss: 0.099| p_loss: 0.158| v_loss: 0.032| per_loss: 0.508 | a_loss: 0.547
Train: Epoch [797/3000], Step [60/158]| g_loss: 0.802| d_loss: 0.607| gp_loss: 0.047| r_loss: 0.100| p_loss: 0.158| v_loss: 0.032| per_loss: 0.513 | a_loss: 0.540
Train: Epoch [797/3000], Step [90/158]| g_loss: 0.821| d_loss: 0.612| gp_loss: 0.051| r_loss: 0.102| p_loss: 0.166| v_loss: 0.031| per_loss: 0.473 | a_loss: 0.558
Train: Epoch [797/3000], Step [120/158]| g_loss: 0.761| d_loss: 0.589| gp_loss: 0.054| r_loss: 0.098| p_loss: 0.156| v_loss: 0.030| per_loss: 0.520 | a_loss: 0.502
Train: Epoch [797/3000], Step [150/158]| g_loss: 0.801| d_loss: 0.586| gp_loss: 0.058| r_loss: 0.098| p_loss: 0.161| v_loss: 0.032| per_loss: 0.567 | a_loss: 0.535
Train: Epoch [798/3000], Step [30/158]| g_loss: 0.839| d_loss: 0.624| gp_loss: 0.107| r_loss: 0.099| p_loss: 0.156| v_loss: 0.032| per_loss: 0.517 | a_loss: 0.578
Train: Epoch [798/3000], Step [60/158]| g_loss: 0.824| d_loss: 0.611| gp_loss: 0.051| r_loss: 0.095| p_loss: 0.160| v_loss: 0.030| per_loss: 0.525 | a_loss: 0.567
Train: Epoch [798/3000], Step [90/158]| g_loss: 0.859| d_loss: 0.482| gp_loss: 0.057| r_loss: 0.099| p_loss: 0.155| v_loss: 0.032| per_loss: 0.521 | a_loss: 0.598
Train: Epoch [798/3000], Step [120/158]| g_loss: 0.816| d_loss: 0.623| gp_loss: 0.052| r_loss: 0.101| p_loss: 0.162| v_loss: 0.031| per_loss: 0.533 | a_loss: 0.549
Train: Epoch [798/3000], Step [150/158]| g_loss: 0.839| d_loss: 0.553| gp_loss: 0.056| r_loss: 0.105| p_loss: 0.164| v_loss: 0.032| per_loss: 0.505 | a_loss: 0.570
Train: Epoch [799/3000], Step [30/158]| g_loss: 0.858| d_loss: 0.610| gp_loss: 0.141| r_loss: 0.099| p_loss: 0.161| v_loss: 0.032| per_loss: 0.503 | a_loss: 0.597
Train: Epoch [799/3000], Step [60/158]| g_loss: 0.825| d_loss: 0.604| gp_loss: 0.054| r_loss: 0.106| p_loss: 0.166| v_loss: 0.031| per_loss: 0.517 | a_loss: 0.553
Train: Epoch [799/3000], Step [90/158]| g_loss: 0.833| d_loss: 0.556| gp_loss: 0.054| r_loss: 0.098| p_loss: 0.163| v_loss: 0.032| per_loss: 0.484 | a_loss: 0.574
Train: Epoch [799/3000], Step [120/158]| g_loss: 0.787| d_loss: 0.587| gp_loss: 0.057| r_loss: 0.103| p_loss: 0.165| v_loss: 0.032| per_loss: 0.487 | a_loss: 0.521
Train: Epoch [799/3000], Step [150/158]| g_loss: 0.776| d_loss: 0.664| gp_loss: 0.054| r_loss: 0.101| p_loss: 0.170| v_loss: 0.033| per_loss: 0.531 | a_loss: 0.504
Train: Epoch [800/3000], Step [30/158]| g_loss: 0.797| d_loss: 0.646| gp_loss: 0.120| r_loss: 0.102| p_loss: 0.161| v_loss: 0.034| per_loss: 0.502 | a_loss: 0.530
Train: Epoch [800/3000], Step [60/158]| g_loss: 0.832| d_loss: 0.642| gp_loss: 0.057| r_loss: 0.100| p_loss: 0.167| v_loss: 0.034| per_loss: 0.556 | a_loss: 0.559
Train: Epoch [800/3000], Step [90/158]| g_loss: 0.758| d_loss: 0.594| gp_loss: 0.057| r_loss: 0.099| p_loss: 0.163| v_loss: 0.033| per_loss: 0.481 | a_loss: 0.497
Train: Epoch [800/3000], Step [120/158]| g_loss: 0.804| d_loss: 0.589| gp_loss: 0.060| r_loss: 0.101| p_loss: 0.163| v_loss: 0.032| per_loss: 0.521 | a_loss: 0.537
Train: Epoch [800/3000], Step [150/158]| g_loss: 0.827| d_loss: 0.492| gp_loss: 0.061| r_loss: 0.094| p_loss: 0.151| v_loss: 0.031| per_loss: 0.537 | a_loss: 0.572
Test: Epoch [800/3000]| g_loss: 0.659| r_loss: 0.404| p_loss: 0.301| v_loss: 0.026
Train: Epoch [801/3000], Step [30/158]| g_loss: 0.829| d_loss: 0.605| gp_loss: 0.052| r_loss: 0.102| p_loss: 0.162| v_loss: 0.032| per_loss: 0.508 | a_loss: 0.563
Train: Epoch [801/3000], Step [60/158]| g_loss: 0.852| d_loss: 0.538| gp_loss: 0.052| r_loss: 0.097| p_loss: 0.156| v_loss: 0.031| per_loss: 0.498 | a_loss: 0.597
Train: Epoch [801/3000], Step [90/158]| g_loss: 0.794| d_loss: 0.652| gp_loss: 0.054| r_loss: 0.096| p_loss: 0.163| v_loss: 0.032| per_loss: 0.479 | a_loss: 0.536
Train: Epoch [801/3000], Step [120/158]| g_loss: 0.763| d_loss: 0.594| gp_loss: 0.054| r_loss: 0.102| p_loss: 0.160| v_loss: 0.033| per_loss: 0.462 | a_loss: 0.502
Train: Epoch [801/3000], Step [150/158]| g_loss: 0.832| d_loss: 0.543| gp_loss: 0.059| r_loss: 0.094| p_loss: 0.152| v_loss: 0.032| per_loss: 0.493 | a_loss: 0.580
Train: Epoch [802/3000], Step [30/158]| g_loss: 0.798| d_loss: 0.731| gp_loss: 0.158| r_loss: 0.104| p_loss: 0.167| v_loss: 0.032| per_loss: 0.486 | a_loss: 0.530
Train: Epoch [802/3000], Step [60/158]| g_loss: 0.815| d_loss: 0.646| gp_loss: 0.055| r_loss: 0.096| p_loss: 0.166| v_loss: 0.030| per_loss: 0.494 | a_loss: 0.556
Train: Epoch [802/3000], Step [90/158]| g_loss: 0.812| d_loss: 0.545| gp_loss: 0.053| r_loss: 0.099| p_loss: 0.161| v_loss: 0.032| per_loss: 0.503 | a_loss: 0.550
Train: Epoch [802/3000], Step [120/158]| g_loss: 0.805| d_loss: 0.615| gp_loss: 0.054| r_loss: 0.098| p_loss: 0.165| v_loss: 0.031| per_loss: 0.484 | a_loss: 0.546
Train: Epoch [802/3000], Step [150/158]| g_loss: 0.866| d_loss: 0.542| gp_loss: 0.055| r_loss: 0.103| p_loss: 0.161| v_loss: 0.032| per_loss: 0.501 | a_loss: 0.601
Train: Epoch [803/3000], Step [30/158]| g_loss: 0.827| d_loss: 0.657| gp_loss: 0.147| r_loss: 0.099| p_loss: 0.162| v_loss: 0.032| per_loss: 0.509 | a_loss: 0.564
Train: Epoch [803/3000], Step [60/158]| g_loss: 0.854| d_loss: 0.590| gp_loss: 0.050| r_loss: 0.096| p_loss: 0.154| v_loss: 0.032| per_loss: 0.497 | a_loss: 0.600
Train: Epoch [803/3000], Step [90/158]| g_loss: 0.845| d_loss: 0.501| gp_loss: 0.049| r_loss: 0.099| p_loss: 0.154| v_loss: 0.032| per_loss: 0.453 | a_loss: 0.592
Train: Epoch [803/3000], Step [120/158]| g_loss: 0.766| d_loss: 0.688| gp_loss: 0.052| r_loss: 0.096| p_loss: 0.155| v_loss: 0.031| per_loss: 0.506 | a_loss: 0.511
Train: Epoch [803/3000], Step [150/158]| g_loss: 0.761| d_loss: 0.581| gp_loss: 0.054| r_loss: 0.098| p_loss: 0.156| v_loss: 0.031| per_loss: 0.479 | a_loss: 0.506
Train: Epoch [804/3000], Step [30/158]| g_loss: 0.858| d_loss: 0.596| gp_loss: 0.117| r_loss: 0.099| p_loss: 0.155| v_loss: 0.031| per_loss: 0.492 | a_loss: 0.602
Train: Epoch [804/3000], Step [60/158]| g_loss: 0.826| d_loss: 0.570| gp_loss: 0.050| r_loss: 0.105| p_loss: 0.163| v_loss: 0.030| per_loss: 0.465 | a_loss: 0.563
Train: Epoch [804/3000], Step [90/158]| g_loss: 0.801| d_loss: 0.605| gp_loss: 0.051| r_loss: 0.098| p_loss: 0.156| v_loss: 0.031| per_loss: 0.465 | a_loss: 0.548
Train: Epoch [804/3000], Step [120/158]| g_loss: 0.732| d_loss: 0.702| gp_loss: 0.053| r_loss: 0.100| p_loss: 0.160| v_loss: 0.031| per_loss: 0.485 | a_loss: 0.473
Train: Epoch [804/3000], Step [150/158]| g_loss: 0.846| d_loss: 0.515| gp_loss: 0.055| r_loss: 0.095| p_loss: 0.157| v_loss: 0.031| per_loss: 0.459 | a_loss: 0.595
Train: Epoch [805/3000], Step [30/158]| g_loss: 0.829| d_loss: 0.713| gp_loss: 0.204| r_loss: 0.099| p_loss: 0.162| v_loss: 0.032| per_loss: 0.515 | a_loss: 0.565
Train: Epoch [805/3000], Step [60/158]| g_loss: 0.780| d_loss: 0.599| gp_loss: 0.050| r_loss: 0.096| p_loss: 0.156| v_loss: 0.030| per_loss: 0.491 | a_loss: 0.527
Train: Epoch [805/3000], Step [90/158]| g_loss: 0.822| d_loss: 0.579| gp_loss: 0.051| r_loss: 0.091| p_loss: 0.146| v_loss: 0.029| per_loss: 0.481 | a_loss: 0.581
Train: Epoch [805/3000], Step [120/158]| g_loss: 0.783| d_loss: 0.612| gp_loss: 0.053| r_loss: 0.099| p_loss: 0.147| v_loss: 0.030| per_loss: 0.494 | a_loss: 0.531
Train: Epoch [805/3000], Step [150/158]| g_loss: 0.802| d_loss: 0.586| gp_loss: 0.052| r_loss: 0.096| p_loss: 0.154| v_loss: 0.029| per_loss: 0.470 | a_loss: 0.552
Train: Epoch [806/3000], Step [30/158]| g_loss: 0.827| d_loss: 0.644| gp_loss: 0.147| r_loss: 0.097| p_loss: 0.153| v_loss: 0.031| per_loss: 0.487 | a_loss: 0.574
Train: Epoch [806/3000], Step [60/158]| g_loss: 0.777| d_loss: 0.594| gp_loss: 0.047| r_loss: 0.095| p_loss: 0.153| v_loss: 0.031| per_loss: 0.501 | a_loss: 0.524
Train: Epoch [806/3000], Step [90/158]| g_loss: 0.806| d_loss: 0.611| gp_loss: 0.050| r_loss: 0.099| p_loss: 0.155| v_loss: 0.030| per_loss: 0.490 | a_loss: 0.550
Train: Epoch [806/3000], Step [120/158]| g_loss: 0.791| d_loss: 0.548| gp_loss: 0.053| r_loss: 0.100| p_loss: 0.158| v_loss: 0.032| per_loss: 0.470 | a_loss: 0.533
Train: Epoch [806/3000], Step [150/158]| g_loss: 0.820| d_loss: 0.577| gp_loss: 0.053| r_loss: 0.096| p_loss: 0.155| v_loss: 0.029| per_loss: 0.497 | a_loss: 0.568
Train: Epoch [807/3000], Step [30/158]| g_loss: 0.829| d_loss: 0.672| gp_loss: 0.178| r_loss: 0.096| p_loss: 0.152| v_loss: 0.031| per_loss: 0.493 | a_loss: 0.578
Train: Epoch [807/3000], Step [60/158]| g_loss: 0.784| d_loss: 0.610| gp_loss: 0.049| r_loss: 0.098| p_loss: 0.153| v_loss: 0.030| per_loss: 0.492 | a_loss: 0.530
Train: Epoch [807/3000], Step [90/158]| g_loss: 0.763| d_loss: 0.656| gp_loss: 0.048| r_loss: 0.095| p_loss: 0.151| v_loss: 0.030| per_loss: 0.474 | a_loss: 0.516
Train: Epoch [807/3000], Step [120/158]| g_loss: 0.833| d_loss: 0.561| gp_loss: 0.050| r_loss: 0.099| p_loss: 0.157| v_loss: 0.031| per_loss: 0.475 | a_loss: 0.576
Train: Epoch [807/3000], Step [150/158]| g_loss: 0.798| d_loss: 0.552| gp_loss: 0.051| r_loss: 0.095| p_loss: 0.150| v_loss: 0.031| per_loss: 0.482 | a_loss: 0.549
Train: Epoch [808/3000], Step [30/158]| g_loss: 0.776| d_loss: 0.686| gp_loss: 0.123| r_loss: 0.093| p_loss: 0.151| v_loss: 0.029| per_loss: 0.483 | a_loss: 0.531
Train: Epoch [808/3000], Step [60/158]| g_loss: 0.777| d_loss: 0.628| gp_loss: 0.051| r_loss: 0.097| p_loss: 0.155| v_loss: 0.029| per_loss: 0.457 | a_loss: 0.528
Train: Epoch [808/3000], Step [90/158]| g_loss: 0.745| d_loss: 0.615| gp_loss: 0.049| r_loss: 0.098| p_loss: 0.157| v_loss: 0.030| per_loss: 0.471 | a_loss: 0.492
Train: Epoch [808/3000], Step [120/158]| g_loss: 0.794| d_loss: 0.559| gp_loss: 0.051| r_loss: 0.100| p_loss: 0.158| v_loss: 0.030| per_loss: 0.530 | a_loss: 0.533
Train: Epoch [808/3000], Step [150/158]| g_loss: 0.817| d_loss: 0.581| gp_loss: 0.050| r_loss: 0.100| p_loss: 0.163| v_loss: 0.031| per_loss: 0.488 | a_loss: 0.556
Train: Epoch [809/3000], Step [30/158]| g_loss: 0.812| d_loss: 0.628| gp_loss: 0.144| r_loss: 0.096| p_loss: 0.160| v_loss: 0.030| per_loss: 0.470 | a_loss: 0.559
Train: Epoch [809/3000], Step [60/158]| g_loss: 0.822| d_loss: 0.558| gp_loss: 0.048| r_loss: 0.093| p_loss: 0.154| v_loss: 0.030| per_loss: 0.485 | a_loss: 0.573
Train: Epoch [809/3000], Step [90/158]| g_loss: 0.744| d_loss: 0.656| gp_loss: 0.047| r_loss: 0.100| p_loss: 0.165| v_loss: 0.031| per_loss: 0.477 | a_loss: 0.482
Train: Epoch [809/3000], Step [120/158]| g_loss: 0.786| d_loss: 0.631| gp_loss: 0.050| r_loss: 0.101| p_loss: 0.163| v_loss: 0.031| per_loss: 0.482 | a_loss: 0.524
Train: Epoch [809/3000], Step [150/158]| g_loss: 0.748| d_loss: 0.644| gp_loss: 0.049| r_loss: 0.101| p_loss: 0.157| v_loss: 0.030| per_loss: 0.447 | a_loss: 0.493
Train: Epoch [810/3000], Step [30/158]| g_loss: 0.782| d_loss: 0.681| gp_loss: 0.147| r_loss: 0.102| p_loss: 0.163| v_loss: 0.032| per_loss: 0.469 | a_loss: 0.520
Train: Epoch [810/3000], Step [60/158]| g_loss: 0.720| d_loss: 0.711| gp_loss: 0.048| r_loss: 0.096| p_loss: 0.147| v_loss: 0.031| per_loss: 0.495 | a_loss: 0.471
Train: Epoch [810/3000], Step [90/158]| g_loss: 0.810| d_loss: 0.554| gp_loss: 0.052| r_loss: 0.098| p_loss: 0.154| v_loss: 0.031| per_loss: 0.431 | a_loss: 0.561
Train: Epoch [810/3000], Step [120/158]| g_loss: 0.807| d_loss: 0.584| gp_loss: 0.054| r_loss: 0.097| p_loss: 0.161| v_loss: 0.030| per_loss: 0.446 | a_loss: 0.554
Train: Epoch [810/3000], Step [150/158]| g_loss: 0.808| d_loss: 0.551| gp_loss: 0.052| r_loss: 0.094| p_loss: 0.154| v_loss: 0.031| per_loss: 0.496 | a_loss: 0.556
Train: Epoch [811/3000], Step [30/158]| g_loss: 0.855| d_loss: 0.630| gp_loss: 0.177| r_loss: 0.095| p_loss: 0.150| v_loss: 0.033| per_loss: 0.463 | a_loss: 0.606
Train: Epoch [811/3000], Step [60/158]| g_loss: 0.742| d_loss: 0.639| gp_loss: 0.049| r_loss: 0.096| p_loss: 0.155| v_loss: 0.031| per_loss: 0.465 | a_loss: 0.491
Train: Epoch [811/3000], Step [90/158]| g_loss: 0.747| d_loss: 0.694| gp_loss: 0.048| r_loss: 0.097| p_loss: 0.161| v_loss: 0.031| per_loss: 0.467 | a_loss: 0.491
Train: Epoch [811/3000], Step [120/158]| g_loss: 0.798| d_loss: 0.575| gp_loss: 0.055| r_loss: 0.098| p_loss: 0.151| v_loss: 0.030| per_loss: 0.467 | a_loss: 0.549
Train: Epoch [811/3000], Step [150/158]| g_loss: 0.810| d_loss: 0.487| gp_loss: 0.055| r_loss: 0.095| p_loss: 0.148| v_loss: 0.029| per_loss: 0.455 | a_loss: 0.566
Train: Epoch [812/3000], Step [30/158]| g_loss: 0.845| d_loss: 0.639| gp_loss: 0.129| r_loss: 0.098| p_loss: 0.154| v_loss: 0.031| per_loss: 0.506 | a_loss: 0.588
Train: Epoch [812/3000], Step [60/158]| g_loss: 0.806| d_loss: 0.625| gp_loss: 0.049| r_loss: 0.100| p_loss: 0.158| v_loss: 0.031| per_loss: 0.492 | a_loss: 0.547
Train: Epoch [812/3000], Step [90/158]| g_loss: 0.747| d_loss: 0.652| gp_loss: 0.052| r_loss: 0.101| p_loss: 0.161| v_loss: 0.033| per_loss: 0.485 | a_loss: 0.484
Train: Epoch [812/3000], Step [120/158]| g_loss: 0.826| d_loss: 0.554| gp_loss: 0.050| r_loss: 0.097| p_loss: 0.157| v_loss: 0.032| per_loss: 0.480 | a_loss: 0.571
Train: Epoch [812/3000], Step [150/158]| g_loss: 0.813| d_loss: 0.575| gp_loss: 0.049| r_loss: 0.093| p_loss: 0.152| v_loss: 0.029| per_loss: 0.481 | a_loss: 0.566
Train: Epoch [813/3000], Step [30/158]| g_loss: 0.753| d_loss: 0.682| gp_loss: 0.100| r_loss: 0.103| p_loss: 0.156| v_loss: 0.029| per_loss: 0.477 | a_loss: 0.495
Train: Epoch [813/3000], Step [60/158]| g_loss: 0.782| d_loss: 0.634| gp_loss: 0.049| r_loss: 0.101| p_loss: 0.164| v_loss: 0.030| per_loss: 0.490 | a_loss: 0.521
Train: Epoch [813/3000], Step [90/158]| g_loss: 0.786| d_loss: 0.575| gp_loss: 0.054| r_loss: 0.094| p_loss: 0.157| v_loss: 0.031| per_loss: 0.455 | a_loss: 0.538
Train: Epoch [813/3000], Step [120/158]| g_loss: 0.819| d_loss: 0.517| gp_loss: 0.048| r_loss: 0.097| p_loss: 0.153| v_loss: 0.031| per_loss: 0.485 | a_loss: 0.566
Train: Epoch [813/3000], Step [150/158]| g_loss: 0.820| d_loss: 0.608| gp_loss: 0.050| r_loss: 0.099| p_loss: 0.154| v_loss: 0.031| per_loss: 0.489 | a_loss: 0.565
Train: Epoch [814/3000], Step [30/158]| g_loss: 0.734| d_loss: 0.717| gp_loss: 0.121| r_loss: 0.099| p_loss: 0.154| v_loss: 0.031| per_loss: 0.491 | a_loss: 0.477
Train: Epoch [814/3000], Step [60/158]| g_loss: 0.805| d_loss: 0.644| gp_loss: 0.049| r_loss: 0.093| p_loss: 0.149| v_loss: 0.029| per_loss: 0.466 | a_loss: 0.563
Train: Epoch [814/3000], Step [90/158]| g_loss: 0.774| d_loss: 0.492| gp_loss: 0.052| r_loss: 0.095| p_loss: 0.151| v_loss: 0.030| per_loss: 0.525 | a_loss: 0.521
Train: Epoch [814/3000], Step [120/158]| g_loss: 0.887| d_loss: 0.508| gp_loss: 0.053| r_loss: 0.101| p_loss: 0.161| v_loss: 0.032| per_loss: 0.480 | a_loss: 0.626
Train: Epoch [814/3000], Step [150/158]| g_loss: 0.781| d_loss: 0.659| gp_loss: 0.054| r_loss: 0.099| p_loss: 0.160| v_loss: 0.031| per_loss: 0.480 | a_loss: 0.522
Train: Epoch [815/3000], Step [30/158]| g_loss: 0.756| d_loss: 0.781| gp_loss: 0.149| r_loss: 0.096| p_loss: 0.153| v_loss: 0.030| per_loss: 0.468 | a_loss: 0.506
Train: Epoch [815/3000], Step [60/158]| g_loss: 0.834| d_loss: 0.502| gp_loss: 0.049| r_loss: 0.095| p_loss: 0.155| v_loss: 0.032| per_loss: 0.475 | a_loss: 0.582
Train: Epoch [815/3000], Step [90/158]| g_loss: 0.766| d_loss: 0.617| gp_loss: 0.052| r_loss: 0.099| p_loss: 0.161| v_loss: 0.031| per_loss: 0.501 | a_loss: 0.506
Train: Epoch [815/3000], Step [120/158]| g_loss: 0.781| d_loss: 0.644| gp_loss: 0.050| r_loss: 0.095| p_loss: 0.155| v_loss: 0.029| per_loss: 0.461 | a_loss: 0.533
Train: Epoch [815/3000], Step [150/158]| g_loss: 0.773| d_loss: 0.581| gp_loss: 0.051| r_loss: 0.096| p_loss: 0.157| v_loss: 0.030| per_loss: 0.494 | a_loss: 0.519
Train: Epoch [816/3000], Step [30/158]| g_loss: 0.775| d_loss: 0.730| gp_loss: 0.121| r_loss: 0.096| p_loss: 0.159| v_loss: 0.029| per_loss: 0.448 | a_loss: 0.525
Train: Epoch [816/3000], Step [60/158]| g_loss: 0.761| d_loss: 0.600| gp_loss: 0.050| r_loss: 0.098| p_loss: 0.152| v_loss: 0.030| per_loss: 0.472 | a_loss: 0.511
Train: Epoch [816/3000], Step [90/158]| g_loss: 0.774| d_loss: 0.612| gp_loss: 0.053| r_loss: 0.099| p_loss: 0.160| v_loss: 0.031| per_loss: 0.481 | a_loss: 0.516
Train: Epoch [816/3000], Step [120/158]| g_loss: 0.838| d_loss: 0.512| gp_loss: 0.056| r_loss: 0.098| p_loss: 0.161| v_loss: 0.030| per_loss: 0.442 | a_loss: 0.585
Train: Epoch [816/3000], Step [150/158]| g_loss: 0.791| d_loss: 0.582| gp_loss: 0.055| r_loss: 0.095| p_loss: 0.148| v_loss: 0.030| per_loss: 0.479 | a_loss: 0.544
Train: Epoch [817/3000], Step [30/158]| g_loss: 0.831| d_loss: 0.720| gp_loss: 0.171| r_loss: 0.097| p_loss: 0.156| v_loss: 0.030| per_loss: 0.510 | a_loss: 0.575
Train: Epoch [817/3000], Step [60/158]| g_loss: 0.700| d_loss: 0.626| gp_loss: 0.049| r_loss: 0.093| p_loss: 0.149| v_loss: 0.029| per_loss: 0.472 | a_loss: 0.455
Train: Epoch [817/3000], Step [90/158]| g_loss: 0.883| d_loss: 0.566| gp_loss: 0.051| r_loss: 0.094| p_loss: 0.154| v_loss: 0.030| per_loss: 0.454 | a_loss: 0.637
Train: Epoch [817/3000], Step [120/158]| g_loss: 0.740| d_loss: 0.624| gp_loss: 0.050| r_loss: 0.093| p_loss: 0.152| v_loss: 0.030| per_loss: 0.476 | a_loss: 0.493
Train: Epoch [817/3000], Step [150/158]| g_loss: 0.732| d_loss: 0.622| gp_loss: 0.049| r_loss: 0.094| p_loss: 0.152| v_loss: 0.031| per_loss: 0.463 | a_loss: 0.485
Train: Epoch [818/3000], Step [30/158]| g_loss: 0.814| d_loss: 0.684| gp_loss: 0.131| r_loss: 0.097| p_loss: 0.153| v_loss: 0.031| per_loss: 0.431 | a_loss: 0.567
Train: Epoch [818/3000], Step [60/158]| g_loss: 0.729| d_loss: 0.674| gp_loss: 0.045| r_loss: 0.094| p_loss: 0.151| v_loss: 0.029| per_loss: 0.455 | a_loss: 0.485
Train: Epoch [818/3000], Step [90/158]| g_loss: 0.796| d_loss: 0.570| gp_loss: 0.052| r_loss: 0.096| p_loss: 0.156| v_loss: 0.030| per_loss: 0.487 | a_loss: 0.543
Train: Epoch [818/3000], Step [120/158]| g_loss: 0.774| d_loss: 0.568| gp_loss: 0.055| r_loss: 0.095| p_loss: 0.153| v_loss: 0.030| per_loss: 0.454 | a_loss: 0.527
Train: Epoch [818/3000], Step [150/158]| g_loss: 0.839| d_loss: 0.588| gp_loss: 0.052| r_loss: 0.097| p_loss: 0.154| v_loss: 0.031| per_loss: 0.471 | a_loss: 0.587
Train: Epoch [819/3000], Step [30/158]| g_loss: 0.807| d_loss: 0.696| gp_loss: 0.182| r_loss: 0.098| p_loss: 0.163| v_loss: 0.031| per_loss: 0.486 | a_loss: 0.548
Train: Epoch [819/3000], Step [60/158]| g_loss: 0.813| d_loss: 0.597| gp_loss: 0.050| r_loss: 0.094| p_loss: 0.153| v_loss: 0.031| per_loss: 0.484 | a_loss: 0.563
Train: Epoch [819/3000], Step [90/158]| g_loss: 0.758| d_loss: 0.566| gp_loss: 0.051| r_loss: 0.092| p_loss: 0.146| v_loss: 0.031| per_loss: 0.429 | a_loss: 0.519
Train: Epoch [819/3000], Step [120/158]| g_loss: 0.810| d_loss: 0.595| gp_loss: 0.051| r_loss: 0.094| p_loss: 0.150| v_loss: 0.030| per_loss: 0.473 | a_loss: 0.564
Train: Epoch [819/3000], Step [150/158]| g_loss: 0.765| d_loss: 0.630| gp_loss: 0.050| r_loss: 0.094| p_loss: 0.147| v_loss: 0.030| per_loss: 0.476 | a_loss: 0.520
Train: Epoch [820/3000], Step [30/158]| g_loss: 0.793| d_loss: 0.640| gp_loss: 0.134| r_loss: 0.093| p_loss: 0.144| v_loss: 0.030| per_loss: 0.470 | a_loss: 0.551
Train: Epoch [820/3000], Step [60/158]| g_loss: 0.754| d_loss: 0.636| gp_loss: 0.050| r_loss: 0.094| p_loss: 0.149| v_loss: 0.030| per_loss: 0.468 | a_loss: 0.508
Train: Epoch [820/3000], Step [90/158]| g_loss: 0.829| d_loss: 0.498| gp_loss: 0.051| r_loss: 0.095| p_loss: 0.150| v_loss: 0.030| per_loss: 0.462 | a_loss: 0.583
Train: Epoch [820/3000], Step [120/158]| g_loss: 0.872| d_loss: 0.486| gp_loss: 0.051| r_loss: 0.097| p_loss: 0.150| v_loss: 0.031| per_loss: 0.462 | a_loss: 0.623
Train: Epoch [820/3000], Step [150/158]| g_loss: 0.716| d_loss: 0.764| gp_loss: 0.051| r_loss: 0.096| p_loss: 0.156| v_loss: 0.029| per_loss: 0.460 | a_loss: 0.466
Train: Epoch [821/3000], Step [30/158]| g_loss: 0.772| d_loss: 0.660| gp_loss: 0.117| r_loss: 0.096| p_loss: 0.160| v_loss: 0.031| per_loss: 0.497 | a_loss: 0.515
Train: Epoch [821/3000], Step [60/158]| g_loss: 0.724| d_loss: 0.602| gp_loss: 0.054| r_loss: 0.093| p_loss: 0.150| v_loss: 0.030| per_loss: 0.466 | a_loss: 0.478
Train: Epoch [821/3000], Step [90/158]| g_loss: 0.776| d_loss: 0.687| gp_loss: 0.054| r_loss: 0.096| p_loss: 0.160| v_loss: 0.031| per_loss: 0.454 | a_loss: 0.523
Train: Epoch [821/3000], Step [120/158]| g_loss: 0.816| d_loss: 0.569| gp_loss: 0.056| r_loss: 0.100| p_loss: 0.161| v_loss: 0.031| per_loss: 0.493 | a_loss: 0.555
Train: Epoch [821/3000], Step [150/158]| g_loss: 0.830| d_loss: 0.575| gp_loss: 0.054| r_loss: 0.102| p_loss: 0.168| v_loss: 0.032| per_loss: 0.480 | a_loss: 0.565
Train: Epoch [822/3000], Step [30/158]| g_loss: 0.784| d_loss: 0.704| gp_loss: 0.104| r_loss: 0.100| p_loss: 0.165| v_loss: 0.032| per_loss: 0.471 | a_loss: 0.523
Train: Epoch [822/3000], Step [60/158]| g_loss: 0.824| d_loss: 0.606| gp_loss: 0.054| r_loss: 0.104| p_loss: 0.169| v_loss: 0.031| per_loss: 0.507 | a_loss: 0.555
Train: Epoch [822/3000], Step [90/158]| g_loss: 0.831| d_loss: 0.560| gp_loss: 0.052| r_loss: 0.102| p_loss: 0.169| v_loss: 0.031| per_loss: 0.528 | a_loss: 0.561
Train: Epoch [822/3000], Step [120/158]| g_loss: 0.829| d_loss: 0.618| gp_loss: 0.054| r_loss: 0.101| p_loss: 0.171| v_loss: 0.032| per_loss: 0.513 | a_loss: 0.560
Train: Epoch [822/3000], Step [150/158]| g_loss: 0.797| d_loss: 0.610| gp_loss: 0.053| r_loss: 0.095| p_loss: 0.154| v_loss: 0.031| per_loss: 0.477 | a_loss: 0.546
Train: Epoch [823/3000], Step [30/158]| g_loss: 0.781| d_loss: 0.700| gp_loss: 0.134| r_loss: 0.097| p_loss: 0.162| v_loss: 0.032| per_loss: 0.468 | a_loss: 0.525
Train: Epoch [823/3000], Step [60/158]| g_loss: 0.844| d_loss: 0.549| gp_loss: 0.049| r_loss: 0.094| p_loss: 0.154| v_loss: 0.031| per_loss: 0.500 | a_loss: 0.591
Train: Epoch [823/3000], Step [90/158]| g_loss: 0.781| d_loss: 0.598| gp_loss: 0.051| r_loss: 0.101| p_loss: 0.157| v_loss: 0.030| per_loss: 0.489 | a_loss: 0.523
Train: Epoch [823/3000], Step [120/158]| g_loss: 0.819| d_loss: 0.583| gp_loss: 0.052| r_loss: 0.097| p_loss: 0.156| v_loss: 0.032| per_loss: 0.441 | a_loss: 0.568
Train: Epoch [823/3000], Step [150/158]| g_loss: 0.772| d_loss: 0.570| gp_loss: 0.055| r_loss: 0.093| p_loss: 0.146| v_loss: 0.031| per_loss: 0.498 | a_loss: 0.525
Train: Epoch [824/3000], Step [30/158]| g_loss: 0.781| d_loss: 0.664| gp_loss: 0.112| r_loss: 0.093| p_loss: 0.156| v_loss: 0.031| per_loss: 0.456 | a_loss: 0.533
Train: Epoch [824/3000], Step [60/158]| g_loss: 0.758| d_loss: 0.624| gp_loss: 0.049| r_loss: 0.095| p_loss: 0.151| v_loss: 0.030| per_loss: 0.461 | a_loss: 0.511
Train: Epoch [824/3000], Step [90/158]| g_loss: 0.745| d_loss: 0.639| gp_loss: 0.052| r_loss: 0.094| p_loss: 0.150| v_loss: 0.032| per_loss: 0.482 | a_loss: 0.497
Train: Epoch [824/3000], Step [120/158]| g_loss: 0.838| d_loss: 0.541| gp_loss: 0.055| r_loss: 0.096| p_loss: 0.151| v_loss: 0.032| per_loss: 0.507 | a_loss: 0.584
Train: Epoch [824/3000], Step [150/158]| g_loss: 0.761| d_loss: 0.618| gp_loss: 0.054| r_loss: 0.094| p_loss: 0.153| v_loss: 0.030| per_loss: 0.479 | a_loss: 0.512
Train: Epoch [825/3000], Step [30/158]| g_loss: 0.795| d_loss: 0.685| gp_loss: 0.124| r_loss: 0.097| p_loss: 0.152| v_loss: 0.030| per_loss: 0.491 | a_loss: 0.543
Train: Epoch [825/3000], Step [60/158]| g_loss: 0.726| d_loss: 0.621| gp_loss: 0.050| r_loss: 0.091| p_loss: 0.147| v_loss: 0.030| per_loss: 0.457 | a_loss: 0.485
Train: Epoch [825/3000], Step [90/158]| g_loss: 0.797| d_loss: 0.606| gp_loss: 0.052| r_loss: 0.097| p_loss: 0.151| v_loss: 0.030| per_loss: 0.480 | a_loss: 0.547
Train: Epoch [825/3000], Step [120/158]| g_loss: 0.850| d_loss: 0.519| gp_loss: 0.055| r_loss: 0.094| p_loss: 0.149| v_loss: 0.032| per_loss: 0.479 | a_loss: 0.601
Train: Epoch [825/3000], Step [150/158]| g_loss: 0.770| d_loss: 0.596| gp_loss: 0.054| r_loss: 0.092| p_loss: 0.147| v_loss: 0.030| per_loss: 0.447 | a_loss: 0.530
Train: Epoch [826/3000], Step [30/158]| g_loss: 0.807| d_loss: 0.639| gp_loss: 0.160| r_loss: 0.095| p_loss: 0.158| v_loss: 0.033| per_loss: 0.447 | a_loss: 0.555
Train: Epoch [826/3000], Step [60/158]| g_loss: 0.729| d_loss: 0.700| gp_loss: 0.048| r_loss: 0.094| p_loss: 0.148| v_loss: 0.031| per_loss: 0.478 | a_loss: 0.483
Train: Epoch [826/3000], Step [90/158]| g_loss: 0.786| d_loss: 0.639| gp_loss: 0.053| r_loss: 0.095| p_loss: 0.150| v_loss: 0.030| per_loss: 0.475 | a_loss: 0.539
Train: Epoch [826/3000], Step [120/158]| g_loss: 0.763| d_loss: 0.593| gp_loss: 0.055| r_loss: 0.096| p_loss: 0.149| v_loss: 0.030| per_loss: 0.469 | a_loss: 0.515
Train: Epoch [826/3000], Step [150/158]| g_loss: 0.819| d_loss: 0.529| gp_loss: 0.056| r_loss: 0.097| p_loss: 0.156| v_loss: 0.031| per_loss: 0.499 | a_loss: 0.564
Train: Epoch [827/3000], Step [30/158]| g_loss: 0.823| d_loss: 0.614| gp_loss: 0.108| r_loss: 0.096| p_loss: 0.152| v_loss: 0.031| per_loss: 0.495 | a_loss: 0.570
Train: Epoch [827/3000], Step [60/158]| g_loss: 0.741| d_loss: 0.669| gp_loss: 0.051| r_loss: 0.097| p_loss: 0.150| v_loss: 0.032| per_loss: 0.481 | a_loss: 0.489
Train: Epoch [827/3000], Step [90/158]| g_loss: 0.781| d_loss: 0.562| gp_loss: 0.056| r_loss: 0.102| p_loss: 0.155| v_loss: 0.031| per_loss: 0.475 | a_loss: 0.524
Train: Epoch [827/3000], Step [120/158]| g_loss: 0.829| d_loss: 0.561| gp_loss: 0.057| r_loss: 0.095| p_loss: 0.152| v_loss: 0.031| per_loss: 0.499 | a_loss: 0.577
Train: Epoch [827/3000], Step [150/158]| g_loss: 0.770| d_loss: 0.610| gp_loss: 0.056| r_loss: 0.092| p_loss: 0.152| v_loss: 0.030| per_loss: 0.470 | a_loss: 0.525
Train: Epoch [828/3000], Step [30/158]| g_loss: 0.864| d_loss: 0.625| gp_loss: 0.170| r_loss: 0.098| p_loss: 0.155| v_loss: 0.032| per_loss: 0.502 | a_loss: 0.607
Train: Epoch [828/3000], Step [60/158]| g_loss: 0.876| d_loss: 0.547| gp_loss: 0.050| r_loss: 0.094| p_loss: 0.153| v_loss: 0.032| per_loss: 0.506 | a_loss: 0.622
Train: Epoch [828/3000], Step [90/158]| g_loss: 0.783| d_loss: 0.540| gp_loss: 0.052| r_loss: 0.095| p_loss: 0.153| v_loss: 0.033| per_loss: 0.460 | a_loss: 0.533
Train: Epoch [828/3000], Step [120/158]| g_loss: 0.779| d_loss: 0.640| gp_loss: 0.052| r_loss: 0.095| p_loss: 0.152| v_loss: 0.032| per_loss: 0.497 | a_loss: 0.526
Train: Epoch [828/3000], Step [150/158]| g_loss: 0.731| d_loss: 0.660| gp_loss: 0.054| r_loss: 0.097| p_loss: 0.149| v_loss: 0.030| per_loss: 0.468 | a_loss: 0.482
Train: Epoch [829/3000], Step [30/158]| g_loss: 0.751| d_loss: 0.713| gp_loss: 0.183| r_loss: 0.093| p_loss: 0.151| v_loss: 0.030| per_loss: 0.486 | a_loss: 0.503
Train: Epoch [829/3000], Step [60/158]| g_loss: 0.853| d_loss: 0.527| gp_loss: 0.051| r_loss: 0.100| p_loss: 0.155| v_loss: 0.030| per_loss: 0.480 | a_loss: 0.597
Train: Epoch [829/3000], Step [90/158]| g_loss: 0.824| d_loss: 0.590| gp_loss: 0.051| r_loss: 0.100| p_loss: 0.155| v_loss: 0.030| per_loss: 0.523 | a_loss: 0.564
Train: Epoch [829/3000], Step [120/158]| g_loss: 0.733| d_loss: 0.633| gp_loss: 0.051| r_loss: 0.095| p_loss: 0.157| v_loss: 0.032| per_loss: 0.467 | a_loss: 0.481
Train: Epoch [829/3000], Step [150/158]| g_loss: 0.803| d_loss: 0.588| gp_loss: 0.051| r_loss: 0.092| p_loss: 0.150| v_loss: 0.032| per_loss: 0.446 | a_loss: 0.560
Train: Epoch [830/3000], Step [30/158]| g_loss: 0.776| d_loss: 0.656| gp_loss: 0.089| r_loss: 0.097| p_loss: 0.148| v_loss: 0.032| per_loss: 0.478 | a_loss: 0.526
Train: Epoch [830/3000], Step [60/158]| g_loss: 0.840| d_loss: 0.499| gp_loss: 0.054| r_loss: 0.092| p_loss: 0.144| v_loss: 0.031| per_loss: 0.449 | a_loss: 0.600
Train: Epoch [830/3000], Step [90/158]| g_loss: 0.782| d_loss: 0.646| gp_loss: 0.054| r_loss: 0.097| p_loss: 0.152| v_loss: 0.030| per_loss: 0.459 | a_loss: 0.534
Train: Epoch [830/3000], Step [120/158]| g_loss: 0.761| d_loss: 0.586| gp_loss: 0.057| r_loss: 0.096| p_loss: 0.155| v_loss: 0.032| per_loss: 0.500 | a_loss: 0.506
Train: Epoch [830/3000], Step [150/158]| g_loss: 0.772| d_loss: 0.621| gp_loss: 0.061| r_loss: 0.094| p_loss: 0.150| v_loss: 0.029| per_loss: 0.498 | a_loss: 0.524
Train: Epoch [831/3000], Step [30/158]| g_loss: 0.872| d_loss: 0.626| gp_loss: 0.140| r_loss: 0.101| p_loss: 0.163| v_loss: 0.031| per_loss: 0.490 | a_loss: 0.610
Train: Epoch [831/3000], Step [60/158]| g_loss: 0.801| d_loss: 0.529| gp_loss: 0.056| r_loss: 0.097| p_loss: 0.155| v_loss: 0.032| per_loss: 0.473 | a_loss: 0.547
Train: Epoch [831/3000], Step [90/158]| g_loss: 0.831| d_loss: 0.562| gp_loss: 0.055| r_loss: 0.093| p_loss: 0.155| v_loss: 0.032| per_loss: 0.471 | a_loss: 0.582
Train: Epoch [831/3000], Step [120/158]| g_loss: 0.807| d_loss: 0.594| gp_loss: 0.055| r_loss: 0.094| p_loss: 0.149| v_loss: 0.031| per_loss: 0.484 | a_loss: 0.559
Train: Epoch [831/3000], Step [150/158]| g_loss: 0.791| d_loss: 0.588| gp_loss: 0.058| r_loss: 0.096| p_loss: 0.158| v_loss: 0.031| per_loss: 0.525 | a_loss: 0.532
Train: Epoch [832/3000], Step [30/158]| g_loss: 0.752| d_loss: 0.713| gp_loss: 0.071| r_loss: 0.105| p_loss: 0.170| v_loss: 0.032| per_loss: 0.495 | a_loss: 0.481
Train: Epoch [832/3000], Step [60/158]| g_loss: 0.819| d_loss: 0.621| gp_loss: 0.061| r_loss: 0.102| p_loss: 0.175| v_loss: 0.031| per_loss: 0.502 | a_loss: 0.549
Train: Epoch [832/3000], Step [90/158]| g_loss: 0.808| d_loss: 0.621| gp_loss: 0.060| r_loss: 0.098| p_loss: 0.165| v_loss: 0.031| per_loss: 0.502 | a_loss: 0.547
Train: Epoch [832/3000], Step [120/158]| g_loss: 0.773| d_loss: 0.673| gp_loss: 0.058| r_loss: 0.100| p_loss: 0.177| v_loss: 0.031| per_loss: 0.481 | a_loss: 0.505
Train: Epoch [832/3000], Step [150/158]| g_loss: 0.825| d_loss: 0.586| gp_loss: 0.063| r_loss: 0.101| p_loss: 0.169| v_loss: 0.031| per_loss: 0.502 | a_loss: 0.557
Train: Epoch [833/3000], Step [30/158]| g_loss: 0.822| d_loss: 0.692| gp_loss: 0.146| r_loss: 0.101| p_loss: 0.172| v_loss: 0.032| per_loss: 0.486 | a_loss: 0.554
Train: Epoch [833/3000], Step [60/158]| g_loss: 0.834| d_loss: 0.594| gp_loss: 0.050| r_loss: 0.102| p_loss: 0.176| v_loss: 0.032| per_loss: 0.505 | a_loss: 0.562
Train: Epoch [833/3000], Step [90/158]| g_loss: 0.855| d_loss: 0.572| gp_loss: 0.058| r_loss: 0.098| p_loss: 0.163| v_loss: 0.031| per_loss: 0.502 | a_loss: 0.595
Train: Epoch [833/3000], Step [120/158]| g_loss: 0.731| d_loss: 0.641| gp_loss: 0.051| r_loss: 0.098| p_loss: 0.162| v_loss: 0.030| per_loss: 0.491 | a_loss: 0.473
Train: Epoch [833/3000], Step [150/158]| g_loss: 0.790| d_loss: 0.658| gp_loss: 0.053| r_loss: 0.098| p_loss: 0.164| v_loss: 0.029| per_loss: 0.444 | a_loss: 0.536
Train: Epoch [834/3000], Step [30/158]| g_loss: 0.787| d_loss: 0.758| gp_loss: 0.227| r_loss: 0.098| p_loss: 0.160| v_loss: 0.030| per_loss: 0.448 | a_loss: 0.535
Train: Epoch [834/3000], Step [60/158]| g_loss: 0.806| d_loss: 0.652| gp_loss: 0.047| r_loss: 0.098| p_loss: 0.161| v_loss: 0.030| per_loss: 0.491 | a_loss: 0.548
Train: Epoch [834/3000], Step [90/158]| g_loss: 0.798| d_loss: 0.558| gp_loss: 0.050| r_loss: 0.097| p_loss: 0.159| v_loss: 0.032| per_loss: 0.500 | a_loss: 0.540
Train: Epoch [834/3000], Step [120/158]| g_loss: 0.729| d_loss: 0.606| gp_loss: 0.047| r_loss: 0.095| p_loss: 0.156| v_loss: 0.031| per_loss: 0.466 | a_loss: 0.479
Train: Epoch [834/3000], Step [150/158]| g_loss: 0.800| d_loss: 0.644| gp_loss: 0.048| r_loss: 0.097| p_loss: 0.156| v_loss: 0.030| per_loss: 0.463 | a_loss: 0.550
Train: Epoch [835/3000], Step [30/158]| g_loss: 0.765| d_loss: 0.755| gp_loss: 0.146| r_loss: 0.095| p_loss: 0.156| v_loss: 0.030| per_loss: 0.475 | a_loss: 0.516
Train: Epoch [835/3000], Step [60/158]| g_loss: 0.770| d_loss: 0.587| gp_loss: 0.049| r_loss: 0.095| p_loss: 0.148| v_loss: 0.030| per_loss: 0.469 | a_loss: 0.524
Train: Epoch [835/3000], Step [90/158]| g_loss: 0.771| d_loss: 0.624| gp_loss: 0.048| r_loss: 0.096| p_loss: 0.150| v_loss: 0.031| per_loss: 0.442 | a_loss: 0.525
Train: Epoch [835/3000], Step [120/158]| g_loss: 0.828| d_loss: 0.523| gp_loss: 0.053| r_loss: 0.093| p_loss: 0.145| v_loss: 0.031| per_loss: 0.490 | a_loss: 0.583
Train: Epoch [835/3000], Step [150/158]| g_loss: 0.782| d_loss: 0.614| gp_loss: 0.052| r_loss: 0.093| p_loss: 0.146| v_loss: 0.029| per_loss: 0.453 | a_loss: 0.541
Train: Epoch [836/3000], Step [30/158]| g_loss: 0.776| d_loss: 0.689| gp_loss: 0.126| r_loss: 0.095| p_loss: 0.156| v_loss: 0.030| per_loss: 0.456 | a_loss: 0.527
Train: Epoch [836/3000], Step [60/158]| g_loss: 0.810| d_loss: 0.634| gp_loss: 0.049| r_loss: 0.095| p_loss: 0.155| v_loss: 0.029| per_loss: 0.472 | a_loss: 0.562
Train: Epoch [836/3000], Step [90/158]| g_loss: 0.791| d_loss: 0.502| gp_loss: 0.052| r_loss: 0.097| p_loss: 0.152| v_loss: 0.029| per_loss: 0.457 | a_loss: 0.544
Train: Epoch [836/3000], Step [120/158]| g_loss: 0.765| d_loss: 0.671| gp_loss: 0.050| r_loss: 0.099| p_loss: 0.158| v_loss: 0.030| per_loss: 0.479 | a_loss: 0.509
Train: Epoch [836/3000], Step [150/158]| g_loss: 0.818| d_loss: 0.579| gp_loss: 0.050| r_loss: 0.095| p_loss: 0.155| v_loss: 0.030| per_loss: 0.480 | a_loss: 0.567
Train: Epoch [837/3000], Step [30/158]| g_loss: 0.812| d_loss: 0.735| gp_loss: 0.170| r_loss: 0.098| p_loss: 0.159| v_loss: 0.031| per_loss: 0.516 | a_loss: 0.552
Train: Epoch [837/3000], Step [60/158]| g_loss: 0.715| d_loss: 0.680| gp_loss: 0.048| r_loss: 0.095| p_loss: 0.159| v_loss: 0.031| per_loss: 0.474 | a_loss: 0.461
Train: Epoch [837/3000], Step [90/158]| g_loss: 0.807| d_loss: 0.564| gp_loss: 0.050| r_loss: 0.098| p_loss: 0.155| v_loss: 0.031| per_loss: 0.493 | a_loss: 0.551
Train: Epoch [837/3000], Step [120/158]| g_loss: 0.802| d_loss: 0.516| gp_loss: 0.054| r_loss: 0.094| p_loss: 0.149| v_loss: 0.029| per_loss: 0.492 | a_loss: 0.556
Train: Epoch [837/3000], Step [150/158]| g_loss: 0.844| d_loss: 0.533| gp_loss: 0.051| r_loss: 0.095| p_loss: 0.152| v_loss: 0.029| per_loss: 0.467 | a_loss: 0.597
Train: Epoch [838/3000], Step [30/158]| g_loss: 0.805| d_loss: 0.604| gp_loss: 0.128| r_loss: 0.091| p_loss: 0.143| v_loss: 0.029| per_loss: 0.464 | a_loss: 0.566
Train: Epoch [838/3000], Step [60/158]| g_loss: 0.859| d_loss: 0.566| gp_loss: 0.048| r_loss: 0.098| p_loss: 0.154| v_loss: 0.032| per_loss: 0.458 | a_loss: 0.607
Train: Epoch [838/3000], Step [90/158]| g_loss: 0.688| d_loss: 0.686| gp_loss: 0.048| r_loss: 0.090| p_loss: 0.141| v_loss: 0.028| per_loss: 0.463 | a_loss: 0.453
Train: Epoch [838/3000], Step [120/158]| g_loss: 0.737| d_loss: 0.584| gp_loss: 0.051| r_loss: 0.094| p_loss: 0.149| v_loss: 0.031| per_loss: 0.491 | a_loss: 0.489
Train: Epoch [838/3000], Step [150/158]| g_loss: 0.785| d_loss: 0.587| gp_loss: 0.051| r_loss: 0.094| p_loss: 0.151| v_loss: 0.031| per_loss: 0.515 | a_loss: 0.534
Train: Epoch [839/3000], Step [30/158]| g_loss: 0.781| d_loss: 0.676| gp_loss: 0.135| r_loss: 0.097| p_loss: 0.157| v_loss: 0.029| per_loss: 0.460 | a_loss: 0.530
Train: Epoch [839/3000], Step [60/158]| g_loss: 0.780| d_loss: 0.577| gp_loss: 0.052| r_loss: 0.092| p_loss: 0.148| v_loss: 0.028| per_loss: 0.440 | a_loss: 0.541
Train: Epoch [839/3000], Step [90/158]| g_loss: 0.804| d_loss: 0.548| gp_loss: 0.053| r_loss: 0.092| p_loss: 0.148| v_loss: 0.031| per_loss: 0.492 | a_loss: 0.557
Train: Epoch [839/3000], Step [120/158]| g_loss: 0.741| d_loss: 0.657| gp_loss: 0.055| r_loss: 0.094| p_loss: 0.154| v_loss: 0.031| per_loss: 0.466 | a_loss: 0.493
Train: Epoch [839/3000], Step [150/158]| g_loss: 0.809| d_loss: 0.587| gp_loss: 0.056| r_loss: 0.092| p_loss: 0.150| v_loss: 0.031| per_loss: 0.522 | a_loss: 0.559
Train: Epoch [840/3000], Step [30/158]| g_loss: 0.779| d_loss: 0.640| gp_loss: 0.110| r_loss: 0.094| p_loss: 0.154| v_loss: 0.030| per_loss: 0.494 | a_loss: 0.529
Train: Epoch [840/3000], Step [60/158]| g_loss: 0.853| d_loss: 0.453| gp_loss: 0.054| r_loss: 0.098| p_loss: 0.149| v_loss: 0.032| per_loss: 0.465 | a_loss: 0.603
Train: Epoch [840/3000], Step [90/158]| g_loss: 0.723| d_loss: 0.712| gp_loss: 0.054| r_loss: 0.096| p_loss: 0.156| v_loss: 0.028| per_loss: 0.475 | a_loss: 0.473
Train: Epoch [840/3000], Step [120/158]| g_loss: 0.802| d_loss: 0.675| gp_loss: 0.056| r_loss: 0.096| p_loss: 0.160| v_loss: 0.030| per_loss: 0.467 | a_loss: 0.550
Train: Epoch [840/3000], Step [150/158]| g_loss: 0.802| d_loss: 0.610| gp_loss: 0.055| r_loss: 0.102| p_loss: 0.165| v_loss: 0.031| per_loss: 0.481 | a_loss: 0.539
Train: Epoch [841/3000], Step [30/158]| g_loss: 0.767| d_loss: 0.716| gp_loss: 0.121| r_loss: 0.094| p_loss: 0.158| v_loss: 0.029| per_loss: 0.486 | a_loss: 0.516
Train: Epoch [841/3000], Step [60/158]| g_loss: 0.806| d_loss: 0.572| gp_loss: 0.055| r_loss: 0.094| p_loss: 0.160| v_loss: 0.030| per_loss: 0.491 | a_loss: 0.552
Train: Epoch [841/3000], Step [90/158]| g_loss: 0.828| d_loss: 0.583| gp_loss: 0.055| r_loss: 0.099| p_loss: 0.164| v_loss: 0.029| per_loss: 0.488 | a_loss: 0.569
Train: Epoch [841/3000], Step [120/158]| g_loss: 0.774| d_loss: 0.642| gp_loss: 0.055| r_loss: 0.097| p_loss: 0.160| v_loss: 0.030| per_loss: 0.465 | a_loss: 0.520
Train: Epoch [841/3000], Step [150/158]| g_loss: 0.792| d_loss: 0.618| gp_loss: 0.057| r_loss: 0.100| p_loss: 0.160| v_loss: 0.031| per_loss: 0.492 | a_loss: 0.531
Train: Epoch [842/3000], Step [30/158]| g_loss: 0.770| d_loss: 0.728| gp_loss: 0.156| r_loss: 0.090| p_loss: 0.150| v_loss: 0.030| per_loss: 0.495 | a_loss: 0.525
Train: Epoch [842/3000], Step [60/158]| g_loss: 0.819| d_loss: 0.603| gp_loss: 0.053| r_loss: 0.095| p_loss: 0.160| v_loss: 0.030| per_loss: 0.482 | a_loss: 0.566
Train: Epoch [842/3000], Step [90/158]| g_loss: 0.743| d_loss: 0.653| gp_loss: 0.054| r_loss: 0.100| p_loss: 0.156| v_loss: 0.030| per_loss: 0.477 | a_loss: 0.487
Train: Epoch [842/3000], Step [120/158]| g_loss: 0.880| d_loss: 0.477| gp_loss: 0.057| r_loss: 0.095| p_loss: 0.158| v_loss: 0.030| per_loss: 0.503 | a_loss: 0.626
Train: Epoch [842/3000], Step [150/158]| g_loss: 0.776| d_loss: 0.599| gp_loss: 0.055| r_loss: 0.100| p_loss: 0.157| v_loss: 0.030| per_loss: 0.487 | a_loss: 0.518
Train: Epoch [843/3000], Step [30/158]| g_loss: 0.822| d_loss: 0.737| gp_loss: 0.180| r_loss: 0.101| p_loss: 0.160| v_loss: 0.030| per_loss: 0.458 | a_loss: 0.565
Train: Epoch [843/3000], Step [60/158]| g_loss: 0.716| d_loss: 0.669| gp_loss: 0.051| r_loss: 0.094| p_loss: 0.154| v_loss: 0.030| per_loss: 0.499 | a_loss: 0.464
Train: Epoch [843/3000], Step [90/158]| g_loss: 0.832| d_loss: 0.525| gp_loss: 0.054| r_loss: 0.099| p_loss: 0.158| v_loss: 0.031| per_loss: 0.462 | a_loss: 0.576
Train: Epoch [843/3000], Step [120/158]| g_loss: 0.841| d_loss: 0.588| gp_loss: 0.054| r_loss: 0.099| p_loss: 0.165| v_loss: 0.031| per_loss: 0.473 | a_loss: 0.581
Train: Epoch [843/3000], Step [150/158]| g_loss: 0.827| d_loss: 0.545| gp_loss: 0.052| r_loss: 0.095| p_loss: 0.156| v_loss: 0.030| per_loss: 0.486 | a_loss: 0.575
Train: Epoch [844/3000], Step [30/158]| g_loss: 0.756| d_loss: 0.783| gp_loss: 0.119| r_loss: 0.098| p_loss: 0.161| v_loss: 0.030| per_loss: 0.464 | a_loss: 0.501
Train: Epoch [844/3000], Step [60/158]| g_loss: 0.772| d_loss: 0.578| gp_loss: 0.055| r_loss: 0.104| p_loss: 0.164| v_loss: 0.030| per_loss: 0.484 | a_loss: 0.506
Train: Epoch [844/3000], Step [90/158]| g_loss: 0.806| d_loss: 0.646| gp_loss: 0.050| r_loss: 0.104| p_loss: 0.161| v_loss: 0.029| per_loss: 0.467 | a_loss: 0.546
Train: Epoch [844/3000], Step [120/158]| g_loss: 0.746| d_loss: 0.589| gp_loss: 0.053| r_loss: 0.093| p_loss: 0.152| v_loss: 0.030| per_loss: 0.474 | a_loss: 0.500
Train: Epoch [844/3000], Step [150/158]| g_loss: 0.797| d_loss: 0.585| gp_loss: 0.057| r_loss: 0.102| p_loss: 0.161| v_loss: 0.031| per_loss: 0.470 | a_loss: 0.538
Train: Epoch [845/3000], Step [30/158]| g_loss: 0.790| d_loss: 0.681| gp_loss: 0.122| r_loss: 0.102| p_loss: 0.153| v_loss: 0.031| per_loss: 0.468 | a_loss: 0.533
Train: Epoch [845/3000], Step [60/158]| g_loss: 0.792| d_loss: 0.588| gp_loss: 0.053| r_loss: 0.101| p_loss: 0.158| v_loss: 0.030| per_loss: 0.469 | a_loss: 0.536
Train: Epoch [845/3000], Step [90/158]| g_loss: 0.809| d_loss: 0.553| gp_loss: 0.052| r_loss: 0.095| p_loss: 0.152| v_loss: 0.031| per_loss: 0.530 | a_loss: 0.554
Train: Epoch [845/3000], Step [120/158]| g_loss: 0.781| d_loss: 0.621| gp_loss: 0.053| r_loss: 0.093| p_loss: 0.150| v_loss: 0.030| per_loss: 0.471 | a_loss: 0.536
Train: Epoch [845/3000], Step [150/158]| g_loss: 0.745| d_loss: 0.599| gp_loss: 0.055| r_loss: 0.096| p_loss: 0.154| v_loss: 0.031| per_loss: 0.482 | a_loss: 0.493
Train: Epoch [846/3000], Step [30/158]| g_loss: 0.789| d_loss: 0.722| gp_loss: 0.178| r_loss: 0.099| p_loss: 0.150| v_loss: 0.029| per_loss: 0.488 | a_loss: 0.537
Train: Epoch [846/3000], Step [60/158]| g_loss: 0.819| d_loss: 0.577| gp_loss: 0.050| r_loss: 0.097| p_loss: 0.148| v_loss: 0.030| per_loss: 0.494 | a_loss: 0.569
Train: Epoch [846/3000], Step [90/158]| g_loss: 0.809| d_loss: 0.523| gp_loss: 0.051| r_loss: 0.090| p_loss: 0.143| v_loss: 0.030| per_loss: 0.486 | a_loss: 0.569
Train: Epoch [846/3000], Step [120/158]| g_loss: 0.748| d_loss: 0.659| gp_loss: 0.049| r_loss: 0.093| p_loss: 0.154| v_loss: 0.030| per_loss: 0.435 | a_loss: 0.504
Train: Epoch [846/3000], Step [150/158]| g_loss: 0.813| d_loss: 0.597| gp_loss: 0.055| r_loss: 0.100| p_loss: 0.156| v_loss: 0.031| per_loss: 0.476 | a_loss: 0.556
Train: Epoch [847/3000], Step [30/158]| g_loss: 0.751| d_loss: 0.680| gp_loss: 0.108| r_loss: 0.098| p_loss: 0.161| v_loss: 0.031| per_loss: 0.508 | a_loss: 0.491
Train: Epoch [847/3000], Step [60/158]| g_loss: 0.855| d_loss: 0.537| gp_loss: 0.053| r_loss: 0.092| p_loss: 0.147| v_loss: 0.031| per_loss: 0.468 | a_loss: 0.612
Train: Epoch [847/3000], Step [90/158]| g_loss: 0.815| d_loss: 0.570| gp_loss: 0.050| r_loss: 0.100| p_loss: 0.157| v_loss: 0.031| per_loss: 0.469 | a_loss: 0.559
Train: Epoch [847/3000], Step [120/158]| g_loss: 0.681| d_loss: 0.699| gp_loss: 0.056| r_loss: 0.094| p_loss: 0.153| v_loss: 0.030| per_loss: 0.460 | a_loss: 0.434
Train: Epoch [847/3000], Step [150/158]| g_loss: 0.854| d_loss: 0.556| gp_loss: 0.056| r_loss: 0.096| p_loss: 0.151| v_loss: 0.031| per_loss: 0.460 | a_loss: 0.606
Train: Epoch [848/3000], Step [30/158]| g_loss: 0.772| d_loss: 0.690| gp_loss: 0.163| r_loss: 0.097| p_loss: 0.155| v_loss: 0.031| per_loss: 0.444 | a_loss: 0.523
Train: Epoch [848/3000], Step [60/158]| g_loss: 0.787| d_loss: 0.604| gp_loss: 0.050| r_loss: 0.093| p_loss: 0.148| v_loss: 0.030| per_loss: 0.483 | a_loss: 0.541
Train: Epoch [848/3000], Step [90/158]| g_loss: 0.778| d_loss: 0.594| gp_loss: 0.054| r_loss: 0.093| p_loss: 0.145| v_loss: 0.030| per_loss: 0.470 | a_loss: 0.535
Train: Epoch [848/3000], Step [120/158]| g_loss: 0.776| d_loss: 0.581| gp_loss: 0.054| r_loss: 0.095| p_loss: 0.147| v_loss: 0.030| per_loss: 0.496 | a_loss: 0.527
Train: Epoch [848/3000], Step [150/158]| g_loss: 0.749| d_loss: 0.561| gp_loss: 0.054| r_loss: 0.091| p_loss: 0.150| v_loss: 0.031| per_loss: 0.472 | a_loss: 0.505
Train: Epoch [849/3000], Step [30/158]| g_loss: 0.839| d_loss: 0.657| gp_loss: 0.142| r_loss: 0.091| p_loss: 0.148| v_loss: 0.031| per_loss: 0.482 | a_loss: 0.595
Train: Epoch [849/3000], Step [60/158]| g_loss: 0.794| d_loss: 0.593| gp_loss: 0.052| r_loss: 0.094| p_loss: 0.153| v_loss: 0.031| per_loss: 0.477 | a_loss: 0.546
Train: Epoch [849/3000], Step [90/158]| g_loss: 0.773| d_loss: 0.584| gp_loss: 0.053| r_loss: 0.093| p_loss: 0.155| v_loss: 0.030| per_loss: 0.454 | a_loss: 0.527
Train: Epoch [849/3000], Step [120/158]| g_loss: 0.792| d_loss: 0.661| gp_loss: 0.055| r_loss: 0.095| p_loss: 0.159| v_loss: 0.031| per_loss: 0.466 | a_loss: 0.540
Train: Epoch [849/3000], Step [150/158]| g_loss: 0.754| d_loss: 0.621| gp_loss: 0.055| r_loss: 0.100| p_loss: 0.159| v_loss: 0.029| per_loss: 0.484 | a_loss: 0.497
Train: Epoch [850/3000], Step [30/158]| g_loss: 0.797| d_loss: 0.695| gp_loss: 0.085| r_loss: 0.096| p_loss: 0.161| v_loss: 0.030| per_loss: 0.510 | a_loss: 0.539
Train: Epoch [850/3000], Step [60/158]| g_loss: 0.811| d_loss: 0.580| gp_loss: 0.052| r_loss: 0.095| p_loss: 0.154| v_loss: 0.031| per_loss: 0.505 | a_loss: 0.557
Train: Epoch [850/3000], Step [90/158]| g_loss: 0.724| d_loss: 0.682| gp_loss: 0.055| r_loss: 0.096| p_loss: 0.153| v_loss: 0.031| per_loss: 0.428 | a_loss: 0.478
Train: Epoch [850/3000], Step [120/158]| g_loss: 0.884| d_loss: 0.430| gp_loss: 0.057| r_loss: 0.094| p_loss: 0.152| v_loss: 0.032| per_loss: 0.489 | a_loss: 0.634
Train: Epoch [850/3000], Step [150/158]| g_loss: 0.767| d_loss: 0.679| gp_loss: 0.056| r_loss: 0.094| p_loss: 0.151| v_loss: 0.029| per_loss: 0.457 | a_loss: 0.523
Test: Epoch [850/3000]| g_loss: 0.661| r_loss: 0.423| p_loss: 0.290| v_loss: 0.024
Train: Epoch [851/3000], Step [30/158]| g_loss: 0.768| d_loss: 0.641| gp_loss: 0.054| r_loss: 0.094| p_loss: 0.157| v_loss: 0.031| per_loss: 0.482 | a_loss: 0.516
Train: Epoch [851/3000], Step [60/158]| g_loss: 0.772| d_loss: 0.581| gp_loss: 0.055| r_loss: 0.098| p_loss: 0.151| v_loss: 0.031| per_loss: 0.457 | a_loss: 0.523
Train: Epoch [851/3000], Step [90/158]| g_loss: 0.792| d_loss: 0.595| gp_loss: 0.054| r_loss: 0.092| p_loss: 0.146| v_loss: 0.031| per_loss: 0.462 | a_loss: 0.549
Train: Epoch [851/3000], Step [120/158]| g_loss: 0.792| d_loss: 0.608| gp_loss: 0.056| r_loss: 0.092| p_loss: 0.150| v_loss: 0.030| per_loss: 0.452 | a_loss: 0.550
Train: Epoch [851/3000], Step [150/158]| g_loss: 0.762| d_loss: 0.584| gp_loss: 0.055| r_loss: 0.094| p_loss: 0.149| v_loss: 0.032| per_loss: 0.488 | a_loss: 0.512
Train: Epoch [852/3000], Step [30/158]| g_loss: 0.798| d_loss: 0.650| gp_loss: 0.115| r_loss: 0.091| p_loss: 0.147| v_loss: 0.030| per_loss: 0.497 | a_loss: 0.552
Train: Epoch [852/3000], Step [60/158]| g_loss: 0.748| d_loss: 0.612| gp_loss: 0.055| r_loss: 0.089| p_loss: 0.146| v_loss: 0.031| per_loss: 0.458 | a_loss: 0.509
Train: Epoch [852/3000], Step [90/158]| g_loss: 0.792| d_loss: 0.544| gp_loss: 0.058| r_loss: 0.092| p_loss: 0.142| v_loss: 0.030| per_loss: 0.440 | a_loss: 0.555
Train: Epoch [852/3000], Step [120/158]| g_loss: 0.802| d_loss: 0.593| gp_loss: 0.057| r_loss: 0.094| p_loss: 0.150| v_loss: 0.031| per_loss: 0.505 | a_loss: 0.551
Train: Epoch [852/3000], Step [150/158]| g_loss: 0.793| d_loss: 0.577| gp_loss: 0.055| r_loss: 0.089| p_loss: 0.144| v_loss: 0.030| per_loss: 0.463 | a_loss: 0.555
Train: Epoch [853/3000], Step [30/158]| g_loss: 0.795| d_loss: 0.653| gp_loss: 0.143| r_loss: 0.093| p_loss: 0.145| v_loss: 0.030| per_loss: 0.493 | a_loss: 0.550
Train: Epoch [853/3000], Step [60/158]| g_loss: 0.898| d_loss: 0.499| gp_loss: 0.049| r_loss: 0.091| p_loss: 0.142| v_loss: 0.031| per_loss: 0.498 | a_loss: 0.656
Train: Epoch [853/3000], Step [90/158]| g_loss: 0.715| d_loss: 0.671| gp_loss: 0.052| r_loss: 0.092| p_loss: 0.144| v_loss: 0.030| per_loss: 0.432 | a_loss: 0.477
Train: Epoch [853/3000], Step [120/158]| g_loss: 0.766| d_loss: 0.668| gp_loss: 0.055| r_loss: 0.096| p_loss: 0.160| v_loss: 0.032| per_loss: 0.469 | a_loss: 0.511
Train: Epoch [853/3000], Step [150/158]| g_loss: 0.752| d_loss: 0.630| gp_loss: 0.054| r_loss: 0.095| p_loss: 0.154| v_loss: 0.030| per_loss: 0.448 | a_loss: 0.505
Train: Epoch [854/3000], Step [30/158]| g_loss: 0.766| d_loss: 0.694| gp_loss: 0.116| r_loss: 0.094| p_loss: 0.146| v_loss: 0.029| per_loss: 0.495 | a_loss: 0.521
Train: Epoch [854/3000], Step [60/158]| g_loss: 0.868| d_loss: 0.481| gp_loss: 0.054| r_loss: 0.093| p_loss: 0.150| v_loss: 0.031| per_loss: 0.477 | a_loss: 0.621
Train: Epoch [854/3000], Step [90/158]| g_loss: 0.801| d_loss: 0.568| gp_loss: 0.054| r_loss: 0.093| p_loss: 0.145| v_loss: 0.031| per_loss: 0.423 | a_loss: 0.562
Train: Epoch [854/3000], Step [120/158]| g_loss: 0.754| d_loss: 0.685| gp_loss: 0.054| r_loss: 0.093| p_loss: 0.151| v_loss: 0.030| per_loss: 0.508 | a_loss: 0.505
Train: Epoch [854/3000], Step [150/158]| g_loss: 0.751| d_loss: 0.581| gp_loss: 0.057| r_loss: 0.094| p_loss: 0.150| v_loss: 0.030| per_loss: 0.460 | a_loss: 0.506
Train: Epoch [855/3000], Step [30/158]| g_loss: 0.789| d_loss: 0.694| gp_loss: 0.177| r_loss: 0.091| p_loss: 0.147| v_loss: 0.031| per_loss: 0.448 | a_loss: 0.549
Train: Epoch [855/3000], Step [60/158]| g_loss: 0.838| d_loss: 0.500| gp_loss: 0.051| r_loss: 0.089| p_loss: 0.139| v_loss: 0.030| per_loss: 0.494 | a_loss: 0.600
Train: Epoch [855/3000], Step [90/158]| g_loss: 0.797| d_loss: 0.627| gp_loss: 0.050| r_loss: 0.093| p_loss: 0.153| v_loss: 0.031| per_loss: 0.468 | a_loss: 0.550
Train: Epoch [855/3000], Step [120/158]| g_loss: 0.771| d_loss: 0.589| gp_loss: 0.055| r_loss: 0.095| p_loss: 0.155| v_loss: 0.030| per_loss: 0.482 | a_loss: 0.520
Train: Epoch [855/3000], Step [150/158]| g_loss: 0.781| d_loss: 0.650| gp_loss: 0.058| r_loss: 0.095| p_loss: 0.150| v_loss: 0.031| per_loss: 0.504 | a_loss: 0.530
Train: Epoch [856/3000], Step [30/158]| g_loss: 0.751| d_loss: 0.692| gp_loss: 0.171| r_loss: 0.090| p_loss: 0.142| v_loss: 0.030| per_loss: 0.464 | a_loss: 0.513
Train: Epoch [856/3000], Step [60/158]| g_loss: 0.834| d_loss: 0.519| gp_loss: 0.056| r_loss: 0.093| p_loss: 0.146| v_loss: 0.031| per_loss: 0.484 | a_loss: 0.588
Train: Epoch [856/3000], Step [90/158]| g_loss: 0.806| d_loss: 0.556| gp_loss: 0.053| r_loss: 0.089| p_loss: 0.142| v_loss: 0.030| per_loss: 0.480 | a_loss: 0.568
Train: Epoch [856/3000], Step [120/158]| g_loss: 0.715| d_loss: 0.710| gp_loss: 0.054| r_loss: 0.092| p_loss: 0.147| v_loss: 0.030| per_loss: 0.462 | a_loss: 0.473
Train: Epoch [856/3000], Step [150/158]| g_loss: 0.784| d_loss: 0.597| gp_loss: 0.058| r_loss: 0.093| p_loss: 0.150| v_loss: 0.031| per_loss: 0.484 | a_loss: 0.537
Train: Epoch [857/3000], Step [30/158]| g_loss: 0.762| d_loss: 0.706| gp_loss: 0.188| r_loss: 0.088| p_loss: 0.142| v_loss: 0.030| per_loss: 0.471 | a_loss: 0.525
Train: Epoch [857/3000], Step [60/158]| g_loss: 0.835| d_loss: 0.546| gp_loss: 0.053| r_loss: 0.089| p_loss: 0.140| v_loss: 0.030| per_loss: 0.497 | a_loss: 0.596
Train: Epoch [857/3000], Step [90/158]| g_loss: 0.782| d_loss: 0.625| gp_loss: 0.054| r_loss: 0.097| p_loss: 0.155| v_loss: 0.031| per_loss: 0.461 | a_loss: 0.531
Train: Epoch [857/3000], Step [120/158]| g_loss: 0.791| d_loss: 0.627| gp_loss: 0.054| r_loss: 0.097| p_loss: 0.153| v_loss: 0.030| per_loss: 0.477 | a_loss: 0.540
Train: Epoch [857/3000], Step [150/158]| g_loss: 0.745| d_loss: 0.657| gp_loss: 0.053| r_loss: 0.099| p_loss: 0.159| v_loss: 0.031| per_loss: 0.477 | a_loss: 0.488
Train: Epoch [858/3000], Step [30/158]| g_loss: 0.726| d_loss: 0.734| gp_loss: 0.107| r_loss: 0.095| p_loss: 0.162| v_loss: 0.031| per_loss: 0.506 | a_loss: 0.468
Train: Epoch [858/3000], Step [60/158]| g_loss: 0.803| d_loss: 0.692| gp_loss: 0.051| r_loss: 0.096| p_loss: 0.155| v_loss: 0.031| per_loss: 0.477 | a_loss: 0.551
Train: Epoch [858/3000], Step [90/158]| g_loss: 0.782| d_loss: 0.599| gp_loss: 0.053| r_loss: 0.097| p_loss: 0.151| v_loss: 0.031| per_loss: 0.511 | a_loss: 0.528
Train: Epoch [858/3000], Step [120/158]| g_loss: 0.807| d_loss: 0.549| gp_loss: 0.054| r_loss: 0.091| p_loss: 0.144| v_loss: 0.030| per_loss: 0.461 | a_loss: 0.568
Train: Epoch [858/3000], Step [150/158]| g_loss: 0.786| d_loss: 0.585| gp_loss: 0.058| r_loss: 0.091| p_loss: 0.141| v_loss: 0.030| per_loss: 0.477 | a_loss: 0.546
Train: Epoch [859/3000], Step [30/158]| g_loss: 0.733| d_loss: 0.847| gp_loss: 0.233| r_loss: 0.093| p_loss: 0.151| v_loss: 0.030| per_loss: 0.449 | a_loss: 0.489
Train: Epoch [859/3000], Step [60/158]| g_loss: 0.818| d_loss: 0.556| gp_loss: 0.047| r_loss: 0.094| p_loss: 0.149| v_loss: 0.030| per_loss: 0.487 | a_loss: 0.571
Train: Epoch [859/3000], Step [90/158]| g_loss: 0.840| d_loss: 0.518| gp_loss: 0.051| r_loss: 0.098| p_loss: 0.148| v_loss: 0.032| per_loss: 0.453 | a_loss: 0.591
Train: Epoch [859/3000], Step [120/158]| g_loss: 0.816| d_loss: 0.624| gp_loss: 0.052| r_loss: 0.093| p_loss: 0.153| v_loss: 0.030| per_loss: 0.487 | a_loss: 0.568
Train: Epoch [859/3000], Step [150/158]| g_loss: 0.758| d_loss: 0.580| gp_loss: 0.053| r_loss: 0.093| p_loss: 0.148| v_loss: 0.031| per_loss: 0.500 | a_loss: 0.511
Train: Epoch [860/3000], Step [30/158]| g_loss: 0.774| d_loss: 0.694| gp_loss: 0.108| r_loss: 0.091| p_loss: 0.149| v_loss: 0.031| per_loss: 0.488 | a_loss: 0.529
Train: Epoch [860/3000], Step [60/158]| g_loss: 0.746| d_loss: 0.662| gp_loss: 0.047| r_loss: 0.094| p_loss: 0.147| v_loss: 0.030| per_loss: 0.471 | a_loss: 0.501
Train: Epoch [860/3000], Step [90/158]| g_loss: 0.742| d_loss: 0.616| gp_loss: 0.051| r_loss: 0.093| p_loss: 0.150| v_loss: 0.029| per_loss: 0.423 | a_loss: 0.503
Train: Epoch [860/3000], Step [120/158]| g_loss: 0.839| d_loss: 0.522| gp_loss: 0.052| r_loss: 0.092| p_loss: 0.145| v_loss: 0.030| per_loss: 0.485 | a_loss: 0.597
Train: Epoch [860/3000], Step [150/158]| g_loss: 0.796| d_loss: 0.595| gp_loss: 0.050| r_loss: 0.093| p_loss: 0.147| v_loss: 0.030| per_loss: 0.495 | a_loss: 0.550
Train: Epoch [861/3000], Step [30/158]| g_loss: 0.804| d_loss: 0.709| gp_loss: 0.158| r_loss: 0.092| p_loss: 0.142| v_loss: 0.030| per_loss: 0.492 | a_loss: 0.561
Train: Epoch [861/3000], Step [60/158]| g_loss: 0.799| d_loss: 0.497| gp_loss: 0.047| r_loss: 0.091| p_loss: 0.143| v_loss: 0.030| per_loss: 0.491 | a_loss: 0.558
Train: Epoch [861/3000], Step [90/158]| g_loss: 0.734| d_loss: 0.613| gp_loss: 0.051| r_loss: 0.092| p_loss: 0.147| v_loss: 0.031| per_loss: 0.446 | a_loss: 0.493
Train: Epoch [861/3000], Step [120/158]| g_loss: 0.776| d_loss: 0.609| gp_loss: 0.050| r_loss: 0.089| p_loss: 0.141| v_loss: 0.029| per_loss: 0.471 | a_loss: 0.539
Train: Epoch [861/3000], Step [150/158]| g_loss: 0.751| d_loss: 0.638| gp_loss: 0.051| r_loss: 0.092| p_loss: 0.146| v_loss: 0.030| per_loss: 0.449 | a_loss: 0.511
Train: Epoch [862/3000], Step [30/158]| g_loss: 0.744| d_loss: 0.724| gp_loss: 0.153| r_loss: 0.092| p_loss: 0.141| v_loss: 0.030| per_loss: 0.475 | a_loss: 0.503
Train: Epoch [862/3000], Step [60/158]| g_loss: 0.819| d_loss: 0.554| gp_loss: 0.050| r_loss: 0.092| p_loss: 0.145| v_loss: 0.030| per_loss: 0.456 | a_loss: 0.579
Train: Epoch [862/3000], Step [90/158]| g_loss: 0.740| d_loss: 0.620| gp_loss: 0.050| r_loss: 0.095| p_loss: 0.148| v_loss: 0.029| per_loss: 0.455 | a_loss: 0.495
Train: Epoch [862/3000], Step [120/158]| g_loss: 0.789| d_loss: 0.580| gp_loss: 0.051| r_loss: 0.093| p_loss: 0.146| v_loss: 0.030| per_loss: 0.475 | a_loss: 0.546
Train: Epoch [862/3000], Step [150/158]| g_loss: 0.756| d_loss: 0.627| gp_loss: 0.053| r_loss: 0.094| p_loss: 0.154| v_loss: 0.029| per_loss: 0.449 | a_loss: 0.511
Train: Epoch [863/3000], Step [30/158]| g_loss: 0.761| d_loss: 0.706| gp_loss: 0.180| r_loss: 0.088| p_loss: 0.138| v_loss: 0.029| per_loss: 0.513 | a_loss: 0.523
Train: Epoch [863/3000], Step [60/158]| g_loss: 0.789| d_loss: 0.586| gp_loss: 0.051| r_loss: 0.091| p_loss: 0.150| v_loss: 0.031| per_loss: 0.435 | a_loss: 0.548
Train: Epoch [863/3000], Step [90/158]| g_loss: 0.740| d_loss: 0.642| gp_loss: 0.053| r_loss: 0.094| p_loss: 0.153| v_loss: 0.029| per_loss: 0.442 | a_loss: 0.496
Train: Epoch [863/3000], Step [120/158]| g_loss: 0.733| d_loss: 0.669| gp_loss: 0.055| r_loss: 0.093| p_loss: 0.149| v_loss: 0.029| per_loss: 0.500 | a_loss: 0.487
Train: Epoch [863/3000], Step [150/158]| g_loss: 0.826| d_loss: 0.492| gp_loss: 0.057| r_loss: 0.093| p_loss: 0.145| v_loss: 0.030| per_loss: 0.462 | a_loss: 0.584
Train: Epoch [864/3000], Step [30/158]| g_loss: 0.783| d_loss: 0.726| gp_loss: 0.173| r_loss: 0.091| p_loss: 0.146| v_loss: 0.030| per_loss: 0.474 | a_loss: 0.542
Train: Epoch [864/3000], Step [60/158]| g_loss: 0.786| d_loss: 0.561| gp_loss: 0.053| r_loss: 0.093| p_loss: 0.148| v_loss: 0.031| per_loss: 0.498 | a_loss: 0.538
Train: Epoch [864/3000], Step [90/158]| g_loss: 0.725| d_loss: 0.696| gp_loss: 0.051| r_loss: 0.089| p_loss: 0.143| v_loss: 0.031| per_loss: 0.439 | a_loss: 0.489
Train: Epoch [864/3000], Step [120/158]| g_loss: 0.775| d_loss: 0.535| gp_loss: 0.056| r_loss: 0.094| p_loss: 0.146| v_loss: 0.030| per_loss: 0.486 | a_loss: 0.529
Train: Epoch [864/3000], Step [150/158]| g_loss: 0.887| d_loss: 0.484| gp_loss: 0.056| r_loss: 0.093| p_loss: 0.150| v_loss: 0.030| per_loss: 0.464 | a_loss: 0.643
Train: Epoch [865/3000], Step [30/158]| g_loss: 0.823| d_loss: 0.620| gp_loss: 0.147| r_loss: 0.097| p_loss: 0.154| v_loss: 0.031| per_loss: 0.476 | a_loss: 0.570
Train: Epoch [865/3000], Step [60/158]| g_loss: 0.834| d_loss: 0.570| gp_loss: 0.051| r_loss: 0.095| p_loss: 0.149| v_loss: 0.031| per_loss: 0.483 | a_loss: 0.585
Train: Epoch [865/3000], Step [90/158]| g_loss: 0.722| d_loss: 0.655| gp_loss: 0.051| r_loss: 0.095| p_loss: 0.145| v_loss: 0.031| per_loss: 0.419 | a_loss: 0.481
Train: Epoch [865/3000], Step [120/158]| g_loss: 0.783| d_loss: 0.545| gp_loss: 0.054| r_loss: 0.088| p_loss: 0.137| v_loss: 0.030| per_loss: 0.499 | a_loss: 0.547
Train: Epoch [865/3000], Step [150/158]| g_loss: 0.727| d_loss: 0.699| gp_loss: 0.059| r_loss: 0.091| p_loss: 0.144| v_loss: 0.031| per_loss: 0.471 | a_loss: 0.486
Train: Epoch [866/3000], Step [30/158]| g_loss: 0.798| d_loss: 0.629| gp_loss: 0.127| r_loss: 0.092| p_loss: 0.144| v_loss: 0.030| per_loss: 0.490 | a_loss: 0.555
Train: Epoch [866/3000], Step [60/158]| g_loss: 0.817| d_loss: 0.590| gp_loss: 0.052| r_loss: 0.094| p_loss: 0.155| v_loss: 0.029| per_loss: 0.474 | a_loss: 0.568
Train: Epoch [866/3000], Step [90/158]| g_loss: 0.797| d_loss: 0.624| gp_loss: 0.054| r_loss: 0.091| p_loss: 0.145| v_loss: 0.030| per_loss: 0.472 | a_loss: 0.557
Train: Epoch [866/3000], Step [120/158]| g_loss: 0.822| d_loss: 0.482| gp_loss: 0.054| r_loss: 0.090| p_loss: 0.145| v_loss: 0.031| per_loss: 0.498 | a_loss: 0.579
Train: Epoch [866/3000], Step [150/158]| g_loss: 0.734| d_loss: 0.734| gp_loss: 0.055| r_loss: 0.097| p_loss: 0.158| v_loss: 0.031| per_loss: 0.470 | a_loss: 0.480
Train: Epoch [867/3000], Step [30/158]| g_loss: 0.753| d_loss: 0.768| gp_loss: 0.182| r_loss: 0.093| p_loss: 0.155| v_loss: 0.030| per_loss: 0.499 | a_loss: 0.502
Train: Epoch [867/3000], Step [60/158]| g_loss: 0.828| d_loss: 0.581| gp_loss: 0.050| r_loss: 0.097| p_loss: 0.150| v_loss: 0.031| per_loss: 0.494 | a_loss: 0.576
Train: Epoch [867/3000], Step [90/158]| g_loss: 0.750| d_loss: 0.593| gp_loss: 0.053| r_loss: 0.089| p_loss: 0.145| v_loss: 0.030| per_loss: 0.455 | a_loss: 0.514
Train: Epoch [867/3000], Step [120/158]| g_loss: 0.831| d_loss: 0.548| gp_loss: 0.052| r_loss: 0.094| p_loss: 0.156| v_loss: 0.031| per_loss: 0.488 | a_loss: 0.579
Train: Epoch [867/3000], Step [150/158]| g_loss: 0.800| d_loss: 0.616| gp_loss: 0.051| r_loss: 0.092| p_loss: 0.149| v_loss: 0.031| per_loss: 0.478 | a_loss: 0.554
Train: Epoch [868/3000], Step [30/158]| g_loss: 0.774| d_loss: 0.666| gp_loss: 0.149| r_loss: 0.093| p_loss: 0.146| v_loss: 0.032| per_loss: 0.529 | a_loss: 0.524
Train: Epoch [868/3000], Step [60/158]| g_loss: 0.803| d_loss: 0.590| gp_loss: 0.048| r_loss: 0.093| p_loss: 0.147| v_loss: 0.031| per_loss: 0.460 | a_loss: 0.560
Train: Epoch [868/3000], Step [90/158]| g_loss: 0.717| d_loss: 0.631| gp_loss: 0.049| r_loss: 0.086| p_loss: 0.141| v_loss: 0.029| per_loss: 0.450 | a_loss: 0.485
Train: Epoch [868/3000], Step [120/158]| g_loss: 0.871| d_loss: 0.489| gp_loss: 0.048| r_loss: 0.094| p_loss: 0.149| v_loss: 0.031| per_loss: 0.464 | a_loss: 0.624
Train: Epoch [868/3000], Step [150/158]| g_loss: 0.773| d_loss: 0.611| gp_loss: 0.050| r_loss: 0.090| p_loss: 0.146| v_loss: 0.030| per_loss: 0.464 | a_loss: 0.533
Train: Epoch [869/3000], Step [30/158]| g_loss: 0.734| d_loss: 0.768| gp_loss: 0.136| r_loss: 0.094| p_loss: 0.146| v_loss: 0.030| per_loss: 0.457 | a_loss: 0.491
Train: Epoch [869/3000], Step [60/158]| g_loss: 0.776| d_loss: 0.572| gp_loss: 0.047| r_loss: 0.091| p_loss: 0.149| v_loss: 0.030| per_loss: 0.443 | a_loss: 0.536
Train: Epoch [869/3000], Step [90/158]| g_loss: 0.828| d_loss: 0.567| gp_loss: 0.049| r_loss: 0.093| p_loss: 0.150| v_loss: 0.030| per_loss: 0.497 | a_loss: 0.580
Train: Epoch [869/3000], Step [120/158]| g_loss: 0.794| d_loss: 0.565| gp_loss: 0.055| r_loss: 0.097| p_loss: 0.155| v_loss: 0.030| per_loss: 0.441 | a_loss: 0.545
Train: Epoch [869/3000], Step [150/158]| g_loss: 0.777| d_loss: 0.605| gp_loss: 0.053| r_loss: 0.102| p_loss: 0.158| v_loss: 0.030| per_loss: 0.485 | a_loss: 0.517
Train: Epoch [870/3000], Step [30/158]| g_loss: 0.777| d_loss: 0.746| gp_loss: 0.161| r_loss: 0.095| p_loss: 0.156| v_loss: 0.031| per_loss: 0.474 | a_loss: 0.526
Train: Epoch [870/3000], Step [60/158]| g_loss: 0.806| d_loss: 0.569| gp_loss: 0.053| r_loss: 0.095| p_loss: 0.159| v_loss: 0.032| per_loss: 0.444 | a_loss: 0.556
Train: Epoch [870/3000], Step [90/158]| g_loss: 0.805| d_loss: 0.590| gp_loss: 0.055| r_loss: 0.093| p_loss: 0.150| v_loss: 0.030| per_loss: 0.462 | a_loss: 0.561
Train: Epoch [870/3000], Step [120/158]| g_loss: 0.844| d_loss: 0.584| gp_loss: 0.053| r_loss: 0.100| p_loss: 0.160| v_loss: 0.030| per_loss: 0.489 | a_loss: 0.585
Train: Epoch [870/3000], Step [150/158]| g_loss: 0.819| d_loss: 0.575| gp_loss: 0.053| r_loss: 0.095| p_loss: 0.157| v_loss: 0.030| per_loss: 0.473 | a_loss: 0.568
Train: Epoch [871/3000], Step [30/158]| g_loss: 0.749| d_loss: 0.778| gp_loss: 0.187| r_loss: 0.096| p_loss: 0.154| v_loss: 0.031| per_loss: 0.471 | a_loss: 0.499
Train: Epoch [871/3000], Step [60/158]| g_loss: 0.792| d_loss: 0.598| gp_loss: 0.046| r_loss: 0.090| p_loss: 0.143| v_loss: 0.030| per_loss: 0.477 | a_loss: 0.554
Train: Epoch [871/3000], Step [90/158]| g_loss: 0.759| d_loss: 0.587| gp_loss: 0.052| r_loss: 0.091| p_loss: 0.141| v_loss: 0.031| per_loss: 0.466 | a_loss: 0.520
Train: Epoch [871/3000], Step [120/158]| g_loss: 0.840| d_loss: 0.532| gp_loss: 0.049| r_loss: 0.095| p_loss: 0.146| v_loss: 0.030| per_loss: 0.449 | a_loss: 0.597
Train: Epoch [871/3000], Step [150/158]| g_loss: 0.738| d_loss: 0.650| gp_loss: 0.050| r_loss: 0.093| p_loss: 0.149| v_loss: 0.030| per_loss: 0.467 | a_loss: 0.494
Train: Epoch [872/3000], Step [30/158]| g_loss: 0.812| d_loss: 0.641| gp_loss: 0.186| r_loss: 0.091| p_loss: 0.144| v_loss: 0.031| per_loss: 0.426 | a_loss: 0.575
Train: Epoch [872/3000], Step [60/158]| g_loss: 0.789| d_loss: 0.625| gp_loss: 0.048| r_loss: 0.095| p_loss: 0.142| v_loss: 0.029| per_loss: 0.497 | a_loss: 0.544
Train: Epoch [872/3000], Step [90/158]| g_loss: 0.706| d_loss: 0.682| gp_loss: 0.047| r_loss: 0.093| p_loss: 0.148| v_loss: 0.031| per_loss: 0.446 | a_loss: 0.463
Train: Epoch [872/3000], Step [120/158]| g_loss: 0.798| d_loss: 0.527| gp_loss: 0.053| r_loss: 0.089| p_loss: 0.146| v_loss: 0.030| per_loss: 0.494 | a_loss: 0.556
Train: Epoch [872/3000], Step [150/158]| g_loss: 0.811| d_loss: 0.636| gp_loss: 0.049| r_loss: 0.093| p_loss: 0.150| v_loss: 0.030| per_loss: 0.472 | a_loss: 0.565
Train: Epoch [873/3000], Step [30/158]| g_loss: 0.725| d_loss: 0.747| gp_loss: 0.162| r_loss: 0.091| p_loss: 0.149| v_loss: 0.029| per_loss: 0.416 | a_loss: 0.489
Train: Epoch [873/3000], Step [60/158]| g_loss: 0.763| d_loss: 0.659| gp_loss: 0.047| r_loss: 0.095| p_loss: 0.151| v_loss: 0.030| per_loss: 0.470 | a_loss: 0.515
Train: Epoch [873/3000], Step [90/158]| g_loss: 0.844| d_loss: 0.466| gp_loss: 0.051| r_loss: 0.093| p_loss: 0.145| v_loss: 0.032| per_loss: 0.487 | a_loss: 0.598
Train: Epoch [873/3000], Step [120/158]| g_loss: 0.769| d_loss: 0.637| gp_loss: 0.051| r_loss: 0.084| p_loss: 0.138| v_loss: 0.029| per_loss: 0.479 | a_loss: 0.539
Train: Epoch [873/3000], Step [150/158]| g_loss: 0.761| d_loss: 0.605| gp_loss: 0.053| r_loss: 0.093| p_loss: 0.146| v_loss: 0.030| per_loss: 0.477 | a_loss: 0.518
Train: Epoch [874/3000], Step [30/158]| g_loss: 0.762| d_loss: 0.669| gp_loss: 0.110| r_loss: 0.089| p_loss: 0.137| v_loss: 0.029| per_loss: 0.497 | a_loss: 0.526
Train: Epoch [874/3000], Step [60/158]| g_loss: 0.830| d_loss: 0.526| gp_loss: 0.053| r_loss: 0.094| p_loss: 0.149| v_loss: 0.031| per_loss: 0.456 | a_loss: 0.585
Train: Epoch [874/3000], Step [90/158]| g_loss: 0.810| d_loss: 0.603| gp_loss: 0.051| r_loss: 0.093| p_loss: 0.151| v_loss: 0.030| per_loss: 0.477 | a_loss: 0.564
Train: Epoch [874/3000], Step [120/158]| g_loss: 0.788| d_loss: 0.544| gp_loss: 0.054| r_loss: 0.092| p_loss: 0.144| v_loss: 0.030| per_loss: 0.471 | a_loss: 0.546
Train: Epoch [874/3000], Step [150/158]| g_loss: 0.799| d_loss: 0.615| gp_loss: 0.055| r_loss: 0.092| p_loss: 0.146| v_loss: 0.030| per_loss: 0.490 | a_loss: 0.555
Train: Epoch [875/3000], Step [30/158]| g_loss: 0.772| d_loss: 0.701| gp_loss: 0.168| r_loss: 0.093| p_loss: 0.146| v_loss: 0.031| per_loss: 0.472 | a_loss: 0.528
Train: Epoch [875/3000], Step [60/158]| g_loss: 0.828| d_loss: 0.565| gp_loss: 0.049| r_loss: 0.090| p_loss: 0.144| v_loss: 0.031| per_loss: 0.488 | a_loss: 0.586
Train: Epoch [875/3000], Step [90/158]| g_loss: 0.750| d_loss: 0.649| gp_loss: 0.051| r_loss: 0.094| p_loss: 0.149| v_loss: 0.030| per_loss: 0.468 | a_loss: 0.504
Train: Epoch [875/3000], Step [120/158]| g_loss: 0.779| d_loss: 0.581| gp_loss: 0.052| r_loss: 0.095| p_loss: 0.157| v_loss: 0.029| per_loss: 0.475 | a_loss: 0.529
Train: Epoch [875/3000], Step [150/158]| g_loss: 0.778| d_loss: 0.613| gp_loss: 0.052| r_loss: 0.095| p_loss: 0.152| v_loss: 0.029| per_loss: 0.471 | a_loss: 0.532
Train: Epoch [876/3000], Step [30/158]| g_loss: 0.789| d_loss: 0.732| gp_loss: 0.137| r_loss: 0.102| p_loss: 0.162| v_loss: 0.031| per_loss: 0.492 | a_loss: 0.526
Train: Epoch [876/3000], Step [60/158]| g_loss: 0.744| d_loss: 0.657| gp_loss: 0.052| r_loss: 0.099| p_loss: 0.158| v_loss: 0.032| per_loss: 0.471 | a_loss: 0.487
Train: Epoch [876/3000], Step [90/158]| g_loss: 0.808| d_loss: 0.563| gp_loss: 0.053| r_loss: 0.096| p_loss: 0.158| v_loss: 0.031| per_loss: 0.498 | a_loss: 0.552
Train: Epoch [876/3000], Step [120/158]| g_loss: 0.838| d_loss: 0.529| gp_loss: 0.052| r_loss: 0.094| p_loss: 0.155| v_loss: 0.030| per_loss: 0.487 | a_loss: 0.587
Train: Epoch [876/3000], Step [150/158]| g_loss: 0.829| d_loss: 0.551| gp_loss: 0.053| r_loss: 0.094| p_loss: 0.153| v_loss: 0.031| per_loss: 0.476 | a_loss: 0.581
Train: Epoch [877/3000], Step [30/158]| g_loss: 0.857| d_loss: 0.653| gp_loss: 0.172| r_loss: 0.093| p_loss: 0.144| v_loss: 0.029| per_loss: 0.480 | a_loss: 0.615
Train: Epoch [877/3000], Step [60/158]| g_loss: 0.733| d_loss: 0.644| gp_loss: 0.047| r_loss: 0.088| p_loss: 0.135| v_loss: 0.030| per_loss: 0.432 | a_loss: 0.505
Train: Epoch [877/3000], Step [90/158]| g_loss: 0.776| d_loss: 0.623| gp_loss: 0.050| r_loss: 0.092| p_loss: 0.147| v_loss: 0.029| per_loss: 0.478 | a_loss: 0.533
Train: Epoch [877/3000], Step [120/158]| g_loss: 0.788| d_loss: 0.598| gp_loss: 0.048| r_loss: 0.097| p_loss: 0.159| v_loss: 0.030| per_loss: 0.495 | a_loss: 0.533
Train: Epoch [877/3000], Step [150/158]| g_loss: 0.776| d_loss: 0.618| gp_loss: 0.049| r_loss: 0.098| p_loss: 0.161| v_loss: 0.031| per_loss: 0.454 | a_loss: 0.521
Train: Epoch [878/3000], Step [30/158]| g_loss: 0.831| d_loss: 0.699| gp_loss: 0.164| r_loss: 0.095| p_loss: 0.153| v_loss: 0.030| per_loss: 0.474 | a_loss: 0.582
Train: Epoch [878/3000], Step [60/158]| g_loss: 0.784| d_loss: 0.554| gp_loss: 0.052| r_loss: 0.092| p_loss: 0.145| v_loss: 0.030| per_loss: 0.467 | a_loss: 0.542
Train: Epoch [878/3000], Step [90/158]| g_loss: 0.776| d_loss: 0.571| gp_loss: 0.047| r_loss: 0.090| p_loss: 0.144| v_loss: 0.029| per_loss: 0.462 | a_loss: 0.539
Train: Epoch [878/3000], Step [120/158]| g_loss: 0.789| d_loss: 0.626| gp_loss: 0.050| r_loss: 0.096| p_loss: 0.150| v_loss: 0.031| per_loss: 0.464 | a_loss: 0.540
Train: Epoch [878/3000], Step [150/158]| g_loss: 0.782| d_loss: 0.581| gp_loss: 0.054| r_loss: 0.092| p_loss: 0.151| v_loss: 0.029| per_loss: 0.432 | a_loss: 0.542
Train: Epoch [879/3000], Step [30/158]| g_loss: 0.787| d_loss: 0.671| gp_loss: 0.130| r_loss: 0.097| p_loss: 0.157| v_loss: 0.030| per_loss: 0.455 | a_loss: 0.537
Train: Epoch [879/3000], Step [60/158]| g_loss: 0.750| d_loss: 0.648| gp_loss: 0.050| r_loss: 0.090| p_loss: 0.143| v_loss: 0.029| per_loss: 0.437 | a_loss: 0.516
Train: Epoch [879/3000], Step [90/158]| g_loss: 0.849| d_loss: 0.498| gp_loss: 0.053| r_loss: 0.090| p_loss: 0.144| v_loss: 0.029| per_loss: 0.473 | a_loss: 0.611
Train: Epoch [879/3000], Step [120/158]| g_loss: 0.718| d_loss: 0.605| gp_loss: 0.050| r_loss: 0.088| p_loss: 0.146| v_loss: 0.030| per_loss: 0.482 | a_loss: 0.479
Train: Epoch [879/3000], Step [150/158]| g_loss: 0.744| d_loss: 0.708| gp_loss: 0.052| r_loss: 0.093| p_loss: 0.149| v_loss: 0.030| per_loss: 0.441 | a_loss: 0.502
Train: Epoch [880/3000], Step [30/158]| g_loss: 0.781| d_loss: 0.737| gp_loss: 0.189| r_loss: 0.096| p_loss: 0.154| v_loss: 0.030| per_loss: 0.469 | a_loss: 0.531
Train: Epoch [880/3000], Step [60/158]| g_loss: 0.790| d_loss: 0.512| gp_loss: 0.048| r_loss: 0.088| p_loss: 0.134| v_loss: 0.028| per_loss: 0.463 | a_loss: 0.560
Train: Epoch [880/3000], Step [90/158]| g_loss: 0.832| d_loss: 0.586| gp_loss: 0.052| r_loss: 0.091| p_loss: 0.145| v_loss: 0.030| per_loss: 0.468 | a_loss: 0.591
Train: Epoch [880/3000], Step [120/158]| g_loss: 0.757| d_loss: 0.619| gp_loss: 0.051| r_loss: 0.095| p_loss: 0.146| v_loss: 0.029| per_loss: 0.450 | a_loss: 0.515
Train: Epoch [880/3000], Step [150/158]| g_loss: 0.739| d_loss: 0.639| gp_loss: 0.051| r_loss: 0.093| p_loss: 0.145| v_loss: 0.029| per_loss: 0.466 | a_loss: 0.498
Train: Epoch [881/3000], Step [30/158]| g_loss: 0.793| d_loss: 0.658| gp_loss: 0.144| r_loss: 0.090| p_loss: 0.144| v_loss: 0.029| per_loss: 0.475 | a_loss: 0.554
Train: Epoch [881/3000], Step [60/158]| g_loss: 0.853| d_loss: 0.559| gp_loss: 0.050| r_loss: 0.094| p_loss: 0.143| v_loss: 0.029| per_loss: 0.524 | a_loss: 0.606
Train: Epoch [881/3000], Step [90/158]| g_loss: 0.759| d_loss: 0.577| gp_loss: 0.052| r_loss: 0.088| p_loss: 0.144| v_loss: 0.028| per_loss: 0.485 | a_loss: 0.523
Train: Epoch [881/3000], Step [120/158]| g_loss: 0.775| d_loss: 0.630| gp_loss: 0.053| r_loss: 0.091| p_loss: 0.147| v_loss: 0.031| per_loss: 0.490 | a_loss: 0.531
Train: Epoch [881/3000], Step [150/158]| g_loss: 0.755| d_loss: 0.611| gp_loss: 0.053| r_loss: 0.091| p_loss: 0.150| v_loss: 0.030| per_loss: 0.426 | a_loss: 0.515
Train: Epoch [882/3000], Step [30/158]| g_loss: 0.778| d_loss: 0.712| gp_loss: 0.167| r_loss: 0.093| p_loss: 0.149| v_loss: 0.029| per_loss: 0.481 | a_loss: 0.533
Train: Epoch [882/3000], Step [60/158]| g_loss: 0.792| d_loss: 0.605| gp_loss: 0.050| r_loss: 0.100| p_loss: 0.164| v_loss: 0.031| per_loss: 0.461 | a_loss: 0.534
Train: Epoch [882/3000], Step [90/158]| g_loss: 0.795| d_loss: 0.605| gp_loss: 0.052| r_loss: 0.091| p_loss: 0.151| v_loss: 0.029| per_loss: 0.497 | a_loss: 0.549
Train: Epoch [882/3000], Step [120/158]| g_loss: 0.787| d_loss: 0.570| gp_loss: 0.052| r_loss: 0.092| p_loss: 0.145| v_loss: 0.029| per_loss: 0.482 | a_loss: 0.545
Train: Epoch [882/3000], Step [150/158]| g_loss: 0.850| d_loss: 0.546| gp_loss: 0.052| r_loss: 0.093| p_loss: 0.151| v_loss: 0.031| per_loss: 0.518 | a_loss: 0.598
Train: Epoch [883/3000], Step [30/158]| g_loss: 0.785| d_loss: 0.650| gp_loss: 0.106| r_loss: 0.097| p_loss: 0.155| v_loss: 0.030| per_loss: 0.494 | a_loss: 0.531
Train: Epoch [883/3000], Step [60/158]| g_loss: 0.794| d_loss: 0.605| gp_loss: 0.051| r_loss: 0.095| p_loss: 0.153| v_loss: 0.031| per_loss: 0.471 | a_loss: 0.544
Train: Epoch [883/3000], Step [90/158]| g_loss: 0.815| d_loss: 0.585| gp_loss: 0.053| r_loss: 0.092| p_loss: 0.151| v_loss: 0.030| per_loss: 0.546 | a_loss: 0.563
Train: Epoch [883/3000], Step [120/158]| g_loss: 0.785| d_loss: 0.631| gp_loss: 0.051| r_loss: 0.097| p_loss: 0.154| v_loss: 0.031| per_loss: 0.455 | a_loss: 0.535
Train: Epoch [883/3000], Step [150/158]| g_loss: 0.748| d_loss: 0.603| gp_loss: 0.053| r_loss: 0.094| p_loss: 0.151| v_loss: 0.030| per_loss: 0.475 | a_loss: 0.501
Train: Epoch [884/3000], Step [30/158]| g_loss: 0.792| d_loss: 0.718| gp_loss: 0.144| r_loss: 0.097| p_loss: 0.158| v_loss: 0.030| per_loss: 0.458 | a_loss: 0.540
Train: Epoch [884/3000], Step [60/158]| g_loss: 0.865| d_loss: 0.516| gp_loss: 0.051| r_loss: 0.096| p_loss: 0.155| v_loss: 0.031| per_loss: 0.526 | a_loss: 0.608
Train: Epoch [884/3000], Step [90/158]| g_loss: 0.800| d_loss: 0.603| gp_loss: 0.051| r_loss: 0.095| p_loss: 0.150| v_loss: 0.030| per_loss: 0.481 | a_loss: 0.552
Train: Epoch [884/3000], Step [120/158]| g_loss: 0.775| d_loss: 0.612| gp_loss: 0.054| r_loss: 0.097| p_loss: 0.152| v_loss: 0.029| per_loss: 0.494 | a_loss: 0.523
Train: Epoch [884/3000], Step [150/158]| g_loss: 0.789| d_loss: 0.609| gp_loss: 0.056| r_loss: 0.098| p_loss: 0.158| v_loss: 0.031| per_loss: 0.485 | a_loss: 0.533
Train: Epoch [885/3000], Step [30/158]| g_loss: 0.774| d_loss: 0.703| gp_loss: 0.102| r_loss: 0.095| p_loss: 0.152| v_loss: 0.030| per_loss: 0.490 | a_loss: 0.524
Train: Epoch [885/3000], Step [60/158]| g_loss: 0.808| d_loss: 0.588| gp_loss: 0.053| r_loss: 0.092| p_loss: 0.149| v_loss: 0.030| per_loss: 0.474 | a_loss: 0.564
Train: Epoch [885/3000], Step [90/158]| g_loss: 0.766| d_loss: 0.585| gp_loss: 0.052| r_loss: 0.096| p_loss: 0.148| v_loss: 0.030| per_loss: 0.490 | a_loss: 0.517
Train: Epoch [885/3000], Step [120/158]| g_loss: 0.823| d_loss: 0.618| gp_loss: 0.053| r_loss: 0.102| p_loss: 0.163| v_loss: 0.031| per_loss: 0.495 | a_loss: 0.559
Train: Epoch [885/3000], Step [150/158]| g_loss: 0.810| d_loss: 0.598| gp_loss: 0.055| r_loss: 0.096| p_loss: 0.152| v_loss: 0.029| per_loss: 0.462 | a_loss: 0.563
Train: Epoch [886/3000], Step [30/158]| g_loss: 0.795| d_loss: 0.707| gp_loss: 0.149| r_loss: 0.099| p_loss: 0.161| v_loss: 0.031| per_loss: 0.477 | a_loss: 0.537
Train: Epoch [886/3000], Step [60/158]| g_loss: 0.808| d_loss: 0.524| gp_loss: 0.050| r_loss: 0.093| p_loss: 0.151| v_loss: 0.031| per_loss: 0.500 | a_loss: 0.558
Train: Epoch [886/3000], Step [90/158]| g_loss: 0.782| d_loss: 0.610| gp_loss: 0.051| r_loss: 0.094| p_loss: 0.151| v_loss: 0.030| per_loss: 0.494 | a_loss: 0.532
Train: Epoch [886/3000], Step [120/158]| g_loss: 0.769| d_loss: 0.597| gp_loss: 0.053| r_loss: 0.093| p_loss: 0.149| v_loss: 0.029| per_loss: 0.474 | a_loss: 0.525
Train: Epoch [886/3000], Step [150/158]| g_loss: 0.771| d_loss: 0.587| gp_loss: 0.056| r_loss: 0.098| p_loss: 0.150| v_loss: 0.029| per_loss: 0.479 | a_loss: 0.521
Train: Epoch [887/3000], Step [30/158]| g_loss: 0.781| d_loss: 0.694| gp_loss: 0.149| r_loss: 0.094| p_loss: 0.151| v_loss: 0.030| per_loss: 0.496 | a_loss: 0.532
Train: Epoch [887/3000], Step [60/158]| g_loss: 0.763| d_loss: 0.574| gp_loss: 0.051| r_loss: 0.092| p_loss: 0.154| v_loss: 0.030| per_loss: 0.449 | a_loss: 0.519
Train: Epoch [887/3000], Step [90/158]| g_loss: 0.735| d_loss: 0.699| gp_loss: 0.049| r_loss: 0.096| p_loss: 0.158| v_loss: 0.030| per_loss: 0.482 | a_loss: 0.482
Train: Epoch [887/3000], Step [120/158]| g_loss: 0.839| d_loss: 0.603| gp_loss: 0.056| r_loss: 0.099| p_loss: 0.161| v_loss: 0.032| per_loss: 0.502 | a_loss: 0.578
Train: Epoch [887/3000], Step [150/158]| g_loss: 0.776| d_loss: 0.534| gp_loss: 0.053| r_loss: 0.094| p_loss: 0.149| v_loss: 0.030| per_loss: 0.507 | a_loss: 0.527
Train: Epoch [888/3000], Step [30/158]| g_loss: 0.822| d_loss: 0.549| gp_loss: 0.093| r_loss: 0.093| p_loss: 0.152| v_loss: 0.032| per_loss: 0.527 | a_loss: 0.569
Train: Epoch [888/3000], Step [60/158]| g_loss: 0.846| d_loss: 0.634| gp_loss: 0.053| r_loss: 0.094| p_loss: 0.156| v_loss: 0.030| per_loss: 0.499 | a_loss: 0.594
Train: Epoch [888/3000], Step [90/158]| g_loss: 0.768| d_loss: 0.554| gp_loss: 0.055| r_loss: 0.097| p_loss: 0.149| v_loss: 0.031| per_loss: 0.472 | a_loss: 0.519
Train: Epoch [888/3000], Step [120/158]| g_loss: 0.806| d_loss: 0.576| gp_loss: 0.055| r_loss: 0.097| p_loss: 0.159| v_loss: 0.030| per_loss: 0.505 | a_loss: 0.549
Train: Epoch [888/3000], Step [150/158]| g_loss: 0.766| d_loss: 0.655| gp_loss: 0.057| r_loss: 0.096| p_loss: 0.159| v_loss: 0.031| per_loss: 0.515 | a_loss: 0.508
Train: Epoch [889/3000], Step [30/158]| g_loss: 0.766| d_loss: 0.691| gp_loss: 0.114| r_loss: 0.097| p_loss: 0.162| v_loss: 0.030| per_loss: 0.510 | a_loss: 0.507
Train: Epoch [889/3000], Step [60/158]| g_loss: 0.835| d_loss: 0.573| gp_loss: 0.053| r_loss: 0.100| p_loss: 0.166| v_loss: 0.030| per_loss: 0.562 | a_loss: 0.566
Train: Epoch [889/3000], Step [90/158]| g_loss: 0.767| d_loss: 0.612| gp_loss: 0.056| r_loss: 0.097| p_loss: 0.157| v_loss: 0.030| per_loss: 0.546 | a_loss: 0.506
Train: Epoch [889/3000], Step [120/158]| g_loss: 0.809| d_loss: 0.540| gp_loss: 0.061| r_loss: 0.103| p_loss: 0.164| v_loss: 0.032| per_loss: 0.495 | a_loss: 0.543
Train: Epoch [889/3000], Step [150/158]| g_loss: 0.888| d_loss: 0.554| gp_loss: 0.057| r_loss: 0.097| p_loss: 0.158| v_loss: 0.030| per_loss: 0.496 | a_loss: 0.633
Train: Epoch [890/3000], Step [30/158]| g_loss: 0.791| d_loss: 0.732| gp_loss: 0.162| r_loss: 0.100| p_loss: 0.158| v_loss: 0.031| per_loss: 0.496 | a_loss: 0.531
Train: Epoch [890/3000], Step [60/158]| g_loss: 0.797| d_loss: 0.611| gp_loss: 0.055| r_loss: 0.101| p_loss: 0.154| v_loss: 0.031| per_loss: 0.495 | a_loss: 0.539
Train: Epoch [890/3000], Step [90/158]| g_loss: 0.773| d_loss: 0.599| gp_loss: 0.054| r_loss: 0.091| p_loss: 0.150| v_loss: 0.029| per_loss: 0.549 | a_loss: 0.522
Train: Epoch [890/3000], Step [120/158]| g_loss: 0.822| d_loss: 0.554| gp_loss: 0.060| r_loss: 0.098| p_loss: 0.149| v_loss: 0.031| per_loss: 0.532 | a_loss: 0.565
Train: Epoch [890/3000], Step [150/158]| g_loss: 0.774| d_loss: 0.622| gp_loss: 0.060| r_loss: 0.096| p_loss: 0.156| v_loss: 0.030| per_loss: 0.503 | a_loss: 0.520
Train: Epoch [891/3000], Step [30/158]| g_loss: 0.854| d_loss: 0.649| gp_loss: 0.146| r_loss: 0.102| p_loss: 0.174| v_loss: 0.031| per_loss: 0.497 | a_loss: 0.584
Train: Epoch [891/3000], Step [60/158]| g_loss: 0.833| d_loss: 0.556| gp_loss: 0.053| r_loss: 0.110| p_loss: 0.175| v_loss: 0.033| per_loss: 0.513 | a_loss: 0.552
Train: Epoch [891/3000], Step [90/158]| g_loss: 0.855| d_loss: 0.591| gp_loss: 0.053| r_loss: 0.100| p_loss: 0.161| v_loss: 0.032| per_loss: 0.512 | a_loss: 0.592
Train: Epoch [891/3000], Step [120/158]| g_loss: 0.794| d_loss: 0.656| gp_loss: 0.055| r_loss: 0.102| p_loss: 0.165| v_loss: 0.033| per_loss: 0.540 | a_loss: 0.523
Train: Epoch [891/3000], Step [150/158]| g_loss: 0.808| d_loss: 0.620| gp_loss: 0.057| r_loss: 0.102| p_loss: 0.164| v_loss: 0.030| per_loss: 0.486 | a_loss: 0.546
Train: Epoch [892/3000], Step [30/158]| g_loss: 0.763| d_loss: 0.721| gp_loss: 0.172| r_loss: 0.100| p_loss: 0.163| v_loss: 0.032| per_loss: 0.499 | a_loss: 0.499
Train: Epoch [892/3000], Step [60/158]| g_loss: 0.798| d_loss: 0.593| gp_loss: 0.051| r_loss: 0.090| p_loss: 0.146| v_loss: 0.029| per_loss: 0.500 | a_loss: 0.556
Train: Epoch [892/3000], Step [90/158]| g_loss: 0.801| d_loss: 0.589| gp_loss: 0.054| r_loss: 0.099| p_loss: 0.160| v_loss: 0.031| per_loss: 0.522 | a_loss: 0.539
Train: Epoch [892/3000], Step [120/158]| g_loss: 0.817| d_loss: 0.545| gp_loss: 0.055| r_loss: 0.091| p_loss: 0.144| v_loss: 0.030| per_loss: 0.472 | a_loss: 0.578
Train: Epoch [892/3000], Step [150/158]| g_loss: 0.777| d_loss: 0.654| gp_loss: 0.053| r_loss: 0.096| p_loss: 0.156| v_loss: 0.030| per_loss: 0.521 | a_loss: 0.521
Train: Epoch [893/3000], Step [30/158]| g_loss: 0.799| d_loss: 0.655| gp_loss: 0.151| r_loss: 0.091| p_loss: 0.147| v_loss: 0.031| per_loss: 0.492 | a_loss: 0.554
Train: Epoch [893/3000], Step [60/158]| g_loss: 0.794| d_loss: 0.582| gp_loss: 0.048| r_loss: 0.095| p_loss: 0.146| v_loss: 0.032| per_loss: 0.477 | a_loss: 0.547
Train: Epoch [893/3000], Step [90/158]| g_loss: 0.790| d_loss: 0.575| gp_loss: 0.053| r_loss: 0.093| p_loss: 0.151| v_loss: 0.032| per_loss: 0.510 | a_loss: 0.539
Train: Epoch [893/3000], Step [120/158]| g_loss: 0.762| d_loss: 0.601| gp_loss: 0.055| r_loss: 0.087| p_loss: 0.140| v_loss: 0.030| per_loss: 0.494 | a_loss: 0.525
Train: Epoch [893/3000], Step [150/158]| g_loss: 0.776| d_loss: 0.622| gp_loss: 0.055| r_loss: 0.094| p_loss: 0.142| v_loss: 0.029| per_loss: 0.491 | a_loss: 0.531
Train: Epoch [894/3000], Step [30/158]| g_loss: 0.828| d_loss: 0.692| gp_loss: 0.188| r_loss: 0.095| p_loss: 0.156| v_loss: 0.033| per_loss: 0.500 | a_loss: 0.573
Train: Epoch [894/3000], Step [60/158]| g_loss: 0.820| d_loss: 0.587| gp_loss: 0.050| r_loss: 0.093| p_loss: 0.151| v_loss: 0.031| per_loss: 0.505 | a_loss: 0.570
Train: Epoch [894/3000], Step [90/158]| g_loss: 0.761| d_loss: 0.604| gp_loss: 0.052| r_loss: 0.094| p_loss: 0.147| v_loss: 0.032| per_loss: 0.492 | a_loss: 0.512
Train: Epoch [894/3000], Step [120/158]| g_loss: 0.828| d_loss: 0.579| gp_loss: 0.053| r_loss: 0.092| p_loss: 0.142| v_loss: 0.030| per_loss: 0.497 | a_loss: 0.585
Train: Epoch [894/3000], Step [150/158]| g_loss: 0.762| d_loss: 0.613| gp_loss: 0.053| r_loss: 0.097| p_loss: 0.147| v_loss: 0.032| per_loss: 0.478 | a_loss: 0.512
Train: Epoch [895/3000], Step [30/158]| g_loss: 0.757| d_loss: 0.705| gp_loss: 0.121| r_loss: 0.093| p_loss: 0.147| v_loss: 0.031| per_loss: 0.489 | a_loss: 0.510
Train: Epoch [895/3000], Step [60/158]| g_loss: 0.791| d_loss: 0.535| gp_loss: 0.053| r_loss: 0.096| p_loss: 0.149| v_loss: 0.030| per_loss: 0.500 | a_loss: 0.540
Train: Epoch [895/3000], Step [90/158]| g_loss: 0.810| d_loss: 0.618| gp_loss: 0.052| r_loss: 0.097| p_loss: 0.151| v_loss: 0.030| per_loss: 0.505 | a_loss: 0.557
Train: Epoch [895/3000], Step [120/158]| g_loss: 0.784| d_loss: 0.607| gp_loss: 0.053| r_loss: 0.098| p_loss: 0.154| v_loss: 0.031| per_loss: 0.489 | a_loss: 0.529
Train: Epoch [895/3000], Step [150/158]| g_loss: 0.748| d_loss: 0.640| gp_loss: 0.053| r_loss: 0.090| p_loss: 0.149| v_loss: 0.030| per_loss: 0.462 | a_loss: 0.508
Train: Epoch [896/3000], Step [30/158]| g_loss: 0.738| d_loss: 0.738| gp_loss: 0.098| r_loss: 0.091| p_loss: 0.147| v_loss: 0.031| per_loss: 0.465 | a_loss: 0.496
Train: Epoch [896/3000], Step [60/158]| g_loss: 0.739| d_loss: 0.669| gp_loss: 0.052| r_loss: 0.091| p_loss: 0.143| v_loss: 0.031| per_loss: 0.451 | a_loss: 0.501
Train: Epoch [896/3000], Step [90/158]| g_loss: 0.706| d_loss: 0.608| gp_loss: 0.058| r_loss: 0.097| p_loss: 0.150| v_loss: 0.029| per_loss: 0.506 | a_loss: 0.455
Train: Epoch [896/3000], Step [120/158]| g_loss: 0.885| d_loss: 0.490| gp_loss: 0.056| r_loss: 0.098| p_loss: 0.152| v_loss: 0.031| per_loss: 0.493 | a_loss: 0.632
Train: Epoch [896/3000], Step [150/158]| g_loss: 0.785| d_loss: 0.553| gp_loss: 0.059| r_loss: 0.092| p_loss: 0.147| v_loss: 0.030| per_loss: 0.503 | a_loss: 0.540
Train: Epoch [897/3000], Step [30/158]| g_loss: 0.799| d_loss: 0.728| gp_loss: 0.169| r_loss: 0.095| p_loss: 0.160| v_loss: 0.031| per_loss: 0.469 | a_loss: 0.546
Train: Epoch [897/3000], Step [60/158]| g_loss: 0.741| d_loss: 0.666| gp_loss: 0.054| r_loss: 0.094| p_loss: 0.150| v_loss: 0.031| per_loss: 0.465 | a_loss: 0.495
Train: Epoch [897/3000], Step [90/158]| g_loss: 0.804| d_loss: 0.556| gp_loss: 0.055| r_loss: 0.092| p_loss: 0.145| v_loss: 0.030| per_loss: 0.482 | a_loss: 0.560
Train: Epoch [897/3000], Step [120/158]| g_loss: 0.784| d_loss: 0.583| gp_loss: 0.060| r_loss: 0.089| p_loss: 0.142| v_loss: 0.031| per_loss: 0.486 | a_loss: 0.544
Train: Epoch [897/3000], Step [150/158]| g_loss: 0.823| d_loss: 0.514| gp_loss: 0.059| r_loss: 0.091| p_loss: 0.139| v_loss: 0.031| per_loss: 0.527 | a_loss: 0.579
Train: Epoch [898/3000], Step [30/158]| g_loss: 0.846| d_loss: 0.687| gp_loss: 0.233| r_loss: 0.092| p_loss: 0.141| v_loss: 0.031| per_loss: 0.491 | a_loss: 0.603
Train: Epoch [898/3000], Step [60/158]| g_loss: 0.789| d_loss: 0.595| gp_loss: 0.051| r_loss: 0.096| p_loss: 0.143| v_loss: 0.032| per_loss: 0.448 | a_loss: 0.544
Train: Epoch [898/3000], Step [90/158]| g_loss: 0.724| d_loss: 0.666| gp_loss: 0.052| r_loss: 0.087| p_loss: 0.137| v_loss: 0.029| per_loss: 0.490 | a_loss: 0.490
Train: Epoch [898/3000], Step [120/158]| g_loss: 0.787| d_loss: 0.593| gp_loss: 0.054| r_loss: 0.090| p_loss: 0.138| v_loss: 0.030| per_loss: 0.506 | a_loss: 0.548
Train: Epoch [898/3000], Step [150/158]| g_loss: 0.804| d_loss: 0.493| gp_loss: 0.058| r_loss: 0.091| p_loss: 0.143| v_loss: 0.029| per_loss: 0.469 | a_loss: 0.565
Train: Epoch [899/3000], Step [30/158]| g_loss: 0.801| d_loss: 0.689| gp_loss: 0.156| r_loss: 0.093| p_loss: 0.144| v_loss: 0.030| per_loss: 0.518 | a_loss: 0.554
Train: Epoch [899/3000], Step [60/158]| g_loss: 0.793| d_loss: 0.492| gp_loss: 0.050| r_loss: 0.088| p_loss: 0.132| v_loss: 0.030| per_loss: 0.485 | a_loss: 0.560
Train: Epoch [899/3000], Step [90/158]| g_loss: 0.768| d_loss: 0.604| gp_loss: 0.052| r_loss: 0.090| p_loss: 0.141| v_loss: 0.031| per_loss: 0.484 | a_loss: 0.528
Train: Epoch [899/3000], Step [120/158]| g_loss: 0.781| d_loss: 0.609| gp_loss: 0.054| r_loss: 0.090| p_loss: 0.141| v_loss: 0.030| per_loss: 0.482 | a_loss: 0.542
Train: Epoch [899/3000], Step [150/158]| g_loss: 0.763| d_loss: 0.667| gp_loss: 0.053| r_loss: 0.093| p_loss: 0.145| v_loss: 0.030| per_loss: 0.497 | a_loss: 0.518
Train: Epoch [900/3000], Step [30/158]| g_loss: 0.802| d_loss: 0.639| gp_loss: 0.121| r_loss: 0.095| p_loss: 0.149| v_loss: 0.032| per_loss: 0.514 | a_loss: 0.550
Train: Epoch [900/3000], Step [60/158]| g_loss: 0.782| d_loss: 0.595| gp_loss: 0.053| r_loss: 0.092| p_loss: 0.141| v_loss: 0.030| per_loss: 0.515 | a_loss: 0.538
Train: Epoch [900/3000], Step [90/158]| g_loss: 0.823| d_loss: 0.533| gp_loss: 0.056| r_loss: 0.089| p_loss: 0.143| v_loss: 0.030| per_loss: 0.533 | a_loss: 0.579
Train: Epoch [900/3000], Step [120/158]| g_loss: 0.769| d_loss: 0.630| gp_loss: 0.056| r_loss: 0.089| p_loss: 0.143| v_loss: 0.028| per_loss: 0.499 | a_loss: 0.530
Train: Epoch [900/3000], Step [150/158]| g_loss: 0.789| d_loss: 0.577| gp_loss: 0.057| r_loss: 0.098| p_loss: 0.151| v_loss: 0.032| per_loss: 0.514 | a_loss: 0.532
Test: Epoch [900/3000]| g_loss: 0.658| r_loss: 0.403| p_loss: 0.300| v_loss: 0.025
Train: Epoch [901/3000], Step [30/158]| g_loss: 0.752| d_loss: 0.599| gp_loss: 0.055| r_loss: 0.094| p_loss: 0.151| v_loss: 0.031| per_loss: 0.540 | a_loss: 0.498
Train: Epoch [901/3000], Step [60/158]| g_loss: 0.790| d_loss: 0.621| gp_loss: 0.055| r_loss: 0.091| p_loss: 0.151| v_loss: 0.030| per_loss: 0.504 | a_loss: 0.543
Train: Epoch [901/3000], Step [90/158]| g_loss: 0.759| d_loss: 0.630| gp_loss: 0.056| r_loss: 0.093| p_loss: 0.147| v_loss: 0.030| per_loss: 0.479 | a_loss: 0.514
Train: Epoch [901/3000], Step [120/158]| g_loss: 0.797| d_loss: 0.577| gp_loss: 0.057| r_loss: 0.093| p_loss: 0.152| v_loss: 0.029| per_loss: 0.483 | a_loss: 0.550
Train: Epoch [901/3000], Step [150/158]| g_loss: 0.809| d_loss: 0.529| gp_loss: 0.062| r_loss: 0.093| p_loss: 0.149| v_loss: 0.030| per_loss: 0.504 | a_loss: 0.561
Train: Epoch [902/3000], Step [30/158]| g_loss: 0.885| d_loss: 0.624| gp_loss: 0.162| r_loss: 0.114| p_loss: 0.170| v_loss: 0.031| per_loss: 0.522 | a_loss: 0.602
Train: Epoch [902/3000], Step [60/158]| g_loss: 0.819| d_loss: 0.578| gp_loss: 0.053| r_loss: 0.097| p_loss: 0.157| v_loss: 0.030| per_loss: 0.497 | a_loss: 0.564
Train: Epoch [902/3000], Step [90/158]| g_loss: 0.800| d_loss: 0.614| gp_loss: 0.055| r_loss: 0.095| p_loss: 0.154| v_loss: 0.031| per_loss: 0.499 | a_loss: 0.548
Train: Epoch [902/3000], Step [120/158]| g_loss: 0.767| d_loss: 0.607| gp_loss: 0.057| r_loss: 0.094| p_loss: 0.145| v_loss: 0.031| per_loss: 0.455 | a_loss: 0.524
Train: Epoch [902/3000], Step [150/158]| g_loss: 0.784| d_loss: 0.563| gp_loss: 0.061| r_loss: 0.092| p_loss: 0.148| v_loss: 0.031| per_loss: 0.547 | a_loss: 0.532
Train: Epoch [903/3000], Step [30/158]| g_loss: 0.831| d_loss: 0.653| gp_loss: 0.174| r_loss: 0.097| p_loss: 0.149| v_loss: 0.030| per_loss: 0.488 | a_loss: 0.581
Train: Epoch [903/3000], Step [60/158]| g_loss: 0.765| d_loss: 0.619| gp_loss: 0.054| r_loss: 0.091| p_loss: 0.148| v_loss: 0.030| per_loss: 0.509 | a_loss: 0.519
Train: Epoch [903/3000], Step [90/158]| g_loss: 0.804| d_loss: 0.603| gp_loss: 0.057| r_loss: 0.090| p_loss: 0.144| v_loss: 0.029| per_loss: 0.524 | a_loss: 0.561
Train: Epoch [903/3000], Step [120/158]| g_loss: 0.808| d_loss: 0.531| gp_loss: 0.056| r_loss: 0.095| p_loss: 0.156| v_loss: 0.030| per_loss: 0.504 | a_loss: 0.554
Train: Epoch [903/3000], Step [150/158]| g_loss: 0.796| d_loss: 0.642| gp_loss: 0.053| r_loss: 0.090| p_loss: 0.152| v_loss: 0.031| per_loss: 0.509 | a_loss: 0.549
Train: Epoch [904/3000], Step [30/158]| g_loss: 0.786| d_loss: 0.730| gp_loss: 0.157| r_loss: 0.094| p_loss: 0.152| v_loss: 0.031| per_loss: 0.542 | a_loss: 0.531
Train: Epoch [904/3000], Step [60/158]| g_loss: 0.795| d_loss: 0.510| gp_loss: 0.055| r_loss: 0.095| p_loss: 0.148| v_loss: 0.031| per_loss: 0.503 | a_loss: 0.545
Train: Epoch [904/3000], Step [90/158]| g_loss: 0.830| d_loss: 0.598| gp_loss: 0.052| r_loss: 0.095| p_loss: 0.148| v_loss: 0.031| per_loss: 0.501 | a_loss: 0.580
Train: Epoch [904/3000], Step [120/158]| g_loss: 0.764| d_loss: 0.594| gp_loss: 0.054| r_loss: 0.093| p_loss: 0.146| v_loss: 0.031| per_loss: 0.494 | a_loss: 0.519
Train: Epoch [904/3000], Step [150/158]| g_loss: 0.816| d_loss: 0.596| gp_loss: 0.057| r_loss: 0.092| p_loss: 0.153| v_loss: 0.031| per_loss: 0.478 | a_loss: 0.568
Train: Epoch [905/3000], Step [30/158]| g_loss: 0.748| d_loss: 0.684| gp_loss: 0.125| r_loss: 0.094| p_loss: 0.148| v_loss: 0.030| per_loss: 0.514 | a_loss: 0.499
Train: Epoch [905/3000], Step [60/158]| g_loss: 0.794| d_loss: 0.565| gp_loss: 0.057| r_loss: 0.095| p_loss: 0.148| v_loss: 0.030| per_loss: 0.506 | a_loss: 0.544
Train: Epoch [905/3000], Step [90/158]| g_loss: 0.812| d_loss: 0.599| gp_loss: 0.054| r_loss: 0.098| p_loss: 0.148| v_loss: 0.030| per_loss: 0.470 | a_loss: 0.563
Train: Epoch [905/3000], Step [120/158]| g_loss: 0.794| d_loss: 0.575| gp_loss: 0.055| r_loss: 0.092| p_loss: 0.146| v_loss: 0.030| per_loss: 0.476 | a_loss: 0.551
Train: Epoch [905/3000], Step [150/158]| g_loss: 0.823| d_loss: 0.602| gp_loss: 0.056| r_loss: 0.092| p_loss: 0.148| v_loss: 0.032| per_loss: 0.498 | a_loss: 0.575
Train: Epoch [906/3000], Step [30/158]| g_loss: 0.788| d_loss: 0.674| gp_loss: 0.134| r_loss: 0.099| p_loss: 0.160| v_loss: 0.032| per_loss: 0.469 | a_loss: 0.531
Train: Epoch [906/3000], Step [60/158]| g_loss: 0.811| d_loss: 0.528| gp_loss: 0.052| r_loss: 0.091| p_loss: 0.147| v_loss: 0.031| per_loss: 0.489 | a_loss: 0.566
Train: Epoch [906/3000], Step [90/158]| g_loss: 0.820| d_loss: 0.578| gp_loss: 0.055| r_loss: 0.095| p_loss: 0.158| v_loss: 0.032| per_loss: 0.516 | a_loss: 0.562
Train: Epoch [906/3000], Step [120/158]| g_loss: 0.792| d_loss: 0.600| gp_loss: 0.060| r_loss: 0.093| p_loss: 0.148| v_loss: 0.030| per_loss: 0.503 | a_loss: 0.545
Train: Epoch [906/3000], Step [150/158]| g_loss: 0.774| d_loss: 0.571| gp_loss: 0.059| r_loss: 0.095| p_loss: 0.148| v_loss: 0.029| per_loss: 0.529 | a_loss: 0.523
Train: Epoch [907/3000], Step [30/158]| g_loss: 0.700| d_loss: 0.861| gp_loss: 0.125| r_loss: 0.092| p_loss: 0.154| v_loss: 0.029| per_loss: 0.503 | a_loss: 0.452
Train: Epoch [907/3000], Step [60/158]| g_loss: 0.821| d_loss: 0.572| gp_loss: 0.055| r_loss: 0.095| p_loss: 0.155| v_loss: 0.031| per_loss: 0.490 | a_loss: 0.568
Train: Epoch [907/3000], Step [90/158]| g_loss: 0.754| d_loss: 0.601| gp_loss: 0.056| r_loss: 0.090| p_loss: 0.147| v_loss: 0.029| per_loss: 0.462 | a_loss: 0.515
Train: Epoch [907/3000], Step [120/158]| g_loss: 0.878| d_loss: 0.469| gp_loss: 0.057| r_loss: 0.096| p_loss: 0.159| v_loss: 0.031| per_loss: 0.536 | a_loss: 0.617
Train: Epoch [907/3000], Step [150/158]| g_loss: 0.865| d_loss: 0.522| gp_loss: 0.056| r_loss: 0.094| p_loss: 0.151| v_loss: 0.032| per_loss: 0.474 | a_loss: 0.615
Train: Epoch [908/3000], Step [30/158]| g_loss: 0.795| d_loss: 0.720| gp_loss: 0.129| r_loss: 0.094| p_loss: 0.155| v_loss: 0.032| per_loss: 0.540 | a_loss: 0.537
Train: Epoch [908/3000], Step [60/158]| g_loss: 0.723| d_loss: 0.624| gp_loss: 0.054| r_loss: 0.099| p_loss: 0.154| v_loss: 0.030| per_loss: 0.475 | a_loss: 0.470
Train: Epoch [908/3000], Step [90/158]| g_loss: 0.805| d_loss: 0.576| gp_loss: 0.056| r_loss: 0.092| p_loss: 0.149| v_loss: 0.030| per_loss: 0.522 | a_loss: 0.557
Train: Epoch [908/3000], Step [120/158]| g_loss: 0.768| d_loss: 0.593| gp_loss: 0.055| r_loss: 0.091| p_loss: 0.147| v_loss: 0.029| per_loss: 0.473 | a_loss: 0.527
Train: Epoch [908/3000], Step [150/158]| g_loss: 0.840| d_loss: 0.590| gp_loss: 0.057| r_loss: 0.097| p_loss: 0.156| v_loss: 0.031| per_loss: 0.490 | a_loss: 0.585
Train: Epoch [909/3000], Step [30/158]| g_loss: 0.785| d_loss: 0.682| gp_loss: 0.191| r_loss: 0.088| p_loss: 0.139| v_loss: 0.030| per_loss: 0.495 | a_loss: 0.548
Train: Epoch [909/3000], Step [60/158]| g_loss: 0.770| d_loss: 0.653| gp_loss: 0.047| r_loss: 0.095| p_loss: 0.152| v_loss: 0.032| per_loss: 0.504 | a_loss: 0.517
Train: Epoch [909/3000], Step [90/158]| g_loss: 0.782| d_loss: 0.607| gp_loss: 0.053| r_loss: 0.091| p_loss: 0.143| v_loss: 0.030| per_loss: 0.510 | a_loss: 0.538
Train: Epoch [909/3000], Step [120/158]| g_loss: 0.768| d_loss: 0.622| gp_loss: 0.054| r_loss: 0.092| p_loss: 0.150| v_loss: 0.031| per_loss: 0.475 | a_loss: 0.523
Train: Epoch [909/3000], Step [150/158]| g_loss: 0.825| d_loss: 0.517| gp_loss: 0.055| r_loss: 0.090| p_loss: 0.142| v_loss: 0.031| per_loss: 0.534 | a_loss: 0.580
Train: Epoch [910/3000], Step [30/158]| g_loss: 0.754| d_loss: 0.665| gp_loss: 0.089| r_loss: 0.093| p_loss: 0.143| v_loss: 0.029| per_loss: 0.487 | a_loss: 0.511
Train: Epoch [910/3000], Step [60/158]| g_loss: 0.778| d_loss: 0.618| gp_loss: 0.053| r_loss: 0.091| p_loss: 0.143| v_loss: 0.029| per_loss: 0.445 | a_loss: 0.541
Train: Epoch [910/3000], Step [90/158]| g_loss: 0.766| d_loss: 0.583| gp_loss: 0.053| r_loss: 0.090| p_loss: 0.144| v_loss: 0.030| per_loss: 0.521 | a_loss: 0.522
Train: Epoch [910/3000], Step [120/158]| g_loss: 0.822| d_loss: 0.593| gp_loss: 0.055| r_loss: 0.092| p_loss: 0.150| v_loss: 0.029| per_loss: 0.516 | a_loss: 0.575
Train: Epoch [910/3000], Step [150/158]| g_loss: 0.713| d_loss: 0.635| gp_loss: 0.056| r_loss: 0.097| p_loss: 0.148| v_loss: 0.030| per_loss: 0.498 | a_loss: 0.462
Train: Epoch [911/3000], Step [30/158]| g_loss: 0.808| d_loss: 0.625| gp_loss: 0.119| r_loss: 0.090| p_loss: 0.145| v_loss: 0.029| per_loss: 0.472 | a_loss: 0.569
Train: Epoch [911/3000], Step [60/158]| g_loss: 0.818| d_loss: 0.559| gp_loss: 0.054| r_loss: 0.090| p_loss: 0.136| v_loss: 0.029| per_loss: 0.499 | a_loss: 0.581
Train: Epoch [911/3000], Step [90/158]| g_loss: 0.786| d_loss: 0.583| gp_loss: 0.057| r_loss: 0.090| p_loss: 0.139| v_loss: 0.030| per_loss: 0.494 | a_loss: 0.547
Train: Epoch [911/3000], Step [120/158]| g_loss: 0.736| d_loss: 0.685| gp_loss: 0.056| r_loss: 0.094| p_loss: 0.153| v_loss: 0.030| per_loss: 0.474 | a_loss: 0.488
Train: Epoch [911/3000], Step [150/158]| g_loss: 0.779| d_loss: 0.605| gp_loss: 0.061| r_loss: 0.091| p_loss: 0.148| v_loss: 0.030| per_loss: 0.501 | a_loss: 0.535
Train: Epoch [912/3000], Step [30/158]| g_loss: 0.790| d_loss: 0.678| gp_loss: 0.163| r_loss: 0.096| p_loss: 0.151| v_loss: 0.031| per_loss: 0.482 | a_loss: 0.539
Train: Epoch [912/3000], Step [60/158]| g_loss: 0.783| d_loss: 0.593| gp_loss: 0.053| r_loss: 0.090| p_loss: 0.145| v_loss: 0.031| per_loss: 0.461 | a_loss: 0.543
Train: Epoch [912/3000], Step [90/158]| g_loss: 0.836| d_loss: 0.550| gp_loss: 0.057| r_loss: 0.089| p_loss: 0.141| v_loss: 0.030| per_loss: 0.475 | a_loss: 0.599
Train: Epoch [912/3000], Step [120/158]| g_loss: 0.797| d_loss: 0.566| gp_loss: 0.058| r_loss: 0.092| p_loss: 0.144| v_loss: 0.031| per_loss: 0.528 | a_loss: 0.549
Train: Epoch [912/3000], Step [150/158]| g_loss: 0.782| d_loss: 0.599| gp_loss: 0.059| r_loss: 0.095| p_loss: 0.143| v_loss: 0.029| per_loss: 0.511 | a_loss: 0.536
Train: Epoch [913/3000], Step [30/158]| g_loss: 0.813| d_loss: 0.686| gp_loss: 0.182| r_loss: 0.089| p_loss: 0.140| v_loss: 0.029| per_loss: 0.476 | a_loss: 0.577
Train: Epoch [913/3000], Step [60/158]| g_loss: 0.757| d_loss: 0.584| gp_loss: 0.057| r_loss: 0.094| p_loss: 0.141| v_loss: 0.029| per_loss: 0.476 | a_loss: 0.517
Train: Epoch [913/3000], Step [90/158]| g_loss: 0.799| d_loss: 0.634| gp_loss: 0.054| r_loss: 0.093| p_loss: 0.153| v_loss: 0.030| per_loss: 0.506 | a_loss: 0.548
Train: Epoch [913/3000], Step [120/158]| g_loss: 0.806| d_loss: 0.538| gp_loss: 0.054| r_loss: 0.093| p_loss: 0.149| v_loss: 0.029| per_loss: 0.514 | a_loss: 0.558
Train: Epoch [913/3000], Step [150/158]| g_loss: 0.792| d_loss: 0.606| gp_loss: 0.057| r_loss: 0.089| p_loss: 0.144| v_loss: 0.030| per_loss: 0.517 | a_loss: 0.549
Train: Epoch [914/3000], Step [30/158]| g_loss: 0.777| d_loss: 0.755| gp_loss: 0.190| r_loss: 0.092| p_loss: 0.141| v_loss: 0.029| per_loss: 0.514 | a_loss: 0.534
Train: Epoch [914/3000], Step [60/158]| g_loss: 0.766| d_loss: 0.569| gp_loss: 0.051| r_loss: 0.091| p_loss: 0.142| v_loss: 0.030| per_loss: 0.491 | a_loss: 0.526
Train: Epoch [914/3000], Step [90/158]| g_loss: 0.751| d_loss: 0.622| gp_loss: 0.053| r_loss: 0.088| p_loss: 0.139| v_loss: 0.029| per_loss: 0.476 | a_loss: 0.517
Train: Epoch [914/3000], Step [120/158]| g_loss: 0.802| d_loss: 0.546| gp_loss: 0.054| r_loss: 0.090| p_loss: 0.142| v_loss: 0.029| per_loss: 0.484 | a_loss: 0.564
Train: Epoch [914/3000], Step [150/158]| g_loss: 0.756| d_loss: 0.604| gp_loss: 0.053| r_loss: 0.093| p_loss: 0.142| v_loss: 0.030| per_loss: 0.515 | a_loss: 0.511
Train: Epoch [915/3000], Step [30/158]| g_loss: 0.809| d_loss: 0.606| gp_loss: 0.126| r_loss: 0.089| p_loss: 0.141| v_loss: 0.030| per_loss: 0.487 | a_loss: 0.570
Train: Epoch [915/3000], Step [60/158]| g_loss: 0.735| d_loss: 0.637| gp_loss: 0.051| r_loss: 0.088| p_loss: 0.138| v_loss: 0.030| per_loss: 0.501 | a_loss: 0.497
Train: Epoch [915/3000], Step [90/158]| g_loss: 0.798| d_loss: 0.547| gp_loss: 0.057| r_loss: 0.094| p_loss: 0.141| v_loss: 0.031| per_loss: 0.485 | a_loss: 0.554
Train: Epoch [915/3000], Step [120/158]| g_loss: 0.819| d_loss: 0.542| gp_loss: 0.058| r_loss: 0.091| p_loss: 0.141| v_loss: 0.030| per_loss: 0.476 | a_loss: 0.579
Train: Epoch [915/3000], Step [150/158]| g_loss: 0.798| d_loss: 0.580| gp_loss: 0.056| r_loss: 0.091| p_loss: 0.144| v_loss: 0.028| per_loss: 0.513 | a_loss: 0.556
Train: Epoch [916/3000], Step [30/158]| g_loss: 0.723| d_loss: 0.732| gp_loss: 0.080| r_loss: 0.098| p_loss: 0.166| v_loss: 0.029| per_loss: 0.500 | a_loss: 0.464
Train: Epoch [916/3000], Step [60/158]| g_loss: 0.815| d_loss: 0.574| gp_loss: 0.060| r_loss: 0.097| p_loss: 0.160| v_loss: 0.030| per_loss: 0.513 | a_loss: 0.556
Train: Epoch [916/3000], Step [90/158]| g_loss: 0.824| d_loss: 0.580| gp_loss: 0.061| r_loss: 0.093| p_loss: 0.155| v_loss: 0.029| per_loss: 0.491 | a_loss: 0.575
Train: Epoch [916/3000], Step [120/158]| g_loss: 0.774| d_loss: 0.612| gp_loss: 0.059| r_loss: 0.094| p_loss: 0.155| v_loss: 0.030| per_loss: 0.493 | a_loss: 0.523
Train: Epoch [916/3000], Step [150/158]| g_loss: 0.801| d_loss: 0.592| gp_loss: 0.062| r_loss: 0.095| p_loss: 0.156| v_loss: 0.031| per_loss: 0.526 | a_loss: 0.544
Train: Epoch [917/3000], Step [30/158]| g_loss: 0.809| d_loss: 0.681| gp_loss: 0.139| r_loss: 0.093| p_loss: 0.156| v_loss: 0.030| per_loss: 0.504 | a_loss: 0.558
Train: Epoch [917/3000], Step [60/158]| g_loss: 0.787| d_loss: 0.576| gp_loss: 0.061| r_loss: 0.095| p_loss: 0.155| v_loss: 0.031| per_loss: 0.484 | a_loss: 0.535
Train: Epoch [917/3000], Step [90/158]| g_loss: 0.858| d_loss: 0.571| gp_loss: 0.058| r_loss: 0.093| p_loss: 0.152| v_loss: 0.031| per_loss: 0.512 | a_loss: 0.607
Train: Epoch [917/3000], Step [120/158]| g_loss: 0.798| d_loss: 0.554| gp_loss: 0.061| r_loss: 0.095| p_loss: 0.152| v_loss: 0.031| per_loss: 0.517 | a_loss: 0.544
Train: Epoch [917/3000], Step [150/158]| g_loss: 0.804| d_loss: 0.618| gp_loss: 0.060| r_loss: 0.094| p_loss: 0.154| v_loss: 0.030| per_loss: 0.482 | a_loss: 0.555
Train: Epoch [918/3000], Step [30/158]| g_loss: 0.822| d_loss: 0.716| gp_loss: 0.224| r_loss: 0.095| p_loss: 0.156| v_loss: 0.031| per_loss: 0.522 | a_loss: 0.566
Train: Epoch [918/3000], Step [60/158]| g_loss: 0.786| d_loss: 0.599| gp_loss: 0.051| r_loss: 0.093| p_loss: 0.146| v_loss: 0.030| per_loss: 0.505 | a_loss: 0.539
Train: Epoch [918/3000], Step [90/158]| g_loss: 0.736| d_loss: 0.668| gp_loss: 0.056| r_loss: 0.091| p_loss: 0.148| v_loss: 0.030| per_loss: 0.491 | a_loss: 0.492
Train: Epoch [918/3000], Step [120/158]| g_loss: 0.860| d_loss: 0.495| gp_loss: 0.057| r_loss: 0.091| p_loss: 0.151| v_loss: 0.030| per_loss: 0.480 | a_loss: 0.615
Train: Epoch [918/3000], Step [150/158]| g_loss: 0.754| d_loss: 0.608| gp_loss: 0.055| r_loss: 0.091| p_loss: 0.144| v_loss: 0.030| per_loss: 0.488 | a_loss: 0.512
Train: Epoch [919/3000], Step [30/158]| g_loss: 0.751| d_loss: 0.673| gp_loss: 0.098| r_loss: 0.090| p_loss: 0.139| v_loss: 0.030| per_loss: 0.483 | a_loss: 0.513
Train: Epoch [919/3000], Step [60/158]| g_loss: 0.747| d_loss: 0.636| gp_loss: 0.060| r_loss: 0.087| p_loss: 0.146| v_loss: 0.030| per_loss: 0.490 | a_loss: 0.508
Train: Epoch [919/3000], Step [90/158]| g_loss: 0.785| d_loss: 0.524| gp_loss: 0.056| r_loss: 0.094| p_loss: 0.143| v_loss: 0.031| per_loss: 0.526 | a_loss: 0.537
Train: Epoch [919/3000], Step [120/158]| g_loss: 0.795| d_loss: 0.653| gp_loss: 0.058| r_loss: 0.093| p_loss: 0.148| v_loss: 0.029| per_loss: 0.477 | a_loss: 0.552
Train: Epoch [919/3000], Step [150/158]| g_loss: 0.756| d_loss: 0.617| gp_loss: 0.059| r_loss: 0.091| p_loss: 0.142| v_loss: 0.030| per_loss: 0.477 | a_loss: 0.517
Train: Epoch [920/3000], Step [30/158]| g_loss: 0.744| d_loss: 0.733| gp_loss: 0.173| r_loss: 0.087| p_loss: 0.137| v_loss: 0.029| per_loss: 0.486 | a_loss: 0.510
Train: Epoch [920/3000], Step [60/158]| g_loss: 0.804| d_loss: 0.575| gp_loss: 0.055| r_loss: 0.093| p_loss: 0.140| v_loss: 0.031| per_loss: 0.470 | a_loss: 0.563
Train: Epoch [920/3000], Step [90/158]| g_loss: 0.778| d_loss: 0.567| gp_loss: 0.055| r_loss: 0.086| p_loss: 0.137| v_loss: 0.029| per_loss: 0.522 | a_loss: 0.542
Train: Epoch [920/3000], Step [120/158]| g_loss: 0.766| d_loss: 0.645| gp_loss: 0.054| r_loss: 0.090| p_loss: 0.141| v_loss: 0.030| per_loss: 0.508 | a_loss: 0.524
Train: Epoch [920/3000], Step [150/158]| g_loss: 0.803| d_loss: 0.524| gp_loss: 0.059| r_loss: 0.095| p_loss: 0.144| v_loss: 0.030| per_loss: 0.491 | a_loss: 0.556
Train: Epoch [921/3000], Step [30/158]| g_loss: 0.955| d_loss: 0.561| gp_loss: 0.128| r_loss: 0.101| p_loss: 0.170| v_loss: 0.029| per_loss: 0.568 | a_loss: 0.683
Train: Epoch [921/3000], Step [60/158]| g_loss: 0.799| d_loss: 0.594| gp_loss: 0.051| r_loss: 0.097| p_loss: 0.157| v_loss: 0.030| per_loss: 0.551 | a_loss: 0.538
Train: Epoch [921/3000], Step [90/158]| g_loss: 0.809| d_loss: 0.602| gp_loss: 0.054| r_loss: 0.098| p_loss: 0.156| v_loss: 0.029| per_loss: 0.522 | a_loss: 0.552
Train: Epoch [921/3000], Step [120/158]| g_loss: 0.764| d_loss: 0.621| gp_loss: 0.057| r_loss: 0.092| p_loss: 0.149| v_loss: 0.030| per_loss: 0.508 | a_loss: 0.518
Train: Epoch [921/3000], Step [150/158]| g_loss: 0.794| d_loss: 0.620| gp_loss: 0.057| r_loss: 0.095| p_loss: 0.152| v_loss: 0.030| per_loss: 0.532 | a_loss: 0.540
Train: Epoch [922/3000], Step [30/158]| g_loss: 0.827| d_loss: 0.639| gp_loss: 0.156| r_loss: 0.094| p_loss: 0.149| v_loss: 0.030| per_loss: 0.556 | a_loss: 0.573
Train: Epoch [922/3000], Step [60/158]| g_loss: 0.817| d_loss: 0.524| gp_loss: 0.055| r_loss: 0.089| p_loss: 0.143| v_loss: 0.029| per_loss: 0.526 | a_loss: 0.575
Train: Epoch [922/3000], Step [90/158]| g_loss: 0.833| d_loss: 0.566| gp_loss: 0.054| r_loss: 0.098| p_loss: 0.152| v_loss: 0.029| per_loss: 0.555 | a_loss: 0.575
Train: Epoch [922/3000], Step [120/158]| g_loss: 0.715| d_loss: 0.717| gp_loss: 0.057| r_loss: 0.091| p_loss: 0.151| v_loss: 0.028| per_loss: 0.473 | a_loss: 0.472
Train: Epoch [922/3000], Step [150/158]| g_loss: 0.794| d_loss: 0.587| gp_loss: 0.059| r_loss: 0.093| p_loss: 0.145| v_loss: 0.030| per_loss: 0.534 | a_loss: 0.546
Train: Epoch [923/3000], Step [30/158]| g_loss: 0.797| d_loss: 0.633| gp_loss: 0.128| r_loss: 0.091| p_loss: 0.150| v_loss: 0.029| per_loss: 0.488 | a_loss: 0.552
Train: Epoch [923/3000], Step [60/158]| g_loss: 0.828| d_loss: 0.668| gp_loss: 0.054| r_loss: 0.093| p_loss: 0.160| v_loss: 0.029| per_loss: 0.562 | a_loss: 0.569
Train: Epoch [923/3000], Step [90/158]| g_loss: 0.784| d_loss: 0.535| gp_loss: 0.058| r_loss: 0.101| p_loss: 0.158| v_loss: 0.030| per_loss: 0.553 | a_loss: 0.518
Train: Epoch [923/3000], Step [120/158]| g_loss: 0.828| d_loss: 0.605| gp_loss: 0.056| r_loss: 0.093| p_loss: 0.149| v_loss: 0.028| per_loss: 0.528 | a_loss: 0.579
Train: Epoch [923/3000], Step [150/158]| g_loss: 0.820| d_loss: 0.581| gp_loss: 0.057| r_loss: 0.095| p_loss: 0.151| v_loss: 0.030| per_loss: 0.475 | a_loss: 0.572
Train: Epoch [924/3000], Step [30/158]| g_loss: 0.793| d_loss: 0.686| gp_loss: 0.072| r_loss: 0.103| p_loss: 0.176| v_loss: 0.031| per_loss: 0.535 | a_loss: 0.518
Train: Epoch [924/3000], Step [60/158]| g_loss: 0.868| d_loss: 0.609| gp_loss: 0.055| r_loss: 0.101| p_loss: 0.165| v_loss: 0.030| per_loss: 0.513 | a_loss: 0.603
Train: Epoch [924/3000], Step [90/158]| g_loss: 0.765| d_loss: 0.622| gp_loss: 0.060| r_loss: 0.095| p_loss: 0.154| v_loss: 0.031| per_loss: 0.526 | a_loss: 0.509
Train: Epoch [924/3000], Step [120/158]| g_loss: 0.814| d_loss: 0.594| gp_loss: 0.060| r_loss: 0.092| p_loss: 0.151| v_loss: 0.030| per_loss: 0.506 | a_loss: 0.565
Train: Epoch [924/3000], Step [150/158]| g_loss: 0.828| d_loss: 0.519| gp_loss: 0.057| r_loss: 0.096| p_loss: 0.148| v_loss: 0.031| per_loss: 0.541 | a_loss: 0.572
Train: Epoch [925/3000], Step [30/158]| g_loss: 0.752| d_loss: 0.714| gp_loss: 0.092| r_loss: 0.091| p_loss: 0.150| v_loss: 0.028| per_loss: 0.542 | a_loss: 0.503
Train: Epoch [925/3000], Step [60/158]| g_loss: 0.772| d_loss: 0.602| gp_loss: 0.060| r_loss: 0.093| p_loss: 0.141| v_loss: 0.030| per_loss: 0.501 | a_loss: 0.529
Train: Epoch [925/3000], Step [90/158]| g_loss: 0.814| d_loss: 0.533| gp_loss: 0.062| r_loss: 0.094| p_loss: 0.152| v_loss: 0.029| per_loss: 0.515 | a_loss: 0.563
Train: Epoch [925/3000], Step [120/158]| g_loss: 0.825| d_loss: 0.562| gp_loss: 0.059| r_loss: 0.091| p_loss: 0.142| v_loss: 0.030| per_loss: 0.531 | a_loss: 0.581
Train: Epoch [925/3000], Step [150/158]| g_loss: 0.822| d_loss: 0.584| gp_loss: 0.060| r_loss: 0.094| p_loss: 0.153| v_loss: 0.030| per_loss: 0.510 | a_loss: 0.571
Train: Epoch [926/3000], Step [30/158]| g_loss: 0.768| d_loss: 0.742| gp_loss: 0.195| r_loss: 0.094| p_loss: 0.144| v_loss: 0.030| per_loss: 0.522 | a_loss: 0.520
Train: Epoch [926/3000], Step [60/158]| g_loss: 0.827| d_loss: 0.600| gp_loss: 0.055| r_loss: 0.090| p_loss: 0.150| v_loss: 0.030| per_loss: 0.535 | a_loss: 0.579
Train: Epoch [926/3000], Step [90/158]| g_loss: 0.771| d_loss: 0.657| gp_loss: 0.055| r_loss: 0.097| p_loss: 0.156| v_loss: 0.029| per_loss: 0.479 | a_loss: 0.519
Train: Epoch [926/3000], Step [120/158]| g_loss: 0.757| d_loss: 0.560| gp_loss: 0.060| r_loss: 0.090| p_loss: 0.149| v_loss: 0.030| per_loss: 0.530 | a_loss: 0.509
Train: Epoch [926/3000], Step [150/158]| g_loss: 0.818| d_loss: 0.552| gp_loss: 0.061| r_loss: 0.095| p_loss: 0.153| v_loss: 0.030| per_loss: 0.478 | a_loss: 0.569
Train: Epoch [927/3000], Step [30/158]| g_loss: 0.819| d_loss: 0.685| gp_loss: 0.181| r_loss: 0.093| p_loss: 0.145| v_loss: 0.030| per_loss: 0.510 | a_loss: 0.572
Train: Epoch [927/3000], Step [60/158]| g_loss: 0.831| d_loss: 0.594| gp_loss: 0.053| r_loss: 0.094| p_loss: 0.151| v_loss: 0.031| per_loss: 0.513 | a_loss: 0.580
Train: Epoch [927/3000], Step [90/158]| g_loss: 0.761| d_loss: 0.663| gp_loss: 0.052| r_loss: 0.092| p_loss: 0.151| v_loss: 0.029| per_loss: 0.497 | a_loss: 0.515
Train: Epoch [927/3000], Step [120/158]| g_loss: 0.840| d_loss: 0.483| gp_loss: 0.055| r_loss: 0.095| p_loss: 0.147| v_loss: 0.030| per_loss: 0.536 | a_loss: 0.588
Train: Epoch [927/3000], Step [150/158]| g_loss: 0.722| d_loss: 0.630| gp_loss: 0.058| r_loss: 0.091| p_loss: 0.143| v_loss: 0.030| per_loss: 0.503 | a_loss: 0.479
Train: Epoch [928/3000], Step [30/158]| g_loss: 0.828| d_loss: 0.693| gp_loss: 0.162| r_loss: 0.087| p_loss: 0.136| v_loss: 0.029| per_loss: 0.479 | a_loss: 0.595
Train: Epoch [928/3000], Step [60/158]| g_loss: 0.730| d_loss: 0.661| gp_loss: 0.051| r_loss: 0.092| p_loss: 0.138| v_loss: 0.029| per_loss: 0.514 | a_loss: 0.489
Train: Epoch [928/3000], Step [90/158]| g_loss: 0.736| d_loss: 0.646| gp_loss: 0.055| r_loss: 0.090| p_loss: 0.139| v_loss: 0.028| per_loss: 0.511 | a_loss: 0.498
Train: Epoch [928/3000], Step [120/158]| g_loss: 0.835| d_loss: 0.467| gp_loss: 0.050| r_loss: 0.102| p_loss: 0.149| v_loss: 0.030| per_loss: 0.535 | a_loss: 0.574
Train: Epoch [928/3000], Step [150/158]| g_loss: 0.865| d_loss: 0.482| gp_loss: 0.056| r_loss: 0.104| p_loss: 0.151| v_loss: 0.030| per_loss: 0.510 | a_loss: 0.604
Train: Epoch [929/3000], Step [30/158]| g_loss: 0.784| d_loss: 0.682| gp_loss: 0.143| r_loss: 0.091| p_loss: 0.147| v_loss: 0.029| per_loss: 0.499 | a_loss: 0.540
Train: Epoch [929/3000], Step [60/158]| g_loss: 0.753| d_loss: 0.641| gp_loss: 0.051| r_loss: 0.092| p_loss: 0.147| v_loss: 0.029| per_loss: 0.507 | a_loss: 0.507
Train: Epoch [929/3000], Step [90/158]| g_loss: 0.812| d_loss: 0.590| gp_loss: 0.056| r_loss: 0.095| p_loss: 0.148| v_loss: 0.030| per_loss: 0.550 | a_loss: 0.558
Train: Epoch [929/3000], Step [120/158]| g_loss: 0.815| d_loss: 0.531| gp_loss: 0.061| r_loss: 0.093| p_loss: 0.147| v_loss: 0.031| per_loss: 0.478 | a_loss: 0.570
Train: Epoch [929/3000], Step [150/158]| g_loss: 0.847| d_loss: 0.549| gp_loss: 0.061| r_loss: 0.091| p_loss: 0.141| v_loss: 0.031| per_loss: 0.520 | a_loss: 0.602
Train: Epoch [930/3000], Step [30/158]| g_loss: 0.773| d_loss: 0.634| gp_loss: 0.113| r_loss: 0.094| p_loss: 0.145| v_loss: 0.030| per_loss: 0.504 | a_loss: 0.526
Train: Epoch [930/3000], Step [60/158]| g_loss: 0.789| d_loss: 0.613| gp_loss: 0.055| r_loss: 0.095| p_loss: 0.152| v_loss: 0.031| per_loss: 0.505 | a_loss: 0.537
Train: Epoch [930/3000], Step [90/158]| g_loss: 0.870| d_loss: 0.540| gp_loss: 0.055| r_loss: 0.093| p_loss: 0.153| v_loss: 0.029| per_loss: 0.510 | a_loss: 0.620
Train: Epoch [930/3000], Step [120/158]| g_loss: 0.785| d_loss: 0.613| gp_loss: 0.058| r_loss: 0.094| p_loss: 0.158| v_loss: 0.030| per_loss: 0.485 | a_loss: 0.534
Train: Epoch [930/3000], Step [150/158]| g_loss: 0.812| d_loss: 0.568| gp_loss: 0.057| r_loss: 0.095| p_loss: 0.150| v_loss: 0.030| per_loss: 0.519 | a_loss: 0.560
Train: Epoch [931/3000], Step [30/158]| g_loss: 0.777| d_loss: 0.739| gp_loss: 0.155| r_loss: 0.092| p_loss: 0.146| v_loss: 0.030| per_loss: 0.497 | a_loss: 0.533
Train: Epoch [931/3000], Step [60/158]| g_loss: 0.786| d_loss: 0.612| gp_loss: 0.052| r_loss: 0.093| p_loss: 0.149| v_loss: 0.030| per_loss: 0.514 | a_loss: 0.537
Train: Epoch [931/3000], Step [90/158]| g_loss: 0.791| d_loss: 0.581| gp_loss: 0.056| r_loss: 0.091| p_loss: 0.144| v_loss: 0.031| per_loss: 0.490 | a_loss: 0.548
Train: Epoch [931/3000], Step [120/158]| g_loss: 0.794| d_loss: 0.516| gp_loss: 0.061| r_loss: 0.093| p_loss: 0.146| v_loss: 0.030| per_loss: 0.493 | a_loss: 0.550
Train: Epoch [931/3000], Step [150/158]| g_loss: 0.856| d_loss: 0.612| gp_loss: 0.054| r_loss: 0.097| p_loss: 0.160| v_loss: 0.031| per_loss: 0.522 | a_loss: 0.597
Train: Epoch [932/3000], Step [30/158]| g_loss: 0.764| d_loss: 0.707| gp_loss: 0.131| r_loss: 0.092| p_loss: 0.157| v_loss: 0.029| per_loss: 0.460 | a_loss: 0.518
Train: Epoch [932/3000], Step [60/158]| g_loss: 0.791| d_loss: 0.594| gp_loss: 0.055| r_loss: 0.092| p_loss: 0.146| v_loss: 0.030| per_loss: 0.493 | a_loss: 0.547
Train: Epoch [932/3000], Step [90/158]| g_loss: 0.771| d_loss: 0.602| gp_loss: 0.055| r_loss: 0.095| p_loss: 0.151| v_loss: 0.031| per_loss: 0.483 | a_loss: 0.520
Train: Epoch [932/3000], Step [120/158]| g_loss: 0.829| d_loss: 0.591| gp_loss: 0.058| r_loss: 0.092| p_loss: 0.148| v_loss: 0.030| per_loss: 0.522 | a_loss: 0.582
Train: Epoch [932/3000], Step [150/158]| g_loss: 0.753| d_loss: 0.590| gp_loss: 0.057| r_loss: 0.089| p_loss: 0.142| v_loss: 0.029| per_loss: 0.500 | a_loss: 0.514
Train: Epoch [933/3000], Step [30/158]| g_loss: 0.878| d_loss: 0.578| gp_loss: 0.137| r_loss: 0.090| p_loss: 0.144| v_loss: 0.030| per_loss: 0.496 | a_loss: 0.636
Train: Epoch [933/3000], Step [60/158]| g_loss: 0.720| d_loss: 0.663| gp_loss: 0.054| r_loss: 0.091| p_loss: 0.146| v_loss: 0.029| per_loss: 0.489 | a_loss: 0.478
Train: Epoch [933/3000], Step [90/158]| g_loss: 0.819| d_loss: 0.563| gp_loss: 0.057| r_loss: 0.094| p_loss: 0.152| v_loss: 0.031| per_loss: 0.488 | a_loss: 0.570
Train: Epoch [933/3000], Step [120/158]| g_loss: 0.839| d_loss: 0.553| gp_loss: 0.060| r_loss: 0.095| p_loss: 0.150| v_loss: 0.030| per_loss: 0.496 | a_loss: 0.590
Train: Epoch [933/3000], Step [150/158]| g_loss: 0.790| d_loss: 0.606| gp_loss: 0.057| r_loss: 0.093| p_loss: 0.151| v_loss: 0.029| per_loss: 0.478 | a_loss: 0.545
Train: Epoch [934/3000], Step [30/158]| g_loss: 0.830| d_loss: 0.690| gp_loss: 0.180| r_loss: 0.094| p_loss: 0.167| v_loss: 0.030| per_loss: 0.509 | a_loss: 0.572
Train: Epoch [934/3000], Step [60/158]| g_loss: 0.811| d_loss: 0.611| gp_loss: 0.052| r_loss: 0.094| p_loss: 0.150| v_loss: 0.030| per_loss: 0.475 | a_loss: 0.565
Train: Epoch [934/3000], Step [90/158]| g_loss: 0.776| d_loss: 0.577| gp_loss: 0.054| r_loss: 0.092| p_loss: 0.146| v_loss: 0.031| per_loss: 0.474 | a_loss: 0.533
Train: Epoch [934/3000], Step [120/158]| g_loss: 0.816| d_loss: 0.611| gp_loss: 0.054| r_loss: 0.093| p_loss: 0.154| v_loss: 0.030| per_loss: 0.526 | a_loss: 0.563
Train: Epoch [934/3000], Step [150/158]| g_loss: 0.764| d_loss: 0.629| gp_loss: 0.057| r_loss: 0.096| p_loss: 0.156| v_loss: 0.030| per_loss: 0.487 | a_loss: 0.512
Train: Epoch [935/3000], Step [30/158]| g_loss: 0.822| d_loss: 0.716| gp_loss: 0.211| r_loss: 0.095| p_loss: 0.148| v_loss: 0.030| per_loss: 0.460 | a_loss: 0.576
Train: Epoch [935/3000], Step [60/158]| g_loss: 0.730| d_loss: 0.640| gp_loss: 0.050| r_loss: 0.094| p_loss: 0.148| v_loss: 0.031| per_loss: 0.470 | a_loss: 0.485
Train: Epoch [935/3000], Step [90/158]| g_loss: 0.783| d_loss: 0.605| gp_loss: 0.053| r_loss: 0.087| p_loss: 0.133| v_loss: 0.030| per_loss: 0.473 | a_loss: 0.552
Train: Epoch [935/3000], Step [120/158]| g_loss: 0.812| d_loss: 0.505| gp_loss: 0.054| r_loss: 0.089| p_loss: 0.138| v_loss: 0.030| per_loss: 0.533 | a_loss: 0.572
Train: Epoch [935/3000], Step [150/158]| g_loss: 0.749| d_loss: 0.683| gp_loss: 0.052| r_loss: 0.091| p_loss: 0.143| v_loss: 0.031| per_loss: 0.498 | a_loss: 0.506
Train: Epoch [936/3000], Step [30/158]| g_loss: 0.816| d_loss: 0.651| gp_loss: 0.122| r_loss: 0.094| p_loss: 0.149| v_loss: 0.031| per_loss: 0.489 | a_loss: 0.568
Train: Epoch [936/3000], Step [60/158]| g_loss: 0.798| d_loss: 0.599| gp_loss: 0.052| r_loss: 0.090| p_loss: 0.146| v_loss: 0.030| per_loss: 0.512 | a_loss: 0.554
Train: Epoch [936/3000], Step [90/158]| g_loss: 0.819| d_loss: 0.590| gp_loss: 0.052| r_loss: 0.092| p_loss: 0.144| v_loss: 0.030| per_loss: 0.498 | a_loss: 0.575
Train: Epoch [936/3000], Step [120/158]| g_loss: 0.753| d_loss: 0.590| gp_loss: 0.052| r_loss: 0.088| p_loss: 0.136| v_loss: 0.029| per_loss: 0.504 | a_loss: 0.516
Train: Epoch [936/3000], Step [150/158]| g_loss: 0.838| d_loss: 0.578| gp_loss: 0.054| r_loss: 0.090| p_loss: 0.140| v_loss: 0.030| per_loss: 0.462 | a_loss: 0.603
Train: Epoch [937/3000], Step [30/158]| g_loss: 0.703| d_loss: 0.727| gp_loss: 0.100| r_loss: 0.090| p_loss: 0.144| v_loss: 0.030| per_loss: 0.485 | a_loss: 0.463
Train: Epoch [937/3000], Step [60/158]| g_loss: 0.737| d_loss: 0.707| gp_loss: 0.053| r_loss: 0.094| p_loss: 0.152| v_loss: 0.030| per_loss: 0.522 | a_loss: 0.485
Train: Epoch [937/3000], Step [90/158]| g_loss: 0.840| d_loss: 0.512| gp_loss: 0.056| r_loss: 0.091| p_loss: 0.151| v_loss: 0.031| per_loss: 0.501 | a_loss: 0.593
Train: Epoch [937/3000], Step [120/158]| g_loss: 0.818| d_loss: 0.625| gp_loss: 0.053| r_loss: 0.092| p_loss: 0.154| v_loss: 0.030| per_loss: 0.476 | a_loss: 0.571
Train: Epoch [937/3000], Step [150/158]| g_loss: 0.775| d_loss: 0.609| gp_loss: 0.057| r_loss: 0.093| p_loss: 0.155| v_loss: 0.031| per_loss: 0.491 | a_loss: 0.525
Train: Epoch [938/3000], Step [30/158]| g_loss: 0.826| d_loss: 0.630| gp_loss: 0.132| r_loss: 0.093| p_loss: 0.155| v_loss: 0.030| per_loss: 0.529 | a_loss: 0.572
Train: Epoch [938/3000], Step [60/158]| g_loss: 0.788| d_loss: 0.630| gp_loss: 0.049| r_loss: 0.095| p_loss: 0.155| v_loss: 0.031| per_loss: 0.504 | a_loss: 0.533
Train: Epoch [938/3000], Step [90/158]| g_loss: 0.820| d_loss: 0.508| gp_loss: 0.054| r_loss: 0.088| p_loss: 0.145| v_loss: 0.031| per_loss: 0.451 | a_loss: 0.583
Train: Epoch [938/3000], Step [120/158]| g_loss: 0.771| d_loss: 0.650| gp_loss: 0.055| r_loss: 0.093| p_loss: 0.146| v_loss: 0.030| per_loss: 0.531 | a_loss: 0.521
Train: Epoch [938/3000], Step [150/158]| g_loss: 0.820| d_loss: 0.597| gp_loss: 0.055| r_loss: 0.093| p_loss: 0.151| v_loss: 0.031| per_loss: 0.521 | a_loss: 0.568
Train: Epoch [939/3000], Step [30/158]| g_loss: 0.767| d_loss: 0.693| gp_loss: 0.108| r_loss: 0.094| p_loss: 0.149| v_loss: 0.030| per_loss: 0.493 | a_loss: 0.519
Train: Epoch [939/3000], Step [60/158]| g_loss: 0.762| d_loss: 0.619| gp_loss: 0.058| r_loss: 0.094| p_loss: 0.147| v_loss: 0.029| per_loss: 0.484 | a_loss: 0.517
Train: Epoch [939/3000], Step [90/158]| g_loss: 0.800| d_loss: 0.603| gp_loss: 0.053| r_loss: 0.091| p_loss: 0.151| v_loss: 0.030| per_loss: 0.484 | a_loss: 0.555
Train: Epoch [939/3000], Step [120/158]| g_loss: 0.800| d_loss: 0.595| gp_loss: 0.057| r_loss: 0.093| p_loss: 0.147| v_loss: 0.030| per_loss: 0.474 | a_loss: 0.555
Train: Epoch [939/3000], Step [150/158]| g_loss: 0.866| d_loss: 0.556| gp_loss: 0.055| r_loss: 0.092| p_loss: 0.149| v_loss: 0.030| per_loss: 0.514 | a_loss: 0.618
Train: Epoch [940/3000], Step [30/158]| g_loss: 0.803| d_loss: 0.597| gp_loss: 0.110| r_loss: 0.094| p_loss: 0.153| v_loss: 0.030| per_loss: 0.510 | a_loss: 0.551
Train: Epoch [940/3000], Step [60/158]| g_loss: 0.763| d_loss: 0.652| gp_loss: 0.057| r_loss: 0.092| p_loss: 0.152| v_loss: 0.029| per_loss: 0.499 | a_loss: 0.516
Train: Epoch [940/3000], Step [90/158]| g_loss: 0.779| d_loss: 0.600| gp_loss: 0.057| r_loss: 0.096| p_loss: 0.150| v_loss: 0.031| per_loss: 0.479 | a_loss: 0.529
Train: Epoch [940/3000], Step [120/158]| g_loss: 0.789| d_loss: 0.625| gp_loss: 0.057| r_loss: 0.091| p_loss: 0.145| v_loss: 0.030| per_loss: 0.483 | a_loss: 0.548
Train: Epoch [940/3000], Step [150/158]| g_loss: 0.762| d_loss: 0.619| gp_loss: 0.057| r_loss: 0.093| p_loss: 0.149| v_loss: 0.030| per_loss: 0.494 | a_loss: 0.515
Train: Epoch [941/3000], Step [30/158]| g_loss: 0.817| d_loss: 0.650| gp_loss: 0.148| r_loss: 0.100| p_loss: 0.152| v_loss: 0.030| per_loss: 0.484 | a_loss: 0.564
Train: Epoch [941/3000], Step [60/158]| g_loss: 0.774| d_loss: 0.647| gp_loss: 0.048| r_loss: 0.090| p_loss: 0.144| v_loss: 0.029| per_loss: 0.489 | a_loss: 0.534
Train: Epoch [941/3000], Step [90/158]| g_loss: 0.690| d_loss: 0.689| gp_loss: 0.056| r_loss: 0.090| p_loss: 0.149| v_loss: 0.029| per_loss: 0.504 | a_loss: 0.446
Train: Epoch [941/3000], Step [120/158]| g_loss: 0.888| d_loss: 0.519| gp_loss: 0.053| r_loss: 0.089| p_loss: 0.140| v_loss: 0.029| per_loss: 0.460 | a_loss: 0.654
Train: Epoch [941/3000], Step [150/158]| g_loss: 0.744| d_loss: 0.623| gp_loss: 0.058| r_loss: 0.091| p_loss: 0.145| v_loss: 0.030| per_loss: 0.446 | a_loss: 0.505
Train: Epoch [942/3000], Step [30/158]| g_loss: 0.777| d_loss: 0.671| gp_loss: 0.140| r_loss: 0.088| p_loss: 0.136| v_loss: 0.028| per_loss: 0.493 | a_loss: 0.544
Train: Epoch [942/3000], Step [60/158]| g_loss: 0.803| d_loss: 0.524| gp_loss: 0.053| r_loss: 0.090| p_loss: 0.140| v_loss: 0.030| per_loss: 0.510 | a_loss: 0.562
Train: Epoch [942/3000], Step [90/158]| g_loss: 0.837| d_loss: 0.551| gp_loss: 0.055| r_loss: 0.091| p_loss: 0.142| v_loss: 0.031| per_loss: 0.509 | a_loss: 0.594
Train: Epoch [942/3000], Step [120/158]| g_loss: 0.741| d_loss: 0.609| gp_loss: 0.056| r_loss: 0.094| p_loss: 0.138| v_loss: 0.030| per_loss: 0.480 | a_loss: 0.500
Train: Epoch [942/3000], Step [150/158]| g_loss: 0.815| d_loss: 0.604| gp_loss: 0.054| r_loss: 0.087| p_loss: 0.140| v_loss: 0.030| per_loss: 0.447 | a_loss: 0.584
Train: Epoch [943/3000], Step [30/158]| g_loss: 0.672| d_loss: 0.801| gp_loss: 0.145| r_loss: 0.086| p_loss: 0.135| v_loss: 0.028| per_loss: 0.431 | a_loss: 0.447
Train: Epoch [943/3000], Step [60/158]| g_loss: 0.834| d_loss: 0.513| gp_loss: 0.057| r_loss: 0.094| p_loss: 0.145| v_loss: 0.029| per_loss: 0.485 | a_loss: 0.591
Train: Epoch [943/3000], Step [90/158]| g_loss: 0.802| d_loss: 0.571| gp_loss: 0.055| r_loss: 0.093| p_loss: 0.154| v_loss: 0.029| per_loss: 0.492 | a_loss: 0.554
Train: Epoch [943/3000], Step [120/158]| g_loss: 0.767| d_loss: 0.651| gp_loss: 0.054| r_loss: 0.097| p_loss: 0.154| v_loss: 0.028| per_loss: 0.492 | a_loss: 0.515
Train: Epoch [943/3000], Step [150/158]| g_loss: 0.821| d_loss: 0.585| gp_loss: 0.060| r_loss: 0.095| p_loss: 0.151| v_loss: 0.030| per_loss: 0.493 | a_loss: 0.571
Train: Epoch [944/3000], Step [30/158]| g_loss: 0.948| d_loss: 0.552| gp_loss: 0.151| r_loss: 0.116| p_loss: 0.214| v_loss: 0.031| per_loss: 0.519 | a_loss: 0.642
Train: Epoch [944/3000], Step [60/158]| g_loss: 0.825| d_loss: 0.654| gp_loss: 0.050| r_loss: 0.105| p_loss: 0.181| v_loss: 0.029| per_loss: 0.527 | a_loss: 0.548
Train: Epoch [944/3000], Step [90/158]| g_loss: 0.786| d_loss: 0.600| gp_loss: 0.057| r_loss: 0.094| p_loss: 0.164| v_loss: 0.030| per_loss: 0.508 | a_loss: 0.529
Train: Epoch [944/3000], Step [120/158]| g_loss: 0.751| d_loss: 0.650| gp_loss: 0.055| r_loss: 0.102| p_loss: 0.168| v_loss: 0.031| per_loss: 0.512 | a_loss: 0.484
Train: Epoch [944/3000], Step [150/158]| g_loss: 0.839| d_loss: 0.533| gp_loss: 0.059| r_loss: 0.091| p_loss: 0.153| v_loss: 0.030| per_loss: 0.467 | a_loss: 0.594
Train: Epoch [945/3000], Step [30/158]| g_loss: 0.785| d_loss: 0.682| gp_loss: 0.136| r_loss: 0.094| p_loss: 0.154| v_loss: 0.030| per_loss: 0.494 | a_loss: 0.534
Train: Epoch [945/3000], Step [60/158]| g_loss: 0.809| d_loss: 0.562| gp_loss: 0.055| r_loss: 0.090| p_loss: 0.139| v_loss: 0.029| per_loss: 0.480 | a_loss: 0.572
Train: Epoch [945/3000], Step [90/158]| g_loss: 0.810| d_loss: 0.605| gp_loss: 0.055| r_loss: 0.089| p_loss: 0.141| v_loss: 0.029| per_loss: 0.482 | a_loss: 0.573
Train: Epoch [945/3000], Step [120/158]| g_loss: 0.768| d_loss: 0.612| gp_loss: 0.055| r_loss: 0.092| p_loss: 0.147| v_loss: 0.030| per_loss: 0.494 | a_loss: 0.524
Train: Epoch [945/3000], Step [150/158]| g_loss: 0.785| d_loss: 0.589| gp_loss: 0.054| r_loss: 0.092| p_loss: 0.156| v_loss: 0.029| per_loss: 0.472 | a_loss: 0.539
Train: Epoch [946/3000], Step [30/158]| g_loss: 0.811| d_loss: 0.653| gp_loss: 0.132| r_loss: 0.095| p_loss: 0.152| v_loss: 0.031| per_loss: 0.484 | a_loss: 0.562
Train: Epoch [946/3000], Step [60/158]| g_loss: 0.859| d_loss: 0.529| gp_loss: 0.052| r_loss: 0.094| p_loss: 0.151| v_loss: 0.030| per_loss: 0.500 | a_loss: 0.609
Train: Epoch [946/3000], Step [90/158]| g_loss: 0.740| d_loss: 0.671| gp_loss: 0.051| r_loss: 0.099| p_loss: 0.176| v_loss: 0.029| per_loss: 0.533 | a_loss: 0.471
Train: Epoch [946/3000], Step [120/158]| g_loss: 0.783| d_loss: 0.578| gp_loss: 0.057| r_loss: 0.089| p_loss: 0.144| v_loss: 0.028| per_loss: 0.496 | a_loss: 0.544
Train: Epoch [946/3000], Step [150/158]| g_loss: 0.796| d_loss: 0.579| gp_loss: 0.055| r_loss: 0.093| p_loss: 0.145| v_loss: 0.030| per_loss: 0.469 | a_loss: 0.554
Train: Epoch [947/3000], Step [30/158]| g_loss: 0.768| d_loss: 0.656| gp_loss: 0.112| r_loss: 0.090| p_loss: 0.144| v_loss: 0.029| per_loss: 0.497 | a_loss: 0.527
Train: Epoch [947/3000], Step [60/158]| g_loss: 0.864| d_loss: 0.535| gp_loss: 0.054| r_loss: 0.092| p_loss: 0.142| v_loss: 0.031| per_loss: 0.470 | a_loss: 0.622
Train: Epoch [947/3000], Step [90/158]| g_loss: 0.753| d_loss: 0.639| gp_loss: 0.052| r_loss: 0.087| p_loss: 0.138| v_loss: 0.029| per_loss: 0.500 | a_loss: 0.517
Train: Epoch [947/3000], Step [120/158]| g_loss: 0.886| d_loss: 0.638| gp_loss: 0.050| r_loss: 0.137| p_loss: 0.264| v_loss: 0.030| per_loss: 0.573 | a_loss: 0.530
Train: Epoch [947/3000], Step [150/158]| g_loss: 0.900| d_loss: 0.585| gp_loss: 0.061| r_loss: 0.155| p_loss: 0.272| v_loss: 0.031| per_loss: 0.581 | a_loss: 0.521
Train: Epoch [948/3000], Step [30/158]| g_loss: 0.800| d_loss: 0.713| gp_loss: 0.124| r_loss: 0.108| p_loss: 0.190| v_loss: 0.030| per_loss: 0.505 | a_loss: 0.517
Train: Epoch [948/3000], Step [60/158]| g_loss: 0.828| d_loss: 0.519| gp_loss: 0.055| r_loss: 0.102| p_loss: 0.170| v_loss: 0.031| per_loss: 0.472 | a_loss: 0.564
Train: Epoch [948/3000], Step [90/158]| g_loss: 0.796| d_loss: 0.540| gp_loss: 0.057| r_loss: 0.095| p_loss: 0.157| v_loss: 0.029| per_loss: 0.504 | a_loss: 0.542
Train: Epoch [948/3000], Step [120/158]| g_loss: 0.853| d_loss: 0.556| gp_loss: 0.056| r_loss: 0.096| p_loss: 0.154| v_loss: 0.030| per_loss: 0.493 | a_loss: 0.601
Train: Epoch [948/3000], Step [150/158]| g_loss: 0.749| d_loss: 0.656| gp_loss: 0.059| r_loss: 0.092| p_loss: 0.152| v_loss: 0.030| per_loss: 0.498 | a_loss: 0.501
Train: Epoch [949/3000], Step [30/158]| g_loss: 0.815| d_loss: 0.637| gp_loss: 0.148| r_loss: 0.094| p_loss: 0.160| v_loss: 0.030| per_loss: 0.482 | a_loss: 0.563
Train: Epoch [949/3000], Step [60/158]| g_loss: 0.827| d_loss: 0.581| gp_loss: 0.055| r_loss: 0.094| p_loss: 0.148| v_loss: 0.029| per_loss: 0.472 | a_loss: 0.583
Train: Epoch [949/3000], Step [90/158]| g_loss: 0.816| d_loss: 0.595| gp_loss: 0.055| r_loss: 0.094| p_loss: 0.149| v_loss: 0.031| per_loss: 0.485 | a_loss: 0.569
Train: Epoch [949/3000], Step [120/158]| g_loss: 0.742| d_loss: 0.557| gp_loss: 0.057| r_loss: 0.088| p_loss: 0.147| v_loss: 0.030| per_loss: 0.488 | a_loss: 0.502
Train: Epoch [949/3000], Step [150/158]| g_loss: 0.843| d_loss: 0.622| gp_loss: 0.059| r_loss: 0.092| p_loss: 0.147| v_loss: 0.030| per_loss: 0.518 | a_loss: 0.595
Train: Epoch [950/3000], Step [30/158]| g_loss: 0.820| d_loss: 0.570| gp_loss: 0.113| r_loss: 0.087| p_loss: 0.138| v_loss: 0.030| per_loss: 0.515 | a_loss: 0.583
Train: Epoch [950/3000], Step [60/158]| g_loss: 0.727| d_loss: 0.685| gp_loss: 0.056| r_loss: 0.091| p_loss: 0.146| v_loss: 0.029| per_loss: 0.439 | a_loss: 0.491
Train: Epoch [950/3000], Step [90/158]| g_loss: 0.735| d_loss: 0.649| gp_loss: 0.054| r_loss: 0.089| p_loss: 0.145| v_loss: 0.029| per_loss: 0.484 | a_loss: 0.496
Train: Epoch [950/3000], Step [120/158]| g_loss: 0.815| d_loss: 0.568| gp_loss: 0.060| r_loss: 0.091| p_loss: 0.146| v_loss: 0.031| per_loss: 0.470 | a_loss: 0.572
Train: Epoch [950/3000], Step [150/158]| g_loss: 0.802| d_loss: 0.569| gp_loss: 0.060| r_loss: 0.089| p_loss: 0.137| v_loss: 0.029| per_loss: 0.473 | a_loss: 0.568
Test: Epoch [950/3000]| g_loss: 0.628| r_loss: 0.391| p_loss: 0.283| v_loss: 0.025
Train: Epoch [951/3000], Step [30/158]| g_loss: 0.734| d_loss: 0.647| gp_loss: 0.055| r_loss: 0.090| p_loss: 0.140| v_loss: 0.029| per_loss: 0.480 | a_loss: 0.496
Train: Epoch [951/3000], Step [60/158]| g_loss: 0.786| d_loss: 0.608| gp_loss: 0.054| r_loss: 0.089| p_loss: 0.145| v_loss: 0.030| per_loss: 0.457 | a_loss: 0.549
Train: Epoch [951/3000], Step [90/158]| g_loss: 0.827| d_loss: 0.523| gp_loss: 0.059| r_loss: 0.091| p_loss: 0.147| v_loss: 0.031| per_loss: 0.515 | a_loss: 0.580
Train: Epoch [951/3000], Step [120/158]| g_loss: 0.762| d_loss: 0.688| gp_loss: 0.054| r_loss: 0.095| p_loss: 0.154| v_loss: 0.030| per_loss: 0.507 | a_loss: 0.509
Train: Epoch [951/3000], Step [150/158]| g_loss: 0.802| d_loss: 0.511| gp_loss: 0.060| r_loss: 0.089| p_loss: 0.146| v_loss: 0.029| per_loss: 0.453 | a_loss: 0.566
Train: Epoch [952/3000], Step [30/158]| g_loss: 0.818| d_loss: 0.673| gp_loss: 0.142| r_loss: 0.090| p_loss: 0.144| v_loss: 0.028| per_loss: 0.555 | a_loss: 0.572
Train: Epoch [952/3000], Step [60/158]| g_loss: 0.780| d_loss: 0.583| gp_loss: 0.052| r_loss: 0.088| p_loss: 0.145| v_loss: 0.030| per_loss: 0.500 | a_loss: 0.539
Train: Epoch [952/3000], Step [90/158]| g_loss: 0.840| d_loss: 0.590| gp_loss: 0.057| r_loss: 0.092| p_loss: 0.152| v_loss: 0.031| per_loss: 0.492 | a_loss: 0.592
Train: Epoch [952/3000], Step [120/158]| g_loss: 0.788| d_loss: 0.553| gp_loss: 0.053| r_loss: 0.090| p_loss: 0.148| v_loss: 0.031| per_loss: 0.517 | a_loss: 0.541
Train: Epoch [952/3000], Step [150/158]| g_loss: 0.810| d_loss: 0.648| gp_loss: 0.058| r_loss: 0.090| p_loss: 0.146| v_loss: 0.029| per_loss: 0.455 | a_loss: 0.572
Train: Epoch [953/3000], Step [30/158]| g_loss: 0.758| d_loss: 0.751| gp_loss: 0.188| r_loss: 0.091| p_loss: 0.146| v_loss: 0.031| per_loss: 0.498 | a_loss: 0.513
Train: Epoch [953/3000], Step [60/158]| g_loss: 0.753| d_loss: 0.631| gp_loss: 0.052| r_loss: 0.088| p_loss: 0.145| v_loss: 0.031| per_loss: 0.502 | a_loss: 0.512
Train: Epoch [953/3000], Step [90/158]| g_loss: 0.829| d_loss: 0.583| gp_loss: 0.054| r_loss: 0.092| p_loss: 0.143| v_loss: 0.030| per_loss: 0.486 | a_loss: 0.587
Train: Epoch [953/3000], Step [120/158]| g_loss: 0.811| d_loss: 0.573| gp_loss: 0.055| r_loss: 0.094| p_loss: 0.146| v_loss: 0.030| per_loss: 0.481 | a_loss: 0.566
Train: Epoch [953/3000], Step [150/158]| g_loss: 0.763| d_loss: 0.650| gp_loss: 0.054| r_loss: 0.093| p_loss: 0.149| v_loss: 0.030| per_loss: 0.510 | a_loss: 0.515
Train: Epoch [954/3000], Step [30/158]| g_loss: 0.738| d_loss: 0.730| gp_loss: 0.142| r_loss: 0.093| p_loss: 0.143| v_loss: 0.029| per_loss: 0.475 | a_loss: 0.496
Train: Epoch [954/3000], Step [60/158]| g_loss: 0.753| d_loss: 0.629| gp_loss: 0.046| r_loss: 0.089| p_loss: 0.140| v_loss: 0.029| per_loss: 0.523 | a_loss: 0.513
Train: Epoch [954/3000], Step [90/158]| g_loss: 0.842| d_loss: 0.472| gp_loss: 0.059| r_loss: 0.090| p_loss: 0.141| v_loss: 0.030| per_loss: 0.465 | a_loss: 0.605
Train: Epoch [954/3000], Step [120/158]| g_loss: 0.825| d_loss: 0.573| gp_loss: 0.053| r_loss: 0.091| p_loss: 0.146| v_loss: 0.030| per_loss: 0.520 | a_loss: 0.579
Train: Epoch [954/3000], Step [150/158]| g_loss: 0.769| d_loss: 0.595| gp_loss: 0.055| r_loss: 0.091| p_loss: 0.146| v_loss: 0.030| per_loss: 0.485 | a_loss: 0.527
Train: Epoch [955/3000], Step [30/158]| g_loss: 0.802| d_loss: 0.708| gp_loss: 0.182| r_loss: 0.090| p_loss: 0.142| v_loss: 0.030| per_loss: 0.474 | a_loss: 0.564
Train: Epoch [955/3000], Step [60/158]| g_loss: 0.757| d_loss: 0.541| gp_loss: 0.050| r_loss: 0.091| p_loss: 0.139| v_loss: 0.029| per_loss: 0.491 | a_loss: 0.519
Train: Epoch [955/3000], Step [90/158]| g_loss: 0.828| d_loss: 0.580| gp_loss: 0.051| r_loss: 0.088| p_loss: 0.140| v_loss: 0.029| per_loss: 0.448 | a_loss: 0.595
Train: Epoch [955/3000], Step [120/158]| g_loss: 0.783| d_loss: 0.549| gp_loss: 0.055| r_loss: 0.095| p_loss: 0.146| v_loss: 0.029| per_loss: 0.489 | a_loss: 0.537
Train: Epoch [955/3000], Step [150/158]| g_loss: 0.796| d_loss: 0.580| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.139| v_loss: 0.028| per_loss: 0.492 | a_loss: 0.565
Train: Epoch [956/3000], Step [30/158]| g_loss: 0.765| d_loss: 0.755| gp_loss: 0.181| r_loss: 0.090| p_loss: 0.150| v_loss: 0.029| per_loss: 0.475 | a_loss: 0.524
Train: Epoch [956/3000], Step [60/158]| g_loss: 0.798| d_loss: 0.615| gp_loss: 0.053| r_loss: 0.095| p_loss: 0.157| v_loss: 0.030| per_loss: 0.498 | a_loss: 0.545
Train: Epoch [956/3000], Step [90/158]| g_loss: 0.755| d_loss: 0.642| gp_loss: 0.057| r_loss: 0.093| p_loss: 0.147| v_loss: 0.029| per_loss: 0.487 | a_loss: 0.511
Train: Epoch [956/3000], Step [120/158]| g_loss: 0.836| d_loss: 0.513| gp_loss: 0.056| r_loss: 0.090| p_loss: 0.152| v_loss: 0.030| per_loss: 0.481 | a_loss: 0.592
Train: Epoch [956/3000], Step [150/158]| g_loss: 0.770| d_loss: 0.592| gp_loss: 0.056| r_loss: 0.091| p_loss: 0.148| v_loss: 0.030| per_loss: 0.499 | a_loss: 0.524
Train: Epoch [957/3000], Step [30/158]| g_loss: 0.808| d_loss: 0.704| gp_loss: 0.153| r_loss: 0.088| p_loss: 0.144| v_loss: 0.029| per_loss: 0.516 | a_loss: 0.568
Train: Epoch [957/3000], Step [60/158]| g_loss: 0.772| d_loss: 0.594| gp_loss: 0.054| r_loss: 0.088| p_loss: 0.139| v_loss: 0.029| per_loss: 0.500 | a_loss: 0.535
Train: Epoch [957/3000], Step [90/158]| g_loss: 0.830| d_loss: 0.569| gp_loss: 0.054| r_loss: 0.092| p_loss: 0.148| v_loss: 0.030| per_loss: 0.465 | a_loss: 0.588
Train: Epoch [957/3000], Step [120/158]| g_loss: 0.803| d_loss: 0.491| gp_loss: 0.057| r_loss: 0.091| p_loss: 0.142| v_loss: 0.030| per_loss: 0.503 | a_loss: 0.561
Train: Epoch [957/3000], Step [150/158]| g_loss: 0.788| d_loss: 0.619| gp_loss: 0.054| r_loss: 0.090| p_loss: 0.144| v_loss: 0.031| per_loss: 0.464 | a_loss: 0.550
Train: Epoch [958/3000], Step [30/158]| g_loss: 0.741| d_loss: 0.661| gp_loss: 0.104| r_loss: 0.089| p_loss: 0.143| v_loss: 0.030| per_loss: 0.491 | a_loss: 0.502
Train: Epoch [958/3000], Step [60/158]| g_loss: 0.739| d_loss: 0.726| gp_loss: 0.056| r_loss: 0.089| p_loss: 0.144| v_loss: 0.029| per_loss: 0.492 | a_loss: 0.500
Train: Epoch [958/3000], Step [90/158]| g_loss: 0.777| d_loss: 0.558| gp_loss: 0.054| r_loss: 0.091| p_loss: 0.145| v_loss: 0.030| per_loss: 0.538 | a_loss: 0.530
Train: Epoch [958/3000], Step [120/158]| g_loss: 0.868| d_loss: 0.469| gp_loss: 0.054| r_loss: 0.097| p_loss: 0.149| v_loss: 0.031| per_loss: 0.449 | a_loss: 0.622
Train: Epoch [958/3000], Step [150/158]| g_loss: 0.809| d_loss: 0.596| gp_loss: 0.058| r_loss: 0.094| p_loss: 0.153| v_loss: 0.030| per_loss: 0.473 | a_loss: 0.561
Train: Epoch [959/3000], Step [30/158]| g_loss: 0.740| d_loss: 0.765| gp_loss: 0.147| r_loss: 0.100| p_loss: 0.155| v_loss: 0.031| per_loss: 0.482 | a_loss: 0.483
Train: Epoch [959/3000], Step [60/158]| g_loss: 0.822| d_loss: 0.558| gp_loss: 0.051| r_loss: 0.088| p_loss: 0.142| v_loss: 0.031| per_loss: 0.462 | a_loss: 0.587
Train: Epoch [959/3000], Step [90/158]| g_loss: 0.759| d_loss: 0.626| gp_loss: 0.053| r_loss: 0.092| p_loss: 0.144| v_loss: 0.031| per_loss: 0.492 | a_loss: 0.515
Train: Epoch [959/3000], Step [120/158]| g_loss: 0.781| d_loss: 0.576| gp_loss: 0.057| r_loss: 0.089| p_loss: 0.140| v_loss: 0.030| per_loss: 0.495 | a_loss: 0.543
Train: Epoch [959/3000], Step [150/158]| g_loss: 0.791| d_loss: 0.567| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.136| v_loss: 0.029| per_loss: 0.467 | a_loss: 0.562
Train: Epoch [960/3000], Step [30/158]| g_loss: 0.815| d_loss: 0.659| gp_loss: 0.188| r_loss: 0.087| p_loss: 0.136| v_loss: 0.029| per_loss: 0.477 | a_loss: 0.584
Train: Epoch [960/3000], Step [60/158]| g_loss: 0.737| d_loss: 0.611| gp_loss: 0.051| r_loss: 0.089| p_loss: 0.140| v_loss: 0.031| per_loss: 0.481 | a_loss: 0.499
Train: Epoch [960/3000], Step [90/158]| g_loss: 0.796| d_loss: 0.619| gp_loss: 0.052| r_loss: 0.090| p_loss: 0.134| v_loss: 0.030| per_loss: 0.485 | a_loss: 0.561
Train: Epoch [960/3000], Step [120/158]| g_loss: 0.755| d_loss: 0.603| gp_loss: 0.055| r_loss: 0.086| p_loss: 0.143| v_loss: 0.029| per_loss: 0.465 | a_loss: 0.522
Train: Epoch [960/3000], Step [150/158]| g_loss: 0.757| d_loss: 0.585| gp_loss: 0.051| r_loss: 0.086| p_loss: 0.141| v_loss: 0.030| per_loss: 0.448 | a_loss: 0.526
Train: Epoch [961/3000], Step [30/158]| g_loss: 0.841| d_loss: 0.635| gp_loss: 0.128| r_loss: 0.094| p_loss: 0.156| v_loss: 0.030| per_loss: 0.519 | a_loss: 0.588
Train: Epoch [961/3000], Step [60/158]| g_loss: 0.756| d_loss: 0.685| gp_loss: 0.052| r_loss: 0.094| p_loss: 0.163| v_loss: 0.029| per_loss: 0.500 | a_loss: 0.501
Train: Epoch [961/3000], Step [90/158]| g_loss: 0.815| d_loss: 0.608| gp_loss: 0.059| r_loss: 0.097| p_loss: 0.159| v_loss: 0.030| per_loss: 0.514 | a_loss: 0.557
Train: Epoch [961/3000], Step [120/158]| g_loss: 0.791| d_loss: 0.549| gp_loss: 0.061| r_loss: 0.091| p_loss: 0.155| v_loss: 0.031| per_loss: 0.506 | a_loss: 0.541
Train: Epoch [961/3000], Step [150/158]| g_loss: 0.842| d_loss: 0.570| gp_loss: 0.059| r_loss: 0.094| p_loss: 0.154| v_loss: 0.031| per_loss: 0.490 | a_loss: 0.591
Train: Epoch [962/3000], Step [30/158]| g_loss: 0.809| d_loss: 0.745| gp_loss: 0.190| r_loss: 0.095| p_loss: 0.149| v_loss: 0.031| per_loss: 0.482 | a_loss: 0.561
Train: Epoch [962/3000], Step [60/158]| g_loss: 0.789| d_loss: 0.615| gp_loss: 0.049| r_loss: 0.094| p_loss: 0.155| v_loss: 0.030| per_loss: 0.488 | a_loss: 0.538
Train: Epoch [962/3000], Step [90/158]| g_loss: 0.851| d_loss: 0.526| gp_loss: 0.058| r_loss: 0.089| p_loss: 0.147| v_loss: 0.031| per_loss: 0.495 | a_loss: 0.608
Train: Epoch [962/3000], Step [120/158]| g_loss: 0.790| d_loss: 0.720| gp_loss: 0.052| r_loss: 0.096| p_loss: 0.158| v_loss: 0.030| per_loss: 0.534 | a_loss: 0.531
Train: Epoch [962/3000], Step [150/158]| g_loss: 0.858| d_loss: 0.491| gp_loss: 0.065| r_loss: 0.098| p_loss: 0.159| v_loss: 0.032| per_loss: 0.498 | a_loss: 0.599
Train: Epoch [963/3000], Step [30/158]| g_loss: 0.828| d_loss: 0.755| gp_loss: 0.190| r_loss: 0.093| p_loss: 0.151| v_loss: 0.032| per_loss: 0.517 | a_loss: 0.576
Train: Epoch [963/3000], Step [60/158]| g_loss: 0.817| d_loss: 0.605| gp_loss: 0.052| r_loss: 0.099| p_loss: 0.159| v_loss: 0.031| per_loss: 0.488 | a_loss: 0.559
Train: Epoch [963/3000], Step [90/158]| g_loss: 0.831| d_loss: 0.539| gp_loss: 0.051| r_loss: 0.093| p_loss: 0.156| v_loss: 0.031| per_loss: 0.529 | a_loss: 0.575
Train: Epoch [963/3000], Step [120/158]| g_loss: 0.818| d_loss: 0.642| gp_loss: 0.056| r_loss: 0.093| p_loss: 0.154| v_loss: 0.030| per_loss: 0.452 | a_loss: 0.573
Train: Epoch [963/3000], Step [150/158]| g_loss: 0.771| d_loss: 0.560| gp_loss: 0.049| r_loss: 0.087| p_loss: 0.142| v_loss: 0.029| per_loss: 0.465 | a_loss: 0.538
Train: Epoch [964/3000], Step [30/158]| g_loss: 0.799| d_loss: 0.612| gp_loss: 0.141| r_loss: 0.092| p_loss: 0.138| v_loss: 0.030| per_loss: 0.515 | a_loss: 0.558
Train: Epoch [964/3000], Step [60/158]| g_loss: 0.794| d_loss: 0.551| gp_loss: 0.052| r_loss: 0.087| p_loss: 0.137| v_loss: 0.029| per_loss: 0.469 | a_loss: 0.562
Train: Epoch [964/3000], Step [90/158]| g_loss: 0.781| d_loss: 0.589| gp_loss: 0.051| r_loss: 0.089| p_loss: 0.142| v_loss: 0.031| per_loss: 0.514 | a_loss: 0.539
Train: Epoch [964/3000], Step [120/158]| g_loss: 0.740| d_loss: 0.700| gp_loss: 0.055| r_loss: 0.089| p_loss: 0.143| v_loss: 0.030| per_loss: 0.483 | a_loss: 0.501
Train: Epoch [964/3000], Step [150/158]| g_loss: 0.786| d_loss: 0.632| gp_loss: 0.054| r_loss: 0.089| p_loss: 0.147| v_loss: 0.032| per_loss: 0.478 | a_loss: 0.543
Train: Epoch [965/3000], Step [30/158]| g_loss: 0.809| d_loss: 0.610| gp_loss: 0.142| r_loss: 0.089| p_loss: 0.144| v_loss: 0.030| per_loss: 0.472 | a_loss: 0.571
Train: Epoch [965/3000], Step [60/158]| g_loss: 0.820| d_loss: 0.604| gp_loss: 0.051| r_loss: 0.091| p_loss: 0.144| v_loss: 0.031| per_loss: 0.486 | a_loss: 0.578
Train: Epoch [965/3000], Step [90/158]| g_loss: 0.741| d_loss: 0.623| gp_loss: 0.050| r_loss: 0.087| p_loss: 0.136| v_loss: 0.031| per_loss: 0.487 | a_loss: 0.507
Train: Epoch [965/3000], Step [120/158]| g_loss: 0.715| d_loss: 0.650| gp_loss: 0.053| r_loss: 0.090| p_loss: 0.139| v_loss: 0.029| per_loss: 0.467 | a_loss: 0.480
Train: Epoch [965/3000], Step [150/158]| g_loss: 0.820| d_loss: 0.554| gp_loss: 0.054| r_loss: 0.090| p_loss: 0.142| v_loss: 0.030| per_loss: 0.475 | a_loss: 0.581
Train: Epoch [966/3000], Step [30/158]| g_loss: 0.766| d_loss: 0.748| gp_loss: 0.213| r_loss: 0.090| p_loss: 0.137| v_loss: 0.029| per_loss: 0.485 | a_loss: 0.530
Train: Epoch [966/3000], Step [60/158]| g_loss: 0.806| d_loss: 0.521| gp_loss: 0.049| r_loss: 0.085| p_loss: 0.141| v_loss: 0.030| per_loss: 0.457 | a_loss: 0.575
Train: Epoch [966/3000], Step [90/158]| g_loss: 0.770| d_loss: 0.650| gp_loss: 0.050| r_loss: 0.090| p_loss: 0.145| v_loss: 0.029| per_loss: 0.470 | a_loss: 0.531
Train: Epoch [966/3000], Step [120/158]| g_loss: 0.815| d_loss: 0.564| gp_loss: 0.051| r_loss: 0.090| p_loss: 0.142| v_loss: 0.030| per_loss: 0.534 | a_loss: 0.571
Train: Epoch [966/3000], Step [150/158]| g_loss: 0.778| d_loss: 0.624| gp_loss: 0.052| r_loss: 0.089| p_loss: 0.142| v_loss: 0.031| per_loss: 0.469 | a_loss: 0.540
Train: Epoch [967/3000], Step [30/158]| g_loss: 0.761| d_loss: 0.709| gp_loss: 0.144| r_loss: 0.090| p_loss: 0.141| v_loss: 0.030| per_loss: 0.441 | a_loss: 0.527
Train: Epoch [967/3000], Step [60/158]| g_loss: 0.807| d_loss: 0.575| gp_loss: 0.050| r_loss: 0.088| p_loss: 0.139| v_loss: 0.029| per_loss: 0.488 | a_loss: 0.572
Train: Epoch [967/3000], Step [90/158]| g_loss: 0.791| d_loss: 0.628| gp_loss: 0.050| r_loss: 0.091| p_loss: 0.143| v_loss: 0.030| per_loss: 0.470 | a_loss: 0.552
Train: Epoch [967/3000], Step [120/158]| g_loss: 0.792| d_loss: 0.581| gp_loss: 0.054| r_loss: 0.092| p_loss: 0.136| v_loss: 0.030| per_loss: 0.486 | a_loss: 0.554
Train: Epoch [967/3000], Step [150/158]| g_loss: 0.812| d_loss: 0.561| gp_loss: 0.053| r_loss: 0.091| p_loss: 0.141| v_loss: 0.032| per_loss: 0.484 | a_loss: 0.569
Train: Epoch [968/3000], Step [30/158]| g_loss: 0.760| d_loss: 0.673| gp_loss: 0.102| r_loss: 0.092| p_loss: 0.146| v_loss: 0.031| per_loss: 0.456 | a_loss: 0.517
Train: Epoch [968/3000], Step [60/158]| g_loss: 0.782| d_loss: 0.598| gp_loss: 0.051| r_loss: 0.088| p_loss: 0.139| v_loss: 0.030| per_loss: 0.496 | a_loss: 0.545
Train: Epoch [968/3000], Step [90/158]| g_loss: 0.789| d_loss: 0.572| gp_loss: 0.051| r_loss: 0.090| p_loss: 0.148| v_loss: 0.030| per_loss: 0.489 | a_loss: 0.546
Train: Epoch [968/3000], Step [120/158]| g_loss: 0.744| d_loss: 0.664| gp_loss: 0.052| r_loss: 0.090| p_loss: 0.141| v_loss: 0.029| per_loss: 0.460 | a_loss: 0.509
Train: Epoch [968/3000], Step [150/158]| g_loss: 0.819| d_loss: 0.537| gp_loss: 0.057| r_loss: 0.087| p_loss: 0.142| v_loss: 0.030| per_loss: 0.471 | a_loss: 0.584
Train: Epoch [969/3000], Step [30/158]| g_loss: 0.821| d_loss: 0.604| gp_loss: 0.090| r_loss: 0.088| p_loss: 0.137| v_loss: 0.029| per_loss: 0.471 | a_loss: 0.588
Train: Epoch [969/3000], Step [60/158]| g_loss: 0.781| d_loss: 0.528| gp_loss: 0.056| r_loss: 0.087| p_loss: 0.143| v_loss: 0.030| per_loss: 0.488 | a_loss: 0.544
Train: Epoch [969/3000], Step [90/158]| g_loss: 0.796| d_loss: 0.676| gp_loss: 0.051| r_loss: 0.086| p_loss: 0.145| v_loss: 0.029| per_loss: 0.461 | a_loss: 0.562
Train: Epoch [969/3000], Step [120/158]| g_loss: 0.689| d_loss: 0.698| gp_loss: 0.053| r_loss: 0.088| p_loss: 0.133| v_loss: 0.029| per_loss: 0.486 | a_loss: 0.457
Train: Epoch [969/3000], Step [150/158]| g_loss: 0.842| d_loss: 0.542| gp_loss: 0.056| r_loss: 0.092| p_loss: 0.146| v_loss: 0.031| per_loss: 0.496 | a_loss: 0.596
Train: Epoch [970/3000], Step [30/158]| g_loss: 0.793| d_loss: 0.605| gp_loss: 0.120| r_loss: 0.086| p_loss: 0.137| v_loss: 0.030| per_loss: 0.497 | a_loss: 0.558
Train: Epoch [970/3000], Step [60/158]| g_loss: 0.791| d_loss: 0.592| gp_loss: 0.053| r_loss: 0.091| p_loss: 0.144| v_loss: 0.030| per_loss: 0.456 | a_loss: 0.552
Train: Epoch [970/3000], Step [90/158]| g_loss: 0.799| d_loss: 0.590| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.136| v_loss: 0.029| per_loss: 0.472 | a_loss: 0.570
Train: Epoch [970/3000], Step [120/158]| g_loss: 0.818| d_loss: 0.535| gp_loss: 0.056| r_loss: 0.090| p_loss: 0.137| v_loss: 0.030| per_loss: 0.463 | a_loss: 0.583
Train: Epoch [970/3000], Step [150/158]| g_loss: 0.753| d_loss: 0.650| gp_loss: 0.057| r_loss: 0.089| p_loss: 0.137| v_loss: 0.029| per_loss: 0.481 | a_loss: 0.519
Train: Epoch [971/3000], Step [30/158]| g_loss: 0.782| d_loss: 0.679| gp_loss: 0.126| r_loss: 0.089| p_loss: 0.142| v_loss: 0.030| per_loss: 0.459 | a_loss: 0.546
Train: Epoch [971/3000], Step [60/158]| g_loss: 0.731| d_loss: 0.596| gp_loss: 0.052| r_loss: 0.085| p_loss: 0.133| v_loss: 0.030| per_loss: 0.497 | a_loss: 0.500
Train: Epoch [971/3000], Step [90/158]| g_loss: 0.723| d_loss: 0.760| gp_loss: 0.051| r_loss: 0.096| p_loss: 0.150| v_loss: 0.030| per_loss: 0.462 | a_loss: 0.476
Train: Epoch [971/3000], Step [120/158]| g_loss: 0.799| d_loss: 0.587| gp_loss: 0.061| r_loss: 0.087| p_loss: 0.138| v_loss: 0.030| per_loss: 0.487 | a_loss: 0.564
Train: Epoch [971/3000], Step [150/158]| g_loss: 0.767| d_loss: 0.537| gp_loss: 0.058| r_loss: 0.090| p_loss: 0.138| v_loss: 0.031| per_loss: 0.475 | a_loss: 0.530
Train: Epoch [972/3000], Step [30/158]| g_loss: 0.825| d_loss: 0.556| gp_loss: 0.140| r_loss: 0.089| p_loss: 0.132| v_loss: 0.029| per_loss: 0.478 | a_loss: 0.592
Train: Epoch [972/3000], Step [60/158]| g_loss: 0.794| d_loss: 0.582| gp_loss: 0.055| r_loss: 0.087| p_loss: 0.136| v_loss: 0.030| per_loss: 0.443 | a_loss: 0.565
Train: Epoch [972/3000], Step [90/158]| g_loss: 0.734| d_loss: 0.679| gp_loss: 0.054| r_loss: 0.086| p_loss: 0.145| v_loss: 0.029| per_loss: 0.512 | a_loss: 0.496
Train: Epoch [972/3000], Step [120/158]| g_loss: 0.757| d_loss: 0.598| gp_loss: 0.057| r_loss: 0.086| p_loss: 0.140| v_loss: 0.030| per_loss: 0.452 | a_loss: 0.526
Train: Epoch [972/3000], Step [150/158]| g_loss: 0.784| d_loss: 0.597| gp_loss: 0.059| r_loss: 0.089| p_loss: 0.143| v_loss: 0.029| per_loss: 0.531 | a_loss: 0.541
Train: Epoch [973/3000], Step [30/158]| g_loss: 0.716| d_loss: 0.758| gp_loss: 0.071| r_loss: 0.091| p_loss: 0.155| v_loss: 0.029| per_loss: 0.462 | a_loss: 0.472
Train: Epoch [973/3000], Step [60/158]| g_loss: 0.825| d_loss: 0.566| gp_loss: 0.058| r_loss: 0.091| p_loss: 0.144| v_loss: 0.031| per_loss: 0.497 | a_loss: 0.581
Train: Epoch [973/3000], Step [90/158]| g_loss: 0.762| d_loss: 0.589| gp_loss: 0.059| r_loss: 0.088| p_loss: 0.142| v_loss: 0.030| per_loss: 0.486 | a_loss: 0.524
Train: Epoch [973/3000], Step [120/158]| g_loss: 0.779| d_loss: 0.622| gp_loss: 0.059| r_loss: 0.090| p_loss: 0.142| v_loss: 0.030| per_loss: 0.443 | a_loss: 0.545
Train: Epoch [973/3000], Step [150/158]| g_loss: 0.824| d_loss: 0.566| gp_loss: 0.061| r_loss: 0.090| p_loss: 0.147| v_loss: 0.029| per_loss: 0.498 | a_loss: 0.581
Train: Epoch [974/3000], Step [30/158]| g_loss: 0.808| d_loss: 0.733| gp_loss: 0.189| r_loss: 0.091| p_loss: 0.150| v_loss: 0.029| per_loss: 0.542 | a_loss: 0.558
Train: Epoch [974/3000], Step [60/158]| g_loss: 0.832| d_loss: 0.607| gp_loss: 0.054| r_loss: 0.094| p_loss: 0.147| v_loss: 0.029| per_loss: 0.500 | a_loss: 0.585
Train: Epoch [974/3000], Step [90/158]| g_loss: 0.748| d_loss: 0.606| gp_loss: 0.055| r_loss: 0.089| p_loss: 0.147| v_loss: 0.030| per_loss: 0.454 | a_loss: 0.510
Train: Epoch [974/3000], Step [120/158]| g_loss: 0.823| d_loss: 0.554| gp_loss: 0.053| r_loss: 0.093| p_loss: 0.149| v_loss: 0.030| per_loss: 0.517 | a_loss: 0.575
Train: Epoch [974/3000], Step [150/158]| g_loss: 0.751| d_loss: 0.628| gp_loss: 0.051| r_loss: 0.087| p_loss: 0.143| v_loss: 0.030| per_loss: 0.486 | a_loss: 0.515
Train: Epoch [975/3000], Step [30/158]| g_loss: 0.814| d_loss: 0.715| gp_loss: 0.189| r_loss: 0.090| p_loss: 0.140| v_loss: 0.030| per_loss: 0.495 | a_loss: 0.574
Train: Epoch [975/3000], Step [60/158]| g_loss: 0.772| d_loss: 0.557| gp_loss: 0.049| r_loss: 0.090| p_loss: 0.145| v_loss: 0.030| per_loss: 0.515 | a_loss: 0.528
Train: Epoch [975/3000], Step [90/158]| g_loss: 0.763| d_loss: 0.603| gp_loss: 0.050| r_loss: 0.087| p_loss: 0.138| v_loss: 0.029| per_loss: 0.465 | a_loss: 0.530
Train: Epoch [975/3000], Step [120/158]| g_loss: 0.764| d_loss: 0.644| gp_loss: 0.054| r_loss: 0.088| p_loss: 0.147| v_loss: 0.030| per_loss: 0.478 | a_loss: 0.524
Train: Epoch [975/3000], Step [150/158]| g_loss: 0.851| d_loss: 0.560| gp_loss: 0.054| r_loss: 0.101| p_loss: 0.156| v_loss: 0.030| per_loss: 0.485 | a_loss: 0.594
Train: Epoch [976/3000], Step [30/158]| g_loss: 0.775| d_loss: 0.715| gp_loss: 0.192| r_loss: 0.092| p_loss: 0.158| v_loss: 0.030| per_loss: 0.459 | a_loss: 0.529
Train: Epoch [976/3000], Step [60/158]| g_loss: 0.781| d_loss: 0.610| gp_loss: 0.049| r_loss: 0.091| p_loss: 0.153| v_loss: 0.031| per_loss: 0.503 | a_loss: 0.532
Train: Epoch [976/3000], Step [90/158]| g_loss: 0.795| d_loss: 0.589| gp_loss: 0.054| r_loss: 0.095| p_loss: 0.151| v_loss: 0.029| per_loss: 0.477 | a_loss: 0.547
Train: Epoch [976/3000], Step [120/158]| g_loss: 0.807| d_loss: 0.590| gp_loss: 0.057| r_loss: 0.089| p_loss: 0.143| v_loss: 0.030| per_loss: 0.481 | a_loss: 0.570
Train: Epoch [976/3000], Step [150/158]| g_loss: 0.772| d_loss: 0.591| gp_loss: 0.056| r_loss: 0.087| p_loss: 0.139| v_loss: 0.029| per_loss: 0.478 | a_loss: 0.540
Train: Epoch [977/3000], Step [30/158]| g_loss: 0.717| d_loss: 0.902| gp_loss: 0.260| r_loss: 0.086| p_loss: 0.139| v_loss: 0.030| per_loss: 0.484 | a_loss: 0.484
Train: Epoch [977/3000], Step [60/158]| g_loss: 0.793| d_loss: 0.602| gp_loss: 0.051| r_loss: 0.088| p_loss: 0.143| v_loss: 0.030| per_loss: 0.503 | a_loss: 0.554
Train: Epoch [977/3000], Step [90/158]| g_loss: 0.806| d_loss: 0.534| gp_loss: 0.048| r_loss: 0.090| p_loss: 0.145| v_loss: 0.031| per_loss: 0.477 | a_loss: 0.565
Train: Epoch [977/3000], Step [120/158]| g_loss: 0.760| d_loss: 0.641| gp_loss: 0.052| r_loss: 0.089| p_loss: 0.142| v_loss: 0.030| per_loss: 0.472 | a_loss: 0.522
Train: Epoch [977/3000], Step [150/158]| g_loss: 0.828| d_loss: 0.548| gp_loss: 0.049| r_loss: 0.091| p_loss: 0.140| v_loss: 0.030| per_loss: 0.481 | a_loss: 0.590
Train: Epoch [978/3000], Step [30/158]| g_loss: 0.841| d_loss: 0.576| gp_loss: 0.121| r_loss: 0.084| p_loss: 0.134| v_loss: 0.028| per_loss: 0.496 | a_loss: 0.613
Train: Epoch [978/3000], Step [60/158]| g_loss: 0.690| d_loss: 0.665| gp_loss: 0.047| r_loss: 0.085| p_loss: 0.139| v_loss: 0.030| per_loss: 0.466 | a_loss: 0.459
Train: Epoch [978/3000], Step [90/158]| g_loss: 0.781| d_loss: 0.552| gp_loss: 0.050| r_loss: 0.090| p_loss: 0.142| v_loss: 0.030| per_loss: 0.482 | a_loss: 0.541
Train: Epoch [978/3000], Step [120/158]| g_loss: 0.820| d_loss: 0.588| gp_loss: 0.048| r_loss: 0.093| p_loss: 0.145| v_loss: 0.031| per_loss: 0.500 | a_loss: 0.573
Train: Epoch [978/3000], Step [150/158]| g_loss: 0.764| d_loss: 0.611| gp_loss: 0.050| r_loss: 0.092| p_loss: 0.147| v_loss: 0.028| per_loss: 0.462 | a_loss: 0.525
Train: Epoch [979/3000], Step [30/158]| g_loss: 0.757| d_loss: 0.714| gp_loss: 0.156| r_loss: 0.091| p_loss: 0.144| v_loss: 0.029| per_loss: 0.503 | a_loss: 0.515
Train: Epoch [979/3000], Step [60/158]| g_loss: 0.809| d_loss: 0.577| gp_loss: 0.049| r_loss: 0.089| p_loss: 0.143| v_loss: 0.030| per_loss: 0.495 | a_loss: 0.569
Train: Epoch [979/3000], Step [90/158]| g_loss: 0.753| d_loss: 0.705| gp_loss: 0.051| r_loss: 0.088| p_loss: 0.141| v_loss: 0.029| per_loss: 0.501 | a_loss: 0.516
Train: Epoch [979/3000], Step [120/158]| g_loss: 0.800| d_loss: 0.543| gp_loss: 0.050| r_loss: 0.093| p_loss: 0.147| v_loss: 0.030| per_loss: 0.475 | a_loss: 0.555
Train: Epoch [979/3000], Step [150/158]| g_loss: 0.727| d_loss: 0.600| gp_loss: 0.052| r_loss: 0.088| p_loss: 0.140| v_loss: 0.029| per_loss: 0.465 | a_loss: 0.494
Train: Epoch [980/3000], Step [30/158]| g_loss: 0.826| d_loss: 0.640| gp_loss: 0.140| r_loss: 0.090| p_loss: 0.147| v_loss: 0.029| per_loss: 0.472 | a_loss: 0.586
Train: Epoch [980/3000], Step [60/158]| g_loss: 0.783| d_loss: 0.578| gp_loss: 0.048| r_loss: 0.085| p_loss: 0.136| v_loss: 0.028| per_loss: 0.447 | a_loss: 0.556
Train: Epoch [980/3000], Step [90/158]| g_loss: 0.772| d_loss: 0.580| gp_loss: 0.050| r_loss: 0.090| p_loss: 0.142| v_loss: 0.031| per_loss: 0.500 | a_loss: 0.530
Train: Epoch [980/3000], Step [120/158]| g_loss: 0.740| d_loss: 0.638| gp_loss: 0.051| r_loss: 0.089| p_loss: 0.145| v_loss: 0.030| per_loss: 0.440 | a_loss: 0.505
Train: Epoch [980/3000], Step [150/158]| g_loss: 0.777| d_loss: 0.586| gp_loss: 0.054| r_loss: 0.085| p_loss: 0.134| v_loss: 0.029| per_loss: 0.497 | a_loss: 0.547
Train: Epoch [981/3000], Step [30/158]| g_loss: 0.764| d_loss: 0.621| gp_loss: 0.090| r_loss: 0.084| p_loss: 0.140| v_loss: 0.029| per_loss: 0.473 | a_loss: 0.534
Train: Epoch [981/3000], Step [60/158]| g_loss: 0.753| d_loss: 0.637| gp_loss: 0.054| r_loss: 0.091| p_loss: 0.137| v_loss: 0.029| per_loss: 0.458 | a_loss: 0.519
Train: Epoch [981/3000], Step [90/158]| g_loss: 0.764| d_loss: 0.639| gp_loss: 0.055| r_loss: 0.088| p_loss: 0.144| v_loss: 0.030| per_loss: 0.471 | a_loss: 0.528
Train: Epoch [981/3000], Step [120/158]| g_loss: 0.858| d_loss: 0.481| gp_loss: 0.056| r_loss: 0.087| p_loss: 0.128| v_loss: 0.028| per_loss: 0.465 | a_loss: 0.632
Train: Epoch [981/3000], Step [150/158]| g_loss: 0.826| d_loss: 0.612| gp_loss: 0.055| r_loss: 0.090| p_loss: 0.140| v_loss: 0.030| per_loss: 0.530 | a_loss: 0.583
Train: Epoch [982/3000], Step [30/158]| g_loss: 0.778| d_loss: 0.694| gp_loss: 0.156| r_loss: 0.096| p_loss: 0.149| v_loss: 0.031| per_loss: 0.466 | a_loss: 0.530
Train: Epoch [982/3000], Step [60/158]| g_loss: 0.860| d_loss: 0.502| gp_loss: 0.053| r_loss: 0.093| p_loss: 0.142| v_loss: 0.030| per_loss: 0.449 | a_loss: 0.621
Train: Epoch [982/3000], Step [90/158]| g_loss: 0.742| d_loss: 0.679| gp_loss: 0.052| r_loss: 0.089| p_loss: 0.143| v_loss: 0.029| per_loss: 0.512 | a_loss: 0.501
Train: Epoch [982/3000], Step [120/158]| g_loss: 0.786| d_loss: 0.624| gp_loss: 0.052| r_loss: 0.085| p_loss: 0.141| v_loss: 0.029| per_loss: 0.495 | a_loss: 0.553
Train: Epoch [982/3000], Step [150/158]| g_loss: 0.767| d_loss: 0.540| gp_loss: 0.055| r_loss: 0.087| p_loss: 0.141| v_loss: 0.029| per_loss: 0.491 | a_loss: 0.532
Train: Epoch [983/3000], Step [30/158]| g_loss: 0.766| d_loss: 0.735| gp_loss: 0.113| r_loss: 0.091| p_loss: 0.153| v_loss: 0.029| per_loss: 0.485 | a_loss: 0.520
Train: Epoch [983/3000], Step [60/158]| g_loss: 0.793| d_loss: 0.635| gp_loss: 0.050| r_loss: 0.092| p_loss: 0.150| v_loss: 0.030| per_loss: 0.505 | a_loss: 0.546
Train: Epoch [983/3000], Step [90/158]| g_loss: 0.783| d_loss: 0.596| gp_loss: 0.052| r_loss: 0.089| p_loss: 0.144| v_loss: 0.029| per_loss: 0.487 | a_loss: 0.544
Train: Epoch [983/3000], Step [120/158]| g_loss: 0.842| d_loss: 0.528| gp_loss: 0.054| r_loss: 0.090| p_loss: 0.144| v_loss: 0.030| per_loss: 0.473 | a_loss: 0.603
Train: Epoch [983/3000], Step [150/158]| g_loss: 0.771| d_loss: 0.646| gp_loss: 0.052| r_loss: 0.089| p_loss: 0.136| v_loss: 0.029| per_loss: 0.530 | a_loss: 0.532
Train: Epoch [984/3000], Step [30/158]| g_loss: 0.827| d_loss: 0.645| gp_loss: 0.146| r_loss: 0.112| p_loss: 0.154| v_loss: 0.030| per_loss: 0.502 | a_loss: 0.557
Train: Epoch [984/3000], Step [60/158]| g_loss: 0.734| d_loss: 0.692| gp_loss: 0.049| r_loss: 0.094| p_loss: 0.144| v_loss: 0.029| per_loss: 0.481 | a_loss: 0.491
Train: Epoch [984/3000], Step [90/158]| g_loss: 0.802| d_loss: 0.510| gp_loss: 0.054| r_loss: 0.089| p_loss: 0.138| v_loss: 0.029| per_loss: 0.490 | a_loss: 0.565
Train: Epoch [984/3000], Step [120/158]| g_loss: 0.780| d_loss: 0.578| gp_loss: 0.054| r_loss: 0.086| p_loss: 0.132| v_loss: 0.028| per_loss: 0.472 | a_loss: 0.553
Train: Epoch [984/3000], Step [150/158]| g_loss: 0.795| d_loss: 0.594| gp_loss: 0.056| r_loss: 0.090| p_loss: 0.151| v_loss: 0.029| per_loss: 0.508 | a_loss: 0.550
Train: Epoch [985/3000], Step [30/158]| g_loss: 0.785| d_loss: 0.655| gp_loss: 0.153| r_loss: 0.089| p_loss: 0.140| v_loss: 0.029| per_loss: 0.492 | a_loss: 0.548
Train: Epoch [985/3000], Step [60/158]| g_loss: 0.743| d_loss: 0.659| gp_loss: 0.054| r_loss: 0.088| p_loss: 0.141| v_loss: 0.029| per_loss: 0.473 | a_loss: 0.508
Train: Epoch [985/3000], Step [90/158]| g_loss: 0.861| d_loss: 0.537| gp_loss: 0.053| r_loss: 0.089| p_loss: 0.141| v_loss: 0.030| per_loss: 0.523 | a_loss: 0.619
Train: Epoch [985/3000], Step [120/158]| g_loss: 0.717| d_loss: 0.632| gp_loss: 0.058| r_loss: 0.086| p_loss: 0.140| v_loss: 0.028| per_loss: 0.455 | a_loss: 0.487
Train: Epoch [985/3000], Step [150/158]| g_loss: 0.839| d_loss: 0.570| gp_loss: 0.058| r_loss: 0.094| p_loss: 0.150| v_loss: 0.030| per_loss: 0.499 | a_loss: 0.589
Train: Epoch [986/3000], Step [30/158]| g_loss: 0.835| d_loss: 0.624| gp_loss: 0.145| r_loss: 0.095| p_loss: 0.158| v_loss: 0.030| per_loss: 0.450 | a_loss: 0.585
Train: Epoch [986/3000], Step [60/158]| g_loss: 0.785| d_loss: 0.639| gp_loss: 0.053| r_loss: 0.090| p_loss: 0.144| v_loss: 0.028| per_loss: 0.525 | a_loss: 0.541
Train: Epoch [986/3000], Step [90/158]| g_loss: 0.760| d_loss: 0.575| gp_loss: 0.053| r_loss: 0.090| p_loss: 0.142| v_loss: 0.030| per_loss: 0.479 | a_loss: 0.522
Train: Epoch [986/3000], Step [120/158]| g_loss: 0.752| d_loss: 0.641| gp_loss: 0.054| r_loss: 0.087| p_loss: 0.137| v_loss: 0.029| per_loss: 0.476 | a_loss: 0.520
Train: Epoch [986/3000], Step [150/158]| g_loss: 0.813| d_loss: 0.645| gp_loss: 0.054| r_loss: 0.088| p_loss: 0.136| v_loss: 0.029| per_loss: 0.465 | a_loss: 0.581
Train: Epoch [987/3000], Step [30/158]| g_loss: 0.804| d_loss: 0.663| gp_loss: 0.151| r_loss: 0.092| p_loss: 0.142| v_loss: 0.029| per_loss: 0.552 | a_loss: 0.558
Train: Epoch [987/3000], Step [60/158]| g_loss: 0.725| d_loss: 0.686| gp_loss: 0.053| r_loss: 0.088| p_loss: 0.143| v_loss: 0.030| per_loss: 0.467 | a_loss: 0.488
Train: Epoch [987/3000], Step [90/158]| g_loss: 0.774| d_loss: 0.664| gp_loss: 0.054| r_loss: 0.088| p_loss: 0.148| v_loss: 0.030| per_loss: 0.458 | a_loss: 0.537
Train: Epoch [987/3000], Step [120/158]| g_loss: 0.761| d_loss: 0.576| gp_loss: 0.055| r_loss: 0.092| p_loss: 0.152| v_loss: 0.029| per_loss: 0.467 | a_loss: 0.518
Train: Epoch [987/3000], Step [150/158]| g_loss: 0.843| d_loss: 0.492| gp_loss: 0.056| r_loss: 0.090| p_loss: 0.143| v_loss: 0.029| per_loss: 0.507 | a_loss: 0.602
Train: Epoch [988/3000], Step [30/158]| g_loss: 0.824| d_loss: 0.725| gp_loss: 0.167| r_loss: 0.089| p_loss: 0.146| v_loss: 0.031| per_loss: 0.475 | a_loss: 0.584
Train: Epoch [988/3000], Step [60/158]| g_loss: 0.779| d_loss: 0.590| gp_loss: 0.048| r_loss: 0.088| p_loss: 0.148| v_loss: 0.031| per_loss: 0.510 | a_loss: 0.535
Train: Epoch [988/3000], Step [90/158]| g_loss: 0.770| d_loss: 0.568| gp_loss: 0.050| r_loss: 0.083| p_loss: 0.131| v_loss: 0.030| per_loss: 0.510 | a_loss: 0.541
Train: Epoch [988/3000], Step [120/158]| g_loss: 0.796| d_loss: 0.561| gp_loss: 0.054| r_loss: 0.088| p_loss: 0.136| v_loss: 0.030| per_loss: 0.481 | a_loss: 0.562
Train: Epoch [988/3000], Step [150/158]| g_loss: 0.782| d_loss: 0.566| gp_loss: 0.054| r_loss: 0.090| p_loss: 0.144| v_loss: 0.029| per_loss: 0.482 | a_loss: 0.543
Train: Epoch [989/3000], Step [30/158]| g_loss: 0.757| d_loss: 0.712| gp_loss: 0.093| r_loss: 0.087| p_loss: 0.139| v_loss: 0.028| per_loss: 0.492 | a_loss: 0.522
Train: Epoch [989/3000], Step [60/158]| g_loss: 0.748| d_loss: 0.615| gp_loss: 0.053| r_loss: 0.088| p_loss: 0.145| v_loss: 0.029| per_loss: 0.516 | a_loss: 0.507
Train: Epoch [989/3000], Step [90/158]| g_loss: 0.789| d_loss: 0.580| gp_loss: 0.054| r_loss: 0.090| p_loss: 0.143| v_loss: 0.030| per_loss: 0.529 | a_loss: 0.545
Train: Epoch [989/3000], Step [120/158]| g_loss: 0.800| d_loss: 0.544| gp_loss: 0.057| r_loss: 0.090| p_loss: 0.146| v_loss: 0.031| per_loss: 0.486 | a_loss: 0.558
Train: Epoch [989/3000], Step [150/158]| g_loss: 0.839| d_loss: 0.545| gp_loss: 0.057| r_loss: 0.091| p_loss: 0.149| v_loss: 0.030| per_loss: 0.505 | a_loss: 0.593
Train: Epoch [990/3000], Step [30/158]| g_loss: 0.738| d_loss: 0.798| gp_loss: 0.170| r_loss: 0.093| p_loss: 0.156| v_loss: 0.030| per_loss: 0.529 | a_loss: 0.484
Train: Epoch [990/3000], Step [60/158]| g_loss: 0.746| d_loss: 0.688| gp_loss: 0.054| r_loss: 0.091| p_loss: 0.147| v_loss: 0.029| per_loss: 0.480 | a_loss: 0.505
Train: Epoch [990/3000], Step [90/158]| g_loss: 0.860| d_loss: 0.474| gp_loss: 0.055| r_loss: 0.090| p_loss: 0.146| v_loss: 0.030| per_loss: 0.492 | a_loss: 0.617
Train: Epoch [990/3000], Step [120/158]| g_loss: 0.833| d_loss: 0.571| gp_loss: 0.052| r_loss: 0.089| p_loss: 0.145| v_loss: 0.029| per_loss: 0.506 | a_loss: 0.592
Train: Epoch [990/3000], Step [150/158]| g_loss: 0.761| d_loss: 0.576| gp_loss: 0.055| r_loss: 0.088| p_loss: 0.140| v_loss: 0.029| per_loss: 0.467 | a_loss: 0.526
Train: Epoch [991/3000], Step [30/158]| g_loss: 0.764| d_loss: 0.725| gp_loss: 0.135| r_loss: 0.086| p_loss: 0.138| v_loss: 0.029| per_loss: 0.474 | a_loss: 0.532
Train: Epoch [991/3000], Step [60/158]| g_loss: 0.816| d_loss: 0.590| gp_loss: 0.052| r_loss: 0.088| p_loss: 0.141| v_loss: 0.030| per_loss: 0.531 | a_loss: 0.575
Train: Epoch [991/3000], Step [90/158]| g_loss: 0.742| d_loss: 0.603| gp_loss: 0.056| r_loss: 0.089| p_loss: 0.146| v_loss: 0.030| per_loss: 0.466 | a_loss: 0.504
Train: Epoch [991/3000], Step [120/158]| g_loss: 0.849| d_loss: 0.511| gp_loss: 0.056| r_loss: 0.093| p_loss: 0.146| v_loss: 0.031| per_loss: 0.515 | a_loss: 0.601
Train: Epoch [991/3000], Step [150/158]| g_loss: 0.813| d_loss: 0.584| gp_loss: 0.055| r_loss: 0.091| p_loss: 0.143| v_loss: 0.029| per_loss: 0.500 | a_loss: 0.571
Train: Epoch [992/3000], Step [30/158]| g_loss: 0.719| d_loss: 0.731| gp_loss: 0.105| r_loss: 0.090| p_loss: 0.150| v_loss: 0.029| per_loss: 0.521 | a_loss: 0.472
Train: Epoch [992/3000], Step [60/158]| g_loss: 0.772| d_loss: 0.578| gp_loss: 0.055| r_loss: 0.088| p_loss: 0.138| v_loss: 0.030| per_loss: 0.485 | a_loss: 0.537
Train: Epoch [992/3000], Step [90/158]| g_loss: 0.814| d_loss: 0.593| gp_loss: 0.056| r_loss: 0.094| p_loss: 0.144| v_loss: 0.029| per_loss: 0.481 | a_loss: 0.571
Train: Epoch [992/3000], Step [120/158]| g_loss: 0.789| d_loss: 0.572| gp_loss: 0.054| r_loss: 0.087| p_loss: 0.139| v_loss: 0.029| per_loss: 0.495 | a_loss: 0.554
Train: Epoch [992/3000], Step [150/158]| g_loss: 0.795| d_loss: 0.635| gp_loss: 0.053| r_loss: 0.091| p_loss: 0.143| v_loss: 0.031| per_loss: 0.547 | a_loss: 0.547
Train: Epoch [993/3000], Step [30/158]| g_loss: 0.810| d_loss: 0.617| gp_loss: 0.139| r_loss: 0.094| p_loss: 0.151| v_loss: 0.031| per_loss: 0.547 | a_loss: 0.554
Train: Epoch [993/3000], Step [60/158]| g_loss: 0.758| d_loss: 0.606| gp_loss: 0.052| r_loss: 0.088| p_loss: 0.146| v_loss: 0.029| per_loss: 0.456 | a_loss: 0.523
Train: Epoch [993/3000], Step [90/158]| g_loss: 0.769| d_loss: 0.675| gp_loss: 0.055| r_loss: 0.093| p_loss: 0.153| v_loss: 0.030| per_loss: 0.474 | a_loss: 0.522
Train: Epoch [993/3000], Step [120/158]| g_loss: 0.765| d_loss: 0.635| gp_loss: 0.056| r_loss: 0.090| p_loss: 0.152| v_loss: 0.030| per_loss: 0.490 | a_loss: 0.520
Train: Epoch [993/3000], Step [150/158]| g_loss: 0.840| d_loss: 0.530| gp_loss: 0.057| r_loss: 0.095| p_loss: 0.151| v_loss: 0.030| per_loss: 0.484 | a_loss: 0.590
Train: Epoch [994/3000], Step [30/158]| g_loss: 0.767| d_loss: 0.708| gp_loss: 0.174| r_loss: 0.091| p_loss: 0.142| v_loss: 0.029| per_loss: 0.484 | a_loss: 0.528
Train: Epoch [994/3000], Step [60/158]| g_loss: 0.821| d_loss: 0.541| gp_loss: 0.051| r_loss: 0.086| p_loss: 0.135| v_loss: 0.029| per_loss: 0.501 | a_loss: 0.589
Train: Epoch [994/3000], Step [90/158]| g_loss: 0.847| d_loss: 0.532| gp_loss: 0.055| r_loss: 0.091| p_loss: 0.145| v_loss: 0.031| per_loss: 0.485 | a_loss: 0.603
Train: Epoch [994/3000], Step [120/158]| g_loss: 0.792| d_loss: 0.620| gp_loss: 0.055| r_loss: 0.092| p_loss: 0.150| v_loss: 0.030| per_loss: 0.469 | a_loss: 0.548
Train: Epoch [994/3000], Step [150/158]| g_loss: 0.728| d_loss: 0.652| gp_loss: 0.055| r_loss: 0.086| p_loss: 0.143| v_loss: 0.030| per_loss: 0.466 | a_loss: 0.494
Train: Epoch [995/3000], Step [30/158]| g_loss: 0.761| d_loss: 0.683| gp_loss: 0.156| r_loss: 0.090| p_loss: 0.142| v_loss: 0.030| per_loss: 0.463 | a_loss: 0.524
Train: Epoch [995/3000], Step [60/158]| g_loss: 0.819| d_loss: 0.552| gp_loss: 0.050| r_loss: 0.091| p_loss: 0.144| v_loss: 0.029| per_loss: 0.500 | a_loss: 0.576
Train: Epoch [995/3000], Step [90/158]| g_loss: 0.747| d_loss: 0.612| gp_loss: 0.055| r_loss: 0.087| p_loss: 0.138| v_loss: 0.029| per_loss: 0.476 | a_loss: 0.514
Train: Epoch [995/3000], Step [120/158]| g_loss: 0.760| d_loss: 0.668| gp_loss: 0.050| r_loss: 0.086| p_loss: 0.143| v_loss: 0.028| per_loss: 0.487 | a_loss: 0.526
Train: Epoch [995/3000], Step [150/158]| g_loss: 0.820| d_loss: 0.568| gp_loss: 0.054| r_loss: 0.090| p_loss: 0.143| v_loss: 0.030| per_loss: 0.472 | a_loss: 0.582
Train: Epoch [996/3000], Step [30/158]| g_loss: 0.778| d_loss: 0.666| gp_loss: 0.111| r_loss: 0.090| p_loss: 0.144| v_loss: 0.029| per_loss: 0.487 | a_loss: 0.538
Train: Epoch [996/3000], Step [60/158]| g_loss: 0.776| d_loss: 0.630| gp_loss: 0.053| r_loss: 0.088| p_loss: 0.142| v_loss: 0.029| per_loss: 0.492 | a_loss: 0.539
Train: Epoch [996/3000], Step [90/158]| g_loss: 0.766| d_loss: 0.593| gp_loss: 0.057| r_loss: 0.088| p_loss: 0.140| v_loss: 0.030| per_loss: 0.484 | a_loss: 0.530
Train: Epoch [996/3000], Step [120/158]| g_loss: 0.772| d_loss: 0.589| gp_loss: 0.059| r_loss: 0.090| p_loss: 0.144| v_loss: 0.030| per_loss: 0.466 | a_loss: 0.534
Train: Epoch [996/3000], Step [150/158]| g_loss: 0.851| d_loss: 0.545| gp_loss: 0.056| r_loss: 0.089| p_loss: 0.138| v_loss: 0.030| per_loss: 0.481 | a_loss: 0.615
Train: Epoch [997/3000], Step [30/158]| g_loss: 0.743| d_loss: 0.731| gp_loss: 0.142| r_loss: 0.088| p_loss: 0.140| v_loss: 0.030| per_loss: 0.490 | a_loss: 0.507
Train: Epoch [997/3000], Step [60/158]| g_loss: 0.838| d_loss: 0.536| gp_loss: 0.056| r_loss: 0.084| p_loss: 0.132| v_loss: 0.028| per_loss: 0.501 | a_loss: 0.610
Train: Epoch [997/3000], Step [90/158]| g_loss: 0.801| d_loss: 0.555| gp_loss: 0.053| r_loss: 0.088| p_loss: 0.138| v_loss: 0.029| per_loss: 0.489 | a_loss: 0.566
Train: Epoch [997/3000], Step [120/158]| g_loss: 0.739| d_loss: 0.639| gp_loss: 0.059| r_loss: 0.089| p_loss: 0.146| v_loss: 0.029| per_loss: 0.452 | a_loss: 0.503
Train: Epoch [997/3000], Step [150/158]| g_loss: 0.827| d_loss: 0.497| gp_loss: 0.057| r_loss: 0.089| p_loss: 0.141| v_loss: 0.030| per_loss: 0.495 | a_loss: 0.588
Train: Epoch [998/3000], Step [30/158]| g_loss: 0.802| d_loss: 0.691| gp_loss: 0.148| r_loss: 0.090| p_loss: 0.140| v_loss: 0.029| per_loss: 0.484 | a_loss: 0.564
Train: Epoch [998/3000], Step [60/158]| g_loss: 0.815| d_loss: 0.535| gp_loss: 0.052| r_loss: 0.089| p_loss: 0.135| v_loss: 0.029| per_loss: 0.504 | a_loss: 0.580
Train: Epoch [998/3000], Step [90/158]| g_loss: 0.798| d_loss: 0.543| gp_loss: 0.056| r_loss: 0.092| p_loss: 0.140| v_loss: 0.030| per_loss: 0.480 | a_loss: 0.558
Train: Epoch [998/3000], Step [120/158]| g_loss: 0.829| d_loss: 0.582| gp_loss: 0.055| r_loss: 0.085| p_loss: 0.144| v_loss: 0.030| per_loss: 0.446 | a_loss: 0.598
Train: Epoch [998/3000], Step [150/158]| g_loss: 0.762| d_loss: 0.672| gp_loss: 0.054| r_loss: 0.086| p_loss: 0.138| v_loss: 0.028| per_loss: 0.505 | a_loss: 0.528
Train: Epoch [999/3000], Step [30/158]| g_loss: 0.821| d_loss: 0.630| gp_loss: 0.091| r_loss: 0.093| p_loss: 0.151| v_loss: 0.030| per_loss: 0.504 | a_loss: 0.573
Train: Epoch [999/3000], Step [60/158]| g_loss: 0.788| d_loss: 0.553| gp_loss: 0.055| r_loss: 0.089| p_loss: 0.142| v_loss: 0.029| per_loss: 0.438 | a_loss: 0.555
Train: Epoch [999/3000], Step [90/158]| g_loss: 0.759| d_loss: 0.575| gp_loss: 0.057| r_loss: 0.090| p_loss: 0.136| v_loss: 0.029| per_loss: 0.489 | a_loss: 0.524
Train: Epoch [999/3000], Step [120/158]| g_loss: 0.713| d_loss: 0.749| gp_loss: 0.055| r_loss: 0.092| p_loss: 0.144| v_loss: 0.028| per_loss: 0.502 | a_loss: 0.471
Train: Epoch [999/3000], Step [150/158]| g_loss: 0.785| d_loss: 0.541| gp_loss: 0.059| r_loss: 0.090| p_loss: 0.138| v_loss: 0.029| per_loss: 0.495 | a_loss: 0.548
Train: Epoch [1000/3000], Step [30/158]| g_loss: 0.779| d_loss: 0.782| gp_loss: 0.204| r_loss: 0.089| p_loss: 0.144| v_loss: 0.030| per_loss: 0.471 | a_loss: 0.542
Train: Epoch [1000/3000], Step [60/158]| g_loss: 0.752| d_loss: 0.566| gp_loss: 0.052| r_loss: 0.090| p_loss: 0.137| v_loss: 0.030| per_loss: 0.472 | a_loss: 0.516
Train: Epoch [1000/3000], Step [90/158]| g_loss: 0.799| d_loss: 0.606| gp_loss: 0.054| r_loss: 0.087| p_loss: 0.133| v_loss: 0.029| per_loss: 0.515 | a_loss: 0.566
Train: Epoch [1000/3000], Step [120/158]| g_loss: 0.755| d_loss: 0.540| gp_loss: 0.055| r_loss: 0.085| p_loss: 0.138| v_loss: 0.027| per_loss: 0.486 | a_loss: 0.525
Train: Epoch [1000/3000], Step [150/158]| g_loss: 0.795| d_loss: 0.578| gp_loss: 0.055| r_loss: 0.088| p_loss: 0.138| v_loss: 0.029| per_loss: 0.471 | a_loss: 0.561
Test: Epoch [1000/3000]| g_loss: 0.635| r_loss: 0.384| p_loss: 0.291| v_loss: 0.024
Train: Epoch [1001/3000], Step [30/158]| g_loss: 0.747| d_loss: 0.598| gp_loss: 0.053| r_loss: 0.088| p_loss: 0.135| v_loss: 0.029| per_loss: 0.465 | a_loss: 0.515
Train: Epoch [1001/3000], Step [60/158]| g_loss: 0.743| d_loss: 0.652| gp_loss: 0.052| r_loss: 0.087| p_loss: 0.132| v_loss: 0.029| per_loss: 0.492 | a_loss: 0.512
Train: Epoch [1001/3000], Step [90/158]| g_loss: 0.769| d_loss: 0.557| gp_loss: 0.056| r_loss: 0.085| p_loss: 0.133| v_loss: 0.029| per_loss: 0.486 | a_loss: 0.540
Train: Epoch [1001/3000], Step [120/158]| g_loss: 0.823| d_loss: 0.540| gp_loss: 0.055| r_loss: 0.083| p_loss: 0.129| v_loss: 0.028| per_loss: 0.485 | a_loss: 0.599
Train: Epoch [1001/3000], Step [150/158]| g_loss: 0.770| d_loss: 0.637| gp_loss: 0.054| r_loss: 0.090| p_loss: 0.143| v_loss: 0.030| per_loss: 0.477 | a_loss: 0.531
Train: Epoch [1002/3000], Step [30/158]| g_loss: 0.748| d_loss: 0.684| gp_loss: 0.168| r_loss: 0.083| p_loss: 0.130| v_loss: 0.029| per_loss: 0.444 | a_loss: 0.526
Train: Epoch [1002/3000], Step [60/158]| g_loss: 0.717| d_loss: 0.682| gp_loss: 0.050| r_loss: 0.085| p_loss: 0.132| v_loss: 0.028| per_loss: 0.506 | a_loss: 0.487
Train: Epoch [1002/3000], Step [90/158]| g_loss: 0.750| d_loss: 0.596| gp_loss: 0.054| r_loss: 0.089| p_loss: 0.137| v_loss: 0.028| per_loss: 0.496 | a_loss: 0.514
Train: Epoch [1002/3000], Step [120/158]| g_loss: 0.807| d_loss: 0.567| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.131| v_loss: 0.029| per_loss: 0.469 | a_loss: 0.580
Train: Epoch [1002/3000], Step [150/158]| g_loss: 0.815| d_loss: 0.478| gp_loss: 0.059| r_loss: 0.086| p_loss: 0.132| v_loss: 0.029| per_loss: 0.491 | a_loss: 0.585
Train: Epoch [1003/3000], Step [30/158]| g_loss: 0.777| d_loss: 0.674| gp_loss: 0.093| r_loss: 0.093| p_loss: 0.143| v_loss: 0.030| per_loss: 0.456 | a_loss: 0.537
Train: Epoch [1003/3000], Step [60/158]| g_loss: 0.792| d_loss: 0.622| gp_loss: 0.056| r_loss: 0.088| p_loss: 0.141| v_loss: 0.029| per_loss: 0.523 | a_loss: 0.552
Train: Epoch [1003/3000], Step [90/158]| g_loss: 0.771| d_loss: 0.618| gp_loss: 0.056| r_loss: 0.087| p_loss: 0.136| v_loss: 0.029| per_loss: 0.467 | a_loss: 0.540
Train: Epoch [1003/3000], Step [120/158]| g_loss: 0.769| d_loss: 0.583| gp_loss: 0.055| r_loss: 0.087| p_loss: 0.148| v_loss: 0.030| per_loss: 0.487 | a_loss: 0.530
Train: Epoch [1003/3000], Step [150/158]| g_loss: 0.800| d_loss: 0.634| gp_loss: 0.057| r_loss: 0.091| p_loss: 0.150| v_loss: 0.029| per_loss: 0.506 | a_loss: 0.554
Train: Epoch [1004/3000], Step [30/158]| g_loss: 0.765| d_loss: 0.650| gp_loss: 0.124| r_loss: 0.088| p_loss: 0.146| v_loss: 0.030| per_loss: 0.513 | a_loss: 0.523
Train: Epoch [1004/3000], Step [60/158]| g_loss: 0.772| d_loss: 0.630| gp_loss: 0.056| r_loss: 0.090| p_loss: 0.146| v_loss: 0.029| per_loss: 0.474 | a_loss: 0.533
Train: Epoch [1004/3000], Step [90/158]| g_loss: 0.836| d_loss: 0.552| gp_loss: 0.060| r_loss: 0.090| p_loss: 0.144| v_loss: 0.029| per_loss: 0.521 | a_loss: 0.592
Train: Epoch [1004/3000], Step [120/158]| g_loss: 0.806| d_loss: 0.593| gp_loss: 0.057| r_loss: 0.091| p_loss: 0.143| v_loss: 0.029| per_loss: 0.536 | a_loss: 0.561
Train: Epoch [1004/3000], Step [150/158]| g_loss: 0.770| d_loss: 0.577| gp_loss: 0.061| r_loss: 0.090| p_loss: 0.140| v_loss: 0.030| per_loss: 0.502 | a_loss: 0.530
Train: Epoch [1005/3000], Step [30/158]| g_loss: 0.850| d_loss: 0.727| gp_loss: 0.196| r_loss: 0.113| p_loss: 0.168| v_loss: 0.030| per_loss: 0.521 | a_loss: 0.571
Train: Epoch [1005/3000], Step [60/158]| g_loss: 0.786| d_loss: 0.580| gp_loss: 0.053| r_loss: 0.101| p_loss: 0.159| v_loss: 0.030| per_loss: 0.543 | a_loss: 0.521
Train: Epoch [1005/3000], Step [90/158]| g_loss: 0.873| d_loss: 0.530| gp_loss: 0.062| r_loss: 0.092| p_loss: 0.151| v_loss: 0.029| per_loss: 0.488 | a_loss: 0.628
Train: Epoch [1005/3000], Step [120/158]| g_loss: 0.822| d_loss: 0.641| gp_loss: 0.059| r_loss: 0.096| p_loss: 0.164| v_loss: 0.033| per_loss: 0.509 | a_loss: 0.560
Train: Epoch [1005/3000], Step [150/158]| g_loss: 0.795| d_loss: 0.561| gp_loss: 0.056| r_loss: 0.094| p_loss: 0.157| v_loss: 0.030| per_loss: 0.517 | a_loss: 0.541
Train: Epoch [1006/3000], Step [30/158]| g_loss: 0.805| d_loss: 0.690| gp_loss: 0.126| r_loss: 0.089| p_loss: 0.151| v_loss: 0.031| per_loss: 0.462 | a_loss: 0.564
Train: Epoch [1006/3000], Step [60/158]| g_loss: 0.831| d_loss: 0.564| gp_loss: 0.051| r_loss: 0.095| p_loss: 0.153| v_loss: 0.031| per_loss: 0.541 | a_loss: 0.574
Train: Epoch [1006/3000], Step [90/158]| g_loss: 0.765| d_loss: 0.606| gp_loss: 0.060| r_loss: 0.093| p_loss: 0.150| v_loss: 0.031| per_loss: 0.492 | a_loss: 0.516
Train: Epoch [1006/3000], Step [120/158]| g_loss: 0.783| d_loss: 0.651| gp_loss: 0.057| r_loss: 0.092| p_loss: 0.151| v_loss: 0.030| per_loss: 0.490 | a_loss: 0.536
Train: Epoch [1006/3000], Step [150/158]| g_loss: 0.805| d_loss: 0.588| gp_loss: 0.063| r_loss: 0.092| p_loss: 0.150| v_loss: 0.029| per_loss: 0.463 | a_loss: 0.562
Train: Epoch [1007/3000], Step [30/158]| g_loss: 0.713| d_loss: 0.809| gp_loss: 0.179| r_loss: 0.089| p_loss: 0.153| v_loss: 0.029| per_loss: 0.473 | a_loss: 0.470
Train: Epoch [1007/3000], Step [60/158]| g_loss: 0.734| d_loss: 0.616| gp_loss: 0.052| r_loss: 0.085| p_loss: 0.146| v_loss: 0.030| per_loss: 0.479 | a_loss: 0.497
Train: Epoch [1007/3000], Step [90/158]| g_loss: 0.777| d_loss: 0.641| gp_loss: 0.058| r_loss: 0.094| p_loss: 0.155| v_loss: 0.030| per_loss: 0.474 | a_loss: 0.528
Train: Epoch [1007/3000], Step [120/158]| g_loss: 0.839| d_loss: 0.512| gp_loss: 0.054| r_loss: 0.090| p_loss: 0.152| v_loss: 0.030| per_loss: 0.491 | a_loss: 0.594
Train: Epoch [1007/3000], Step [150/158]| g_loss: 0.835| d_loss: 0.543| gp_loss: 0.056| r_loss: 0.090| p_loss: 0.139| v_loss: 0.030| per_loss: 0.486 | a_loss: 0.597
Train: Epoch [1008/3000], Step [30/158]| g_loss: 0.790| d_loss: 0.725| gp_loss: 0.197| r_loss: 0.087| p_loss: 0.134| v_loss: 0.029| per_loss: 0.454 | a_loss: 0.562
Train: Epoch [1008/3000], Step [60/158]| g_loss: 0.755| d_loss: 0.586| gp_loss: 0.049| r_loss: 0.085| p_loss: 0.135| v_loss: 0.028| per_loss: 0.466 | a_loss: 0.527
Train: Epoch [1008/3000], Step [90/158]| g_loss: 0.738| d_loss: 0.631| gp_loss: 0.051| r_loss: 0.085| p_loss: 0.133| v_loss: 0.030| per_loss: 0.467 | a_loss: 0.510
Train: Epoch [1008/3000], Step [120/158]| g_loss: 0.827| d_loss: 0.527| gp_loss: 0.049| r_loss: 0.087| p_loss: 0.134| v_loss: 0.031| per_loss: 0.520 | a_loss: 0.591
Train: Epoch [1008/3000], Step [150/158]| g_loss: 0.736| d_loss: 0.599| gp_loss: 0.054| r_loss: 0.082| p_loss: 0.129| v_loss: 0.028| per_loss: 0.442 | a_loss: 0.516
Train: Epoch [1009/3000], Step [30/158]| g_loss: 0.813| d_loss: 0.644| gp_loss: 0.188| r_loss: 0.088| p_loss: 0.131| v_loss: 0.030| per_loss: 0.479 | a_loss: 0.582
Train: Epoch [1009/3000], Step [60/158]| g_loss: 0.761| d_loss: 0.601| gp_loss: 0.049| r_loss: 0.083| p_loss: 0.137| v_loss: 0.029| per_loss: 0.464 | a_loss: 0.534
Train: Epoch [1009/3000], Step [90/158]| g_loss: 0.714| d_loss: 0.687| gp_loss: 0.049| r_loss: 0.086| p_loss: 0.135| v_loss: 0.029| per_loss: 0.490 | a_loss: 0.483
Train: Epoch [1009/3000], Step [120/158]| g_loss: 0.778| d_loss: 0.560| gp_loss: 0.054| r_loss: 0.085| p_loss: 0.133| v_loss: 0.030| per_loss: 0.461 | a_loss: 0.550
Train: Epoch [1009/3000], Step [150/158]| g_loss: 0.811| d_loss: 0.580| gp_loss: 0.054| r_loss: 0.088| p_loss: 0.134| v_loss: 0.029| per_loss: 0.498 | a_loss: 0.577
Train: Epoch [1010/3000], Step [30/158]| g_loss: 0.769| d_loss: 0.669| gp_loss: 0.106| r_loss: 0.086| p_loss: 0.134| v_loss: 0.029| per_loss: 0.451 | a_loss: 0.542
Train: Epoch [1010/3000], Step [60/158]| g_loss: 0.750| d_loss: 0.649| gp_loss: 0.053| r_loss: 0.083| p_loss: 0.133| v_loss: 0.029| per_loss: 0.485 | a_loss: 0.523
Train: Epoch [1010/3000], Step [90/158]| g_loss: 0.690| d_loss: 0.695| gp_loss: 0.052| r_loss: 0.083| p_loss: 0.135| v_loss: 0.030| per_loss: 0.460 | a_loss: 0.464
Train: Epoch [1010/3000], Step [120/158]| g_loss: 0.828| d_loss: 0.521| gp_loss: 0.058| r_loss: 0.085| p_loss: 0.138| v_loss: 0.031| per_loss: 0.461 | a_loss: 0.596
Train: Epoch [1010/3000], Step [150/158]| g_loss: 0.756| d_loss: 0.600| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.135| v_loss: 0.029| per_loss: 0.488 | a_loss: 0.525
Train: Epoch [1011/3000], Step [30/158]| g_loss: 0.820| d_loss: 0.631| gp_loss: 0.140| r_loss: 0.090| p_loss: 0.137| v_loss: 0.030| per_loss: 0.478 | a_loss: 0.585
Train: Epoch [1011/3000], Step [60/158]| g_loss: 0.800| d_loss: 0.596| gp_loss: 0.053| r_loss: 0.087| p_loss: 0.137| v_loss: 0.029| per_loss: 0.466 | a_loss: 0.569
Train: Epoch [1011/3000], Step [90/158]| g_loss: 0.746| d_loss: 0.567| gp_loss: 0.056| r_loss: 0.084| p_loss: 0.128| v_loss: 0.029| per_loss: 0.466 | a_loss: 0.523
Train: Epoch [1011/3000], Step [120/158]| g_loss: 0.766| d_loss: 0.651| gp_loss: 0.050| r_loss: 0.086| p_loss: 0.138| v_loss: 0.029| per_loss: 0.515 | a_loss: 0.530
Train: Epoch [1011/3000], Step [150/158]| g_loss: 0.772| d_loss: 0.621| gp_loss: 0.055| r_loss: 0.084| p_loss: 0.139| v_loss: 0.030| per_loss: 0.447 | a_loss: 0.544
Train: Epoch [1012/3000], Step [30/158]| g_loss: 0.784| d_loss: 0.657| gp_loss: 0.144| r_loss: 0.087| p_loss: 0.132| v_loss: 0.030| per_loss: 0.441 | a_loss: 0.557
Train: Epoch [1012/3000], Step [60/158]| g_loss: 0.780| d_loss: 0.572| gp_loss: 0.053| r_loss: 0.093| p_loss: 0.147| v_loss: 0.031| per_loss: 0.471 | a_loss: 0.536
Train: Epoch [1012/3000], Step [90/158]| g_loss: 0.731| d_loss: 0.627| gp_loss: 0.058| r_loss: 0.086| p_loss: 0.134| v_loss: 0.028| per_loss: 0.460 | a_loss: 0.504
Train: Epoch [1012/3000], Step [120/158]| g_loss: 0.736| d_loss: 0.633| gp_loss: 0.052| r_loss: 0.084| p_loss: 0.130| v_loss: 0.028| per_loss: 0.505 | a_loss: 0.508
Train: Epoch [1012/3000], Step [150/158]| g_loss: 0.795| d_loss: 0.565| gp_loss: 0.058| r_loss: 0.085| p_loss: 0.136| v_loss: 0.028| per_loss: 0.514 | a_loss: 0.562
Train: Epoch [1013/3000], Step [30/158]| g_loss: 0.786| d_loss: 0.665| gp_loss: 0.111| r_loss: 0.090| p_loss: 0.148| v_loss: 0.029| per_loss: 0.522 | a_loss: 0.541
Train: Epoch [1013/3000], Step [60/158]| g_loss: 0.774| d_loss: 0.611| gp_loss: 0.053| r_loss: 0.089| p_loss: 0.143| v_loss: 0.030| per_loss: 0.448 | a_loss: 0.539
Train: Epoch [1013/3000], Step [90/158]| g_loss: 0.813| d_loss: 0.570| gp_loss: 0.054| r_loss: 0.087| p_loss: 0.138| v_loss: 0.030| per_loss: 0.481 | a_loss: 0.579
Train: Epoch [1013/3000], Step [120/158]| g_loss: 0.725| d_loss: 0.625| gp_loss: 0.056| r_loss: 0.084| p_loss: 0.133| v_loss: 0.028| per_loss: 0.479 | a_loss: 0.498
Train: Epoch [1013/3000], Step [150/158]| g_loss: 0.813| d_loss: 0.540| gp_loss: 0.062| r_loss: 0.085| p_loss: 0.133| v_loss: 0.030| per_loss: 0.467 | a_loss: 0.584
Train: Epoch [1014/3000], Step [30/158]| g_loss: 0.812| d_loss: 0.620| gp_loss: 0.151| r_loss: 0.088| p_loss: 0.133| v_loss: 0.029| per_loss: 0.440 | a_loss: 0.584
Train: Epoch [1014/3000], Step [60/158]| g_loss: 0.785| d_loss: 0.565| gp_loss: 0.055| r_loss: 0.087| p_loss: 0.131| v_loss: 0.028| per_loss: 0.475 | a_loss: 0.557
Train: Epoch [1014/3000], Step [90/158]| g_loss: 0.813| d_loss: 0.555| gp_loss: 0.055| r_loss: 0.089| p_loss: 0.140| v_loss: 0.030| per_loss: 0.498 | a_loss: 0.573
Train: Epoch [1014/3000], Step [120/158]| g_loss: 0.797| d_loss: 0.558| gp_loss: 0.054| r_loss: 0.088| p_loss: 0.139| v_loss: 0.030| per_loss: 0.484 | a_loss: 0.561
Train: Epoch [1014/3000], Step [150/158]| g_loss: 0.778| d_loss: 0.688| gp_loss: 0.053| r_loss: 0.085| p_loss: 0.137| v_loss: 0.029| per_loss: 0.493 | a_loss: 0.546
Train: Epoch [1015/3000], Step [30/158]| g_loss: 0.732| d_loss: 0.738| gp_loss: 0.115| r_loss: 0.089| p_loss: 0.149| v_loss: 0.029| per_loss: 0.484 | a_loss: 0.491
Train: Epoch [1015/3000], Step [60/158]| g_loss: 0.717| d_loss: 0.749| gp_loss: 0.056| r_loss: 0.095| p_loss: 0.162| v_loss: 0.029| per_loss: 0.509 | a_loss: 0.461
Train: Epoch [1015/3000], Step [90/158]| g_loss: 0.858| d_loss: 0.545| gp_loss: 0.058| r_loss: 0.093| p_loss: 0.148| v_loss: 0.029| per_loss: 0.483 | a_loss: 0.614
Train: Epoch [1015/3000], Step [120/158]| g_loss: 0.794| d_loss: 0.559| gp_loss: 0.056| r_loss: 0.092| p_loss: 0.148| v_loss: 0.028| per_loss: 0.473 | a_loss: 0.552
Train: Epoch [1015/3000], Step [150/158]| g_loss: 0.793| d_loss: 0.558| gp_loss: 0.056| r_loss: 0.086| p_loss: 0.137| v_loss: 0.028| per_loss: 0.467 | a_loss: 0.564
Train: Epoch [1016/3000], Step [30/158]| g_loss: 0.772| d_loss: 0.647| gp_loss: 0.113| r_loss: 0.085| p_loss: 0.134| v_loss: 0.029| per_loss: 0.486 | a_loss: 0.542
Train: Epoch [1016/3000], Step [60/158]| g_loss: 0.787| d_loss: 0.607| gp_loss: 0.052| r_loss: 0.087| p_loss: 0.141| v_loss: 0.030| per_loss: 0.436 | a_loss: 0.557
Train: Epoch [1016/3000], Step [90/158]| g_loss: 0.793| d_loss: 0.606| gp_loss: 0.057| r_loss: 0.086| p_loss: 0.134| v_loss: 0.030| per_loss: 0.487 | a_loss: 0.562
Train: Epoch [1016/3000], Step [120/158]| g_loss: 0.753| d_loss: 0.568| gp_loss: 0.058| r_loss: 0.088| p_loss: 0.133| v_loss: 0.030| per_loss: 0.519 | a_loss: 0.517
Train: Epoch [1016/3000], Step [150/158]| g_loss: 0.792| d_loss: 0.594| gp_loss: 0.059| r_loss: 0.087| p_loss: 0.137| v_loss: 0.029| per_loss: 0.468 | a_loss: 0.561
Train: Epoch [1017/3000], Step [30/158]| g_loss: 0.777| d_loss: 0.668| gp_loss: 0.156| r_loss: 0.088| p_loss: 0.140| v_loss: 0.029| per_loss: 0.466 | a_loss: 0.542
Train: Epoch [1017/3000], Step [60/158]| g_loss: 0.807| d_loss: 0.547| gp_loss: 0.059| r_loss: 0.086| p_loss: 0.133| v_loss: 0.027| per_loss: 0.487 | a_loss: 0.579
Train: Epoch [1017/3000], Step [90/158]| g_loss: 0.747| d_loss: 0.625| gp_loss: 0.056| r_loss: 0.088| p_loss: 0.142| v_loss: 0.029| per_loss: 0.464 | a_loss: 0.512
Train: Epoch [1017/3000], Step [120/158]| g_loss: 0.804| d_loss: 0.548| gp_loss: 0.056| r_loss: 0.086| p_loss: 0.134| v_loss: 0.029| per_loss: 0.533 | a_loss: 0.569
Train: Epoch [1017/3000], Step [150/158]| g_loss: 0.739| d_loss: 0.655| gp_loss: 0.057| r_loss: 0.087| p_loss: 0.139| v_loss: 0.030| per_loss: 0.464 | a_loss: 0.506
Train: Epoch [1018/3000], Step [30/158]| g_loss: 0.824| d_loss: 0.592| gp_loss: 0.123| r_loss: 0.086| p_loss: 0.135| v_loss: 0.030| per_loss: 0.468 | a_loss: 0.593
Train: Epoch [1018/3000], Step [60/158]| g_loss: 0.693| d_loss: 0.615| gp_loss: 0.052| r_loss: 0.083| p_loss: 0.134| v_loss: 0.030| per_loss: 0.444 | a_loss: 0.468
Train: Epoch [1018/3000], Step [90/158]| g_loss: 0.834| d_loss: 0.566| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.134| v_loss: 0.029| per_loss: 0.486 | a_loss: 0.604
Train: Epoch [1018/3000], Step [120/158]| g_loss: 0.789| d_loss: 0.571| gp_loss: 0.056| r_loss: 0.088| p_loss: 0.137| v_loss: 0.028| per_loss: 0.474 | a_loss: 0.558
Train: Epoch [1018/3000], Step [150/158]| g_loss: 0.726| d_loss: 0.635| gp_loss: 0.058| r_loss: 0.088| p_loss: 0.141| v_loss: 0.028| per_loss: 0.518 | a_loss: 0.487
Train: Epoch [1019/3000], Step [30/158]| g_loss: 0.811| d_loss: 0.636| gp_loss: 0.129| r_loss: 0.085| p_loss: 0.138| v_loss: 0.029| per_loss: 0.472 | a_loss: 0.581
Train: Epoch [1019/3000], Step [60/158]| g_loss: 0.723| d_loss: 0.642| gp_loss: 0.054| r_loss: 0.090| p_loss: 0.137| v_loss: 0.028| per_loss: 0.489 | a_loss: 0.488
Train: Epoch [1019/3000], Step [90/158]| g_loss: 0.695| d_loss: 0.690| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.138| v_loss: 0.029| per_loss: 0.460 | a_loss: 0.466
Train: Epoch [1019/3000], Step [120/158]| g_loss: 0.830| d_loss: 0.564| gp_loss: 0.055| r_loss: 0.087| p_loss: 0.134| v_loss: 0.029| per_loss: 0.467 | a_loss: 0.600
Train: Epoch [1019/3000], Step [150/158]| g_loss: 0.813| d_loss: 0.525| gp_loss: 0.064| r_loss: 0.089| p_loss: 0.139| v_loss: 0.031| per_loss: 0.479 | a_loss: 0.576
Train: Epoch [1020/3000], Step [30/158]| g_loss: 0.816| d_loss: 0.665| gp_loss: 0.137| r_loss: 0.084| p_loss: 0.140| v_loss: 0.029| per_loss: 0.463 | a_loss: 0.587
Train: Epoch [1020/3000], Step [60/158]| g_loss: 0.747| d_loss: 0.656| gp_loss: 0.058| r_loss: 0.093| p_loss: 0.146| v_loss: 0.032| per_loss: 0.456 | a_loss: 0.504
Train: Epoch [1020/3000], Step [90/158]| g_loss: 0.805| d_loss: 0.543| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.137| v_loss: 0.028| per_loss: 0.484 | a_loss: 0.574
Train: Epoch [1020/3000], Step [120/158]| g_loss: 0.811| d_loss: 0.554| gp_loss: 0.061| r_loss: 0.086| p_loss: 0.136| v_loss: 0.028| per_loss: 0.477 | a_loss: 0.581
Train: Epoch [1020/3000], Step [150/158]| g_loss: 0.792| d_loss: 0.616| gp_loss: 0.059| r_loss: 0.090| p_loss: 0.140| v_loss: 0.029| per_loss: 0.478 | a_loss: 0.556
Train: Epoch [1021/3000], Step [30/158]| g_loss: 0.789| d_loss: 0.680| gp_loss: 0.157| r_loss: 0.085| p_loss: 0.135| v_loss: 0.030| per_loss: 0.451 | a_loss: 0.561
Train: Epoch [1021/3000], Step [60/158]| g_loss: 0.786| d_loss: 0.509| gp_loss: 0.057| r_loss: 0.081| p_loss: 0.124| v_loss: 0.029| per_loss: 0.489 | a_loss: 0.565
Train: Epoch [1021/3000], Step [90/158]| g_loss: 0.804| d_loss: 0.589| gp_loss: 0.055| r_loss: 0.087| p_loss: 0.134| v_loss: 0.030| per_loss: 0.495 | a_loss: 0.571
Train: Epoch [1021/3000], Step [120/158]| g_loss: 0.743| d_loss: 0.645| gp_loss: 0.054| r_loss: 0.087| p_loss: 0.136| v_loss: 0.030| per_loss: 0.449 | a_loss: 0.514
Train: Epoch [1021/3000], Step [150/158]| g_loss: 0.799| d_loss: 0.600| gp_loss: 0.055| r_loss: 0.091| p_loss: 0.140| v_loss: 0.029| per_loss: 0.476 | a_loss: 0.562
Train: Epoch [1022/3000], Step [30/158]| g_loss: 0.734| d_loss: 0.740| gp_loss: 0.135| r_loss: 0.084| p_loss: 0.139| v_loss: 0.029| per_loss: 0.469 | a_loss: 0.504
Train: Epoch [1022/3000], Step [60/158]| g_loss: 0.750| d_loss: 0.581| gp_loss: 0.055| r_loss: 0.084| p_loss: 0.136| v_loss: 0.028| per_loss: 0.518 | a_loss: 0.518
Train: Epoch [1022/3000], Step [90/158]| g_loss: 0.769| d_loss: 0.625| gp_loss: 0.057| r_loss: 0.084| p_loss: 0.135| v_loss: 0.028| per_loss: 0.492 | a_loss: 0.541
Train: Epoch [1022/3000], Step [120/158]| g_loss: 0.883| d_loss: 0.439| gp_loss: 0.059| r_loss: 0.092| p_loss: 0.141| v_loss: 0.029| per_loss: 0.482 | a_loss: 0.644
Train: Epoch [1022/3000], Step [150/158]| g_loss: 0.858| d_loss: 0.542| gp_loss: 0.059| r_loss: 0.102| p_loss: 0.146| v_loss: 0.031| per_loss: 0.471 | a_loss: 0.605
Train: Epoch [1023/3000], Step [30/158]| g_loss: 0.765| d_loss: 0.677| gp_loss: 0.132| r_loss: 0.086| p_loss: 0.143| v_loss: 0.029| per_loss: 0.459 | a_loss: 0.532
Train: Epoch [1023/3000], Step [60/158]| g_loss: 0.821| d_loss: 0.554| gp_loss: 0.054| r_loss: 0.086| p_loss: 0.139| v_loss: 0.030| per_loss: 0.485 | a_loss: 0.587
Train: Epoch [1023/3000], Step [90/158]| g_loss: 0.788| d_loss: 0.568| gp_loss: 0.057| r_loss: 0.091| p_loss: 0.143| v_loss: 0.031| per_loss: 0.501 | a_loss: 0.545
Train: Epoch [1023/3000], Step [120/158]| g_loss: 0.743| d_loss: 0.631| gp_loss: 0.061| r_loss: 0.086| p_loss: 0.140| v_loss: 0.029| per_loss: 0.480 | a_loss: 0.509
Train: Epoch [1023/3000], Step [150/158]| g_loss: 0.769| d_loss: 0.658| gp_loss: 0.057| r_loss: 0.083| p_loss: 0.133| v_loss: 0.028| per_loss: 0.473 | a_loss: 0.543
Train: Epoch [1024/3000], Step [30/158]| g_loss: 0.842| d_loss: 0.596| gp_loss: 0.128| r_loss: 0.086| p_loss: 0.138| v_loss: 0.029| per_loss: 0.503 | a_loss: 0.608
Train: Epoch [1024/3000], Step [60/158]| g_loss: 0.833| d_loss: 0.511| gp_loss: 0.058| r_loss: 0.096| p_loss: 0.149| v_loss: 0.030| per_loss: 0.471 | a_loss: 0.584
Train: Epoch [1024/3000], Step [90/158]| g_loss: 0.741| d_loss: 0.667| gp_loss: 0.056| r_loss: 0.087| p_loss: 0.144| v_loss: 0.029| per_loss: 0.499 | a_loss: 0.502
Train: Epoch [1024/3000], Step [120/158]| g_loss: 0.774| d_loss: 0.619| gp_loss: 0.059| r_loss: 0.087| p_loss: 0.138| v_loss: 0.029| per_loss: 0.451 | a_loss: 0.544
Train: Epoch [1024/3000], Step [150/158]| g_loss: 0.723| d_loss: 0.642| gp_loss: 0.059| r_loss: 0.086| p_loss: 0.139| v_loss: 0.029| per_loss: 0.465 | a_loss: 0.493
Train: Epoch [1025/3000], Step [30/158]| g_loss: 0.806| d_loss: 0.660| gp_loss: 0.160| r_loss: 0.086| p_loss: 0.136| v_loss: 0.029| per_loss: 0.486 | a_loss: 0.575
Train: Epoch [1025/3000], Step [60/158]| g_loss: 0.744| d_loss: 0.661| gp_loss: 0.051| r_loss: 0.089| p_loss: 0.140| v_loss: 0.029| per_loss: 0.461 | a_loss: 0.509
Train: Epoch [1025/3000], Step [90/158]| g_loss: 0.765| d_loss: 0.576| gp_loss: 0.057| r_loss: 0.088| p_loss: 0.139| v_loss: 0.029| per_loss: 0.500 | a_loss: 0.529
Train: Epoch [1025/3000], Step [120/158]| g_loss: 0.843| d_loss: 0.548| gp_loss: 0.057| r_loss: 0.086| p_loss: 0.136| v_loss: 0.030| per_loss: 0.467 | a_loss: 0.612
Train: Epoch [1025/3000], Step [150/158]| g_loss: 0.756| d_loss: 0.628| gp_loss: 0.057| r_loss: 0.086| p_loss: 0.139| v_loss: 0.029| per_loss: 0.478 | a_loss: 0.523
Train: Epoch [1026/3000], Step [30/158]| g_loss: 0.719| d_loss: 0.676| gp_loss: 0.122| r_loss: 0.085| p_loss: 0.135| v_loss: 0.029| per_loss: 0.478 | a_loss: 0.490
Train: Epoch [1026/3000], Step [60/158]| g_loss: 0.806| d_loss: 0.579| gp_loss: 0.055| r_loss: 0.086| p_loss: 0.135| v_loss: 0.029| per_loss: 0.490 | a_loss: 0.575
Train: Epoch [1026/3000], Step [90/158]| g_loss: 0.745| d_loss: 0.665| gp_loss: 0.056| r_loss: 0.084| p_loss: 0.131| v_loss: 0.027| per_loss: 0.450 | a_loss: 0.523
Train: Epoch [1026/3000], Step [120/158]| g_loss: 0.707| d_loss: 0.626| gp_loss: 0.058| r_loss: 0.082| p_loss: 0.129| v_loss: 0.028| per_loss: 0.466 | a_loss: 0.485
Train: Epoch [1026/3000], Step [150/158]| g_loss: 0.817| d_loss: 0.558| gp_loss: 0.057| r_loss: 0.087| p_loss: 0.137| v_loss: 0.030| per_loss: 0.525 | a_loss: 0.579
Train: Epoch [1027/3000], Step [30/158]| g_loss: 0.767| d_loss: 0.753| gp_loss: 0.178| r_loss: 0.087| p_loss: 0.137| v_loss: 0.029| per_loss: 0.482 | a_loss: 0.533
Train: Epoch [1027/3000], Step [60/158]| g_loss: 0.809| d_loss: 0.604| gp_loss: 0.056| r_loss: 0.086| p_loss: 0.141| v_loss: 0.030| per_loss: 0.466 | a_loss: 0.576
Train: Epoch [1027/3000], Step [90/158]| g_loss: 0.780| d_loss: 0.586| gp_loss: 0.055| r_loss: 0.086| p_loss: 0.133| v_loss: 0.028| per_loss: 0.488 | a_loss: 0.551
Train: Epoch [1027/3000], Step [120/158]| g_loss: 0.758| d_loss: 0.564| gp_loss: 0.061| r_loss: 0.088| p_loss: 0.139| v_loss: 0.029| per_loss: 0.478 | a_loss: 0.523
Train: Epoch [1027/3000], Step [150/158]| g_loss: 0.792| d_loss: 0.547| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.133| v_loss: 0.028| per_loss: 0.453 | a_loss: 0.569
Train: Epoch [1028/3000], Step [30/158]| g_loss: 0.807| d_loss: 0.663| gp_loss: 0.165| r_loss: 0.084| p_loss: 0.128| v_loss: 0.027| per_loss: 0.477 | a_loss: 0.584
Train: Epoch [1028/3000], Step [60/158]| g_loss: 0.778| d_loss: 0.607| gp_loss: 0.057| r_loss: 0.090| p_loss: 0.143| v_loss: 0.028| per_loss: 0.437 | a_loss: 0.545
Train: Epoch [1028/3000], Step [90/158]| g_loss: 0.776| d_loss: 0.580| gp_loss: 0.054| r_loss: 0.089| p_loss: 0.136| v_loss: 0.030| per_loss: 0.511 | a_loss: 0.538
Train: Epoch [1028/3000], Step [120/158]| g_loss: 0.753| d_loss: 0.666| gp_loss: 0.055| r_loss: 0.087| p_loss: 0.139| v_loss: 0.030| per_loss: 0.542 | a_loss: 0.513
Train: Epoch [1028/3000], Step [150/158]| g_loss: 0.794| d_loss: 0.568| gp_loss: 0.059| r_loss: 0.087| p_loss: 0.139| v_loss: 0.030| per_loss: 0.519 | a_loss: 0.556
Train: Epoch [1029/3000], Step [30/158]| g_loss: 0.802| d_loss: 0.701| gp_loss: 0.178| r_loss: 0.087| p_loss: 0.140| v_loss: 0.027| per_loss: 0.463 | a_loss: 0.572
Train: Epoch [1029/3000], Step [60/158]| g_loss: 0.767| d_loss: 0.541| gp_loss: 0.053| r_loss: 0.087| p_loss: 0.140| v_loss: 0.029| per_loss: 0.528 | a_loss: 0.528
Train: Epoch [1029/3000], Step [90/158]| g_loss: 0.807| d_loss: 0.608| gp_loss: 0.052| r_loss: 0.089| p_loss: 0.145| v_loss: 0.028| per_loss: 0.551 | a_loss: 0.561
Train: Epoch [1029/3000], Step [120/158]| g_loss: 0.781| d_loss: 0.627| gp_loss: 0.054| r_loss: 0.092| p_loss: 0.152| v_loss: 0.029| per_loss: 0.470 | a_loss: 0.537
Train: Epoch [1029/3000], Step [150/158]| g_loss: 0.782| d_loss: 0.663| gp_loss: 0.060| r_loss: 0.100| p_loss: 0.158| v_loss: 0.029| per_loss: 0.468 | a_loss: 0.527
Train: Epoch [1030/3000], Step [30/158]| g_loss: 0.801| d_loss: 0.715| gp_loss: 0.156| r_loss: 0.092| p_loss: 0.155| v_loss: 0.031| per_loss: 0.518 | a_loss: 0.549
Train: Epoch [1030/3000], Step [60/158]| g_loss: 0.741| d_loss: 0.634| gp_loss: 0.056| r_loss: 0.092| p_loss: 0.147| v_loss: 0.030| per_loss: 0.473 | a_loss: 0.497
Train: Epoch [1030/3000], Step [90/158]| g_loss: 0.870| d_loss: 0.515| gp_loss: 0.057| r_loss: 0.087| p_loss: 0.141| v_loss: 0.029| per_loss: 0.532 | a_loss: 0.630
Train: Epoch [1030/3000], Step [120/158]| g_loss: 0.811| d_loss: 0.560| gp_loss: 0.054| r_loss: 0.090| p_loss: 0.141| v_loss: 0.029| per_loss: 0.531 | a_loss: 0.568
Train: Epoch [1030/3000], Step [150/158]| g_loss: 0.828| d_loss: 0.591| gp_loss: 0.055| r_loss: 0.089| p_loss: 0.144| v_loss: 0.030| per_loss: 0.493 | a_loss: 0.588
Train: Epoch [1031/3000], Step [30/158]| g_loss: 0.850| d_loss: 0.662| gp_loss: 0.170| r_loss: 0.088| p_loss: 0.145| v_loss: 0.031| per_loss: 0.567 | a_loss: 0.602
Train: Epoch [1031/3000], Step [60/158]| g_loss: 0.778| d_loss: 0.579| gp_loss: 0.052| r_loss: 0.090| p_loss: 0.142| v_loss: 0.029| per_loss: 0.478 | a_loss: 0.540
Train: Epoch [1031/3000], Step [90/158]| g_loss: 0.752| d_loss: 0.660| gp_loss: 0.048| r_loss: 0.091| p_loss: 0.155| v_loss: 0.029| per_loss: 0.547 | a_loss: 0.500
Train: Epoch [1031/3000], Step [120/158]| g_loss: 0.824| d_loss: 0.540| gp_loss: 0.055| r_loss: 0.086| p_loss: 0.140| v_loss: 0.028| per_loss: 0.496 | a_loss: 0.590
Train: Epoch [1031/3000], Step [150/158]| g_loss: 0.832| d_loss: 0.546| gp_loss: 0.054| r_loss: 0.089| p_loss: 0.148| v_loss: 0.029| per_loss: 0.548 | a_loss: 0.586
Train: Epoch [1032/3000], Step [30/158]| g_loss: 0.791| d_loss: 0.645| gp_loss: 0.136| r_loss: 0.087| p_loss: 0.141| v_loss: 0.030| per_loss: 0.521 | a_loss: 0.551
Train: Epoch [1032/3000], Step [60/158]| g_loss: 0.830| d_loss: 0.552| gp_loss: 0.053| r_loss: 0.087| p_loss: 0.145| v_loss: 0.030| per_loss: 0.511 | a_loss: 0.590
Train: Epoch [1032/3000], Step [90/158]| g_loss: 0.802| d_loss: 0.584| gp_loss: 0.052| r_loss: 0.089| p_loss: 0.147| v_loss: 0.029| per_loss: 0.499 | a_loss: 0.560
Train: Epoch [1032/3000], Step [120/158]| g_loss: 0.802| d_loss: 0.541| gp_loss: 0.055| r_loss: 0.092| p_loss: 0.149| v_loss: 0.030| per_loss: 0.494 | a_loss: 0.556
Train: Epoch [1032/3000], Step [150/158]| g_loss: 0.707| d_loss: 0.685| gp_loss: 0.052| r_loss: 0.090| p_loss: 0.149| v_loss: 0.030| per_loss: 0.456 | a_loss: 0.468
Train: Epoch [1033/3000], Step [30/158]| g_loss: 0.860| d_loss: 0.606| gp_loss: 0.157| r_loss: 0.089| p_loss: 0.148| v_loss: 0.030| per_loss: 0.488 | a_loss: 0.619
Train: Epoch [1033/3000], Step [60/158]| g_loss: 0.735| d_loss: 0.670| gp_loss: 0.052| r_loss: 0.090| p_loss: 0.149| v_loss: 0.029| per_loss: 0.548 | a_loss: 0.487
Train: Epoch [1033/3000], Step [90/158]| g_loss: 0.794| d_loss: 0.624| gp_loss: 0.052| r_loss: 0.091| p_loss: 0.151| v_loss: 0.029| per_loss: 0.431 | a_loss: 0.555
Train: Epoch [1033/3000], Step [120/158]| g_loss: 0.711| d_loss: 0.691| gp_loss: 0.054| r_loss: 0.089| p_loss: 0.148| v_loss: 0.029| per_loss: 0.484 | a_loss: 0.471
Train: Epoch [1033/3000], Step [150/158]| g_loss: 0.795| d_loss: 0.564| gp_loss: 0.055| r_loss: 0.090| p_loss: 0.144| v_loss: 0.029| per_loss: 0.496 | a_loss: 0.555
Train: Epoch [1034/3000], Step [30/158]| g_loss: 0.745| d_loss: 0.718| gp_loss: 0.127| r_loss: 0.089| p_loss: 0.141| v_loss: 0.029| per_loss: 0.493 | a_loss: 0.508
Train: Epoch [1034/3000], Step [60/158]| g_loss: 0.786| d_loss: 0.586| gp_loss: 0.058| r_loss: 0.089| p_loss: 0.145| v_loss: 0.030| per_loss: 0.479 | a_loss: 0.547
Train: Epoch [1034/3000], Step [90/158]| g_loss: 0.826| d_loss: 0.590| gp_loss: 0.056| r_loss: 0.090| p_loss: 0.144| v_loss: 0.029| per_loss: 0.462 | a_loss: 0.589
Train: Epoch [1034/3000], Step [120/158]| g_loss: 0.766| d_loss: 0.599| gp_loss: 0.056| r_loss: 0.089| p_loss: 0.144| v_loss: 0.030| per_loss: 0.493 | a_loss: 0.526
Train: Epoch [1034/3000], Step [150/158]| g_loss: 0.798| d_loss: 0.589| gp_loss: 0.054| r_loss: 0.091| p_loss: 0.142| v_loss: 0.029| per_loss: 0.447 | a_loss: 0.563
Train: Epoch [1035/3000], Step [30/158]| g_loss: 0.802| d_loss: 0.600| gp_loss: 0.134| r_loss: 0.088| p_loss: 0.139| v_loss: 0.029| per_loss: 0.492 | a_loss: 0.566
Train: Epoch [1035/3000], Step [60/158]| g_loss: 0.847| d_loss: 0.545| gp_loss: 0.053| r_loss: 0.086| p_loss: 0.138| v_loss: 0.028| per_loss: 0.450 | a_loss: 0.619
Train: Epoch [1035/3000], Step [90/158]| g_loss: 0.780| d_loss: 0.641| gp_loss: 0.052| r_loss: 0.091| p_loss: 0.146| v_loss: 0.029| per_loss: 0.504 | a_loss: 0.537
Train: Epoch [1035/3000], Step [120/158]| g_loss: 0.759| d_loss: 0.607| gp_loss: 0.056| r_loss: 0.089| p_loss: 0.148| v_loss: 0.030| per_loss: 0.498 | a_loss: 0.517
Train: Epoch [1035/3000], Step [150/158]| g_loss: 0.756| d_loss: 0.672| gp_loss: 0.054| r_loss: 0.086| p_loss: 0.144| v_loss: 0.029| per_loss: 0.495 | a_loss: 0.519
Train: Epoch [1036/3000], Step [30/158]| g_loss: 0.772| d_loss: 0.740| gp_loss: 0.172| r_loss: 0.089| p_loss: 0.144| v_loss: 0.029| per_loss: 0.486 | a_loss: 0.533
Train: Epoch [1036/3000], Step [60/158]| g_loss: 0.733| d_loss: 0.645| gp_loss: 0.052| r_loss: 0.087| p_loss: 0.142| v_loss: 0.029| per_loss: 0.472 | a_loss: 0.499
Train: Epoch [1036/3000], Step [90/158]| g_loss: 0.769| d_loss: 0.645| gp_loss: 0.052| r_loss: 0.087| p_loss: 0.140| v_loss: 0.027| per_loss: 0.522 | a_loss: 0.532
Train: Epoch [1036/3000], Step [120/158]| g_loss: 0.828| d_loss: 0.534| gp_loss: 0.055| r_loss: 0.091| p_loss: 0.151| v_loss: 0.030| per_loss: 0.494 | a_loss: 0.582
Train: Epoch [1036/3000], Step [150/158]| g_loss: 0.798| d_loss: 0.579| gp_loss: 0.052| r_loss: 0.088| p_loss: 0.140| v_loss: 0.029| per_loss: 0.488 | a_loss: 0.562
Train: Epoch [1037/3000], Step [30/158]| g_loss: 0.817| d_loss: 0.697| gp_loss: 0.165| r_loss: 0.089| p_loss: 0.147| v_loss: 0.030| per_loss: 0.489 | a_loss: 0.575
Train: Epoch [1037/3000], Step [60/158]| g_loss: 0.834| d_loss: 0.578| gp_loss: 0.051| r_loss: 0.086| p_loss: 0.139| v_loss: 0.029| per_loss: 0.481 | a_loss: 0.602
Train: Epoch [1037/3000], Step [90/158]| g_loss: 0.744| d_loss: 0.584| gp_loss: 0.050| r_loss: 0.085| p_loss: 0.137| v_loss: 0.030| per_loss: 0.467 | a_loss: 0.513
Train: Epoch [1037/3000], Step [120/158]| g_loss: 0.774| d_loss: 0.637| gp_loss: 0.053| r_loss: 0.090| p_loss: 0.144| v_loss: 0.031| per_loss: 0.500 | a_loss: 0.531
Train: Epoch [1037/3000], Step [150/158]| g_loss: 0.781| d_loss: 0.604| gp_loss: 0.055| r_loss: 0.088| p_loss: 0.138| v_loss: 0.029| per_loss: 0.480 | a_loss: 0.547
Train: Epoch [1038/3000], Step [30/158]| g_loss: 0.787| d_loss: 0.625| gp_loss: 0.143| r_loss: 0.084| p_loss: 0.132| v_loss: 0.029| per_loss: 0.468 | a_loss: 0.561
Train: Epoch [1038/3000], Step [60/158]| g_loss: 0.742| d_loss: 0.622| gp_loss: 0.054| r_loss: 0.087| p_loss: 0.139| v_loss: 0.029| per_loss: 0.496 | a_loss: 0.507
Train: Epoch [1038/3000], Step [90/158]| g_loss: 0.716| d_loss: 0.626| gp_loss: 0.055| r_loss: 0.085| p_loss: 0.139| v_loss: 0.028| per_loss: 0.473 | a_loss: 0.487
Train: Epoch [1038/3000], Step [120/158]| g_loss: 0.861| d_loss: 0.591| gp_loss: 0.054| r_loss: 0.093| p_loss: 0.151| v_loss: 0.029| per_loss: 0.493 | a_loss: 0.614
Train: Epoch [1038/3000], Step [150/158]| g_loss: 0.756| d_loss: 0.639| gp_loss: 0.060| r_loss: 0.088| p_loss: 0.148| v_loss: 0.029| per_loss: 0.478 | a_loss: 0.518
Train: Epoch [1039/3000], Step [30/158]| g_loss: 0.790| d_loss: 0.631| gp_loss: 0.131| r_loss: 0.086| p_loss: 0.141| v_loss: 0.030| per_loss: 0.478 | a_loss: 0.556
Train: Epoch [1039/3000], Step [60/158]| g_loss: 0.782| d_loss: 0.583| gp_loss: 0.055| r_loss: 0.087| p_loss: 0.144| v_loss: 0.029| per_loss: 0.438 | a_loss: 0.550
Train: Epoch [1039/3000], Step [90/158]| g_loss: 0.873| d_loss: 0.532| gp_loss: 0.057| r_loss: 0.089| p_loss: 0.143| v_loss: 0.030| per_loss: 0.483 | a_loss: 0.634
Train: Epoch [1039/3000], Step [120/158]| g_loss: 0.747| d_loss: 0.730| gp_loss: 0.050| r_loss: 0.089| p_loss: 0.143| v_loss: 0.029| per_loss: 0.486 | a_loss: 0.509
Train: Epoch [1039/3000], Step [150/158]| g_loss: 0.779| d_loss: 0.546| gp_loss: 0.057| r_loss: 0.087| p_loss: 0.136| v_loss: 0.029| per_loss: 0.459 | a_loss: 0.549
Train: Epoch [1040/3000], Step [30/158]| g_loss: 0.716| d_loss: 0.712| gp_loss: 0.105| r_loss: 0.085| p_loss: 0.138| v_loss: 0.029| per_loss: 0.496 | a_loss: 0.483
Train: Epoch [1040/3000], Step [60/158]| g_loss: 0.791| d_loss: 0.576| gp_loss: 0.056| r_loss: 0.085| p_loss: 0.135| v_loss: 0.028| per_loss: 0.441 | a_loss: 0.566
Train: Epoch [1040/3000], Step [90/158]| g_loss: 0.758| d_loss: 0.587| gp_loss: 0.055| r_loss: 0.088| p_loss: 0.136| v_loss: 0.027| per_loss: 0.456 | a_loss: 0.529
Train: Epoch [1040/3000], Step [120/158]| g_loss: 0.772| d_loss: 0.572| gp_loss: 0.057| r_loss: 0.083| p_loss: 0.133| v_loss: 0.028| per_loss: 0.474 | a_loss: 0.547
Train: Epoch [1040/3000], Step [150/158]| g_loss: 0.794| d_loss: 0.555| gp_loss: 0.057| r_loss: 0.086| p_loss: 0.137| v_loss: 0.031| per_loss: 0.458 | a_loss: 0.563
Train: Epoch [1041/3000], Step [30/158]| g_loss: 0.762| d_loss: 0.683| gp_loss: 0.114| r_loss: 0.089| p_loss: 0.142| v_loss: 0.030| per_loss: 0.441 | a_loss: 0.527
Train: Epoch [1041/3000], Step [60/158]| g_loss: 0.832| d_loss: 0.563| gp_loss: 0.056| r_loss: 0.087| p_loss: 0.141| v_loss: 0.029| per_loss: 0.483 | a_loss: 0.597
Train: Epoch [1041/3000], Step [90/158]| g_loss: 0.763| d_loss: 0.584| gp_loss: 0.056| r_loss: 0.090| p_loss: 0.139| v_loss: 0.030| per_loss: 0.485 | a_loss: 0.525
Train: Epoch [1041/3000], Step [120/158]| g_loss: 0.858| d_loss: 0.510| gp_loss: 0.060| r_loss: 0.090| p_loss: 0.146| v_loss: 0.029| per_loss: 0.461 | a_loss: 0.620
Train: Epoch [1041/3000], Step [150/158]| g_loss: 0.719| d_loss: 0.720| gp_loss: 0.057| r_loss: 0.088| p_loss: 0.145| v_loss: 0.028| per_loss: 0.485 | a_loss: 0.482
Train: Epoch [1042/3000], Step [30/158]| g_loss: 0.763| d_loss: 0.649| gp_loss: 0.100| r_loss: 0.088| p_loss: 0.147| v_loss: 0.029| per_loss: 0.467 | a_loss: 0.526
Train: Epoch [1042/3000], Step [60/158]| g_loss: 0.781| d_loss: 0.651| gp_loss: 0.059| r_loss: 0.087| p_loss: 0.145| v_loss: 0.029| per_loss: 0.503 | a_loss: 0.543
Train: Epoch [1042/3000], Step [90/158]| g_loss: 0.735| d_loss: 0.656| gp_loss: 0.059| r_loss: 0.089| p_loss: 0.153| v_loss: 0.030| per_loss: 0.481 | a_loss: 0.491
Train: Epoch [1042/3000], Step [120/158]| g_loss: 0.796| d_loss: 0.565| gp_loss: 0.065| r_loss: 0.088| p_loss: 0.152| v_loss: 0.030| per_loss: 0.488 | a_loss: 0.554
Train: Epoch [1042/3000], Step [150/158]| g_loss: 0.794| d_loss: 0.591| gp_loss: 0.057| r_loss: 0.093| p_loss: 0.151| v_loss: 0.029| per_loss: 0.463 | a_loss: 0.550
Train: Epoch [1043/3000], Step [30/158]| g_loss: 0.792| d_loss: 0.727| gp_loss: 0.145| r_loss: 0.090| p_loss: 0.149| v_loss: 0.029| per_loss: 0.498 | a_loss: 0.549
Train: Epoch [1043/3000], Step [60/158]| g_loss: 0.768| d_loss: 0.572| gp_loss: 0.059| r_loss: 0.084| p_loss: 0.139| v_loss: 0.030| per_loss: 0.478 | a_loss: 0.537
Train: Epoch [1043/3000], Step [90/158]| g_loss: 0.807| d_loss: 0.527| gp_loss: 0.059| r_loss: 0.087| p_loss: 0.138| v_loss: 0.029| per_loss: 0.447 | a_loss: 0.578
Train: Epoch [1043/3000], Step [120/158]| g_loss: 0.801| d_loss: 0.566| gp_loss: 0.062| r_loss: 0.083| p_loss: 0.132| v_loss: 0.027| per_loss: 0.502 | a_loss: 0.574
Train: Epoch [1043/3000], Step [150/158]| g_loss: 0.799| d_loss: 0.645| gp_loss: 0.057| r_loss: 0.090| p_loss: 0.148| v_loss: 0.030| per_loss: 0.473 | a_loss: 0.557
Train: Epoch [1044/3000], Step [30/158]| g_loss: 0.731| d_loss: 0.852| gp_loss: 0.302| r_loss: 0.084| p_loss: 0.139| v_loss: 0.029| per_loss: 0.461 | a_loss: 0.503
Train: Epoch [1044/3000], Step [60/158]| g_loss: 0.826| d_loss: 0.583| gp_loss: 0.053| r_loss: 0.087| p_loss: 0.138| v_loss: 0.029| per_loss: 0.500 | a_loss: 0.590
Train: Epoch [1044/3000], Step [90/158]| g_loss: 0.736| d_loss: 0.577| gp_loss: 0.052| r_loss: 0.089| p_loss: 0.143| v_loss: 0.030| per_loss: 0.461 | a_loss: 0.499
Train: Epoch [1044/3000], Step [120/158]| g_loss: 0.792| d_loss: 0.591| gp_loss: 0.053| r_loss: 0.089| p_loss: 0.141| v_loss: 0.029| per_loss: 0.461 | a_loss: 0.557
Train: Epoch [1044/3000], Step [150/158]| g_loss: 0.777| d_loss: 0.671| gp_loss: 0.054| r_loss: 0.092| p_loss: 0.152| v_loss: 0.030| per_loss: 0.514 | a_loss: 0.528
Train: Epoch [1045/3000], Step [30/158]| g_loss: 0.789| d_loss: 0.648| gp_loss: 0.153| r_loss: 0.091| p_loss: 0.150| v_loss: 0.029| per_loss: 0.479 | a_loss: 0.546
Train: Epoch [1045/3000], Step [60/158]| g_loss: 0.806| d_loss: 0.531| gp_loss: 0.051| r_loss: 0.087| p_loss: 0.137| v_loss: 0.029| per_loss: 0.459 | a_loss: 0.575
Train: Epoch [1045/3000], Step [90/158]| g_loss: 0.755| d_loss: 0.654| gp_loss: 0.054| r_loss: 0.089| p_loss: 0.143| v_loss: 0.029| per_loss: 0.462 | a_loss: 0.519
Train: Epoch [1045/3000], Step [120/158]| g_loss: 0.796| d_loss: 0.585| gp_loss: 0.054| r_loss: 0.094| p_loss: 0.145| v_loss: 0.029| per_loss: 0.481 | a_loss: 0.552
Train: Epoch [1045/3000], Step [150/158]| g_loss: 0.752| d_loss: 0.576| gp_loss: 0.057| r_loss: 0.083| p_loss: 0.138| v_loss: 0.028| per_loss: 0.499 | a_loss: 0.522
Train: Epoch [1046/3000], Step [30/158]| g_loss: 0.795| d_loss: 0.672| gp_loss: 0.161| r_loss: 0.086| p_loss: 0.136| v_loss: 0.030| per_loss: 0.465 | a_loss: 0.565
Train: Epoch [1046/3000], Step [60/158]| g_loss: 0.813| d_loss: 0.516| gp_loss: 0.051| r_loss: 0.082| p_loss: 0.129| v_loss: 0.029| per_loss: 0.433 | a_loss: 0.594
Train: Epoch [1046/3000], Step [90/158]| g_loss: 0.767| d_loss: 0.584| gp_loss: 0.051| r_loss: 0.088| p_loss: 0.135| v_loss: 0.028| per_loss: 0.513 | a_loss: 0.531
Train: Epoch [1046/3000], Step [120/158]| g_loss: 0.796| d_loss: 0.619| gp_loss: 0.054| r_loss: 0.084| p_loss: 0.138| v_loss: 0.028| per_loss: 0.454 | a_loss: 0.569
Train: Epoch [1046/3000], Step [150/158]| g_loss: 0.714| d_loss: 0.654| gp_loss: 0.052| r_loss: 0.082| p_loss: 0.128| v_loss: 0.028| per_loss: 0.460 | a_loss: 0.494
Train: Epoch [1047/3000], Step [30/158]| g_loss: 0.740| d_loss: 0.723| gp_loss: 0.173| r_loss: 0.085| p_loss: 0.128| v_loss: 0.030| per_loss: 0.456 | a_loss: 0.515
Train: Epoch [1047/3000], Step [60/158]| g_loss: 0.698| d_loss: 0.639| gp_loss: 0.051| r_loss: 0.085| p_loss: 0.132| v_loss: 0.028| per_loss: 0.467 | a_loss: 0.472
Train: Epoch [1047/3000], Step [90/158]| g_loss: 0.787| d_loss: 0.571| gp_loss: 0.055| r_loss: 0.083| p_loss: 0.136| v_loss: 0.029| per_loss: 0.464 | a_loss: 0.560
Train: Epoch [1047/3000], Step [120/158]| g_loss: 0.830| d_loss: 0.479| gp_loss: 0.061| r_loss: 0.085| p_loss: 0.133| v_loss: 0.028| per_loss: 0.479 | a_loss: 0.602
Train: Epoch [1047/3000], Step [150/158]| g_loss: 0.727| d_loss: 0.609| gp_loss: 0.059| r_loss: 0.080| p_loss: 0.131| v_loss: 0.027| per_loss: 0.442 | a_loss: 0.510
Train: Epoch [1048/3000], Step [30/158]| g_loss: 0.753| d_loss: 0.699| gp_loss: 0.137| r_loss: 0.085| p_loss: 0.132| v_loss: 0.028| per_loss: 0.476 | a_loss: 0.526
Train: Epoch [1048/3000], Step [60/158]| g_loss: 0.824| d_loss: 0.518| gp_loss: 0.057| r_loss: 0.083| p_loss: 0.131| v_loss: 0.028| per_loss: 0.471 | a_loss: 0.600
Train: Epoch [1048/3000], Step [90/158]| g_loss: 0.799| d_loss: 0.581| gp_loss: 0.057| r_loss: 0.086| p_loss: 0.138| v_loss: 0.029| per_loss: 0.499 | a_loss: 0.565
Train: Epoch [1048/3000], Step [120/158]| g_loss: 0.805| d_loss: 0.563| gp_loss: 0.057| r_loss: 0.084| p_loss: 0.134| v_loss: 0.028| per_loss: 0.488 | a_loss: 0.577
Train: Epoch [1048/3000], Step [150/158]| g_loss: 0.746| d_loss: 0.628| gp_loss: 0.057| r_loss: 0.090| p_loss: 0.147| v_loss: 0.029| per_loss: 0.478 | a_loss: 0.506
Train: Epoch [1049/3000], Step [30/158]| g_loss: 0.803| d_loss: 0.681| gp_loss: 0.169| r_loss: 0.088| p_loss: 0.142| v_loss: 0.028| per_loss: 0.509 | a_loss: 0.565
Train: Epoch [1049/3000], Step [60/158]| g_loss: 0.847| d_loss: 0.513| gp_loss: 0.053| r_loss: 0.085| p_loss: 0.136| v_loss: 0.029| per_loss: 0.492 | a_loss: 0.616
Train: Epoch [1049/3000], Step [90/158]| g_loss: 0.740| d_loss: 0.649| gp_loss: 0.053| r_loss: 0.086| p_loss: 0.145| v_loss: 0.029| per_loss: 0.489 | a_loss: 0.504
Train: Epoch [1049/3000], Step [120/158]| g_loss: 0.743| d_loss: 0.679| gp_loss: 0.053| r_loss: 0.086| p_loss: 0.138| v_loss: 0.030| per_loss: 0.464 | a_loss: 0.512
Train: Epoch [1049/3000], Step [150/158]| g_loss: 0.794| d_loss: 0.548| gp_loss: 0.059| r_loss: 0.087| p_loss: 0.138| v_loss: 0.028| per_loss: 0.520 | a_loss: 0.558
Train: Epoch [1050/3000], Step [30/158]| g_loss: 0.803| d_loss: 0.695| gp_loss: 0.154| r_loss: 0.085| p_loss: 0.138| v_loss: 0.027| per_loss: 0.457 | a_loss: 0.576
Train: Epoch [1050/3000], Step [60/158]| g_loss: 0.819| d_loss: 0.599| gp_loss: 0.049| r_loss: 0.092| p_loss: 0.144| v_loss: 0.029| per_loss: 0.502 | a_loss: 0.576
Train: Epoch [1050/3000], Step [90/158]| g_loss: 0.754| d_loss: 0.642| gp_loss: 0.060| r_loss: 0.091| p_loss: 0.152| v_loss: 0.030| per_loss: 0.505 | a_loss: 0.506
Train: Epoch [1050/3000], Step [120/158]| g_loss: 0.814| d_loss: 0.547| gp_loss: 0.054| r_loss: 0.092| p_loss: 0.140| v_loss: 0.030| per_loss: 0.452 | a_loss: 0.577
Train: Epoch [1050/3000], Step [150/158]| g_loss: 0.769| d_loss: 0.654| gp_loss: 0.059| r_loss: 0.091| p_loss: 0.145| v_loss: 0.029| per_loss: 0.503 | a_loss: 0.526
Test: Epoch [1050/3000]| g_loss: 0.667| r_loss: 0.414| p_loss: 0.315| v_loss: 0.024
Train: Epoch [1051/3000], Step [30/158]| g_loss: 0.842| d_loss: 0.547| gp_loss: 0.051| r_loss: 0.091| p_loss: 0.146| v_loss: 0.027| per_loss: 0.468 | a_loss: 0.604
Train: Epoch [1051/3000], Step [60/158]| g_loss: 0.779| d_loss: 0.587| gp_loss: 0.050| r_loss: 0.090| p_loss: 0.140| v_loss: 0.029| per_loss: 0.509 | a_loss: 0.539
Train: Epoch [1051/3000], Step [90/158]| g_loss: 0.762| d_loss: 0.605| gp_loss: 0.057| r_loss: 0.087| p_loss: 0.136| v_loss: 0.029| per_loss: 0.488 | a_loss: 0.530
Train: Epoch [1051/3000], Step [120/158]| g_loss: 0.784| d_loss: 0.567| gp_loss: 0.054| r_loss: 0.083| p_loss: 0.135| v_loss: 0.028| per_loss: 0.474 | a_loss: 0.558
Train: Epoch [1051/3000], Step [150/158]| g_loss: 0.753| d_loss: 0.696| gp_loss: 0.052| r_loss: 0.086| p_loss: 0.138| v_loss: 0.028| per_loss: 0.464 | a_loss: 0.523
Train: Epoch [1052/3000], Step [30/158]| g_loss: 0.774| d_loss: 0.660| gp_loss: 0.150| r_loss: 0.085| p_loss: 0.131| v_loss: 0.028| per_loss: 0.504 | a_loss: 0.545
Train: Epoch [1052/3000], Step [60/158]| g_loss: 0.774| d_loss: 0.557| gp_loss: 0.049| r_loss: 0.087| p_loss: 0.135| v_loss: 0.029| per_loss: 0.527 | a_loss: 0.538
Train: Epoch [1052/3000], Step [90/158]| g_loss: 0.808| d_loss: 0.616| gp_loss: 0.050| r_loss: 0.084| p_loss: 0.131| v_loss: 0.029| per_loss: 0.448 | a_loss: 0.585
Train: Epoch [1052/3000], Step [120/158]| g_loss: 0.730| d_loss: 0.603| gp_loss: 0.054| r_loss: 0.086| p_loss: 0.137| v_loss: 0.028| per_loss: 0.472 | a_loss: 0.500
Train: Epoch [1052/3000], Step [150/158]| g_loss: 0.729| d_loss: 0.671| gp_loss: 0.054| r_loss: 0.085| p_loss: 0.138| v_loss: 0.028| per_loss: 0.475 | a_loss: 0.500
Train: Epoch [1053/3000], Step [30/158]| g_loss: 0.778| d_loss: 0.602| gp_loss: 0.137| r_loss: 0.084| p_loss: 0.133| v_loss: 0.028| per_loss: 0.476 | a_loss: 0.553
Train: Epoch [1053/3000], Step [60/158]| g_loss: 0.842| d_loss: 0.520| gp_loss: 0.052| r_loss: 0.084| p_loss: 0.131| v_loss: 0.029| per_loss: 0.488 | a_loss: 0.615
Train: Epoch [1053/3000], Step [90/158]| g_loss: 0.696| d_loss: 0.690| gp_loss: 0.053| r_loss: 0.084| p_loss: 0.137| v_loss: 0.027| per_loss: 0.493 | a_loss: 0.467
Train: Epoch [1053/3000], Step [120/158]| g_loss: 0.816| d_loss: 0.563| gp_loss: 0.055| r_loss: 0.086| p_loss: 0.137| v_loss: 0.028| per_loss: 0.462 | a_loss: 0.588
Train: Epoch [1053/3000], Step [150/158]| g_loss: 0.756| d_loss: 0.558| gp_loss: 0.053| r_loss: 0.085| p_loss: 0.132| v_loss: 0.029| per_loss: 0.450 | a_loss: 0.532
Train: Epoch [1054/3000], Step [30/158]| g_loss: 0.713| d_loss: 0.783| gp_loss: 0.131| r_loss: 0.080| p_loss: 0.132| v_loss: 0.027| per_loss: 0.456 | a_loss: 0.494
Train: Epoch [1054/3000], Step [60/158]| g_loss: 0.799| d_loss: 0.580| gp_loss: 0.051| r_loss: 0.084| p_loss: 0.135| v_loss: 0.028| per_loss: 0.477 | a_loss: 0.572
Train: Epoch [1054/3000], Step [90/158]| g_loss: 0.753| d_loss: 0.605| gp_loss: 0.053| r_loss: 0.087| p_loss: 0.137| v_loss: 0.028| per_loss: 0.455 | a_loss: 0.524
Train: Epoch [1054/3000], Step [120/158]| g_loss: 0.791| d_loss: 0.589| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.132| v_loss: 0.027| per_loss: 0.472 | a_loss: 0.566
Train: Epoch [1054/3000], Step [150/158]| g_loss: 0.742| d_loss: 0.560| gp_loss: 0.057| r_loss: 0.088| p_loss: 0.138| v_loss: 0.030| per_loss: 0.490 | a_loss: 0.506
Train: Epoch [1055/3000], Step [30/158]| g_loss: 0.810| d_loss: 0.647| gp_loss: 0.135| r_loss: 0.083| p_loss: 0.136| v_loss: 0.027| per_loss: 0.490 | a_loss: 0.583
Train: Epoch [1055/3000], Step [60/158]| g_loss: 0.772| d_loss: 0.620| gp_loss: 0.052| r_loss: 0.089| p_loss: 0.143| v_loss: 0.029| per_loss: 0.477 | a_loss: 0.535
Train: Epoch [1055/3000], Step [90/158]| g_loss: 0.730| d_loss: 0.634| gp_loss: 0.052| r_loss: 0.089| p_loss: 0.143| v_loss: 0.028| per_loss: 0.466 | a_loss: 0.495
Train: Epoch [1055/3000], Step [120/158]| g_loss: 0.836| d_loss: 0.531| gp_loss: 0.057| r_loss: 0.088| p_loss: 0.136| v_loss: 0.028| per_loss: 0.505 | a_loss: 0.602
Train: Epoch [1055/3000], Step [150/158]| g_loss: 0.756| d_loss: 0.652| gp_loss: 0.054| r_loss: 0.083| p_loss: 0.134| v_loss: 0.027| per_loss: 0.471 | a_loss: 0.532
Train: Epoch [1056/3000], Step [30/158]| g_loss: 0.787| d_loss: 0.642| gp_loss: 0.166| r_loss: 0.087| p_loss: 0.140| v_loss: 0.029| per_loss: 0.487 | a_loss: 0.552
Train: Epoch [1056/3000], Step [60/158]| g_loss: 0.781| d_loss: 0.622| gp_loss: 0.055| r_loss: 0.084| p_loss: 0.134| v_loss: 0.028| per_loss: 0.501 | a_loss: 0.552
Train: Epoch [1056/3000], Step [90/158]| g_loss: 0.769| d_loss: 0.576| gp_loss: 0.052| r_loss: 0.085| p_loss: 0.138| v_loss: 0.028| per_loss: 0.473 | a_loss: 0.539
Train: Epoch [1056/3000], Step [120/158]| g_loss: 0.755| d_loss: 0.646| gp_loss: 0.055| r_loss: 0.083| p_loss: 0.135| v_loss: 0.027| per_loss: 0.499 | a_loss: 0.527
Train: Epoch [1056/3000], Step [150/158]| g_loss: 0.777| d_loss: 0.613| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.138| v_loss: 0.028| per_loss: 0.479 | a_loss: 0.547
Train: Epoch [1057/3000], Step [30/158]| g_loss: 0.797| d_loss: 0.679| gp_loss: 0.161| r_loss: 0.094| p_loss: 0.144| v_loss: 0.028| per_loss: 0.442 | a_loss: 0.559
Train: Epoch [1057/3000], Step [60/158]| g_loss: 0.801| d_loss: 0.559| gp_loss: 0.052| r_loss: 0.085| p_loss: 0.136| v_loss: 0.029| per_loss: 0.513 | a_loss: 0.567
Train: Epoch [1057/3000], Step [90/158]| g_loss: 0.775| d_loss: 0.562| gp_loss: 0.053| r_loss: 0.085| p_loss: 0.137| v_loss: 0.029| per_loss: 0.508 | a_loss: 0.541
Train: Epoch [1057/3000], Step [120/158]| g_loss: 0.823| d_loss: 0.559| gp_loss: 0.053| r_loss: 0.085| p_loss: 0.133| v_loss: 0.028| per_loss: 0.472 | a_loss: 0.597
Train: Epoch [1057/3000], Step [150/158]| g_loss: 0.752| d_loss: 0.644| gp_loss: 0.057| r_loss: 0.087| p_loss: 0.136| v_loss: 0.028| per_loss: 0.469 | a_loss: 0.522
Train: Epoch [1058/3000], Step [30/158]| g_loss: 0.748| d_loss: 0.726| gp_loss: 0.127| r_loss: 0.082| p_loss: 0.137| v_loss: 0.028| per_loss: 0.483 | a_loss: 0.520
Train: Epoch [1058/3000], Step [60/158]| g_loss: 0.798| d_loss: 0.577| gp_loss: 0.055| r_loss: 0.091| p_loss: 0.147| v_loss: 0.029| per_loss: 0.495 | a_loss: 0.556
Train: Epoch [1058/3000], Step [90/158]| g_loss: 0.778| d_loss: 0.603| gp_loss: 0.053| r_loss: 0.088| p_loss: 0.139| v_loss: 0.028| per_loss: 0.475 | a_loss: 0.545
Train: Epoch [1058/3000], Step [120/158]| g_loss: 0.767| d_loss: 0.611| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.135| v_loss: 0.028| per_loss: 0.462 | a_loss: 0.540
Train: Epoch [1058/3000], Step [150/158]| g_loss: 0.762| d_loss: 0.601| gp_loss: 0.055| r_loss: 0.085| p_loss: 0.137| v_loss: 0.029| per_loss: 0.481 | a_loss: 0.531
Train: Epoch [1059/3000], Step [30/158]| g_loss: 0.788| d_loss: 0.744| gp_loss: 0.203| r_loss: 0.088| p_loss: 0.142| v_loss: 0.029| per_loss: 0.476 | a_loss: 0.552
Train: Epoch [1059/3000], Step [60/158]| g_loss: 0.809| d_loss: 0.559| gp_loss: 0.049| r_loss: 0.084| p_loss: 0.137| v_loss: 0.028| per_loss: 0.483 | a_loss: 0.580
Train: Epoch [1059/3000], Step [90/158]| g_loss: 0.792| d_loss: 0.575| gp_loss: 0.052| r_loss: 0.089| p_loss: 0.139| v_loss: 0.028| per_loss: 0.470 | a_loss: 0.559
Train: Epoch [1059/3000], Step [120/158]| g_loss: 0.818| d_loss: 0.564| gp_loss: 0.052| r_loss: 0.087| p_loss: 0.138| v_loss: 0.028| per_loss: 0.476 | a_loss: 0.586
Train: Epoch [1059/3000], Step [150/158]| g_loss: 0.712| d_loss: 0.654| gp_loss: 0.053| r_loss: 0.084| p_loss: 0.131| v_loss: 0.029| per_loss: 0.453 | a_loss: 0.488
Train: Epoch [1060/3000], Step [30/158]| g_loss: 0.687| d_loss: 0.728| gp_loss: 0.111| r_loss: 0.084| p_loss: 0.135| v_loss: 0.028| per_loss: 0.448 | a_loss: 0.463
Train: Epoch [1060/3000], Step [60/158]| g_loss: 0.793| d_loss: 0.571| gp_loss: 0.052| r_loss: 0.086| p_loss: 0.133| v_loss: 0.029| per_loss: 0.495 | a_loss: 0.562
Train: Epoch [1060/3000], Step [90/158]| g_loss: 0.779| d_loss: 0.613| gp_loss: 0.054| r_loss: 0.086| p_loss: 0.129| v_loss: 0.028| per_loss: 0.467 | a_loss: 0.555
Train: Epoch [1060/3000], Step [120/158]| g_loss: 0.860| d_loss: 0.452| gp_loss: 0.058| r_loss: 0.085| p_loss: 0.133| v_loss: 0.029| per_loss: 0.467 | a_loss: 0.633
Train: Epoch [1060/3000], Step [150/158]| g_loss: 0.703| d_loss: 0.672| gp_loss: 0.056| r_loss: 0.082| p_loss: 0.134| v_loss: 0.028| per_loss: 0.507 | a_loss: 0.475
Train: Epoch [1061/3000], Step [30/158]| g_loss: 0.748| d_loss: 0.756| gp_loss: 0.140| r_loss: 0.081| p_loss: 0.133| v_loss: 0.028| per_loss: 0.470 | a_loss: 0.526
Train: Epoch [1061/3000], Step [60/158]| g_loss: 0.819| d_loss: 0.530| gp_loss: 0.056| r_loss: 0.087| p_loss: 0.134| v_loss: 0.029| per_loss: 0.500 | a_loss: 0.585
Train: Epoch [1061/3000], Step [90/158]| g_loss: 0.792| d_loss: 0.565| gp_loss: 0.056| r_loss: 0.083| p_loss: 0.133| v_loss: 0.029| per_loss: 0.481 | a_loss: 0.566
Train: Epoch [1061/3000], Step [120/158]| g_loss: 0.769| d_loss: 0.580| gp_loss: 0.055| r_loss: 0.080| p_loss: 0.127| v_loss: 0.028| per_loss: 0.465 | a_loss: 0.551
Train: Epoch [1061/3000], Step [150/158]| g_loss: 0.774| d_loss: 0.611| gp_loss: 0.055| r_loss: 0.087| p_loss: 0.136| v_loss: 0.029| per_loss: 0.476 | a_loss: 0.542
Train: Epoch [1062/3000], Step [30/158]| g_loss: 0.789| d_loss: 0.698| gp_loss: 0.194| r_loss: 0.086| p_loss: 0.134| v_loss: 0.028| per_loss: 0.472 | a_loss: 0.561
Train: Epoch [1062/3000], Step [60/158]| g_loss: 0.856| d_loss: 0.516| gp_loss: 0.049| r_loss: 0.087| p_loss: 0.139| v_loss: 0.029| per_loss: 0.498 | a_loss: 0.622
Train: Epoch [1062/3000], Step [90/158]| g_loss: 0.766| d_loss: 0.627| gp_loss: 0.057| r_loss: 0.082| p_loss: 0.127| v_loss: 0.028| per_loss: 0.519 | a_loss: 0.541
Train: Epoch [1062/3000], Step [120/158]| g_loss: 0.747| d_loss: 0.640| gp_loss: 0.051| r_loss: 0.084| p_loss: 0.140| v_loss: 0.029| per_loss: 0.447 | a_loss: 0.519
Train: Epoch [1062/3000], Step [150/158]| g_loss: 0.801| d_loss: 0.595| gp_loss: 0.057| r_loss: 0.083| p_loss: 0.138| v_loss: 0.028| per_loss: 0.462 | a_loss: 0.575
Train: Epoch [1063/3000], Step [30/158]| g_loss: 0.822| d_loss: 0.712| gp_loss: 0.156| r_loss: 0.089| p_loss: 0.145| v_loss: 0.029| per_loss: 0.515 | a_loss: 0.580
Train: Epoch [1063/3000], Step [60/158]| g_loss: 0.664| d_loss: 0.707| gp_loss: 0.055| r_loss: 0.085| p_loss: 0.142| v_loss: 0.027| per_loss: 0.450 | a_loss: 0.437
Train: Epoch [1063/3000], Step [90/158]| g_loss: 0.806| d_loss: 0.589| gp_loss: 0.051| r_loss: 0.085| p_loss: 0.135| v_loss: 0.028| per_loss: 0.459 | a_loss: 0.580
Train: Epoch [1063/3000], Step [120/158]| g_loss: 0.747| d_loss: 0.588| gp_loss: 0.055| r_loss: 0.086| p_loss: 0.146| v_loss: 0.030| per_loss: 0.488 | a_loss: 0.509
Train: Epoch [1063/3000], Step [150/158]| g_loss: 0.822| d_loss: 0.514| gp_loss: 0.057| r_loss: 0.088| p_loss: 0.143| v_loss: 0.030| per_loss: 0.490 | a_loss: 0.583
Train: Epoch [1064/3000], Step [30/158]| g_loss: 0.740| d_loss: 0.823| gp_loss: 0.178| r_loss: 0.081| p_loss: 0.126| v_loss: 0.028| per_loss: 0.465 | a_loss: 0.521
Train: Epoch [1064/3000], Step [60/158]| g_loss: 0.750| d_loss: 0.603| gp_loss: 0.052| r_loss: 0.082| p_loss: 0.134| v_loss: 0.028| per_loss: 0.481 | a_loss: 0.525
Train: Epoch [1064/3000], Step [90/158]| g_loss: 0.808| d_loss: 0.548| gp_loss: 0.055| r_loss: 0.083| p_loss: 0.130| v_loss: 0.028| per_loss: 0.463 | a_loss: 0.585
Train: Epoch [1064/3000], Step [120/158]| g_loss: 0.758| d_loss: 0.559| gp_loss: 0.054| r_loss: 0.085| p_loss: 0.135| v_loss: 0.029| per_loss: 0.442 | a_loss: 0.533
Train: Epoch [1064/3000], Step [150/158]| g_loss: 0.827| d_loss: 0.520| gp_loss: 0.057| r_loss: 0.087| p_loss: 0.138| v_loss: 0.028| per_loss: 0.486 | a_loss: 0.594
Train: Epoch [1065/3000], Step [30/158]| g_loss: 0.769| d_loss: 0.678| gp_loss: 0.144| r_loss: 0.080| p_loss: 0.126| v_loss: 0.028| per_loss: 0.467 | a_loss: 0.551
Train: Epoch [1065/3000], Step [60/158]| g_loss: 0.717| d_loss: 0.659| gp_loss: 0.052| r_loss: 0.083| p_loss: 0.131| v_loss: 0.028| per_loss: 0.452 | a_loss: 0.496
Train: Epoch [1065/3000], Step [90/158]| g_loss: 0.757| d_loss: 0.598| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.135| v_loss: 0.029| per_loss: 0.444 | a_loss: 0.530
Train: Epoch [1065/3000], Step [120/158]| g_loss: 0.812| d_loss: 0.504| gp_loss: 0.057| r_loss: 0.086| p_loss: 0.132| v_loss: 0.029| per_loss: 0.486 | a_loss: 0.582
Train: Epoch [1065/3000], Step [150/158]| g_loss: 0.844| d_loss: 0.489| gp_loss: 0.055| r_loss: 0.086| p_loss: 0.136| v_loss: 0.027| per_loss: 0.478 | a_loss: 0.615
Train: Epoch [1066/3000], Step [30/158]| g_loss: 0.793| d_loss: 0.656| gp_loss: 0.123| r_loss: 0.088| p_loss: 0.136| v_loss: 0.029| per_loss: 0.467 | a_loss: 0.561
Train: Epoch [1066/3000], Step [60/158]| g_loss: 0.819| d_loss: 0.531| gp_loss: 0.053| r_loss: 0.085| p_loss: 0.134| v_loss: 0.028| per_loss: 0.452 | a_loss: 0.594
Train: Epoch [1066/3000], Step [90/158]| g_loss: 0.780| d_loss: 0.624| gp_loss: 0.055| r_loss: 0.085| p_loss: 0.136| v_loss: 0.029| per_loss: 0.490 | a_loss: 0.550
Train: Epoch [1066/3000], Step [120/158]| g_loss: 0.789| d_loss: 0.616| gp_loss: 0.054| r_loss: 0.083| p_loss: 0.131| v_loss: 0.029| per_loss: 0.506 | a_loss: 0.560
Train: Epoch [1066/3000], Step [150/158]| g_loss: 0.745| d_loss: 0.636| gp_loss: 0.056| r_loss: 0.084| p_loss: 0.137| v_loss: 0.028| per_loss: 0.491 | a_loss: 0.515
Train: Epoch [1067/3000], Step [30/158]| g_loss: 0.700| d_loss: 0.731| gp_loss: 0.116| r_loss: 0.086| p_loss: 0.136| v_loss: 0.028| per_loss: 0.467 | a_loss: 0.472
Train: Epoch [1067/3000], Step [60/158]| g_loss: 0.814| d_loss: 0.525| gp_loss: 0.052| r_loss: 0.087| p_loss: 0.136| v_loss: 0.028| per_loss: 0.527 | a_loss: 0.579
Train: Epoch [1067/3000], Step [90/158]| g_loss: 0.795| d_loss: 0.591| gp_loss: 0.057| r_loss: 0.086| p_loss: 0.131| v_loss: 0.029| per_loss: 0.456 | a_loss: 0.569
Train: Epoch [1067/3000], Step [120/158]| g_loss: 0.787| d_loss: 0.553| gp_loss: 0.059| r_loss: 0.083| p_loss: 0.135| v_loss: 0.029| per_loss: 0.462 | a_loss: 0.562
Train: Epoch [1067/3000], Step [150/158]| g_loss: 0.775| d_loss: 0.603| gp_loss: 0.059| r_loss: 0.084| p_loss: 0.132| v_loss: 0.029| per_loss: 0.471 | a_loss: 0.548
Train: Epoch [1068/3000], Step [30/158]| g_loss: 0.740| d_loss: 0.727| gp_loss: 0.185| r_loss: 0.083| p_loss: 0.130| v_loss: 0.028| per_loss: 0.475 | a_loss: 0.516
Train: Epoch [1068/3000], Step [60/158]| g_loss: 0.811| d_loss: 0.588| gp_loss: 0.050| r_loss: 0.084| p_loss: 0.129| v_loss: 0.029| per_loss: 0.499 | a_loss: 0.584
Train: Epoch [1068/3000], Step [90/158]| g_loss: 0.726| d_loss: 0.650| gp_loss: 0.055| r_loss: 0.085| p_loss: 0.132| v_loss: 0.029| per_loss: 0.470 | a_loss: 0.500
Train: Epoch [1068/3000], Step [120/158]| g_loss: 0.778| d_loss: 0.611| gp_loss: 0.054| r_loss: 0.086| p_loss: 0.132| v_loss: 0.029| per_loss: 0.480 | a_loss: 0.550
Train: Epoch [1068/3000], Step [150/158]| g_loss: 0.783| d_loss: 0.568| gp_loss: 0.059| r_loss: 0.084| p_loss: 0.133| v_loss: 0.028| per_loss: 0.456 | a_loss: 0.559
Train: Epoch [1069/3000], Step [30/158]| g_loss: 0.797| d_loss: 0.696| gp_loss: 0.197| r_loss: 0.087| p_loss: 0.135| v_loss: 0.028| per_loss: 0.477 | a_loss: 0.566
Train: Epoch [1069/3000], Step [60/158]| g_loss: 0.752| d_loss: 0.604| gp_loss: 0.048| r_loss: 0.088| p_loss: 0.134| v_loss: 0.030| per_loss: 0.465 | a_loss: 0.521
Train: Epoch [1069/3000], Step [90/158]| g_loss: 0.806| d_loss: 0.511| gp_loss: 0.053| r_loss: 0.083| p_loss: 0.130| v_loss: 0.029| per_loss: 0.445 | a_loss: 0.584
Train: Epoch [1069/3000], Step [120/158]| g_loss: 0.740| d_loss: 0.633| gp_loss: 0.054| r_loss: 0.085| p_loss: 0.128| v_loss: 0.029| per_loss: 0.503 | a_loss: 0.511
Train: Epoch [1069/3000], Step [150/158]| g_loss: 0.786| d_loss: 0.572| gp_loss: 0.057| r_loss: 0.084| p_loss: 0.134| v_loss: 0.029| per_loss: 0.489 | a_loss: 0.558
Train: Epoch [1070/3000], Step [30/158]| g_loss: 0.756| d_loss: 0.668| gp_loss: 0.148| r_loss: 0.085| p_loss: 0.131| v_loss: 0.028| per_loss: 0.524 | a_loss: 0.524
Train: Epoch [1070/3000], Step [60/158]| g_loss: 0.780| d_loss: 0.574| gp_loss: 0.056| r_loss: 0.082| p_loss: 0.127| v_loss: 0.029| per_loss: 0.455 | a_loss: 0.560
Train: Epoch [1070/3000], Step [90/158]| g_loss: 0.802| d_loss: 0.549| gp_loss: 0.054| r_loss: 0.081| p_loss: 0.131| v_loss: 0.030| per_loss: 0.446 | a_loss: 0.581
Train: Epoch [1070/3000], Step [120/158]| g_loss: 0.742| d_loss: 0.639| gp_loss: 0.056| r_loss: 0.086| p_loss: 0.131| v_loss: 0.029| per_loss: 0.462 | a_loss: 0.515
Train: Epoch [1070/3000], Step [150/158]| g_loss: 0.727| d_loss: 0.625| gp_loss: 0.059| r_loss: 0.086| p_loss: 0.140| v_loss: 0.028| per_loss: 0.459 | a_loss: 0.498
Train: Epoch [1071/3000], Step [30/158]| g_loss: 0.829| d_loss: 0.590| gp_loss: 0.117| r_loss: 0.086| p_loss: 0.132| v_loss: 0.029| per_loss: 0.515 | a_loss: 0.596
Train: Epoch [1071/3000], Step [60/158]| g_loss: 0.816| d_loss: 0.560| gp_loss: 0.055| r_loss: 0.085| p_loss: 0.133| v_loss: 0.028| per_loss: 0.466 | a_loss: 0.590
Train: Epoch [1071/3000], Step [90/158]| g_loss: 0.787| d_loss: 0.605| gp_loss: 0.060| r_loss: 0.092| p_loss: 0.145| v_loss: 0.030| per_loss: 0.486 | a_loss: 0.544
Train: Epoch [1071/3000], Step [120/158]| g_loss: 0.814| d_loss: 0.638| gp_loss: 0.058| r_loss: 0.092| p_loss: 0.142| v_loss: 0.028| per_loss: 0.468 | a_loss: 0.576
Train: Epoch [1071/3000], Step [150/158]| g_loss: 0.742| d_loss: 0.651| gp_loss: 0.061| r_loss: 0.092| p_loss: 0.148| v_loss: 0.030| per_loss: 0.469 | a_loss: 0.499
Train: Epoch [1072/3000], Step [30/158]| g_loss: 0.750| d_loss: 0.637| gp_loss: 0.078| r_loss: 0.093| p_loss: 0.151| v_loss: 0.030| per_loss: 0.454 | a_loss: 0.506
Train: Epoch [1072/3000], Step [60/158]| g_loss: 0.809| d_loss: 0.568| gp_loss: 0.061| r_loss: 0.085| p_loss: 0.140| v_loss: 0.028| per_loss: 0.480 | a_loss: 0.578
Train: Epoch [1072/3000], Step [90/158]| g_loss: 0.778| d_loss: 0.647| gp_loss: 0.063| r_loss: 0.090| p_loss: 0.141| v_loss: 0.029| per_loss: 0.495 | a_loss: 0.539
Train: Epoch [1072/3000], Step [120/158]| g_loss: 0.784| d_loss: 0.594| gp_loss: 0.056| r_loss: 0.082| p_loss: 0.134| v_loss: 0.028| per_loss: 0.509 | a_loss: 0.555
Train: Epoch [1072/3000], Step [150/158]| g_loss: 0.747| d_loss: 0.644| gp_loss: 0.062| r_loss: 0.085| p_loss: 0.139| v_loss: 0.030| per_loss: 0.465 | a_loss: 0.516
Train: Epoch [1073/3000], Step [30/158]| g_loss: 0.810| d_loss: 0.634| gp_loss: 0.140| r_loss: 0.086| p_loss: 0.136| v_loss: 0.031| per_loss: 0.465 | a_loss: 0.578
Train: Epoch [1073/3000], Step [60/158]| g_loss: 0.755| d_loss: 0.633| gp_loss: 0.054| r_loss: 0.085| p_loss: 0.139| v_loss: 0.031| per_loss: 0.451 | a_loss: 0.524
Train: Epoch [1073/3000], Step [90/158]| g_loss: 0.756| d_loss: 0.594| gp_loss: 0.057| r_loss: 0.082| p_loss: 0.135| v_loss: 0.029| per_loss: 0.500 | a_loss: 0.527
Train: Epoch [1073/3000], Step [120/158]| g_loss: 0.766| d_loss: 0.579| gp_loss: 0.060| r_loss: 0.095| p_loss: 0.146| v_loss: 0.030| per_loss: 0.436 | a_loss: 0.525
Train: Epoch [1073/3000], Step [150/158]| g_loss: 0.766| d_loss: 0.617| gp_loss: 0.061| r_loss: 0.090| p_loss: 0.144| v_loss: 0.029| per_loss: 0.493 | a_loss: 0.526
Train: Epoch [1074/3000], Step [30/158]| g_loss: 0.757| d_loss: 0.787| gp_loss: 0.221| r_loss: 0.099| p_loss: 0.162| v_loss: 0.030| per_loss: 0.469 | a_loss: 0.500
Train: Epoch [1074/3000], Step [60/158]| g_loss: 0.802| d_loss: 0.652| gp_loss: 0.055| r_loss: 0.089| p_loss: 0.146| v_loss: 0.030| per_loss: 0.486 | a_loss: 0.561
Train: Epoch [1074/3000], Step [90/158]| g_loss: 0.788| d_loss: 0.569| gp_loss: 0.058| r_loss: 0.091| p_loss: 0.149| v_loss: 0.030| per_loss: 0.468 | a_loss: 0.546
Train: Epoch [1074/3000], Step [120/158]| g_loss: 0.735| d_loss: 0.632| gp_loss: 0.055| r_loss: 0.085| p_loss: 0.135| v_loss: 0.030| per_loss: 0.457 | a_loss: 0.506
Train: Epoch [1074/3000], Step [150/158]| g_loss: 0.783| d_loss: 0.632| gp_loss: 0.060| r_loss: 0.082| p_loss: 0.130| v_loss: 0.028| per_loss: 0.491 | a_loss: 0.559
Train: Epoch [1075/3000], Step [30/158]| g_loss: 0.738| d_loss: 0.724| gp_loss: 0.161| r_loss: 0.084| p_loss: 0.130| v_loss: 0.029| per_loss: 0.493 | a_loss: 0.510
Train: Epoch [1075/3000], Step [60/158]| g_loss: 0.732| d_loss: 0.571| gp_loss: 0.054| r_loss: 0.085| p_loss: 0.134| v_loss: 0.030| per_loss: 0.461 | a_loss: 0.504
Train: Epoch [1075/3000], Step [90/158]| g_loss: 0.937| d_loss: 0.402| gp_loss: 0.059| r_loss: 0.088| p_loss: 0.141| v_loss: 0.031| per_loss: 0.489 | a_loss: 0.699
Train: Epoch [1075/3000], Step [120/158]| g_loss: 0.752| d_loss: 0.624| gp_loss: 0.053| r_loss: 0.081| p_loss: 0.131| v_loss: 0.030| per_loss: 0.461 | a_loss: 0.529
Train: Epoch [1075/3000], Step [150/158]| g_loss: 0.789| d_loss: 0.632| gp_loss: 0.055| r_loss: 0.081| p_loss: 0.132| v_loss: 0.029| per_loss: 0.472 | a_loss: 0.566
Train: Epoch [1076/3000], Step [30/158]| g_loss: 0.744| d_loss: 0.724| gp_loss: 0.161| r_loss: 0.090| p_loss: 0.138| v_loss: 0.029| per_loss: 0.471 | a_loss: 0.508
Train: Epoch [1076/3000], Step [60/158]| g_loss: 0.719| d_loss: 0.618| gp_loss: 0.054| r_loss: 0.082| p_loss: 0.133| v_loss: 0.028| per_loss: 0.490 | a_loss: 0.493
Train: Epoch [1076/3000], Step [90/158]| g_loss: 0.788| d_loss: 0.611| gp_loss: 0.053| r_loss: 0.080| p_loss: 0.126| v_loss: 0.028| per_loss: 0.458 | a_loss: 0.572
Train: Epoch [1076/3000], Step [120/158]| g_loss: 0.720| d_loss: 0.622| gp_loss: 0.054| r_loss: 0.085| p_loss: 0.129| v_loss: 0.028| per_loss: 0.471 | a_loss: 0.495
Train: Epoch [1076/3000], Step [150/158]| g_loss: 0.778| d_loss: 0.600| gp_loss: 0.058| r_loss: 0.085| p_loss: 0.134| v_loss: 0.030| per_loss: 0.457 | a_loss: 0.550
Train: Epoch [1077/3000], Step [30/158]| g_loss: 0.766| d_loss: 0.666| gp_loss: 0.113| r_loss: 0.084| p_loss: 0.133| v_loss: 0.029| per_loss: 0.457 | a_loss: 0.541
Train: Epoch [1077/3000], Step [60/158]| g_loss: 0.708| d_loss: 0.707| gp_loss: 0.056| r_loss: 0.090| p_loss: 0.141| v_loss: 0.029| per_loss: 0.458 | a_loss: 0.473
Train: Epoch [1077/3000], Step [90/158]| g_loss: 0.830| d_loss: 0.547| gp_loss: 0.062| r_loss: 0.088| p_loss: 0.142| v_loss: 0.030| per_loss: 0.476 | a_loss: 0.594
Train: Epoch [1077/3000], Step [120/158]| g_loss: 0.772| d_loss: 0.584| gp_loss: 0.057| r_loss: 0.086| p_loss: 0.136| v_loss: 0.029| per_loss: 0.477 | a_loss: 0.541
Train: Epoch [1077/3000], Step [150/158]| g_loss: 0.789| d_loss: 0.525| gp_loss: 0.058| r_loss: 0.085| p_loss: 0.136| v_loss: 0.028| per_loss: 0.527 | a_loss: 0.556
Train: Epoch [1078/3000], Step [30/158]| g_loss: 0.772| d_loss: 0.657| gp_loss: 0.105| r_loss: 0.082| p_loss: 0.130| v_loss: 0.028| per_loss: 0.493 | a_loss: 0.548
Train: Epoch [1078/3000], Step [60/158]| g_loss: 0.778| d_loss: 0.556| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.131| v_loss: 0.028| per_loss: 0.503 | a_loss: 0.550
Train: Epoch [1078/3000], Step [90/158]| g_loss: 0.818| d_loss: 0.564| gp_loss: 0.057| r_loss: 0.087| p_loss: 0.137| v_loss: 0.028| per_loss: 0.515 | a_loss: 0.583
Train: Epoch [1078/3000], Step [120/158]| g_loss: 0.788| d_loss: 0.602| gp_loss: 0.056| r_loss: 0.085| p_loss: 0.136| v_loss: 0.028| per_loss: 0.503 | a_loss: 0.556
Train: Epoch [1078/3000], Step [150/158]| g_loss: 0.771| d_loss: 0.660| gp_loss: 0.057| r_loss: 0.086| p_loss: 0.143| v_loss: 0.030| per_loss: 0.519 | a_loss: 0.532
Train: Epoch [1079/3000], Step [30/158]| g_loss: 0.803| d_loss: 0.720| gp_loss: 0.225| r_loss: 0.088| p_loss: 0.141| v_loss: 0.029| per_loss: 0.534 | a_loss: 0.562
Train: Epoch [1079/3000], Step [60/158]| g_loss: 0.826| d_loss: 0.538| gp_loss: 0.053| r_loss: 0.085| p_loss: 0.140| v_loss: 0.030| per_loss: 0.574 | a_loss: 0.584
Train: Epoch [1079/3000], Step [90/158]| g_loss: 0.720| d_loss: 0.711| gp_loss: 0.051| r_loss: 0.083| p_loss: 0.135| v_loss: 0.029| per_loss: 0.572 | a_loss: 0.482
Train: Epoch [1079/3000], Step [120/158]| g_loss: 0.821| d_loss: 0.561| gp_loss: 0.059| r_loss: 0.085| p_loss: 0.137| v_loss: 0.027| per_loss: 0.524 | a_loss: 0.587
Train: Epoch [1079/3000], Step [150/158]| g_loss: 0.812| d_loss: 0.551| gp_loss: 0.057| r_loss: 0.095| p_loss: 0.157| v_loss: 0.029| per_loss: 0.560 | a_loss: 0.553
Train: Epoch [1080/3000], Step [30/158]| g_loss: 0.821| d_loss: 0.646| gp_loss: 0.118| r_loss: 0.093| p_loss: 0.149| v_loss: 0.029| per_loss: 0.576 | a_loss: 0.567
Train: Epoch [1080/3000], Step [60/158]| g_loss: 0.772| d_loss: 0.596| gp_loss: 0.053| r_loss: 0.086| p_loss: 0.141| v_loss: 0.028| per_loss: 0.580 | a_loss: 0.531
Train: Epoch [1080/3000], Step [90/158]| g_loss: 0.812| d_loss: 0.603| gp_loss: 0.055| r_loss: 0.089| p_loss: 0.138| v_loss: 0.029| per_loss: 0.554 | a_loss: 0.569
Train: Epoch [1080/3000], Step [120/158]| g_loss: 0.834| d_loss: 0.532| gp_loss: 0.061| r_loss: 0.091| p_loss: 0.140| v_loss: 0.029| per_loss: 0.499 | a_loss: 0.594
Train: Epoch [1080/3000], Step [150/158]| g_loss: 0.789| d_loss: 0.586| gp_loss: 0.057| r_loss: 0.091| p_loss: 0.143| v_loss: 0.029| per_loss: 0.514 | a_loss: 0.546
Train: Epoch [1081/3000], Step [30/158]| g_loss: 0.806| d_loss: 0.640| gp_loss: 0.151| r_loss: 0.089| p_loss: 0.135| v_loss: 0.029| per_loss: 0.544 | a_loss: 0.566
Train: Epoch [1081/3000], Step [60/158]| g_loss: 0.811| d_loss: 0.513| gp_loss: 0.053| r_loss: 0.084| p_loss: 0.128| v_loss: 0.027| per_loss: 0.498 | a_loss: 0.586
Train: Epoch [1081/3000], Step [90/158]| g_loss: 0.776| d_loss: 0.650| gp_loss: 0.053| r_loss: 0.084| p_loss: 0.133| v_loss: 0.028| per_loss: 0.499 | a_loss: 0.548
Train: Epoch [1081/3000], Step [120/158]| g_loss: 0.741| d_loss: 0.549| gp_loss: 0.054| r_loss: 0.084| p_loss: 0.130| v_loss: 0.029| per_loss: 0.543 | a_loss: 0.508
Train: Epoch [1081/3000], Step [150/158]| g_loss: 0.848| d_loss: 0.531| gp_loss: 0.057| r_loss: 0.083| p_loss: 0.131| v_loss: 0.029| per_loss: 0.535 | a_loss: 0.617
Train: Epoch [1082/3000], Step [30/158]| g_loss: 0.797| d_loss: 0.604| gp_loss: 0.159| r_loss: 0.087| p_loss: 0.138| v_loss: 0.029| per_loss: 0.531 | a_loss: 0.559
Train: Epoch [1082/3000], Step [60/158]| g_loss: 0.786| d_loss: 0.561| gp_loss: 0.053| r_loss: 0.082| p_loss: 0.124| v_loss: 0.028| per_loss: 0.532 | a_loss: 0.561
Train: Epoch [1082/3000], Step [90/158]| g_loss: 0.855| d_loss: 0.522| gp_loss: 0.053| r_loss: 0.085| p_loss: 0.134| v_loss: 0.028| per_loss: 0.510 | a_loss: 0.624
Train: Epoch [1082/3000], Step [120/158]| g_loss: 0.801| d_loss: 0.587| gp_loss: 0.053| r_loss: 0.088| p_loss: 0.139| v_loss: 0.028| per_loss: 0.528 | a_loss: 0.562
Train: Epoch [1082/3000], Step [150/158]| g_loss: 0.795| d_loss: 0.607| gp_loss: 0.052| r_loss: 0.087| p_loss: 0.139| v_loss: 0.028| per_loss: 0.512 | a_loss: 0.559
Train: Epoch [1083/3000], Step [30/158]| g_loss: 0.771| d_loss: 0.685| gp_loss: 0.171| r_loss: 0.087| p_loss: 0.143| v_loss: 0.029| per_loss: 0.502 | a_loss: 0.533
Train: Epoch [1083/3000], Step [60/158]| g_loss: 0.788| d_loss: 0.601| gp_loss: 0.054| r_loss: 0.088| p_loss: 0.143| v_loss: 0.029| per_loss: 0.535 | a_loss: 0.546
Train: Epoch [1083/3000], Step [90/158]| g_loss: 0.858| d_loss: 0.486| gp_loss: 0.057| r_loss: 0.086| p_loss: 0.140| v_loss: 0.028| per_loss: 0.536 | a_loss: 0.621
Train: Epoch [1083/3000], Step [120/158]| g_loss: 0.773| d_loss: 0.641| gp_loss: 0.057| r_loss: 0.091| p_loss: 0.145| v_loss: 0.028| per_loss: 0.534 | a_loss: 0.528
Train: Epoch [1083/3000], Step [150/158]| g_loss: 0.827| d_loss: 0.521| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.131| v_loss: 0.027| per_loss: 0.555 | a_loss: 0.595
Train: Epoch [1084/3000], Step [30/158]| g_loss: 0.802| d_loss: 0.704| gp_loss: 0.197| r_loss: 0.087| p_loss: 0.138| v_loss: 0.028| per_loss: 0.526 | a_loss: 0.565
Train: Epoch [1084/3000], Step [60/158]| g_loss: 0.772| d_loss: 0.590| gp_loss: 0.054| r_loss: 0.083| p_loss: 0.130| v_loss: 0.028| per_loss: 0.497 | a_loss: 0.547
Train: Epoch [1084/3000], Step [90/158]| g_loss: 0.816| d_loss: 0.510| gp_loss: 0.055| r_loss: 0.088| p_loss: 0.134| v_loss: 0.029| per_loss: 0.511 | a_loss: 0.581
Train: Epoch [1084/3000], Step [120/158]| g_loss: 0.887| d_loss: 0.480| gp_loss: 0.053| r_loss: 0.086| p_loss: 0.133| v_loss: 0.028| per_loss: 0.549 | a_loss: 0.651
Train: Epoch [1084/3000], Step [150/158]| g_loss: 0.763| d_loss: 0.676| gp_loss: 0.056| r_loss: 0.085| p_loss: 0.141| v_loss: 0.027| per_loss: 0.518 | a_loss: 0.528
Train: Epoch [1085/3000], Step [30/158]| g_loss: 0.819| d_loss: 0.637| gp_loss: 0.150| r_loss: 0.087| p_loss: 0.142| v_loss: 0.030| per_loss: 0.520 | a_loss: 0.580
Train: Epoch [1085/3000], Step [60/158]| g_loss: 0.800| d_loss: 0.580| gp_loss: 0.054| r_loss: 0.089| p_loss: 0.142| v_loss: 0.028| per_loss: 0.517 | a_loss: 0.561
Train: Epoch [1085/3000], Step [90/158]| g_loss: 0.831| d_loss: 0.597| gp_loss: 0.052| r_loss: 0.093| p_loss: 0.149| v_loss: 0.029| per_loss: 0.583 | a_loss: 0.576
Train: Epoch [1085/3000], Step [120/158]| g_loss: 0.815| d_loss: 0.557| gp_loss: 0.053| r_loss: 0.091| p_loss: 0.139| v_loss: 0.029| per_loss: 0.533 | a_loss: 0.572
Train: Epoch [1085/3000], Step [150/158]| g_loss: 0.810| d_loss: 0.570| gp_loss: 0.053| r_loss: 0.089| p_loss: 0.137| v_loss: 0.028| per_loss: 0.505 | a_loss: 0.575
Train: Epoch [1086/3000], Step [30/158]| g_loss: 0.807| d_loss: 0.616| gp_loss: 0.158| r_loss: 0.086| p_loss: 0.136| v_loss: 0.028| per_loss: 0.518 | a_loss: 0.574
Train: Epoch [1086/3000], Step [60/158]| g_loss: 0.837| d_loss: 0.520| gp_loss: 0.050| r_loss: 0.090| p_loss: 0.135| v_loss: 0.029| per_loss: 0.539 | a_loss: 0.597
Train: Epoch [1086/3000], Step [90/158]| g_loss: 0.835| d_loss: 0.561| gp_loss: 0.051| r_loss: 0.089| p_loss: 0.138| v_loss: 0.029| per_loss: 0.563 | a_loss: 0.592
Train: Epoch [1086/3000], Step [120/158]| g_loss: 0.789| d_loss: 0.562| gp_loss: 0.052| r_loss: 0.084| p_loss: 0.126| v_loss: 0.028| per_loss: 0.473 | a_loss: 0.568
Train: Epoch [1086/3000], Step [150/158]| g_loss: 0.746| d_loss: 0.624| gp_loss: 0.056| r_loss: 0.085| p_loss: 0.133| v_loss: 0.027| per_loss: 0.495 | a_loss: 0.518
Train: Epoch [1087/3000], Step [30/158]| g_loss: 0.745| d_loss: 0.731| gp_loss: 0.170| r_loss: 0.084| p_loss: 0.132| v_loss: 0.028| per_loss: 0.483 | a_loss: 0.519
Train: Epoch [1087/3000], Step [60/158]| g_loss: 0.777| d_loss: 0.660| gp_loss: 0.054| r_loss: 0.090| p_loss: 0.144| v_loss: 0.028| per_loss: 0.555 | a_loss: 0.531
Train: Epoch [1087/3000], Step [90/158]| g_loss: 0.758| d_loss: 0.526| gp_loss: 0.051| r_loss: 0.089| p_loss: 0.138| v_loss: 0.028| per_loss: 0.514 | a_loss: 0.521
Train: Epoch [1087/3000], Step [120/158]| g_loss: 0.838| d_loss: 0.515| gp_loss: 0.055| r_loss: 0.088| p_loss: 0.135| v_loss: 0.027| per_loss: 0.497 | a_loss: 0.605
Train: Epoch [1087/3000], Step [150/158]| g_loss: 0.806| d_loss: 0.568| gp_loss: 0.054| r_loss: 0.087| p_loss: 0.137| v_loss: 0.027| per_loss: 0.549 | a_loss: 0.567
Train: Epoch [1088/3000], Step [30/158]| g_loss: 0.804| d_loss: 0.677| gp_loss: 0.190| r_loss: 0.087| p_loss: 0.139| v_loss: 0.029| per_loss: 0.541 | a_loss: 0.564
Train: Epoch [1088/3000], Step [60/158]| g_loss: 0.801| d_loss: 0.563| gp_loss: 0.049| r_loss: 0.090| p_loss: 0.140| v_loss: 0.029| per_loss: 0.533 | a_loss: 0.560
Train: Epoch [1088/3000], Step [90/158]| g_loss: 0.860| d_loss: 0.526| gp_loss: 0.051| r_loss: 0.087| p_loss: 0.137| v_loss: 0.029| per_loss: 0.520 | a_loss: 0.623
Train: Epoch [1088/3000], Step [120/158]| g_loss: 0.737| d_loss: 0.611| gp_loss: 0.054| r_loss: 0.086| p_loss: 0.138| v_loss: 0.028| per_loss: 0.516 | a_loss: 0.503
Train: Epoch [1088/3000], Step [150/158]| g_loss: 0.842| d_loss: 0.545| gp_loss: 0.055| r_loss: 0.088| p_loss: 0.140| v_loss: 0.028| per_loss: 0.538 | a_loss: 0.603
Train: Epoch [1089/3000], Step [30/158]| g_loss: 0.724| d_loss: 0.804| gp_loss: 0.139| r_loss: 0.091| p_loss: 0.155| v_loss: 0.028| per_loss: 0.509 | a_loss: 0.476
Train: Epoch [1089/3000], Step [60/158]| g_loss: 0.810| d_loss: 0.546| gp_loss: 0.057| r_loss: 0.095| p_loss: 0.149| v_loss: 0.030| per_loss: 0.500 | a_loss: 0.561
Train: Epoch [1089/3000], Step [90/158]| g_loss: 0.866| d_loss: 0.543| gp_loss: 0.057| r_loss: 0.089| p_loss: 0.145| v_loss: 0.030| per_loss: 0.532 | a_loss: 0.622
Train: Epoch [1089/3000], Step [120/158]| g_loss: 0.840| d_loss: 0.511| gp_loss: 0.059| r_loss: 0.087| p_loss: 0.141| v_loss: 0.030| per_loss: 0.543 | a_loss: 0.598
Train: Epoch [1089/3000], Step [150/158]| g_loss: 0.743| d_loss: 0.557| gp_loss: 0.061| r_loss: 0.089| p_loss: 0.140| v_loss: 0.030| per_loss: 0.512 | a_loss: 0.504
Train: Epoch [1090/3000], Step [30/158]| g_loss: 0.852| d_loss: 0.673| gp_loss: 0.191| r_loss: 0.094| p_loss: 0.149| v_loss: 0.030| per_loss: 0.526 | a_loss: 0.601
Train: Epoch [1090/3000], Step [60/158]| g_loss: 0.839| d_loss: 0.492| gp_loss: 0.054| r_loss: 0.087| p_loss: 0.136| v_loss: 0.028| per_loss: 0.562 | a_loss: 0.599
Train: Epoch [1090/3000], Step [90/158]| g_loss: 0.752| d_loss: 0.629| gp_loss: 0.058| r_loss: 0.091| p_loss: 0.146| v_loss: 0.029| per_loss: 0.503 | a_loss: 0.509
Train: Epoch [1090/3000], Step [120/158]| g_loss: 0.852| d_loss: 0.530| gp_loss: 0.058| r_loss: 0.090| p_loss: 0.148| v_loss: 0.029| per_loss: 0.502 | a_loss: 0.608
Train: Epoch [1090/3000], Step [150/158]| g_loss: 0.840| d_loss: 0.566| gp_loss: 0.060| r_loss: 0.088| p_loss: 0.142| v_loss: 0.029| per_loss: 0.539 | a_loss: 0.599
Train: Epoch [1091/3000], Step [30/158]| g_loss: 0.854| d_loss: 0.618| gp_loss: 0.163| r_loss: 0.090| p_loss: 0.149| v_loss: 0.030| per_loss: 0.543 | a_loss: 0.605
Train: Epoch [1091/3000], Step [60/158]| g_loss: 0.849| d_loss: 0.510| gp_loss: 0.054| r_loss: 0.089| p_loss: 0.149| v_loss: 0.030| per_loss: 0.535 | a_loss: 0.602
Train: Epoch [1091/3000], Step [90/158]| g_loss: 0.817| d_loss: 0.522| gp_loss: 0.056| r_loss: 0.087| p_loss: 0.132| v_loss: 0.029| per_loss: 0.526 | a_loss: 0.583
Train: Epoch [1091/3000], Step [120/158]| g_loss: 0.787| d_loss: 0.582| gp_loss: 0.056| r_loss: 0.089| p_loss: 0.143| v_loss: 0.029| per_loss: 0.539 | a_loss: 0.544
Train: Epoch [1091/3000], Step [150/158]| g_loss: 0.796| d_loss: 0.614| gp_loss: 0.061| r_loss: 0.091| p_loss: 0.156| v_loss: 0.029| per_loss: 0.520 | a_loss: 0.545
Train: Epoch [1092/3000], Step [30/158]| g_loss: 0.845| d_loss: 0.623| gp_loss: 0.142| r_loss: 0.095| p_loss: 0.150| v_loss: 0.029| per_loss: 0.549 | a_loss: 0.592
Train: Epoch [1092/3000], Step [60/158]| g_loss: 0.836| d_loss: 0.559| gp_loss: 0.054| r_loss: 0.091| p_loss: 0.151| v_loss: 0.030| per_loss: 0.546 | a_loss: 0.584
Train: Epoch [1092/3000], Step [90/158]| g_loss: 0.819| d_loss: 0.521| gp_loss: 0.057| r_loss: 0.084| p_loss: 0.138| v_loss: 0.030| per_loss: 0.520 | a_loss: 0.584
Train: Epoch [1092/3000], Step [120/158]| g_loss: 0.875| d_loss: 0.485| gp_loss: 0.061| r_loss: 0.091| p_loss: 0.144| v_loss: 0.029| per_loss: 0.566 | a_loss: 0.626
Train: Epoch [1092/3000], Step [150/158]| g_loss: 0.793| d_loss: 0.618| gp_loss: 0.059| r_loss: 0.088| p_loss: 0.145| v_loss: 0.029| per_loss: 0.490 | a_loss: 0.555
Train: Epoch [1093/3000], Step [30/158]| g_loss: 0.849| d_loss: 0.632| gp_loss: 0.144| r_loss: 0.090| p_loss: 0.147| v_loss: 0.030| per_loss: 0.596 | a_loss: 0.595
Train: Epoch [1093/3000], Step [60/158]| g_loss: 0.838| d_loss: 0.526| gp_loss: 0.058| r_loss: 0.093| p_loss: 0.150| v_loss: 0.030| per_loss: 0.536 | a_loss: 0.587
Train: Epoch [1093/3000], Step [90/158]| g_loss: 0.893| d_loss: 0.454| gp_loss: 0.058| r_loss: 0.093| p_loss: 0.148| v_loss: 0.030| per_loss: 0.554 | a_loss: 0.641
Train: Epoch [1093/3000], Step [120/158]| g_loss: 0.801| d_loss: 0.623| gp_loss: 0.056| r_loss: 0.090| p_loss: 0.148| v_loss: 0.030| per_loss: 0.536 | a_loss: 0.554
Train: Epoch [1093/3000], Step [150/158]| g_loss: 0.821| d_loss: 0.544| gp_loss: 0.061| r_loss: 0.089| p_loss: 0.144| v_loss: 0.030| per_loss: 0.515 | a_loss: 0.579
Train: Epoch [1094/3000], Step [30/158]| g_loss: 0.832| d_loss: 0.717| gp_loss: 0.175| r_loss: 0.095| p_loss: 0.163| v_loss: 0.030| per_loss: 0.554 | a_loss: 0.570
Train: Epoch [1094/3000], Step [60/158]| g_loss: 0.876| d_loss: 0.540| gp_loss: 0.056| r_loss: 0.097| p_loss: 0.156| v_loss: 0.031| per_loss: 0.535 | a_loss: 0.616
Train: Epoch [1094/3000], Step [90/158]| g_loss: 0.809| d_loss: 0.611| gp_loss: 0.052| r_loss: 0.090| p_loss: 0.150| v_loss: 0.031| per_loss: 0.520 | a_loss: 0.560
Train: Epoch [1094/3000], Step [120/158]| g_loss: 0.756| d_loss: 0.565| gp_loss: 0.057| r_loss: 0.088| p_loss: 0.139| v_loss: 0.029| per_loss: 0.483 | a_loss: 0.521
Train: Epoch [1094/3000], Step [150/158]| g_loss: 0.891| d_loss: 0.457| gp_loss: 0.057| r_loss: 0.091| p_loss: 0.147| v_loss: 0.030| per_loss: 0.497 | a_loss: 0.646
Train: Epoch [1095/3000], Step [30/158]| g_loss: 0.742| d_loss: 0.782| gp_loss: 0.174| r_loss: 0.096| p_loss: 0.164| v_loss: 0.029| per_loss: 0.484 | a_loss: 0.487
Train: Epoch [1095/3000], Step [60/158]| g_loss: 0.863| d_loss: 0.500| gp_loss: 0.053| r_loss: 0.086| p_loss: 0.146| v_loss: 0.030| per_loss: 0.541 | a_loss: 0.619
Train: Epoch [1095/3000], Step [90/158]| g_loss: 0.802| d_loss: 0.547| gp_loss: 0.055| r_loss: 0.091| p_loss: 0.140| v_loss: 0.030| per_loss: 0.538 | a_loss: 0.556
Train: Epoch [1095/3000], Step [120/158]| g_loss: 0.873| d_loss: 0.531| gp_loss: 0.055| r_loss: 0.090| p_loss: 0.146| v_loss: 0.031| per_loss: 0.579 | a_loss: 0.621
Train: Epoch [1095/3000], Step [150/158]| g_loss: 0.792| d_loss: 0.609| gp_loss: 0.057| r_loss: 0.091| p_loss: 0.149| v_loss: 0.032| per_loss: 0.522 | a_loss: 0.543
Train: Epoch [1096/3000], Step [30/158]| g_loss: 0.817| d_loss: 0.677| gp_loss: 0.179| r_loss: 0.094| p_loss: 0.149| v_loss: 0.032| per_loss: 0.524 | a_loss: 0.564
Train: Epoch [1096/3000], Step [60/158]| g_loss: 0.869| d_loss: 0.467| gp_loss: 0.056| r_loss: 0.092| p_loss: 0.146| v_loss: 0.031| per_loss: 0.550 | a_loss: 0.618
Train: Epoch [1096/3000], Step [90/158]| g_loss: 0.802| d_loss: 0.594| gp_loss: 0.056| r_loss: 0.091| p_loss: 0.150| v_loss: 0.030| per_loss: 0.542 | a_loss: 0.552
Train: Epoch [1096/3000], Step [120/158]| g_loss: 0.769| d_loss: 0.612| gp_loss: 0.059| r_loss: 0.090| p_loss: 0.147| v_loss: 0.029| per_loss: 0.524 | a_loss: 0.524
Train: Epoch [1096/3000], Step [150/158]| g_loss: 0.852| d_loss: 0.500| gp_loss: 0.062| r_loss: 0.088| p_loss: 0.142| v_loss: 0.030| per_loss: 0.534 | a_loss: 0.610
Train: Epoch [1097/3000], Step [30/158]| g_loss: 0.772| d_loss: 0.741| gp_loss: 0.105| r_loss: 0.091| p_loss: 0.156| v_loss: 0.031| per_loss: 0.565 | a_loss: 0.516
Train: Epoch [1097/3000], Step [60/158]| g_loss: 0.868| d_loss: 0.549| gp_loss: 0.060| r_loss: 0.095| p_loss: 0.164| v_loss: 0.031| per_loss: 0.566 | a_loss: 0.603
Train: Epoch [1097/3000], Step [90/158]| g_loss: 0.792| d_loss: 0.626| gp_loss: 0.059| r_loss: 0.094| p_loss: 0.151| v_loss: 0.031| per_loss: 0.563 | a_loss: 0.535
Train: Epoch [1097/3000], Step [120/158]| g_loss: 0.749| d_loss: 0.653| gp_loss: 0.060| r_loss: 0.093| p_loss: 0.149| v_loss: 0.031| per_loss: 0.521 | a_loss: 0.499
Train: Epoch [1097/3000], Step [150/158]| g_loss: 0.796| d_loss: 0.530| gp_loss: 0.064| r_loss: 0.090| p_loss: 0.144| v_loss: 0.031| per_loss: 0.558 | a_loss: 0.547
Train: Epoch [1098/3000], Step [30/158]| g_loss: 0.849| d_loss: 0.656| gp_loss: 0.216| r_loss: 0.090| p_loss: 0.148| v_loss: 0.032| per_loss: 0.537 | a_loss: 0.598
Train: Epoch [1098/3000], Step [60/158]| g_loss: 0.905| d_loss: 0.497| gp_loss: 0.056| r_loss: 0.092| p_loss: 0.143| v_loss: 0.032| per_loss: 0.545 | a_loss: 0.654
Train: Epoch [1098/3000], Step [90/158]| g_loss: 0.773| d_loss: 0.547| gp_loss: 0.056| r_loss: 0.089| p_loss: 0.140| v_loss: 0.032| per_loss: 0.496 | a_loss: 0.532
Train: Epoch [1098/3000], Step [120/158]| g_loss: 0.829| d_loss: 0.604| gp_loss: 0.062| r_loss: 0.093| p_loss: 0.141| v_loss: 0.032| per_loss: 0.533 | a_loss: 0.580
Train: Epoch [1098/3000], Step [150/158]| g_loss: 0.795| d_loss: 0.661| gp_loss: 0.061| r_loss: 0.093| p_loss: 0.146| v_loss: 0.031| per_loss: 0.516 | a_loss: 0.546
Train: Epoch [1099/3000], Step [30/158]| g_loss: 0.807| d_loss: 0.703| gp_loss: 0.181| r_loss: 0.089| p_loss: 0.147| v_loss: 0.031| per_loss: 0.496 | a_loss: 0.563
Train: Epoch [1099/3000], Step [60/158]| g_loss: 0.825| d_loss: 0.559| gp_loss: 0.054| r_loss: 0.091| p_loss: 0.146| v_loss: 0.031| per_loss: 0.505 | a_loss: 0.579
Train: Epoch [1099/3000], Step [90/158]| g_loss: 0.749| d_loss: 0.666| gp_loss: 0.055| r_loss: 0.094| p_loss: 0.149| v_loss: 0.030| per_loss: 0.503 | a_loss: 0.500
Train: Epoch [1099/3000], Step [120/158]| g_loss: 0.811| d_loss: 0.604| gp_loss: 0.056| r_loss: 0.095| p_loss: 0.158| v_loss: 0.032| per_loss: 0.540 | a_loss: 0.551
Train: Epoch [1099/3000], Step [150/158]| g_loss: 0.841| d_loss: 0.532| gp_loss: 0.062| r_loss: 0.091| p_loss: 0.146| v_loss: 0.031| per_loss: 0.534 | a_loss: 0.593
Train: Epoch [1100/3000], Step [30/158]| g_loss: 0.838| d_loss: 0.672| gp_loss: 0.172| r_loss: 0.090| p_loss: 0.142| v_loss: 0.031| per_loss: 0.540 | a_loss: 0.593
Train: Epoch [1100/3000], Step [60/158]| g_loss: 0.788| d_loss: 0.641| gp_loss: 0.054| r_loss: 0.090| p_loss: 0.153| v_loss: 0.032| per_loss: 0.510 | a_loss: 0.538
Train: Epoch [1100/3000], Step [90/158]| g_loss: 0.831| d_loss: 0.569| gp_loss: 0.062| r_loss: 0.094| p_loss: 0.148| v_loss: 0.033| per_loss: 0.517 | a_loss: 0.579
Train: Epoch [1100/3000], Step [120/158]| g_loss: 0.873| d_loss: 0.516| gp_loss: 0.054| r_loss: 0.093| p_loss: 0.153| v_loss: 0.032| per_loss: 0.509 | a_loss: 0.621
Train: Epoch [1100/3000], Step [150/158]| g_loss: 0.843| d_loss: 0.579| gp_loss: 0.059| r_loss: 0.090| p_loss: 0.147| v_loss: 0.033| per_loss: 0.480 | a_loss: 0.599
Test: Epoch [1100/3000]| g_loss: 0.647| r_loss: 0.400| p_loss: 0.303| v_loss: 0.029
Train: Epoch [1101/3000], Step [30/158]| g_loss: 0.792| d_loss: 0.563| gp_loss: 0.057| r_loss: 0.094| p_loss: 0.153| v_loss: 0.032| per_loss: 0.559 | a_loss: 0.533
Train: Epoch [1101/3000], Step [60/158]| g_loss: 0.831| d_loss: 0.566| gp_loss: 0.056| r_loss: 0.088| p_loss: 0.147| v_loss: 0.032| per_loss: 0.519 | a_loss: 0.586
Train: Epoch [1101/3000], Step [90/158]| g_loss: 0.859| d_loss: 0.572| gp_loss: 0.062| r_loss: 0.092| p_loss: 0.151| v_loss: 0.033| per_loss: 0.493 | a_loss: 0.608
Train: Epoch [1101/3000], Step [120/158]| g_loss: 0.800| d_loss: 0.555| gp_loss: 0.058| r_loss: 0.090| p_loss: 0.148| v_loss: 0.032| per_loss: 0.482 | a_loss: 0.557
Train: Epoch [1101/3000], Step [150/158]| g_loss: 0.811| d_loss: 0.598| gp_loss: 0.060| r_loss: 0.090| p_loss: 0.145| v_loss: 0.031| per_loss: 0.477 | a_loss: 0.569
Train: Epoch [1102/3000], Step [30/158]| g_loss: 0.820| d_loss: 0.673| gp_loss: 0.147| r_loss: 0.096| p_loss: 0.158| v_loss: 0.032| per_loss: 0.507 | a_loss: 0.562
Train: Epoch [1102/3000], Step [60/158]| g_loss: 0.815| d_loss: 0.575| gp_loss: 0.057| r_loss: 0.091| p_loss: 0.150| v_loss: 0.031| per_loss: 0.504 | a_loss: 0.567
Train: Epoch [1102/3000], Step [90/158]| g_loss: 0.811| d_loss: 0.571| gp_loss: 0.057| r_loss: 0.089| p_loss: 0.144| v_loss: 0.031| per_loss: 0.502 | a_loss: 0.568
Train: Epoch [1102/3000], Step [120/158]| g_loss: 0.810| d_loss: 0.645| gp_loss: 0.063| r_loss: 0.093| p_loss: 0.153| v_loss: 0.032| per_loss: 0.504 | a_loss: 0.558
Train: Epoch [1102/3000], Step [150/158]| g_loss: 0.887| d_loss: 0.508| gp_loss: 0.058| r_loss: 0.096| p_loss: 0.161| v_loss: 0.032| per_loss: 0.548 | a_loss: 0.623
Train: Epoch [1103/3000], Step [30/158]| g_loss: 0.806| d_loss: 0.679| gp_loss: 0.132| r_loss: 0.095| p_loss: 0.162| v_loss: 0.032| per_loss: 0.567 | a_loss: 0.541
Train: Epoch [1103/3000], Step [60/158]| g_loss: 0.808| d_loss: 0.532| gp_loss: 0.053| r_loss: 0.091| p_loss: 0.148| v_loss: 0.031| per_loss: 0.506 | a_loss: 0.562
Train: Epoch [1103/3000], Step [90/158]| g_loss: 0.752| d_loss: 0.673| gp_loss: 0.055| r_loss: 0.094| p_loss: 0.149| v_loss: 0.031| per_loss: 0.501 | a_loss: 0.503
Train: Epoch [1103/3000], Step [120/158]| g_loss: 0.854| d_loss: 0.571| gp_loss: 0.055| r_loss: 0.092| p_loss: 0.149| v_loss: 0.030| per_loss: 0.491 | a_loss: 0.608
Train: Epoch [1103/3000], Step [150/158]| g_loss: 0.796| d_loss: 0.609| gp_loss: 0.056| r_loss: 0.093| p_loss: 0.159| v_loss: 0.032| per_loss: 0.475 | a_loss: 0.544
Train: Epoch [1104/3000], Step [30/158]| g_loss: 0.799| d_loss: 0.670| gp_loss: 0.151| r_loss: 0.090| p_loss: 0.145| v_loss: 0.030| per_loss: 0.529 | a_loss: 0.554
Train: Epoch [1104/3000], Step [60/158]| g_loss: 0.810| d_loss: 0.559| gp_loss: 0.057| r_loss: 0.088| p_loss: 0.145| v_loss: 0.030| per_loss: 0.501 | a_loss: 0.570
Train: Epoch [1104/3000], Step [90/158]| g_loss: 0.877| d_loss: 0.480| gp_loss: 0.055| r_loss: 0.086| p_loss: 0.138| v_loss: 0.031| per_loss: 0.502 | a_loss: 0.641
Train: Epoch [1104/3000], Step [120/158]| g_loss: 0.815| d_loss: 0.566| gp_loss: 0.056| r_loss: 0.092| p_loss: 0.145| v_loss: 0.031| per_loss: 0.481 | a_loss: 0.572
Train: Epoch [1104/3000], Step [150/158]| g_loss: 0.747| d_loss: 0.644| gp_loss: 0.056| r_loss: 0.093| p_loss: 0.147| v_loss: 0.031| per_loss: 0.541 | a_loss: 0.496
Train: Epoch [1105/3000], Step [30/158]| g_loss: 0.776| d_loss: 0.724| gp_loss: 0.191| r_loss: 0.087| p_loss: 0.144| v_loss: 0.031| per_loss: 0.482 | a_loss: 0.537
Train: Epoch [1105/3000], Step [60/158]| g_loss: 0.762| d_loss: 0.628| gp_loss: 0.055| r_loss: 0.086| p_loss: 0.135| v_loss: 0.029| per_loss: 0.498 | a_loss: 0.529
Train: Epoch [1105/3000], Step [90/158]| g_loss: 0.807| d_loss: 0.519| gp_loss: 0.057| r_loss: 0.090| p_loss: 0.140| v_loss: 0.031| per_loss: 0.508 | a_loss: 0.565
Train: Epoch [1105/3000], Step [120/158]| g_loss: 0.795| d_loss: 0.614| gp_loss: 0.057| r_loss: 0.092| p_loss: 0.143| v_loss: 0.030| per_loss: 0.504 | a_loss: 0.552
Train: Epoch [1105/3000], Step [150/158]| g_loss: 0.820| d_loss: 0.569| gp_loss: 0.056| r_loss: 0.085| p_loss: 0.135| v_loss: 0.030| per_loss: 0.528 | a_loss: 0.584
Train: Epoch [1106/3000], Step [30/158]| g_loss: 0.812| d_loss: 0.641| gp_loss: 0.115| r_loss: 0.090| p_loss: 0.141| v_loss: 0.031| per_loss: 0.495 | a_loss: 0.571
Train: Epoch [1106/3000], Step [60/158]| g_loss: 0.762| d_loss: 0.596| gp_loss: 0.055| r_loss: 0.089| p_loss: 0.137| v_loss: 0.030| per_loss: 0.465 | a_loss: 0.528
Train: Epoch [1106/3000], Step [90/158]| g_loss: 0.755| d_loss: 0.573| gp_loss: 0.059| r_loss: 0.087| p_loss: 0.134| v_loss: 0.030| per_loss: 0.513 | a_loss: 0.519
Train: Epoch [1106/3000], Step [120/158]| g_loss: 0.825| d_loss: 0.560| gp_loss: 0.060| r_loss: 0.085| p_loss: 0.134| v_loss: 0.029| per_loss: 0.496 | a_loss: 0.594
Train: Epoch [1106/3000], Step [150/158]| g_loss: 0.797| d_loss: 0.576| gp_loss: 0.056| r_loss: 0.087| p_loss: 0.145| v_loss: 0.029| per_loss: 0.512 | a_loss: 0.558
Train: Epoch [1107/3000], Step [30/158]| g_loss: 0.851| d_loss: 0.630| gp_loss: 0.156| r_loss: 0.088| p_loss: 0.137| v_loss: 0.029| per_loss: 0.517 | a_loss: 0.613
Train: Epoch [1107/3000], Step [60/158]| g_loss: 0.798| d_loss: 0.555| gp_loss: 0.055| r_loss: 0.083| p_loss: 0.128| v_loss: 0.029| per_loss: 0.501 | a_loss: 0.571
Train: Epoch [1107/3000], Step [90/158]| g_loss: 0.798| d_loss: 0.527| gp_loss: 0.055| r_loss: 0.087| p_loss: 0.133| v_loss: 0.031| per_loss: 0.533 | a_loss: 0.560
Train: Epoch [1107/3000], Step [120/158]| g_loss: 0.818| d_loss: 0.597| gp_loss: 0.054| r_loss: 0.087| p_loss: 0.137| v_loss: 0.030| per_loss: 0.499 | a_loss: 0.583
Train: Epoch [1107/3000], Step [150/158]| g_loss: 0.783| d_loss: 0.600| gp_loss: 0.060| r_loss: 0.086| p_loss: 0.142| v_loss: 0.030| per_loss: 0.503 | a_loss: 0.546
Train: Epoch [1108/3000], Step [30/158]| g_loss: 0.791| d_loss: 0.667| gp_loss: 0.161| r_loss: 0.087| p_loss: 0.139| v_loss: 0.031| per_loss: 0.503 | a_loss: 0.553
Train: Epoch [1108/3000], Step [60/158]| g_loss: 0.818| d_loss: 0.518| gp_loss: 0.059| r_loss: 0.087| p_loss: 0.141| v_loss: 0.030| per_loss: 0.490 | a_loss: 0.583
Train: Epoch [1108/3000], Step [90/158]| g_loss: 0.777| d_loss: 0.601| gp_loss: 0.054| r_loss: 0.086| p_loss: 0.135| v_loss: 0.030| per_loss: 0.531 | a_loss: 0.540
Train: Epoch [1108/3000], Step [120/158]| g_loss: 0.809| d_loss: 0.563| gp_loss: 0.058| r_loss: 0.086| p_loss: 0.137| v_loss: 0.029| per_loss: 0.507 | a_loss: 0.574
Train: Epoch [1108/3000], Step [150/158]| g_loss: 0.796| d_loss: 0.595| gp_loss: 0.058| r_loss: 0.087| p_loss: 0.140| v_loss: 0.029| per_loss: 0.515 | a_loss: 0.558
Train: Epoch [1109/3000], Step [30/158]| g_loss: 0.824| d_loss: 0.648| gp_loss: 0.182| r_loss: 0.090| p_loss: 0.142| v_loss: 0.029| per_loss: 0.495 | a_loss: 0.585
Train: Epoch [1109/3000], Step [60/158]| g_loss: 0.814| d_loss: 0.538| gp_loss: 0.055| r_loss: 0.089| p_loss: 0.142| v_loss: 0.029| per_loss: 0.511 | a_loss: 0.573
Train: Epoch [1109/3000], Step [90/158]| g_loss: 0.791| d_loss: 0.601| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.133| v_loss: 0.029| per_loss: 0.473 | a_loss: 0.564
Train: Epoch [1109/3000], Step [120/158]| g_loss: 0.797| d_loss: 0.561| gp_loss: 0.054| r_loss: 0.084| p_loss: 0.134| v_loss: 0.029| per_loss: 0.501 | a_loss: 0.567
Train: Epoch [1109/3000], Step [150/158]| g_loss: 0.812| d_loss: 0.558| gp_loss: 0.060| r_loss: 0.092| p_loss: 0.140| v_loss: 0.030| per_loss: 0.533 | a_loss: 0.566
Train: Epoch [1110/3000], Step [30/158]| g_loss: 0.727| d_loss: 0.769| gp_loss: 0.213| r_loss: 0.088| p_loss: 0.135| v_loss: 0.029| per_loss: 0.481 | a_loss: 0.494
Train: Epoch [1110/3000], Step [60/158]| g_loss: 0.813| d_loss: 0.583| gp_loss: 0.053| r_loss: 0.085| p_loss: 0.139| v_loss: 0.030| per_loss: 0.541 | a_loss: 0.574
Train: Epoch [1110/3000], Step [90/158]| g_loss: 0.764| d_loss: 0.626| gp_loss: 0.056| r_loss: 0.088| p_loss: 0.142| v_loss: 0.029| per_loss: 0.482 | a_loss: 0.528
Train: Epoch [1110/3000], Step [120/158]| g_loss: 0.796| d_loss: 0.622| gp_loss: 0.056| r_loss: 0.090| p_loss: 0.145| v_loss: 0.028| per_loss: 0.489 | a_loss: 0.556
Train: Epoch [1110/3000], Step [150/158]| g_loss: 0.828| d_loss: 0.508| gp_loss: 0.054| r_loss: 0.088| p_loss: 0.141| v_loss: 0.028| per_loss: 0.484 | a_loss: 0.593
Train: Epoch [1111/3000], Step [30/158]| g_loss: 0.822| d_loss: 0.623| gp_loss: 0.171| r_loss: 0.089| p_loss: 0.141| v_loss: 0.030| per_loss: 0.477 | a_loss: 0.585
Train: Epoch [1111/3000], Step [60/158]| g_loss: 0.771| d_loss: 0.629| gp_loss: 0.052| r_loss: 0.088| p_loss: 0.139| v_loss: 0.030| per_loss: 0.494 | a_loss: 0.535
Train: Epoch [1111/3000], Step [90/158]| g_loss: 0.784| d_loss: 0.620| gp_loss: 0.053| r_loss: 0.093| p_loss: 0.151| v_loss: 0.030| per_loss: 0.500 | a_loss: 0.535
Train: Epoch [1111/3000], Step [120/158]| g_loss: 0.790| d_loss: 0.630| gp_loss: 0.054| r_loss: 0.087| p_loss: 0.138| v_loss: 0.030| per_loss: 0.519 | a_loss: 0.551
Train: Epoch [1111/3000], Step [150/158]| g_loss: 0.792| d_loss: 0.543| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.132| v_loss: 0.029| per_loss: 0.489 | a_loss: 0.564
Train: Epoch [1112/3000], Step [30/158]| g_loss: 0.804| d_loss: 0.732| gp_loss: 0.168| r_loss: 0.089| p_loss: 0.142| v_loss: 0.029| per_loss: 0.489 | a_loss: 0.567
Train: Epoch [1112/3000], Step [60/158]| g_loss: 0.771| d_loss: 0.591| gp_loss: 0.054| r_loss: 0.089| p_loss: 0.138| v_loss: 0.031| per_loss: 0.489 | a_loss: 0.533
Train: Epoch [1112/3000], Step [90/158]| g_loss: 0.751| d_loss: 0.598| gp_loss: 0.057| r_loss: 0.092| p_loss: 0.142| v_loss: 0.030| per_loss: 0.540 | a_loss: 0.503
Train: Epoch [1112/3000], Step [120/158]| g_loss: 0.838| d_loss: 0.527| gp_loss: 0.055| r_loss: 0.085| p_loss: 0.136| v_loss: 0.029| per_loss: 0.491 | a_loss: 0.607
Train: Epoch [1112/3000], Step [150/158]| g_loss: 0.792| d_loss: 0.570| gp_loss: 0.055| r_loss: 0.088| p_loss: 0.140| v_loss: 0.029| per_loss: 0.497 | a_loss: 0.554
Train: Epoch [1113/3000], Step [30/158]| g_loss: 0.814| d_loss: 0.636| gp_loss: 0.163| r_loss: 0.088| p_loss: 0.139| v_loss: 0.028| per_loss: 0.499 | a_loss: 0.578
Train: Epoch [1113/3000], Step [60/158]| g_loss: 0.794| d_loss: 0.604| gp_loss: 0.056| r_loss: 0.086| p_loss: 0.135| v_loss: 0.029| per_loss: 0.520 | a_loss: 0.559
Train: Epoch [1113/3000], Step [90/158]| g_loss: 0.757| d_loss: 0.652| gp_loss: 0.052| r_loss: 0.086| p_loss: 0.139| v_loss: 0.031| per_loss: 0.493 | a_loss: 0.522
Train: Epoch [1113/3000], Step [120/158]| g_loss: 0.844| d_loss: 0.545| gp_loss: 0.058| r_loss: 0.089| p_loss: 0.141| v_loss: 0.030| per_loss: 0.500 | a_loss: 0.605
Train: Epoch [1113/3000], Step [150/158]| g_loss: 0.791| d_loss: 0.579| gp_loss: 0.060| r_loss: 0.087| p_loss: 0.143| v_loss: 0.030| per_loss: 0.477 | a_loss: 0.554
Train: Epoch [1114/3000], Step [30/158]| g_loss: 0.770| d_loss: 0.677| gp_loss: 0.130| r_loss: 0.089| p_loss: 0.141| v_loss: 0.030| per_loss: 0.506 | a_loss: 0.531
Train: Epoch [1114/3000], Step [60/158]| g_loss: 0.780| d_loss: 0.639| gp_loss: 0.056| r_loss: 0.088| p_loss: 0.148| v_loss: 0.030| per_loss: 0.512 | a_loss: 0.537
Train: Epoch [1114/3000], Step [90/158]| g_loss: 0.792| d_loss: 0.581| gp_loss: 0.059| r_loss: 0.088| p_loss: 0.145| v_loss: 0.029| per_loss: 0.511 | a_loss: 0.551
Train: Epoch [1114/3000], Step [120/158]| g_loss: 0.835| d_loss: 0.491| gp_loss: 0.060| r_loss: 0.090| p_loss: 0.143| v_loss: 0.031| per_loss: 0.480 | a_loss: 0.595
Train: Epoch [1114/3000], Step [150/158]| g_loss: 0.869| d_loss: 0.558| gp_loss: 0.060| r_loss: 0.088| p_loss: 0.142| v_loss: 0.029| per_loss: 0.519 | a_loss: 0.630
Train: Epoch [1115/3000], Step [30/158]| g_loss: 0.786| d_loss: 0.625| gp_loss: 0.126| r_loss: 0.089| p_loss: 0.147| v_loss: 0.029| per_loss: 0.490 | a_loss: 0.545
Train: Epoch [1115/3000], Step [60/158]| g_loss: 0.851| d_loss: 0.525| gp_loss: 0.055| r_loss: 0.088| p_loss: 0.151| v_loss: 0.029| per_loss: 0.526 | a_loss: 0.606
Train: Epoch [1115/3000], Step [90/158]| g_loss: 0.785| d_loss: 0.650| gp_loss: 0.059| r_loss: 0.096| p_loss: 0.154| v_loss: 0.030| per_loss: 0.485 | a_loss: 0.533
Train: Epoch [1115/3000], Step [120/158]| g_loss: 0.826| d_loss: 0.663| gp_loss: 0.061| r_loss: 0.092| p_loss: 0.159| v_loss: 0.031| per_loss: 0.524 | a_loss: 0.571
Train: Epoch [1115/3000], Step [150/158]| g_loss: 0.784| d_loss: 0.609| gp_loss: 0.062| r_loss: 0.093| p_loss: 0.147| v_loss: 0.030| per_loss: 0.492 | a_loss: 0.539
Train: Epoch [1116/3000], Step [30/158]| g_loss: 0.823| d_loss: 0.697| gp_loss: 0.148| r_loss: 0.091| p_loss: 0.156| v_loss: 0.031| per_loss: 0.532 | a_loss: 0.570
Train: Epoch [1116/3000], Step [60/158]| g_loss: 0.770| d_loss: 0.608| gp_loss: 0.059| r_loss: 0.093| p_loss: 0.154| v_loss: 0.030| per_loss: 0.483 | a_loss: 0.522
Train: Epoch [1116/3000], Step [90/158]| g_loss: 0.805| d_loss: 0.554| gp_loss: 0.059| r_loss: 0.093| p_loss: 0.144| v_loss: 0.030| per_loss: 0.533 | a_loss: 0.556
Train: Epoch [1116/3000], Step [120/158]| g_loss: 0.784| d_loss: 0.666| gp_loss: 0.062| r_loss: 0.101| p_loss: 0.156| v_loss: 0.029| per_loss: 0.506 | a_loss: 0.525
Train: Epoch [1116/3000], Step [150/158]| g_loss: 0.822| d_loss: 0.524| gp_loss: 0.064| r_loss: 0.091| p_loss: 0.152| v_loss: 0.031| per_loss: 0.487 | a_loss: 0.576
Train: Epoch [1117/3000], Step [30/158]| g_loss: 0.844| d_loss: 0.603| gp_loss: 0.140| r_loss: 0.092| p_loss: 0.146| v_loss: 0.032| per_loss: 0.483 | a_loss: 0.600
Train: Epoch [1117/3000], Step [60/158]| g_loss: 0.803| d_loss: 0.555| gp_loss: 0.056| r_loss: 0.086| p_loss: 0.134| v_loss: 0.030| per_loss: 0.535 | a_loss: 0.566
Train: Epoch [1117/3000], Step [90/158]| g_loss: 0.765| d_loss: 0.588| gp_loss: 0.059| r_loss: 0.089| p_loss: 0.140| v_loss: 0.031| per_loss: 0.489 | a_loss: 0.526
Train: Epoch [1117/3000], Step [120/158]| g_loss: 0.847| d_loss: 0.553| gp_loss: 0.058| r_loss: 0.090| p_loss: 0.144| v_loss: 0.031| per_loss: 0.492 | a_loss: 0.605
Train: Epoch [1117/3000], Step [150/158]| g_loss: 0.757| d_loss: 0.618| gp_loss: 0.061| r_loss: 0.090| p_loss: 0.145| v_loss: 0.031| per_loss: 0.489 | a_loss: 0.515
Train: Epoch [1118/3000], Step [30/158]| g_loss: 0.706| d_loss: 0.789| gp_loss: 0.084| r_loss: 0.091| p_loss: 0.146| v_loss: 0.030| per_loss: 0.467 | a_loss: 0.465
Train: Epoch [1118/3000], Step [60/158]| g_loss: 0.832| d_loss: 0.584| gp_loss: 0.061| r_loss: 0.094| p_loss: 0.152| v_loss: 0.032| per_loss: 0.499 | a_loss: 0.580
Train: Epoch [1118/3000], Step [90/158]| g_loss: 0.753| d_loss: 0.616| gp_loss: 0.068| r_loss: 0.089| p_loss: 0.149| v_loss: 0.032| per_loss: 0.492 | a_loss: 0.509
Train: Epoch [1118/3000], Step [120/158]| g_loss: 0.830| d_loss: 0.585| gp_loss: 0.057| r_loss: 0.090| p_loss: 0.147| v_loss: 0.031| per_loss: 0.513 | a_loss: 0.584
Train: Epoch [1118/3000], Step [150/158]| g_loss: 0.832| d_loss: 0.521| gp_loss: 0.064| r_loss: 0.084| p_loss: 0.139| v_loss: 0.031| per_loss: 0.523 | a_loss: 0.594
Train: Epoch [1119/3000], Step [30/158]| g_loss: 0.798| d_loss: 0.696| gp_loss: 0.160| r_loss: 0.088| p_loss: 0.137| v_loss: 0.031| per_loss: 0.522 | a_loss: 0.558
Train: Epoch [1119/3000], Step [60/158]| g_loss: 0.805| d_loss: 0.564| gp_loss: 0.059| r_loss: 0.085| p_loss: 0.133| v_loss: 0.031| per_loss: 0.482 | a_loss: 0.574
Train: Epoch [1119/3000], Step [90/158]| g_loss: 0.792| d_loss: 0.533| gp_loss: 0.060| r_loss: 0.083| p_loss: 0.131| v_loss: 0.031| per_loss: 0.480 | a_loss: 0.564
Train: Epoch [1119/3000], Step [120/158]| g_loss: 0.762| d_loss: 0.598| gp_loss: 0.058| r_loss: 0.086| p_loss: 0.137| v_loss: 0.031| per_loss: 0.468 | a_loss: 0.529
Train: Epoch [1119/3000], Step [150/158]| g_loss: 0.849| d_loss: 0.578| gp_loss: 0.062| r_loss: 0.089| p_loss: 0.141| v_loss: 0.031| per_loss: 0.492 | a_loss: 0.610
Train: Epoch [1120/3000], Step [30/158]| g_loss: 0.844| d_loss: 0.573| gp_loss: 0.169| r_loss: 0.085| p_loss: 0.135| v_loss: 0.031| per_loss: 0.498 | a_loss: 0.610
Train: Epoch [1120/3000], Step [60/158]| g_loss: 0.781| d_loss: 0.651| gp_loss: 0.056| r_loss: 0.086| p_loss: 0.141| v_loss: 0.032| per_loss: 0.484 | a_loss: 0.544
Train: Epoch [1120/3000], Step [90/158]| g_loss: 0.768| d_loss: 0.599| gp_loss: 0.059| r_loss: 0.089| p_loss: 0.139| v_loss: 0.031| per_loss: 0.502 | a_loss: 0.528
Train: Epoch [1120/3000], Step [120/158]| g_loss: 0.848| d_loss: 0.583| gp_loss: 0.057| r_loss: 0.088| p_loss: 0.137| v_loss: 0.031| per_loss: 0.481 | a_loss: 0.612
Train: Epoch [1120/3000], Step [150/158]| g_loss: 0.738| d_loss: 0.598| gp_loss: 0.062| r_loss: 0.086| p_loss: 0.141| v_loss: 0.032| per_loss: 0.519 | a_loss: 0.498
Train: Epoch [1121/3000], Step [30/158]| g_loss: 0.863| d_loss: 0.613| gp_loss: 0.151| r_loss: 0.089| p_loss: 0.138| v_loss: 0.033| per_loss: 0.517 | a_loss: 0.620
Train: Epoch [1121/3000], Step [60/158]| g_loss: 0.793| d_loss: 0.639| gp_loss: 0.056| r_loss: 0.085| p_loss: 0.140| v_loss: 0.030| per_loss: 0.477 | a_loss: 0.560
Train: Epoch [1121/3000], Step [90/158]| g_loss: 0.797| d_loss: 0.566| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.133| v_loss: 0.030| per_loss: 0.436 | a_loss: 0.573
Train: Epoch [1121/3000], Step [120/158]| g_loss: 0.785| d_loss: 0.605| gp_loss: 0.057| r_loss: 0.089| p_loss: 0.139| v_loss: 0.031| per_loss: 0.512 | a_loss: 0.545
Train: Epoch [1121/3000], Step [150/158]| g_loss: 0.769| d_loss: 0.560| gp_loss: 0.058| r_loss: 0.085| p_loss: 0.137| v_loss: 0.030| per_loss: 0.474 | a_loss: 0.538
Train: Epoch [1122/3000], Step [30/158]| g_loss: 0.873| d_loss: 0.581| gp_loss: 0.160| r_loss: 0.086| p_loss: 0.135| v_loss: 0.032| per_loss: 0.492 | a_loss: 0.638
Train: Epoch [1122/3000], Step [60/158]| g_loss: 0.760| d_loss: 0.566| gp_loss: 0.056| r_loss: 0.086| p_loss: 0.127| v_loss: 0.029| per_loss: 0.469 | a_loss: 0.535
Train: Epoch [1122/3000], Step [90/158]| g_loss: 0.788| d_loss: 0.604| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.136| v_loss: 0.031| per_loss: 0.523 | a_loss: 0.553
Train: Epoch [1122/3000], Step [120/158]| g_loss: 0.768| d_loss: 0.639| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.138| v_loss: 0.030| per_loss: 0.489 | a_loss: 0.536
Train: Epoch [1122/3000], Step [150/158]| g_loss: 0.788| d_loss: 0.590| gp_loss: 0.060| r_loss: 0.086| p_loss: 0.142| v_loss: 0.032| per_loss: 0.484 | a_loss: 0.551
Train: Epoch [1123/3000], Step [30/158]| g_loss: 0.827| d_loss: 0.663| gp_loss: 0.209| r_loss: 0.083| p_loss: 0.134| v_loss: 0.030| per_loss: 0.490 | a_loss: 0.597
Train: Epoch [1123/3000], Step [60/158]| g_loss: 0.734| d_loss: 0.624| gp_loss: 0.053| r_loss: 0.084| p_loss: 0.133| v_loss: 0.029| per_loss: 0.471 | a_loss: 0.507
Train: Epoch [1123/3000], Step [90/158]| g_loss: 0.789| d_loss: 0.575| gp_loss: 0.058| r_loss: 0.086| p_loss: 0.134| v_loss: 0.030| per_loss: 0.476 | a_loss: 0.558
Train: Epoch [1123/3000], Step [120/158]| g_loss: 0.803| d_loss: 0.578| gp_loss: 0.056| r_loss: 0.087| p_loss: 0.137| v_loss: 0.031| per_loss: 0.453 | a_loss: 0.571
Train: Epoch [1123/3000], Step [150/158]| g_loss: 0.773| d_loss: 0.591| gp_loss: 0.058| r_loss: 0.087| p_loss: 0.137| v_loss: 0.030| per_loss: 0.497 | a_loss: 0.538
Train: Epoch [1124/3000], Step [30/158]| g_loss: 0.783| d_loss: 0.698| gp_loss: 0.159| r_loss: 0.086| p_loss: 0.139| v_loss: 0.030| per_loss: 0.470 | a_loss: 0.551
Train: Epoch [1124/3000], Step [60/158]| g_loss: 0.743| d_loss: 0.604| gp_loss: 0.056| r_loss: 0.084| p_loss: 0.133| v_loss: 0.030| per_loss: 0.495 | a_loss: 0.512
Train: Epoch [1124/3000], Step [90/158]| g_loss: 0.807| d_loss: 0.530| gp_loss: 0.059| r_loss: 0.086| p_loss: 0.139| v_loss: 0.030| per_loss: 0.510 | a_loss: 0.571
Train: Epoch [1124/3000], Step [120/158]| g_loss: 0.838| d_loss: 0.565| gp_loss: 0.058| r_loss: 0.088| p_loss: 0.145| v_loss: 0.031| per_loss: 0.495 | a_loss: 0.598
Train: Epoch [1124/3000], Step [150/158]| g_loss: 0.840| d_loss: 0.596| gp_loss: 0.062| r_loss: 0.088| p_loss: 0.149| v_loss: 0.032| per_loss: 0.507 | a_loss: 0.594
Train: Epoch [1125/3000], Step [30/158]| g_loss: 0.811| d_loss: 0.654| gp_loss: 0.148| r_loss: 0.089| p_loss: 0.142| v_loss: 0.033| per_loss: 0.488 | a_loss: 0.570
Train: Epoch [1125/3000], Step [60/158]| g_loss: 0.765| d_loss: 0.584| gp_loss: 0.054| r_loss: 0.085| p_loss: 0.135| v_loss: 0.030| per_loss: 0.483 | a_loss: 0.534
Train: Epoch [1125/3000], Step [90/158]| g_loss: 0.803| d_loss: 0.511| gp_loss: 0.058| r_loss: 0.082| p_loss: 0.128| v_loss: 0.031| per_loss: 0.475 | a_loss: 0.578
Train: Epoch [1125/3000], Step [120/158]| g_loss: 0.761| d_loss: 0.615| gp_loss: 0.055| r_loss: 0.086| p_loss: 0.138| v_loss: 0.031| per_loss: 0.455 | a_loss: 0.530
Train: Epoch [1125/3000], Step [150/158]| g_loss: 0.779| d_loss: 0.599| gp_loss: 0.059| r_loss: 0.088| p_loss: 0.140| v_loss: 0.030| per_loss: 0.522 | a_loss: 0.539
Train: Epoch [1126/3000], Step [30/158]| g_loss: 0.756| d_loss: 0.704| gp_loss: 0.158| r_loss: 0.086| p_loss: 0.132| v_loss: 0.031| per_loss: 0.521 | a_loss: 0.522
Train: Epoch [1126/3000], Step [60/158]| g_loss: 0.842| d_loss: 0.509| gp_loss: 0.055| r_loss: 0.085| p_loss: 0.133| v_loss: 0.029| per_loss: 0.463 | a_loss: 0.615
Train: Epoch [1126/3000], Step [90/158]| g_loss: 0.792| d_loss: 0.534| gp_loss: 0.057| r_loss: 0.083| p_loss: 0.127| v_loss: 0.029| per_loss: 0.457 | a_loss: 0.570
Train: Epoch [1126/3000], Step [120/158]| g_loss: 0.766| d_loss: 0.623| gp_loss: 0.056| r_loss: 0.084| p_loss: 0.128| v_loss: 0.029| per_loss: 0.487 | a_loss: 0.540
Train: Epoch [1126/3000], Step [150/158]| g_loss: 0.779| d_loss: 0.575| gp_loss: 0.058| r_loss: 0.085| p_loss: 0.130| v_loss: 0.030| per_loss: 0.518 | a_loss: 0.547
Train: Epoch [1127/3000], Step [30/158]| g_loss: 0.779| d_loss: 0.661| gp_loss: 0.130| r_loss: 0.083| p_loss: 0.137| v_loss: 0.030| per_loss: 0.493 | a_loss: 0.547
Train: Epoch [1127/3000], Step [60/158]| g_loss: 0.807| d_loss: 0.593| gp_loss: 0.055| r_loss: 0.086| p_loss: 0.137| v_loss: 0.032| per_loss: 0.488 | a_loss: 0.572
Train: Epoch [1127/3000], Step [90/158]| g_loss: 0.742| d_loss: 0.631| gp_loss: 0.062| r_loss: 0.083| p_loss: 0.133| v_loss: 0.031| per_loss: 0.475 | a_loss: 0.513
Train: Epoch [1127/3000], Step [120/158]| g_loss: 0.775| d_loss: 0.548| gp_loss: 0.060| r_loss: 0.087| p_loss: 0.137| v_loss: 0.032| per_loss: 0.467 | a_loss: 0.541
Train: Epoch [1127/3000], Step [150/158]| g_loss: 0.859| d_loss: 0.534| gp_loss: 0.066| r_loss: 0.085| p_loss: 0.133| v_loss: 0.031| per_loss: 0.492 | a_loss: 0.628
Train: Epoch [1128/3000], Step [30/158]| g_loss: 0.781| d_loss: 0.648| gp_loss: 0.099| r_loss: 0.089| p_loss: 0.142| v_loss: 0.032| per_loss: 0.507 | a_loss: 0.538
Train: Epoch [1128/3000], Step [60/158]| g_loss: 0.830| d_loss: 0.577| gp_loss: 0.063| r_loss: 0.087| p_loss: 0.144| v_loss: 0.031| per_loss: 0.503 | a_loss: 0.590
Train: Epoch [1128/3000], Step [90/158]| g_loss: 0.841| d_loss: 0.584| gp_loss: 0.063| r_loss: 0.085| p_loss: 0.139| v_loss: 0.031| per_loss: 0.462 | a_loss: 0.609
Train: Epoch [1128/3000], Step [120/158]| g_loss: 0.781| d_loss: 0.575| gp_loss: 0.065| r_loss: 0.084| p_loss: 0.132| v_loss: 0.030| per_loss: 0.480 | a_loss: 0.553
Train: Epoch [1128/3000], Step [150/158]| g_loss: 0.780| d_loss: 0.566| gp_loss: 0.065| r_loss: 0.082| p_loss: 0.136| v_loss: 0.029| per_loss: 0.489 | a_loss: 0.552
Train: Epoch [1129/3000], Step [30/158]| g_loss: 0.812| d_loss: 0.621| gp_loss: 0.179| r_loss: 0.086| p_loss: 0.135| v_loss: 0.030| per_loss: 0.486 | a_loss: 0.580
Train: Epoch [1129/3000], Step [60/158]| g_loss: 0.833| d_loss: 0.599| gp_loss: 0.060| r_loss: 0.085| p_loss: 0.138| v_loss: 0.031| per_loss: 0.468 | a_loss: 0.601
Train: Epoch [1129/3000], Step [90/158]| g_loss: 0.707| d_loss: 0.668| gp_loss: 0.062| r_loss: 0.083| p_loss: 0.136| v_loss: 0.031| per_loss: 0.493 | a_loss: 0.476
Train: Epoch [1129/3000], Step [120/158]| g_loss: 0.838| d_loss: 0.543| gp_loss: 0.058| r_loss: 0.087| p_loss: 0.135| v_loss: 0.032| per_loss: 0.489 | a_loss: 0.603
Train: Epoch [1129/3000], Step [150/158]| g_loss: 0.788| d_loss: 0.602| gp_loss: 0.061| r_loss: 0.087| p_loss: 0.139| v_loss: 0.032| per_loss: 0.500 | a_loss: 0.549
Train: Epoch [1130/3000], Step [30/158]| g_loss: 0.809| d_loss: 0.602| gp_loss: 0.148| r_loss: 0.081| p_loss: 0.125| v_loss: 0.029| per_loss: 0.487 | a_loss: 0.588
Train: Epoch [1130/3000], Step [60/158]| g_loss: 0.742| d_loss: 0.655| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.131| v_loss: 0.029| per_loss: 0.460 | a_loss: 0.518
Train: Epoch [1130/3000], Step [90/158]| g_loss: 0.820| d_loss: 0.556| gp_loss: 0.063| r_loss: 0.084| p_loss: 0.127| v_loss: 0.030| per_loss: 0.515 | a_loss: 0.591
Train: Epoch [1130/3000], Step [120/158]| g_loss: 0.797| d_loss: 0.542| gp_loss: 0.059| r_loss: 0.083| p_loss: 0.131| v_loss: 0.029| per_loss: 0.486 | a_loss: 0.571
Train: Epoch [1130/3000], Step [150/158]| g_loss: 0.847| d_loss: 0.583| gp_loss: 0.060| r_loss: 0.086| p_loss: 0.139| v_loss: 0.031| per_loss: 0.492 | a_loss: 0.611
Train: Epoch [1131/3000], Step [30/158]| g_loss: 0.816| d_loss: 0.686| gp_loss: 0.158| r_loss: 0.093| p_loss: 0.143| v_loss: 0.032| per_loss: 0.511 | a_loss: 0.568
Train: Epoch [1131/3000], Step [60/158]| g_loss: 0.759| d_loss: 0.609| gp_loss: 0.053| r_loss: 0.087| p_loss: 0.140| v_loss: 0.032| per_loss: 0.521 | a_loss: 0.518
Train: Epoch [1131/3000], Step [90/158]| g_loss: 0.780| d_loss: 0.567| gp_loss: 0.060| r_loss: 0.084| p_loss: 0.134| v_loss: 0.031| per_loss: 0.498 | a_loss: 0.548
Train: Epoch [1131/3000], Step [120/158]| g_loss: 0.838| d_loss: 0.543| gp_loss: 0.059| r_loss: 0.083| p_loss: 0.135| v_loss: 0.032| per_loss: 0.501 | a_loss: 0.606
Train: Epoch [1131/3000], Step [150/158]| g_loss: 0.806| d_loss: 0.578| gp_loss: 0.063| r_loss: 0.089| p_loss: 0.144| v_loss: 0.030| per_loss: 0.496 | a_loss: 0.565
Train: Epoch [1132/3000], Step [30/158]| g_loss: 0.845| d_loss: 0.634| gp_loss: 0.159| r_loss: 0.087| p_loss: 0.151| v_loss: 0.030| per_loss: 0.478 | a_loss: 0.605
Train: Epoch [1132/3000], Step [60/158]| g_loss: 0.786| d_loss: 0.609| gp_loss: 0.056| r_loss: 0.091| p_loss: 0.146| v_loss: 0.031| per_loss: 0.484 | a_loss: 0.543
Train: Epoch [1132/3000], Step [90/158]| g_loss: 0.812| d_loss: 0.511| gp_loss: 0.059| r_loss: 0.085| p_loss: 0.135| v_loss: 0.029| per_loss: 0.537 | a_loss: 0.577
Train: Epoch [1132/3000], Step [120/158]| g_loss: 0.833| d_loss: 0.568| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.135| v_loss: 0.030| per_loss: 0.508 | a_loss: 0.600
Train: Epoch [1132/3000], Step [150/158]| g_loss: 0.735| d_loss: 0.692| gp_loss: 0.059| r_loss: 0.085| p_loss: 0.137| v_loss: 0.028| per_loss: 0.490 | a_loss: 0.504
Train: Epoch [1133/3000], Step [30/158]| g_loss: 0.829| d_loss: 0.656| gp_loss: 0.196| r_loss: 0.085| p_loss: 0.137| v_loss: 0.030| per_loss: 0.510 | a_loss: 0.594
Train: Epoch [1133/3000], Step [60/158]| g_loss: 0.826| d_loss: 0.534| gp_loss: 0.056| r_loss: 0.085| p_loss: 0.136| v_loss: 0.030| per_loss: 0.513 | a_loss: 0.593
Train: Epoch [1133/3000], Step [90/158]| g_loss: 0.786| d_loss: 0.645| gp_loss: 0.059| r_loss: 0.087| p_loss: 0.137| v_loss: 0.029| per_loss: 0.465 | a_loss: 0.554
Train: Epoch [1133/3000], Step [120/158]| g_loss: 0.812| d_loss: 0.571| gp_loss: 0.057| r_loss: 0.087| p_loss: 0.138| v_loss: 0.029| per_loss: 0.492 | a_loss: 0.578
Train: Epoch [1133/3000], Step [150/158]| g_loss: 0.815| d_loss: 0.572| gp_loss: 0.060| r_loss: 0.088| p_loss: 0.142| v_loss: 0.030| per_loss: 0.506 | a_loss: 0.575
Train: Epoch [1134/3000], Step [30/158]| g_loss: 0.771| d_loss: 0.640| gp_loss: 0.131| r_loss: 0.086| p_loss: 0.139| v_loss: 0.030| per_loss: 0.501 | a_loss: 0.536
Train: Epoch [1134/3000], Step [60/158]| g_loss: 0.818| d_loss: 0.538| gp_loss: 0.055| r_loss: 0.086| p_loss: 0.132| v_loss: 0.029| per_loss: 0.472 | a_loss: 0.590
Train: Epoch [1134/3000], Step [90/158]| g_loss: 0.727| d_loss: 0.704| gp_loss: 0.055| r_loss: 0.084| p_loss: 0.128| v_loss: 0.028| per_loss: 0.477 | a_loss: 0.503
Train: Epoch [1134/3000], Step [120/158]| g_loss: 0.722| d_loss: 0.563| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.134| v_loss: 0.030| per_loss: 0.498 | a_loss: 0.491
Train: Epoch [1134/3000], Step [150/158]| g_loss: 0.852| d_loss: 0.604| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.143| v_loss: 0.031| per_loss: 0.472 | a_loss: 0.619
Train: Epoch [1135/3000], Step [30/158]| g_loss: 0.815| d_loss: 0.740| gp_loss: 0.270| r_loss: 0.086| p_loss: 0.138| v_loss: 0.031| per_loss: 0.510 | a_loss: 0.578
Train: Epoch [1135/3000], Step [60/158]| g_loss: 0.772| d_loss: 0.567| gp_loss: 0.052| r_loss: 0.084| p_loss: 0.133| v_loss: 0.029| per_loss: 0.494 | a_loss: 0.542
Train: Epoch [1135/3000], Step [90/158]| g_loss: 0.794| d_loss: 0.568| gp_loss: 0.054| r_loss: 0.085| p_loss: 0.131| v_loss: 0.028| per_loss: 0.482 | a_loss: 0.567
Train: Epoch [1135/3000], Step [120/158]| g_loss: 0.775| d_loss: 0.548| gp_loss: 0.056| r_loss: 0.084| p_loss: 0.130| v_loss: 0.029| per_loss: 0.470 | a_loss: 0.550
Train: Epoch [1135/3000], Step [150/158]| g_loss: 0.756| d_loss: 0.666| gp_loss: 0.051| r_loss: 0.081| p_loss: 0.130| v_loss: 0.029| per_loss: 0.487 | a_loss: 0.533
Train: Epoch [1136/3000], Step [30/158]| g_loss: 0.785| d_loss: 0.614| gp_loss: 0.119| r_loss: 0.085| p_loss: 0.132| v_loss: 0.029| per_loss: 0.486 | a_loss: 0.557
Train: Epoch [1136/3000], Step [60/158]| g_loss: 0.789| d_loss: 0.623| gp_loss: 0.055| r_loss: 0.087| p_loss: 0.135| v_loss: 0.029| per_loss: 0.509 | a_loss: 0.554
Train: Epoch [1136/3000], Step [90/158]| g_loss: 0.803| d_loss: 0.555| gp_loss: 0.052| r_loss: 0.085| p_loss: 0.133| v_loss: 0.029| per_loss: 0.525 | a_loss: 0.570
Train: Epoch [1136/3000], Step [120/158]| g_loss: 0.846| d_loss: 0.568| gp_loss: 0.056| r_loss: 0.085| p_loss: 0.139| v_loss: 0.028| per_loss: 0.488 | a_loss: 0.614
Train: Epoch [1136/3000], Step [150/158]| g_loss: 0.747| d_loss: 0.630| gp_loss: 0.057| r_loss: 0.090| p_loss: 0.141| v_loss: 0.029| per_loss: 0.484 | a_loss: 0.510
Train: Epoch [1137/3000], Step [30/158]| g_loss: 0.794| d_loss: 0.653| gp_loss: 0.096| r_loss: 0.089| p_loss: 0.143| v_loss: 0.030| per_loss: 0.508 | a_loss: 0.552
Train: Epoch [1137/3000], Step [60/158]| g_loss: 0.727| d_loss: 0.684| gp_loss: 0.055| r_loss: 0.088| p_loss: 0.142| v_loss: 0.029| per_loss: 0.495 | a_loss: 0.491
Train: Epoch [1137/3000], Step [90/158]| g_loss: 0.796| d_loss: 0.554| gp_loss: 0.052| r_loss: 0.081| p_loss: 0.129| v_loss: 0.029| per_loss: 0.510 | a_loss: 0.571
Train: Epoch [1137/3000], Step [120/158]| g_loss: 0.782| d_loss: 0.549| gp_loss: 0.061| r_loss: 0.086| p_loss: 0.132| v_loss: 0.029| per_loss: 0.475 | a_loss: 0.554
Train: Epoch [1137/3000], Step [150/158]| g_loss: 0.816| d_loss: 0.557| gp_loss: 0.058| r_loss: 0.087| p_loss: 0.136| v_loss: 0.029| per_loss: 0.494 | a_loss: 0.583
Train: Epoch [1138/3000], Step [30/158]| g_loss: 0.768| d_loss: 0.707| gp_loss: 0.099| r_loss: 0.091| p_loss: 0.142| v_loss: 0.031| per_loss: 0.515 | a_loss: 0.524
Train: Epoch [1138/3000], Step [60/158]| g_loss: 0.902| d_loss: 0.506| gp_loss: 0.057| r_loss: 0.092| p_loss: 0.150| v_loss: 0.030| per_loss: 0.505 | a_loss: 0.654
Train: Epoch [1138/3000], Step [90/158]| g_loss: 0.745| d_loss: 0.668| gp_loss: 0.058| r_loss: 0.088| p_loss: 0.139| v_loss: 0.029| per_loss: 0.485 | a_loss: 0.510
Train: Epoch [1138/3000], Step [120/158]| g_loss: 0.802| d_loss: 0.567| gp_loss: 0.063| r_loss: 0.087| p_loss: 0.140| v_loss: 0.030| per_loss: 0.514 | a_loss: 0.563
Train: Epoch [1138/3000], Step [150/158]| g_loss: 0.737| d_loss: 0.618| gp_loss: 0.063| r_loss: 0.085| p_loss: 0.138| v_loss: 0.028| per_loss: 0.483 | a_loss: 0.506
Train: Epoch [1139/3000], Step [30/158]| g_loss: 0.779| d_loss: 0.698| gp_loss: 0.183| r_loss: 0.086| p_loss: 0.137| v_loss: 0.030| per_loss: 0.475 | a_loss: 0.547
Train: Epoch [1139/3000], Step [60/158]| g_loss: 0.787| d_loss: 0.586| gp_loss: 0.055| r_loss: 0.084| p_loss: 0.132| v_loss: 0.029| per_loss: 0.486 | a_loss: 0.560
Train: Epoch [1139/3000], Step [90/158]| g_loss: 0.750| d_loss: 0.651| gp_loss: 0.057| r_loss: 0.082| p_loss: 0.133| v_loss: 0.028| per_loss: 0.499 | a_loss: 0.524
Train: Epoch [1139/3000], Step [120/158]| g_loss: 0.759| d_loss: 0.542| gp_loss: 0.058| r_loss: 0.085| p_loss: 0.131| v_loss: 0.029| per_loss: 0.487 | a_loss: 0.531
Train: Epoch [1139/3000], Step [150/158]| g_loss: 0.872| d_loss: 0.565| gp_loss: 0.058| r_loss: 0.086| p_loss: 0.131| v_loss: 0.029| per_loss: 0.535 | a_loss: 0.639
Train: Epoch [1140/3000], Step [30/158]| g_loss: 0.724| d_loss: 0.716| gp_loss: 0.165| r_loss: 0.082| p_loss: 0.128| v_loss: 0.029| per_loss: 0.472 | a_loss: 0.501
Train: Epoch [1140/3000], Step [60/158]| g_loss: 0.830| d_loss: 0.571| gp_loss: 0.054| r_loss: 0.086| p_loss: 0.136| v_loss: 0.030| per_loss: 0.501 | a_loss: 0.597
Train: Epoch [1140/3000], Step [90/158]| g_loss: 0.741| d_loss: 0.574| gp_loss: 0.055| r_loss: 0.096| p_loss: 0.145| v_loss: 0.030| per_loss: 0.472 | a_loss: 0.496
Train: Epoch [1140/3000], Step [120/158]| g_loss: 0.833| d_loss: 0.565| gp_loss: 0.057| r_loss: 0.093| p_loss: 0.141| v_loss: 0.029| per_loss: 0.490 | a_loss: 0.591
Train: Epoch [1140/3000], Step [150/158]| g_loss: 0.785| d_loss: 0.594| gp_loss: 0.059| r_loss: 0.085| p_loss: 0.131| v_loss: 0.029| per_loss: 0.522 | a_loss: 0.553
Train: Epoch [1141/3000], Step [30/158]| g_loss: 0.790| d_loss: 0.670| gp_loss: 0.139| r_loss: 0.088| p_loss: 0.141| v_loss: 0.031| per_loss: 0.484 | a_loss: 0.552
Train: Epoch [1141/3000], Step [60/158]| g_loss: 0.871| d_loss: 0.447| gp_loss: 0.058| r_loss: 0.086| p_loss: 0.134| v_loss: 0.031| per_loss: 0.530 | a_loss: 0.634
Train: Epoch [1141/3000], Step [90/158]| g_loss: 0.795| d_loss: 0.638| gp_loss: 0.057| r_loss: 0.086| p_loss: 0.140| v_loss: 0.028| per_loss: 0.500 | a_loss: 0.560
Train: Epoch [1141/3000], Step [120/158]| g_loss: 0.737| d_loss: 0.664| gp_loss: 0.061| r_loss: 0.088| p_loss: 0.145| v_loss: 0.028| per_loss: 0.497 | a_loss: 0.498
Train: Epoch [1141/3000], Step [150/158]| g_loss: 0.805| d_loss: 0.516| gp_loss: 0.061| r_loss: 0.091| p_loss: 0.147| v_loss: 0.029| per_loss: 0.474 | a_loss: 0.565
Train: Epoch [1142/3000], Step [30/158]| g_loss: 0.744| d_loss: 0.765| gp_loss: 0.149| r_loss: 0.086| p_loss: 0.142| v_loss: 0.027| per_loss: 0.491 | a_loss: 0.510
Train: Epoch [1142/3000], Step [60/158]| g_loss: 0.770| d_loss: 0.658| gp_loss: 0.061| r_loss: 0.089| p_loss: 0.144| v_loss: 0.029| per_loss: 0.526 | a_loss: 0.527
Train: Epoch [1142/3000], Step [90/158]| g_loss: 0.760| d_loss: 0.676| gp_loss: 0.055| r_loss: 0.088| p_loss: 0.137| v_loss: 0.029| per_loss: 0.502 | a_loss: 0.525
Train: Epoch [1142/3000], Step [120/158]| g_loss: 0.834| d_loss: 0.524| gp_loss: 0.066| r_loss: 0.088| p_loss: 0.147| v_loss: 0.030| per_loss: 0.494 | a_loss: 0.593
Train: Epoch [1142/3000], Step [150/158]| g_loss: 0.815| d_loss: 0.560| gp_loss: 0.058| r_loss: 0.088| p_loss: 0.147| v_loss: 0.030| per_loss: 0.471 | a_loss: 0.576
Train: Epoch [1143/3000], Step [30/158]| g_loss: 0.811| d_loss: 0.687| gp_loss: 0.157| r_loss: 0.085| p_loss: 0.138| v_loss: 0.029| per_loss: 0.472 | a_loss: 0.581
Train: Epoch [1143/3000], Step [60/158]| g_loss: 0.868| d_loss: 0.506| gp_loss: 0.055| r_loss: 0.083| p_loss: 0.137| v_loss: 0.030| per_loss: 0.532 | a_loss: 0.634
Train: Epoch [1143/3000], Step [90/158]| g_loss: 0.778| d_loss: 0.554| gp_loss: 0.058| r_loss: 0.085| p_loss: 0.136| v_loss: 0.029| per_loss: 0.502 | a_loss: 0.545
Train: Epoch [1143/3000], Step [120/158]| g_loss: 0.794| d_loss: 0.607| gp_loss: 0.059| r_loss: 0.088| p_loss: 0.133| v_loss: 0.028| per_loss: 0.471 | a_loss: 0.564
Train: Epoch [1143/3000], Step [150/158]| g_loss: 0.784| d_loss: 0.549| gp_loss: 0.061| r_loss: 0.085| p_loss: 0.140| v_loss: 0.029| per_loss: 0.507 | a_loss: 0.549
Train: Epoch [1144/3000], Step [30/158]| g_loss: 0.801| d_loss: 0.730| gp_loss: 0.175| r_loss: 0.088| p_loss: 0.140| v_loss: 0.029| per_loss: 0.474 | a_loss: 0.567
Train: Epoch [1144/3000], Step [60/158]| g_loss: 0.745| d_loss: 0.597| gp_loss: 0.056| r_loss: 0.085| p_loss: 0.139| v_loss: 0.029| per_loss: 0.519 | a_loss: 0.509
Train: Epoch [1144/3000], Step [90/158]| g_loss: 0.884| d_loss: 0.521| gp_loss: 0.058| r_loss: 0.089| p_loss: 0.143| v_loss: 0.030| per_loss: 0.497 | a_loss: 0.644
Train: Epoch [1144/3000], Step [120/158]| g_loss: 0.768| d_loss: 0.618| gp_loss: 0.057| r_loss: 0.087| p_loss: 0.141| v_loss: 0.030| per_loss: 0.491 | a_loss: 0.532
Train: Epoch [1144/3000], Step [150/158]| g_loss: 0.769| d_loss: 0.612| gp_loss: 0.062| r_loss: 0.086| p_loss: 0.134| v_loss: 0.029| per_loss: 0.472 | a_loss: 0.540
Train: Epoch [1145/3000], Step [30/158]| g_loss: 0.788| d_loss: 0.698| gp_loss: 0.177| r_loss: 0.085| p_loss: 0.136| v_loss: 0.028| per_loss: 0.504 | a_loss: 0.556
Train: Epoch [1145/3000], Step [60/158]| g_loss: 0.801| d_loss: 0.562| gp_loss: 0.052| r_loss: 0.085| p_loss: 0.134| v_loss: 0.030| per_loss: 0.490 | a_loss: 0.570
Train: Epoch [1145/3000], Step [90/158]| g_loss: 0.751| d_loss: 0.631| gp_loss: 0.059| r_loss: 0.088| p_loss: 0.136| v_loss: 0.029| per_loss: 0.468 | a_loss: 0.520
Train: Epoch [1145/3000], Step [120/158]| g_loss: 0.843| d_loss: 0.516| gp_loss: 0.052| r_loss: 0.085| p_loss: 0.134| v_loss: 0.029| per_loss: 0.516 | a_loss: 0.611
Train: Epoch [1145/3000], Step [150/158]| g_loss: 0.728| d_loss: 0.591| gp_loss: 0.061| r_loss: 0.084| p_loss: 0.136| v_loss: 0.029| per_loss: 0.456 | a_loss: 0.501
Train: Epoch [1146/3000], Step [30/158]| g_loss: 0.842| d_loss: 0.628| gp_loss: 0.128| r_loss: 0.088| p_loss: 0.135| v_loss: 0.030| per_loss: 0.471 | a_loss: 0.610
Train: Epoch [1146/3000], Step [60/158]| g_loss: 0.794| d_loss: 0.587| gp_loss: 0.058| r_loss: 0.088| p_loss: 0.139| v_loss: 0.029| per_loss: 0.487 | a_loss: 0.559
Train: Epoch [1146/3000], Step [90/158]| g_loss: 0.807| d_loss: 0.563| gp_loss: 0.058| r_loss: 0.086| p_loss: 0.133| v_loss: 0.028| per_loss: 0.504 | a_loss: 0.576
Train: Epoch [1146/3000], Step [120/158]| g_loss: 0.802| d_loss: 0.560| gp_loss: 0.059| r_loss: 0.082| p_loss: 0.128| v_loss: 0.028| per_loss: 0.479 | a_loss: 0.580
Train: Epoch [1146/3000], Step [150/158]| g_loss: 0.771| d_loss: 0.654| gp_loss: 0.057| r_loss: 0.086| p_loss: 0.144| v_loss: 0.030| per_loss: 0.476 | a_loss: 0.536
Train: Epoch [1147/3000], Step [30/158]| g_loss: 0.767| d_loss: 0.737| gp_loss: 0.175| r_loss: 0.085| p_loss: 0.138| v_loss: 0.029| per_loss: 0.477 | a_loss: 0.536
Train: Epoch [1147/3000], Step [60/158]| g_loss: 0.790| d_loss: 0.553| gp_loss: 0.054| r_loss: 0.083| p_loss: 0.131| v_loss: 0.029| per_loss: 0.519 | a_loss: 0.560
Train: Epoch [1147/3000], Step [90/158]| g_loss: 0.840| d_loss: 0.480| gp_loss: 0.054| r_loss: 0.082| p_loss: 0.125| v_loss: 0.028| per_loss: 0.496 | a_loss: 0.617
Train: Epoch [1147/3000], Step [120/158]| g_loss: 0.793| d_loss: 0.607| gp_loss: 0.054| r_loss: 0.086| p_loss: 0.133| v_loss: 0.029| per_loss: 0.474 | a_loss: 0.565
Train: Epoch [1147/3000], Step [150/158]| g_loss: 0.709| d_loss: 0.634| gp_loss: 0.059| r_loss: 0.085| p_loss: 0.131| v_loss: 0.029| per_loss: 0.468 | a_loss: 0.483
Train: Epoch [1148/3000], Step [30/158]| g_loss: 0.807| d_loss: 0.649| gp_loss: 0.141| r_loss: 0.082| p_loss: 0.129| v_loss: 0.028| per_loss: 0.454 | a_loss: 0.587
Train: Epoch [1148/3000], Step [60/158]| g_loss: 0.817| d_loss: 0.542| gp_loss: 0.054| r_loss: 0.085| p_loss: 0.131| v_loss: 0.029| per_loss: 0.501 | a_loss: 0.587
Train: Epoch [1148/3000], Step [90/158]| g_loss: 0.770| d_loss: 0.612| gp_loss: 0.054| r_loss: 0.083| p_loss: 0.130| v_loss: 0.028| per_loss: 0.457 | a_loss: 0.548
Train: Epoch [1148/3000], Step [120/158]| g_loss: 0.777| d_loss: 0.605| gp_loss: 0.056| r_loss: 0.086| p_loss: 0.129| v_loss: 0.029| per_loss: 0.507 | a_loss: 0.546
Train: Epoch [1148/3000], Step [150/158]| g_loss: 0.748| d_loss: 0.608| gp_loss: 0.062| r_loss: 0.086| p_loss: 0.133| v_loss: 0.029| per_loss: 0.492 | a_loss: 0.517
Train: Epoch [1149/3000], Step [30/158]| g_loss: 0.813| d_loss: 0.637| gp_loss: 0.155| r_loss: 0.083| p_loss: 0.128| v_loss: 0.029| per_loss: 0.495 | a_loss: 0.587
Train: Epoch [1149/3000], Step [60/158]| g_loss: 0.794| d_loss: 0.579| gp_loss: 0.053| r_loss: 0.082| p_loss: 0.123| v_loss: 0.029| per_loss: 0.519 | a_loss: 0.569
Train: Epoch [1149/3000], Step [90/158]| g_loss: 0.790| d_loss: 0.616| gp_loss: 0.053| r_loss: 0.085| p_loss: 0.132| v_loss: 0.030| per_loss: 0.482 | a_loss: 0.561
Train: Epoch [1149/3000], Step [120/158]| g_loss: 0.731| d_loss: 0.616| gp_loss: 0.055| r_loss: 0.082| p_loss: 0.131| v_loss: 0.029| per_loss: 0.473 | a_loss: 0.507
Train: Epoch [1149/3000], Step [150/158]| g_loss: 0.798| d_loss: 0.561| gp_loss: 0.060| r_loss: 0.080| p_loss: 0.128| v_loss: 0.028| per_loss: 0.452 | a_loss: 0.581
Train: Epoch [1150/3000], Step [30/158]| g_loss: 0.795| d_loss: 0.636| gp_loss: 0.142| r_loss: 0.081| p_loss: 0.126| v_loss: 0.028| per_loss: 0.491 | a_loss: 0.574
Train: Epoch [1150/3000], Step [60/158]| g_loss: 0.773| d_loss: 0.581| gp_loss: 0.055| r_loss: 0.087| p_loss: 0.129| v_loss: 0.028| per_loss: 0.484 | a_loss: 0.545
Train: Epoch [1150/3000], Step [90/158]| g_loss: 0.751| d_loss: 0.636| gp_loss: 0.054| r_loss: 0.083| p_loss: 0.131| v_loss: 0.028| per_loss: 0.453 | a_loss: 0.529
Train: Epoch [1150/3000], Step [120/158]| g_loss: 0.714| d_loss: 0.574| gp_loss: 0.058| r_loss: 0.081| p_loss: 0.130| v_loss: 0.028| per_loss: 0.469 | a_loss: 0.493
Train: Epoch [1150/3000], Step [150/158]| g_loss: 0.812| d_loss: 0.558| gp_loss: 0.058| r_loss: 0.082| p_loss: 0.128| v_loss: 0.027| per_loss: 0.515 | a_loss: 0.587
Test: Epoch [1150/3000]| g_loss: 0.626| r_loss: 0.389| p_loss: 0.280| v_loss: 0.024
Train: Epoch [1151/3000], Step [30/158]| g_loss: 0.853| d_loss: 0.503| gp_loss: 0.055| r_loss: 0.080| p_loss: 0.126| v_loss: 0.029| per_loss: 0.492 | a_loss: 0.632
Train: Epoch [1151/3000], Step [60/158]| g_loss: 0.771| d_loss: 0.565| gp_loss: 0.055| r_loss: 0.081| p_loss: 0.125| v_loss: 0.028| per_loss: 0.477 | a_loss: 0.551
Train: Epoch [1151/3000], Step [90/158]| g_loss: 0.770| d_loss: 0.612| gp_loss: 0.054| r_loss: 0.085| p_loss: 0.127| v_loss: 0.028| per_loss: 0.466 | a_loss: 0.547
Train: Epoch [1151/3000], Step [120/158]| g_loss: 0.804| d_loss: 0.543| gp_loss: 0.062| r_loss: 0.086| p_loss: 0.136| v_loss: 0.029| per_loss: 0.512 | a_loss: 0.570
Train: Epoch [1151/3000], Step [150/158]| g_loss: 0.795| d_loss: 0.640| gp_loss: 0.056| r_loss: 0.083| p_loss: 0.134| v_loss: 0.028| per_loss: 0.459 | a_loss: 0.571
Train: Epoch [1152/3000], Step [30/158]| g_loss: 0.810| d_loss: 0.681| gp_loss: 0.195| r_loss: 0.084| p_loss: 0.134| v_loss: 0.028| per_loss: 0.486 | a_loss: 0.582
Train: Epoch [1152/3000], Step [60/158]| g_loss: 0.757| d_loss: 0.581| gp_loss: 0.057| r_loss: 0.083| p_loss: 0.135| v_loss: 0.028| per_loss: 0.475 | a_loss: 0.530
Train: Epoch [1152/3000], Step [90/158]| g_loss: 0.802| d_loss: 0.586| gp_loss: 0.052| r_loss: 0.084| p_loss: 0.129| v_loss: 0.028| per_loss: 0.497 | a_loss: 0.575
Train: Epoch [1152/3000], Step [120/158]| g_loss: 0.774| d_loss: 0.553| gp_loss: 0.055| r_loss: 0.083| p_loss: 0.132| v_loss: 0.029| per_loss: 0.505 | a_loss: 0.545
Train: Epoch [1152/3000], Step [150/158]| g_loss: 0.765| d_loss: 0.625| gp_loss: 0.055| r_loss: 0.084| p_loss: 0.133| v_loss: 0.028| per_loss: 0.473 | a_loss: 0.540
Train: Epoch [1153/3000], Step [30/158]| g_loss: 0.778| d_loss: 0.670| gp_loss: 0.124| r_loss: 0.086| p_loss: 0.140| v_loss: 0.029| per_loss: 0.518 | a_loss: 0.541
Train: Epoch [1153/3000], Step [60/158]| g_loss: 0.795| d_loss: 0.525| gp_loss: 0.055| r_loss: 0.083| p_loss: 0.137| v_loss: 0.028| per_loss: 0.466 | a_loss: 0.568
Train: Epoch [1153/3000], Step [90/158]| g_loss: 0.748| d_loss: 0.678| gp_loss: 0.055| r_loss: 0.084| p_loss: 0.136| v_loss: 0.029| per_loss: 0.494 | a_loss: 0.517
Train: Epoch [1153/3000], Step [120/158]| g_loss: 0.790| d_loss: 0.608| gp_loss: 0.056| r_loss: 0.086| p_loss: 0.136| v_loss: 0.029| per_loss: 0.499 | a_loss: 0.557
Train: Epoch [1153/3000], Step [150/158]| g_loss: 0.810| d_loss: 0.557| gp_loss: 0.059| r_loss: 0.082| p_loss: 0.131| v_loss: 0.028| per_loss: 0.512 | a_loss: 0.583
Train: Epoch [1154/3000], Step [30/158]| g_loss: 0.817| d_loss: 0.617| gp_loss: 0.156| r_loss: 0.086| p_loss: 0.141| v_loss: 0.029| per_loss: 0.474 | a_loss: 0.584
Train: Epoch [1154/3000], Step [60/158]| g_loss: 0.792| d_loss: 0.589| gp_loss: 0.055| r_loss: 0.084| p_loss: 0.138| v_loss: 0.028| per_loss: 0.489 | a_loss: 0.563
Train: Epoch [1154/3000], Step [90/158]| g_loss: 0.863| d_loss: 0.566| gp_loss: 0.051| r_loss: 0.089| p_loss: 0.150| v_loss: 0.030| per_loss: 0.503 | a_loss: 0.618
Train: Epoch [1154/3000], Step [120/158]| g_loss: 0.807| d_loss: 0.613| gp_loss: 0.058| r_loss: 0.089| p_loss: 0.156| v_loss: 0.030| per_loss: 0.497 | a_loss: 0.560
Train: Epoch [1154/3000], Step [150/158]| g_loss: 0.794| d_loss: 0.595| gp_loss: 0.054| r_loss: 0.094| p_loss: 0.155| v_loss: 0.030| per_loss: 0.522 | a_loss: 0.539
Train: Epoch [1155/3000], Step [30/158]| g_loss: 0.826| d_loss: 0.790| gp_loss: 0.168| r_loss: 0.134| p_loss: 0.176| v_loss: 0.029| per_loss: 0.544 | a_loss: 0.520
Train: Epoch [1155/3000], Step [60/158]| g_loss: 0.828| d_loss: 0.575| gp_loss: 0.058| r_loss: 0.099| p_loss: 0.166| v_loss: 0.031| per_loss: 0.471 | a_loss: 0.567
Train: Epoch [1155/3000], Step [90/158]| g_loss: 0.812| d_loss: 0.547| gp_loss: 0.059| r_loss: 0.092| p_loss: 0.157| v_loss: 0.029| per_loss: 0.492 | a_loss: 0.563
Train: Epoch [1155/3000], Step [120/158]| g_loss: 0.788| d_loss: 0.610| gp_loss: 0.059| r_loss: 0.089| p_loss: 0.144| v_loss: 0.028| per_loss: 0.495 | a_loss: 0.549
Train: Epoch [1155/3000], Step [150/158]| g_loss: 0.762| d_loss: 0.596| gp_loss: 0.060| r_loss: 0.084| p_loss: 0.138| v_loss: 0.029| per_loss: 0.508 | a_loss: 0.530
Train: Epoch [1156/3000], Step [30/158]| g_loss: 0.729| d_loss: 0.715| gp_loss: 0.095| r_loss: 0.088| p_loss: 0.156| v_loss: 0.029| per_loss: 0.514 | a_loss: 0.482
Train: Epoch [1156/3000], Step [60/158]| g_loss: 0.836| d_loss: 0.592| gp_loss: 0.062| r_loss: 0.088| p_loss: 0.143| v_loss: 0.029| per_loss: 0.544 | a_loss: 0.593
Train: Epoch [1156/3000], Step [90/158]| g_loss: 0.792| d_loss: 0.595| gp_loss: 0.065| r_loss: 0.091| p_loss: 0.151| v_loss: 0.029| per_loss: 0.510 | a_loss: 0.546
Train: Epoch [1156/3000], Step [120/158]| g_loss: 0.759| d_loss: 0.591| gp_loss: 0.065| r_loss: 0.086| p_loss: 0.142| v_loss: 0.029| per_loss: 0.525 | a_loss: 0.520
Train: Epoch [1156/3000], Step [150/158]| g_loss: 0.840| d_loss: 0.548| gp_loss: 0.063| r_loss: 0.087| p_loss: 0.141| v_loss: 0.030| per_loss: 0.485 | a_loss: 0.604
Train: Epoch [1157/3000], Step [30/158]| g_loss: 0.842| d_loss: 0.559| gp_loss: 0.163| r_loss: 0.082| p_loss: 0.134| v_loss: 0.030| per_loss: 0.514 | a_loss: 0.612
Train: Epoch [1157/3000], Step [60/158]| g_loss: 0.841| d_loss: 0.527| gp_loss: 0.058| r_loss: 0.087| p_loss: 0.137| v_loss: 0.030| per_loss: 0.541 | a_loss: 0.601
Train: Epoch [1157/3000], Step [90/158]| g_loss: 0.771| d_loss: 0.567| gp_loss: 0.060| r_loss: 0.088| p_loss: 0.136| v_loss: 0.030| per_loss: 0.505 | a_loss: 0.534
Train: Epoch [1157/3000], Step [120/158]| g_loss: 0.817| d_loss: 0.577| gp_loss: 0.063| r_loss: 0.085| p_loss: 0.139| v_loss: 0.029| per_loss: 0.482 | a_loss: 0.586
Train: Epoch [1157/3000], Step [150/158]| g_loss: 0.708| d_loss: 0.693| gp_loss: 0.059| r_loss: 0.082| p_loss: 0.136| v_loss: 0.028| per_loss: 0.479 | a_loss: 0.482
Train: Epoch [1158/3000], Step [30/158]| g_loss: 0.772| d_loss: 0.682| gp_loss: 0.146| r_loss: 0.087| p_loss: 0.138| v_loss: 0.030| per_loss: 0.505 | a_loss: 0.536
Train: Epoch [1158/3000], Step [60/158]| g_loss: 0.743| d_loss: 0.653| gp_loss: 0.061| r_loss: 0.087| p_loss: 0.141| v_loss: 0.028| per_loss: 0.469 | a_loss: 0.511
Train: Epoch [1158/3000], Step [90/158]| g_loss: 0.807| d_loss: 0.566| gp_loss: 0.060| r_loss: 0.083| p_loss: 0.133| v_loss: 0.030| per_loss: 0.485 | a_loss: 0.579
Train: Epoch [1158/3000], Step [120/158]| g_loss: 0.859| d_loss: 0.531| gp_loss: 0.060| r_loss: 0.086| p_loss: 0.138| v_loss: 0.029| per_loss: 0.514 | a_loss: 0.624
Train: Epoch [1158/3000], Step [150/158]| g_loss: 0.787| d_loss: 0.550| gp_loss: 0.058| r_loss: 0.085| p_loss: 0.139| v_loss: 0.030| per_loss: 0.501 | a_loss: 0.553
Train: Epoch [1159/3000], Step [30/158]| g_loss: 0.760| d_loss: 0.744| gp_loss: 0.129| r_loss: 0.090| p_loss: 0.151| v_loss: 0.030| per_loss: 0.508 | a_loss: 0.514
Train: Epoch [1159/3000], Step [60/158]| g_loss: 0.748| d_loss: 0.635| gp_loss: 0.059| r_loss: 0.087| p_loss: 0.138| v_loss: 0.030| per_loss: 0.507 | a_loss: 0.512
Train: Epoch [1159/3000], Step [90/158]| g_loss: 0.815| d_loss: 0.584| gp_loss: 0.056| r_loss: 0.086| p_loss: 0.139| v_loss: 0.029| per_loss: 0.505 | a_loss: 0.580
Train: Epoch [1159/3000], Step [120/158]| g_loss: 0.810| d_loss: 0.509| gp_loss: 0.065| r_loss: 0.084| p_loss: 0.135| v_loss: 0.029| per_loss: 0.503 | a_loss: 0.579
Train: Epoch [1159/3000], Step [150/158]| g_loss: 0.833| d_loss: 0.565| gp_loss: 0.061| r_loss: 0.082| p_loss: 0.123| v_loss: 0.029| per_loss: 0.493 | a_loss: 0.611
Train: Epoch [1160/3000], Step [30/158]| g_loss: 0.769| d_loss: 0.765| gp_loss: 0.204| r_loss: 0.085| p_loss: 0.131| v_loss: 0.030| per_loss: 0.507 | a_loss: 0.538
Train: Epoch [1160/3000], Step [60/158]| g_loss: 0.804| d_loss: 0.551| gp_loss: 0.056| r_loss: 0.088| p_loss: 0.134| v_loss: 0.031| per_loss: 0.492 | a_loss: 0.569
Train: Epoch [1160/3000], Step [90/158]| g_loss: 0.822| d_loss: 0.480| gp_loss: 0.053| r_loss: 0.083| p_loss: 0.127| v_loss: 0.030| per_loss: 0.479 | a_loss: 0.597
Train: Epoch [1160/3000], Step [120/158]| g_loss: 0.817| d_loss: 0.572| gp_loss: 0.054| r_loss: 0.089| p_loss: 0.139| v_loss: 0.030| per_loss: 0.480 | a_loss: 0.580
Train: Epoch [1160/3000], Step [150/158]| g_loss: 0.759| d_loss: 0.615| gp_loss: 0.054| r_loss: 0.083| p_loss: 0.130| v_loss: 0.030| per_loss: 0.507 | a_loss: 0.530
Train: Epoch [1161/3000], Step [30/158]| g_loss: 0.748| d_loss: 0.747| gp_loss: 0.182| r_loss: 0.085| p_loss: 0.137| v_loss: 0.030| per_loss: 0.502 | a_loss: 0.514
Train: Epoch [1161/3000], Step [60/158]| g_loss: 0.791| d_loss: 0.570| gp_loss: 0.054| r_loss: 0.084| p_loss: 0.131| v_loss: 0.030| per_loss: 0.475 | a_loss: 0.565
Train: Epoch [1161/3000], Step [90/158]| g_loss: 0.771| d_loss: 0.552| gp_loss: 0.053| r_loss: 0.083| p_loss: 0.129| v_loss: 0.029| per_loss: 0.496 | a_loss: 0.546
Train: Epoch [1161/3000], Step [120/158]| g_loss: 0.793| d_loss: 0.581| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.131| v_loss: 0.029| per_loss: 0.498 | a_loss: 0.565
Train: Epoch [1161/3000], Step [150/158]| g_loss: 0.799| d_loss: 0.543| gp_loss: 0.055| r_loss: 0.085| p_loss: 0.133| v_loss: 0.029| per_loss: 0.492 | a_loss: 0.569
Train: Epoch [1162/3000], Step [30/158]| g_loss: 0.744| d_loss: 0.672| gp_loss: 0.133| r_loss: 0.082| p_loss: 0.127| v_loss: 0.029| per_loss: 0.471 | a_loss: 0.522
Train: Epoch [1162/3000], Step [60/158]| g_loss: 0.760| d_loss: 0.632| gp_loss: 0.055| r_loss: 0.081| p_loss: 0.133| v_loss: 0.030| per_loss: 0.475 | a_loss: 0.535
Train: Epoch [1162/3000], Step [90/158]| g_loss: 0.746| d_loss: 0.552| gp_loss: 0.061| r_loss: 0.080| p_loss: 0.125| v_loss: 0.029| per_loss: 0.482 | a_loss: 0.526
Train: Epoch [1162/3000], Step [120/158]| g_loss: 0.771| d_loss: 0.587| gp_loss: 0.058| r_loss: 0.090| p_loss: 0.142| v_loss: 0.029| per_loss: 0.530 | a_loss: 0.528
Train: Epoch [1162/3000], Step [150/158]| g_loss: 0.847| d_loss: 0.544| gp_loss: 0.060| r_loss: 0.086| p_loss: 0.135| v_loss: 0.030| per_loss: 0.521 | a_loss: 0.612
Train: Epoch [1163/3000], Step [30/158]| g_loss: 0.771| d_loss: 0.722| gp_loss: 0.180| r_loss: 0.088| p_loss: 0.148| v_loss: 0.029| per_loss: 0.516 | a_loss: 0.528
Train: Epoch [1163/3000], Step [60/158]| g_loss: 0.812| d_loss: 0.604| gp_loss: 0.059| r_loss: 0.092| p_loss: 0.155| v_loss: 0.031| per_loss: 0.521 | a_loss: 0.560
Train: Epoch [1163/3000], Step [90/158]| g_loss: 0.787| d_loss: 0.558| gp_loss: 0.058| r_loss: 0.091| p_loss: 0.148| v_loss: 0.032| per_loss: 0.507 | a_loss: 0.539
Train: Epoch [1163/3000], Step [120/158]| g_loss: 0.850| d_loss: 0.567| gp_loss: 0.065| r_loss: 0.091| p_loss: 0.151| v_loss: 0.031| per_loss: 0.533 | a_loss: 0.599
Train: Epoch [1163/3000], Step [150/158]| g_loss: 0.817| d_loss: 0.490| gp_loss: 0.059| r_loss: 0.084| p_loss: 0.136| v_loss: 0.029| per_loss: 0.566 | a_loss: 0.579
Train: Epoch [1164/3000], Step [30/158]| g_loss: 0.785| d_loss: 0.712| gp_loss: 0.162| r_loss: 0.087| p_loss: 0.143| v_loss: 0.032| per_loss: 0.515 | a_loss: 0.543
Train: Epoch [1164/3000], Step [60/158]| g_loss: 0.805| d_loss: 0.601| gp_loss: 0.054| r_loss: 0.086| p_loss: 0.135| v_loss: 0.031| per_loss: 0.527 | a_loss: 0.568
Train: Epoch [1164/3000], Step [90/158]| g_loss: 0.828| d_loss: 0.516| gp_loss: 0.062| r_loss: 0.087| p_loss: 0.135| v_loss: 0.031| per_loss: 0.517 | a_loss: 0.590
Train: Epoch [1164/3000], Step [120/158]| g_loss: 0.861| d_loss: 0.511| gp_loss: 0.061| r_loss: 0.086| p_loss: 0.130| v_loss: 0.030| per_loss: 0.516 | a_loss: 0.627
Train: Epoch [1164/3000], Step [150/158]| g_loss: 0.811| d_loss: 0.557| gp_loss: 0.062| r_loss: 0.085| p_loss: 0.136| v_loss: 0.031| per_loss: 0.549 | a_loss: 0.572
Train: Epoch [1165/3000], Step [30/158]| g_loss: 0.823| d_loss: 0.599| gp_loss: 0.117| r_loss: 0.084| p_loss: 0.130| v_loss: 0.031| per_loss: 0.550 | a_loss: 0.587
Train: Epoch [1165/3000], Step [60/158]| g_loss: 0.726| d_loss: 0.632| gp_loss: 0.059| r_loss: 0.090| p_loss: 0.144| v_loss: 0.031| per_loss: 0.501 | a_loss: 0.483
Train: Epoch [1165/3000], Step [90/158]| g_loss: 0.856| d_loss: 0.524| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.137| v_loss: 0.031| per_loss: 0.484 | a_loss: 0.623
Train: Epoch [1165/3000], Step [120/158]| g_loss: 0.800| d_loss: 0.644| gp_loss: 0.056| r_loss: 0.088| p_loss: 0.142| v_loss: 0.029| per_loss: 0.534 | a_loss: 0.558
Train: Epoch [1165/3000], Step [150/158]| g_loss: 0.763| d_loss: 0.625| gp_loss: 0.062| r_loss: 0.086| p_loss: 0.140| v_loss: 0.030| per_loss: 0.515 | a_loss: 0.525
Train: Epoch [1166/3000], Step [30/158]| g_loss: 0.758| d_loss: 0.734| gp_loss: 0.188| r_loss: 0.092| p_loss: 0.147| v_loss: 0.031| per_loss: 0.520 | a_loss: 0.510
Train: Epoch [1166/3000], Step [60/158]| g_loss: 0.789| d_loss: 0.578| gp_loss: 0.058| r_loss: 0.087| p_loss: 0.140| v_loss: 0.029| per_loss: 0.490 | a_loss: 0.554
Train: Epoch [1166/3000], Step [90/158]| g_loss: 0.809| d_loss: 0.517| gp_loss: 0.055| r_loss: 0.087| p_loss: 0.136| v_loss: 0.030| per_loss: 0.532 | a_loss: 0.571
Train: Epoch [1166/3000], Step [120/158]| g_loss: 0.752| d_loss: 0.639| gp_loss: 0.055| r_loss: 0.085| p_loss: 0.139| v_loss: 0.031| per_loss: 0.496 | a_loss: 0.517
Train: Epoch [1166/3000], Step [150/158]| g_loss: 0.806| d_loss: 0.521| gp_loss: 0.058| r_loss: 0.087| p_loss: 0.140| v_loss: 0.032| per_loss: 0.481 | a_loss: 0.570
Train: Epoch [1167/3000], Step [30/158]| g_loss: 0.796| d_loss: 0.706| gp_loss: 0.163| r_loss: 0.086| p_loss: 0.138| v_loss: 0.032| per_loss: 0.476 | a_loss: 0.561
Train: Epoch [1167/3000], Step [60/158]| g_loss: 0.783| d_loss: 0.555| gp_loss: 0.051| r_loss: 0.083| p_loss: 0.129| v_loss: 0.031| per_loss: 0.498 | a_loss: 0.555
Train: Epoch [1167/3000], Step [90/158]| g_loss: 0.798| d_loss: 0.599| gp_loss: 0.057| r_loss: 0.086| p_loss: 0.139| v_loss: 0.030| per_loss: 0.495 | a_loss: 0.564
Train: Epoch [1167/3000], Step [120/158]| g_loss: 0.796| d_loss: 0.537| gp_loss: 0.059| r_loss: 0.085| p_loss: 0.135| v_loss: 0.030| per_loss: 0.532 | a_loss: 0.559
Train: Epoch [1167/3000], Step [150/158]| g_loss: 0.799| d_loss: 0.594| gp_loss: 0.058| r_loss: 0.085| p_loss: 0.136| v_loss: 0.030| per_loss: 0.464 | a_loss: 0.570
Train: Epoch [1168/3000], Step [30/158]| g_loss: 0.781| d_loss: 0.577| gp_loss: 0.117| r_loss: 0.082| p_loss: 0.132| v_loss: 0.028| per_loss: 0.494 | a_loss: 0.557
Train: Epoch [1168/3000], Step [60/158]| g_loss: 0.771| d_loss: 0.595| gp_loss: 0.056| r_loss: 0.082| p_loss: 0.134| v_loss: 0.030| per_loss: 0.495 | a_loss: 0.543
Train: Epoch [1168/3000], Step [90/158]| g_loss: 0.822| d_loss: 0.536| gp_loss: 0.060| r_loss: 0.083| p_loss: 0.129| v_loss: 0.029| per_loss: 0.495 | a_loss: 0.596
Train: Epoch [1168/3000], Step [120/158]| g_loss: 0.795| d_loss: 0.551| gp_loss: 0.060| r_loss: 0.087| p_loss: 0.132| v_loss: 0.029| per_loss: 0.484 | a_loss: 0.564
Train: Epoch [1168/3000], Step [150/158]| g_loss: 0.765| d_loss: 0.708| gp_loss: 0.059| r_loss: 0.086| p_loss: 0.133| v_loss: 0.029| per_loss: 0.477 | a_loss: 0.535
Train: Epoch [1169/3000], Step [30/158]| g_loss: 0.697| d_loss: 0.862| gp_loss: 0.148| r_loss: 0.088| p_loss: 0.145| v_loss: 0.031| per_loss: 0.492 | a_loss: 0.456
Train: Epoch [1169/3000], Step [60/158]| g_loss: 0.867| d_loss: 0.540| gp_loss: 0.054| r_loss: 0.091| p_loss: 0.149| v_loss: 0.032| per_loss: 0.524 | a_loss: 0.617
Train: Epoch [1169/3000], Step [90/158]| g_loss: 0.740| d_loss: 0.568| gp_loss: 0.058| r_loss: 0.087| p_loss: 0.136| v_loss: 0.028| per_loss: 0.499 | a_loss: 0.508
Train: Epoch [1169/3000], Step [120/158]| g_loss: 0.925| d_loss: 0.511| gp_loss: 0.055| r_loss: 0.088| p_loss: 0.136| v_loss: 0.030| per_loss: 0.517 | a_loss: 0.687
Train: Epoch [1169/3000], Step [150/158]| g_loss: 0.732| d_loss: 0.645| gp_loss: 0.056| r_loss: 0.083| p_loss: 0.132| v_loss: 0.028| per_loss: 0.488 | a_loss: 0.506
Train: Epoch [1170/3000], Step [30/158]| g_loss: 0.739| d_loss: 0.704| gp_loss: 0.154| r_loss: 0.084| p_loss: 0.135| v_loss: 0.031| per_loss: 0.444 | a_loss: 0.513
Train: Epoch [1170/3000], Step [60/158]| g_loss: 0.815| d_loss: 0.577| gp_loss: 0.053| r_loss: 0.082| p_loss: 0.126| v_loss: 0.031| per_loss: 0.532 | a_loss: 0.586
Train: Epoch [1170/3000], Step [90/158]| g_loss: 0.845| d_loss: 0.534| gp_loss: 0.056| r_loss: 0.086| p_loss: 0.135| v_loss: 0.030| per_loss: 0.486 | a_loss: 0.612
Train: Epoch [1170/3000], Step [120/158]| g_loss: 0.769| d_loss: 0.616| gp_loss: 0.060| r_loss: 0.094| p_loss: 0.140| v_loss: 0.030| per_loss: 0.456 | a_loss: 0.529
Train: Epoch [1170/3000], Step [150/158]| g_loss: 0.781| d_loss: 0.577| gp_loss: 0.058| r_loss: 0.086| p_loss: 0.134| v_loss: 0.030| per_loss: 0.517 | a_loss: 0.546
Train: Epoch [1171/3000], Step [30/158]| g_loss: 0.801| d_loss: 0.665| gp_loss: 0.155| r_loss: 0.086| p_loss: 0.134| v_loss: 0.030| per_loss: 0.513 | a_loss: 0.567
Train: Epoch [1171/3000], Step [60/158]| g_loss: 0.765| d_loss: 0.566| gp_loss: 0.054| r_loss: 0.087| p_loss: 0.134| v_loss: 0.030| per_loss: 0.467 | a_loss: 0.534
Train: Epoch [1171/3000], Step [90/158]| g_loss: 0.797| d_loss: 0.548| gp_loss: 0.055| r_loss: 0.084| p_loss: 0.131| v_loss: 0.028| per_loss: 0.469 | a_loss: 0.573
Train: Epoch [1171/3000], Step [120/158]| g_loss: 0.777| d_loss: 0.642| gp_loss: 0.057| r_loss: 0.082| p_loss: 0.133| v_loss: 0.029| per_loss: 0.500 | a_loss: 0.550
Train: Epoch [1171/3000], Step [150/158]| g_loss: 0.774| d_loss: 0.557| gp_loss: 0.065| r_loss: 0.082| p_loss: 0.130| v_loss: 0.029| per_loss: 0.482 | a_loss: 0.550
Train: Epoch [1172/3000], Step [30/158]| g_loss: 0.771| d_loss: 0.700| gp_loss: 0.152| r_loss: 0.085| p_loss: 0.133| v_loss: 0.029| per_loss: 0.497 | a_loss: 0.540
Train: Epoch [1172/3000], Step [60/158]| g_loss: 0.773| d_loss: 0.611| gp_loss: 0.055| r_loss: 0.078| p_loss: 0.126| v_loss: 0.029| per_loss: 0.536 | a_loss: 0.549
Train: Epoch [1172/3000], Step [90/158]| g_loss: 0.798| d_loss: 0.556| gp_loss: 0.063| r_loss: 0.084| p_loss: 0.132| v_loss: 0.030| per_loss: 0.453 | a_loss: 0.572
Train: Epoch [1172/3000], Step [120/158]| g_loss: 0.795| d_loss: 0.581| gp_loss: 0.057| r_loss: 0.083| p_loss: 0.130| v_loss: 0.030| per_loss: 0.494 | a_loss: 0.568
Train: Epoch [1172/3000], Step [150/158]| g_loss: 0.849| d_loss: 0.548| gp_loss: 0.059| r_loss: 0.085| p_loss: 0.136| v_loss: 0.030| per_loss: 0.497 | a_loss: 0.617
Train: Epoch [1173/3000], Step [30/158]| g_loss: 0.769| d_loss: 0.704| gp_loss: 0.166| r_loss: 0.088| p_loss: 0.139| v_loss: 0.030| per_loss: 0.504 | a_loss: 0.530
Train: Epoch [1173/3000], Step [60/158]| g_loss: 0.826| d_loss: 0.554| gp_loss: 0.060| r_loss: 0.084| p_loss: 0.136| v_loss: 0.029| per_loss: 0.473 | a_loss: 0.598
Train: Epoch [1173/3000], Step [90/158]| g_loss: 0.823| d_loss: 0.503| gp_loss: 0.056| r_loss: 0.083| p_loss: 0.131| v_loss: 0.030| per_loss: 0.519 | a_loss: 0.592
Train: Epoch [1173/3000], Step [120/158]| g_loss: 0.802| d_loss: 0.529| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.127| v_loss: 0.029| per_loss: 0.504 | a_loss: 0.576
Train: Epoch [1173/3000], Step [150/158]| g_loss: 0.779| d_loss: 0.664| gp_loss: 0.060| r_loss: 0.085| p_loss: 0.135| v_loss: 0.028| per_loss: 0.454 | a_loss: 0.553
Train: Epoch [1174/3000], Step [30/158]| g_loss: 0.773| d_loss: 0.649| gp_loss: 0.116| r_loss: 0.083| p_loss: 0.130| v_loss: 0.029| per_loss: 0.501 | a_loss: 0.546
Train: Epoch [1174/3000], Step [60/158]| g_loss: 0.797| d_loss: 0.599| gp_loss: 0.061| r_loss: 0.084| p_loss: 0.139| v_loss: 0.029| per_loss: 0.470 | a_loss: 0.567
Train: Epoch [1174/3000], Step [90/158]| g_loss: 0.817| d_loss: 0.529| gp_loss: 0.061| r_loss: 0.085| p_loss: 0.139| v_loss: 0.029| per_loss: 0.465 | a_loss: 0.587
Train: Epoch [1174/3000], Step [120/158]| g_loss: 0.800| d_loss: 0.599| gp_loss: 0.060| r_loss: 0.084| p_loss: 0.130| v_loss: 0.028| per_loss: 0.493 | a_loss: 0.573
Train: Epoch [1174/3000], Step [150/158]| g_loss: 0.751| d_loss: 0.673| gp_loss: 0.061| r_loss: 0.085| p_loss: 0.131| v_loss: 0.030| per_loss: 0.528 | a_loss: 0.519
Train: Epoch [1175/3000], Step [30/158]| g_loss: 0.776| d_loss: 0.623| gp_loss: 0.133| r_loss: 0.084| p_loss: 0.138| v_loss: 0.031| per_loss: 0.499 | a_loss: 0.542
Train: Epoch [1175/3000], Step [60/158]| g_loss: 0.801| d_loss: 0.633| gp_loss: 0.054| r_loss: 0.085| p_loss: 0.133| v_loss: 0.030| per_loss: 0.476 | a_loss: 0.572
Train: Epoch [1175/3000], Step [90/158]| g_loss: 0.801| d_loss: 0.526| gp_loss: 0.060| r_loss: 0.084| p_loss: 0.129| v_loss: 0.029| per_loss: 0.485 | a_loss: 0.575
Train: Epoch [1175/3000], Step [120/158]| g_loss: 0.777| d_loss: 0.602| gp_loss: 0.061| r_loss: 0.082| p_loss: 0.128| v_loss: 0.029| per_loss: 0.470 | a_loss: 0.555
Train: Epoch [1175/3000], Step [150/158]| g_loss: 0.777| d_loss: 0.588| gp_loss: 0.061| r_loss: 0.081| p_loss: 0.130| v_loss: 0.028| per_loss: 0.500 | a_loss: 0.553
Train: Epoch [1176/3000], Step [30/158]| g_loss: 0.719| d_loss: 0.761| gp_loss: 0.177| r_loss: 0.088| p_loss: 0.137| v_loss: 0.029| per_loss: 0.505 | a_loss: 0.483
Train: Epoch [1176/3000], Step [60/158]| g_loss: 0.741| d_loss: 0.616| gp_loss: 0.061| r_loss: 0.078| p_loss: 0.122| v_loss: 0.028| per_loss: 0.441 | a_loss: 0.530
Train: Epoch [1176/3000], Step [90/158]| g_loss: 0.739| d_loss: 0.640| gp_loss: 0.058| r_loss: 0.080| p_loss: 0.128| v_loss: 0.028| per_loss: 0.492 | a_loss: 0.517
Train: Epoch [1176/3000], Step [120/158]| g_loss: 0.814| d_loss: 0.552| gp_loss: 0.059| r_loss: 0.083| p_loss: 0.129| v_loss: 0.029| per_loss: 0.541 | a_loss: 0.584
Train: Epoch [1176/3000], Step [150/158]| g_loss: 0.819| d_loss: 0.494| gp_loss: 0.063| r_loss: 0.083| p_loss: 0.127| v_loss: 0.028| per_loss: 0.445 | a_loss: 0.600
Train: Epoch [1177/3000], Step [30/158]| g_loss: 0.761| d_loss: 0.727| gp_loss: 0.207| r_loss: 0.080| p_loss: 0.132| v_loss: 0.029| per_loss: 0.490 | a_loss: 0.536
Train: Epoch [1177/3000], Step [60/158]| g_loss: 0.830| d_loss: 0.587| gp_loss: 0.056| r_loss: 0.085| p_loss: 0.133| v_loss: 0.028| per_loss: 0.475 | a_loss: 0.603
Train: Epoch [1177/3000], Step [90/158]| g_loss: 0.811| d_loss: 0.542| gp_loss: 0.057| r_loss: 0.084| p_loss: 0.132| v_loss: 0.028| per_loss: 0.501 | a_loss: 0.583
Train: Epoch [1177/3000], Step [120/158]| g_loss: 0.751| d_loss: 0.614| gp_loss: 0.061| r_loss: 0.092| p_loss: 0.146| v_loss: 0.030| per_loss: 0.477 | a_loss: 0.509
Train: Epoch [1177/3000], Step [150/158]| g_loss: 0.791| d_loss: 0.578| gp_loss: 0.059| r_loss: 0.081| p_loss: 0.127| v_loss: 0.028| per_loss: 0.480 | a_loss: 0.570
Train: Epoch [1178/3000], Step [30/158]| g_loss: 0.857| d_loss: 0.574| gp_loss: 0.162| r_loss: 0.085| p_loss: 0.129| v_loss: 0.030| per_loss: 0.465 | a_loss: 0.632
Train: Epoch [1178/3000], Step [60/158]| g_loss: 0.725| d_loss: 0.676| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.134| v_loss: 0.030| per_loss: 0.489 | a_loss: 0.495
Train: Epoch [1178/3000], Step [90/158]| g_loss: 0.829| d_loss: 0.535| gp_loss: 0.055| r_loss: 0.084| p_loss: 0.136| v_loss: 0.030| per_loss: 0.490 | a_loss: 0.597
Train: Epoch [1178/3000], Step [120/158]| g_loss: 0.806| d_loss: 0.540| gp_loss: 0.056| r_loss: 0.081| p_loss: 0.126| v_loss: 0.029| per_loss: 0.473 | a_loss: 0.586
Train: Epoch [1178/3000], Step [150/158]| g_loss: 0.792| d_loss: 0.570| gp_loss: 0.059| r_loss: 0.085| p_loss: 0.136| v_loss: 0.028| per_loss: 0.516 | a_loss: 0.560
Train: Epoch [1179/3000], Step [30/158]| g_loss: 0.776| d_loss: 0.673| gp_loss: 0.146| r_loss: 0.085| p_loss: 0.137| v_loss: 0.029| per_loss: 0.487 | a_loss: 0.545
Train: Epoch [1179/3000], Step [60/158]| g_loss: 0.771| d_loss: 0.595| gp_loss: 0.054| r_loss: 0.082| p_loss: 0.133| v_loss: 0.029| per_loss: 0.502 | a_loss: 0.543
Train: Epoch [1179/3000], Step [90/158]| g_loss: 0.769| d_loss: 0.592| gp_loss: 0.057| r_loss: 0.086| p_loss: 0.131| v_loss: 0.029| per_loss: 0.505 | a_loss: 0.538
Train: Epoch [1179/3000], Step [120/158]| g_loss: 0.772| d_loss: 0.629| gp_loss: 0.060| r_loss: 0.087| p_loss: 0.134| v_loss: 0.028| per_loss: 0.491 | a_loss: 0.541
Train: Epoch [1179/3000], Step [150/158]| g_loss: 0.790| d_loss: 0.545| gp_loss: 0.064| r_loss: 0.087| p_loss: 0.138| v_loss: 0.030| per_loss: 0.501 | a_loss: 0.555
Train: Epoch [1180/3000], Step [30/158]| g_loss: 0.810| d_loss: 0.735| gp_loss: 0.206| r_loss: 0.086| p_loss: 0.139| v_loss: 0.030| per_loss: 0.493 | a_loss: 0.576
Train: Epoch [1180/3000], Step [60/158]| g_loss: 0.787| d_loss: 0.627| gp_loss: 0.055| r_loss: 0.081| p_loss: 0.131| v_loss: 0.029| per_loss: 0.493 | a_loss: 0.562
Train: Epoch [1180/3000], Step [90/158]| g_loss: 0.782| d_loss: 0.560| gp_loss: 0.059| r_loss: 0.084| p_loss: 0.137| v_loss: 0.029| per_loss: 0.492 | a_loss: 0.551
Train: Epoch [1180/3000], Step [120/158]| g_loss: 0.839| d_loss: 0.560| gp_loss: 0.055| r_loss: 0.086| p_loss: 0.136| v_loss: 0.029| per_loss: 0.514 | a_loss: 0.605
Train: Epoch [1180/3000], Step [150/158]| g_loss: 0.788| d_loss: 0.549| gp_loss: 0.062| r_loss: 0.083| p_loss: 0.139| v_loss: 0.029| per_loss: 0.469 | a_loss: 0.559
Train: Epoch [1181/3000], Step [30/158]| g_loss: 0.777| d_loss: 0.680| gp_loss: 0.150| r_loss: 0.086| p_loss: 0.143| v_loss: 0.030| per_loss: 0.485 | a_loss: 0.541
Train: Epoch [1181/3000], Step [60/158]| g_loss: 0.762| d_loss: 0.634| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.140| v_loss: 0.029| per_loss: 0.487 | a_loss: 0.530
Train: Epoch [1181/3000], Step [90/158]| g_loss: 0.790| d_loss: 0.594| gp_loss: 0.060| r_loss: 0.085| p_loss: 0.143| v_loss: 0.029| per_loss: 0.513 | a_loss: 0.554
Train: Epoch [1181/3000], Step [120/158]| g_loss: 0.824| d_loss: 0.563| gp_loss: 0.061| r_loss: 0.086| p_loss: 0.138| v_loss: 0.030| per_loss: 0.524 | a_loss: 0.586
Train: Epoch [1181/3000], Step [150/158]| g_loss: 0.797| d_loss: 0.589| gp_loss: 0.062| r_loss: 0.087| p_loss: 0.142| v_loss: 0.030| per_loss: 0.493 | a_loss: 0.559
Train: Epoch [1182/3000], Step [30/158]| g_loss: 0.809| d_loss: 0.698| gp_loss: 0.174| r_loss: 0.087| p_loss: 0.143| v_loss: 0.029| per_loss: 0.486 | a_loss: 0.572
Train: Epoch [1182/3000], Step [60/158]| g_loss: 0.804| d_loss: 0.597| gp_loss: 0.056| r_loss: 0.091| p_loss: 0.141| v_loss: 0.030| per_loss: 0.509 | a_loss: 0.562
Train: Epoch [1182/3000], Step [90/158]| g_loss: 0.834| d_loss: 0.493| gp_loss: 0.058| r_loss: 0.085| p_loss: 0.133| v_loss: 0.030| per_loss: 0.554 | a_loss: 0.597
Train: Epoch [1182/3000], Step [120/158]| g_loss: 0.752| d_loss: 0.573| gp_loss: 0.060| r_loss: 0.084| p_loss: 0.136| v_loss: 0.031| per_loss: 0.444 | a_loss: 0.524
Train: Epoch [1182/3000], Step [150/158]| g_loss: 0.857| d_loss: 0.587| gp_loss: 0.059| r_loss: 0.082| p_loss: 0.133| v_loss: 0.028| per_loss: 0.543 | a_loss: 0.626
Train: Epoch [1183/3000], Step [30/158]| g_loss: 0.774| d_loss: 0.736| gp_loss: 0.132| r_loss: 0.088| p_loss: 0.146| v_loss: 0.030| per_loss: 0.521 | a_loss: 0.531
Train: Epoch [1183/3000], Step [60/158]| g_loss: 0.855| d_loss: 0.485| gp_loss: 0.059| r_loss: 0.084| p_loss: 0.137| v_loss: 0.029| per_loss: 0.495 | a_loss: 0.623
Train: Epoch [1183/3000], Step [90/158]| g_loss: 0.795| d_loss: 0.609| gp_loss: 0.055| r_loss: 0.085| p_loss: 0.141| v_loss: 0.029| per_loss: 0.518 | a_loss: 0.557
Train: Epoch [1183/3000], Step [120/158]| g_loss: 0.816| d_loss: 0.538| gp_loss: 0.063| r_loss: 0.086| p_loss: 0.135| v_loss: 0.029| per_loss: 0.502 | a_loss: 0.583
Train: Epoch [1183/3000], Step [150/158]| g_loss: 0.832| d_loss: 0.586| gp_loss: 0.059| r_loss: 0.088| p_loss: 0.141| v_loss: 0.030| per_loss: 0.493 | a_loss: 0.594
Train: Epoch [1184/3000], Step [30/158]| g_loss: 0.800| d_loss: 0.724| gp_loss: 0.205| r_loss: 0.084| p_loss: 0.136| v_loss: 0.029| per_loss: 0.492 | a_loss: 0.570
Train: Epoch [1184/3000], Step [60/158]| g_loss: 0.743| d_loss: 0.576| gp_loss: 0.053| r_loss: 0.085| p_loss: 0.129| v_loss: 0.030| per_loss: 0.539 | a_loss: 0.510
Train: Epoch [1184/3000], Step [90/158]| g_loss: 0.753| d_loss: 0.641| gp_loss: 0.056| r_loss: 0.086| p_loss: 0.138| v_loss: 0.029| per_loss: 0.484 | a_loss: 0.520
Train: Epoch [1184/3000], Step [120/158]| g_loss: 0.820| d_loss: 0.525| gp_loss: 0.059| r_loss: 0.084| p_loss: 0.136| v_loss: 0.029| per_loss: 0.466 | a_loss: 0.593
Train: Epoch [1184/3000], Step [150/158]| g_loss: 0.865| d_loss: 0.499| gp_loss: 0.060| r_loss: 0.087| p_loss: 0.138| v_loss: 0.030| per_loss: 0.502 | a_loss: 0.629
Train: Epoch [1185/3000], Step [30/158]| g_loss: 0.814| d_loss: 0.656| gp_loss: 0.165| r_loss: 0.087| p_loss: 0.143| v_loss: 0.030| per_loss: 0.498 | a_loss: 0.576
Train: Epoch [1185/3000], Step [60/158]| g_loss: 0.802| d_loss: 0.619| gp_loss: 0.051| r_loss: 0.085| p_loss: 0.136| v_loss: 0.030| per_loss: 0.490 | a_loss: 0.569
Train: Epoch [1185/3000], Step [90/158]| g_loss: 0.743| d_loss: 0.589| gp_loss: 0.058| r_loss: 0.086| p_loss: 0.133| v_loss: 0.030| per_loss: 0.518 | a_loss: 0.508
Train: Epoch [1185/3000], Step [120/158]| g_loss: 0.859| d_loss: 0.557| gp_loss: 0.055| r_loss: 0.086| p_loss: 0.144| v_loss: 0.031| per_loss: 0.496 | a_loss: 0.620
Train: Epoch [1185/3000], Step [150/158]| g_loss: 0.769| d_loss: 0.609| gp_loss: 0.061| r_loss: 0.088| p_loss: 0.140| v_loss: 0.029| per_loss: 0.514 | a_loss: 0.531
Train: Epoch [1186/3000], Step [30/158]| g_loss: 0.871| d_loss: 0.573| gp_loss: 0.144| r_loss: 0.087| p_loss: 0.140| v_loss: 0.030| per_loss: 0.506 | a_loss: 0.633
Train: Epoch [1186/3000], Step [60/158]| g_loss: 0.813| d_loss: 0.514| gp_loss: 0.053| r_loss: 0.083| p_loss: 0.131| v_loss: 0.029| per_loss: 0.512 | a_loss: 0.585
Train: Epoch [1186/3000], Step [90/158]| g_loss: 0.819| d_loss: 0.569| gp_loss: 0.055| r_loss: 0.084| p_loss: 0.135| v_loss: 0.030| per_loss: 0.533 | a_loss: 0.585
Train: Epoch [1186/3000], Step [120/158]| g_loss: 0.718| d_loss: 0.676| gp_loss: 0.054| r_loss: 0.087| p_loss: 0.133| v_loss: 0.029| per_loss: 0.456 | a_loss: 0.489
Train: Epoch [1186/3000], Step [150/158]| g_loss: 0.731| d_loss: 0.662| gp_loss: 0.057| r_loss: 0.087| p_loss: 0.141| v_loss: 0.029| per_loss: 0.490 | a_loss: 0.495
Train: Epoch [1187/3000], Step [30/158]| g_loss: 0.802| d_loss: 0.640| gp_loss: 0.129| r_loss: 0.086| p_loss: 0.142| v_loss: 0.031| per_loss: 0.492 | a_loss: 0.565
Train: Epoch [1187/3000], Step [60/158]| g_loss: 0.776| d_loss: 0.595| gp_loss: 0.051| r_loss: 0.083| p_loss: 0.129| v_loss: 0.029| per_loss: 0.476 | a_loss: 0.553
Train: Epoch [1187/3000], Step [90/158]| g_loss: 0.790| d_loss: 0.533| gp_loss: 0.060| r_loss: 0.084| p_loss: 0.132| v_loss: 0.029| per_loss: 0.516 | a_loss: 0.559
Train: Epoch [1187/3000], Step [120/158]| g_loss: 0.828| d_loss: 0.532| gp_loss: 0.059| r_loss: 0.083| p_loss: 0.131| v_loss: 0.029| per_loss: 0.481 | a_loss: 0.602
Train: Epoch [1187/3000], Step [150/158]| g_loss: 0.733| d_loss: 0.653| gp_loss: 0.061| r_loss: 0.085| p_loss: 0.132| v_loss: 0.030| per_loss: 0.493 | a_loss: 0.503
Train: Epoch [1188/3000], Step [30/158]| g_loss: 0.710| d_loss: 0.746| gp_loss: 0.134| r_loss: 0.080| p_loss: 0.129| v_loss: 0.029| per_loss: 0.505 | a_loss: 0.486
Train: Epoch [1188/3000], Step [60/158]| g_loss: 0.776| d_loss: 0.612| gp_loss: 0.059| r_loss: 0.087| p_loss: 0.135| v_loss: 0.030| per_loss: 0.487 | a_loss: 0.543
Train: Epoch [1188/3000], Step [90/158]| g_loss: 0.825| d_loss: 0.470| gp_loss: 0.060| r_loss: 0.079| p_loss: 0.127| v_loss: 0.029| per_loss: 0.499 | a_loss: 0.604
Train: Epoch [1188/3000], Step [120/158]| g_loss: 0.838| d_loss: 0.526| gp_loss: 0.062| r_loss: 0.084| p_loss: 0.134| v_loss: 0.029| per_loss: 0.531 | a_loss: 0.605
Train: Epoch [1188/3000], Step [150/158]| g_loss: 0.706| d_loss: 0.663| gp_loss: 0.062| r_loss: 0.083| p_loss: 0.129| v_loss: 0.028| per_loss: 0.471 | a_loss: 0.484
Train: Epoch [1189/3000], Step [30/158]| g_loss: 0.808| d_loss: 0.658| gp_loss: 0.157| r_loss: 0.088| p_loss: 0.134| v_loss: 0.028| per_loss: 0.498 | a_loss: 0.575
Train: Epoch [1189/3000], Step [60/158]| g_loss: 0.816| d_loss: 0.540| gp_loss: 0.061| r_loss: 0.084| p_loss: 0.137| v_loss: 0.030| per_loss: 0.529 | a_loss: 0.581
Train: Epoch [1189/3000], Step [90/158]| g_loss: 0.786| d_loss: 0.616| gp_loss: 0.059| r_loss: 0.088| p_loss: 0.137| v_loss: 0.028| per_loss: 0.518 | a_loss: 0.550
Train: Epoch [1189/3000], Step [120/158]| g_loss: 0.769| d_loss: 0.626| gp_loss: 0.064| r_loss: 0.081| p_loss: 0.130| v_loss: 0.029| per_loss: 0.476 | a_loss: 0.546
Train: Epoch [1189/3000], Step [150/158]| g_loss: 0.770| d_loss: 0.578| gp_loss: 0.061| r_loss: 0.084| p_loss: 0.131| v_loss: 0.029| per_loss: 0.481 | a_loss: 0.544
Train: Epoch [1190/3000], Step [30/158]| g_loss: 0.805| d_loss: 0.643| gp_loss: 0.145| r_loss: 0.082| p_loss: 0.131| v_loss: 0.028| per_loss: 0.550 | a_loss: 0.575
Train: Epoch [1190/3000], Step [60/158]| g_loss: 0.762| d_loss: 0.568| gp_loss: 0.058| r_loss: 0.079| p_loss: 0.125| v_loss: 0.029| per_loss: 0.534 | a_loss: 0.538
Train: Epoch [1190/3000], Step [90/158]| g_loss: 0.780| d_loss: 0.597| gp_loss: 0.058| r_loss: 0.082| p_loss: 0.133| v_loss: 0.028| per_loss: 0.508 | a_loss: 0.553
Train: Epoch [1190/3000], Step [120/158]| g_loss: 0.805| d_loss: 0.588| gp_loss: 0.066| r_loss: 0.090| p_loss: 0.143| v_loss: 0.030| per_loss: 0.493 | a_loss: 0.564
Train: Epoch [1190/3000], Step [150/158]| g_loss: 0.864| d_loss: 0.516| gp_loss: 0.063| r_loss: 0.087| p_loss: 0.142| v_loss: 0.030| per_loss: 0.467 | a_loss: 0.629
Train: Epoch [1191/3000], Step [30/158]| g_loss: 0.759| d_loss: 0.761| gp_loss: 0.229| r_loss: 0.087| p_loss: 0.142| v_loss: 0.030| per_loss: 0.532 | a_loss: 0.518
Train: Epoch [1191/3000], Step [60/158]| g_loss: 0.858| d_loss: 0.509| gp_loss: 0.063| r_loss: 0.086| p_loss: 0.136| v_loss: 0.030| per_loss: 0.515 | a_loss: 0.623
Train: Epoch [1191/3000], Step [90/158]| g_loss: 0.771| d_loss: 0.634| gp_loss: 0.060| r_loss: 0.090| p_loss: 0.140| v_loss: 0.030| per_loss: 0.509 | a_loss: 0.529
Train: Epoch [1191/3000], Step [120/158]| g_loss: 0.811| d_loss: 0.544| gp_loss: 0.066| r_loss: 0.089| p_loss: 0.144| v_loss: 0.029| per_loss: 0.505 | a_loss: 0.570
Train: Epoch [1191/3000], Step [150/158]| g_loss: 0.788| d_loss: 0.627| gp_loss: 0.064| r_loss: 0.091| p_loss: 0.151| v_loss: 0.029| per_loss: 0.492 | a_loss: 0.543
Train: Epoch [1192/3000], Step [30/158]| g_loss: 0.831| d_loss: 0.711| gp_loss: 0.191| r_loss: 0.094| p_loss: 0.153| v_loss: 0.029| per_loss: 0.532 | a_loss: 0.578
Train: Epoch [1192/3000], Step [60/158]| g_loss: 0.758| d_loss: 0.585| gp_loss: 0.059| r_loss: 0.091| p_loss: 0.142| v_loss: 0.031| per_loss: 0.522 | a_loss: 0.513
Train: Epoch [1192/3000], Step [90/158]| g_loss: 0.812| d_loss: 0.602| gp_loss: 0.059| r_loss: 0.086| p_loss: 0.136| v_loss: 0.030| per_loss: 0.536 | a_loss: 0.575
Train: Epoch [1192/3000], Step [120/158]| g_loss: 0.793| d_loss: 0.621| gp_loss: 0.059| r_loss: 0.086| p_loss: 0.138| v_loss: 0.029| per_loss: 0.505 | a_loss: 0.558
Train: Epoch [1192/3000], Step [150/158]| g_loss: 0.837| d_loss: 0.494| gp_loss: 0.061| r_loss: 0.086| p_loss: 0.133| v_loss: 0.029| per_loss: 0.524 | a_loss: 0.603
Train: Epoch [1193/3000], Step [30/158]| g_loss: 0.769| d_loss: 0.713| gp_loss: 0.153| r_loss: 0.085| p_loss: 0.134| v_loss: 0.030| per_loss: 0.495 | a_loss: 0.538
Train: Epoch [1193/3000], Step [60/158]| g_loss: 0.826| d_loss: 0.527| gp_loss: 0.055| r_loss: 0.084| p_loss: 0.126| v_loss: 0.029| per_loss: 0.554 | a_loss: 0.595
Train: Epoch [1193/3000], Step [90/158]| g_loss: 0.794| d_loss: 0.587| gp_loss: 0.060| r_loss: 0.086| p_loss: 0.133| v_loss: 0.030| per_loss: 0.511 | a_loss: 0.561
Train: Epoch [1193/3000], Step [120/158]| g_loss: 0.755| d_loss: 0.634| gp_loss: 0.055| r_loss: 0.087| p_loss: 0.141| v_loss: 0.029| per_loss: 0.507 | a_loss: 0.518
Train: Epoch [1193/3000], Step [150/158]| g_loss: 0.814| d_loss: 0.548| gp_loss: 0.059| r_loss: 0.087| p_loss: 0.142| v_loss: 0.029| per_loss: 0.514 | a_loss: 0.575
Train: Epoch [1194/3000], Step [30/158]| g_loss: 0.745| d_loss: 0.704| gp_loss: 0.123| r_loss: 0.091| p_loss: 0.142| v_loss: 0.029| per_loss: 0.503 | a_loss: 0.503
Train: Epoch [1194/3000], Step [60/158]| g_loss: 0.865| d_loss: 0.533| gp_loss: 0.060| r_loss: 0.089| p_loss: 0.140| v_loss: 0.029| per_loss: 0.522 | a_loss: 0.625
Train: Epoch [1194/3000], Step [90/158]| g_loss: 0.827| d_loss: 0.531| gp_loss: 0.061| r_loss: 0.088| p_loss: 0.136| v_loss: 0.029| per_loss: 0.527 | a_loss: 0.590
Train: Epoch [1194/3000], Step [120/158]| g_loss: 0.807| d_loss: 0.529| gp_loss: 0.057| r_loss: 0.086| p_loss: 0.144| v_loss: 0.030| per_loss: 0.494 | a_loss: 0.569
Train: Epoch [1194/3000], Step [150/158]| g_loss: 0.811| d_loss: 0.617| gp_loss: 0.063| r_loss: 0.088| p_loss: 0.142| v_loss: 0.029| per_loss: 0.516 | a_loss: 0.571
Train: Epoch [1195/3000], Step [30/158]| g_loss: 0.821| d_loss: 0.600| gp_loss: 0.156| r_loss: 0.088| p_loss: 0.135| v_loss: 0.030| per_loss: 0.469 | a_loss: 0.589
Train: Epoch [1195/3000], Step [60/158]| g_loss: 0.752| d_loss: 0.619| gp_loss: 0.056| r_loss: 0.086| p_loss: 0.136| v_loss: 0.028| per_loss: 0.509 | a_loss: 0.519
Train: Epoch [1195/3000], Step [90/158]| g_loss: 0.841| d_loss: 0.501| gp_loss: 0.059| r_loss: 0.085| p_loss: 0.138| v_loss: 0.029| per_loss: 0.500 | a_loss: 0.608
Train: Epoch [1195/3000], Step [120/158]| g_loss: 0.779| d_loss: 0.619| gp_loss: 0.059| r_loss: 0.088| p_loss: 0.134| v_loss: 0.027| per_loss: 0.499 | a_loss: 0.546
Train: Epoch [1195/3000], Step [150/158]| g_loss: 0.732| d_loss: 0.658| gp_loss: 0.061| r_loss: 0.084| p_loss: 0.136| v_loss: 0.028| per_loss: 0.497 | a_loss: 0.502
Train: Epoch [1196/3000], Step [30/158]| g_loss: 0.847| d_loss: 0.604| gp_loss: 0.155| r_loss: 0.084| p_loss: 0.133| v_loss: 0.029| per_loss: 0.518 | a_loss: 0.616
Train: Epoch [1196/3000], Step [60/158]| g_loss: 0.812| d_loss: 0.594| gp_loss: 0.056| r_loss: 0.088| p_loss: 0.137| v_loss: 0.027| per_loss: 0.506 | a_loss: 0.578
Train: Epoch [1196/3000], Step [90/158]| g_loss: 0.750| d_loss: 0.636| gp_loss: 0.059| r_loss: 0.086| p_loss: 0.144| v_loss: 0.029| per_loss: 0.486 | a_loss: 0.515
Train: Epoch [1196/3000], Step [120/158]| g_loss: 0.743| d_loss: 0.665| gp_loss: 0.061| r_loss: 0.090| p_loss: 0.144| v_loss: 0.029| per_loss: 0.504 | a_loss: 0.502
Train: Epoch [1196/3000], Step [150/158]| g_loss: 0.856| d_loss: 0.509| gp_loss: 0.060| r_loss: 0.090| p_loss: 0.144| v_loss: 0.031| per_loss: 0.577 | a_loss: 0.606
Train: Epoch [1197/3000], Step [30/158]| g_loss: 0.764| d_loss: 0.740| gp_loss: 0.160| r_loss: 0.087| p_loss: 0.143| v_loss: 0.028| per_loss: 0.502 | a_loss: 0.526
Train: Epoch [1197/3000], Step [60/158]| g_loss: 0.860| d_loss: 0.514| gp_loss: 0.057| r_loss: 0.086| p_loss: 0.142| v_loss: 0.029| per_loss: 0.529 | a_loss: 0.621
Train: Epoch [1197/3000], Step [90/158]| g_loss: 0.772| d_loss: 0.604| gp_loss: 0.057| r_loss: 0.084| p_loss: 0.135| v_loss: 0.029| per_loss: 0.546 | a_loss: 0.538
Train: Epoch [1197/3000], Step [120/158]| g_loss: 0.790| d_loss: 0.632| gp_loss: 0.060| r_loss: 0.085| p_loss: 0.139| v_loss: 0.028| per_loss: 0.503 | a_loss: 0.557
Train: Epoch [1197/3000], Step [150/158]| g_loss: 0.804| d_loss: 0.558| gp_loss: 0.062| r_loss: 0.085| p_loss: 0.134| v_loss: 0.029| per_loss: 0.516 | a_loss: 0.571
Train: Epoch [1198/3000], Step [30/158]| g_loss: 0.812| d_loss: 0.657| gp_loss: 0.168| r_loss: 0.083| p_loss: 0.134| v_loss: 0.028| per_loss: 0.480 | a_loss: 0.585
Train: Epoch [1198/3000], Step [60/158]| g_loss: 0.837| d_loss: 0.502| gp_loss: 0.057| r_loss: 0.087| p_loss: 0.132| v_loss: 0.028| per_loss: 0.499 | a_loss: 0.606
Train: Epoch [1198/3000], Step [90/158]| g_loss: 0.794| d_loss: 0.604| gp_loss: 0.057| r_loss: 0.087| p_loss: 0.134| v_loss: 0.029| per_loss: 0.550 | a_loss: 0.556
Train: Epoch [1198/3000], Step [120/158]| g_loss: 0.818| d_loss: 0.604| gp_loss: 0.060| r_loss: 0.087| p_loss: 0.138| v_loss: 0.029| per_loss: 0.510 | a_loss: 0.583
Train: Epoch [1198/3000], Step [150/158]| g_loss: 0.764| d_loss: 0.590| gp_loss: 0.064| r_loss: 0.084| p_loss: 0.133| v_loss: 0.029| per_loss: 0.504 | a_loss: 0.535
Train: Epoch [1199/3000], Step [30/158]| g_loss: 0.783| d_loss: 0.646| gp_loss: 0.137| r_loss: 0.082| p_loss: 0.132| v_loss: 0.028| per_loss: 0.508 | a_loss: 0.556
Train: Epoch [1199/3000], Step [60/158]| g_loss: 0.775| d_loss: 0.625| gp_loss: 0.059| r_loss: 0.087| p_loss: 0.142| v_loss: 0.029| per_loss: 0.491 | a_loss: 0.539
Train: Epoch [1199/3000], Step [90/158]| g_loss: 0.860| d_loss: 0.550| gp_loss: 0.057| r_loss: 0.087| p_loss: 0.136| v_loss: 0.030| per_loss: 0.509 | a_loss: 0.624
Train: Epoch [1199/3000], Step [120/158]| g_loss: 0.756| d_loss: 0.563| gp_loss: 0.062| r_loss: 0.083| p_loss: 0.133| v_loss: 0.029| per_loss: 0.477 | a_loss: 0.530
Train: Epoch [1199/3000], Step [150/158]| g_loss: 0.791| d_loss: 0.617| gp_loss: 0.059| r_loss: 0.084| p_loss: 0.138| v_loss: 0.029| per_loss: 0.505 | a_loss: 0.558
Train: Epoch [1200/3000], Step [30/158]| g_loss: 0.790| d_loss: 0.685| gp_loss: 0.171| r_loss: 0.087| p_loss: 0.143| v_loss: 0.030| per_loss: 0.498 | a_loss: 0.551
Train: Epoch [1200/3000], Step [60/158]| g_loss: 0.886| d_loss: 0.590| gp_loss: 0.058| r_loss: 0.118| p_loss: 0.228| v_loss: 0.031| per_loss: 0.545 | a_loss: 0.568
Train: Epoch [1200/3000], Step [90/158]| g_loss: 0.838| d_loss: 0.572| gp_loss: 0.056| r_loss: 0.110| p_loss: 0.193| v_loss: 0.029| per_loss: 0.501 | a_loss: 0.552
Train: Epoch [1200/3000], Step [120/158]| g_loss: 0.769| d_loss: 0.572| gp_loss: 0.063| r_loss: 0.088| p_loss: 0.148| v_loss: 0.029| per_loss: 0.496 | a_loss: 0.529
Train: Epoch [1200/3000], Step [150/158]| g_loss: 0.833| d_loss: 0.499| gp_loss: 0.064| r_loss: 0.092| p_loss: 0.147| v_loss: 0.030| per_loss: 0.487 | a_loss: 0.589
Test: Epoch [1200/3000]| g_loss: 0.648| r_loss: 0.398| p_loss: 0.291| v_loss: 0.024
Train: Epoch [1201/3000], Step [30/158]| g_loss: 0.821| d_loss: 0.566| gp_loss: 0.064| r_loss: 0.083| p_loss: 0.142| v_loss: 0.030| per_loss: 0.510 | a_loss: 0.586
Train: Epoch [1201/3000], Step [60/158]| g_loss: 0.852| d_loss: 0.528| gp_loss: 0.061| r_loss: 0.088| p_loss: 0.147| v_loss: 0.029| per_loss: 0.494 | a_loss: 0.612
Train: Epoch [1201/3000], Step [90/158]| g_loss: 0.808| d_loss: 0.570| gp_loss: 0.061| r_loss: 0.088| p_loss: 0.140| v_loss: 0.030| per_loss: 0.467 | a_loss: 0.574
Train: Epoch [1201/3000], Step [120/158]| g_loss: 0.744| d_loss: 0.644| gp_loss: 0.061| r_loss: 0.087| p_loss: 0.140| v_loss: 0.028| per_loss: 0.501 | a_loss: 0.508
Train: Epoch [1201/3000], Step [150/158]| g_loss: 0.804| d_loss: 0.612| gp_loss: 0.060| r_loss: 0.083| p_loss: 0.136| v_loss: 0.029| per_loss: 0.543 | a_loss: 0.570
Train: Epoch [1202/3000], Step [30/158]| g_loss: 0.808| d_loss: 0.667| gp_loss: 0.161| r_loss: 0.085| p_loss: 0.141| v_loss: 0.030| per_loss: 0.464 | a_loss: 0.577
Train: Epoch [1202/3000], Step [60/158]| g_loss: 0.760| d_loss: 0.587| gp_loss: 0.057| r_loss: 0.084| p_loss: 0.123| v_loss: 0.029| per_loss: 0.531 | a_loss: 0.533
Train: Epoch [1202/3000], Step [90/158]| g_loss: 0.844| d_loss: 0.526| gp_loss: 0.057| r_loss: 0.081| p_loss: 0.131| v_loss: 0.028| per_loss: 0.485 | a_loss: 0.621
Train: Epoch [1202/3000], Step [120/158]| g_loss: 0.798| d_loss: 0.535| gp_loss: 0.056| r_loss: 0.083| p_loss: 0.128| v_loss: 0.029| per_loss: 0.542 | a_loss: 0.567
Train: Epoch [1202/3000], Step [150/158]| g_loss: 0.786| d_loss: 0.590| gp_loss: 0.062| r_loss: 0.084| p_loss: 0.130| v_loss: 0.029| per_loss: 0.515 | a_loss: 0.557
Train: Epoch [1203/3000], Step [30/158]| g_loss: 0.727| d_loss: 0.772| gp_loss: 0.189| r_loss: 0.084| p_loss: 0.136| v_loss: 0.028| per_loss: 0.477 | a_loss: 0.499
Train: Epoch [1203/3000], Step [60/158]| g_loss: 0.787| d_loss: 0.515| gp_loss: 0.057| r_loss: 0.083| p_loss: 0.135| v_loss: 0.029| per_loss: 0.481 | a_loss: 0.559
Train: Epoch [1203/3000], Step [90/158]| g_loss: 0.841| d_loss: 0.539| gp_loss: 0.059| r_loss: 0.083| p_loss: 0.132| v_loss: 0.029| per_loss: 0.534 | a_loss: 0.609
Train: Epoch [1203/3000], Step [120/158]| g_loss: 0.779| d_loss: 0.646| gp_loss: 0.059| r_loss: 0.085| p_loss: 0.143| v_loss: 0.031| per_loss: 0.528 | a_loss: 0.539
Train: Epoch [1203/3000], Step [150/158]| g_loss: 0.806| d_loss: 0.629| gp_loss: 0.060| r_loss: 0.087| p_loss: 0.139| v_loss: 0.029| per_loss: 0.488 | a_loss: 0.572
Train: Epoch [1204/3000], Step [30/158]| g_loss: 0.748| d_loss: 0.725| gp_loss: 0.115| r_loss: 0.086| p_loss: 0.133| v_loss: 0.029| per_loss: 0.518 | a_loss: 0.514
Train: Epoch [1204/3000], Step [60/158]| g_loss: 0.812| d_loss: 0.548| gp_loss: 0.059| r_loss: 0.083| p_loss: 0.134| v_loss: 0.029| per_loss: 0.489 | a_loss: 0.584
Train: Epoch [1204/3000], Step [90/158]| g_loss: 0.760| d_loss: 0.637| gp_loss: 0.062| r_loss: 0.083| p_loss: 0.135| v_loss: 0.029| per_loss: 0.509 | a_loss: 0.530
Train: Epoch [1204/3000], Step [120/158]| g_loss: 0.754| d_loss: 0.681| gp_loss: 0.059| r_loss: 0.083| p_loss: 0.134| v_loss: 0.029| per_loss: 0.497 | a_loss: 0.524
Train: Epoch [1204/3000], Step [150/158]| g_loss: 0.865| d_loss: 0.518| gp_loss: 0.062| r_loss: 0.085| p_loss: 0.136| v_loss: 0.030| per_loss: 0.486 | a_loss: 0.634
Train: Epoch [1205/3000], Step [30/158]| g_loss: 0.788| d_loss: 0.690| gp_loss: 0.136| r_loss: 0.088| p_loss: 0.146| v_loss: 0.030| per_loss: 0.512 | a_loss: 0.547
Train: Epoch [1205/3000], Step [60/158]| g_loss: 0.800| d_loss: 0.558| gp_loss: 0.055| r_loss: 0.082| p_loss: 0.133| v_loss: 0.030| per_loss: 0.509 | a_loss: 0.572
Train: Epoch [1205/3000], Step [90/158]| g_loss: 0.775| d_loss: 0.558| gp_loss: 0.062| r_loss: 0.084| p_loss: 0.128| v_loss: 0.028| per_loss: 0.523 | a_loss: 0.547
Train: Epoch [1205/3000], Step [120/158]| g_loss: 0.874| d_loss: 0.484| gp_loss: 0.056| r_loss: 0.084| p_loss: 0.128| v_loss: 0.029| per_loss: 0.486 | a_loss: 0.648
Train: Epoch [1205/3000], Step [150/158]| g_loss: 0.775| d_loss: 0.631| gp_loss: 0.059| r_loss: 0.084| p_loss: 0.133| v_loss: 0.030| per_loss: 0.481 | a_loss: 0.547
Train: Epoch [1206/3000], Step [30/158]| g_loss: 0.713| d_loss: 0.725| gp_loss: 0.152| r_loss: 0.082| p_loss: 0.130| v_loss: 0.029| per_loss: 0.505 | a_loss: 0.486
Train: Epoch [1206/3000], Step [60/158]| g_loss: 0.804| d_loss: 0.605| gp_loss: 0.056| r_loss: 0.081| p_loss: 0.128| v_loss: 0.028| per_loss: 0.494 | a_loss: 0.581
Train: Epoch [1206/3000], Step [90/158]| g_loss: 0.723| d_loss: 0.615| gp_loss: 0.061| r_loss: 0.082| p_loss: 0.131| v_loss: 0.028| per_loss: 0.490 | a_loss: 0.498
Train: Epoch [1206/3000], Step [120/158]| g_loss: 0.836| d_loss: 0.490| gp_loss: 0.059| r_loss: 0.082| p_loss: 0.125| v_loss: 0.030| per_loss: 0.505 | a_loss: 0.611
Train: Epoch [1206/3000], Step [150/158]| g_loss: 0.813| d_loss: 0.586| gp_loss: 0.059| r_loss: 0.083| p_loss: 0.126| v_loss: 0.028| per_loss: 0.500 | a_loss: 0.589
Train: Epoch [1207/3000], Step [30/158]| g_loss: 0.716| d_loss: 0.778| gp_loss: 0.212| r_loss: 0.082| p_loss: 0.125| v_loss: 0.029| per_loss: 0.500 | a_loss: 0.492
Train: Epoch [1207/3000], Step [60/158]| g_loss: 0.770| d_loss: 0.584| gp_loss: 0.056| r_loss: 0.082| p_loss: 0.126| v_loss: 0.029| per_loss: 0.502 | a_loss: 0.545
Train: Epoch [1207/3000], Step [90/158]| g_loss: 0.786| d_loss: 0.618| gp_loss: 0.056| r_loss: 0.083| p_loss: 0.131| v_loss: 0.029| per_loss: 0.491 | a_loss: 0.559
Train: Epoch [1207/3000], Step [120/158]| g_loss: 0.774| d_loss: 0.574| gp_loss: 0.060| r_loss: 0.080| p_loss: 0.126| v_loss: 0.028| per_loss: 0.509 | a_loss: 0.552
Train: Epoch [1207/3000], Step [150/158]| g_loss: 0.858| d_loss: 0.469| gp_loss: 0.059| r_loss: 0.083| p_loss: 0.127| v_loss: 0.029| per_loss: 0.499 | a_loss: 0.633
Train: Epoch [1208/3000], Step [30/158]| g_loss: 0.746| d_loss: 0.696| gp_loss: 0.130| r_loss: 0.082| p_loss: 0.125| v_loss: 0.030| per_loss: 0.486 | a_loss: 0.523
Train: Epoch [1208/3000], Step [60/158]| g_loss: 0.761| d_loss: 0.581| gp_loss: 0.055| r_loss: 0.082| p_loss: 0.124| v_loss: 0.029| per_loss: 0.480 | a_loss: 0.540
Train: Epoch [1208/3000], Step [90/158]| g_loss: 0.806| d_loss: 0.553| gp_loss: 0.052| r_loss: 0.082| p_loss: 0.128| v_loss: 0.028| per_loss: 0.482 | a_loss: 0.584
Train: Epoch [1208/3000], Step [120/158]| g_loss: 0.811| d_loss: 0.497| gp_loss: 0.061| r_loss: 0.079| p_loss: 0.119| v_loss: 0.028| per_loss: 0.497 | a_loss: 0.595
Train: Epoch [1208/3000], Step [150/158]| g_loss: 0.801| d_loss: 0.640| gp_loss: 0.058| r_loss: 0.083| p_loss: 0.125| v_loss: 0.028| per_loss: 0.513 | a_loss: 0.576
Train: Epoch [1209/3000], Step [30/158]| g_loss: 0.730| d_loss: 0.676| gp_loss: 0.074| r_loss: 0.079| p_loss: 0.127| v_loss: 0.028| per_loss: 0.518 | a_loss: 0.507
Train: Epoch [1209/3000], Step [60/158]| g_loss: 0.810| d_loss: 0.593| gp_loss: 0.057| r_loss: 0.086| p_loss: 0.137| v_loss: 0.029| per_loss: 0.510 | a_loss: 0.576
Train: Epoch [1209/3000], Step [90/158]| g_loss: 0.739| d_loss: 0.642| gp_loss: 0.060| r_loss: 0.080| p_loss: 0.129| v_loss: 0.028| per_loss: 0.500 | a_loss: 0.516
Train: Epoch [1209/3000], Step [120/158]| g_loss: 0.754| d_loss: 0.551| gp_loss: 0.061| r_loss: 0.082| p_loss: 0.130| v_loss: 0.029| per_loss: 0.485 | a_loss: 0.530
Train: Epoch [1209/3000], Step [150/158]| g_loss: 0.774| d_loss: 0.632| gp_loss: 0.064| r_loss: 0.083| p_loss: 0.130| v_loss: 0.028| per_loss: 0.468 | a_loss: 0.551
Train: Epoch [1210/3000], Step [30/158]| g_loss: 0.846| d_loss: 0.690| gp_loss: 0.222| r_loss: 0.085| p_loss: 0.134| v_loss: 0.029| per_loss: 0.497 | a_loss: 0.615
Train: Epoch [1210/3000], Step [60/158]| g_loss: 0.783| d_loss: 0.590| gp_loss: 0.056| r_loss: 0.081| p_loss: 0.130| v_loss: 0.027| per_loss: 0.505 | a_loss: 0.558
Train: Epoch [1210/3000], Step [90/158]| g_loss: 0.795| d_loss: 0.598| gp_loss: 0.059| r_loss: 0.085| p_loss: 0.134| v_loss: 0.028| per_loss: 0.508 | a_loss: 0.564
Train: Epoch [1210/3000], Step [120/158]| g_loss: 0.802| d_loss: 0.532| gp_loss: 0.060| r_loss: 0.085| p_loss: 0.130| v_loss: 0.029| per_loss: 0.508 | a_loss: 0.573
Train: Epoch [1210/3000], Step [150/158]| g_loss: 0.756| d_loss: 0.616| gp_loss: 0.062| r_loss: 0.081| p_loss: 0.128| v_loss: 0.029| per_loss: 0.489 | a_loss: 0.533
Train: Epoch [1211/3000], Step [30/158]| g_loss: 0.840| d_loss: 0.602| gp_loss: 0.151| r_loss: 0.082| p_loss: 0.128| v_loss: 0.030| per_loss: 0.509 | a_loss: 0.613
Train: Epoch [1211/3000], Step [60/158]| g_loss: 0.771| d_loss: 0.551| gp_loss: 0.058| r_loss: 0.082| p_loss: 0.133| v_loss: 0.030| per_loss: 0.538 | a_loss: 0.540
Train: Epoch [1211/3000], Step [90/158]| g_loss: 0.835| d_loss: 0.613| gp_loss: 0.055| r_loss: 0.117| p_loss: 0.184| v_loss: 0.029| per_loss: 0.505 | a_loss: 0.546
Train: Epoch [1211/3000], Step [120/158]| g_loss: 0.766| d_loss: 0.577| gp_loss: 0.063| r_loss: 0.092| p_loss: 0.149| v_loss: 0.030| per_loss: 0.545 | a_loss: 0.515
Train: Epoch [1211/3000], Step [150/158]| g_loss: 0.779| d_loss: 0.635| gp_loss: 0.062| r_loss: 0.087| p_loss: 0.139| v_loss: 0.028| per_loss: 0.481 | a_loss: 0.546
Train: Epoch [1212/3000], Step [30/158]| g_loss: 0.795| d_loss: 0.680| gp_loss: 0.205| r_loss: 0.082| p_loss: 0.129| v_loss: 0.028| per_loss: 0.514 | a_loss: 0.569
Train: Epoch [1212/3000], Step [60/158]| g_loss: 0.761| d_loss: 0.606| gp_loss: 0.055| r_loss: 0.086| p_loss: 0.141| v_loss: 0.028| per_loss: 0.565 | a_loss: 0.521
Train: Epoch [1212/3000], Step [90/158]| g_loss: 0.817| d_loss: 0.552| gp_loss: 0.058| r_loss: 0.085| p_loss: 0.138| v_loss: 0.031| per_loss: 0.516 | a_loss: 0.581
Train: Epoch [1212/3000], Step [120/158]| g_loss: 0.799| d_loss: 0.558| gp_loss: 0.057| r_loss: 0.087| p_loss: 0.132| v_loss: 0.029| per_loss: 0.494 | a_loss: 0.568
Train: Epoch [1212/3000], Step [150/158]| g_loss: 0.754| d_loss: 0.620| gp_loss: 0.061| r_loss: 0.089| p_loss: 0.135| v_loss: 0.029| per_loss: 0.501 | a_loss: 0.518
Train: Epoch [1213/3000], Step [30/158]| g_loss: 0.802| d_loss: 0.643| gp_loss: 0.157| r_loss: 0.085| p_loss: 0.131| v_loss: 0.029| per_loss: 0.551 | a_loss: 0.567
Train: Epoch [1213/3000], Step [60/158]| g_loss: 0.749| d_loss: 0.633| gp_loss: 0.058| r_loss: 0.088| p_loss: 0.140| v_loss: 0.030| per_loss: 0.472 | a_loss: 0.514
Train: Epoch [1213/3000], Step [90/158]| g_loss: 0.875| d_loss: 0.527| gp_loss: 0.064| r_loss: 0.084| p_loss: 0.132| v_loss: 0.029| per_loss: 0.519 | a_loss: 0.644
Train: Epoch [1213/3000], Step [120/158]| g_loss: 0.800| d_loss: 0.614| gp_loss: 0.058| r_loss: 0.089| p_loss: 0.141| v_loss: 0.029| per_loss: 0.495 | a_loss: 0.562
Train: Epoch [1213/3000], Step [150/158]| g_loss: 0.764| d_loss: 0.534| gp_loss: 0.061| r_loss: 0.086| p_loss: 0.135| v_loss: 0.030| per_loss: 0.518 | a_loss: 0.529
Train: Epoch [1214/3000], Step [30/158]| g_loss: 0.808| d_loss: 0.683| gp_loss: 0.186| r_loss: 0.084| p_loss: 0.132| v_loss: 0.029| per_loss: 0.511 | a_loss: 0.578
Train: Epoch [1214/3000], Step [60/158]| g_loss: 0.849| d_loss: 0.524| gp_loss: 0.059| r_loss: 0.092| p_loss: 0.143| v_loss: 0.030| per_loss: 0.542 | a_loss: 0.601
Train: Epoch [1214/3000], Step [90/158]| g_loss: 0.810| d_loss: 0.536| gp_loss: 0.058| r_loss: 0.083| p_loss: 0.133| v_loss: 0.030| per_loss: 0.492 | a_loss: 0.580
Train: Epoch [1214/3000], Step [120/158]| g_loss: 0.809| d_loss: 0.590| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.132| v_loss: 0.029| per_loss: 0.541 | a_loss: 0.575
Train: Epoch [1214/3000], Step [150/158]| g_loss: 0.800| d_loss: 0.603| gp_loss: 0.059| r_loss: 0.091| p_loss: 0.144| v_loss: 0.031| per_loss: 0.495 | a_loss: 0.556
Train: Epoch [1215/3000], Step [30/158]| g_loss: 0.761| d_loss: 0.692| gp_loss: 0.110| r_loss: 0.088| p_loss: 0.151| v_loss: 0.030| per_loss: 0.500 | a_loss: 0.517
Train: Epoch [1215/3000], Step [60/158]| g_loss: 0.786| d_loss: 0.645| gp_loss: 0.063| r_loss: 0.090| p_loss: 0.145| v_loss: 0.030| per_loss: 0.512 | a_loss: 0.543
Train: Epoch [1215/3000], Step [90/158]| g_loss: 0.749| d_loss: 0.642| gp_loss: 0.061| r_loss: 0.086| p_loss: 0.139| v_loss: 0.028| per_loss: 0.520 | a_loss: 0.514
Train: Epoch [1215/3000], Step [120/158]| g_loss: 0.818| d_loss: 0.576| gp_loss: 0.061| r_loss: 0.085| p_loss: 0.139| v_loss: 0.030| per_loss: 0.527 | a_loss: 0.581
Train: Epoch [1215/3000], Step [150/158]| g_loss: 0.878| d_loss: 0.496| gp_loss: 0.060| r_loss: 0.088| p_loss: 0.144| v_loss: 0.029| per_loss: 0.518 | a_loss: 0.637
Train: Epoch [1216/3000], Step [30/158]| g_loss: 0.800| d_loss: 0.680| gp_loss: 0.157| r_loss: 0.088| p_loss: 0.136| v_loss: 0.030| per_loss: 0.504 | a_loss: 0.564
Train: Epoch [1216/3000], Step [60/158]| g_loss: 0.803| d_loss: 0.555| gp_loss: 0.057| r_loss: 0.086| p_loss: 0.137| v_loss: 0.030| per_loss: 0.459 | a_loss: 0.572
Train: Epoch [1216/3000], Step [90/158]| g_loss: 0.858| d_loss: 0.551| gp_loss: 0.053| r_loss: 0.086| p_loss: 0.136| v_loss: 0.030| per_loss: 0.500 | a_loss: 0.624
Train: Epoch [1216/3000], Step [120/158]| g_loss: 0.769| d_loss: 0.592| gp_loss: 0.061| r_loss: 0.087| p_loss: 0.133| v_loss: 0.030| per_loss: 0.491 | a_loss: 0.537
Train: Epoch [1216/3000], Step [150/158]| g_loss: 0.809| d_loss: 0.571| gp_loss: 0.062| r_loss: 0.086| p_loss: 0.134| v_loss: 0.031| per_loss: 0.537 | a_loss: 0.571
Train: Epoch [1217/3000], Step [30/158]| g_loss: 0.700| d_loss: 0.765| gp_loss: 0.132| r_loss: 0.087| p_loss: 0.139| v_loss: 0.030| per_loss: 0.518 | a_loss: 0.462
Train: Epoch [1217/3000], Step [60/158]| g_loss: 0.807| d_loss: 0.552| gp_loss: 0.061| r_loss: 0.087| p_loss: 0.138| v_loss: 0.031| per_loss: 0.536 | a_loss: 0.566
Train: Epoch [1217/3000], Step [90/158]| g_loss: 0.829| d_loss: 0.610| gp_loss: 0.063| r_loss: 0.091| p_loss: 0.144| v_loss: 0.029| per_loss: 0.522 | a_loss: 0.584
Train: Epoch [1217/3000], Step [120/158]| g_loss: 0.773| d_loss: 0.620| gp_loss: 0.063| r_loss: 0.090| p_loss: 0.145| v_loss: 0.029| per_loss: 0.496 | a_loss: 0.531
Train: Epoch [1217/3000], Step [150/158]| g_loss: 0.829| d_loss: 0.523| gp_loss: 0.062| r_loss: 0.088| p_loss: 0.143| v_loss: 0.030| per_loss: 0.538 | a_loss: 0.587
Train: Epoch [1218/3000], Step [30/158]| g_loss: 0.796| d_loss: 0.702| gp_loss: 0.165| r_loss: 0.088| p_loss: 0.138| v_loss: 0.030| per_loss: 0.498 | a_loss: 0.560
Train: Epoch [1218/3000], Step [60/158]| g_loss: 0.751| d_loss: 0.622| gp_loss: 0.061| r_loss: 0.086| p_loss: 0.140| v_loss: 0.029| per_loss: 0.537 | a_loss: 0.512
Train: Epoch [1218/3000], Step [90/158]| g_loss: 0.842| d_loss: 0.535| gp_loss: 0.060| r_loss: 0.083| p_loss: 0.130| v_loss: 0.030| per_loss: 0.508 | a_loss: 0.613
Train: Epoch [1218/3000], Step [120/158]| g_loss: 0.759| d_loss: 0.600| gp_loss: 0.063| r_loss: 0.091| p_loss: 0.142| v_loss: 0.031| per_loss: 0.466 | a_loss: 0.520
Train: Epoch [1218/3000], Step [150/158]| g_loss: 0.881| d_loss: 0.530| gp_loss: 0.064| r_loss: 0.087| p_loss: 0.139| v_loss: 0.031| per_loss: 0.524 | a_loss: 0.642
Train: Epoch [1219/3000], Step [30/158]| g_loss: 0.783| d_loss: 0.699| gp_loss: 0.188| r_loss: 0.085| p_loss: 0.139| v_loss: 0.030| per_loss: 0.538 | a_loss: 0.545
Train: Epoch [1219/3000], Step [60/158]| g_loss: 0.814| d_loss: 0.551| gp_loss: 0.058| r_loss: 0.085| p_loss: 0.139| v_loss: 0.030| per_loss: 0.471 | a_loss: 0.583
Train: Epoch [1219/3000], Step [90/158]| g_loss: 0.809| d_loss: 0.588| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.136| v_loss: 0.030| per_loss: 0.506 | a_loss: 0.577
Train: Epoch [1219/3000], Step [120/158]| g_loss: 0.830| d_loss: 0.557| gp_loss: 0.061| r_loss: 0.090| p_loss: 0.138| v_loss: 0.030| per_loss: 0.518 | a_loss: 0.589
Train: Epoch [1219/3000], Step [150/158]| g_loss: 0.845| d_loss: 0.578| gp_loss: 0.059| r_loss: 0.090| p_loss: 0.145| v_loss: 0.029| per_loss: 0.520 | a_loss: 0.601
Train: Epoch [1220/3000], Step [30/158]| g_loss: 0.803| d_loss: 0.672| gp_loss: 0.179| r_loss: 0.086| p_loss: 0.136| v_loss: 0.029| per_loss: 0.513 | a_loss: 0.569
Train: Epoch [1220/3000], Step [60/158]| g_loss: 0.808| d_loss: 0.553| gp_loss: 0.057| r_loss: 0.087| p_loss: 0.140| v_loss: 0.031| per_loss: 0.538 | a_loss: 0.566
Train: Epoch [1220/3000], Step [90/158]| g_loss: 0.767| d_loss: 0.669| gp_loss: 0.056| r_loss: 0.084| p_loss: 0.136| v_loss: 0.028| per_loss: 0.513 | a_loss: 0.535
Train: Epoch [1220/3000], Step [120/158]| g_loss: 0.779| d_loss: 0.523| gp_loss: 0.058| r_loss: 0.083| p_loss: 0.129| v_loss: 0.030| per_loss: 0.505 | a_loss: 0.552
Train: Epoch [1220/3000], Step [150/158]| g_loss: 0.752| d_loss: 0.670| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.126| v_loss: 0.030| per_loss: 0.471 | a_loss: 0.529
Train: Epoch [1221/3000], Step [30/158]| g_loss: 0.823| d_loss: 0.648| gp_loss: 0.148| r_loss: 0.087| p_loss: 0.136| v_loss: 0.030| per_loss: 0.491 | a_loss: 0.589
Train: Epoch [1221/3000], Step [60/158]| g_loss: 0.734| d_loss: 0.618| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.134| v_loss: 0.029| per_loss: 0.494 | a_loss: 0.505
Train: Epoch [1221/3000], Step [90/158]| g_loss: 0.828| d_loss: 0.578| gp_loss: 0.055| r_loss: 0.085| p_loss: 0.137| v_loss: 0.029| per_loss: 0.493 | a_loss: 0.596
Train: Epoch [1221/3000], Step [120/158]| g_loss: 0.782| d_loss: 0.625| gp_loss: 0.063| r_loss: 0.081| p_loss: 0.128| v_loss: 0.029| per_loss: 0.512 | a_loss: 0.556
Train: Epoch [1221/3000], Step [150/158]| g_loss: 0.795| d_loss: 0.606| gp_loss: 0.060| r_loss: 0.083| p_loss: 0.134| v_loss: 0.029| per_loss: 0.542 | a_loss: 0.562
Train: Epoch [1222/3000], Step [30/158]| g_loss: 0.782| d_loss: 0.753| gp_loss: 0.194| r_loss: 0.085| p_loss: 0.135| v_loss: 0.030| per_loss: 0.542 | a_loss: 0.546
Train: Epoch [1222/3000], Step [60/158]| g_loss: 0.778| d_loss: 0.607| gp_loss: 0.058| r_loss: 0.086| p_loss: 0.136| v_loss: 0.030| per_loss: 0.529 | a_loss: 0.541
Train: Epoch [1222/3000], Step [90/158]| g_loss: 0.879| d_loss: 0.518| gp_loss: 0.062| r_loss: 0.085| p_loss: 0.133| v_loss: 0.029| per_loss: 0.481 | a_loss: 0.650
Train: Epoch [1222/3000], Step [120/158]| g_loss: 0.776| d_loss: 0.557| gp_loss: 0.061| r_loss: 0.088| p_loss: 0.134| v_loss: 0.029| per_loss: 0.473 | a_loss: 0.545
Train: Epoch [1222/3000], Step [150/158]| g_loss: 0.793| d_loss: 0.582| gp_loss: 0.058| r_loss: 0.089| p_loss: 0.137| v_loss: 0.030| per_loss: 0.504 | a_loss: 0.556
Train: Epoch [1223/3000], Step [30/158]| g_loss: 0.847| d_loss: 0.688| gp_loss: 0.181| r_loss: 0.095| p_loss: 0.143| v_loss: 0.031| per_loss: 0.511 | a_loss: 0.598
Train: Epoch [1223/3000], Step [60/158]| g_loss: 0.770| d_loss: 0.572| gp_loss: 0.053| r_loss: 0.087| p_loss: 0.136| v_loss: 0.030| per_loss: 0.525 | a_loss: 0.532
Train: Epoch [1223/3000], Step [90/158]| g_loss: 0.766| d_loss: 0.577| gp_loss: 0.054| r_loss: 0.084| p_loss: 0.130| v_loss: 0.031| per_loss: 0.525 | a_loss: 0.533
Train: Epoch [1223/3000], Step [120/158]| g_loss: 0.763| d_loss: 0.589| gp_loss: 0.054| r_loss: 0.084| p_loss: 0.130| v_loss: 0.029| per_loss: 0.478 | a_loss: 0.537
Train: Epoch [1223/3000], Step [150/158]| g_loss: 0.785| d_loss: 0.602| gp_loss: 0.056| r_loss: 0.081| p_loss: 0.125| v_loss: 0.029| per_loss: 0.542 | a_loss: 0.559
Train: Epoch [1224/3000], Step [30/158]| g_loss: 0.807| d_loss: 0.699| gp_loss: 0.163| r_loss: 0.087| p_loss: 0.137| v_loss: 0.030| per_loss: 0.521 | a_loss: 0.569
Train: Epoch [1224/3000], Step [60/158]| g_loss: 0.778| d_loss: 0.555| gp_loss: 0.056| r_loss: 0.086| p_loss: 0.128| v_loss: 0.029| per_loss: 0.509 | a_loss: 0.547
Train: Epoch [1224/3000], Step [90/158]| g_loss: 0.858| d_loss: 0.540| gp_loss: 0.056| r_loss: 0.083| p_loss: 0.132| v_loss: 0.029| per_loss: 0.491 | a_loss: 0.631
Train: Epoch [1224/3000], Step [120/158]| g_loss: 0.756| d_loss: 0.624| gp_loss: 0.054| r_loss: 0.082| p_loss: 0.133| v_loss: 0.028| per_loss: 0.503 | a_loss: 0.529
Train: Epoch [1224/3000], Step [150/158]| g_loss: 0.822| d_loss: 0.591| gp_loss: 0.058| r_loss: 0.083| p_loss: 0.128| v_loss: 0.028| per_loss: 0.501 | a_loss: 0.597
Train: Epoch [1225/3000], Step [30/158]| g_loss: 0.797| d_loss: 0.638| gp_loss: 0.135| r_loss: 0.086| p_loss: 0.134| v_loss: 0.029| per_loss: 0.524 | a_loss: 0.562
Train: Epoch [1225/3000], Step [60/158]| g_loss: 0.751| d_loss: 0.632| gp_loss: 0.055| r_loss: 0.088| p_loss: 0.139| v_loss: 0.029| per_loss: 0.493 | a_loss: 0.516
Train: Epoch [1225/3000], Step [90/158]| g_loss: 0.782| d_loss: 0.535| gp_loss: 0.057| r_loss: 0.089| p_loss: 0.139| v_loss: 0.030| per_loss: 0.510 | a_loss: 0.544
Train: Epoch [1225/3000], Step [120/158]| g_loss: 0.804| d_loss: 0.660| gp_loss: 0.057| r_loss: 0.088| p_loss: 0.138| v_loss: 0.029| per_loss: 0.522 | a_loss: 0.566
Train: Epoch [1225/3000], Step [150/158]| g_loss: 0.776| d_loss: 0.659| gp_loss: 0.058| r_loss: 0.092| p_loss: 0.150| v_loss: 0.030| per_loss: 0.539 | a_loss: 0.526
Train: Epoch [1226/3000], Step [30/158]| g_loss: 0.852| d_loss: 0.598| gp_loss: 0.159| r_loss: 0.088| p_loss: 0.140| v_loss: 0.030| per_loss: 0.528 | a_loss: 0.612
Train: Epoch [1226/3000], Step [60/158]| g_loss: 0.805| d_loss: 0.514| gp_loss: 0.055| r_loss: 0.086| p_loss: 0.132| v_loss: 0.031| per_loss: 0.515 | a_loss: 0.571
Train: Epoch [1226/3000], Step [90/158]| g_loss: 0.791| d_loss: 0.590| gp_loss: 0.054| r_loss: 0.083| p_loss: 0.130| v_loss: 0.028| per_loss: 0.512 | a_loss: 0.564
Train: Epoch [1226/3000], Step [120/158]| g_loss: 0.823| d_loss: 0.532| gp_loss: 0.056| r_loss: 0.080| p_loss: 0.124| v_loss: 0.029| per_loss: 0.531 | a_loss: 0.599
Train: Epoch [1226/3000], Step [150/158]| g_loss: 0.751| d_loss: 0.680| gp_loss: 0.057| r_loss: 0.083| p_loss: 0.133| v_loss: 0.028| per_loss: 0.502 | a_loss: 0.524
Train: Epoch [1227/3000], Step [30/158]| g_loss: 0.760| d_loss: 0.736| gp_loss: 0.145| r_loss: 0.082| p_loss: 0.129| v_loss: 0.029| per_loss: 0.537 | a_loss: 0.531
Train: Epoch [1227/3000], Step [60/158]| g_loss: 0.791| d_loss: 0.529| gp_loss: 0.057| r_loss: 0.081| p_loss: 0.130| v_loss: 0.029| per_loss: 0.509 | a_loss: 0.565
Train: Epoch [1227/3000], Step [90/158]| g_loss: 0.820| d_loss: 0.581| gp_loss: 0.058| r_loss: 0.085| p_loss: 0.130| v_loss: 0.029| per_loss: 0.479 | a_loss: 0.592
Train: Epoch [1227/3000], Step [120/158]| g_loss: 0.760| d_loss: 0.666| gp_loss: 0.056| r_loss: 0.084| p_loss: 0.130| v_loss: 0.028| per_loss: 0.478 | a_loss: 0.534
Train: Epoch [1227/3000], Step [150/158]| g_loss: 0.803| d_loss: 0.525| gp_loss: 0.060| r_loss: 0.084| p_loss: 0.135| v_loss: 0.030| per_loss: 0.531 | a_loss: 0.568
Train: Epoch [1228/3000], Step [30/158]| g_loss: 0.805| d_loss: 0.712| gp_loss: 0.160| r_loss: 0.090| p_loss: 0.144| v_loss: 0.029| per_loss: 0.489 | a_loss: 0.565
Train: Epoch [1228/3000], Step [60/158]| g_loss: 0.832| d_loss: 0.551| gp_loss: 0.054| r_loss: 0.088| p_loss: 0.147| v_loss: 0.030| per_loss: 0.524 | a_loss: 0.588
Train: Epoch [1228/3000], Step [90/158]| g_loss: 0.792| d_loss: 0.640| gp_loss: 0.055| r_loss: 0.090| p_loss: 0.144| v_loss: 0.028| per_loss: 0.524 | a_loss: 0.549
Train: Epoch [1228/3000], Step [120/158]| g_loss: 0.822| d_loss: 0.531| gp_loss: 0.061| r_loss: 0.083| p_loss: 0.128| v_loss: 0.028| per_loss: 0.492 | a_loss: 0.598
Train: Epoch [1228/3000], Step [150/158]| g_loss: 0.734| d_loss: 0.635| gp_loss: 0.055| r_loss: 0.084| p_loss: 0.134| v_loss: 0.028| per_loss: 0.540 | a_loss: 0.500
Train: Epoch [1229/3000], Step [30/158]| g_loss: 0.803| d_loss: 0.659| gp_loss: 0.145| r_loss: 0.091| p_loss: 0.140| v_loss: 0.029| per_loss: 0.493 | a_loss: 0.563
Train: Epoch [1229/3000], Step [60/158]| g_loss: 0.777| d_loss: 0.658| gp_loss: 0.054| r_loss: 0.098| p_loss: 0.146| v_loss: 0.029| per_loss: 0.488 | a_loss: 0.529
Train: Epoch [1229/3000], Step [90/158]| g_loss: 0.819| d_loss: 0.554| gp_loss: 0.061| r_loss: 0.095| p_loss: 0.151| v_loss: 0.030| per_loss: 0.541 | a_loss: 0.564
Train: Epoch [1229/3000], Step [120/158]| g_loss: 0.808| d_loss: 0.588| gp_loss: 0.060| r_loss: 0.091| p_loss: 0.145| v_loss: 0.030| per_loss: 0.534 | a_loss: 0.561
Train: Epoch [1229/3000], Step [150/158]| g_loss: 0.859| d_loss: 0.509| gp_loss: 0.061| r_loss: 0.088| p_loss: 0.145| v_loss: 0.030| per_loss: 0.487 | a_loss: 0.620
Train: Epoch [1230/3000], Step [30/158]| g_loss: 0.783| d_loss: 0.798| gp_loss: 0.236| r_loss: 0.088| p_loss: 0.142| v_loss: 0.030| per_loss: 0.502 | a_loss: 0.543
Train: Epoch [1230/3000], Step [60/158]| g_loss: 0.798| d_loss: 0.558| gp_loss: 0.053| r_loss: 0.101| p_loss: 0.145| v_loss: 0.029| per_loss: 0.542 | a_loss: 0.541
Train: Epoch [1230/3000], Step [90/158]| g_loss: 0.802| d_loss: 0.563| gp_loss: 0.057| r_loss: 0.103| p_loss: 0.153| v_loss: 0.029| per_loss: 0.465 | a_loss: 0.547
Train: Epoch [1230/3000], Step [120/158]| g_loss: 0.780| d_loss: 0.677| gp_loss: 0.057| r_loss: 0.096| p_loss: 0.145| v_loss: 0.028| per_loss: 0.494 | a_loss: 0.534
Train: Epoch [1230/3000], Step [150/158]| g_loss: 0.859| d_loss: 0.488| gp_loss: 0.055| r_loss: 0.088| p_loss: 0.137| v_loss: 0.029| per_loss: 0.527 | a_loss: 0.621
Train: Epoch [1231/3000], Step [30/158]| g_loss: 0.771| d_loss: 0.747| gp_loss: 0.216| r_loss: 0.090| p_loss: 0.136| v_loss: 0.028| per_loss: 0.511 | a_loss: 0.534
Train: Epoch [1231/3000], Step [60/158]| g_loss: 0.750| d_loss: 0.657| gp_loss: 0.056| r_loss: 0.086| p_loss: 0.135| v_loss: 0.028| per_loss: 0.501 | a_loss: 0.518
Train: Epoch [1231/3000], Step [90/158]| g_loss: 0.815| d_loss: 0.622| gp_loss: 0.059| r_loss: 0.090| p_loss: 0.142| v_loss: 0.028| per_loss: 0.541 | a_loss: 0.572
Train: Epoch [1231/3000], Step [120/158]| g_loss: 0.775| d_loss: 0.601| gp_loss: 0.056| r_loss: 0.088| p_loss: 0.135| v_loss: 0.029| per_loss: 0.500 | a_loss: 0.541
Train: Epoch [1231/3000], Step [150/158]| g_loss: 0.785| d_loss: 0.574| gp_loss: 0.061| r_loss: 0.086| p_loss: 0.137| v_loss: 0.029| per_loss: 0.486 | a_loss: 0.553
Train: Epoch [1232/3000], Step [30/158]| g_loss: 0.770| d_loss: 0.789| gp_loss: 0.162| r_loss: 0.088| p_loss: 0.142| v_loss: 0.028| per_loss: 0.530 | a_loss: 0.529
Train: Epoch [1232/3000], Step [60/158]| g_loss: 0.794| d_loss: 0.518| gp_loss: 0.057| r_loss: 0.087| p_loss: 0.132| v_loss: 0.028| per_loss: 0.486 | a_loss: 0.564
Train: Epoch [1232/3000], Step [90/158]| g_loss: 0.743| d_loss: 0.647| gp_loss: 0.052| r_loss: 0.085| p_loss: 0.135| v_loss: 0.028| per_loss: 0.489 | a_loss: 0.514
Train: Epoch [1232/3000], Step [120/158]| g_loss: 0.803| d_loss: 0.549| gp_loss: 0.058| r_loss: 0.082| p_loss: 0.127| v_loss: 0.028| per_loss: 0.539 | a_loss: 0.575
Train: Epoch [1232/3000], Step [150/158]| g_loss: 0.863| d_loss: 0.487| gp_loss: 0.059| r_loss: 0.085| p_loss: 0.130| v_loss: 0.029| per_loss: 0.517 | a_loss: 0.633
Train: Epoch [1233/3000], Step [30/158]| g_loss: 0.781| d_loss: 0.675| gp_loss: 0.158| r_loss: 0.085| p_loss: 0.127| v_loss: 0.028| per_loss: 0.515 | a_loss: 0.554
Train: Epoch [1233/3000], Step [60/158]| g_loss: 0.753| d_loss: 0.614| gp_loss: 0.053| r_loss: 0.082| p_loss: 0.127| v_loss: 0.029| per_loss: 0.492 | a_loss: 0.529
Train: Epoch [1233/3000], Step [90/158]| g_loss: 0.853| d_loss: 0.547| gp_loss: 0.057| r_loss: 0.086| p_loss: 0.134| v_loss: 0.030| per_loss: 0.508 | a_loss: 0.619
Train: Epoch [1233/3000], Step [120/158]| g_loss: 0.754| d_loss: 0.568| gp_loss: 0.057| r_loss: 0.080| p_loss: 0.124| v_loss: 0.028| per_loss: 0.487 | a_loss: 0.535
Train: Epoch [1233/3000], Step [150/158]| g_loss: 0.778| d_loss: 0.594| gp_loss: 0.061| r_loss: 0.082| p_loss: 0.128| v_loss: 0.028| per_loss: 0.489 | a_loss: 0.556
Train: Epoch [1234/3000], Step [30/158]| g_loss: 0.793| d_loss: 0.702| gp_loss: 0.151| r_loss: 0.083| p_loss: 0.132| v_loss: 0.028| per_loss: 0.490 | a_loss: 0.568
Train: Epoch [1234/3000], Step [60/158]| g_loss: 0.744| d_loss: 0.630| gp_loss: 0.058| r_loss: 0.086| p_loss: 0.133| v_loss: 0.027| per_loss: 0.494 | a_loss: 0.515
Train: Epoch [1234/3000], Step [90/158]| g_loss: 0.834| d_loss: 0.490| gp_loss: 0.061| r_loss: 0.085| p_loss: 0.137| v_loss: 0.029| per_loss: 0.513 | a_loss: 0.599
Train: Epoch [1234/3000], Step [120/158]| g_loss: 0.794| d_loss: 0.616| gp_loss: 0.057| r_loss: 0.087| p_loss: 0.141| v_loss: 0.028| per_loss: 0.535 | a_loss: 0.554
Train: Epoch [1234/3000], Step [150/158]| g_loss: 0.820| d_loss: 0.575| gp_loss: 0.056| r_loss: 0.086| p_loss: 0.135| v_loss: 0.029| per_loss: 0.502 | a_loss: 0.587
Train: Epoch [1235/3000], Step [30/158]| g_loss: 0.761| d_loss: 0.688| gp_loss: 0.126| r_loss: 0.087| p_loss: 0.135| v_loss: 0.029| per_loss: 0.517 | a_loss: 0.526
Train: Epoch [1235/3000], Step [60/158]| g_loss: 0.740| d_loss: 0.623| gp_loss: 0.055| r_loss: 0.083| p_loss: 0.131| v_loss: 0.027| per_loss: 0.490 | a_loss: 0.515
Train: Epoch [1235/3000], Step [90/158]| g_loss: 0.786| d_loss: 0.539| gp_loss: 0.060| r_loss: 0.081| p_loss: 0.132| v_loss: 0.029| per_loss: 0.474 | a_loss: 0.562
Train: Epoch [1235/3000], Step [120/158]| g_loss: 0.774| d_loss: 0.644| gp_loss: 0.058| r_loss: 0.083| p_loss: 0.129| v_loss: 0.027| per_loss: 0.480 | a_loss: 0.551
Train: Epoch [1235/3000], Step [150/158]| g_loss: 0.794| d_loss: 0.574| gp_loss: 0.060| r_loss: 0.087| p_loss: 0.131| v_loss: 0.029| per_loss: 0.522 | a_loss: 0.560
Train: Epoch [1236/3000], Step [30/158]| g_loss: 0.818| d_loss: 0.647| gp_loss: 0.170| r_loss: 0.090| p_loss: 0.131| v_loss: 0.028| per_loss: 0.525 | a_loss: 0.581
Train: Epoch [1236/3000], Step [60/158]| g_loss: 0.824| d_loss: 0.544| gp_loss: 0.056| r_loss: 0.082| p_loss: 0.129| v_loss: 0.028| per_loss: 0.469 | a_loss: 0.602
Train: Epoch [1236/3000], Step [90/158]| g_loss: 0.749| d_loss: 0.680| gp_loss: 0.053| r_loss: 0.085| p_loss: 0.132| v_loss: 0.029| per_loss: 0.495 | a_loss: 0.520
Train: Epoch [1236/3000], Step [120/158]| g_loss: 0.726| d_loss: 0.579| gp_loss: 0.057| r_loss: 0.082| p_loss: 0.130| v_loss: 0.028| per_loss: 0.511 | a_loss: 0.501
Train: Epoch [1236/3000], Step [150/158]| g_loss: 0.874| d_loss: 0.470| gp_loss: 0.058| r_loss: 0.087| p_loss: 0.139| v_loss: 0.028| per_loss: 0.503 | a_loss: 0.639
Train: Epoch [1237/3000], Step [30/158]| g_loss: 0.765| d_loss: 0.766| gp_loss: 0.179| r_loss: 0.097| p_loss: 0.143| v_loss: 0.027| per_loss: 0.494 | a_loss: 0.520
Train: Epoch [1237/3000], Step [60/158]| g_loss: 0.745| d_loss: 0.625| gp_loss: 0.059| r_loss: 0.090| p_loss: 0.135| v_loss: 0.029| per_loss: 0.503 | a_loss: 0.509
Train: Epoch [1237/3000], Step [90/158]| g_loss: 0.848| d_loss: 0.535| gp_loss: 0.059| r_loss: 0.088| p_loss: 0.139| v_loss: 0.029| per_loss: 0.493 | a_loss: 0.612
Train: Epoch [1237/3000], Step [120/158]| g_loss: 0.848| d_loss: 0.496| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.130| v_loss: 0.029| per_loss: 0.550 | a_loss: 0.615
Train: Epoch [1237/3000], Step [150/158]| g_loss: 0.776| d_loss: 0.607| gp_loss: 0.059| r_loss: 0.084| p_loss: 0.135| v_loss: 0.028| per_loss: 0.505 | a_loss: 0.546
Train: Epoch [1238/3000], Step [30/158]| g_loss: 0.811| d_loss: 0.627| gp_loss: 0.130| r_loss: 0.086| p_loss: 0.135| v_loss: 0.028| per_loss: 0.513 | a_loss: 0.578
Train: Epoch [1238/3000], Step [60/158]| g_loss: 0.763| d_loss: 0.647| gp_loss: 0.063| r_loss: 0.086| p_loss: 0.140| v_loss: 0.028| per_loss: 0.512 | a_loss: 0.528
Train: Epoch [1238/3000], Step [90/158]| g_loss: 0.789| d_loss: 0.624| gp_loss: 0.058| r_loss: 0.092| p_loss: 0.142| v_loss: 0.029| per_loss: 0.516 | a_loss: 0.546
Train: Epoch [1238/3000], Step [120/158]| g_loss: 0.789| d_loss: 0.594| gp_loss: 0.063| r_loss: 0.087| p_loss: 0.138| v_loss: 0.029| per_loss: 0.509 | a_loss: 0.553
Train: Epoch [1238/3000], Step [150/158]| g_loss: 0.777| d_loss: 0.613| gp_loss: 0.060| r_loss: 0.088| p_loss: 0.146| v_loss: 0.029| per_loss: 0.545 | a_loss: 0.533
Train: Epoch [1239/3000], Step [30/158]| g_loss: 0.911| d_loss: 0.665| gp_loss: 0.170| r_loss: 0.095| p_loss: 0.159| v_loss: 0.030| per_loss: 0.557 | a_loss: 0.650
Train: Epoch [1239/3000], Step [60/158]| g_loss: 0.793| d_loss: 0.554| gp_loss: 0.054| r_loss: 0.087| p_loss: 0.138| v_loss: 0.030| per_loss: 0.529 | a_loss: 0.554
Train: Epoch [1239/3000], Step [90/158]| g_loss: 0.813| d_loss: 0.576| gp_loss: 0.058| r_loss: 0.088| p_loss: 0.139| v_loss: 0.029| per_loss: 0.528 | a_loss: 0.573
Train: Epoch [1239/3000], Step [120/158]| g_loss: 0.757| d_loss: 0.617| gp_loss: 0.059| r_loss: 0.082| p_loss: 0.130| v_loss: 0.028| per_loss: 0.510 | a_loss: 0.531
Train: Epoch [1239/3000], Step [150/158]| g_loss: 0.798| d_loss: 0.597| gp_loss: 0.060| r_loss: 0.084| p_loss: 0.128| v_loss: 0.027| per_loss: 0.507 | a_loss: 0.572
Train: Epoch [1240/3000], Step [30/158]| g_loss: 0.795| d_loss: 0.737| gp_loss: 0.202| r_loss: 0.088| p_loss: 0.135| v_loss: 0.029| per_loss: 0.512 | a_loss: 0.560
Train: Epoch [1240/3000], Step [60/158]| g_loss: 0.751| d_loss: 0.628| gp_loss: 0.057| r_loss: 0.093| p_loss: 0.144| v_loss: 0.029| per_loss: 0.506 | a_loss: 0.507
Train: Epoch [1240/3000], Step [90/158]| g_loss: 0.798| d_loss: 0.562| gp_loss: 0.062| r_loss: 0.086| p_loss: 0.139| v_loss: 0.028| per_loss: 0.543 | a_loss: 0.560
Train: Epoch [1240/3000], Step [120/158]| g_loss: 0.859| d_loss: 0.516| gp_loss: 0.060| r_loss: 0.088| p_loss: 0.141| v_loss: 0.029| per_loss: 0.539 | a_loss: 0.617
Train: Epoch [1240/3000], Step [150/158]| g_loss: 0.800| d_loss: 0.556| gp_loss: 0.061| r_loss: 0.084| p_loss: 0.132| v_loss: 0.029| per_loss: 0.471 | a_loss: 0.574
Train: Epoch [1241/3000], Step [30/158]| g_loss: 0.857| d_loss: 0.635| gp_loss: 0.177| r_loss: 0.085| p_loss: 0.142| v_loss: 0.029| per_loss: 0.560 | a_loss: 0.616
Train: Epoch [1241/3000], Step [60/158]| g_loss: 0.801| d_loss: 0.552| gp_loss: 0.056| r_loss: 0.087| p_loss: 0.138| v_loss: 0.030| per_loss: 0.560 | a_loss: 0.559
Train: Epoch [1241/3000], Step [90/158]| g_loss: 0.727| d_loss: 0.657| gp_loss: 0.056| r_loss: 0.084| p_loss: 0.131| v_loss: 0.028| per_loss: 0.486 | a_loss: 0.501
Train: Epoch [1241/3000], Step [120/158]| g_loss: 0.761| d_loss: 0.678| gp_loss: 0.055| r_loss: 0.088| p_loss: 0.136| v_loss: 0.027| per_loss: 0.485 | a_loss: 0.529
Train: Epoch [1241/3000], Step [150/158]| g_loss: 0.789| d_loss: 0.593| gp_loss: 0.060| r_loss: 0.087| p_loss: 0.141| v_loss: 0.029| per_loss: 0.492 | a_loss: 0.553
Train: Epoch [1242/3000], Step [30/158]| g_loss: 0.750| d_loss: 0.740| gp_loss: 0.153| r_loss: 0.088| p_loss: 0.142| v_loss: 0.028| per_loss: 0.500 | a_loss: 0.513
Train: Epoch [1242/3000], Step [60/158]| g_loss: 0.786| d_loss: 0.595| gp_loss: 0.053| r_loss: 0.086| p_loss: 0.138| v_loss: 0.028| per_loss: 0.523 | a_loss: 0.550
Train: Epoch [1242/3000], Step [90/158]| g_loss: 0.795| d_loss: 0.610| gp_loss: 0.053| r_loss: 0.090| p_loss: 0.139| v_loss: 0.031| per_loss: 0.490 | a_loss: 0.556
Train: Epoch [1242/3000], Step [120/158]| g_loss: 0.822| d_loss: 0.560| gp_loss: 0.059| r_loss: 0.087| p_loss: 0.142| v_loss: 0.030| per_loss: 0.522 | a_loss: 0.581
Train: Epoch [1242/3000], Step [150/158]| g_loss: 0.853| d_loss: 0.546| gp_loss: 0.058| r_loss: 0.086| p_loss: 0.133| v_loss: 0.029| per_loss: 0.494 | a_loss: 0.622
Train: Epoch [1243/3000], Step [30/158]| g_loss: 0.823| d_loss: 0.696| gp_loss: 0.168| r_loss: 0.087| p_loss: 0.139| v_loss: 0.029| per_loss: 0.484 | a_loss: 0.590
Train: Epoch [1243/3000], Step [60/158]| g_loss: 0.804| d_loss: 0.567| gp_loss: 0.055| r_loss: 0.086| p_loss: 0.139| v_loss: 0.029| per_loss: 0.535 | a_loss: 0.566
Train: Epoch [1243/3000], Step [90/158]| g_loss: 0.744| d_loss: 0.638| gp_loss: 0.053| r_loss: 0.087| p_loss: 0.134| v_loss: 0.029| per_loss: 0.516 | a_loss: 0.510
Train: Epoch [1243/3000], Step [120/158]| g_loss: 0.762| d_loss: 0.586| gp_loss: 0.059| r_loss: 0.083| p_loss: 0.129| v_loss: 0.028| per_loss: 0.495 | a_loss: 0.536
Train: Epoch [1243/3000], Step [150/158]| g_loss: 0.795| d_loss: 0.536| gp_loss: 0.057| r_loss: 0.082| p_loss: 0.128| v_loss: 0.029| per_loss: 0.504 | a_loss: 0.569
Train: Epoch [1244/3000], Step [30/158]| g_loss: 0.816| d_loss: 0.673| gp_loss: 0.186| r_loss: 0.085| p_loss: 0.131| v_loss: 0.028| per_loss: 0.502 | a_loss: 0.588
Train: Epoch [1244/3000], Step [60/158]| g_loss: 0.766| d_loss: 0.591| gp_loss: 0.055| r_loss: 0.083| p_loss: 0.129| v_loss: 0.028| per_loss: 0.469 | a_loss: 0.544
Train: Epoch [1244/3000], Step [90/158]| g_loss: 0.834| d_loss: 0.511| gp_loss: 0.054| r_loss: 0.082| p_loss: 0.126| v_loss: 0.029| per_loss: 0.516 | a_loss: 0.608
Train: Epoch [1244/3000], Step [120/158]| g_loss: 0.701| d_loss: 0.750| gp_loss: 0.054| r_loss: 0.084| p_loss: 0.138| v_loss: 0.028| per_loss: 0.473 | a_loss: 0.472
Train: Epoch [1244/3000], Step [150/158]| g_loss: 0.788| d_loss: 0.563| gp_loss: 0.062| r_loss: 0.087| p_loss: 0.134| v_loss: 0.029| per_loss: 0.523 | a_loss: 0.553
Train: Epoch [1245/3000], Step [30/158]| g_loss: 0.819| d_loss: 0.703| gp_loss: 0.185| r_loss: 0.085| p_loss: 0.134| v_loss: 0.029| per_loss: 0.487 | a_loss: 0.589
Train: Epoch [1245/3000], Step [60/158]| g_loss: 0.823| d_loss: 0.546| gp_loss: 0.054| r_loss: 0.086| p_loss: 0.131| v_loss: 0.029| per_loss: 0.523 | a_loss: 0.590
Train: Epoch [1245/3000], Step [90/158]| g_loss: 0.788| d_loss: 0.591| gp_loss: 0.057| r_loss: 0.083| p_loss: 0.131| v_loss: 0.029| per_loss: 0.498 | a_loss: 0.562
Train: Epoch [1245/3000], Step [120/158]| g_loss: 0.745| d_loss: 0.572| gp_loss: 0.056| r_loss: 0.083| p_loss: 0.130| v_loss: 0.028| per_loss: 0.482 | a_loss: 0.521
Train: Epoch [1245/3000], Step [150/158]| g_loss: 0.803| d_loss: 0.657| gp_loss: 0.058| r_loss: 0.088| p_loss: 0.140| v_loss: 0.029| per_loss: 0.502 | a_loss: 0.566
Train: Epoch [1246/3000], Step [30/158]| g_loss: 0.808| d_loss: 0.762| gp_loss: 0.221| r_loss: 0.082| p_loss: 0.132| v_loss: 0.028| per_loss: 0.532 | a_loss: 0.579
Train: Epoch [1246/3000], Step [60/158]| g_loss: 0.704| d_loss: 0.636| gp_loss: 0.055| r_loss: 0.083| p_loss: 0.129| v_loss: 0.029| per_loss: 0.510 | a_loss: 0.476
Train: Epoch [1246/3000], Step [90/158]| g_loss: 0.811| d_loss: 0.608| gp_loss: 0.057| r_loss: 0.086| p_loss: 0.133| v_loss: 0.030| per_loss: 0.520 | a_loss: 0.577
Train: Epoch [1246/3000], Step [120/158]| g_loss: 0.859| d_loss: 0.546| gp_loss: 0.054| r_loss: 0.086| p_loss: 0.138| v_loss: 0.030| per_loss: 0.552 | a_loss: 0.619
Train: Epoch [1246/3000], Step [150/158]| g_loss: 0.783| d_loss: 0.577| gp_loss: 0.054| r_loss: 0.084| p_loss: 0.134| v_loss: 0.029| per_loss: 0.502 | a_loss: 0.552
Train: Epoch [1247/3000], Step [30/158]| g_loss: 0.752| d_loss: 0.655| gp_loss: 0.114| r_loss: 0.085| p_loss: 0.130| v_loss: 0.029| per_loss: 0.515 | a_loss: 0.522
Train: Epoch [1247/3000], Step [60/158]| g_loss: 0.799| d_loss: 0.606| gp_loss: 0.057| r_loss: 0.082| p_loss: 0.127| v_loss: 0.029| per_loss: 0.480 | a_loss: 0.576
Train: Epoch [1247/3000], Step [90/158]| g_loss: 0.818| d_loss: 0.552| gp_loss: 0.058| r_loss: 0.081| p_loss: 0.127| v_loss: 0.028| per_loss: 0.528 | a_loss: 0.593
Train: Epoch [1247/3000], Step [120/158]| g_loss: 0.816| d_loss: 0.620| gp_loss: 0.060| r_loss: 0.090| p_loss: 0.134| v_loss: 0.029| per_loss: 0.540 | a_loss: 0.576
Train: Epoch [1247/3000], Step [150/158]| g_loss: 0.767| d_loss: 0.596| gp_loss: 0.060| r_loss: 0.084| p_loss: 0.133| v_loss: 0.029| per_loss: 0.511 | a_loss: 0.537
Train: Epoch [1248/3000], Step [30/158]| g_loss: 0.766| d_loss: 0.706| gp_loss: 0.196| r_loss: 0.085| p_loss: 0.133| v_loss: 0.029| per_loss: 0.478 | a_loss: 0.538
Train: Epoch [1248/3000], Step [60/158]| g_loss: 0.764| d_loss: 0.583| gp_loss: 0.060| r_loss: 0.082| p_loss: 0.128| v_loss: 0.028| per_loss: 0.487 | a_loss: 0.542
Train: Epoch [1248/3000], Step [90/158]| g_loss: 0.789| d_loss: 0.656| gp_loss: 0.053| r_loss: 0.086| p_loss: 0.138| v_loss: 0.029| per_loss: 0.508 | a_loss: 0.554
Train: Epoch [1248/3000], Step [120/158]| g_loss: 0.742| d_loss: 0.627| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.139| v_loss: 0.030| per_loss: 0.478 | a_loss: 0.510
Train: Epoch [1248/3000], Step [150/158]| g_loss: 0.774| d_loss: 0.599| gp_loss: 0.056| r_loss: 0.081| p_loss: 0.129| v_loss: 0.027| per_loss: 0.531 | a_loss: 0.547
Train: Epoch [1249/3000], Step [30/158]| g_loss: 0.792| d_loss: 0.632| gp_loss: 0.143| r_loss: 0.082| p_loss: 0.126| v_loss: 0.029| per_loss: 0.511 | a_loss: 0.568
Train: Epoch [1249/3000], Step [60/158]| g_loss: 0.753| d_loss: 0.595| gp_loss: 0.055| r_loss: 0.083| p_loss: 0.129| v_loss: 0.029| per_loss: 0.478 | a_loss: 0.528
Train: Epoch [1249/3000], Step [90/158]| g_loss: 0.836| d_loss: 0.557| gp_loss: 0.054| r_loss: 0.085| p_loss: 0.129| v_loss: 0.030| per_loss: 0.532 | a_loss: 0.604
Train: Epoch [1249/3000], Step [120/158]| g_loss: 0.774| d_loss: 0.653| gp_loss: 0.060| r_loss: 0.085| p_loss: 0.135| v_loss: 0.028| per_loss: 0.460 | a_loss: 0.548
Train: Epoch [1249/3000], Step [150/158]| g_loss: 0.748| d_loss: 0.646| gp_loss: 0.054| r_loss: 0.084| p_loss: 0.131| v_loss: 0.029| per_loss: 0.511 | a_loss: 0.519
Train: Epoch [1250/3000], Step [30/158]| g_loss: 0.768| d_loss: 0.672| gp_loss: 0.181| r_loss: 0.082| p_loss: 0.127| v_loss: 0.029| per_loss: 0.514 | a_loss: 0.543
Train: Epoch [1250/3000], Step [60/158]| g_loss: 0.747| d_loss: 0.612| gp_loss: 0.053| r_loss: 0.084| p_loss: 0.127| v_loss: 0.029| per_loss: 0.463 | a_loss: 0.525
Train: Epoch [1250/3000], Step [90/158]| g_loss: 0.775| d_loss: 0.613| gp_loss: 0.055| r_loss: 0.082| p_loss: 0.123| v_loss: 0.028| per_loss: 0.498 | a_loss: 0.553
Train: Epoch [1250/3000], Step [120/158]| g_loss: 0.753| d_loss: 0.656| gp_loss: 0.057| r_loss: 0.083| p_loss: 0.125| v_loss: 0.028| per_loss: 0.510 | a_loss: 0.529
Train: Epoch [1250/3000], Step [150/158]| g_loss: 0.837| d_loss: 0.501| gp_loss: 0.059| r_loss: 0.083| p_loss: 0.127| v_loss: 0.028| per_loss: 0.461 | a_loss: 0.616
Test: Epoch [1250/3000]| g_loss: 0.630| r_loss: 0.379| p_loss: 0.294| v_loss: 0.025
Train: Epoch [1251/3000], Step [30/158]| g_loss: 0.761| d_loss: 0.624| gp_loss: 0.056| r_loss: 0.086| p_loss: 0.133| v_loss: 0.029| per_loss: 0.514 | a_loss: 0.527
Train: Epoch [1251/3000], Step [60/158]| g_loss: 0.813| d_loss: 0.549| gp_loss: 0.056| r_loss: 0.083| p_loss: 0.128| v_loss: 0.029| per_loss: 0.471 | a_loss: 0.590
Train: Epoch [1251/3000], Step [90/158]| g_loss: 0.755| d_loss: 0.599| gp_loss: 0.055| r_loss: 0.080| p_loss: 0.129| v_loss: 0.028| per_loss: 0.509 | a_loss: 0.531
Train: Epoch [1251/3000], Step [120/158]| g_loss: 0.824| d_loss: 0.528| gp_loss: 0.058| r_loss: 0.080| p_loss: 0.126| v_loss: 0.027| per_loss: 0.509 | a_loss: 0.603
Train: Epoch [1251/3000], Step [150/158]| g_loss: 0.774| d_loss: 0.620| gp_loss: 0.059| r_loss: 0.088| p_loss: 0.137| v_loss: 0.029| per_loss: 0.467 | a_loss: 0.542
Train: Epoch [1252/3000], Step [30/158]| g_loss: 0.721| d_loss: 0.768| gp_loss: 0.128| r_loss: 0.086| p_loss: 0.134| v_loss: 0.028| per_loss: 0.486 | a_loss: 0.492
Train: Epoch [1252/3000], Step [60/158]| g_loss: 0.787| d_loss: 0.593| gp_loss: 0.058| r_loss: 0.082| p_loss: 0.137| v_loss: 0.029| per_loss: 0.532 | a_loss: 0.554
Train: Epoch [1252/3000], Step [90/158]| g_loss: 0.780| d_loss: 0.596| gp_loss: 0.061| r_loss: 0.082| p_loss: 0.130| v_loss: 0.028| per_loss: 0.451 | a_loss: 0.560
Train: Epoch [1252/3000], Step [120/158]| g_loss: 0.739| d_loss: 0.627| gp_loss: 0.058| r_loss: 0.082| p_loss: 0.128| v_loss: 0.029| per_loss: 0.496 | a_loss: 0.514
Train: Epoch [1252/3000], Step [150/158]| g_loss: 0.784| d_loss: 0.560| gp_loss: 0.061| r_loss: 0.083| p_loss: 0.130| v_loss: 0.029| per_loss: 0.477 | a_loss: 0.558
Train: Epoch [1253/3000], Step [30/158]| g_loss: 0.780| d_loss: 0.729| gp_loss: 0.182| r_loss: 0.083| p_loss: 0.135| v_loss: 0.030| per_loss: 0.480 | a_loss: 0.551
Train: Epoch [1253/3000], Step [60/158]| g_loss: 0.778| d_loss: 0.623| gp_loss: 0.053| r_loss: 0.083| p_loss: 0.129| v_loss: 0.028| per_loss: 0.502 | a_loss: 0.553
Train: Epoch [1253/3000], Step [90/158]| g_loss: 0.795| d_loss: 0.594| gp_loss: 0.058| r_loss: 0.085| p_loss: 0.131| v_loss: 0.028| per_loss: 0.489 | a_loss: 0.568
Train: Epoch [1253/3000], Step [120/158]| g_loss: 0.759| d_loss: 0.638| gp_loss: 0.056| r_loss: 0.085| p_loss: 0.131| v_loss: 0.028| per_loss: 0.481 | a_loss: 0.532
Train: Epoch [1253/3000], Step [150/158]| g_loss: 0.818| d_loss: 0.531| gp_loss: 0.062| r_loss: 0.084| p_loss: 0.137| v_loss: 0.029| per_loss: 0.495 | a_loss: 0.588
Train: Epoch [1254/3000], Step [30/158]| g_loss: 0.782| d_loss: 0.682| gp_loss: 0.078| r_loss: 0.083| p_loss: 0.131| v_loss: 0.029| per_loss: 0.486 | a_loss: 0.557
Train: Epoch [1254/3000], Step [60/158]| g_loss: 0.760| d_loss: 0.624| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.129| v_loss: 0.029| per_loss: 0.501 | a_loss: 0.533
Train: Epoch [1254/3000], Step [90/158]| g_loss: 0.831| d_loss: 0.558| gp_loss: 0.060| r_loss: 0.085| p_loss: 0.134| v_loss: 0.030| per_loss: 0.496 | a_loss: 0.599
Train: Epoch [1254/3000], Step [120/158]| g_loss: 0.785| d_loss: 0.600| gp_loss: 0.059| r_loss: 0.085| p_loss: 0.142| v_loss: 0.029| per_loss: 0.506 | a_loss: 0.550
Train: Epoch [1254/3000], Step [150/158]| g_loss: 0.836| d_loss: 0.496| gp_loss: 0.061| r_loss: 0.085| p_loss: 0.134| v_loss: 0.030| per_loss: 0.498 | a_loss: 0.604
Train: Epoch [1255/3000], Step [30/158]| g_loss: 0.769| d_loss: 0.767| gp_loss: 0.147| r_loss: 0.083| p_loss: 0.134| v_loss: 0.028| per_loss: 0.487 | a_loss: 0.542
Train: Epoch [1255/3000], Step [60/158]| g_loss: 0.774| d_loss: 0.578| gp_loss: 0.056| r_loss: 0.082| p_loss: 0.134| v_loss: 0.028| per_loss: 0.496 | a_loss: 0.547
Train: Epoch [1255/3000], Step [90/158]| g_loss: 0.834| d_loss: 0.550| gp_loss: 0.052| r_loss: 0.088| p_loss: 0.136| v_loss: 0.030| per_loss: 0.493 | a_loss: 0.598
Train: Epoch [1255/3000], Step [120/158]| g_loss: 0.739| d_loss: 0.675| gp_loss: 0.059| r_loss: 0.087| p_loss: 0.135| v_loss: 0.029| per_loss: 0.511 | a_loss: 0.506
Train: Epoch [1255/3000], Step [150/158]| g_loss: 0.767| d_loss: 0.603| gp_loss: 0.056| r_loss: 0.083| p_loss: 0.129| v_loss: 0.030| per_loss: 0.532 | a_loss: 0.536
Train: Epoch [1256/3000], Step [30/158]| g_loss: 0.814| d_loss: 0.616| gp_loss: 0.138| r_loss: 0.083| p_loss: 0.132| v_loss: 0.030| per_loss: 0.486 | a_loss: 0.587
Train: Epoch [1256/3000], Step [60/158]| g_loss: 0.774| d_loss: 0.644| gp_loss: 0.054| r_loss: 0.085| p_loss: 0.132| v_loss: 0.028| per_loss: 0.496 | a_loss: 0.546
Train: Epoch [1256/3000], Step [90/158]| g_loss: 0.821| d_loss: 0.551| gp_loss: 0.064| r_loss: 0.084| p_loss: 0.136| v_loss: 0.030| per_loss: 0.515 | a_loss: 0.588
Train: Epoch [1256/3000], Step [120/158]| g_loss: 0.769| d_loss: 0.636| gp_loss: 0.058| r_loss: 0.086| p_loss: 0.138| v_loss: 0.029| per_loss: 0.494 | a_loss: 0.535
Train: Epoch [1256/3000], Step [150/158]| g_loss: 0.788| d_loss: 0.616| gp_loss: 0.060| r_loss: 0.086| p_loss: 0.135| v_loss: 0.030| per_loss: 0.518 | a_loss: 0.552
Train: Epoch [1257/3000], Step [30/158]| g_loss: 0.799| d_loss: 0.634| gp_loss: 0.147| r_loss: 0.096| p_loss: 0.145| v_loss: 0.029| per_loss: 0.475 | a_loss: 0.555
Train: Epoch [1257/3000], Step [60/158]| g_loss: 0.744| d_loss: 0.721| gp_loss: 0.055| r_loss: 0.086| p_loss: 0.139| v_loss: 0.028| per_loss: 0.497 | a_loss: 0.511
Train: Epoch [1257/3000], Step [90/158]| g_loss: 0.756| d_loss: 0.574| gp_loss: 0.063| r_loss: 0.086| p_loss: 0.136| v_loss: 0.028| per_loss: 0.504 | a_loss: 0.523
Train: Epoch [1257/3000], Step [120/158]| g_loss: 0.830| d_loss: 0.566| gp_loss: 0.058| r_loss: 0.086| p_loss: 0.132| v_loss: 0.030| per_loss: 0.476 | a_loss: 0.601
Train: Epoch [1257/3000], Step [150/158]| g_loss: 0.807| d_loss: 0.556| gp_loss: 0.060| r_loss: 0.083| p_loss: 0.136| v_loss: 0.029| per_loss: 0.508 | a_loss: 0.577
Train: Epoch [1258/3000], Step [30/158]| g_loss: 0.782| d_loss: 0.709| gp_loss: 0.163| r_loss: 0.084| p_loss: 0.139| v_loss: 0.029| per_loss: 0.488 | a_loss: 0.550
Train: Epoch [1258/3000], Step [60/158]| g_loss: 0.776| d_loss: 0.662| gp_loss: 0.051| r_loss: 0.087| p_loss: 0.139| v_loss: 0.029| per_loss: 0.502 | a_loss: 0.540
Train: Epoch [1258/3000], Step [90/158]| g_loss: 0.724| d_loss: 0.665| gp_loss: 0.058| r_loss: 0.083| p_loss: 0.133| v_loss: 0.030| per_loss: 0.500 | a_loss: 0.495
Train: Epoch [1258/3000], Step [120/158]| g_loss: 0.774| d_loss: 0.610| gp_loss: 0.059| r_loss: 0.082| p_loss: 0.133| v_loss: 0.029| per_loss: 0.496 | a_loss: 0.547
Train: Epoch [1258/3000], Step [150/158]| g_loss: 0.819| d_loss: 0.556| gp_loss: 0.066| r_loss: 0.084| p_loss: 0.131| v_loss: 0.029| per_loss: 0.536 | a_loss: 0.587
Train: Epoch [1259/3000], Step [30/158]| g_loss: 0.840| d_loss: 0.693| gp_loss: 0.202| r_loss: 0.084| p_loss: 0.130| v_loss: 0.029| per_loss: 0.516 | a_loss: 0.610
Train: Epoch [1259/3000], Step [60/158]| g_loss: 0.784| d_loss: 0.591| gp_loss: 0.055| r_loss: 0.083| p_loss: 0.135| v_loss: 0.029| per_loss: 0.501 | a_loss: 0.555
Train: Epoch [1259/3000], Step [90/158]| g_loss: 0.715| d_loss: 0.625| gp_loss: 0.056| r_loss: 0.082| p_loss: 0.125| v_loss: 0.028| per_loss: 0.446 | a_loss: 0.498
Train: Epoch [1259/3000], Step [120/158]| g_loss: 0.758| d_loss: 0.651| gp_loss: 0.055| r_loss: 0.083| p_loss: 0.127| v_loss: 0.030| per_loss: 0.486 | a_loss: 0.534
Train: Epoch [1259/3000], Step [150/158]| g_loss: 0.759| d_loss: 0.570| gp_loss: 0.060| r_loss: 0.080| p_loss: 0.126| v_loss: 0.029| per_loss: 0.519 | a_loss: 0.534
Train: Epoch [1260/3000], Step [30/158]| g_loss: 0.795| d_loss: 0.674| gp_loss: 0.151| r_loss: 0.081| p_loss: 0.125| v_loss: 0.029| per_loss: 0.481 | a_loss: 0.574
Train: Epoch [1260/3000], Step [60/158]| g_loss: 0.786| d_loss: 0.562| gp_loss: 0.055| r_loss: 0.087| p_loss: 0.135| v_loss: 0.030| per_loss: 0.502 | a_loss: 0.551
Train: Epoch [1260/3000], Step [90/158]| g_loss: 0.798| d_loss: 0.587| gp_loss: 0.055| r_loss: 0.080| p_loss: 0.127| v_loss: 0.029| per_loss: 0.485 | a_loss: 0.578
Train: Epoch [1260/3000], Step [120/158]| g_loss: 0.744| d_loss: 0.619| gp_loss: 0.056| r_loss: 0.085| p_loss: 0.129| v_loss: 0.028| per_loss: 0.481 | a_loss: 0.518
Train: Epoch [1260/3000], Step [150/158]| g_loss: 0.740| d_loss: 0.635| gp_loss: 0.060| r_loss: 0.081| p_loss: 0.125| v_loss: 0.028| per_loss: 0.487 | a_loss: 0.519
Train: Epoch [1261/3000], Step [30/158]| g_loss: 0.738| d_loss: 0.712| gp_loss: 0.167| r_loss: 0.080| p_loss: 0.126| v_loss: 0.029| per_loss: 0.466 | a_loss: 0.519
Train: Epoch [1261/3000], Step [60/158]| g_loss: 0.812| d_loss: 0.598| gp_loss: 0.054| r_loss: 0.082| p_loss: 0.129| v_loss: 0.029| per_loss: 0.467 | a_loss: 0.589
Train: Epoch [1261/3000], Step [90/158]| g_loss: 0.809| d_loss: 0.534| gp_loss: 0.054| r_loss: 0.083| p_loss: 0.126| v_loss: 0.030| per_loss: 0.524 | a_loss: 0.581
Train: Epoch [1261/3000], Step [120/158]| g_loss: 0.781| d_loss: 0.552| gp_loss: 0.057| r_loss: 0.083| p_loss: 0.127| v_loss: 0.029| per_loss: 0.489 | a_loss: 0.556
Train: Epoch [1261/3000], Step [150/158]| g_loss: 0.761| d_loss: 0.654| gp_loss: 0.056| r_loss: 0.084| p_loss: 0.131| v_loss: 0.029| per_loss: 0.492 | a_loss: 0.534
Train: Epoch [1262/3000], Step [30/158]| g_loss: 0.703| d_loss: 0.775| gp_loss: 0.123| r_loss: 0.083| p_loss: 0.132| v_loss: 0.029| per_loss: 0.517 | a_loss: 0.473
Train: Epoch [1262/3000], Step [60/158]| g_loss: 0.766| d_loss: 0.650| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.135| v_loss: 0.029| per_loss: 0.465 | a_loss: 0.538
Train: Epoch [1262/3000], Step [90/158]| g_loss: 0.794| d_loss: 0.577| gp_loss: 0.059| r_loss: 0.082| p_loss: 0.132| v_loss: 0.028| per_loss: 0.500 | a_loss: 0.568
Train: Epoch [1262/3000], Step [120/158]| g_loss: 0.780| d_loss: 0.526| gp_loss: 0.059| r_loss: 0.084| p_loss: 0.133| v_loss: 0.030| per_loss: 0.482 | a_loss: 0.551
Train: Epoch [1262/3000], Step [150/158]| g_loss: 0.799| d_loss: 0.598| gp_loss: 0.059| r_loss: 0.084| p_loss: 0.130| v_loss: 0.028| per_loss: 0.471 | a_loss: 0.575
Train: Epoch [1263/3000], Step [30/158]| g_loss: 0.785| d_loss: 0.721| gp_loss: 0.120| r_loss: 0.085| p_loss: 0.135| v_loss: 0.028| per_loss: 0.505 | a_loss: 0.554
Train: Epoch [1263/3000], Step [60/158]| g_loss: 0.794| d_loss: 0.587| gp_loss: 0.059| r_loss: 0.085| p_loss: 0.139| v_loss: 0.029| per_loss: 0.467 | a_loss: 0.564
Train: Epoch [1263/3000], Step [90/158]| g_loss: 0.813| d_loss: 0.507| gp_loss: 0.058| r_loss: 0.082| p_loss: 0.131| v_loss: 0.029| per_loss: 0.537 | a_loss: 0.583
Train: Epoch [1263/3000], Step [120/158]| g_loss: 0.792| d_loss: 0.584| gp_loss: 0.058| r_loss: 0.083| p_loss: 0.137| v_loss: 0.030| per_loss: 0.498 | a_loss: 0.560
Train: Epoch [1263/3000], Step [150/158]| g_loss: 0.725| d_loss: 0.697| gp_loss: 0.061| r_loss: 0.083| p_loss: 0.133| v_loss: 0.029| per_loss: 0.477 | a_loss: 0.499
Train: Epoch [1264/3000], Step [30/158]| g_loss: 0.739| d_loss: 0.696| gp_loss: 0.104| r_loss: 0.083| p_loss: 0.132| v_loss: 0.029| per_loss: 0.487 | a_loss: 0.513
Train: Epoch [1264/3000], Step [60/158]| g_loss: 0.745| d_loss: 0.656| gp_loss: 0.061| r_loss: 0.086| p_loss: 0.139| v_loss: 0.030| per_loss: 0.522 | a_loss: 0.508
Train: Epoch [1264/3000], Step [90/158]| g_loss: 0.738| d_loss: 0.656| gp_loss: 0.063| r_loss: 0.083| p_loss: 0.132| v_loss: 0.028| per_loss: 0.489 | a_loss: 0.511
Train: Epoch [1264/3000], Step [120/158]| g_loss: 0.874| d_loss: 0.486| gp_loss: 0.063| r_loss: 0.083| p_loss: 0.131| v_loss: 0.029| per_loss: 0.509 | a_loss: 0.646
Train: Epoch [1264/3000], Step [150/158]| g_loss: 0.823| d_loss: 0.532| gp_loss: 0.059| r_loss: 0.082| p_loss: 0.129| v_loss: 0.029| per_loss: 0.531 | a_loss: 0.594
Train: Epoch [1265/3000], Step [30/158]| g_loss: 0.786| d_loss: 0.757| gp_loss: 0.199| r_loss: 0.084| p_loss: 0.136| v_loss: 0.030| per_loss: 0.486 | a_loss: 0.555
Train: Epoch [1265/3000], Step [60/158]| g_loss: 0.748| d_loss: 0.661| gp_loss: 0.059| r_loss: 0.083| p_loss: 0.135| v_loss: 0.030| per_loss: 0.496 | a_loss: 0.519
Train: Epoch [1265/3000], Step [90/158]| g_loss: 0.759| d_loss: 0.532| gp_loss: 0.059| r_loss: 0.084| p_loss: 0.132| v_loss: 0.031| per_loss: 0.488 | a_loss: 0.529
Train: Epoch [1265/3000], Step [120/158]| g_loss: 0.810| d_loss: 0.569| gp_loss: 0.057| r_loss: 0.079| p_loss: 0.120| v_loss: 0.028| per_loss: 0.496 | a_loss: 0.594
Train: Epoch [1265/3000], Step [150/158]| g_loss: 0.773| d_loss: 0.592| gp_loss: 0.060| r_loss: 0.080| p_loss: 0.126| v_loss: 0.029| per_loss: 0.485 | a_loss: 0.552
Train: Epoch [1266/3000], Step [30/158]| g_loss: 0.742| d_loss: 0.720| gp_loss: 0.174| r_loss: 0.081| p_loss: 0.126| v_loss: 0.029| per_loss: 0.455 | a_loss: 0.523
Train: Epoch [1266/3000], Step [60/158]| g_loss: 0.778| d_loss: 0.605| gp_loss: 0.054| r_loss: 0.082| p_loss: 0.131| v_loss: 0.029| per_loss: 0.488 | a_loss: 0.552
Train: Epoch [1266/3000], Step [90/158]| g_loss: 0.805| d_loss: 0.550| gp_loss: 0.055| r_loss: 0.081| p_loss: 0.124| v_loss: 0.030| per_loss: 0.513 | a_loss: 0.580
Train: Epoch [1266/3000], Step [120/158]| g_loss: 0.739| d_loss: 0.617| gp_loss: 0.056| r_loss: 0.084| p_loss: 0.125| v_loss: 0.029| per_loss: 0.477 | a_loss: 0.516
Train: Epoch [1266/3000], Step [150/158]| g_loss: 0.736| d_loss: 0.621| gp_loss: 0.056| r_loss: 0.077| p_loss: 0.122| v_loss: 0.028| per_loss: 0.467 | a_loss: 0.523
Train: Epoch [1267/3000], Step [30/158]| g_loss: 0.772| d_loss: 0.694| gp_loss: 0.145| r_loss: 0.081| p_loss: 0.130| v_loss: 0.028| per_loss: 0.474 | a_loss: 0.551
Train: Epoch [1267/3000], Step [60/158]| g_loss: 0.806| d_loss: 0.511| gp_loss: 0.061| r_loss: 0.084| p_loss: 0.129| v_loss: 0.029| per_loss: 0.461 | a_loss: 0.582
Train: Epoch [1267/3000], Step [90/158]| g_loss: 0.755| d_loss: 0.649| gp_loss: 0.055| r_loss: 0.084| p_loss: 0.128| v_loss: 0.028| per_loss: 0.471 | a_loss: 0.532
Train: Epoch [1267/3000], Step [120/158]| g_loss: 0.783| d_loss: 0.593| gp_loss: 0.056| r_loss: 0.080| p_loss: 0.120| v_loss: 0.028| per_loss: 0.487 | a_loss: 0.566
Train: Epoch [1267/3000], Step [150/158]| g_loss: 0.757| d_loss: 0.581| gp_loss: 0.061| r_loss: 0.080| p_loss: 0.124| v_loss: 0.028| per_loss: 0.511 | a_loss: 0.537
Train: Epoch [1268/3000], Step [30/158]| g_loss: 0.782| d_loss: 0.695| gp_loss: 0.165| r_loss: 0.083| p_loss: 0.136| v_loss: 0.029| per_loss: 0.467 | a_loss: 0.555
Train: Epoch [1268/3000], Step [60/158]| g_loss: 0.805| d_loss: 0.611| gp_loss: 0.056| r_loss: 0.085| p_loss: 0.141| v_loss: 0.029| per_loss: 0.490 | a_loss: 0.571
Train: Epoch [1268/3000], Step [90/158]| g_loss: 0.761| d_loss: 0.597| gp_loss: 0.054| r_loss: 0.079| p_loss: 0.127| v_loss: 0.029| per_loss: 0.496 | a_loss: 0.540
Train: Epoch [1268/3000], Step [120/158]| g_loss: 0.825| d_loss: 0.503| gp_loss: 0.058| r_loss: 0.081| p_loss: 0.124| v_loss: 0.029| per_loss: 0.478 | a_loss: 0.606
Train: Epoch [1268/3000], Step [150/158]| g_loss: 0.759| d_loss: 0.668| gp_loss: 0.057| r_loss: 0.083| p_loss: 0.128| v_loss: 0.030| per_loss: 0.498 | a_loss: 0.533
Train: Epoch [1269/3000], Step [30/158]| g_loss: 0.757| d_loss: 0.749| gp_loss: 0.182| r_loss: 0.082| p_loss: 0.129| v_loss: 0.028| per_loss: 0.463 | a_loss: 0.537
Train: Epoch [1269/3000], Step [60/158]| g_loss: 0.781| d_loss: 0.603| gp_loss: 0.052| r_loss: 0.081| p_loss: 0.130| v_loss: 0.028| per_loss: 0.489 | a_loss: 0.558
Train: Epoch [1269/3000], Step [90/158]| g_loss: 0.747| d_loss: 0.646| gp_loss: 0.055| r_loss: 0.083| p_loss: 0.130| v_loss: 0.028| per_loss: 0.499 | a_loss: 0.521
Train: Epoch [1269/3000], Step [120/158]| g_loss: 0.820| d_loss: 0.556| gp_loss: 0.057| r_loss: 0.082| p_loss: 0.132| v_loss: 0.028| per_loss: 0.510 | a_loss: 0.592
Train: Epoch [1269/3000], Step [150/158]| g_loss: 0.779| d_loss: 0.563| gp_loss: 0.060| r_loss: 0.082| p_loss: 0.126| v_loss: 0.029| per_loss: 0.487 | a_loss: 0.557
Train: Epoch [1270/3000], Step [30/158]| g_loss: 0.777| d_loss: 0.620| gp_loss: 0.123| r_loss: 0.080| p_loss: 0.125| v_loss: 0.030| per_loss: 0.473 | a_loss: 0.557
Train: Epoch [1270/3000], Step [60/158]| g_loss: 0.804| d_loss: 0.579| gp_loss: 0.056| r_loss: 0.085| p_loss: 0.133| v_loss: 0.029| per_loss: 0.460 | a_loss: 0.577
Train: Epoch [1270/3000], Step [90/158]| g_loss: 0.851| d_loss: 0.494| gp_loss: 0.060| r_loss: 0.083| p_loss: 0.128| v_loss: 0.029| per_loss: 0.475 | a_loss: 0.628
Train: Epoch [1270/3000], Step [120/158]| g_loss: 0.702| d_loss: 0.689| gp_loss: 0.056| r_loss: 0.082| p_loss: 0.130| v_loss: 0.028| per_loss: 0.472 | a_loss: 0.480
Train: Epoch [1270/3000], Step [150/158]| g_loss: 0.762| d_loss: 0.622| gp_loss: 0.055| r_loss: 0.085| p_loss: 0.134| v_loss: 0.029| per_loss: 0.525 | a_loss: 0.529
Train: Epoch [1271/3000], Step [30/158]| g_loss: 0.737| d_loss: 0.732| gp_loss: 0.169| r_loss: 0.080| p_loss: 0.128| v_loss: 0.029| per_loss: 0.485 | a_loss: 0.515
Train: Epoch [1271/3000], Step [60/158]| g_loss: 0.725| d_loss: 0.633| gp_loss: 0.054| r_loss: 0.080| p_loss: 0.124| v_loss: 0.028| per_loss: 0.512 | a_loss: 0.503
Train: Epoch [1271/3000], Step [90/158]| g_loss: 0.775| d_loss: 0.592| gp_loss: 0.056| r_loss: 0.082| p_loss: 0.129| v_loss: 0.029| per_loss: 0.456 | a_loss: 0.554
Train: Epoch [1271/3000], Step [120/158]| g_loss: 0.782| d_loss: 0.569| gp_loss: 0.057| r_loss: 0.083| p_loss: 0.129| v_loss: 0.028| per_loss: 0.458 | a_loss: 0.560
Train: Epoch [1271/3000], Step [150/158]| g_loss: 0.812| d_loss: 0.566| gp_loss: 0.058| r_loss: 0.083| p_loss: 0.129| v_loss: 0.028| per_loss: 0.479 | a_loss: 0.589
Train: Epoch [1272/3000], Step [30/158]| g_loss: 0.821| d_loss: 0.632| gp_loss: 0.162| r_loss: 0.084| p_loss: 0.129| v_loss: 0.030| per_loss: 0.489 | a_loss: 0.595
Train: Epoch [1272/3000], Step [60/158]| g_loss: 0.744| d_loss: 0.652| gp_loss: 0.051| r_loss: 0.080| p_loss: 0.126| v_loss: 0.028| per_loss: 0.467 | a_loss: 0.525
Train: Epoch [1272/3000], Step [90/158]| g_loss: 0.747| d_loss: 0.634| gp_loss: 0.055| r_loss: 0.080| p_loss: 0.128| v_loss: 0.029| per_loss: 0.465 | a_loss: 0.528
Train: Epoch [1272/3000], Step [120/158]| g_loss: 0.851| d_loss: 0.614| gp_loss: 0.058| r_loss: 0.086| p_loss: 0.138| v_loss: 0.029| per_loss: 0.496 | a_loss: 0.617
Train: Epoch [1272/3000], Step [150/158]| g_loss: 0.774| d_loss: 0.571| gp_loss: 0.054| r_loss: 0.084| p_loss: 0.133| v_loss: 0.029| per_loss: 0.484 | a_loss: 0.546
Train: Epoch [1273/3000], Step [30/158]| g_loss: 0.754| d_loss: 0.766| gp_loss: 0.152| r_loss: 0.087| p_loss: 0.143| v_loss: 0.029| per_loss: 0.481 | a_loss: 0.518
Train: Epoch [1273/3000], Step [60/158]| g_loss: 0.801| d_loss: 0.575| gp_loss: 0.054| r_loss: 0.083| p_loss: 0.131| v_loss: 0.029| per_loss: 0.521 | a_loss: 0.572
Train: Epoch [1273/3000], Step [90/158]| g_loss: 0.780| d_loss: 0.605| gp_loss: 0.055| r_loss: 0.083| p_loss: 0.134| v_loss: 0.029| per_loss: 0.470 | a_loss: 0.554
Train: Epoch [1273/3000], Step [120/158]| g_loss: 0.799| d_loss: 0.548| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.135| v_loss: 0.029| per_loss: 0.522 | a_loss: 0.565
Train: Epoch [1273/3000], Step [150/158]| g_loss: 0.834| d_loss: 0.592| gp_loss: 0.059| r_loss: 0.086| p_loss: 0.135| v_loss: 0.029| per_loss: 0.470 | a_loss: 0.605
Train: Epoch [1274/3000], Step [30/158]| g_loss: 0.805| d_loss: 0.594| gp_loss: 0.133| r_loss: 0.082| p_loss: 0.129| v_loss: 0.029| per_loss: 0.480 | a_loss: 0.581
Train: Epoch [1274/3000], Step [60/158]| g_loss: 0.762| d_loss: 0.601| gp_loss: 0.053| r_loss: 0.081| p_loss: 0.127| v_loss: 0.030| per_loss: 0.477 | a_loss: 0.539
Train: Epoch [1274/3000], Step [90/158]| g_loss: 0.758| d_loss: 0.566| gp_loss: 0.057| r_loss: 0.083| p_loss: 0.123| v_loss: 0.030| per_loss: 0.501 | a_loss: 0.534
Train: Epoch [1274/3000], Step [120/158]| g_loss: 0.790| d_loss: 0.614| gp_loss: 0.053| r_loss: 0.082| p_loss: 0.130| v_loss: 0.030| per_loss: 0.497 | a_loss: 0.564
Train: Epoch [1274/3000], Step [150/158]| g_loss: 0.717| d_loss: 0.650| gp_loss: 0.057| r_loss: 0.080| p_loss: 0.128| v_loss: 0.029| per_loss: 0.468 | a_loss: 0.496
Train: Epoch [1275/3000], Step [30/158]| g_loss: 0.752| d_loss: 0.744| gp_loss: 0.149| r_loss: 0.081| p_loss: 0.126| v_loss: 0.027| per_loss: 0.515 | a_loss: 0.530
Train: Epoch [1275/3000], Step [60/158]| g_loss: 0.778| d_loss: 0.524| gp_loss: 0.057| r_loss: 0.080| p_loss: 0.127| v_loss: 0.030| per_loss: 0.498 | a_loss: 0.555
Train: Epoch [1275/3000], Step [90/158]| g_loss: 0.796| d_loss: 0.526| gp_loss: 0.060| r_loss: 0.083| p_loss: 0.129| v_loss: 0.030| per_loss: 0.472 | a_loss: 0.571
Train: Epoch [1275/3000], Step [120/158]| g_loss: 0.777| d_loss: 0.602| gp_loss: 0.056| r_loss: 0.082| p_loss: 0.132| v_loss: 0.030| per_loss: 0.480 | a_loss: 0.551
Train: Epoch [1275/3000], Step [150/158]| g_loss: 0.751| d_loss: 0.644| gp_loss: 0.055| r_loss: 0.084| p_loss: 0.131| v_loss: 0.028| per_loss: 0.469 | a_loss: 0.527
Train: Epoch [1276/3000], Step [30/158]| g_loss: 0.763| d_loss: 0.699| gp_loss: 0.138| r_loss: 0.085| p_loss: 0.136| v_loss: 0.030| per_loss: 0.509 | a_loss: 0.529
Train: Epoch [1276/3000], Step [60/158]| g_loss: 0.827| d_loss: 0.512| gp_loss: 0.055| r_loss: 0.080| p_loss: 0.131| v_loss: 0.028| per_loss: 0.506 | a_loss: 0.603
Train: Epoch [1276/3000], Step [90/158]| g_loss: 0.797| d_loss: 0.574| gp_loss: 0.058| r_loss: 0.089| p_loss: 0.136| v_loss: 0.030| per_loss: 0.462 | a_loss: 0.564
Train: Epoch [1276/3000], Step [120/158]| g_loss: 0.740| d_loss: 0.657| gp_loss: 0.059| r_loss: 0.081| p_loss: 0.133| v_loss: 0.029| per_loss: 0.435 | a_loss: 0.520
Train: Epoch [1276/3000], Step [150/158]| g_loss: 0.784| d_loss: 0.603| gp_loss: 0.059| r_loss: 0.088| p_loss: 0.140| v_loss: 0.030| per_loss: 0.504 | a_loss: 0.546
Train: Epoch [1277/3000], Step [30/158]| g_loss: 0.834| d_loss: 0.666| gp_loss: 0.169| r_loss: 0.086| p_loss: 0.140| v_loss: 0.030| per_loss: 0.487 | a_loss: 0.599
Train: Epoch [1277/3000], Step [60/158]| g_loss: 0.794| d_loss: 0.628| gp_loss: 0.054| r_loss: 0.084| p_loss: 0.138| v_loss: 0.029| per_loss: 0.493 | a_loss: 0.563
Train: Epoch [1277/3000], Step [90/158]| g_loss: 0.760| d_loss: 0.556| gp_loss: 0.059| r_loss: 0.083| p_loss: 0.132| v_loss: 0.029| per_loss: 0.464 | a_loss: 0.535
Train: Epoch [1277/3000], Step [120/158]| g_loss: 0.789| d_loss: 0.528| gp_loss: 0.055| r_loss: 0.080| p_loss: 0.124| v_loss: 0.027| per_loss: 0.491 | a_loss: 0.571
Train: Epoch [1277/3000], Step [150/158]| g_loss: 0.753| d_loss: 0.688| gp_loss: 0.057| r_loss: 0.083| p_loss: 0.128| v_loss: 0.028| per_loss: 0.479 | a_loss: 0.530
Train: Epoch [1278/3000], Step [30/158]| g_loss: 0.810| d_loss: 0.691| gp_loss: 0.176| r_loss: 0.085| p_loss: 0.137| v_loss: 0.030| per_loss: 0.446 | a_loss: 0.582
Train: Epoch [1278/3000], Step [60/158]| g_loss: 0.781| d_loss: 0.628| gp_loss: 0.051| r_loss: 0.086| p_loss: 0.136| v_loss: 0.030| per_loss: 0.466 | a_loss: 0.550
Train: Epoch [1278/3000], Step [90/158]| g_loss: 0.713| d_loss: 0.598| gp_loss: 0.054| r_loss: 0.080| p_loss: 0.125| v_loss: 0.029| per_loss: 0.515 | a_loss: 0.491
Train: Epoch [1278/3000], Step [120/158]| g_loss: 0.719| d_loss: 0.710| gp_loss: 0.057| r_loss: 0.082| p_loss: 0.137| v_loss: 0.030| per_loss: 0.470 | a_loss: 0.492
Train: Epoch [1278/3000], Step [150/158]| g_loss: 0.809| d_loss: 0.551| gp_loss: 0.060| r_loss: 0.085| p_loss: 0.134| v_loss: 0.029| per_loss: 0.497 | a_loss: 0.578
Train: Epoch [1279/3000], Step [30/158]| g_loss: 0.865| d_loss: 0.644| gp_loss: 0.189| r_loss: 0.084| p_loss: 0.135| v_loss: 0.028| per_loss: 0.483 | a_loss: 0.637
Train: Epoch [1279/3000], Step [60/158]| g_loss: 0.757| d_loss: 0.633| gp_loss: 0.052| r_loss: 0.080| p_loss: 0.129| v_loss: 0.027| per_loss: 0.477 | a_loss: 0.538
Train: Epoch [1279/3000], Step [90/158]| g_loss: 0.770| d_loss: 0.609| gp_loss: 0.056| r_loss: 0.082| p_loss: 0.130| v_loss: 0.029| per_loss: 0.484 | a_loss: 0.546
Train: Epoch [1279/3000], Step [120/158]| g_loss: 0.776| d_loss: 0.579| gp_loss: 0.055| r_loss: 0.079| p_loss: 0.123| v_loss: 0.028| per_loss: 0.478 | a_loss: 0.559
Train: Epoch [1279/3000], Step [150/158]| g_loss: 0.730| d_loss: 0.664| gp_loss: 0.056| r_loss: 0.084| p_loss: 0.130| v_loss: 0.029| per_loss: 0.471 | a_loss: 0.505
Train: Epoch [1280/3000], Step [30/158]| g_loss: 0.772| d_loss: 0.648| gp_loss: 0.135| r_loss: 0.080| p_loss: 0.126| v_loss: 0.029| per_loss: 0.494 | a_loss: 0.551
Train: Epoch [1280/3000], Step [60/158]| g_loss: 0.773| d_loss: 0.582| gp_loss: 0.054| r_loss: 0.087| p_loss: 0.140| v_loss: 0.030| per_loss: 0.487 | a_loss: 0.537
Train: Epoch [1280/3000], Step [90/158]| g_loss: 0.838| d_loss: 0.543| gp_loss: 0.060| r_loss: 0.082| p_loss: 0.136| v_loss: 0.029| per_loss: 0.487 | a_loss: 0.611
Train: Epoch [1280/3000], Step [120/158]| g_loss: 0.767| d_loss: 0.605| gp_loss: 0.055| r_loss: 0.080| p_loss: 0.128| v_loss: 0.029| per_loss: 0.449 | a_loss: 0.549
Train: Epoch [1280/3000], Step [150/158]| g_loss: 0.738| d_loss: 0.636| gp_loss: 0.058| r_loss: 0.080| p_loss: 0.126| v_loss: 0.027| per_loss: 0.485 | a_loss: 0.520
Train: Epoch [1281/3000], Step [30/158]| g_loss: 0.732| d_loss: 0.800| gp_loss: 0.208| r_loss: 0.081| p_loss: 0.131| v_loss: 0.029| per_loss: 0.467 | a_loss: 0.509
Train: Epoch [1281/3000], Step [60/158]| g_loss: 0.849| d_loss: 0.565| gp_loss: 0.053| r_loss: 0.084| p_loss: 0.135| v_loss: 0.029| per_loss: 0.496 | a_loss: 0.619
Train: Epoch [1281/3000], Step [90/158]| g_loss: 0.745| d_loss: 0.604| gp_loss: 0.053| r_loss: 0.080| p_loss: 0.123| v_loss: 0.028| per_loss: 0.486 | a_loss: 0.527
Train: Epoch [1281/3000], Step [120/158]| g_loss: 0.829| d_loss: 0.567| gp_loss: 0.061| r_loss: 0.079| p_loss: 0.128| v_loss: 0.029| per_loss: 0.487 | a_loss: 0.608
Train: Epoch [1281/3000], Step [150/158]| g_loss: 0.705| d_loss: 0.610| gp_loss: 0.053| r_loss: 0.080| p_loss: 0.120| v_loss: 0.028| per_loss: 0.477 | a_loss: 0.489
Train: Epoch [1282/3000], Step [30/158]| g_loss: 0.764| d_loss: 0.767| gp_loss: 0.195| r_loss: 0.080| p_loss: 0.129| v_loss: 0.029| per_loss: 0.462 | a_loss: 0.544
Train: Epoch [1282/3000], Step [60/158]| g_loss: 0.811| d_loss: 0.593| gp_loss: 0.055| r_loss: 0.082| p_loss: 0.127| v_loss: 0.029| per_loss: 0.493 | a_loss: 0.588
Train: Epoch [1282/3000], Step [90/158]| g_loss: 0.739| d_loss: 0.569| gp_loss: 0.051| r_loss: 0.084| p_loss: 0.130| v_loss: 0.030| per_loss: 0.496 | a_loss: 0.511
Train: Epoch [1282/3000], Step [120/158]| g_loss: 0.787| d_loss: 0.591| gp_loss: 0.054| r_loss: 0.079| p_loss: 0.123| v_loss: 0.027| per_loss: 0.514 | a_loss: 0.568
Train: Epoch [1282/3000], Step [150/158]| g_loss: 0.793| d_loss: 0.588| gp_loss: 0.060| r_loss: 0.079| p_loss: 0.127| v_loss: 0.027| per_loss: 0.454 | a_loss: 0.577
Train: Epoch [1283/3000], Step [30/158]| g_loss: 0.800| d_loss: 0.676| gp_loss: 0.171| r_loss: 0.080| p_loss: 0.128| v_loss: 0.028| per_loss: 0.515 | a_loss: 0.576
Train: Epoch [1283/3000], Step [60/158]| g_loss: 0.765| d_loss: 0.625| gp_loss: 0.051| r_loss: 0.082| p_loss: 0.131| v_loss: 0.027| per_loss: 0.487 | a_loss: 0.541
Train: Epoch [1283/3000], Step [90/158]| g_loss: 0.709| d_loss: 0.686| gp_loss: 0.051| r_loss: 0.080| p_loss: 0.131| v_loss: 0.028| per_loss: 0.468 | a_loss: 0.489
Train: Epoch [1283/3000], Step [120/158]| g_loss: 0.821| d_loss: 0.506| gp_loss: 0.056| r_loss: 0.080| p_loss: 0.126| v_loss: 0.030| per_loss: 0.477 | a_loss: 0.600
Train: Epoch [1283/3000], Step [150/158]| g_loss: 0.767| d_loss: 0.605| gp_loss: 0.056| r_loss: 0.082| p_loss: 0.128| v_loss: 0.029| per_loss: 0.505 | a_loss: 0.542
Train: Epoch [1284/3000], Step [30/158]| g_loss: 0.770| d_loss: 0.654| gp_loss: 0.167| r_loss: 0.080| p_loss: 0.126| v_loss: 0.029| per_loss: 0.443 | a_loss: 0.554
Train: Epoch [1284/3000], Step [60/158]| g_loss: 0.780| d_loss: 0.625| gp_loss: 0.053| r_loss: 0.078| p_loss: 0.126| v_loss: 0.028| per_loss: 0.474 | a_loss: 0.563
Train: Epoch [1284/3000], Step [90/158]| g_loss: 0.790| d_loss: 0.555| gp_loss: 0.053| r_loss: 0.080| p_loss: 0.126| v_loss: 0.028| per_loss: 0.491 | a_loss: 0.569
Train: Epoch [1284/3000], Step [120/158]| g_loss: 0.734| d_loss: 0.650| gp_loss: 0.055| r_loss: 0.084| p_loss: 0.130| v_loss: 0.029| per_loss: 0.480 | a_loss: 0.508
Train: Epoch [1284/3000], Step [150/158]| g_loss: 0.797| d_loss: 0.566| gp_loss: 0.058| r_loss: 0.079| p_loss: 0.125| v_loss: 0.029| per_loss: 0.495 | a_loss: 0.577
Train: Epoch [1285/3000], Step [30/158]| g_loss: 0.726| d_loss: 0.772| gp_loss: 0.153| r_loss: 0.082| p_loss: 0.132| v_loss: 0.029| per_loss: 0.507 | a_loss: 0.498
Train: Epoch [1285/3000], Step [60/158]| g_loss: 0.883| d_loss: 0.417| gp_loss: 0.052| r_loss: 0.078| p_loss: 0.122| v_loss: 0.029| per_loss: 0.506 | a_loss: 0.664
Train: Epoch [1285/3000], Step [90/158]| g_loss: 0.728| d_loss: 0.668| gp_loss: 0.052| r_loss: 0.082| p_loss: 0.131| v_loss: 0.028| per_loss: 0.454 | a_loss: 0.507
Train: Epoch [1285/3000], Step [120/158]| g_loss: 0.792| d_loss: 0.602| gp_loss: 0.054| r_loss: 0.086| p_loss: 0.135| v_loss: 0.029| per_loss: 0.475 | a_loss: 0.562
Train: Epoch [1285/3000], Step [150/158]| g_loss: 0.744| d_loss: 0.656| gp_loss: 0.055| r_loss: 0.081| p_loss: 0.127| v_loss: 0.029| per_loss: 0.463 | a_loss: 0.524
Train: Epoch [1286/3000], Step [30/158]| g_loss: 0.768| d_loss: 0.760| gp_loss: 0.192| r_loss: 0.084| p_loss: 0.129| v_loss: 0.029| per_loss: 0.449 | a_loss: 0.546
Train: Epoch [1286/3000], Step [60/158]| g_loss: 0.818| d_loss: 0.506| gp_loss: 0.054| r_loss: 0.081| p_loss: 0.130| v_loss: 0.028| per_loss: 0.495 | a_loss: 0.594
Train: Epoch [1286/3000], Step [90/158]| g_loss: 0.803| d_loss: 0.521| gp_loss: 0.049| r_loss: 0.078| p_loss: 0.127| v_loss: 0.028| per_loss: 0.466 | a_loss: 0.586
Train: Epoch [1286/3000], Step [120/158]| g_loss: 0.772| d_loss: 0.627| gp_loss: 0.052| r_loss: 0.081| p_loss: 0.125| v_loss: 0.028| per_loss: 0.508 | a_loss: 0.549
Train: Epoch [1286/3000], Step [150/158]| g_loss: 0.795| d_loss: 0.580| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.129| v_loss: 0.029| per_loss: 0.476 | a_loss: 0.570
Train: Epoch [1287/3000], Step [30/158]| g_loss: 0.721| d_loss: 0.761| gp_loss: 0.151| r_loss: 0.080| p_loss: 0.127| v_loss: 0.028| per_loss: 0.495 | a_loss: 0.499
Train: Epoch [1287/3000], Step [60/158]| g_loss: 0.794| d_loss: 0.567| gp_loss: 0.055| r_loss: 0.082| p_loss: 0.128| v_loss: 0.029| per_loss: 0.481 | a_loss: 0.571
Train: Epoch [1287/3000], Step [90/158]| g_loss: 0.846| d_loss: 0.508| gp_loss: 0.057| r_loss: 0.082| p_loss: 0.133| v_loss: 0.029| per_loss: 0.513 | a_loss: 0.617
Train: Epoch [1287/3000], Step [120/158]| g_loss: 0.773| d_loss: 0.571| gp_loss: 0.055| r_loss: 0.085| p_loss: 0.135| v_loss: 0.027| per_loss: 0.492 | a_loss: 0.544
Train: Epoch [1287/3000], Step [150/158]| g_loss: 0.775| d_loss: 0.606| gp_loss: 0.055| r_loss: 0.084| p_loss: 0.133| v_loss: 0.029| per_loss: 0.512 | a_loss: 0.544
Train: Epoch [1288/3000], Step [30/158]| g_loss: 0.767| d_loss: 0.713| gp_loss: 0.178| r_loss: 0.082| p_loss: 0.133| v_loss: 0.028| per_loss: 0.511 | a_loss: 0.539
Train: Epoch [1288/3000], Step [60/158]| g_loss: 0.813| d_loss: 0.561| gp_loss: 0.053| r_loss: 0.083| p_loss: 0.136| v_loss: 0.029| per_loss: 0.504 | a_loss: 0.583
Train: Epoch [1288/3000], Step [90/158]| g_loss: 0.872| d_loss: 0.563| gp_loss: 0.051| r_loss: 0.093| p_loss: 0.157| v_loss: 0.030| per_loss: 0.508 | a_loss: 0.621
Train: Epoch [1288/3000], Step [120/158]| g_loss: 0.814| d_loss: 0.614| gp_loss: 0.054| r_loss: 0.101| p_loss: 0.183| v_loss: 0.029| per_loss: 0.549 | a_loss: 0.537
Train: Epoch [1288/3000], Step [150/158]| g_loss: 0.813| d_loss: 0.583| gp_loss: 0.055| r_loss: 0.092| p_loss: 0.152| v_loss: 0.029| per_loss: 0.498 | a_loss: 0.566
Train: Epoch [1289/3000], Step [30/158]| g_loss: 0.820| d_loss: 0.665| gp_loss: 0.196| r_loss: 0.087| p_loss: 0.144| v_loss: 0.030| per_loss: 0.478 | a_loss: 0.584
Train: Epoch [1289/3000], Step [60/158]| g_loss: 0.784| d_loss: 0.646| gp_loss: 0.048| r_loss: 0.083| p_loss: 0.135| v_loss: 0.029| per_loss: 0.551 | a_loss: 0.550
Train: Epoch [1289/3000], Step [90/158]| g_loss: 0.725| d_loss: 0.641| gp_loss: 0.052| r_loss: 0.084| p_loss: 0.136| v_loss: 0.029| per_loss: 0.490 | a_loss: 0.495
Train: Epoch [1289/3000], Step [120/158]| g_loss: 0.766| d_loss: 0.555| gp_loss: 0.053| r_loss: 0.080| p_loss: 0.125| v_loss: 0.029| per_loss: 0.524 | a_loss: 0.543
Train: Epoch [1289/3000], Step [150/158]| g_loss: 0.861| d_loss: 0.545| gp_loss: 0.052| r_loss: 0.085| p_loss: 0.139| v_loss: 0.029| per_loss: 0.530 | a_loss: 0.625
Train: Epoch [1290/3000], Step [30/158]| g_loss: 0.803| d_loss: 0.698| gp_loss: 0.169| r_loss: 0.083| p_loss: 0.134| v_loss: 0.030| per_loss: 0.492 | a_loss: 0.574
Train: Epoch [1290/3000], Step [60/158]| g_loss: 0.779| d_loss: 0.551| gp_loss: 0.053| r_loss: 0.085| p_loss: 0.132| v_loss: 0.030| per_loss: 0.498 | a_loss: 0.549
Train: Epoch [1290/3000], Step [90/158]| g_loss: 0.775| d_loss: 0.590| gp_loss: 0.053| r_loss: 0.083| p_loss: 0.134| v_loss: 0.030| per_loss: 0.516 | a_loss: 0.543
Train: Epoch [1290/3000], Step [120/158]| g_loss: 0.774| d_loss: 0.611| gp_loss: 0.055| r_loss: 0.083| p_loss: 0.131| v_loss: 0.029| per_loss: 0.508 | a_loss: 0.545
Train: Epoch [1290/3000], Step [150/158]| g_loss: 0.771| d_loss: 0.594| gp_loss: 0.054| r_loss: 0.086| p_loss: 0.135| v_loss: 0.029| per_loss: 0.484 | a_loss: 0.541
Train: Epoch [1291/3000], Step [30/158]| g_loss: 0.773| d_loss: 0.659| gp_loss: 0.160| r_loss: 0.088| p_loss: 0.136| v_loss: 0.029| per_loss: 0.481 | a_loss: 0.541
Train: Epoch [1291/3000], Step [60/158]| g_loss: 0.750| d_loss: 0.621| gp_loss: 0.053| r_loss: 0.083| p_loss: 0.130| v_loss: 0.028| per_loss: 0.483 | a_loss: 0.526
Train: Epoch [1291/3000], Step [90/158]| g_loss: 0.731| d_loss: 0.610| gp_loss: 0.054| r_loss: 0.080| p_loss: 0.124| v_loss: 0.028| per_loss: 0.480 | a_loss: 0.514
Train: Epoch [1291/3000], Step [120/158]| g_loss: 0.841| d_loss: 0.580| gp_loss: 0.056| r_loss: 0.084| p_loss: 0.132| v_loss: 0.029| per_loss: 0.467 | a_loss: 0.615
Train: Epoch [1291/3000], Step [150/158]| g_loss: 0.789| d_loss: 0.589| gp_loss: 0.057| r_loss: 0.084| p_loss: 0.130| v_loss: 0.030| per_loss: 0.486 | a_loss: 0.561
Train: Epoch [1292/3000], Step [30/158]| g_loss: 0.769| d_loss: 0.816| gp_loss: 0.247| r_loss: 0.082| p_loss: 0.133| v_loss: 0.029| per_loss: 0.499 | a_loss: 0.542
Train: Epoch [1292/3000], Step [60/158]| g_loss: 0.797| d_loss: 0.550| gp_loss: 0.052| r_loss: 0.083| p_loss: 0.134| v_loss: 0.029| per_loss: 0.498 | a_loss: 0.568
Train: Epoch [1292/3000], Step [90/158]| g_loss: 0.784| d_loss: 0.568| gp_loss: 0.050| r_loss: 0.084| p_loss: 0.131| v_loss: 0.029| per_loss: 0.530 | a_loss: 0.553
Train: Epoch [1292/3000], Step [120/158]| g_loss: 0.784| d_loss: 0.628| gp_loss: 0.054| r_loss: 0.088| p_loss: 0.138| v_loss: 0.030| per_loss: 0.463 | a_loss: 0.551
Train: Epoch [1292/3000], Step [150/158]| g_loss: 0.750| d_loss: 0.596| gp_loss: 0.053| r_loss: 0.081| p_loss: 0.134| v_loss: 0.029| per_loss: 0.445 | a_loss: 0.528
Train: Epoch [1293/3000], Step [30/158]| g_loss: 0.781| d_loss: 0.675| gp_loss: 0.129| r_loss: 0.081| p_loss: 0.134| v_loss: 0.028| per_loss: 0.477 | a_loss: 0.557
Train: Epoch [1293/3000], Step [60/158]| g_loss: 0.788| d_loss: 0.566| gp_loss: 0.054| r_loss: 0.082| p_loss: 0.129| v_loss: 0.029| per_loss: 0.524 | a_loss: 0.561
Train: Epoch [1293/3000], Step [90/158]| g_loss: 0.693| d_loss: 0.738| gp_loss: 0.053| r_loss: 0.081| p_loss: 0.128| v_loss: 0.028| per_loss: 0.433 | a_loss: 0.477
Train: Epoch [1293/3000], Step [120/158]| g_loss: 0.823| d_loss: 0.529| gp_loss: 0.055| r_loss: 0.081| p_loss: 0.126| v_loss: 0.029| per_loss: 0.498 | a_loss: 0.600
Train: Epoch [1293/3000], Step [150/158]| g_loss: 0.750| d_loss: 0.619| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.131| v_loss: 0.029| per_loss: 0.467 | a_loss: 0.525
Train: Epoch [1294/3000], Step [30/158]| g_loss: 0.784| d_loss: 0.684| gp_loss: 0.166| r_loss: 0.091| p_loss: 0.135| v_loss: 0.029| per_loss: 0.473 | a_loss: 0.548
Train: Epoch [1294/3000], Step [60/158]| g_loss: 0.827| d_loss: 0.585| gp_loss: 0.050| r_loss: 0.083| p_loss: 0.133| v_loss: 0.029| per_loss: 0.460 | a_loss: 0.603
Train: Epoch [1294/3000], Step [90/158]| g_loss: 0.773| d_loss: 0.581| gp_loss: 0.051| r_loss: 0.081| p_loss: 0.130| v_loss: 0.030| per_loss: 0.485 | a_loss: 0.549
Train: Epoch [1294/3000], Step [120/158]| g_loss: 0.814| d_loss: 0.547| gp_loss: 0.053| r_loss: 0.083| p_loss: 0.129| v_loss: 0.030| per_loss: 0.497 | a_loss: 0.586
Train: Epoch [1294/3000], Step [150/158]| g_loss: 0.694| d_loss: 0.672| gp_loss: 0.057| r_loss: 0.082| p_loss: 0.127| v_loss: 0.029| per_loss: 0.450 | a_loss: 0.475
Train: Epoch [1295/3000], Step [30/158]| g_loss: 0.725| d_loss: 0.740| gp_loss: 0.086| r_loss: 0.082| p_loss: 0.134| v_loss: 0.028| per_loss: 0.482 | a_loss: 0.499
Train: Epoch [1295/3000], Step [60/158]| g_loss: 0.833| d_loss: 0.568| gp_loss: 0.059| r_loss: 0.085| p_loss: 0.138| v_loss: 0.030| per_loss: 0.485 | a_loss: 0.600
Train: Epoch [1295/3000], Step [90/158]| g_loss: 0.764| d_loss: 0.611| gp_loss: 0.059| r_loss: 0.081| p_loss: 0.134| v_loss: 0.028| per_loss: 0.517 | a_loss: 0.536
Train: Epoch [1295/3000], Step [120/158]| g_loss: 0.783| d_loss: 0.551| gp_loss: 0.059| r_loss: 0.081| p_loss: 0.130| v_loss: 0.028| per_loss: 0.451 | a_loss: 0.563
Train: Epoch [1295/3000], Step [150/158]| g_loss: 0.782| d_loss: 0.576| gp_loss: 0.060| r_loss: 0.083| p_loss: 0.131| v_loss: 0.030| per_loss: 0.465 | a_loss: 0.558
Train: Epoch [1296/3000], Step [30/158]| g_loss: 0.825| d_loss: 0.702| gp_loss: 0.196| r_loss: 0.084| p_loss: 0.132| v_loss: 0.031| per_loss: 0.463 | a_loss: 0.599
Train: Epoch [1296/3000], Step [60/158]| g_loss: 0.786| d_loss: 0.566| gp_loss: 0.053| r_loss: 0.083| p_loss: 0.124| v_loss: 0.030| per_loss: 0.470 | a_loss: 0.564
Train: Epoch [1296/3000], Step [90/158]| g_loss: 0.823| d_loss: 0.527| gp_loss: 0.052| r_loss: 0.082| p_loss: 0.125| v_loss: 0.031| per_loss: 0.509 | a_loss: 0.597
Train: Epoch [1296/3000], Step [120/158]| g_loss: 0.770| d_loss: 0.595| gp_loss: 0.052| r_loss: 0.078| p_loss: 0.122| v_loss: 0.029| per_loss: 0.504 | a_loss: 0.552
Train: Epoch [1296/3000], Step [150/158]| g_loss: 0.734| d_loss: 0.682| gp_loss: 0.057| r_loss: 0.079| p_loss: 0.126| v_loss: 0.028| per_loss: 0.431 | a_loss: 0.521
Train: Epoch [1297/3000], Step [30/158]| g_loss: 0.792| d_loss: 0.596| gp_loss: 0.126| r_loss: 0.079| p_loss: 0.123| v_loss: 0.030| per_loss: 0.471 | a_loss: 0.575
Train: Epoch [1297/3000], Step [60/158]| g_loss: 0.770| d_loss: 0.589| gp_loss: 0.055| r_loss: 0.078| p_loss: 0.122| v_loss: 0.028| per_loss: 0.469 | a_loss: 0.555
Train: Epoch [1297/3000], Step [90/158]| g_loss: 0.753| d_loss: 0.588| gp_loss: 0.054| r_loss: 0.079| p_loss: 0.119| v_loss: 0.028| per_loss: 0.511 | a_loss: 0.535
Train: Epoch [1297/3000], Step [120/158]| g_loss: 0.774| d_loss: 0.592| gp_loss: 0.059| r_loss: 0.080| p_loss: 0.125| v_loss: 0.030| per_loss: 0.471 | a_loss: 0.554
Train: Epoch [1297/3000], Step [150/158]| g_loss: 0.801| d_loss: 0.634| gp_loss: 0.056| r_loss: 0.081| p_loss: 0.128| v_loss: 0.030| per_loss: 0.496 | a_loss: 0.576
Train: Epoch [1298/3000], Step [30/158]| g_loss: 0.746| d_loss: 0.666| gp_loss: 0.142| r_loss: 0.082| p_loss: 0.133| v_loss: 0.031| per_loss: 0.485 | a_loss: 0.518
Train: Epoch [1298/3000], Step [60/158]| g_loss: 0.791| d_loss: 0.593| gp_loss: 0.055| r_loss: 0.079| p_loss: 0.124| v_loss: 0.029| per_loss: 0.490 | a_loss: 0.572
Train: Epoch [1298/3000], Step [90/158]| g_loss: 0.739| d_loss: 0.663| gp_loss: 0.060| r_loss: 0.082| p_loss: 0.129| v_loss: 0.029| per_loss: 0.474 | a_loss: 0.517
Train: Epoch [1298/3000], Step [120/158]| g_loss: 0.737| d_loss: 0.570| gp_loss: 0.061| r_loss: 0.079| p_loss: 0.127| v_loss: 0.029| per_loss: 0.486 | a_loss: 0.517
Train: Epoch [1298/3000], Step [150/158]| g_loss: 0.783| d_loss: 0.565| gp_loss: 0.060| r_loss: 0.083| p_loss: 0.129| v_loss: 0.029| per_loss: 0.473 | a_loss: 0.559
Train: Epoch [1299/3000], Step [30/158]| g_loss: 0.839| d_loss: 0.579| gp_loss: 0.129| r_loss: 0.082| p_loss: 0.133| v_loss: 0.030| per_loss: 0.461 | a_loss: 0.614
Train: Epoch [1299/3000], Step [60/158]| g_loss: 0.758| d_loss: 0.626| gp_loss: 0.058| r_loss: 0.085| p_loss: 0.134| v_loss: 0.030| per_loss: 0.463 | a_loss: 0.529
Train: Epoch [1299/3000], Step [90/158]| g_loss: 0.819| d_loss: 0.505| gp_loss: 0.056| r_loss: 0.078| p_loss: 0.124| v_loss: 0.030| per_loss: 0.466 | a_loss: 0.602
Train: Epoch [1299/3000], Step [120/158]| g_loss: 0.752| d_loss: 0.573| gp_loss: 0.060| r_loss: 0.080| p_loss: 0.124| v_loss: 0.029| per_loss: 0.510 | a_loss: 0.530
Train: Epoch [1299/3000], Step [150/158]| g_loss: 0.764| d_loss: 0.652| gp_loss: 0.058| r_loss: 0.078| p_loss: 0.125| v_loss: 0.028| per_loss: 0.496 | a_loss: 0.546
Train: Epoch [1300/3000], Step [30/158]| g_loss: 0.800| d_loss: 0.655| gp_loss: 0.165| r_loss: 0.081| p_loss: 0.127| v_loss: 0.030| per_loss: 0.461 | a_loss: 0.579
Train: Epoch [1300/3000], Step [60/158]| g_loss: 0.789| d_loss: 0.589| gp_loss: 0.055| r_loss: 0.078| p_loss: 0.125| v_loss: 0.029| per_loss: 0.489 | a_loss: 0.570
Train: Epoch [1300/3000], Step [90/158]| g_loss: 0.731| d_loss: 0.573| gp_loss: 0.056| r_loss: 0.080| p_loss: 0.120| v_loss: 0.030| per_loss: 0.478 | a_loss: 0.514
Train: Epoch [1300/3000], Step [120/158]| g_loss: 0.753| d_loss: 0.590| gp_loss: 0.060| r_loss: 0.081| p_loss: 0.127| v_loss: 0.030| per_loss: 0.461 | a_loss: 0.533
Train: Epoch [1300/3000], Step [150/158]| g_loss: 0.790| d_loss: 0.574| gp_loss: 0.060| r_loss: 0.078| p_loss: 0.122| v_loss: 0.028| per_loss: 0.522 | a_loss: 0.570
Test: Epoch [1300/3000]| g_loss: 0.629| r_loss: 0.395| p_loss: 0.296| v_loss: 0.026
Train: Epoch [1301/3000], Step [30/158]| g_loss: 0.695| d_loss: 0.658| gp_loss: 0.063| r_loss: 0.085| p_loss: 0.140| v_loss: 0.030| per_loss: 0.509 | a_loss: 0.459
Train: Epoch [1301/3000], Step [60/158]| g_loss: 0.799| d_loss: 0.574| gp_loss: 0.061| r_loss: 0.083| p_loss: 0.132| v_loss: 0.031| per_loss: 0.477 | a_loss: 0.571
Train: Epoch [1301/3000], Step [90/158]| g_loss: 0.823| d_loss: 0.489| gp_loss: 0.065| r_loss: 0.083| p_loss: 0.134| v_loss: 0.029| per_loss: 0.489 | a_loss: 0.595
Train: Epoch [1301/3000], Step [120/158]| g_loss: 0.810| d_loss: 0.539| gp_loss: 0.062| r_loss: 0.083| p_loss: 0.134| v_loss: 0.032| per_loss: 0.483 | a_loss: 0.580
Train: Epoch [1301/3000], Step [150/158]| g_loss: 0.785| d_loss: 0.585| gp_loss: 0.063| r_loss: 0.080| p_loss: 0.132| v_loss: 0.030| per_loss: 0.497 | a_loss: 0.559
Train: Epoch [1302/3000], Step [30/158]| g_loss: 0.822| d_loss: 0.650| gp_loss: 0.163| r_loss: 0.086| p_loss: 0.137| v_loss: 0.032| per_loss: 0.523 | a_loss: 0.584
Train: Epoch [1302/3000], Step [60/158]| g_loss: 0.825| d_loss: 0.503| gp_loss: 0.063| r_loss: 0.082| p_loss: 0.135| v_loss: 0.032| per_loss: 0.446 | a_loss: 0.599
Train: Epoch [1302/3000], Step [90/158]| g_loss: 0.860| d_loss: 0.584| gp_loss: 0.062| r_loss: 0.083| p_loss: 0.131| v_loss: 0.030| per_loss: 0.483 | a_loss: 0.633
Train: Epoch [1302/3000], Step [120/158]| g_loss: 0.727| d_loss: 0.581| gp_loss: 0.064| r_loss: 0.084| p_loss: 0.138| v_loss: 0.031| per_loss: 0.506 | a_loss: 0.492
Train: Epoch [1302/3000], Step [150/158]| g_loss: 0.763| d_loss: 0.660| gp_loss: 0.064| r_loss: 0.082| p_loss: 0.137| v_loss: 0.029| per_loss: 0.522 | a_loss: 0.530
Train: Epoch [1303/3000], Step [30/158]| g_loss: 0.781| d_loss: 0.716| gp_loss: 0.180| r_loss: 0.084| p_loss: 0.135| v_loss: 0.030| per_loss: 0.484 | a_loss: 0.551
Train: Epoch [1303/3000], Step [60/158]| g_loss: 0.791| d_loss: 0.562| gp_loss: 0.063| r_loss: 0.088| p_loss: 0.143| v_loss: 0.030| per_loss: 0.493 | a_loss: 0.553
Train: Epoch [1303/3000], Step [90/158]| g_loss: 0.798| d_loss: 0.553| gp_loss: 0.058| r_loss: 0.085| p_loss: 0.138| v_loss: 0.029| per_loss: 0.462 | a_loss: 0.568
Train: Epoch [1303/3000], Step [120/158]| g_loss: 0.790| d_loss: 0.595| gp_loss: 0.059| r_loss: 0.083| p_loss: 0.133| v_loss: 0.029| per_loss: 0.518 | a_loss: 0.560
Train: Epoch [1303/3000], Step [150/158]| g_loss: 0.780| d_loss: 0.649| gp_loss: 0.060| r_loss: 0.084| p_loss: 0.137| v_loss: 0.030| per_loss: 0.456 | a_loss: 0.552
Train: Epoch [1304/3000], Step [30/158]| g_loss: 0.745| d_loss: 0.735| gp_loss: 0.162| r_loss: 0.082| p_loss: 0.128| v_loss: 0.030| per_loss: 0.468 | a_loss: 0.523
Train: Epoch [1304/3000], Step [60/158]| g_loss: 0.841| d_loss: 0.489| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.131| v_loss: 0.031| per_loss: 0.467 | a_loss: 0.614
Train: Epoch [1304/3000], Step [90/158]| g_loss: 0.795| d_loss: 0.574| gp_loss: 0.058| r_loss: 0.081| p_loss: 0.130| v_loss: 0.031| per_loss: 0.479 | a_loss: 0.570
Train: Epoch [1304/3000], Step [120/158]| g_loss: 0.773| d_loss: 0.596| gp_loss: 0.058| r_loss: 0.082| p_loss: 0.130| v_loss: 0.030| per_loss: 0.467 | a_loss: 0.549
Train: Epoch [1304/3000], Step [150/158]| g_loss: 0.832| d_loss: 0.585| gp_loss: 0.061| r_loss: 0.081| p_loss: 0.134| v_loss: 0.030| per_loss: 0.480 | a_loss: 0.606
Train: Epoch [1305/3000], Step [30/158]| g_loss: 0.790| d_loss: 0.670| gp_loss: 0.166| r_loss: 0.082| p_loss: 0.137| v_loss: 0.030| per_loss: 0.493 | a_loss: 0.560
Train: Epoch [1305/3000], Step [60/158]| g_loss: 0.736| d_loss: 0.687| gp_loss: 0.056| r_loss: 0.084| p_loss: 0.137| v_loss: 0.030| per_loss: 0.464 | a_loss: 0.508
Train: Epoch [1305/3000], Step [90/158]| g_loss: 0.741| d_loss: 0.675| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.135| v_loss: 0.030| per_loss: 0.503 | a_loss: 0.509
Train: Epoch [1305/3000], Step [120/158]| g_loss: 0.744| d_loss: 0.620| gp_loss: 0.057| r_loss: 0.084| p_loss: 0.140| v_loss: 0.031| per_loss: 0.480 | a_loss: 0.512
Train: Epoch [1305/3000], Step [150/158]| g_loss: 0.823| d_loss: 0.581| gp_loss: 0.057| r_loss: 0.082| p_loss: 0.128| v_loss: 0.028| per_loss: 0.472 | a_loss: 0.602
Train: Epoch [1306/3000], Step [30/158]| g_loss: 0.825| d_loss: 0.597| gp_loss: 0.131| r_loss: 0.079| p_loss: 0.122| v_loss: 0.030| per_loss: 0.486 | a_loss: 0.607
Train: Epoch [1306/3000], Step [60/158]| g_loss: 0.756| d_loss: 0.634| gp_loss: 0.056| r_loss: 0.083| p_loss: 0.130| v_loss: 0.029| per_loss: 0.526 | a_loss: 0.526
Train: Epoch [1306/3000], Step [90/158]| g_loss: 0.742| d_loss: 0.574| gp_loss: 0.058| r_loss: 0.082| p_loss: 0.132| v_loss: 0.030| per_loss: 0.484 | a_loss: 0.516
Train: Epoch [1306/3000], Step [120/158]| g_loss: 0.790| d_loss: 0.572| gp_loss: 0.060| r_loss: 0.082| p_loss: 0.130| v_loss: 0.030| per_loss: 0.482 | a_loss: 0.565
Train: Epoch [1306/3000], Step [150/158]| g_loss: 0.820| d_loss: 0.616| gp_loss: 0.062| r_loss: 0.083| p_loss: 0.138| v_loss: 0.030| per_loss: 0.436 | a_loss: 0.594
Train: Epoch [1307/3000], Step [30/158]| g_loss: 0.811| d_loss: 0.664| gp_loss: 0.144| r_loss: 0.082| p_loss: 0.133| v_loss: 0.029| per_loss: 0.510 | a_loss: 0.582
Train: Epoch [1307/3000], Step [60/158]| g_loss: 0.728| d_loss: 0.705| gp_loss: 0.055| r_loss: 0.083| p_loss: 0.137| v_loss: 0.029| per_loss: 0.482 | a_loss: 0.499
Train: Epoch [1307/3000], Step [90/158]| g_loss: 0.751| d_loss: 0.629| gp_loss: 0.064| r_loss: 0.083| p_loss: 0.136| v_loss: 0.029| per_loss: 0.478 | a_loss: 0.523
Train: Epoch [1307/3000], Step [120/158]| g_loss: 0.831| d_loss: 0.519| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.136| v_loss: 0.030| per_loss: 0.507 | a_loss: 0.597
Train: Epoch [1307/3000], Step [150/158]| g_loss: 0.783| d_loss: 0.563| gp_loss: 0.065| r_loss: 0.080| p_loss: 0.126| v_loss: 0.029| per_loss: 0.453 | a_loss: 0.565
Train: Epoch [1308/3000], Step [30/158]| g_loss: 0.715| d_loss: 0.744| gp_loss: 0.110| r_loss: 0.082| p_loss: 0.131| v_loss: 0.029| per_loss: 0.503 | a_loss: 0.488
Train: Epoch [1308/3000], Step [60/158]| g_loss: 0.816| d_loss: 0.586| gp_loss: 0.058| r_loss: 0.083| p_loss: 0.137| v_loss: 0.029| per_loss: 0.495 | a_loss: 0.586
Train: Epoch [1308/3000], Step [90/158]| g_loss: 0.728| d_loss: 0.658| gp_loss: 0.061| r_loss: 0.081| p_loss: 0.133| v_loss: 0.030| per_loss: 0.506 | a_loss: 0.499
Train: Epoch [1308/3000], Step [120/158]| g_loss: 0.820| d_loss: 0.568| gp_loss: 0.059| r_loss: 0.080| p_loss: 0.125| v_loss: 0.028| per_loss: 0.495 | a_loss: 0.599
Train: Epoch [1308/3000], Step [150/158]| g_loss: 0.769| d_loss: 0.550| gp_loss: 0.060| r_loss: 0.081| p_loss: 0.127| v_loss: 0.029| per_loss: 0.459 | a_loss: 0.550
Train: Epoch [1309/3000], Step [30/158]| g_loss: 0.897| d_loss: 0.578| gp_loss: 0.176| r_loss: 0.079| p_loss: 0.119| v_loss: 0.029| per_loss: 0.494 | a_loss: 0.680
Train: Epoch [1309/3000], Step [60/158]| g_loss: 0.703| d_loss: 0.630| gp_loss: 0.055| r_loss: 0.079| p_loss: 0.126| v_loss: 0.029| per_loss: 0.513 | a_loss: 0.481
Train: Epoch [1309/3000], Step [90/158]| g_loss: 0.761| d_loss: 0.612| gp_loss: 0.057| r_loss: 0.080| p_loss: 0.124| v_loss: 0.029| per_loss: 0.439 | a_loss: 0.546
Train: Epoch [1309/3000], Step [120/158]| g_loss: 0.756| d_loss: 0.584| gp_loss: 0.057| r_loss: 0.077| p_loss: 0.119| v_loss: 0.028| per_loss: 0.463 | a_loss: 0.545
Train: Epoch [1309/3000], Step [150/158]| g_loss: 0.736| d_loss: 0.641| gp_loss: 0.059| r_loss: 0.078| p_loss: 0.127| v_loss: 0.028| per_loss: 0.480 | a_loss: 0.519
Train: Epoch [1310/3000], Step [30/158]| g_loss: 0.774| d_loss: 0.688| gp_loss: 0.136| r_loss: 0.081| p_loss: 0.130| v_loss: 0.028| per_loss: 0.475 | a_loss: 0.553
Train: Epoch [1310/3000], Step [60/158]| g_loss: 0.844| d_loss: 0.528| gp_loss: 0.057| r_loss: 0.081| p_loss: 0.135| v_loss: 0.030| per_loss: 0.493 | a_loss: 0.616
Train: Epoch [1310/3000], Step [90/158]| g_loss: 0.729| d_loss: 0.740| gp_loss: 0.054| r_loss: 0.082| p_loss: 0.133| v_loss: 0.028| per_loss: 0.491 | a_loss: 0.502
Train: Epoch [1310/3000], Step [120/158]| g_loss: 0.748| d_loss: 0.623| gp_loss: 0.061| r_loss: 0.084| p_loss: 0.142| v_loss: 0.028| per_loss: 0.493 | a_loss: 0.515
Train: Epoch [1310/3000], Step [150/158]| g_loss: 0.806| d_loss: 0.580| gp_loss: 0.063| r_loss: 0.084| p_loss: 0.131| v_loss: 0.029| per_loss: 0.488 | a_loss: 0.579
Train: Epoch [1311/3000], Step [30/158]| g_loss: 0.805| d_loss: 0.664| gp_loss: 0.155| r_loss: 0.079| p_loss: 0.121| v_loss: 0.029| per_loss: 0.463 | a_loss: 0.590
Train: Epoch [1311/3000], Step [60/158]| g_loss: 0.789| d_loss: 0.581| gp_loss: 0.056| r_loss: 0.078| p_loss: 0.125| v_loss: 0.028| per_loss: 0.483 | a_loss: 0.572
Train: Epoch [1311/3000], Step [90/158]| g_loss: 0.791| d_loss: 0.577| gp_loss: 0.058| r_loss: 0.081| p_loss: 0.124| v_loss: 0.029| per_loss: 0.493 | a_loss: 0.569
Train: Epoch [1311/3000], Step [120/158]| g_loss: 0.756| d_loss: 0.641| gp_loss: 0.057| r_loss: 0.080| p_loss: 0.124| v_loss: 0.029| per_loss: 0.487 | a_loss: 0.536
Train: Epoch [1311/3000], Step [150/158]| g_loss: 0.764| d_loss: 0.594| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.131| v_loss: 0.029| per_loss: 0.433 | a_loss: 0.543
Train: Epoch [1312/3000], Step [30/158]| g_loss: 0.786| d_loss: 0.661| gp_loss: 0.160| r_loss: 0.082| p_loss: 0.127| v_loss: 0.029| per_loss: 0.487 | a_loss: 0.563
Train: Epoch [1312/3000], Step [60/158]| g_loss: 0.712| d_loss: 0.700| gp_loss: 0.055| r_loss: 0.083| p_loss: 0.132| v_loss: 0.029| per_loss: 0.439 | a_loss: 0.490
Train: Epoch [1312/3000], Step [90/158]| g_loss: 0.756| d_loss: 0.599| gp_loss: 0.054| r_loss: 0.079| p_loss: 0.123| v_loss: 0.029| per_loss: 0.504 | a_loss: 0.535
Train: Epoch [1312/3000], Step [120/158]| g_loss: 0.768| d_loss: 0.602| gp_loss: 0.057| r_loss: 0.078| p_loss: 0.125| v_loss: 0.028| per_loss: 0.498 | a_loss: 0.551
Train: Epoch [1312/3000], Step [150/158]| g_loss: 0.811| d_loss: 0.520| gp_loss: 0.058| r_loss: 0.074| p_loss: 0.113| v_loss: 0.028| per_loss: 0.487 | a_loss: 0.604
Train: Epoch [1313/3000], Step [30/158]| g_loss: 0.732| d_loss: 0.681| gp_loss: 0.121| r_loss: 0.079| p_loss: 0.117| v_loss: 0.028| per_loss: 0.456 | a_loss: 0.522
Train: Epoch [1313/3000], Step [60/158]| g_loss: 0.794| d_loss: 0.527| gp_loss: 0.055| r_loss: 0.075| p_loss: 0.117| v_loss: 0.028| per_loss: 0.481 | a_loss: 0.584
Train: Epoch [1313/3000], Step [90/158]| g_loss: 0.808| d_loss: 0.554| gp_loss: 0.059| r_loss: 0.085| p_loss: 0.128| v_loss: 0.030| per_loss: 0.462 | a_loss: 0.583
Train: Epoch [1313/3000], Step [120/158]| g_loss: 0.707| d_loss: 0.667| gp_loss: 0.056| r_loss: 0.076| p_loss: 0.120| v_loss: 0.028| per_loss: 0.485 | a_loss: 0.495
Train: Epoch [1313/3000], Step [150/158]| g_loss: 0.790| d_loss: 0.549| gp_loss: 0.062| r_loss: 0.075| p_loss: 0.118| v_loss: 0.028| per_loss: 0.507 | a_loss: 0.577
Train: Epoch [1314/3000], Step [30/158]| g_loss: 0.791| d_loss: 0.674| gp_loss: 0.170| r_loss: 0.079| p_loss: 0.124| v_loss: 0.027| per_loss: 0.464 | a_loss: 0.577
Train: Epoch [1314/3000], Step [60/158]| g_loss: 0.875| d_loss: 0.527| gp_loss: 0.057| r_loss: 0.085| p_loss: 0.137| v_loss: 0.029| per_loss: 0.478 | a_loss: 0.644
Train: Epoch [1314/3000], Step [90/158]| g_loss: 0.762| d_loss: 0.569| gp_loss: 0.058| r_loss: 0.083| p_loss: 0.130| v_loss: 0.029| per_loss: 0.485 | a_loss: 0.537
Train: Epoch [1314/3000], Step [120/158]| g_loss: 0.773| d_loss: 0.723| gp_loss: 0.056| r_loss: 0.087| p_loss: 0.140| v_loss: 0.029| per_loss: 0.509 | a_loss: 0.537
Train: Epoch [1314/3000], Step [150/158]| g_loss: 0.727| d_loss: 0.644| gp_loss: 0.059| r_loss: 0.081| p_loss: 0.127| v_loss: 0.028| per_loss: 0.476 | a_loss: 0.507
Train: Epoch [1315/3000], Step [30/158]| g_loss: 0.763| d_loss: 0.701| gp_loss: 0.149| r_loss: 0.082| p_loss: 0.129| v_loss: 0.029| per_loss: 0.513 | a_loss: 0.536
Train: Epoch [1315/3000], Step [60/158]| g_loss: 0.776| d_loss: 0.569| gp_loss: 0.054| r_loss: 0.082| p_loss: 0.124| v_loss: 0.028| per_loss: 0.485 | a_loss: 0.556
Train: Epoch [1315/3000], Step [90/158]| g_loss: 0.716| d_loss: 0.679| gp_loss: 0.056| r_loss: 0.076| p_loss: 0.116| v_loss: 0.027| per_loss: 0.474 | a_loss: 0.508
Train: Epoch [1315/3000], Step [120/158]| g_loss: 0.815| d_loss: 0.585| gp_loss: 0.061| r_loss: 0.078| p_loss: 0.124| v_loss: 0.028| per_loss: 0.474 | a_loss: 0.599
Train: Epoch [1315/3000], Step [150/158]| g_loss: 0.744| d_loss: 0.575| gp_loss: 0.057| r_loss: 0.082| p_loss: 0.126| v_loss: 0.028| per_loss: 0.452 | a_loss: 0.526
Train: Epoch [1316/3000], Step [30/158]| g_loss: 0.766| d_loss: 0.782| gp_loss: 0.219| r_loss: 0.079| p_loss: 0.121| v_loss: 0.028| per_loss: 0.480 | a_loss: 0.549
Train: Epoch [1316/3000], Step [60/158]| g_loss: 0.759| d_loss: 0.640| gp_loss: 0.050| r_loss: 0.081| p_loss: 0.127| v_loss: 0.029| per_loss: 0.444 | a_loss: 0.542
Train: Epoch [1316/3000], Step [90/158]| g_loss: 0.741| d_loss: 0.580| gp_loss: 0.050| r_loss: 0.078| p_loss: 0.119| v_loss: 0.028| per_loss: 0.483 | a_loss: 0.526
Train: Epoch [1316/3000], Step [120/158]| g_loss: 0.752| d_loss: 0.614| gp_loss: 0.053| r_loss: 0.078| p_loss: 0.121| v_loss: 0.027| per_loss: 0.519 | a_loss: 0.535
Train: Epoch [1316/3000], Step [150/158]| g_loss: 0.850| d_loss: 0.480| gp_loss: 0.055| r_loss: 0.080| p_loss: 0.127| v_loss: 0.029| per_loss: 0.466 | a_loss: 0.631
Train: Epoch [1317/3000], Step [30/158]| g_loss: 0.760| d_loss: 0.719| gp_loss: 0.159| r_loss: 0.078| p_loss: 0.126| v_loss: 0.028| per_loss: 0.473 | a_loss: 0.544
Train: Epoch [1317/3000], Step [60/158]| g_loss: 0.804| d_loss: 0.623| gp_loss: 0.050| r_loss: 0.082| p_loss: 0.129| v_loss: 0.028| per_loss: 0.474 | a_loss: 0.582
Train: Epoch [1317/3000], Step [90/158]| g_loss: 0.739| d_loss: 0.582| gp_loss: 0.052| r_loss: 0.080| p_loss: 0.121| v_loss: 0.030| per_loss: 0.480 | a_loss: 0.521
Train: Epoch [1317/3000], Step [120/158]| g_loss: 0.778| d_loss: 0.573| gp_loss: 0.054| r_loss: 0.080| p_loss: 0.124| v_loss: 0.028| per_loss: 0.481 | a_loss: 0.560
Train: Epoch [1317/3000], Step [150/158]| g_loss: 0.763| d_loss: 0.585| gp_loss: 0.057| r_loss: 0.081| p_loss: 0.128| v_loss: 0.028| per_loss: 0.468 | a_loss: 0.543
Train: Epoch [1318/3000], Step [30/158]| g_loss: 0.759| d_loss: 0.755| gp_loss: 0.115| r_loss: 0.080| p_loss: 0.129| v_loss: 0.026| per_loss: 0.491 | a_loss: 0.540
Train: Epoch [1318/3000], Step [60/158]| g_loss: 0.813| d_loss: 0.483| gp_loss: 0.055| r_loss: 0.080| p_loss: 0.119| v_loss: 0.028| per_loss: 0.480 | a_loss: 0.598
Train: Epoch [1318/3000], Step [90/158]| g_loss: 0.805| d_loss: 0.586| gp_loss: 0.053| r_loss: 0.082| p_loss: 0.126| v_loss: 0.028| per_loss: 0.443 | a_loss: 0.587
Train: Epoch [1318/3000], Step [120/158]| g_loss: 0.746| d_loss: 0.593| gp_loss: 0.056| r_loss: 0.080| p_loss: 0.125| v_loss: 0.028| per_loss: 0.460 | a_loss: 0.529
Train: Epoch [1318/3000], Step [150/158]| g_loss: 0.779| d_loss: 0.599| gp_loss: 0.059| r_loss: 0.082| p_loss: 0.136| v_loss: 0.030| per_loss: 0.479 | a_loss: 0.551
Train: Epoch [1319/3000], Step [30/158]| g_loss: 0.807| d_loss: 0.699| gp_loss: 0.181| r_loss: 0.085| p_loss: 0.138| v_loss: 0.028| per_loss: 0.489 | a_loss: 0.576
Train: Epoch [1319/3000], Step [60/158]| g_loss: 0.719| d_loss: 0.679| gp_loss: 0.058| r_loss: 0.083| p_loss: 0.143| v_loss: 0.027| per_loss: 0.468 | a_loss: 0.490
Train: Epoch [1319/3000], Step [90/158]| g_loss: 0.829| d_loss: 0.514| gp_loss: 0.059| r_loss: 0.082| p_loss: 0.131| v_loss: 0.028| per_loss: 0.489 | a_loss: 0.605
Train: Epoch [1319/3000], Step [120/158]| g_loss: 0.748| d_loss: 0.663| gp_loss: 0.053| r_loss: 0.086| p_loss: 0.144| v_loss: 0.029| per_loss: 0.489 | a_loss: 0.511
Train: Epoch [1319/3000], Step [150/158]| g_loss: 0.741| d_loss: 0.621| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.145| v_loss: 0.030| per_loss: 0.509 | a_loss: 0.504
Train: Epoch [1320/3000], Step [30/158]| g_loss: 0.780| d_loss: 0.707| gp_loss: 0.194| r_loss: 0.081| p_loss: 0.130| v_loss: 0.028| per_loss: 0.498 | a_loss: 0.557
Train: Epoch [1320/3000], Step [60/158]| g_loss: 0.877| d_loss: 0.492| gp_loss: 0.054| r_loss: 0.084| p_loss: 0.137| v_loss: 0.030| per_loss: 0.541 | a_loss: 0.641
Train: Epoch [1320/3000], Step [90/158]| g_loss: 0.768| d_loss: 0.622| gp_loss: 0.051| r_loss: 0.082| p_loss: 0.133| v_loss: 0.030| per_loss: 0.517 | a_loss: 0.538
Train: Epoch [1320/3000], Step [120/158]| g_loss: 0.752| d_loss: 0.576| gp_loss: 0.054| r_loss: 0.085| p_loss: 0.134| v_loss: 0.030| per_loss: 0.477 | a_loss: 0.523
Train: Epoch [1320/3000], Step [150/158]| g_loss: 0.779| d_loss: 0.611| gp_loss: 0.055| r_loss: 0.082| p_loss: 0.131| v_loss: 0.029| per_loss: 0.494 | a_loss: 0.553
Train: Epoch [1321/3000], Step [30/158]| g_loss: 0.798| d_loss: 0.617| gp_loss: 0.146| r_loss: 0.082| p_loss: 0.124| v_loss: 0.028| per_loss: 0.545 | a_loss: 0.572
Train: Epoch [1321/3000], Step [60/158]| g_loss: 0.754| d_loss: 0.601| gp_loss: 0.056| r_loss: 0.084| p_loss: 0.129| v_loss: 0.028| per_loss: 0.489 | a_loss: 0.529
Train: Epoch [1321/3000], Step [90/158]| g_loss: 0.792| d_loss: 0.652| gp_loss: 0.056| r_loss: 0.082| p_loss: 0.127| v_loss: 0.028| per_loss: 0.466 | a_loss: 0.573
Train: Epoch [1321/3000], Step [120/158]| g_loss: 0.712| d_loss: 0.618| gp_loss: 0.057| r_loss: 0.084| p_loss: 0.139| v_loss: 0.029| per_loss: 0.471 | a_loss: 0.482
Train: Epoch [1321/3000], Step [150/158]| g_loss: 0.846| d_loss: 0.528| gp_loss: 0.060| r_loss: 0.083| p_loss: 0.132| v_loss: 0.028| per_loss: 0.498 | a_loss: 0.619
Train: Epoch [1322/3000], Step [30/158]| g_loss: 0.728| d_loss: 0.795| gp_loss: 0.190| r_loss: 0.082| p_loss: 0.132| v_loss: 0.028| per_loss: 0.485 | a_loss: 0.504
Train: Epoch [1322/3000], Step [60/158]| g_loss: 0.778| d_loss: 0.668| gp_loss: 0.055| r_loss: 0.086| p_loss: 0.136| v_loss: 0.029| per_loss: 0.453 | a_loss: 0.550
Train: Epoch [1322/3000], Step [90/158]| g_loss: 0.725| d_loss: 0.636| gp_loss: 0.054| r_loss: 0.084| p_loss: 0.132| v_loss: 0.029| per_loss: 0.453 | a_loss: 0.501
Train: Epoch [1322/3000], Step [120/158]| g_loss: 0.853| d_loss: 0.545| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.134| v_loss: 0.029| per_loss: 0.454 | a_loss: 0.628
Train: Epoch [1322/3000], Step [150/158]| g_loss: 0.832| d_loss: 0.457| gp_loss: 0.057| r_loss: 0.081| p_loss: 0.131| v_loss: 0.029| per_loss: 0.472 | a_loss: 0.610
Train: Epoch [1323/3000], Step [30/158]| g_loss: 0.837| d_loss: 0.611| gp_loss: 0.150| r_loss: 0.081| p_loss: 0.125| v_loss: 0.028| per_loss: 0.485 | a_loss: 0.616
Train: Epoch [1323/3000], Step [60/158]| g_loss: 0.800| d_loss: 0.575| gp_loss: 0.050| r_loss: 0.081| p_loss: 0.128| v_loss: 0.029| per_loss: 0.494 | a_loss: 0.576
Train: Epoch [1323/3000], Step [90/158]| g_loss: 0.744| d_loss: 0.639| gp_loss: 0.052| r_loss: 0.080| p_loss: 0.135| v_loss: 0.029| per_loss: 0.452 | a_loss: 0.523
Train: Epoch [1323/3000], Step [120/158]| g_loss: 0.803| d_loss: 0.558| gp_loss: 0.057| r_loss: 0.081| p_loss: 0.126| v_loss: 0.030| per_loss: 0.497 | a_loss: 0.579
Train: Epoch [1323/3000], Step [150/158]| g_loss: 0.735| d_loss: 0.628| gp_loss: 0.057| r_loss: 0.081| p_loss: 0.130| v_loss: 0.030| per_loss: 0.469 | a_loss: 0.512
Train: Epoch [1324/3000], Step [30/158]| g_loss: 0.798| d_loss: 0.688| gp_loss: 0.142| r_loss: 0.084| p_loss: 0.132| v_loss: 0.028| per_loss: 0.459 | a_loss: 0.575
Train: Epoch [1324/3000], Step [60/158]| g_loss: 0.791| d_loss: 0.620| gp_loss: 0.057| r_loss: 0.081| p_loss: 0.133| v_loss: 0.028| per_loss: 0.492 | a_loss: 0.567
Train: Epoch [1324/3000], Step [90/158]| g_loss: 0.782| d_loss: 0.551| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.139| v_loss: 0.029| per_loss: 0.478 | a_loss: 0.552
Train: Epoch [1324/3000], Step [120/158]| g_loss: 0.773| d_loss: 0.642| gp_loss: 0.060| r_loss: 0.086| p_loss: 0.147| v_loss: 0.029| per_loss: 0.474 | a_loss: 0.537
Train: Epoch [1324/3000], Step [150/158]| g_loss: 0.805| d_loss: 0.636| gp_loss: 0.054| r_loss: 0.085| p_loss: 0.135| v_loss: 0.029| per_loss: 0.466 | a_loss: 0.577
Train: Epoch [1325/3000], Step [30/158]| g_loss: 0.763| d_loss: 0.682| gp_loss: 0.162| r_loss: 0.083| p_loss: 0.131| v_loss: 0.029| per_loss: 0.455 | a_loss: 0.540
Train: Epoch [1325/3000], Step [60/158]| g_loss: 0.741| d_loss: 0.625| gp_loss: 0.052| r_loss: 0.080| p_loss: 0.126| v_loss: 0.030| per_loss: 0.479 | a_loss: 0.520
Train: Epoch [1325/3000], Step [90/158]| g_loss: 0.821| d_loss: 0.500| gp_loss: 0.055| r_loss: 0.080| p_loss: 0.129| v_loss: 0.029| per_loss: 0.446 | a_loss: 0.603
Train: Epoch [1325/3000], Step [120/158]| g_loss: 0.735| d_loss: 0.608| gp_loss: 0.056| r_loss: 0.078| p_loss: 0.121| v_loss: 0.028| per_loss: 0.481 | a_loss: 0.519
Train: Epoch [1325/3000], Step [150/158]| g_loss: 0.749| d_loss: 0.614| gp_loss: 0.054| r_loss: 0.078| p_loss: 0.127| v_loss: 0.028| per_loss: 0.460 | a_loss: 0.533
Train: Epoch [1326/3000], Step [30/158]| g_loss: 0.740| d_loss: 0.755| gp_loss: 0.118| r_loss: 0.078| p_loss: 0.128| v_loss: 0.028| per_loss: 0.473 | a_loss: 0.522
Train: Epoch [1326/3000], Step [60/158]| g_loss: 0.739| d_loss: 0.619| gp_loss: 0.057| r_loss: 0.079| p_loss: 0.124| v_loss: 0.027| per_loss: 0.455 | a_loss: 0.526
Train: Epoch [1326/3000], Step [90/158]| g_loss: 0.744| d_loss: 0.583| gp_loss: 0.053| r_loss: 0.080| p_loss: 0.127| v_loss: 0.029| per_loss: 0.516 | a_loss: 0.520
Train: Epoch [1326/3000], Step [120/158]| g_loss: 0.766| d_loss: 0.527| gp_loss: 0.057| r_loss: 0.079| p_loss: 0.126| v_loss: 0.028| per_loss: 0.447 | a_loss: 0.551
Train: Epoch [1326/3000], Step [150/158]| g_loss: 0.792| d_loss: 0.638| gp_loss: 0.055| r_loss: 0.078| p_loss: 0.127| v_loss: 0.028| per_loss: 0.462 | a_loss: 0.576
Train: Epoch [1327/3000], Step [30/158]| g_loss: 0.849| d_loss: 0.586| gp_loss: 0.147| r_loss: 0.079| p_loss: 0.127| v_loss: 0.030| per_loss: 0.493 | a_loss: 0.627
Train: Epoch [1327/3000], Step [60/158]| g_loss: 0.727| d_loss: 0.642| gp_loss: 0.054| r_loss: 0.077| p_loss: 0.123| v_loss: 0.029| per_loss: 0.492 | a_loss: 0.510
Train: Epoch [1327/3000], Step [90/158]| g_loss: 0.766| d_loss: 0.612| gp_loss: 0.054| r_loss: 0.081| p_loss: 0.127| v_loss: 0.029| per_loss: 0.474 | a_loss: 0.545
Train: Epoch [1327/3000], Step [120/158]| g_loss: 0.780| d_loss: 0.581| gp_loss: 0.058| r_loss: 0.079| p_loss: 0.124| v_loss: 0.029| per_loss: 0.448 | a_loss: 0.565
Train: Epoch [1327/3000], Step [150/158]| g_loss: 0.746| d_loss: 0.630| gp_loss: 0.060| r_loss: 0.079| p_loss: 0.119| v_loss: 0.027| per_loss: 0.464 | a_loss: 0.534
Train: Epoch [1328/3000], Step [30/158]| g_loss: 0.765| d_loss: 0.712| gp_loss: 0.172| r_loss: 0.081| p_loss: 0.128| v_loss: 0.028| per_loss: 0.435 | a_loss: 0.548
Train: Epoch [1328/3000], Step [60/158]| g_loss: 0.777| d_loss: 0.570| gp_loss: 0.054| r_loss: 0.079| p_loss: 0.125| v_loss: 0.028| per_loss: 0.472 | a_loss: 0.560
Train: Epoch [1328/3000], Step [90/158]| g_loss: 0.812| d_loss: 0.532| gp_loss: 0.054| r_loss: 0.081| p_loss: 0.127| v_loss: 0.029| per_loss: 0.480 | a_loss: 0.592
Train: Epoch [1328/3000], Step [120/158]| g_loss: 0.793| d_loss: 0.636| gp_loss: 0.057| r_loss: 0.078| p_loss: 0.128| v_loss: 0.028| per_loss: 0.492 | a_loss: 0.573
Train: Epoch [1328/3000], Step [150/158]| g_loss: 0.698| d_loss: 0.675| gp_loss: 0.058| r_loss: 0.080| p_loss: 0.129| v_loss: 0.030| per_loss: 0.500 | a_loss: 0.474
Train: Epoch [1329/3000], Step [30/158]| g_loss: 0.786| d_loss: 0.623| gp_loss: 0.123| r_loss: 0.076| p_loss: 0.120| v_loss: 0.028| per_loss: 0.490 | a_loss: 0.572
Train: Epoch [1329/3000], Step [60/158]| g_loss: 0.860| d_loss: 0.504| gp_loss: 0.055| r_loss: 0.077| p_loss: 0.122| v_loss: 0.029| per_loss: 0.531 | a_loss: 0.640
Train: Epoch [1329/3000], Step [90/158]| g_loss: 0.679| d_loss: 0.694| gp_loss: 0.056| r_loss: 0.078| p_loss: 0.120| v_loss: 0.027| per_loss: 0.457 | a_loss: 0.467
Train: Epoch [1329/3000], Step [120/158]| g_loss: 0.737| d_loss: 0.641| gp_loss: 0.058| r_loss: 0.079| p_loss: 0.124| v_loss: 0.028| per_loss: 0.475 | a_loss: 0.521
Train: Epoch [1329/3000], Step [150/158]| g_loss: 0.745| d_loss: 0.605| gp_loss: 0.062| r_loss: 0.080| p_loss: 0.129| v_loss: 0.028| per_loss: 0.459 | a_loss: 0.527
Train: Epoch [1330/3000], Step [30/158]| g_loss: 0.737| d_loss: 0.691| gp_loss: 0.131| r_loss: 0.078| p_loss: 0.127| v_loss: 0.028| per_loss: 0.465 | a_loss: 0.521
Train: Epoch [1330/3000], Step [60/158]| g_loss: 0.720| d_loss: 0.692| gp_loss: 0.062| r_loss: 0.082| p_loss: 0.135| v_loss: 0.029| per_loss: 0.470 | a_loss: 0.495
Train: Epoch [1330/3000], Step [90/158]| g_loss: 0.785| d_loss: 0.605| gp_loss: 0.057| r_loss: 0.080| p_loss: 0.122| v_loss: 0.029| per_loss: 0.462 | a_loss: 0.569
Train: Epoch [1330/3000], Step [120/158]| g_loss: 0.765| d_loss: 0.608| gp_loss: 0.059| r_loss: 0.080| p_loss: 0.130| v_loss: 0.029| per_loss: 0.484 | a_loss: 0.543
Train: Epoch [1330/3000], Step [150/158]| g_loss: 0.776| d_loss: 0.600| gp_loss: 0.061| r_loss: 0.077| p_loss: 0.123| v_loss: 0.029| per_loss: 0.478 | a_loss: 0.561
Train: Epoch [1331/3000], Step [30/158]| g_loss: 0.747| d_loss: 0.729| gp_loss: 0.179| r_loss: 0.082| p_loss: 0.136| v_loss: 0.029| per_loss: 0.465 | a_loss: 0.522
Train: Epoch [1331/3000], Step [60/158]| g_loss: 0.724| d_loss: 0.669| gp_loss: 0.056| r_loss: 0.080| p_loss: 0.130| v_loss: 0.029| per_loss: 0.458 | a_loss: 0.505
Train: Epoch [1331/3000], Step [90/158]| g_loss: 0.761| d_loss: 0.500| gp_loss: 0.058| r_loss: 0.079| p_loss: 0.127| v_loss: 0.028| per_loss: 0.486 | a_loss: 0.543
Train: Epoch [1331/3000], Step [120/158]| g_loss: 0.753| d_loss: 0.582| gp_loss: 0.060| r_loss: 0.077| p_loss: 0.113| v_loss: 0.026| per_loss: 0.491 | a_loss: 0.546
Train: Epoch [1331/3000], Step [150/158]| g_loss: 0.840| d_loss: 0.573| gp_loss: 0.061| r_loss: 0.080| p_loss: 0.121| v_loss: 0.028| per_loss: 0.491 | a_loss: 0.622
Train: Epoch [1332/3000], Step [30/158]| g_loss: 0.775| d_loss: 0.677| gp_loss: 0.159| r_loss: 0.080| p_loss: 0.125| v_loss: 0.028| per_loss: 0.484 | a_loss: 0.556
Train: Epoch [1332/3000], Step [60/158]| g_loss: 0.769| d_loss: 0.634| gp_loss: 0.055| r_loss: 0.083| p_loss: 0.133| v_loss: 0.030| per_loss: 0.456 | a_loss: 0.545
Train: Epoch [1332/3000], Step [90/158]| g_loss: 0.792| d_loss: 0.583| gp_loss: 0.060| r_loss: 0.083| p_loss: 0.132| v_loss: 0.029| per_loss: 0.475 | a_loss: 0.566
Train: Epoch [1332/3000], Step [120/158]| g_loss: 0.760| d_loss: 0.571| gp_loss: 0.058| r_loss: 0.082| p_loss: 0.130| v_loss: 0.030| per_loss: 0.469 | a_loss: 0.536
Train: Epoch [1332/3000], Step [150/158]| g_loss: 0.764| d_loss: 0.627| gp_loss: 0.059| r_loss: 0.082| p_loss: 0.129| v_loss: 0.029| per_loss: 0.494 | a_loss: 0.539
Train: Epoch [1333/3000], Step [30/158]| g_loss: 0.778| d_loss: 0.668| gp_loss: 0.136| r_loss: 0.079| p_loss: 0.125| v_loss: 0.028| per_loss: 0.480 | a_loss: 0.561
Train: Epoch [1333/3000], Step [60/158]| g_loss: 0.756| d_loss: 0.608| gp_loss: 0.057| r_loss: 0.083| p_loss: 0.134| v_loss: 0.029| per_loss: 0.489 | a_loss: 0.528
Train: Epoch [1333/3000], Step [90/158]| g_loss: 0.766| d_loss: 0.615| gp_loss: 0.060| r_loss: 0.081| p_loss: 0.129| v_loss: 0.028| per_loss: 0.491 | a_loss: 0.544
Train: Epoch [1333/3000], Step [120/158]| g_loss: 0.806| d_loss: 0.524| gp_loss: 0.061| r_loss: 0.079| p_loss: 0.127| v_loss: 0.028| per_loss: 0.456 | a_loss: 0.590
Train: Epoch [1333/3000], Step [150/158]| g_loss: 0.806| d_loss: 0.618| gp_loss: 0.063| r_loss: 0.085| p_loss: 0.136| v_loss: 0.029| per_loss: 0.503 | a_loss: 0.574
Train: Epoch [1334/3000], Step [30/158]| g_loss: 0.806| d_loss: 0.616| gp_loss: 0.142| r_loss: 0.083| p_loss: 0.129| v_loss: 0.029| per_loss: 0.484 | a_loss: 0.581
Train: Epoch [1334/3000], Step [60/158]| g_loss: 0.802| d_loss: 0.576| gp_loss: 0.056| r_loss: 0.080| p_loss: 0.128| v_loss: 0.029| per_loss: 0.474 | a_loss: 0.581
Train: Epoch [1334/3000], Step [90/158]| g_loss: 0.794| d_loss: 0.550| gp_loss: 0.057| r_loss: 0.082| p_loss: 0.129| v_loss: 0.030| per_loss: 0.499 | a_loss: 0.568
Train: Epoch [1334/3000], Step [120/158]| g_loss: 0.803| d_loss: 0.579| gp_loss: 0.054| r_loss: 0.083| p_loss: 0.132| v_loss: 0.030| per_loss: 0.515 | a_loss: 0.573
Train: Epoch [1334/3000], Step [150/158]| g_loss: 0.753| d_loss: 0.624| gp_loss: 0.060| r_loss: 0.079| p_loss: 0.129| v_loss: 0.028| per_loss: 0.476 | a_loss: 0.534
Train: Epoch [1335/3000], Step [30/158]| g_loss: 0.743| d_loss: 0.722| gp_loss: 0.130| r_loss: 0.085| p_loss: 0.140| v_loss: 0.028| per_loss: 0.486 | a_loss: 0.512
Train: Epoch [1335/3000], Step [60/158]| g_loss: 0.798| d_loss: 0.570| gp_loss: 0.063| r_loss: 0.084| p_loss: 0.136| v_loss: 0.029| per_loss: 0.483 | a_loss: 0.569
Train: Epoch [1335/3000], Step [90/158]| g_loss: 0.746| d_loss: 0.694| gp_loss: 0.060| r_loss: 0.083| p_loss: 0.134| v_loss: 0.028| per_loss: 0.467 | a_loss: 0.521
Train: Epoch [1335/3000], Step [120/158]| g_loss: 0.834| d_loss: 0.460| gp_loss: 0.065| r_loss: 0.079| p_loss: 0.124| v_loss: 0.028| per_loss: 0.492 | a_loss: 0.615
Train: Epoch [1335/3000], Step [150/158]| g_loss: 0.797| d_loss: 0.559| gp_loss: 0.058| r_loss: 0.083| p_loss: 0.134| v_loss: 0.030| per_loss: 0.472 | a_loss: 0.570
Train: Epoch [1336/3000], Step [30/158]| g_loss: 0.788| d_loss: 0.637| gp_loss: 0.141| r_loss: 0.084| p_loss: 0.133| v_loss: 0.029| per_loss: 0.466 | a_loss: 0.562
Train: Epoch [1336/3000], Step [60/158]| g_loss: 0.790| d_loss: 0.617| gp_loss: 0.057| r_loss: 0.080| p_loss: 0.129| v_loss: 0.029| per_loss: 0.470 | a_loss: 0.570
Train: Epoch [1336/3000], Step [90/158]| g_loss: 0.789| d_loss: 0.605| gp_loss: 0.060| r_loss: 0.084| p_loss: 0.135| v_loss: 0.029| per_loss: 0.488 | a_loss: 0.560
Train: Epoch [1336/3000], Step [120/158]| g_loss: 0.826| d_loss: 0.563| gp_loss: 0.061| r_loss: 0.081| p_loss: 0.137| v_loss: 0.028| per_loss: 0.468 | a_loss: 0.602
Train: Epoch [1336/3000], Step [150/158]| g_loss: 0.729| d_loss: 0.646| gp_loss: 0.062| r_loss: 0.088| p_loss: 0.144| v_loss: 0.028| per_loss: 0.445 | a_loss: 0.496
Train: Epoch [1337/3000], Step [30/158]| g_loss: 0.794| d_loss: 0.675| gp_loss: 0.122| r_loss: 0.085| p_loss: 0.139| v_loss: 0.028| per_loss: 0.483 | a_loss: 0.563
Train: Epoch [1337/3000], Step [60/158]| g_loss: 0.781| d_loss: 0.567| gp_loss: 0.059| r_loss: 0.083| p_loss: 0.135| v_loss: 0.028| per_loss: 0.465 | a_loss: 0.556
Train: Epoch [1337/3000], Step [90/158]| g_loss: 0.757| d_loss: 0.627| gp_loss: 0.062| r_loss: 0.086| p_loss: 0.135| v_loss: 0.029| per_loss: 0.463 | a_loss: 0.529
Train: Epoch [1337/3000], Step [120/158]| g_loss: 0.801| d_loss: 0.569| gp_loss: 0.062| r_loss: 0.081| p_loss: 0.126| v_loss: 0.028| per_loss: 0.486 | a_loss: 0.580
Train: Epoch [1337/3000], Step [150/158]| g_loss: 0.800| d_loss: 0.612| gp_loss: 0.061| r_loss: 0.081| p_loss: 0.132| v_loss: 0.028| per_loss: 0.449 | a_loss: 0.581
Train: Epoch [1338/3000], Step [30/158]| g_loss: 0.766| d_loss: 0.683| gp_loss: 0.165| r_loss: 0.080| p_loss: 0.129| v_loss: 0.028| per_loss: 0.483 | a_loss: 0.545
Train: Epoch [1338/3000], Step [60/158]| g_loss: 0.745| d_loss: 0.669| gp_loss: 0.056| r_loss: 0.080| p_loss: 0.127| v_loss: 0.028| per_loss: 0.449 | a_loss: 0.528
Train: Epoch [1338/3000], Step [90/158]| g_loss: 0.747| d_loss: 0.619| gp_loss: 0.058| r_loss: 0.079| p_loss: 0.126| v_loss: 0.027| per_loss: 0.457 | a_loss: 0.533
Train: Epoch [1338/3000], Step [120/158]| g_loss: 0.821| d_loss: 0.521| gp_loss: 0.061| r_loss: 0.085| p_loss: 0.130| v_loss: 0.030| per_loss: 0.488 | a_loss: 0.592
Train: Epoch [1338/3000], Step [150/158]| g_loss: 0.722| d_loss: 0.662| gp_loss: 0.061| r_loss: 0.077| p_loss: 0.124| v_loss: 0.029| per_loss: 0.468 | a_loss: 0.507
Train: Epoch [1339/3000], Step [30/158]| g_loss: 0.753| d_loss: 0.733| gp_loss: 0.157| r_loss: 0.084| p_loss: 0.137| v_loss: 0.029| per_loss: 0.458 | a_loss: 0.525
Train: Epoch [1339/3000], Step [60/158]| g_loss: 0.789| d_loss: 0.605| gp_loss: 0.056| r_loss: 0.084| p_loss: 0.135| v_loss: 0.030| per_loss: 0.491 | a_loss: 0.559
Train: Epoch [1339/3000], Step [90/158]| g_loss: 0.772| d_loss: 0.593| gp_loss: 0.059| r_loss: 0.077| p_loss: 0.125| v_loss: 0.028| per_loss: 0.484 | a_loss: 0.555
Train: Epoch [1339/3000], Step [120/158]| g_loss: 0.813| d_loss: 0.519| gp_loss: 0.057| r_loss: 0.081| p_loss: 0.126| v_loss: 0.028| per_loss: 0.445 | a_loss: 0.597
Train: Epoch [1339/3000], Step [150/158]| g_loss: 0.777| d_loss: 0.607| gp_loss: 0.056| r_loss: 0.080| p_loss: 0.126| v_loss: 0.028| per_loss: 0.487 | a_loss: 0.557
Train: Epoch [1340/3000], Step [30/158]| g_loss: 0.776| d_loss: 0.748| gp_loss: 0.220| r_loss: 0.077| p_loss: 0.122| v_loss: 0.028| per_loss: 0.456 | a_loss: 0.564
Train: Epoch [1340/3000], Step [60/158]| g_loss: 0.772| d_loss: 0.590| gp_loss: 0.057| r_loss: 0.084| p_loss: 0.131| v_loss: 0.029| per_loss: 0.489 | a_loss: 0.545
Train: Epoch [1340/3000], Step [90/158]| g_loss: 0.828| d_loss: 0.528| gp_loss: 0.055| r_loss: 0.077| p_loss: 0.124| v_loss: 0.028| per_loss: 0.502 | a_loss: 0.611
Train: Epoch [1340/3000], Step [120/158]| g_loss: 0.748| d_loss: 0.624| gp_loss: 0.059| r_loss: 0.079| p_loss: 0.120| v_loss: 0.028| per_loss: 0.452 | a_loss: 0.535
Train: Epoch [1340/3000], Step [150/158]| g_loss: 0.711| d_loss: 0.615| gp_loss: 0.054| r_loss: 0.078| p_loss: 0.118| v_loss: 0.028| per_loss: 0.451 | a_loss: 0.501
Train: Epoch [1341/3000], Step [30/158]| g_loss: 0.796| d_loss: 0.723| gp_loss: 0.129| r_loss: 0.090| p_loss: 0.138| v_loss: 0.030| per_loss: 0.491 | a_loss: 0.558
Train: Epoch [1341/3000], Step [60/158]| g_loss: 0.724| d_loss: 0.700| gp_loss: 0.053| r_loss: 0.081| p_loss: 0.126| v_loss: 0.028| per_loss: 0.461 | a_loss: 0.507
Train: Epoch [1341/3000], Step [90/158]| g_loss: 0.730| d_loss: 0.535| gp_loss: 0.057| r_loss: 0.076| p_loss: 0.121| v_loss: 0.028| per_loss: 0.487 | a_loss: 0.518
Train: Epoch [1341/3000], Step [120/158]| g_loss: 0.825| d_loss: 0.581| gp_loss: 0.059| r_loss: 0.079| p_loss: 0.128| v_loss: 0.028| per_loss: 0.487 | a_loss: 0.605
Train: Epoch [1341/3000], Step [150/158]| g_loss: 0.723| d_loss: 0.581| gp_loss: 0.060| r_loss: 0.078| p_loss: 0.121| v_loss: 0.027| per_loss: 0.456 | a_loss: 0.512
Train: Epoch [1342/3000], Step [30/158]| g_loss: 0.825| d_loss: 0.567| gp_loss: 0.135| r_loss: 0.076| p_loss: 0.117| v_loss: 0.027| per_loss: 0.450 | a_loss: 0.617
Train: Epoch [1342/3000], Step [60/158]| g_loss: 0.779| d_loss: 0.567| gp_loss: 0.055| r_loss: 0.077| p_loss: 0.119| v_loss: 0.028| per_loss: 0.464 | a_loss: 0.568
Train: Epoch [1342/3000], Step [90/158]| g_loss: 0.769| d_loss: 0.652| gp_loss: 0.058| r_loss: 0.078| p_loss: 0.119| v_loss: 0.028| per_loss: 0.464 | a_loss: 0.557
Train: Epoch [1342/3000], Step [120/158]| g_loss: 0.788| d_loss: 0.597| gp_loss: 0.059| r_loss: 0.078| p_loss: 0.127| v_loss: 0.029| per_loss: 0.506 | a_loss: 0.567
Train: Epoch [1342/3000], Step [150/158]| g_loss: 0.709| d_loss: 0.700| gp_loss: 0.059| r_loss: 0.081| p_loss: 0.135| v_loss: 0.029| per_loss: 0.500 | a_loss: 0.481
Train: Epoch [1343/3000], Step [30/158]| g_loss: 0.850| d_loss: 0.613| gp_loss: 0.199| r_loss: 0.080| p_loss: 0.132| v_loss: 0.029| per_loss: 0.521 | a_loss: 0.623
Train: Epoch [1343/3000], Step [60/158]| g_loss: 0.795| d_loss: 0.568| gp_loss: 0.053| r_loss: 0.080| p_loss: 0.127| v_loss: 0.028| per_loss: 0.505 | a_loss: 0.573
Train: Epoch [1343/3000], Step [90/158]| g_loss: 0.754| d_loss: 0.613| gp_loss: 0.055| r_loss: 0.079| p_loss: 0.129| v_loss: 0.028| per_loss: 0.449 | a_loss: 0.537
Train: Epoch [1343/3000], Step [120/158]| g_loss: 0.694| d_loss: 0.671| gp_loss: 0.057| r_loss: 0.078| p_loss: 0.120| v_loss: 0.027| per_loss: 0.469 | a_loss: 0.483
Train: Epoch [1343/3000], Step [150/158]| g_loss: 0.750| d_loss: 0.622| gp_loss: 0.055| r_loss: 0.083| p_loss: 0.128| v_loss: 0.028| per_loss: 0.493 | a_loss: 0.525
Train: Epoch [1344/3000], Step [30/158]| g_loss: 0.735| d_loss: 0.700| gp_loss: 0.134| r_loss: 0.080| p_loss: 0.128| v_loss: 0.027| per_loss: 0.467 | a_loss: 0.517
Train: Epoch [1344/3000], Step [60/158]| g_loss: 0.785| d_loss: 0.549| gp_loss: 0.059| r_loss: 0.077| p_loss: 0.125| v_loss: 0.029| per_loss: 0.451 | a_loss: 0.572
Train: Epoch [1344/3000], Step [90/158]| g_loss: 0.776| d_loss: 0.583| gp_loss: 0.056| r_loss: 0.079| p_loss: 0.121| v_loss: 0.028| per_loss: 0.491 | a_loss: 0.559
Train: Epoch [1344/3000], Step [120/158]| g_loss: 0.779| d_loss: 0.584| gp_loss: 0.058| r_loss: 0.081| p_loss: 0.127| v_loss: 0.028| per_loss: 0.476 | a_loss: 0.559
Train: Epoch [1344/3000], Step [150/158]| g_loss: 0.809| d_loss: 0.606| gp_loss: 0.056| r_loss: 0.081| p_loss: 0.132| v_loss: 0.028| per_loss: 0.471 | a_loss: 0.587
Train: Epoch [1345/3000], Step [30/158]| g_loss: 0.776| d_loss: 0.738| gp_loss: 0.211| r_loss: 0.088| p_loss: 0.139| v_loss: 0.029| per_loss: 0.499 | a_loss: 0.539
Train: Epoch [1345/3000], Step [60/158]| g_loss: 0.815| d_loss: 0.535| gp_loss: 0.053| r_loss: 0.082| p_loss: 0.137| v_loss: 0.028| per_loss: 0.471 | a_loss: 0.590
Train: Epoch [1345/3000], Step [90/158]| g_loss: 0.766| d_loss: 0.598| gp_loss: 0.054| r_loss: 0.082| p_loss: 0.133| v_loss: 0.029| per_loss: 0.464 | a_loss: 0.542
Train: Epoch [1345/3000], Step [120/158]| g_loss: 0.726| d_loss: 0.683| gp_loss: 0.053| r_loss: 0.081| p_loss: 0.129| v_loss: 0.028| per_loss: 0.450 | a_loss: 0.507
Train: Epoch [1345/3000], Step [150/158]| g_loss: 0.749| d_loss: 0.591| gp_loss: 0.060| r_loss: 0.080| p_loss: 0.131| v_loss: 0.027| per_loss: 0.448 | a_loss: 0.532
Train: Epoch [1346/3000], Step [30/158]| g_loss: 0.763| d_loss: 0.653| gp_loss: 0.139| r_loss: 0.078| p_loss: 0.130| v_loss: 0.028| per_loss: 0.471 | a_loss: 0.545
Train: Epoch [1346/3000], Step [60/158]| g_loss: 0.812| d_loss: 0.554| gp_loss: 0.057| r_loss: 0.080| p_loss: 0.125| v_loss: 0.028| per_loss: 0.455 | a_loss: 0.596
Train: Epoch [1346/3000], Step [90/158]| g_loss: 0.742| d_loss: 0.681| gp_loss: 0.052| r_loss: 0.081| p_loss: 0.130| v_loss: 0.029| per_loss: 0.461 | a_loss: 0.522
Train: Epoch [1346/3000], Step [120/158]| g_loss: 0.774| d_loss: 0.600| gp_loss: 0.060| r_loss: 0.079| p_loss: 0.127| v_loss: 0.028| per_loss: 0.499 | a_loss: 0.554
Train: Epoch [1346/3000], Step [150/158]| g_loss: 0.798| d_loss: 0.537| gp_loss: 0.059| r_loss: 0.083| p_loss: 0.134| v_loss: 0.029| per_loss: 0.454 | a_loss: 0.574
Train: Epoch [1347/3000], Step [30/158]| g_loss: 0.727| d_loss: 0.694| gp_loss: 0.129| r_loss: 0.084| p_loss: 0.129| v_loss: 0.029| per_loss: 0.451 | a_loss: 0.504
Train: Epoch [1347/3000], Step [60/158]| g_loss: 0.761| d_loss: 0.635| gp_loss: 0.056| r_loss: 0.081| p_loss: 0.127| v_loss: 0.029| per_loss: 0.455 | a_loss: 0.543
Train: Epoch [1347/3000], Step [90/158]| g_loss: 0.784| d_loss: 0.543| gp_loss: 0.059| r_loss: 0.080| p_loss: 0.129| v_loss: 0.027| per_loss: 0.462 | a_loss: 0.566
Train: Epoch [1347/3000], Step [120/158]| g_loss: 0.759| d_loss: 0.620| gp_loss: 0.061| r_loss: 0.076| p_loss: 0.123| v_loss: 0.027| per_loss: 0.463 | a_loss: 0.548
Train: Epoch [1347/3000], Step [150/158]| g_loss: 0.790| d_loss: 0.576| gp_loss: 0.059| r_loss: 0.079| p_loss: 0.126| v_loss: 0.028| per_loss: 0.476 | a_loss: 0.573
Train: Epoch [1348/3000], Step [30/158]| g_loss: 0.735| d_loss: 0.726| gp_loss: 0.208| r_loss: 0.079| p_loss: 0.125| v_loss: 0.028| per_loss: 0.447 | a_loss: 0.521
Train: Epoch [1348/3000], Step [60/158]| g_loss: 0.802| d_loss: 0.621| gp_loss: 0.053| r_loss: 0.080| p_loss: 0.126| v_loss: 0.029| per_loss: 0.501 | a_loss: 0.580
Train: Epoch [1348/3000], Step [90/158]| g_loss: 0.761| d_loss: 0.613| gp_loss: 0.055| r_loss: 0.079| p_loss: 0.130| v_loss: 0.028| per_loss: 0.463 | a_loss: 0.543
Train: Epoch [1348/3000], Step [120/158]| g_loss: 0.797| d_loss: 0.545| gp_loss: 0.054| r_loss: 0.079| p_loss: 0.122| v_loss: 0.028| per_loss: 0.504 | a_loss: 0.579
Train: Epoch [1348/3000], Step [150/158]| g_loss: 0.703| d_loss: 0.693| gp_loss: 0.056| r_loss: 0.078| p_loss: 0.128| v_loss: 0.027| per_loss: 0.465 | a_loss: 0.487
Train: Epoch [1349/3000], Step [30/158]| g_loss: 0.748| d_loss: 0.773| gp_loss: 0.199| r_loss: 0.077| p_loss: 0.121| v_loss: 0.027| per_loss: 0.519 | a_loss: 0.531
Train: Epoch [1349/3000], Step [60/158]| g_loss: 0.793| d_loss: 0.529| gp_loss: 0.054| r_loss: 0.079| p_loss: 0.124| v_loss: 0.029| per_loss: 0.479 | a_loss: 0.576
Train: Epoch [1349/3000], Step [90/158]| g_loss: 0.803| d_loss: 0.598| gp_loss: 0.055| r_loss: 0.080| p_loss: 0.128| v_loss: 0.028| per_loss: 0.498 | a_loss: 0.582
Train: Epoch [1349/3000], Step [120/158]| g_loss: 0.743| d_loss: 0.557| gp_loss: 0.056| r_loss: 0.076| p_loss: 0.116| v_loss: 0.027| per_loss: 0.441 | a_loss: 0.537
Train: Epoch [1349/3000], Step [150/158]| g_loss: 0.747| d_loss: 0.620| gp_loss: 0.056| r_loss: 0.077| p_loss: 0.121| v_loss: 0.027| per_loss: 0.493 | a_loss: 0.533
Train: Epoch [1350/3000], Step [30/158]| g_loss: 0.758| d_loss: 0.675| gp_loss: 0.140| r_loss: 0.075| p_loss: 0.117| v_loss: 0.027| per_loss: 0.456 | a_loss: 0.552
Train: Epoch [1350/3000], Step [60/158]| g_loss: 0.797| d_loss: 0.528| gp_loss: 0.058| r_loss: 0.076| p_loss: 0.120| v_loss: 0.027| per_loss: 0.458 | a_loss: 0.588
Train: Epoch [1350/3000], Step [90/158]| g_loss: 0.717| d_loss: 0.693| gp_loss: 0.054| r_loss: 0.078| p_loss: 0.119| v_loss: 0.027| per_loss: 0.428 | a_loss: 0.509
Train: Epoch [1350/3000], Step [120/158]| g_loss: 0.729| d_loss: 0.615| gp_loss: 0.058| r_loss: 0.081| p_loss: 0.126| v_loss: 0.028| per_loss: 0.462 | a_loss: 0.510
Train: Epoch [1350/3000], Step [150/158]| g_loss: 0.749| d_loss: 0.556| gp_loss: 0.057| r_loss: 0.075| p_loss: 0.114| v_loss: 0.027| per_loss: 0.527 | a_loss: 0.537
Test: Epoch [1350/3000]| g_loss: 0.647| r_loss: 0.390| p_loss: 0.289| v_loss: 0.024
Train: Epoch [1351/3000], Step [30/158]| g_loss: 0.762| d_loss: 0.613| gp_loss: 0.054| r_loss: 0.077| p_loss: 0.120| v_loss: 0.026| per_loss: 0.472 | a_loss: 0.552
Train: Epoch [1351/3000], Step [60/158]| g_loss: 0.704| d_loss: 0.661| gp_loss: 0.058| r_loss: 0.077| p_loss: 0.125| v_loss: 0.027| per_loss: 0.459 | a_loss: 0.491
Train: Epoch [1351/3000], Step [90/158]| g_loss: 0.816| d_loss: 0.546| gp_loss: 0.055| r_loss: 0.083| p_loss: 0.128| v_loss: 0.028| per_loss: 0.486 | a_loss: 0.593
Train: Epoch [1351/3000], Step [120/158]| g_loss: 0.750| d_loss: 0.588| gp_loss: 0.053| r_loss: 0.079| p_loss: 0.128| v_loss: 0.027| per_loss: 0.448 | a_loss: 0.535
Train: Epoch [1351/3000], Step [150/158]| g_loss: 0.850| d_loss: 0.562| gp_loss: 0.054| r_loss: 0.081| p_loss: 0.124| v_loss: 0.028| per_loss: 0.485 | a_loss: 0.630
Train: Epoch [1352/3000], Step [30/158]| g_loss: 0.766| d_loss: 0.653| gp_loss: 0.171| r_loss: 0.078| p_loss: 0.118| v_loss: 0.029| per_loss: 0.456 | a_loss: 0.555
Train: Epoch [1352/3000], Step [60/158]| g_loss: 0.715| d_loss: 0.669| gp_loss: 0.050| r_loss: 0.074| p_loss: 0.116| v_loss: 0.027| per_loss: 0.482 | a_loss: 0.507
Train: Epoch [1352/3000], Step [90/158]| g_loss: 0.742| d_loss: 0.611| gp_loss: 0.055| r_loss: 0.080| p_loss: 0.122| v_loss: 0.027| per_loss: 0.467 | a_loss: 0.526
Train: Epoch [1352/3000], Step [120/158]| g_loss: 0.867| d_loss: 0.510| gp_loss: 0.052| r_loss: 0.080| p_loss: 0.119| v_loss: 0.027| per_loss: 0.448 | a_loss: 0.655
Train: Epoch [1352/3000], Step [150/158]| g_loss: 0.715| d_loss: 0.637| gp_loss: 0.055| r_loss: 0.081| p_loss: 0.121| v_loss: 0.027| per_loss: 0.464 | a_loss: 0.500
Train: Epoch [1353/3000], Step [30/158]| g_loss: 0.720| d_loss: 0.715| gp_loss: 0.183| r_loss: 0.075| p_loss: 0.120| v_loss: 0.027| per_loss: 0.446 | a_loss: 0.513
Train: Epoch [1353/3000], Step [60/158]| g_loss: 0.827| d_loss: 0.516| gp_loss: 0.053| r_loss: 0.076| p_loss: 0.120| v_loss: 0.026| per_loss: 0.442 | a_loss: 0.621
Train: Epoch [1353/3000], Step [90/158]| g_loss: 0.776| d_loss: 0.612| gp_loss: 0.050| r_loss: 0.084| p_loss: 0.124| v_loss: 0.027| per_loss: 0.536 | a_loss: 0.549
Train: Epoch [1353/3000], Step [120/158]| g_loss: 0.771| d_loss: 0.596| gp_loss: 0.055| r_loss: 0.084| p_loss: 0.131| v_loss: 0.027| per_loss: 0.456 | a_loss: 0.549
Train: Epoch [1353/3000], Step [150/158]| g_loss: 0.784| d_loss: 0.638| gp_loss: 0.053| r_loss: 0.087| p_loss: 0.143| v_loss: 0.031| per_loss: 0.465 | a_loss: 0.548
Train: Epoch [1354/3000], Step [30/158]| g_loss: 0.763| d_loss: 0.639| gp_loss: 0.123| r_loss: 0.084| p_loss: 0.134| v_loss: 0.028| per_loss: 0.477 | a_loss: 0.537
Train: Epoch [1354/3000], Step [60/158]| g_loss: 0.774| d_loss: 0.580| gp_loss: 0.054| r_loss: 0.081| p_loss: 0.130| v_loss: 0.028| per_loss: 0.449 | a_loss: 0.555
Train: Epoch [1354/3000], Step [90/158]| g_loss: 0.719| d_loss: 0.664| gp_loss: 0.057| r_loss: 0.079| p_loss: 0.127| v_loss: 0.026| per_loss: 0.464 | a_loss: 0.504
Train: Epoch [1354/3000], Step [120/158]| g_loss: 0.840| d_loss: 0.555| gp_loss: 0.055| r_loss: 0.081| p_loss: 0.131| v_loss: 0.028| per_loss: 0.485 | a_loss: 0.618
Train: Epoch [1354/3000], Step [150/158]| g_loss: 0.741| d_loss: 0.611| gp_loss: 0.060| r_loss: 0.079| p_loss: 0.127| v_loss: 0.027| per_loss: 0.483 | a_loss: 0.523
Train: Epoch [1355/3000], Step [30/158]| g_loss: 0.767| d_loss: 0.682| gp_loss: 0.145| r_loss: 0.080| p_loss: 0.125| v_loss: 0.029| per_loss: 0.458 | a_loss: 0.550
Train: Epoch [1355/3000], Step [60/158]| g_loss: 0.763| d_loss: 0.641| gp_loss: 0.055| r_loss: 0.079| p_loss: 0.131| v_loss: 0.028| per_loss: 0.452 | a_loss: 0.545
Train: Epoch [1355/3000], Step [90/158]| g_loss: 0.765| d_loss: 0.618| gp_loss: 0.056| r_loss: 0.078| p_loss: 0.127| v_loss: 0.029| per_loss: 0.480 | a_loss: 0.546
Train: Epoch [1355/3000], Step [120/158]| g_loss: 0.792| d_loss: 0.543| gp_loss: 0.060| r_loss: 0.081| p_loss: 0.122| v_loss: 0.028| per_loss: 0.460 | a_loss: 0.576
Train: Epoch [1355/3000], Step [150/158]| g_loss: 0.794| d_loss: 0.560| gp_loss: 0.058| r_loss: 0.082| p_loss: 0.125| v_loss: 0.028| per_loss: 0.461 | a_loss: 0.575
Train: Epoch [1356/3000], Step [30/158]| g_loss: 0.699| d_loss: 0.683| gp_loss: 0.101| r_loss: 0.079| p_loss: 0.127| v_loss: 0.028| per_loss: 0.455 | a_loss: 0.483
Train: Epoch [1356/3000], Step [60/158]| g_loss: 0.861| d_loss: 0.506| gp_loss: 0.057| r_loss: 0.081| p_loss: 0.129| v_loss: 0.028| per_loss: 0.483 | a_loss: 0.639
Train: Epoch [1356/3000], Step [90/158]| g_loss: 0.764| d_loss: 0.566| gp_loss: 0.058| r_loss: 0.078| p_loss: 0.125| v_loss: 0.028| per_loss: 0.495 | a_loss: 0.546
Train: Epoch [1356/3000], Step [120/158]| g_loss: 0.726| d_loss: 0.691| gp_loss: 0.060| r_loss: 0.077| p_loss: 0.126| v_loss: 0.028| per_loss: 0.455 | a_loss: 0.513
Train: Epoch [1356/3000], Step [150/158]| g_loss: 0.767| d_loss: 0.631| gp_loss: 0.064| r_loss: 0.079| p_loss: 0.126| v_loss: 0.028| per_loss: 0.447 | a_loss: 0.553
Train: Epoch [1357/3000], Step [30/158]| g_loss: 0.819| d_loss: 0.646| gp_loss: 0.147| r_loss: 0.080| p_loss: 0.129| v_loss: 0.027| per_loss: 0.483 | a_loss: 0.599
Train: Epoch [1357/3000], Step [60/158]| g_loss: 0.757| d_loss: 0.596| gp_loss: 0.059| r_loss: 0.079| p_loss: 0.125| v_loss: 0.027| per_loss: 0.469 | a_loss: 0.540
Train: Epoch [1357/3000], Step [90/158]| g_loss: 0.737| d_loss: 0.609| gp_loss: 0.058| r_loss: 0.081| p_loss: 0.129| v_loss: 0.028| per_loss: 0.480 | a_loss: 0.516
Train: Epoch [1357/3000], Step [120/158]| g_loss: 0.811| d_loss: 0.636| gp_loss: 0.059| r_loss: 0.080| p_loss: 0.133| v_loss: 0.028| per_loss: 0.485 | a_loss: 0.588
Train: Epoch [1357/3000], Step [150/158]| g_loss: 0.843| d_loss: 0.548| gp_loss: 0.063| r_loss: 0.082| p_loss: 0.132| v_loss: 0.029| per_loss: 0.480 | a_loss: 0.618
Train: Epoch [1358/3000], Step [30/158]| g_loss: 0.694| d_loss: 0.787| gp_loss: 0.112| r_loss: 0.079| p_loss: 0.129| v_loss: 0.028| per_loss: 0.484 | a_loss: 0.474
Train: Epoch [1358/3000], Step [60/158]| g_loss: 0.695| d_loss: 0.590| gp_loss: 0.059| r_loss: 0.080| p_loss: 0.125| v_loss: 0.029| per_loss: 0.462 | a_loss: 0.477
Train: Epoch [1358/3000], Step [90/158]| g_loss: 0.852| d_loss: 0.557| gp_loss: 0.062| r_loss: 0.081| p_loss: 0.131| v_loss: 0.029| per_loss: 0.515 | a_loss: 0.625
Train: Epoch [1358/3000], Step [120/158]| g_loss: 0.757| d_loss: 0.610| gp_loss: 0.062| r_loss: 0.078| p_loss: 0.121| v_loss: 0.027| per_loss: 0.466 | a_loss: 0.544
Train: Epoch [1358/3000], Step [150/158]| g_loss: 0.808| d_loss: 0.532| gp_loss: 0.063| r_loss: 0.081| p_loss: 0.128| v_loss: 0.027| per_loss: 0.476 | a_loss: 0.588
Train: Epoch [1359/3000], Step [30/158]| g_loss: 0.760| d_loss: 0.686| gp_loss: 0.159| r_loss: 0.077| p_loss: 0.122| v_loss: 0.027| per_loss: 0.503 | a_loss: 0.545
Train: Epoch [1359/3000], Step [60/158]| g_loss: 0.747| d_loss: 0.625| gp_loss: 0.055| r_loss: 0.080| p_loss: 0.126| v_loss: 0.029| per_loss: 0.442 | a_loss: 0.531
Train: Epoch [1359/3000], Step [90/158]| g_loss: 0.768| d_loss: 0.610| gp_loss: 0.058| r_loss: 0.077| p_loss: 0.129| v_loss: 0.027| per_loss: 0.459 | a_loss: 0.553
Train: Epoch [1359/3000], Step [120/158]| g_loss: 0.802| d_loss: 0.644| gp_loss: 0.060| r_loss: 0.082| p_loss: 0.137| v_loss: 0.029| per_loss: 0.488 | a_loss: 0.574
Train: Epoch [1359/3000], Step [150/158]| g_loss: 0.749| d_loss: 0.572| gp_loss: 0.060| r_loss: 0.079| p_loss: 0.123| v_loss: 0.028| per_loss: 0.479 | a_loss: 0.532
Train: Epoch [1360/3000], Step [30/158]| g_loss: 0.800| d_loss: 0.621| gp_loss: 0.151| r_loss: 0.080| p_loss: 0.124| v_loss: 0.028| per_loss: 0.486 | a_loss: 0.582
Train: Epoch [1360/3000], Step [60/158]| g_loss: 0.744| d_loss: 0.647| gp_loss: 0.056| r_loss: 0.076| p_loss: 0.125| v_loss: 0.027| per_loss: 0.468 | a_loss: 0.532
Train: Epoch [1360/3000], Step [90/158]| g_loss: 0.770| d_loss: 0.633| gp_loss: 0.055| r_loss: 0.077| p_loss: 0.121| v_loss: 0.028| per_loss: 0.479 | a_loss: 0.556
Train: Epoch [1360/3000], Step [120/158]| g_loss: 0.801| d_loss: 0.552| gp_loss: 0.057| r_loss: 0.078| p_loss: 0.122| v_loss: 0.029| per_loss: 0.457 | a_loss: 0.587
Train: Epoch [1360/3000], Step [150/158]| g_loss: 0.720| d_loss: 0.661| gp_loss: 0.056| r_loss: 0.079| p_loss: 0.129| v_loss: 0.027| per_loss: 0.449 | a_loss: 0.504
Train: Epoch [1361/3000], Step [30/158]| g_loss: 0.781| d_loss: 0.730| gp_loss: 0.217| r_loss: 0.079| p_loss: 0.126| v_loss: 0.029| per_loss: 0.472 | a_loss: 0.563
Train: Epoch [1361/3000], Step [60/158]| g_loss: 0.719| d_loss: 0.654| gp_loss: 0.052| r_loss: 0.079| p_loss: 0.125| v_loss: 0.027| per_loss: 0.497 | a_loss: 0.501
Train: Epoch [1361/3000], Step [90/158]| g_loss: 0.782| d_loss: 0.673| gp_loss: 0.056| r_loss: 0.081| p_loss: 0.136| v_loss: 0.029| per_loss: 0.472 | a_loss: 0.556
Train: Epoch [1361/3000], Step [120/158]| g_loss: 0.781| d_loss: 0.560| gp_loss: 0.056| r_loss: 0.084| p_loss: 0.137| v_loss: 0.028| per_loss: 0.477 | a_loss: 0.552
Train: Epoch [1361/3000], Step [150/158]| g_loss: 0.790| d_loss: 0.603| gp_loss: 0.054| r_loss: 0.081| p_loss: 0.132| v_loss: 0.028| per_loss: 0.489 | a_loss: 0.566
Train: Epoch [1362/3000], Step [30/158]| g_loss: 0.748| d_loss: 0.745| gp_loss: 0.155| r_loss: 0.082| p_loss: 0.136| v_loss: 0.027| per_loss: 0.465 | a_loss: 0.524
Train: Epoch [1362/3000], Step [60/158]| g_loss: 0.794| d_loss: 0.540| gp_loss: 0.058| r_loss: 0.080| p_loss: 0.127| v_loss: 0.030| per_loss: 0.483 | a_loss: 0.572
Train: Epoch [1362/3000], Step [90/158]| g_loss: 0.794| d_loss: 0.567| gp_loss: 0.054| r_loss: 0.077| p_loss: 0.120| v_loss: 0.028| per_loss: 0.478 | a_loss: 0.582
Train: Epoch [1362/3000], Step [120/158]| g_loss: 0.807| d_loss: 0.587| gp_loss: 0.051| r_loss: 0.082| p_loss: 0.126| v_loss: 0.028| per_loss: 0.495 | a_loss: 0.585
Train: Epoch [1362/3000], Step [150/158]| g_loss: 0.695| d_loss: 0.655| gp_loss: 0.056| r_loss: 0.075| p_loss: 0.123| v_loss: 0.028| per_loss: 0.427 | a_loss: 0.487
Train: Epoch [1363/3000], Step [30/158]| g_loss: 0.741| d_loss: 0.658| gp_loss: 0.145| r_loss: 0.074| p_loss: 0.118| v_loss: 0.028| per_loss: 0.459 | a_loss: 0.534
Train: Epoch [1363/3000], Step [60/158]| g_loss: 0.777| d_loss: 0.584| gp_loss: 0.056| r_loss: 0.081| p_loss: 0.127| v_loss: 0.028| per_loss: 0.459 | a_loss: 0.559
Train: Epoch [1363/3000], Step [90/158]| g_loss: 0.777| d_loss: 0.633| gp_loss: 0.055| r_loss: 0.080| p_loss: 0.134| v_loss: 0.028| per_loss: 0.528 | a_loss: 0.549
Train: Epoch [1363/3000], Step [120/158]| g_loss: 0.778| d_loss: 0.556| gp_loss: 0.058| r_loss: 0.081| p_loss: 0.130| v_loss: 0.029| per_loss: 0.476 | a_loss: 0.556
Train: Epoch [1363/3000], Step [150/158]| g_loss: 0.815| d_loss: 0.626| gp_loss: 0.058| r_loss: 0.080| p_loss: 0.131| v_loss: 0.028| per_loss: 0.480 | a_loss: 0.593
Train: Epoch [1364/3000], Step [30/158]| g_loss: 0.741| d_loss: 0.678| gp_loss: 0.144| r_loss: 0.080| p_loss: 0.125| v_loss: 0.029| per_loss: 0.461 | a_loss: 0.523
Train: Epoch [1364/3000], Step [60/158]| g_loss: 0.816| d_loss: 0.532| gp_loss: 0.054| r_loss: 0.078| p_loss: 0.120| v_loss: 0.029| per_loss: 0.496 | a_loss: 0.599
Train: Epoch [1364/3000], Step [90/158]| g_loss: 0.745| d_loss: 0.572| gp_loss: 0.054| r_loss: 0.078| p_loss: 0.124| v_loss: 0.028| per_loss: 0.469 | a_loss: 0.530
Train: Epoch [1364/3000], Step [120/158]| g_loss: 0.731| d_loss: 0.638| gp_loss: 0.062| r_loss: 0.079| p_loss: 0.124| v_loss: 0.029| per_loss: 0.476 | a_loss: 0.514
Train: Epoch [1364/3000], Step [150/158]| g_loss: 0.827| d_loss: 0.574| gp_loss: 0.058| r_loss: 0.078| p_loss: 0.126| v_loss: 0.027| per_loss: 0.447 | a_loss: 0.614
Train: Epoch [1365/3000], Step [30/158]| g_loss: 0.752| d_loss: 0.761| gp_loss: 0.172| r_loss: 0.080| p_loss: 0.129| v_loss: 0.028| per_loss: 0.448 | a_loss: 0.535
Train: Epoch [1365/3000], Step [60/158]| g_loss: 0.751| d_loss: 0.552| gp_loss: 0.056| r_loss: 0.079| p_loss: 0.125| v_loss: 0.029| per_loss: 0.474 | a_loss: 0.532
Train: Epoch [1365/3000], Step [90/158]| g_loss: 0.760| d_loss: 0.691| gp_loss: 0.053| r_loss: 0.081| p_loss: 0.128| v_loss: 0.028| per_loss: 0.446 | a_loss: 0.542
Train: Epoch [1365/3000], Step [120/158]| g_loss: 0.755| d_loss: 0.598| gp_loss: 0.054| r_loss: 0.078| p_loss: 0.124| v_loss: 0.028| per_loss: 0.494 | a_loss: 0.538
Train: Epoch [1365/3000], Step [150/158]| g_loss: 0.821| d_loss: 0.525| gp_loss: 0.054| r_loss: 0.079| p_loss: 0.123| v_loss: 0.027| per_loss: 0.485 | a_loss: 0.604
Train: Epoch [1366/3000], Step [30/158]| g_loss: 0.717| d_loss: 0.750| gp_loss: 0.130| r_loss: 0.080| p_loss: 0.126| v_loss: 0.028| per_loss: 0.462 | a_loss: 0.500
Train: Epoch [1366/3000], Step [60/158]| g_loss: 0.761| d_loss: 0.623| gp_loss: 0.054| r_loss: 0.077| p_loss: 0.121| v_loss: 0.028| per_loss: 0.495 | a_loss: 0.546
Train: Epoch [1366/3000], Step [90/158]| g_loss: 0.761| d_loss: 0.603| gp_loss: 0.056| r_loss: 0.076| p_loss: 0.122| v_loss: 0.028| per_loss: 0.465 | a_loss: 0.550
Train: Epoch [1366/3000], Step [120/158]| g_loss: 0.737| d_loss: 0.574| gp_loss: 0.060| r_loss: 0.082| p_loss: 0.128| v_loss: 0.029| per_loss: 0.483 | a_loss: 0.513
Train: Epoch [1366/3000], Step [150/158]| g_loss: 0.826| d_loss: 0.503| gp_loss: 0.059| r_loss: 0.077| p_loss: 0.116| v_loss: 0.027| per_loss: 0.467 | a_loss: 0.618
Train: Epoch [1367/3000], Step [30/158]| g_loss: 0.733| d_loss: 0.752| gp_loss: 0.155| r_loss: 0.080| p_loss: 0.124| v_loss: 0.028| per_loss: 0.476 | a_loss: 0.515
Train: Epoch [1367/3000], Step [60/158]| g_loss: 0.709| d_loss: 0.643| gp_loss: 0.053| r_loss: 0.077| p_loss: 0.118| v_loss: 0.027| per_loss: 0.447 | a_loss: 0.501
Train: Epoch [1367/3000], Step [90/158]| g_loss: 0.789| d_loss: 0.538| gp_loss: 0.060| r_loss: 0.078| p_loss: 0.125| v_loss: 0.028| per_loss: 0.487 | a_loss: 0.572
Train: Epoch [1367/3000], Step [120/158]| g_loss: 0.777| d_loss: 0.584| gp_loss: 0.056| r_loss: 0.078| p_loss: 0.120| v_loss: 0.027| per_loss: 0.491 | a_loss: 0.564
Train: Epoch [1367/3000], Step [150/158]| g_loss: 0.834| d_loss: 0.518| gp_loss: 0.061| r_loss: 0.079| p_loss: 0.122| v_loss: 0.029| per_loss: 0.484 | a_loss: 0.617
Train: Epoch [1368/3000], Step [30/158]| g_loss: 0.738| d_loss: 0.690| gp_loss: 0.128| r_loss: 0.079| p_loss: 0.129| v_loss: 0.028| per_loss: 0.477 | a_loss: 0.519
Train: Epoch [1368/3000], Step [60/158]| g_loss: 0.737| d_loss: 0.612| gp_loss: 0.056| r_loss: 0.076| p_loss: 0.119| v_loss: 0.028| per_loss: 0.493 | a_loss: 0.525
Train: Epoch [1368/3000], Step [90/158]| g_loss: 0.774| d_loss: 0.532| gp_loss: 0.057| r_loss: 0.080| p_loss: 0.119| v_loss: 0.027| per_loss: 0.464 | a_loss: 0.561
Train: Epoch [1368/3000], Step [120/158]| g_loss: 0.795| d_loss: 0.560| gp_loss: 0.058| r_loss: 0.084| p_loss: 0.129| v_loss: 0.028| per_loss: 0.471 | a_loss: 0.572
Train: Epoch [1368/3000], Step [150/158]| g_loss: 0.804| d_loss: 0.601| gp_loss: 0.057| r_loss: 0.080| p_loss: 0.123| v_loss: 0.028| per_loss: 0.515 | a_loss: 0.582
Train: Epoch [1369/3000], Step [30/158]| g_loss: 0.704| d_loss: 0.743| gp_loss: 0.121| r_loss: 0.078| p_loss: 0.126| v_loss: 0.027| per_loss: 0.507 | a_loss: 0.485
Train: Epoch [1369/3000], Step [60/158]| g_loss: 0.774| d_loss: 0.572| gp_loss: 0.059| r_loss: 0.080| p_loss: 0.127| v_loss: 0.030| per_loss: 0.461 | a_loss: 0.555
Train: Epoch [1369/3000], Step [90/158]| g_loss: 0.784| d_loss: 0.485| gp_loss: 0.057| r_loss: 0.081| p_loss: 0.125| v_loss: 0.029| per_loss: 0.472 | a_loss: 0.564
Train: Epoch [1369/3000], Step [120/158]| g_loss: 0.780| d_loss: 0.676| gp_loss: 0.056| r_loss: 0.079| p_loss: 0.124| v_loss: 0.028| per_loss: 0.466 | a_loss: 0.565
Train: Epoch [1369/3000], Step [150/158]| g_loss: 0.686| d_loss: 0.638| gp_loss: 0.062| r_loss: 0.077| p_loss: 0.118| v_loss: 0.027| per_loss: 0.485 | a_loss: 0.474
Train: Epoch [1370/3000], Step [30/158]| g_loss: 0.755| d_loss: 0.705| gp_loss: 0.171| r_loss: 0.081| p_loss: 0.125| v_loss: 0.029| per_loss: 0.461 | a_loss: 0.536
Train: Epoch [1370/3000], Step [60/158]| g_loss: 0.788| d_loss: 0.583| gp_loss: 0.053| r_loss: 0.081| p_loss: 0.129| v_loss: 0.028| per_loss: 0.540 | a_loss: 0.560
Train: Epoch [1370/3000], Step [90/158]| g_loss: 0.715| d_loss: 0.702| gp_loss: 0.059| r_loss: 0.081| p_loss: 0.127| v_loss: 0.027| per_loss: 0.462 | a_loss: 0.497
Train: Epoch [1370/3000], Step [120/158]| g_loss: 0.748| d_loss: 0.606| gp_loss: 0.060| r_loss: 0.076| p_loss: 0.120| v_loss: 0.027| per_loss: 0.454 | a_loss: 0.538
Train: Epoch [1370/3000], Step [150/158]| g_loss: 0.818| d_loss: 0.531| gp_loss: 0.059| r_loss: 0.078| p_loss: 0.121| v_loss: 0.028| per_loss: 0.482 | a_loss: 0.603
Train: Epoch [1371/3000], Step [30/158]| g_loss: 0.803| d_loss: 0.695| gp_loss: 0.225| r_loss: 0.081| p_loss: 0.124| v_loss: 0.028| per_loss: 0.473 | a_loss: 0.585
Train: Epoch [1371/3000], Step [60/158]| g_loss: 0.754| d_loss: 0.582| gp_loss: 0.055| r_loss: 0.077| p_loss: 0.125| v_loss: 0.028| per_loss: 0.480 | a_loss: 0.539
Train: Epoch [1371/3000], Step [90/158]| g_loss: 0.767| d_loss: 0.626| gp_loss: 0.053| r_loss: 0.079| p_loss: 0.125| v_loss: 0.028| per_loss: 0.477 | a_loss: 0.549
Train: Epoch [1371/3000], Step [120/158]| g_loss: 0.773| d_loss: 0.532| gp_loss: 0.057| r_loss: 0.078| p_loss: 0.122| v_loss: 0.028| per_loss: 0.474 | a_loss: 0.559
Train: Epoch [1371/3000], Step [150/158]| g_loss: 0.723| d_loss: 0.637| gp_loss: 0.056| r_loss: 0.082| p_loss: 0.129| v_loss: 0.028| per_loss: 0.461 | a_loss: 0.503
Train: Epoch [1372/3000], Step [30/158]| g_loss: 0.673| d_loss: 0.807| gp_loss: 0.145| r_loss: 0.080| p_loss: 0.130| v_loss: 0.028| per_loss: 0.479 | a_loss: 0.452
Train: Epoch [1372/3000], Step [60/158]| g_loss: 0.829| d_loss: 0.549| gp_loss: 0.055| r_loss: 0.082| p_loss: 0.131| v_loss: 0.027| per_loss: 0.498 | a_loss: 0.604
Train: Epoch [1372/3000], Step [90/158]| g_loss: 0.743| d_loss: 0.592| gp_loss: 0.057| r_loss: 0.078| p_loss: 0.124| v_loss: 0.026| per_loss: 0.485 | a_loss: 0.528
Train: Epoch [1372/3000], Step [120/158]| g_loss: 0.777| d_loss: 0.660| gp_loss: 0.055| r_loss: 0.081| p_loss: 0.129| v_loss: 0.029| per_loss: 0.466 | a_loss: 0.556
Train: Epoch [1372/3000], Step [150/158]| g_loss: 0.806| d_loss: 0.586| gp_loss: 0.063| r_loss: 0.080| p_loss: 0.128| v_loss: 0.029| per_loss: 0.479 | a_loss: 0.585
Train: Epoch [1373/3000], Step [30/158]| g_loss: 0.761| d_loss: 0.640| gp_loss: 0.139| r_loss: 0.077| p_loss: 0.126| v_loss: 0.027| per_loss: 0.469 | a_loss: 0.548
Train: Epoch [1373/3000], Step [60/158]| g_loss: 0.832| d_loss: 0.577| gp_loss: 0.057| r_loss: 0.080| p_loss: 0.131| v_loss: 0.029| per_loss: 0.478 | a_loss: 0.609
Train: Epoch [1373/3000], Step [90/158]| g_loss: 0.738| d_loss: 0.598| gp_loss: 0.056| r_loss: 0.077| p_loss: 0.118| v_loss: 0.027| per_loss: 0.473 | a_loss: 0.527
Train: Epoch [1373/3000], Step [120/158]| g_loss: 0.719| d_loss: 0.622| gp_loss: 0.055| r_loss: 0.076| p_loss: 0.118| v_loss: 0.027| per_loss: 0.471 | a_loss: 0.511
Train: Epoch [1373/3000], Step [150/158]| g_loss: 0.748| d_loss: 0.614| gp_loss: 0.060| r_loss: 0.080| p_loss: 0.122| v_loss: 0.029| per_loss: 0.451 | a_loss: 0.533
Train: Epoch [1374/3000], Step [30/158]| g_loss: 0.779| d_loss: 0.734| gp_loss: 0.187| r_loss: 0.082| p_loss: 0.130| v_loss: 0.028| per_loss: 0.484 | a_loss: 0.555
Train: Epoch [1374/3000], Step [60/158]| g_loss: 0.731| d_loss: 0.650| gp_loss: 0.059| r_loss: 0.079| p_loss: 0.132| v_loss: 0.027| per_loss: 0.489 | a_loss: 0.510
Train: Epoch [1374/3000], Step [90/158]| g_loss: 0.786| d_loss: 0.591| gp_loss: 0.061| r_loss: 0.079| p_loss: 0.126| v_loss: 0.028| per_loss: 0.479 | a_loss: 0.568
Train: Epoch [1374/3000], Step [120/158]| g_loss: 0.716| d_loss: 0.610| gp_loss: 0.059| r_loss: 0.079| p_loss: 0.124| v_loss: 0.029| per_loss: 0.472 | a_loss: 0.499
Train: Epoch [1374/3000], Step [150/158]| g_loss: 0.837| d_loss: 0.548| gp_loss: 0.057| r_loss: 0.080| p_loss: 0.124| v_loss: 0.028| per_loss: 0.477 | a_loss: 0.619
Train: Epoch [1375/3000], Step [30/158]| g_loss: 0.750| d_loss: 0.673| gp_loss: 0.093| r_loss: 0.078| p_loss: 0.121| v_loss: 0.028| per_loss: 0.454 | a_loss: 0.538
Train: Epoch [1375/3000], Step [60/158]| g_loss: 0.787| d_loss: 0.557| gp_loss: 0.057| r_loss: 0.074| p_loss: 0.115| v_loss: 0.029| per_loss: 0.494 | a_loss: 0.577
Train: Epoch [1375/3000], Step [90/158]| g_loss: 0.725| d_loss: 0.632| gp_loss: 0.057| r_loss: 0.078| p_loss: 0.118| v_loss: 0.028| per_loss: 0.411 | a_loss: 0.519
Train: Epoch [1375/3000], Step [120/158]| g_loss: 0.789| d_loss: 0.524| gp_loss: 0.060| r_loss: 0.078| p_loss: 0.120| v_loss: 0.027| per_loss: 0.469 | a_loss: 0.576
Train: Epoch [1375/3000], Step [150/158]| g_loss: 0.734| d_loss: 0.638| gp_loss: 0.059| r_loss: 0.082| p_loss: 0.129| v_loss: 0.028| per_loss: 0.482 | a_loss: 0.511
Train: Epoch [1376/3000], Step [30/158]| g_loss: 0.743| d_loss: 0.669| gp_loss: 0.114| r_loss: 0.078| p_loss: 0.122| v_loss: 0.027| per_loss: 0.495 | a_loss: 0.527
Train: Epoch [1376/3000], Step [60/158]| g_loss: 0.765| d_loss: 0.598| gp_loss: 0.059| r_loss: 0.077| p_loss: 0.121| v_loss: 0.027| per_loss: 0.429 | a_loss: 0.559
Train: Epoch [1376/3000], Step [90/158]| g_loss: 0.807| d_loss: 0.514| gp_loss: 0.060| r_loss: 0.077| p_loss: 0.121| v_loss: 0.028| per_loss: 0.481 | a_loss: 0.593
Train: Epoch [1376/3000], Step [120/158]| g_loss: 0.796| d_loss: 0.519| gp_loss: 0.060| r_loss: 0.075| p_loss: 0.111| v_loss: 0.028| per_loss: 0.492 | a_loss: 0.588
Train: Epoch [1376/3000], Step [150/158]| g_loss: 0.738| d_loss: 0.670| gp_loss: 0.061| r_loss: 0.081| p_loss: 0.125| v_loss: 0.028| per_loss: 0.487 | a_loss: 0.518
Train: Epoch [1377/3000], Step [30/158]| g_loss: 0.773| d_loss: 0.685| gp_loss: 0.127| r_loss: 0.080| p_loss: 0.125| v_loss: 0.030| per_loss: 0.486 | a_loss: 0.552
Train: Epoch [1377/3000], Step [60/158]| g_loss: 0.722| d_loss: 0.628| gp_loss: 0.058| r_loss: 0.079| p_loss: 0.127| v_loss: 0.027| per_loss: 0.461 | a_loss: 0.506
Train: Epoch [1377/3000], Step [90/158]| g_loss: 0.785| d_loss: 0.636| gp_loss: 0.064| r_loss: 0.083| p_loss: 0.135| v_loss: 0.028| per_loss: 0.479 | a_loss: 0.558
Train: Epoch [1377/3000], Step [120/158]| g_loss: 0.664| d_loss: 0.772| gp_loss: 0.064| r_loss: 0.079| p_loss: 0.130| v_loss: 0.027| per_loss: 0.443 | a_loss: 0.450
Train: Epoch [1377/3000], Step [150/158]| g_loss: 0.777| d_loss: 0.495| gp_loss: 0.066| r_loss: 0.082| p_loss: 0.128| v_loss: 0.028| per_loss: 0.487 | a_loss: 0.554
Train: Epoch [1378/3000], Step [30/158]| g_loss: 0.835| d_loss: 0.631| gp_loss: 0.128| r_loss: 0.078| p_loss: 0.126| v_loss: 0.028| per_loss: 0.467 | a_loss: 0.619
Train: Epoch [1378/3000], Step [60/158]| g_loss: 0.749| d_loss: 0.608| gp_loss: 0.059| r_loss: 0.076| p_loss: 0.119| v_loss: 0.028| per_loss: 0.463 | a_loss: 0.539
Train: Epoch [1378/3000], Step [90/158]| g_loss: 0.763| d_loss: 0.614| gp_loss: 0.061| r_loss: 0.079| p_loss: 0.119| v_loss: 0.029| per_loss: 0.442 | a_loss: 0.552
Train: Epoch [1378/3000], Step [120/158]| g_loss: 0.750| d_loss: 0.608| gp_loss: 0.060| r_loss: 0.079| p_loss: 0.125| v_loss: 0.029| per_loss: 0.468 | a_loss: 0.533
Train: Epoch [1378/3000], Step [150/158]| g_loss: 0.747| d_loss: 0.584| gp_loss: 0.062| r_loss: 0.075| p_loss: 0.120| v_loss: 0.028| per_loss: 0.447 | a_loss: 0.539
Train: Epoch [1379/3000], Step [30/158]| g_loss: 0.730| d_loss: 0.775| gp_loss: 0.137| r_loss: 0.081| p_loss: 0.132| v_loss: 0.029| per_loss: 0.455 | a_loss: 0.508
Train: Epoch [1379/3000], Step [60/158]| g_loss: 0.767| d_loss: 0.557| gp_loss: 0.061| r_loss: 0.086| p_loss: 0.138| v_loss: 0.028| per_loss: 0.490 | a_loss: 0.536
Train: Epoch [1379/3000], Step [90/158]| g_loss: 0.818| d_loss: 0.549| gp_loss: 0.063| r_loss: 0.079| p_loss: 0.126| v_loss: 0.027| per_loss: 0.485 | a_loss: 0.600
Train: Epoch [1379/3000], Step [120/158]| g_loss: 0.743| d_loss: 0.573| gp_loss: 0.059| r_loss: 0.076| p_loss: 0.119| v_loss: 0.028| per_loss: 0.446 | a_loss: 0.535
Train: Epoch [1379/3000], Step [150/158]| g_loss: 0.721| d_loss: 0.661| gp_loss: 0.061| r_loss: 0.076| p_loss: 0.119| v_loss: 0.029| per_loss: 0.464 | a_loss: 0.510
Train: Epoch [1380/3000], Step [30/158]| g_loss: 0.724| d_loss: 0.709| gp_loss: 0.158| r_loss: 0.076| p_loss: 0.118| v_loss: 0.028| per_loss: 0.518 | a_loss: 0.509
Train: Epoch [1380/3000], Step [60/158]| g_loss: 0.733| d_loss: 0.576| gp_loss: 0.056| r_loss: 0.080| p_loss: 0.119| v_loss: 0.028| per_loss: 0.458 | a_loss: 0.520
Train: Epoch [1380/3000], Step [90/158]| g_loss: 0.772| d_loss: 0.559| gp_loss: 0.059| r_loss: 0.074| p_loss: 0.114| v_loss: 0.028| per_loss: 0.449 | a_loss: 0.568
Train: Epoch [1380/3000], Step [120/158]| g_loss: 0.728| d_loss: 0.624| gp_loss: 0.060| r_loss: 0.074| p_loss: 0.115| v_loss: 0.027| per_loss: 0.478 | a_loss: 0.522
Train: Epoch [1380/3000], Step [150/158]| g_loss: 0.772| d_loss: 0.600| gp_loss: 0.063| r_loss: 0.080| p_loss: 0.128| v_loss: 0.028| per_loss: 0.441 | a_loss: 0.555
Train: Epoch [1381/3000], Step [30/158]| g_loss: 0.736| d_loss: 0.756| gp_loss: 0.123| r_loss: 0.083| p_loss: 0.131| v_loss: 0.028| per_loss: 0.487 | a_loss: 0.511
Train: Epoch [1381/3000], Step [60/158]| g_loss: 0.709| d_loss: 0.665| gp_loss: 0.061| r_loss: 0.079| p_loss: 0.127| v_loss: 0.027| per_loss: 0.438 | a_loss: 0.496
Train: Epoch [1381/3000], Step [90/158]| g_loss: 0.789| d_loss: 0.599| gp_loss: 0.064| r_loss: 0.079| p_loss: 0.124| v_loss: 0.028| per_loss: 0.465 | a_loss: 0.574
Train: Epoch [1381/3000], Step [120/158]| g_loss: 0.774| d_loss: 0.524| gp_loss: 0.068| r_loss: 0.078| p_loss: 0.123| v_loss: 0.028| per_loss: 0.463 | a_loss: 0.561
Train: Epoch [1381/3000], Step [150/158]| g_loss: 0.794| d_loss: 0.539| gp_loss: 0.064| r_loss: 0.077| p_loss: 0.121| v_loss: 0.028| per_loss: 0.492 | a_loss: 0.580
Train: Epoch [1382/3000], Step [30/158]| g_loss: 0.777| d_loss: 0.651| gp_loss: 0.165| r_loss: 0.080| p_loss: 0.126| v_loss: 0.030| per_loss: 0.461 | a_loss: 0.557
Train: Epoch [1382/3000], Step [60/158]| g_loss: 0.800| d_loss: 0.605| gp_loss: 0.056| r_loss: 0.078| p_loss: 0.126| v_loss: 0.027| per_loss: 0.456 | a_loss: 0.587
Train: Epoch [1382/3000], Step [90/158]| g_loss: 0.743| d_loss: 0.594| gp_loss: 0.063| r_loss: 0.079| p_loss: 0.132| v_loss: 0.028| per_loss: 0.444 | a_loss: 0.526
Train: Epoch [1382/3000], Step [120/158]| g_loss: 0.711| d_loss: 0.688| gp_loss: 0.062| r_loss: 0.079| p_loss: 0.126| v_loss: 0.027| per_loss: 0.459 | a_loss: 0.496
Train: Epoch [1382/3000], Step [150/158]| g_loss: 0.775| d_loss: 0.541| gp_loss: 0.066| r_loss: 0.078| p_loss: 0.121| v_loss: 0.027| per_loss: 0.485 | a_loss: 0.561
Train: Epoch [1383/3000], Step [30/158]| g_loss: 0.762| d_loss: 0.746| gp_loss: 0.155| r_loss: 0.078| p_loss: 0.129| v_loss: 0.027| per_loss: 0.475 | a_loss: 0.544
Train: Epoch [1383/3000], Step [60/158]| g_loss: 0.801| d_loss: 0.528| gp_loss: 0.060| r_loss: 0.080| p_loss: 0.131| v_loss: 0.028| per_loss: 0.463 | a_loss: 0.581
Train: Epoch [1383/3000], Step [90/158]| g_loss: 0.791| d_loss: 0.664| gp_loss: 0.056| r_loss: 0.081| p_loss: 0.127| v_loss: 0.028| per_loss: 0.502 | a_loss: 0.568
Train: Epoch [1383/3000], Step [120/158]| g_loss: 0.725| d_loss: 0.629| gp_loss: 0.069| r_loss: 0.081| p_loss: 0.131| v_loss: 0.027| per_loss: 0.464 | a_loss: 0.505
Train: Epoch [1383/3000], Step [150/158]| g_loss: 0.762| d_loss: 0.581| gp_loss: 0.062| r_loss: 0.078| p_loss: 0.123| v_loss: 0.029| per_loss: 0.466 | a_loss: 0.548
Train: Epoch [1384/3000], Step [30/158]| g_loss: 0.768| d_loss: 0.750| gp_loss: 0.162| r_loss: 0.080| p_loss: 0.124| v_loss: 0.027| per_loss: 0.495 | a_loss: 0.549
Train: Epoch [1384/3000], Step [60/158]| g_loss: 0.725| d_loss: 0.602| gp_loss: 0.057| r_loss: 0.077| p_loss: 0.121| v_loss: 0.028| per_loss: 0.456 | a_loss: 0.514
Train: Epoch [1384/3000], Step [90/158]| g_loss: 0.758| d_loss: 0.569| gp_loss: 0.056| r_loss: 0.078| p_loss: 0.120| v_loss: 0.028| per_loss: 0.479 | a_loss: 0.544
Train: Epoch [1384/3000], Step [120/158]| g_loss: 0.758| d_loss: 0.561| gp_loss: 0.060| r_loss: 0.079| p_loss: 0.125| v_loss: 0.028| per_loss: 0.467 | a_loss: 0.542
Train: Epoch [1384/3000], Step [150/158]| g_loss: 0.811| d_loss: 0.570| gp_loss: 0.062| r_loss: 0.076| p_loss: 0.123| v_loss: 0.027| per_loss: 0.454 | a_loss: 0.600
Train: Epoch [1385/3000], Step [30/158]| g_loss: 0.740| d_loss: 0.726| gp_loss: 0.072| r_loss: 0.081| p_loss: 0.132| v_loss: 0.028| per_loss: 0.462 | a_loss: 0.520
Train: Epoch [1385/3000], Step [60/158]| g_loss: 0.808| d_loss: 0.558| gp_loss: 0.060| r_loss: 0.081| p_loss: 0.127| v_loss: 0.029| per_loss: 0.464 | a_loss: 0.589
Train: Epoch [1385/3000], Step [90/158]| g_loss: 0.820| d_loss: 0.557| gp_loss: 0.062| r_loss: 0.079| p_loss: 0.121| v_loss: 0.028| per_loss: 0.486 | a_loss: 0.604
Train: Epoch [1385/3000], Step [120/158]| g_loss: 0.704| d_loss: 0.654| gp_loss: 0.059| r_loss: 0.076| p_loss: 0.120| v_loss: 0.028| per_loss: 0.477 | a_loss: 0.492
Train: Epoch [1385/3000], Step [150/158]| g_loss: 0.763| d_loss: 0.600| gp_loss: 0.063| r_loss: 0.078| p_loss: 0.119| v_loss: 0.027| per_loss: 0.493 | a_loss: 0.549
Train: Epoch [1386/3000], Step [30/158]| g_loss: 0.723| d_loss: 0.738| gp_loss: 0.191| r_loss: 0.076| p_loss: 0.119| v_loss: 0.027| per_loss: 0.439 | a_loss: 0.517
Train: Epoch [1386/3000], Step [60/158]| g_loss: 0.755| d_loss: 0.682| gp_loss: 0.054| r_loss: 0.078| p_loss: 0.127| v_loss: 0.026| per_loss: 0.446 | a_loss: 0.543
Train: Epoch [1386/3000], Step [90/158]| g_loss: 0.722| d_loss: 0.629| gp_loss: 0.060| r_loss: 0.079| p_loss: 0.127| v_loss: 0.028| per_loss: 0.464 | a_loss: 0.505
Train: Epoch [1386/3000], Step [120/158]| g_loss: 0.762| d_loss: 0.553| gp_loss: 0.056| r_loss: 0.080| p_loss: 0.127| v_loss: 0.027| per_loss: 0.484 | a_loss: 0.543
Train: Epoch [1386/3000], Step [150/158]| g_loss: 0.810| d_loss: 0.596| gp_loss: 0.058| r_loss: 0.082| p_loss: 0.131| v_loss: 0.028| per_loss: 0.490 | a_loss: 0.585
Train: Epoch [1387/3000], Step [30/158]| g_loss: 0.739| d_loss: 0.729| gp_loss: 0.141| r_loss: 0.078| p_loss: 0.126| v_loss: 0.028| per_loss: 0.462 | a_loss: 0.524
Train: Epoch [1387/3000], Step [60/158]| g_loss: 0.774| d_loss: 0.514| gp_loss: 0.056| r_loss: 0.079| p_loss: 0.123| v_loss: 0.028| per_loss: 0.482 | a_loss: 0.558
Train: Epoch [1387/3000], Step [90/158]| g_loss: 0.811| d_loss: 0.509| gp_loss: 0.056| r_loss: 0.075| p_loss: 0.121| v_loss: 0.028| per_loss: 0.457 | a_loss: 0.602
Train: Epoch [1387/3000], Step [120/158]| g_loss: 0.751| d_loss: 0.635| gp_loss: 0.058| r_loss: 0.078| p_loss: 0.124| v_loss: 0.028| per_loss: 0.474 | a_loss: 0.535
Train: Epoch [1387/3000], Step [150/158]| g_loss: 0.709| d_loss: 0.628| gp_loss: 0.059| r_loss: 0.075| p_loss: 0.117| v_loss: 0.027| per_loss: 0.448 | a_loss: 0.504
Train: Epoch [1388/3000], Step [30/158]| g_loss: 0.762| d_loss: 0.610| gp_loss: 0.118| r_loss: 0.077| p_loss: 0.119| v_loss: 0.027| per_loss: 0.464 | a_loss: 0.553
Train: Epoch [1388/3000], Step [60/158]| g_loss: 0.774| d_loss: 0.629| gp_loss: 0.057| r_loss: 0.079| p_loss: 0.122| v_loss: 0.028| per_loss: 0.467 | a_loss: 0.559
Train: Epoch [1388/3000], Step [90/158]| g_loss: 0.757| d_loss: 0.540| gp_loss: 0.061| r_loss: 0.076| p_loss: 0.117| v_loss: 0.027| per_loss: 0.452 | a_loss: 0.551
Train: Epoch [1388/3000], Step [120/158]| g_loss: 0.725| d_loss: 0.690| gp_loss: 0.061| r_loss: 0.076| p_loss: 0.123| v_loss: 0.027| per_loss: 0.468 | a_loss: 0.513
Train: Epoch [1388/3000], Step [150/158]| g_loss: 0.751| d_loss: 0.622| gp_loss: 0.064| r_loss: 0.077| p_loss: 0.119| v_loss: 0.026| per_loss: 0.466 | a_loss: 0.541
Train: Epoch [1389/3000], Step [30/158]| g_loss: 0.787| d_loss: 0.656| gp_loss: 0.149| r_loss: 0.081| p_loss: 0.128| v_loss: 0.029| per_loss: 0.469 | a_loss: 0.565
Train: Epoch [1389/3000], Step [60/158]| g_loss: 0.768| d_loss: 0.550| gp_loss: 0.057| r_loss: 0.074| p_loss: 0.117| v_loss: 0.027| per_loss: 0.483 | a_loss: 0.560
Train: Epoch [1389/3000], Step [90/158]| g_loss: 0.760| d_loss: 0.589| gp_loss: 0.056| r_loss: 0.078| p_loss: 0.121| v_loss: 0.029| per_loss: 0.493 | a_loss: 0.543
Train: Epoch [1389/3000], Step [120/158]| g_loss: 0.737| d_loss: 0.653| gp_loss: 0.059| r_loss: 0.078| p_loss: 0.118| v_loss: 0.027| per_loss: 0.517 | a_loss: 0.522
Train: Epoch [1389/3000], Step [150/158]| g_loss: 0.748| d_loss: 0.648| gp_loss: 0.059| r_loss: 0.077| p_loss: 0.118| v_loss: 0.027| per_loss: 0.441 | a_loss: 0.540
Train: Epoch [1390/3000], Step [30/158]| g_loss: 0.739| d_loss: 0.698| gp_loss: 0.133| r_loss: 0.080| p_loss: 0.126| v_loss: 0.027| per_loss: 0.430 | a_loss: 0.526
Train: Epoch [1390/3000], Step [60/158]| g_loss: 0.782| d_loss: 0.505| gp_loss: 0.056| r_loss: 0.079| p_loss: 0.120| v_loss: 0.028| per_loss: 0.507 | a_loss: 0.564
Train: Epoch [1390/3000], Step [90/158]| g_loss: 0.782| d_loss: 0.636| gp_loss: 0.058| r_loss: 0.079| p_loss: 0.121| v_loss: 0.027| per_loss: 0.498 | a_loss: 0.566
Train: Epoch [1390/3000], Step [120/158]| g_loss: 0.775| d_loss: 0.604| gp_loss: 0.060| r_loss: 0.078| p_loss: 0.123| v_loss: 0.028| per_loss: 0.455 | a_loss: 0.562
Train: Epoch [1390/3000], Step [150/158]| g_loss: 0.731| d_loss: 0.630| gp_loss: 0.061| r_loss: 0.076| p_loss: 0.122| v_loss: 0.027| per_loss: 0.481 | a_loss: 0.519
Train: Epoch [1391/3000], Step [30/158]| g_loss: 0.791| d_loss: 0.594| gp_loss: 0.126| r_loss: 0.077| p_loss: 0.119| v_loss: 0.028| per_loss: 0.474 | a_loss: 0.579
Train: Epoch [1391/3000], Step [60/158]| g_loss: 0.728| d_loss: 0.626| gp_loss: 0.059| r_loss: 0.081| p_loss: 0.130| v_loss: 0.029| per_loss: 0.463 | a_loss: 0.506
Train: Epoch [1391/3000], Step [90/158]| g_loss: 0.790| d_loss: 0.606| gp_loss: 0.058| r_loss: 0.077| p_loss: 0.121| v_loss: 0.028| per_loss: 0.444 | a_loss: 0.580
Train: Epoch [1391/3000], Step [120/158]| g_loss: 0.700| d_loss: 0.660| gp_loss: 0.060| r_loss: 0.076| p_loss: 0.123| v_loss: 0.028| per_loss: 0.457 | a_loss: 0.489
Train: Epoch [1391/3000], Step [150/158]| g_loss: 0.783| d_loss: 0.595| gp_loss: 0.057| r_loss: 0.077| p_loss: 0.119| v_loss: 0.028| per_loss: 0.464 | a_loss: 0.571
Train: Epoch [1392/3000], Step [30/158]| g_loss: 0.774| d_loss: 0.639| gp_loss: 0.160| r_loss: 0.077| p_loss: 0.119| v_loss: 0.028| per_loss: 0.507 | a_loss: 0.558
Train: Epoch [1392/3000], Step [60/158]| g_loss: 0.750| d_loss: 0.602| gp_loss: 0.056| r_loss: 0.073| p_loss: 0.115| v_loss: 0.028| per_loss: 0.453 | a_loss: 0.546
Train: Epoch [1392/3000], Step [90/158]| g_loss: 0.767| d_loss: 0.574| gp_loss: 0.059| r_loss: 0.078| p_loss: 0.124| v_loss: 0.028| per_loss: 0.447 | a_loss: 0.554
Train: Epoch [1392/3000], Step [120/158]| g_loss: 0.773| d_loss: 0.597| gp_loss: 0.059| r_loss: 0.081| p_loss: 0.126| v_loss: 0.029| per_loss: 0.485 | a_loss: 0.552
Train: Epoch [1392/3000], Step [150/158]| g_loss: 0.740| d_loss: 0.637| gp_loss: 0.062| r_loss: 0.080| p_loss: 0.127| v_loss: 0.028| per_loss: 0.467 | a_loss: 0.522
Train: Epoch [1393/3000], Step [30/158]| g_loss: 0.781| d_loss: 0.689| gp_loss: 0.159| r_loss: 0.080| p_loss: 0.128| v_loss: 0.027| per_loss: 0.482 | a_loss: 0.562
Train: Epoch [1393/3000], Step [60/158]| g_loss: 0.767| d_loss: 0.584| gp_loss: 0.058| r_loss: 0.079| p_loss: 0.127| v_loss: 0.029| per_loss: 0.518 | a_loss: 0.544
Train: Epoch [1393/3000], Step [90/158]| g_loss: 0.768| d_loss: 0.628| gp_loss: 0.057| r_loss: 0.079| p_loss: 0.121| v_loss: 0.029| per_loss: 0.459 | a_loss: 0.554
Train: Epoch [1393/3000], Step [120/158]| g_loss: 0.797| d_loss: 0.561| gp_loss: 0.058| r_loss: 0.081| p_loss: 0.130| v_loss: 0.028| per_loss: 0.467 | a_loss: 0.576
Train: Epoch [1393/3000], Step [150/158]| g_loss: 0.760| d_loss: 0.639| gp_loss: 0.060| r_loss: 0.078| p_loss: 0.130| v_loss: 0.027| per_loss: 0.494 | a_loss: 0.540
Train: Epoch [1394/3000], Step [30/158]| g_loss: 0.763| d_loss: 0.712| gp_loss: 0.172| r_loss: 0.080| p_loss: 0.127| v_loss: 0.027| per_loss: 0.484 | a_loss: 0.543
Train: Epoch [1394/3000], Step [60/158]| g_loss: 0.780| d_loss: 0.628| gp_loss: 0.056| r_loss: 0.080| p_loss: 0.132| v_loss: 0.028| per_loss: 0.474 | a_loss: 0.559
Train: Epoch [1394/3000], Step [90/158]| g_loss: 0.728| d_loss: 0.650| gp_loss: 0.058| r_loss: 0.076| p_loss: 0.132| v_loss: 0.028| per_loss: 0.521 | a_loss: 0.506
Train: Epoch [1394/3000], Step [120/158]| g_loss: 0.841| d_loss: 0.573| gp_loss: 0.063| r_loss: 0.083| p_loss: 0.134| v_loss: 0.029| per_loss: 0.479 | a_loss: 0.614
Train: Epoch [1394/3000], Step [150/158]| g_loss: 0.772| d_loss: 0.590| gp_loss: 0.061| r_loss: 0.083| p_loss: 0.136| v_loss: 0.029| per_loss: 0.493 | a_loss: 0.544
Train: Epoch [1395/3000], Step [30/158]| g_loss: 0.775| d_loss: 0.642| gp_loss: 0.103| r_loss: 0.081| p_loss: 0.129| v_loss: 0.028| per_loss: 0.484 | a_loss: 0.553
Train: Epoch [1395/3000], Step [60/158]| g_loss: 0.749| d_loss: 0.653| gp_loss: 0.062| r_loss: 0.078| p_loss: 0.129| v_loss: 0.028| per_loss: 0.483 | a_loss: 0.531
Train: Epoch [1395/3000], Step [90/158]| g_loss: 0.796| d_loss: 0.540| gp_loss: 0.061| r_loss: 0.081| p_loss: 0.129| v_loss: 0.029| per_loss: 0.471 | a_loss: 0.575
Train: Epoch [1395/3000], Step [120/158]| g_loss: 0.744| d_loss: 0.624| gp_loss: 0.060| r_loss: 0.077| p_loss: 0.123| v_loss: 0.027| per_loss: 0.477 | a_loss: 0.531
Train: Epoch [1395/3000], Step [150/158]| g_loss: 0.709| d_loss: 0.611| gp_loss: 0.066| r_loss: 0.076| p_loss: 0.119| v_loss: 0.029| per_loss: 0.483 | a_loss: 0.496
Train: Epoch [1396/3000], Step [30/158]| g_loss: 0.763| d_loss: 0.695| gp_loss: 0.143| r_loss: 0.080| p_loss: 0.131| v_loss: 0.029| per_loss: 0.485 | a_loss: 0.540
Train: Epoch [1396/3000], Step [60/158]| g_loss: 0.713| d_loss: 0.640| gp_loss: 0.059| r_loss: 0.079| p_loss: 0.130| v_loss: 0.028| per_loss: 0.464 | a_loss: 0.495
Train: Epoch [1396/3000], Step [90/158]| g_loss: 0.802| d_loss: 0.621| gp_loss: 0.064| r_loss: 0.081| p_loss: 0.135| v_loss: 0.028| per_loss: 0.477 | a_loss: 0.577
Train: Epoch [1396/3000], Step [120/158]| g_loss: 0.786| d_loss: 0.547| gp_loss: 0.061| r_loss: 0.082| p_loss: 0.127| v_loss: 0.028| per_loss: 0.441 | a_loss: 0.569
Train: Epoch [1396/3000], Step [150/158]| g_loss: 0.758| d_loss: 0.655| gp_loss: 0.063| r_loss: 0.079| p_loss: 0.122| v_loss: 0.027| per_loss: 0.488 | a_loss: 0.542
Train: Epoch [1397/3000], Step [30/158]| g_loss: 0.793| d_loss: 0.604| gp_loss: 0.138| r_loss: 0.075| p_loss: 0.115| v_loss: 0.028| per_loss: 0.495 | a_loss: 0.584
Train: Epoch [1397/3000], Step [60/158]| g_loss: 0.758| d_loss: 0.633| gp_loss: 0.062| r_loss: 0.079| p_loss: 0.122| v_loss: 0.028| per_loss: 0.422 | a_loss: 0.548
Train: Epoch [1397/3000], Step [90/158]| g_loss: 0.677| d_loss: 0.605| gp_loss: 0.061| r_loss: 0.074| p_loss: 0.116| v_loss: 0.028| per_loss: 0.438 | a_loss: 0.473
Train: Epoch [1397/3000], Step [120/158]| g_loss: 0.801| d_loss: 0.621| gp_loss: 0.064| r_loss: 0.073| p_loss: 0.119| v_loss: 0.028| per_loss: 0.470 | a_loss: 0.593
Train: Epoch [1397/3000], Step [150/158]| g_loss: 0.786| d_loss: 0.552| gp_loss: 0.067| r_loss: 0.080| p_loss: 0.125| v_loss: 0.029| per_loss: 0.478 | a_loss: 0.567
Train: Epoch [1398/3000], Step [30/158]| g_loss: 0.770| d_loss: 0.738| gp_loss: 0.173| r_loss: 0.077| p_loss: 0.119| v_loss: 0.028| per_loss: 0.477 | a_loss: 0.558
Train: Epoch [1398/3000], Step [60/158]| g_loss: 0.730| d_loss: 0.554| gp_loss: 0.061| r_loss: 0.081| p_loss: 0.123| v_loss: 0.029| per_loss: 0.469 | a_loss: 0.512
Train: Epoch [1398/3000], Step [90/158]| g_loss: 0.798| d_loss: 0.624| gp_loss: 0.066| r_loss: 0.080| p_loss: 0.127| v_loss: 0.028| per_loss: 0.463 | a_loss: 0.580
Train: Epoch [1398/3000], Step [120/158]| g_loss: 0.729| d_loss: 0.684| gp_loss: 0.057| r_loss: 0.075| p_loss: 0.122| v_loss: 0.028| per_loss: 0.496 | a_loss: 0.515
Train: Epoch [1398/3000], Step [150/158]| g_loss: 0.770| d_loss: 0.560| gp_loss: 0.065| r_loss: 0.076| p_loss: 0.118| v_loss: 0.027| per_loss: 0.462 | a_loss: 0.562
Train: Epoch [1399/3000], Step [30/158]| g_loss: 0.712| d_loss: 0.875| gp_loss: 0.201| r_loss: 0.079| p_loss: 0.125| v_loss: 0.028| per_loss: 0.441 | a_loss: 0.499
Train: Epoch [1399/3000], Step [60/158]| g_loss: 0.735| d_loss: 0.641| gp_loss: 0.054| r_loss: 0.079| p_loss: 0.125| v_loss: 0.028| per_loss: 0.464 | a_loss: 0.518
Train: Epoch [1399/3000], Step [90/158]| g_loss: 0.737| d_loss: 0.542| gp_loss: 0.058| r_loss: 0.073| p_loss: 0.116| v_loss: 0.026| per_loss: 0.501 | a_loss: 0.529
Train: Epoch [1399/3000], Step [120/158]| g_loss: 0.757| d_loss: 0.623| gp_loss: 0.057| r_loss: 0.078| p_loss: 0.121| v_loss: 0.027| per_loss: 0.488 | a_loss: 0.543
Train: Epoch [1399/3000], Step [150/158]| g_loss: 0.787| d_loss: 0.518| gp_loss: 0.061| r_loss: 0.073| p_loss: 0.114| v_loss: 0.027| per_loss: 0.460 | a_loss: 0.584
Train: Epoch [1400/3000], Step [30/158]| g_loss: 0.760| d_loss: 0.729| gp_loss: 0.157| r_loss: 0.076| p_loss: 0.113| v_loss: 0.027| per_loss: 0.469 | a_loss: 0.553
Train: Epoch [1400/3000], Step [60/158]| g_loss: 0.751| d_loss: 0.606| gp_loss: 0.058| r_loss: 0.077| p_loss: 0.122| v_loss: 0.028| per_loss: 0.486 | a_loss: 0.537
Train: Epoch [1400/3000], Step [90/158]| g_loss: 0.734| d_loss: 0.627| gp_loss: 0.056| r_loss: 0.077| p_loss: 0.118| v_loss: 0.027| per_loss: 0.454 | a_loss: 0.525
Train: Epoch [1400/3000], Step [120/158]| g_loss: 0.709| d_loss: 0.629| gp_loss: 0.057| r_loss: 0.075| p_loss: 0.117| v_loss: 0.027| per_loss: 0.451 | a_loss: 0.503
Train: Epoch [1400/3000], Step [150/158]| g_loss: 0.764| d_loss: 0.572| gp_loss: 0.063| r_loss: 0.075| p_loss: 0.118| v_loss: 0.028| per_loss: 0.445 | a_loss: 0.558
Test: Epoch [1400/3000]| g_loss: 0.672| r_loss: 0.406| p_loss: 0.304| v_loss: 0.026
Train: Epoch [1401/3000], Step [30/158]| g_loss: 0.814| d_loss: 0.549| gp_loss: 0.055| r_loss: 0.077| p_loss: 0.123| v_loss: 0.029| per_loss: 0.465 | a_loss: 0.600
Train: Epoch [1401/3000], Step [60/158]| g_loss: 0.770| d_loss: 0.624| gp_loss: 0.058| r_loss: 0.079| p_loss: 0.122| v_loss: 0.028| per_loss: 0.469 | a_loss: 0.555
Train: Epoch [1401/3000], Step [90/158]| g_loss: 0.713| d_loss: 0.649| gp_loss: 0.056| r_loss: 0.075| p_loss: 0.119| v_loss: 0.027| per_loss: 0.460 | a_loss: 0.505
Train: Epoch [1401/3000], Step [120/158]| g_loss: 0.772| d_loss: 0.631| gp_loss: 0.060| r_loss: 0.077| p_loss: 0.118| v_loss: 0.027| per_loss: 0.491 | a_loss: 0.561
Train: Epoch [1401/3000], Step [150/158]| g_loss: 0.744| d_loss: 0.532| gp_loss: 0.062| r_loss: 0.073| p_loss: 0.112| v_loss: 0.027| per_loss: 0.428 | a_loss: 0.545
Train: Epoch [1402/3000], Step [30/158]| g_loss: 0.776| d_loss: 0.769| gp_loss: 0.160| r_loss: 0.082| p_loss: 0.131| v_loss: 0.027| per_loss: 0.462 | a_loss: 0.555
Train: Epoch [1402/3000], Step [60/158]| g_loss: 0.757| d_loss: 0.609| gp_loss: 0.065| r_loss: 0.080| p_loss: 0.130| v_loss: 0.028| per_loss: 0.452 | a_loss: 0.540
Train: Epoch [1402/3000], Step [90/158]| g_loss: 0.802| d_loss: 0.579| gp_loss: 0.062| r_loss: 0.080| p_loss: 0.130| v_loss: 0.028| per_loss: 0.442 | a_loss: 0.586
Train: Epoch [1402/3000], Step [120/158]| g_loss: 0.777| d_loss: 0.604| gp_loss: 0.060| r_loss: 0.075| p_loss: 0.126| v_loss: 0.027| per_loss: 0.464 | a_loss: 0.564
Train: Epoch [1402/3000], Step [150/158]| g_loss: 0.750| d_loss: 0.612| gp_loss: 0.058| r_loss: 0.077| p_loss: 0.118| v_loss: 0.027| per_loss: 0.506 | a_loss: 0.536
Train: Epoch [1403/3000], Step [30/158]| g_loss: 0.699| d_loss: 0.730| gp_loss: 0.144| r_loss: 0.076| p_loss: 0.117| v_loss: 0.027| per_loss: 0.473 | a_loss: 0.490
Train: Epoch [1403/3000], Step [60/158]| g_loss: 0.823| d_loss: 0.490| gp_loss: 0.057| r_loss: 0.075| p_loss: 0.113| v_loss: 0.027| per_loss: 0.465 | a_loss: 0.618
Train: Epoch [1403/3000], Step [90/158]| g_loss: 0.753| d_loss: 0.695| gp_loss: 0.054| r_loss: 0.079| p_loss: 0.125| v_loss: 0.027| per_loss: 0.447 | a_loss: 0.540
Train: Epoch [1403/3000], Step [120/158]| g_loss: 0.717| d_loss: 0.515| gp_loss: 0.062| r_loss: 0.076| p_loss: 0.116| v_loss: 0.027| per_loss: 0.470 | a_loss: 0.510
Train: Epoch [1403/3000], Step [150/158]| g_loss: 0.780| d_loss: 0.580| gp_loss: 0.057| r_loss: 0.078| p_loss: 0.120| v_loss: 0.027| per_loss: 0.445 | a_loss: 0.570
Train: Epoch [1404/3000], Step [30/158]| g_loss: 0.691| d_loss: 0.797| gp_loss: 0.135| r_loss: 0.076| p_loss: 0.121| v_loss: 0.027| per_loss: 0.422 | a_loss: 0.486
Train: Epoch [1404/3000], Step [60/158]| g_loss: 0.752| d_loss: 0.606| gp_loss: 0.063| r_loss: 0.078| p_loss: 0.127| v_loss: 0.027| per_loss: 0.475 | a_loss: 0.536
Train: Epoch [1404/3000], Step [90/158]| g_loss: 0.789| d_loss: 0.608| gp_loss: 0.054| r_loss: 0.078| p_loss: 0.118| v_loss: 0.027| per_loss: 0.443 | a_loss: 0.581
Train: Epoch [1404/3000], Step [120/158]| g_loss: 0.766| d_loss: 0.578| gp_loss: 0.057| r_loss: 0.077| p_loss: 0.120| v_loss: 0.026| per_loss: 0.427 | a_loss: 0.559
Train: Epoch [1404/3000], Step [150/158]| g_loss: 0.750| d_loss: 0.646| gp_loss: 0.056| r_loss: 0.080| p_loss: 0.127| v_loss: 0.028| per_loss: 0.508 | a_loss: 0.528
Train: Epoch [1405/3000], Step [30/158]| g_loss: 0.761| d_loss: 0.716| gp_loss: 0.173| r_loss: 0.079| p_loss: 0.127| v_loss: 0.028| per_loss: 0.438 | a_loss: 0.547
Train: Epoch [1405/3000], Step [60/158]| g_loss: 0.785| d_loss: 0.550| gp_loss: 0.055| r_loss: 0.078| p_loss: 0.122| v_loss: 0.027| per_loss: 0.480 | a_loss: 0.572
Train: Epoch [1405/3000], Step [90/158]| g_loss: 0.799| d_loss: 0.559| gp_loss: 0.058| r_loss: 0.079| p_loss: 0.126| v_loss: 0.028| per_loss: 0.443 | a_loss: 0.585
Train: Epoch [1405/3000], Step [120/158]| g_loss: 0.755| d_loss: 0.642| gp_loss: 0.058| r_loss: 0.080| p_loss: 0.125| v_loss: 0.027| per_loss: 0.442 | a_loss: 0.542
Train: Epoch [1405/3000], Step [150/158]| g_loss: 0.701| d_loss: 0.667| gp_loss: 0.056| r_loss: 0.079| p_loss: 0.124| v_loss: 0.027| per_loss: 0.466 | a_loss: 0.486
Train: Epoch [1406/3000], Step [30/158]| g_loss: 0.722| d_loss: 0.788| gp_loss: 0.230| r_loss: 0.081| p_loss: 0.127| v_loss: 0.028| per_loss: 0.448 | a_loss: 0.504
Train: Epoch [1406/3000], Step [60/158]| g_loss: 0.748| d_loss: 0.698| gp_loss: 0.051| r_loss: 0.074| p_loss: 0.116| v_loss: 0.027| per_loss: 0.458 | a_loss: 0.542
Train: Epoch [1406/3000], Step [90/158]| g_loss: 0.760| d_loss: 0.573| gp_loss: 0.057| r_loss: 0.077| p_loss: 0.121| v_loss: 0.028| per_loss: 0.478 | a_loss: 0.546
Train: Epoch [1406/3000], Step [120/158]| g_loss: 0.802| d_loss: 0.513| gp_loss: 0.058| r_loss: 0.076| p_loss: 0.118| v_loss: 0.028| per_loss: 0.464 | a_loss: 0.592
Train: Epoch [1406/3000], Step [150/158]| g_loss: 0.711| d_loss: 0.601| gp_loss: 0.052| r_loss: 0.074| p_loss: 0.117| v_loss: 0.027| per_loss: 0.448 | a_loss: 0.507
Train: Epoch [1407/3000], Step [30/158]| g_loss: 0.767| d_loss: 0.608| gp_loss: 0.118| r_loss: 0.074| p_loss: 0.114| v_loss: 0.026| per_loss: 0.445 | a_loss: 0.565
Train: Epoch [1407/3000], Step [60/158]| g_loss: 0.747| d_loss: 0.597| gp_loss: 0.052| r_loss: 0.074| p_loss: 0.113| v_loss: 0.027| per_loss: 0.416 | a_loss: 0.547
Train: Epoch [1407/3000], Step [90/158]| g_loss: 0.730| d_loss: 0.601| gp_loss: 0.057| r_loss: 0.073| p_loss: 0.112| v_loss: 0.026| per_loss: 0.497 | a_loss: 0.526
Train: Epoch [1407/3000], Step [120/158]| g_loss: 0.705| d_loss: 0.648| gp_loss: 0.053| r_loss: 0.076| p_loss: 0.116| v_loss: 0.027| per_loss: 0.469 | a_loss: 0.497
Train: Epoch [1407/3000], Step [150/158]| g_loss: 0.802| d_loss: 0.558| gp_loss: 0.059| r_loss: 0.076| p_loss: 0.118| v_loss: 0.028| per_loss: 0.503 | a_loss: 0.589
Train: Epoch [1408/3000], Step [30/158]| g_loss: 0.808| d_loss: 0.645| gp_loss: 0.183| r_loss: 0.076| p_loss: 0.117| v_loss: 0.028| per_loss: 0.462 | a_loss: 0.600
Train: Epoch [1408/3000], Step [60/158]| g_loss: 0.765| d_loss: 0.575| gp_loss: 0.053| r_loss: 0.075| p_loss: 0.114| v_loss: 0.027| per_loss: 0.468 | a_loss: 0.559
Train: Epoch [1408/3000], Step [90/158]| g_loss: 0.857| d_loss: 0.539| gp_loss: 0.055| r_loss: 0.077| p_loss: 0.116| v_loss: 0.027| per_loss: 0.458 | a_loss: 0.649
Train: Epoch [1408/3000], Step [120/158]| g_loss: 0.726| d_loss: 0.629| gp_loss: 0.056| r_loss: 0.079| p_loss: 0.126| v_loss: 0.027| per_loss: 0.463 | a_loss: 0.511
Train: Epoch [1408/3000], Step [150/158]| g_loss: 0.717| d_loss: 0.696| gp_loss: 0.053| r_loss: 0.079| p_loss: 0.128| v_loss: 0.028| per_loss: 0.466 | a_loss: 0.499
Train: Epoch [1409/3000], Step [30/158]| g_loss: 0.682| d_loss: 0.763| gp_loss: 0.111| r_loss: 0.078| p_loss: 0.124| v_loss: 0.027| per_loss: 0.461 | a_loss: 0.469
Train: Epoch [1409/3000], Step [60/158]| g_loss: 0.716| d_loss: 0.608| gp_loss: 0.061| r_loss: 0.077| p_loss: 0.119| v_loss: 0.026| per_loss: 0.470 | a_loss: 0.507
Train: Epoch [1409/3000], Step [90/158]| g_loss: 0.796| d_loss: 0.501| gp_loss: 0.057| r_loss: 0.076| p_loss: 0.116| v_loss: 0.027| per_loss: 0.460 | a_loss: 0.589
Train: Epoch [1409/3000], Step [120/158]| g_loss: 0.712| d_loss: 0.654| gp_loss: 0.059| r_loss: 0.073| p_loss: 0.116| v_loss: 0.027| per_loss: 0.449 | a_loss: 0.509
Train: Epoch [1409/3000], Step [150/158]| g_loss: 0.723| d_loss: 0.613| gp_loss: 0.059| r_loss: 0.073| p_loss: 0.111| v_loss: 0.027| per_loss: 0.446 | a_loss: 0.524
Train: Epoch [1410/3000], Step [30/158]| g_loss: 0.758| d_loss: 0.684| gp_loss: 0.158| r_loss: 0.072| p_loss: 0.110| v_loss: 0.027| per_loss: 0.454 | a_loss: 0.559
Train: Epoch [1410/3000], Step [60/158]| g_loss: 0.773| d_loss: 0.524| gp_loss: 0.056| r_loss: 0.075| p_loss: 0.118| v_loss: 0.027| per_loss: 0.451 | a_loss: 0.567
Train: Epoch [1410/3000], Step [90/158]| g_loss: 0.742| d_loss: 0.605| gp_loss: 0.057| r_loss: 0.077| p_loss: 0.116| v_loss: 0.027| per_loss: 0.453 | a_loss: 0.535
Train: Epoch [1410/3000], Step [120/158]| g_loss: 0.754| d_loss: 0.586| gp_loss: 0.060| r_loss: 0.074| p_loss: 0.116| v_loss: 0.027| per_loss: 0.462 | a_loss: 0.549
Train: Epoch [1410/3000], Step [150/158]| g_loss: 0.719| d_loss: 0.672| gp_loss: 0.058| r_loss: 0.078| p_loss: 0.120| v_loss: 0.026| per_loss: 0.468 | a_loss: 0.509
Train: Epoch [1411/3000], Step [30/158]| g_loss: 0.739| d_loss: 0.722| gp_loss: 0.185| r_loss: 0.073| p_loss: 0.117| v_loss: 0.027| per_loss: 0.447 | a_loss: 0.536
Train: Epoch [1411/3000], Step [60/158]| g_loss: 0.746| d_loss: 0.615| gp_loss: 0.054| r_loss: 0.077| p_loss: 0.120| v_loss: 0.027| per_loss: 0.477 | a_loss: 0.535
Train: Epoch [1411/3000], Step [90/158]| g_loss: 0.748| d_loss: 0.547| gp_loss: 0.057| r_loss: 0.076| p_loss: 0.116| v_loss: 0.027| per_loss: 0.440 | a_loss: 0.542
Train: Epoch [1411/3000], Step [120/158]| g_loss: 0.790| d_loss: 0.530| gp_loss: 0.061| r_loss: 0.073| p_loss: 0.113| v_loss: 0.028| per_loss: 0.461 | a_loss: 0.587
Train: Epoch [1411/3000], Step [150/158]| g_loss: 0.784| d_loss: 0.620| gp_loss: 0.057| r_loss: 0.076| p_loss: 0.120| v_loss: 0.027| per_loss: 0.463 | a_loss: 0.574
Train: Epoch [1412/3000], Step [30/158]| g_loss: 0.739| d_loss: 0.708| gp_loss: 0.140| r_loss: 0.076| p_loss: 0.120| v_loss: 0.027| per_loss: 0.468 | a_loss: 0.529
Train: Epoch [1412/3000], Step [60/158]| g_loss: 0.759| d_loss: 0.566| gp_loss: 0.058| r_loss: 0.081| p_loss: 0.124| v_loss: 0.026| per_loss: 0.474 | a_loss: 0.543
Train: Epoch [1412/3000], Step [90/158]| g_loss: 0.789| d_loss: 0.643| gp_loss: 0.055| r_loss: 0.080| p_loss: 0.127| v_loss: 0.026| per_loss: 0.469 | a_loss: 0.573
Train: Epoch [1412/3000], Step [120/158]| g_loss: 0.731| d_loss: 0.618| gp_loss: 0.062| r_loss: 0.076| p_loss: 0.121| v_loss: 0.027| per_loss: 0.480 | a_loss: 0.520
Train: Epoch [1412/3000], Step [150/158]| g_loss: 0.732| d_loss: 0.625| gp_loss: 0.062| r_loss: 0.074| p_loss: 0.121| v_loss: 0.027| per_loss: 0.497 | a_loss: 0.521
Train: Epoch [1413/3000], Step [30/158]| g_loss: 0.697| d_loss: 0.725| gp_loss: 0.079| r_loss: 0.075| p_loss: 0.119| v_loss: 0.026| per_loss: 0.460 | a_loss: 0.490
Train: Epoch [1413/3000], Step [60/158]| g_loss: 0.763| d_loss: 0.660| gp_loss: 0.065| r_loss: 0.078| p_loss: 0.119| v_loss: 0.027| per_loss: 0.455 | a_loss: 0.553
Train: Epoch [1413/3000], Step [90/158]| g_loss: 0.674| d_loss: 0.683| gp_loss: 0.058| r_loss: 0.078| p_loss: 0.118| v_loss: 0.026| per_loss: 0.486 | a_loss: 0.462
Train: Epoch [1413/3000], Step [120/158]| g_loss: 0.753| d_loss: 0.533| gp_loss: 0.061| r_loss: 0.075| p_loss: 0.118| v_loss: 0.027| per_loss: 0.460 | a_loss: 0.546
Train: Epoch [1413/3000], Step [150/158]| g_loss: 0.753| d_loss: 0.593| gp_loss: 0.058| r_loss: 0.073| p_loss: 0.115| v_loss: 0.027| per_loss: 0.438 | a_loss: 0.551
Train: Epoch [1414/3000], Step [30/158]| g_loss: 0.790| d_loss: 0.677| gp_loss: 0.212| r_loss: 0.075| p_loss: 0.115| v_loss: 0.027| per_loss: 0.460 | a_loss: 0.585
Train: Epoch [1414/3000], Step [60/158]| g_loss: 0.772| d_loss: 0.540| gp_loss: 0.054| r_loss: 0.073| p_loss: 0.110| v_loss: 0.026| per_loss: 0.443 | a_loss: 0.573
Train: Epoch [1414/3000], Step [90/158]| g_loss: 0.756| d_loss: 0.641| gp_loss: 0.056| r_loss: 0.077| p_loss: 0.115| v_loss: 0.027| per_loss: 0.438 | a_loss: 0.552
Train: Epoch [1414/3000], Step [120/158]| g_loss: 0.728| d_loss: 0.665| gp_loss: 0.059| r_loss: 0.075| p_loss: 0.120| v_loss: 0.028| per_loss: 0.453 | a_loss: 0.519
Train: Epoch [1414/3000], Step [150/158]| g_loss: 0.736| d_loss: 0.591| gp_loss: 0.061| r_loss: 0.077| p_loss: 0.125| v_loss: 0.028| per_loss: 0.499 | a_loss: 0.518
Train: Epoch [1415/3000], Step [30/158]| g_loss: 0.767| d_loss: 0.720| gp_loss: 0.149| r_loss: 0.080| p_loss: 0.129| v_loss: 0.027| per_loss: 0.444 | a_loss: 0.552
Train: Epoch [1415/3000], Step [60/158]| g_loss: 0.789| d_loss: 0.532| gp_loss: 0.058| r_loss: 0.074| p_loss: 0.118| v_loss: 0.027| per_loss: 0.483 | a_loss: 0.581
Train: Epoch [1415/3000], Step [90/158]| g_loss: 0.751| d_loss: 0.575| gp_loss: 0.056| r_loss: 0.074| p_loss: 0.115| v_loss: 0.028| per_loss: 0.465 | a_loss: 0.546
Train: Epoch [1415/3000], Step [120/158]| g_loss: 0.746| d_loss: 0.599| gp_loss: 0.052| r_loss: 0.073| p_loss: 0.112| v_loss: 0.026| per_loss: 0.483 | a_loss: 0.542
Train: Epoch [1415/3000], Step [150/158]| g_loss: 0.757| d_loss: 0.638| gp_loss: 0.060| r_loss: 0.079| p_loss: 0.123| v_loss: 0.027| per_loss: 0.438 | a_loss: 0.546
Train: Epoch [1416/3000], Step [30/158]| g_loss: 0.771| d_loss: 0.716| gp_loss: 0.184| r_loss: 0.080| p_loss: 0.132| v_loss: 0.027| per_loss: 0.486 | a_loss: 0.550
Train: Epoch [1416/3000], Step [60/158]| g_loss: 0.849| d_loss: 0.540| gp_loss: 0.054| r_loss: 0.101| p_loss: 0.157| v_loss: 0.027| per_loss: 0.513 | a_loss: 0.591
Train: Epoch [1416/3000], Step [90/158]| g_loss: 0.765| d_loss: 0.631| gp_loss: 0.056| r_loss: 0.091| p_loss: 0.160| v_loss: 0.027| per_loss: 0.498 | a_loss: 0.517
Train: Epoch [1416/3000], Step [120/158]| g_loss: 0.736| d_loss: 0.625| gp_loss: 0.055| r_loss: 0.082| p_loss: 0.132| v_loss: 0.028| per_loss: 0.453 | a_loss: 0.515
Train: Epoch [1416/3000], Step [150/158]| g_loss: 0.716| d_loss: 0.643| gp_loss: 0.061| r_loss: 0.080| p_loss: 0.131| v_loss: 0.027| per_loss: 0.452 | a_loss: 0.498
Train: Epoch [1417/3000], Step [30/158]| g_loss: 0.758| d_loss: 0.746| gp_loss: 0.189| r_loss: 0.078| p_loss: 0.126| v_loss: 0.028| per_loss: 0.472 | a_loss: 0.541
Train: Epoch [1417/3000], Step [60/158]| g_loss: 0.759| d_loss: 0.646| gp_loss: 0.057| r_loss: 0.079| p_loss: 0.130| v_loss: 0.027| per_loss: 0.457 | a_loss: 0.543
Train: Epoch [1417/3000], Step [90/158]| g_loss: 0.733| d_loss: 0.694| gp_loss: 0.057| r_loss: 0.080| p_loss: 0.124| v_loss: 0.028| per_loss: 0.462 | a_loss: 0.517
Train: Epoch [1417/3000], Step [120/158]| g_loss: 0.741| d_loss: 0.621| gp_loss: 0.056| r_loss: 0.080| p_loss: 0.124| v_loss: 0.028| per_loss: 0.448 | a_loss: 0.526
Train: Epoch [1417/3000], Step [150/158]| g_loss: 0.825| d_loss: 0.528| gp_loss: 0.055| r_loss: 0.077| p_loss: 0.119| v_loss: 0.027| per_loss: 0.451 | a_loss: 0.616
Train: Epoch [1418/3000], Step [30/158]| g_loss: 0.747| d_loss: 0.687| gp_loss: 0.115| r_loss: 0.078| p_loss: 0.119| v_loss: 0.027| per_loss: 0.480 | a_loss: 0.534
Train: Epoch [1418/3000], Step [60/158]| g_loss: 0.682| d_loss: 0.670| gp_loss: 0.050| r_loss: 0.075| p_loss: 0.118| v_loss: 0.027| per_loss: 0.431 | a_loss: 0.478
Train: Epoch [1418/3000], Step [90/158]| g_loss: 0.714| d_loss: 0.604| gp_loss: 0.059| r_loss: 0.076| p_loss: 0.117| v_loss: 0.027| per_loss: 0.471 | a_loss: 0.506
Train: Epoch [1418/3000], Step [120/158]| g_loss: 0.754| d_loss: 0.607| gp_loss: 0.056| r_loss: 0.072| p_loss: 0.114| v_loss: 0.027| per_loss: 0.447 | a_loss: 0.554
Train: Epoch [1418/3000], Step [150/158]| g_loss: 0.849| d_loss: 0.463| gp_loss: 0.060| r_loss: 0.075| p_loss: 0.119| v_loss: 0.028| per_loss: 0.489 | a_loss: 0.638
Train: Epoch [1419/3000], Step [30/158]| g_loss: 0.775| d_loss: 0.710| gp_loss: 0.195| r_loss: 0.075| p_loss: 0.118| v_loss: 0.028| per_loss: 0.465 | a_loss: 0.567
Train: Epoch [1419/3000], Step [60/158]| g_loss: 0.794| d_loss: 0.585| gp_loss: 0.052| r_loss: 0.077| p_loss: 0.117| v_loss: 0.028| per_loss: 0.457 | a_loss: 0.584
Train: Epoch [1419/3000], Step [90/158]| g_loss: 0.807| d_loss: 0.495| gp_loss: 0.051| r_loss: 0.075| p_loss: 0.116| v_loss: 0.027| per_loss: 0.474 | a_loss: 0.599
Train: Epoch [1419/3000], Step [120/158]| g_loss: 0.679| d_loss: 0.722| gp_loss: 0.053| r_loss: 0.074| p_loss: 0.118| v_loss: 0.027| per_loss: 0.492 | a_loss: 0.470
Train: Epoch [1419/3000], Step [150/158]| g_loss: 0.766| d_loss: 0.589| gp_loss: 0.056| r_loss: 0.078| p_loss: 0.118| v_loss: 0.026| per_loss: 0.443 | a_loss: 0.559
Train: Epoch [1420/3000], Step [30/158]| g_loss: 0.762| d_loss: 0.713| gp_loss: 0.182| r_loss: 0.075| p_loss: 0.115| v_loss: 0.026| per_loss: 0.447 | a_loss: 0.559
Train: Epoch [1420/3000], Step [60/158]| g_loss: 0.759| d_loss: 0.597| gp_loss: 0.051| r_loss: 0.077| p_loss: 0.112| v_loss: 0.026| per_loss: 0.461 | a_loss: 0.554
Train: Epoch [1420/3000], Step [90/158]| g_loss: 0.760| d_loss: 0.605| gp_loss: 0.056| r_loss: 0.076| p_loss: 0.121| v_loss: 0.026| per_loss: 0.440 | a_loss: 0.553
Train: Epoch [1420/3000], Step [120/158]| g_loss: 0.753| d_loss: 0.645| gp_loss: 0.057| r_loss: 0.077| p_loss: 0.119| v_loss: 0.027| per_loss: 0.503 | a_loss: 0.540
Train: Epoch [1420/3000], Step [150/158]| g_loss: 0.745| d_loss: 0.582| gp_loss: 0.058| r_loss: 0.075| p_loss: 0.119| v_loss: 0.027| per_loss: 0.505 | a_loss: 0.533
Train: Epoch [1421/3000], Step [30/158]| g_loss: 0.824| d_loss: 0.640| gp_loss: 0.194| r_loss: 0.079| p_loss: 0.126| v_loss: 0.028| per_loss: 0.509 | a_loss: 0.603
Train: Epoch [1421/3000], Step [60/158]| g_loss: 0.778| d_loss: 0.538| gp_loss: 0.049| r_loss: 0.077| p_loss: 0.116| v_loss: 0.028| per_loss: 0.485 | a_loss: 0.567
Train: Epoch [1421/3000], Step [90/158]| g_loss: 0.726| d_loss: 0.717| gp_loss: 0.048| r_loss: 0.073| p_loss: 0.111| v_loss: 0.026| per_loss: 0.463 | a_loss: 0.526
Train: Epoch [1421/3000], Step [120/158]| g_loss: 0.684| d_loss: 0.666| gp_loss: 0.054| r_loss: 0.074| p_loss: 0.116| v_loss: 0.026| per_loss: 0.451 | a_loss: 0.480
Train: Epoch [1421/3000], Step [150/158]| g_loss: 0.771| d_loss: 0.536| gp_loss: 0.058| r_loss: 0.074| p_loss: 0.114| v_loss: 0.027| per_loss: 0.443 | a_loss: 0.569
Train: Epoch [1422/3000], Step [30/158]| g_loss: 0.756| d_loss: 0.737| gp_loss: 0.184| r_loss: 0.076| p_loss: 0.118| v_loss: 0.027| per_loss: 0.444 | a_loss: 0.550
Train: Epoch [1422/3000], Step [60/158]| g_loss: 0.759| d_loss: 0.555| gp_loss: 0.052| r_loss: 0.073| p_loss: 0.115| v_loss: 0.027| per_loss: 0.434 | a_loss: 0.558
Train: Epoch [1422/3000], Step [90/158]| g_loss: 0.700| d_loss: 0.681| gp_loss: 0.051| r_loss: 0.072| p_loss: 0.111| v_loss: 0.026| per_loss: 0.463 | a_loss: 0.500
Train: Epoch [1422/3000], Step [120/158]| g_loss: 0.733| d_loss: 0.606| gp_loss: 0.056| r_loss: 0.076| p_loss: 0.117| v_loss: 0.028| per_loss: 0.470 | a_loss: 0.524
Train: Epoch [1422/3000], Step [150/158]| g_loss: 0.785| d_loss: 0.520| gp_loss: 0.055| r_loss: 0.078| p_loss: 0.118| v_loss: 0.027| per_loss: 0.472 | a_loss: 0.574
Train: Epoch [1423/3000], Step [30/158]| g_loss: 0.724| d_loss: 0.749| gp_loss: 0.175| r_loss: 0.075| p_loss: 0.116| v_loss: 0.027| per_loss: 0.426 | a_loss: 0.522
Train: Epoch [1423/3000], Step [60/158]| g_loss: 0.777| d_loss: 0.630| gp_loss: 0.051| r_loss: 0.073| p_loss: 0.111| v_loss: 0.026| per_loss: 0.482 | a_loss: 0.574
Train: Epoch [1423/3000], Step [90/158]| g_loss: 0.704| d_loss: 0.573| gp_loss: 0.053| r_loss: 0.074| p_loss: 0.117| v_loss: 0.028| per_loss: 0.444 | a_loss: 0.499
Train: Epoch [1423/3000], Step [120/158]| g_loss: 0.711| d_loss: 0.635| gp_loss: 0.051| r_loss: 0.073| p_loss: 0.112| v_loss: 0.026| per_loss: 0.490 | a_loss: 0.506
Train: Epoch [1423/3000], Step [150/158]| g_loss: 0.790| d_loss: 0.563| gp_loss: 0.056| r_loss: 0.077| p_loss: 0.120| v_loss: 0.026| per_loss: 0.471 | a_loss: 0.580
Train: Epoch [1424/3000], Step [30/158]| g_loss: 0.721| d_loss: 0.778| gp_loss: 0.179| r_loss: 0.074| p_loss: 0.118| v_loss: 0.026| per_loss: 0.459 | a_loss: 0.515
Train: Epoch [1424/3000], Step [60/158]| g_loss: 0.797| d_loss: 0.556| gp_loss: 0.052| r_loss: 0.076| p_loss: 0.119| v_loss: 0.028| per_loss: 0.468 | a_loss: 0.587
Train: Epoch [1424/3000], Step [90/158]| g_loss: 0.748| d_loss: 0.636| gp_loss: 0.049| r_loss: 0.078| p_loss: 0.120| v_loss: 0.026| per_loss: 0.459 | a_loss: 0.538
Train: Epoch [1424/3000], Step [120/158]| g_loss: 0.770| d_loss: 0.551| gp_loss: 0.050| r_loss: 0.074| p_loss: 0.116| v_loss: 0.026| per_loss: 0.479 | a_loss: 0.564
Train: Epoch [1424/3000], Step [150/158]| g_loss: 0.731| d_loss: 0.618| gp_loss: 0.054| r_loss: 0.074| p_loss: 0.111| v_loss: 0.027| per_loss: 0.438 | a_loss: 0.531
Train: Epoch [1425/3000], Step [30/158]| g_loss: 0.716| d_loss: 0.752| gp_loss: 0.159| r_loss: 0.076| p_loss: 0.117| v_loss: 0.027| per_loss: 0.460 | a_loss: 0.508
Train: Epoch [1425/3000], Step [60/158]| g_loss: 0.729| d_loss: 0.601| gp_loss: 0.053| r_loss: 0.079| p_loss: 0.121| v_loss: 0.027| per_loss: 0.475 | a_loss: 0.514
Train: Epoch [1425/3000], Step [90/158]| g_loss: 0.787| d_loss: 0.573| gp_loss: 0.055| r_loss: 0.074| p_loss: 0.117| v_loss: 0.027| per_loss: 0.467 | a_loss: 0.581
Train: Epoch [1425/3000], Step [120/158]| g_loss: 0.751| d_loss: 0.616| gp_loss: 0.054| r_loss: 0.076| p_loss: 0.116| v_loss: 0.026| per_loss: 0.426 | a_loss: 0.549
Train: Epoch [1425/3000], Step [150/158]| g_loss: 0.755| d_loss: 0.558| gp_loss: 0.053| r_loss: 0.076| p_loss: 0.119| v_loss: 0.027| per_loss: 0.446 | a_loss: 0.548
Train: Epoch [1426/3000], Step [30/158]| g_loss: 0.835| d_loss: 0.654| gp_loss: 0.159| r_loss: 0.076| p_loss: 0.122| v_loss: 0.026| per_loss: 0.490 | a_loss: 0.623
Train: Epoch [1426/3000], Step [60/158]| g_loss: 0.716| d_loss: 0.639| gp_loss: 0.049| r_loss: 0.075| p_loss: 0.115| v_loss: 0.026| per_loss: 0.448 | a_loss: 0.512
Train: Epoch [1426/3000], Step [90/158]| g_loss: 0.708| d_loss: 0.657| gp_loss: 0.052| r_loss: 0.077| p_loss: 0.119| v_loss: 0.026| per_loss: 0.476 | a_loss: 0.497
Train: Epoch [1426/3000], Step [120/158]| g_loss: 0.746| d_loss: 0.603| gp_loss: 0.054| r_loss: 0.073| p_loss: 0.112| v_loss: 0.026| per_loss: 0.459 | a_loss: 0.545
Train: Epoch [1426/3000], Step [150/158]| g_loss: 0.757| d_loss: 0.597| gp_loss: 0.054| r_loss: 0.078| p_loss: 0.119| v_loss: 0.027| per_loss: 0.429 | a_loss: 0.549
Train: Epoch [1427/3000], Step [30/158]| g_loss: 0.780| d_loss: 0.742| gp_loss: 0.204| r_loss: 0.076| p_loss: 0.118| v_loss: 0.026| per_loss: 0.468 | a_loss: 0.572
Train: Epoch [1427/3000], Step [60/158]| g_loss: 0.750| d_loss: 0.503| gp_loss: 0.050| r_loss: 0.071| p_loss: 0.109| v_loss: 0.026| per_loss: 0.483 | a_loss: 0.550
Train: Epoch [1427/3000], Step [90/158]| g_loss: 0.716| d_loss: 0.688| gp_loss: 0.050| r_loss: 0.074| p_loss: 0.111| v_loss: 0.026| per_loss: 0.437 | a_loss: 0.517
Train: Epoch [1427/3000], Step [120/158]| g_loss: 0.758| d_loss: 0.571| gp_loss: 0.054| r_loss: 0.074| p_loss: 0.112| v_loss: 0.027| per_loss: 0.451 | a_loss: 0.556
Train: Epoch [1427/3000], Step [150/158]| g_loss: 0.724| d_loss: 0.644| gp_loss: 0.051| r_loss: 0.074| p_loss: 0.115| v_loss: 0.027| per_loss: 0.463 | a_loss: 0.519
Train: Epoch [1428/3000], Step [30/158]| g_loss: 0.728| d_loss: 0.670| gp_loss: 0.147| r_loss: 0.076| p_loss: 0.120| v_loss: 0.027| per_loss: 0.448 | a_loss: 0.520
Train: Epoch [1428/3000], Step [60/158]| g_loss: 0.757| d_loss: 0.597| gp_loss: 0.050| r_loss: 0.076| p_loss: 0.120| v_loss: 0.026| per_loss: 0.445 | a_loss: 0.550
Train: Epoch [1428/3000], Step [90/158]| g_loss: 0.784| d_loss: 0.582| gp_loss: 0.052| r_loss: 0.075| p_loss: 0.119| v_loss: 0.027| per_loss: 0.465 | a_loss: 0.577
Train: Epoch [1428/3000], Step [120/158]| g_loss: 0.787| d_loss: 0.527| gp_loss: 0.056| r_loss: 0.074| p_loss: 0.112| v_loss: 0.028| per_loss: 0.448 | a_loss: 0.584
Train: Epoch [1428/3000], Step [150/158]| g_loss: 0.722| d_loss: 0.694| gp_loss: 0.052| r_loss: 0.074| p_loss: 0.115| v_loss: 0.026| per_loss: 0.502 | a_loss: 0.514
Train: Epoch [1429/3000], Step [30/158]| g_loss: 0.794| d_loss: 0.637| gp_loss: 0.144| r_loss: 0.076| p_loss: 0.118| v_loss: 0.027| per_loss: 0.476 | a_loss: 0.584
Train: Epoch [1429/3000], Step [60/158]| g_loss: 0.734| d_loss: 0.570| gp_loss: 0.049| r_loss: 0.072| p_loss: 0.115| v_loss: 0.026| per_loss: 0.520 | a_loss: 0.525
Train: Epoch [1429/3000], Step [90/158]| g_loss: 0.736| d_loss: 0.645| gp_loss: 0.054| r_loss: 0.077| p_loss: 0.119| v_loss: 0.027| per_loss: 0.457 | a_loss: 0.527
Train: Epoch [1429/3000], Step [120/158]| g_loss: 0.755| d_loss: 0.580| gp_loss: 0.057| r_loss: 0.075| p_loss: 0.118| v_loss: 0.028| per_loss: 0.450 | a_loss: 0.548
Train: Epoch [1429/3000], Step [150/158]| g_loss: 0.761| d_loss: 0.663| gp_loss: 0.054| r_loss: 0.077| p_loss: 0.124| v_loss: 0.026| per_loss: 0.434 | a_loss: 0.553
Train: Epoch [1430/3000], Step [30/158]| g_loss: 0.721| d_loss: 0.740| gp_loss: 0.181| r_loss: 0.076| p_loss: 0.121| v_loss: 0.027| per_loss: 0.445 | a_loss: 0.513
Train: Epoch [1430/3000], Step [60/158]| g_loss: 0.740| d_loss: 0.602| gp_loss: 0.056| r_loss: 0.075| p_loss: 0.117| v_loss: 0.027| per_loss: 0.478 | a_loss: 0.532
Train: Epoch [1430/3000], Step [90/158]| g_loss: 0.824| d_loss: 0.547| gp_loss: 0.055| r_loss: 0.077| p_loss: 0.122| v_loss: 0.027| per_loss: 0.459 | a_loss: 0.613
Train: Epoch [1430/3000], Step [120/158]| g_loss: 0.795| d_loss: 0.565| gp_loss: 0.053| r_loss: 0.076| p_loss: 0.117| v_loss: 0.027| per_loss: 0.507 | a_loss: 0.584
Train: Epoch [1430/3000], Step [150/158]| g_loss: 0.685| d_loss: 0.655| gp_loss: 0.056| r_loss: 0.073| p_loss: 0.115| v_loss: 0.026| per_loss: 0.416 | a_loss: 0.486
Train: Epoch [1431/3000], Step [30/158]| g_loss: 0.772| d_loss: 0.620| gp_loss: 0.116| r_loss: 0.075| p_loss: 0.113| v_loss: 0.028| per_loss: 0.484 | a_loss: 0.563
Train: Epoch [1431/3000], Step [60/158]| g_loss: 0.806| d_loss: 0.522| gp_loss: 0.054| r_loss: 0.073| p_loss: 0.111| v_loss: 0.027| per_loss: 0.471 | a_loss: 0.604
Train: Epoch [1431/3000], Step [90/158]| g_loss: 0.701| d_loss: 0.696| gp_loss: 0.052| r_loss: 0.075| p_loss: 0.116| v_loss: 0.026| per_loss: 0.443 | a_loss: 0.498
Train: Epoch [1431/3000], Step [120/158]| g_loss: 0.714| d_loss: 0.622| gp_loss: 0.060| r_loss: 0.075| p_loss: 0.110| v_loss: 0.025| per_loss: 0.425 | a_loss: 0.516
Train: Epoch [1431/3000], Step [150/158]| g_loss: 0.768| d_loss: 0.565| gp_loss: 0.058| r_loss: 0.074| p_loss: 0.117| v_loss: 0.026| per_loss: 0.479 | a_loss: 0.562
Train: Epoch [1432/3000], Step [30/158]| g_loss: 0.742| d_loss: 0.736| gp_loss: 0.202| r_loss: 0.075| p_loss: 0.118| v_loss: 0.027| per_loss: 0.420 | a_loss: 0.538
Train: Epoch [1432/3000], Step [60/158]| g_loss: 0.793| d_loss: 0.503| gp_loss: 0.051| r_loss: 0.073| p_loss: 0.114| v_loss: 0.027| per_loss: 0.458 | a_loss: 0.591
Train: Epoch [1432/3000], Step [90/158]| g_loss: 0.771| d_loss: 0.640| gp_loss: 0.052| r_loss: 0.077| p_loss: 0.119| v_loss: 0.028| per_loss: 0.472 | a_loss: 0.560
Train: Epoch [1432/3000], Step [120/158]| g_loss: 0.721| d_loss: 0.628| gp_loss: 0.051| r_loss: 0.073| p_loss: 0.111| v_loss: 0.027| per_loss: 0.481 | a_loss: 0.517
Train: Epoch [1432/3000], Step [150/158]| g_loss: 0.726| d_loss: 0.660| gp_loss: 0.051| r_loss: 0.073| p_loss: 0.115| v_loss: 0.026| per_loss: 0.426 | a_loss: 0.526
Train: Epoch [1433/3000], Step [30/158]| g_loss: 0.787| d_loss: 0.591| gp_loss: 0.127| r_loss: 0.073| p_loss: 0.108| v_loss: 0.026| per_loss: 0.467 | a_loss: 0.587
Train: Epoch [1433/3000], Step [60/158]| g_loss: 0.700| d_loss: 0.619| gp_loss: 0.050| r_loss: 0.072| p_loss: 0.112| v_loss: 0.026| per_loss: 0.436 | a_loss: 0.502
Train: Epoch [1433/3000], Step [90/158]| g_loss: 0.719| d_loss: 0.647| gp_loss: 0.055| r_loss: 0.078| p_loss: 0.121| v_loss: 0.028| per_loss: 0.462 | a_loss: 0.507
Train: Epoch [1433/3000], Step [120/158]| g_loss: 0.783| d_loss: 0.570| gp_loss: 0.057| r_loss: 0.073| p_loss: 0.115| v_loss: 0.027| per_loss: 0.484 | a_loss: 0.578
Train: Epoch [1433/3000], Step [150/158]| g_loss: 0.770| d_loss: 0.550| gp_loss: 0.057| r_loss: 0.077| p_loss: 0.125| v_loss: 0.027| per_loss: 0.470 | a_loss: 0.557
Train: Epoch [1434/3000], Step [30/158]| g_loss: 0.720| d_loss: 0.649| gp_loss: 0.129| r_loss: 0.074| p_loss: 0.110| v_loss: 0.026| per_loss: 0.466 | a_loss: 0.519
Train: Epoch [1434/3000], Step [60/158]| g_loss: 0.733| d_loss: 0.738| gp_loss: 0.056| r_loss: 0.073| p_loss: 0.114| v_loss: 0.026| per_loss: 0.449 | a_loss: 0.532
Train: Epoch [1434/3000], Step [90/158]| g_loss: 0.747| d_loss: 0.597| gp_loss: 0.060| r_loss: 0.076| p_loss: 0.120| v_loss: 0.028| per_loss: 0.450 | a_loss: 0.538
Train: Epoch [1434/3000], Step [120/158]| g_loss: 0.787| d_loss: 0.566| gp_loss: 0.064| r_loss: 0.080| p_loss: 0.130| v_loss: 0.028| per_loss: 0.504 | a_loss: 0.564
Train: Epoch [1434/3000], Step [150/158]| g_loss: 0.800| d_loss: 0.540| gp_loss: 0.058| r_loss: 0.075| p_loss: 0.120| v_loss: 0.026| per_loss: 0.463 | a_loss: 0.591
Train: Epoch [1435/3000], Step [30/158]| g_loss: 0.758| d_loss: 0.692| gp_loss: 0.134| r_loss: 0.080| p_loss: 0.126| v_loss: 0.027| per_loss: 0.466 | a_loss: 0.541
Train: Epoch [1435/3000], Step [60/158]| g_loss: 0.712| d_loss: 0.623| gp_loss: 0.058| r_loss: 0.076| p_loss: 0.122| v_loss: 0.027| per_loss: 0.447 | a_loss: 0.503
Train: Epoch [1435/3000], Step [90/158]| g_loss: 0.763| d_loss: 0.621| gp_loss: 0.061| r_loss: 0.078| p_loss: 0.127| v_loss: 0.027| per_loss: 0.478 | a_loss: 0.547
Train: Epoch [1435/3000], Step [120/158]| g_loss: 0.717| d_loss: 0.630| gp_loss: 0.061| r_loss: 0.078| p_loss: 0.121| v_loss: 0.027| per_loss: 0.462 | a_loss: 0.506
Train: Epoch [1435/3000], Step [150/158]| g_loss: 0.807| d_loss: 0.547| gp_loss: 0.061| r_loss: 0.077| p_loss: 0.116| v_loss: 0.027| per_loss: 0.456 | a_loss: 0.600
Train: Epoch [1436/3000], Step [30/158]| g_loss: 0.735| d_loss: 0.694| gp_loss: 0.163| r_loss: 0.075| p_loss: 0.121| v_loss: 0.026| per_loss: 0.462 | a_loss: 0.527
Train: Epoch [1436/3000], Step [60/158]| g_loss: 0.723| d_loss: 0.619| gp_loss: 0.055| r_loss: 0.073| p_loss: 0.109| v_loss: 0.025| per_loss: 0.453 | a_loss: 0.525
Train: Epoch [1436/3000], Step [90/158]| g_loss: 0.753| d_loss: 0.589| gp_loss: 0.058| r_loss: 0.074| p_loss: 0.115| v_loss: 0.026| per_loss: 0.456 | a_loss: 0.550
Train: Epoch [1436/3000], Step [120/158]| g_loss: 0.750| d_loss: 0.645| gp_loss: 0.056| r_loss: 0.075| p_loss: 0.115| v_loss: 0.026| per_loss: 0.462 | a_loss: 0.545
Train: Epoch [1436/3000], Step [150/158]| g_loss: 0.752| d_loss: 0.559| gp_loss: 0.058| r_loss: 0.073| p_loss: 0.117| v_loss: 0.029| per_loss: 0.468 | a_loss: 0.545
Train: Epoch [1437/3000], Step [30/158]| g_loss: 0.745| d_loss: 0.731| gp_loss: 0.169| r_loss: 0.075| p_loss: 0.115| v_loss: 0.027| per_loss: 0.453 | a_loss: 0.541
Train: Epoch [1437/3000], Step [60/158]| g_loss: 0.753| d_loss: 0.505| gp_loss: 0.055| r_loss: 0.071| p_loss: 0.107| v_loss: 0.026| per_loss: 0.426 | a_loss: 0.560
Train: Epoch [1437/3000], Step [90/158]| g_loss: 0.752| d_loss: 0.610| gp_loss: 0.053| r_loss: 0.076| p_loss: 0.113| v_loss: 0.027| per_loss: 0.461 | a_loss: 0.547
Train: Epoch [1437/3000], Step [120/158]| g_loss: 0.759| d_loss: 0.601| gp_loss: 0.059| r_loss: 0.078| p_loss: 0.125| v_loss: 0.028| per_loss: 0.464 | a_loss: 0.544
Train: Epoch [1437/3000], Step [150/158]| g_loss: 0.753| d_loss: 0.623| gp_loss: 0.056| r_loss: 0.075| p_loss: 0.117| v_loss: 0.028| per_loss: 0.493 | a_loss: 0.542
Train: Epoch [1438/3000], Step [30/158]| g_loss: 0.748| d_loss: 0.738| gp_loss: 0.183| r_loss: 0.074| p_loss: 0.112| v_loss: 0.026| per_loss: 0.447 | a_loss: 0.547
Train: Epoch [1438/3000], Step [60/158]| g_loss: 0.766| d_loss: 0.505| gp_loss: 0.053| r_loss: 0.075| p_loss: 0.117| v_loss: 0.028| per_loss: 0.444 | a_loss: 0.560
Train: Epoch [1438/3000], Step [90/158]| g_loss: 0.733| d_loss: 0.675| gp_loss: 0.053| r_loss: 0.073| p_loss: 0.112| v_loss: 0.026| per_loss: 0.468 | a_loss: 0.531
Train: Epoch [1438/3000], Step [120/158]| g_loss: 0.768| d_loss: 0.581| gp_loss: 0.053| r_loss: 0.075| p_loss: 0.115| v_loss: 0.028| per_loss: 0.485 | a_loss: 0.559
Train: Epoch [1438/3000], Step [150/158]| g_loss: 0.678| d_loss: 0.678| gp_loss: 0.055| r_loss: 0.073| p_loss: 0.114| v_loss: 0.025| per_loss: 0.473 | a_loss: 0.475
Train: Epoch [1439/3000], Step [30/158]| g_loss: 0.778| d_loss: 0.636| gp_loss: 0.197| r_loss: 0.076| p_loss: 0.118| v_loss: 0.027| per_loss: 0.462 | a_loss: 0.570
Train: Epoch [1439/3000], Step [60/158]| g_loss: 0.782| d_loss: 0.577| gp_loss: 0.052| r_loss: 0.084| p_loss: 0.122| v_loss: 0.027| per_loss: 0.478 | a_loss: 0.562
Train: Epoch [1439/3000], Step [90/158]| g_loss: 0.794| d_loss: 0.650| gp_loss: 0.053| r_loss: 0.083| p_loss: 0.128| v_loss: 0.027| per_loss: 0.469 | a_loss: 0.573
Train: Epoch [1439/3000], Step [120/158]| g_loss: 0.771| d_loss: 0.506| gp_loss: 0.054| r_loss: 0.077| p_loss: 0.120| v_loss: 0.027| per_loss: 0.454 | a_loss: 0.562
Train: Epoch [1439/3000], Step [150/158]| g_loss: 0.722| d_loss: 0.730| gp_loss: 0.054| r_loss: 0.077| p_loss: 0.124| v_loss: 0.026| per_loss: 0.454 | a_loss: 0.512
Train: Epoch [1440/3000], Step [30/158]| g_loss: 0.763| d_loss: 0.686| gp_loss: 0.162| r_loss: 0.075| p_loss: 0.123| v_loss: 0.028| per_loss: 0.467 | a_loss: 0.551
Train: Epoch [1440/3000], Step [60/158]| g_loss: 0.720| d_loss: 0.601| gp_loss: 0.052| r_loss: 0.075| p_loss: 0.115| v_loss: 0.026| per_loss: 0.444 | a_loss: 0.518
Train: Epoch [1440/3000], Step [90/158]| g_loss: 0.769| d_loss: 0.592| gp_loss: 0.052| r_loss: 0.076| p_loss: 0.115| v_loss: 0.026| per_loss: 0.478 | a_loss: 0.561
Train: Epoch [1440/3000], Step [120/158]| g_loss: 0.723| d_loss: 0.659| gp_loss: 0.052| r_loss: 0.073| p_loss: 0.110| v_loss: 0.026| per_loss: 0.499 | a_loss: 0.520
Train: Epoch [1440/3000], Step [150/158]| g_loss: 0.711| d_loss: 0.608| gp_loss: 0.056| r_loss: 0.076| p_loss: 0.117| v_loss: 0.027| per_loss: 0.439 | a_loss: 0.506
Train: Epoch [1441/3000], Step [30/158]| g_loss: 0.725| d_loss: 0.721| gp_loss: 0.152| r_loss: 0.076| p_loss: 0.121| v_loss: 0.027| per_loss: 0.461 | a_loss: 0.516
Train: Epoch [1441/3000], Step [60/158]| g_loss: 0.807| d_loss: 0.514| gp_loss: 0.055| r_loss: 0.075| p_loss: 0.116| v_loss: 0.027| per_loss: 0.460 | a_loss: 0.600
Train: Epoch [1441/3000], Step [90/158]| g_loss: 0.745| d_loss: 0.626| gp_loss: 0.057| r_loss: 0.074| p_loss: 0.114| v_loss: 0.026| per_loss: 0.462 | a_loss: 0.542
Train: Epoch [1441/3000], Step [120/158]| g_loss: 0.728| d_loss: 0.595| gp_loss: 0.058| r_loss: 0.074| p_loss: 0.114| v_loss: 0.028| per_loss: 0.482 | a_loss: 0.521
Train: Epoch [1441/3000], Step [150/158]| g_loss: 0.800| d_loss: 0.611| gp_loss: 0.054| r_loss: 0.078| p_loss: 0.120| v_loss: 0.027| per_loss: 0.441 | a_loss: 0.591
Train: Epoch [1442/3000], Step [30/158]| g_loss: 0.745| d_loss: 0.677| gp_loss: 0.131| r_loss: 0.076| p_loss: 0.121| v_loss: 0.027| per_loss: 0.433 | a_loss: 0.538
Train: Epoch [1442/3000], Step [60/158]| g_loss: 0.708| d_loss: 0.627| gp_loss: 0.053| r_loss: 0.076| p_loss: 0.117| v_loss: 0.026| per_loss: 0.485 | a_loss: 0.498
Train: Epoch [1442/3000], Step [90/158]| g_loss: 0.772| d_loss: 0.529| gp_loss: 0.058| r_loss: 0.074| p_loss: 0.115| v_loss: 0.026| per_loss: 0.458 | a_loss: 0.568
Train: Epoch [1442/3000], Step [120/158]| g_loss: 0.737| d_loss: 0.584| gp_loss: 0.056| r_loss: 0.074| p_loss: 0.112| v_loss: 0.026| per_loss: 0.498 | a_loss: 0.531
Train: Epoch [1442/3000], Step [150/158]| g_loss: 0.793| d_loss: 0.561| gp_loss: 0.058| r_loss: 0.074| p_loss: 0.120| v_loss: 0.028| per_loss: 0.472 | a_loss: 0.584
Train: Epoch [1443/3000], Step [30/158]| g_loss: 0.801| d_loss: 0.668| gp_loss: 0.162| r_loss: 0.075| p_loss: 0.115| v_loss: 0.026| per_loss: 0.471 | a_loss: 0.595
Train: Epoch [1443/3000], Step [60/158]| g_loss: 0.750| d_loss: 0.505| gp_loss: 0.056| r_loss: 0.073| p_loss: 0.107| v_loss: 0.028| per_loss: 0.475 | a_loss: 0.548
Train: Epoch [1443/3000], Step [90/158]| g_loss: 0.735| d_loss: 0.631| gp_loss: 0.053| r_loss: 0.073| p_loss: 0.113| v_loss: 0.027| per_loss: 0.456 | a_loss: 0.533
Train: Epoch [1443/3000], Step [120/158]| g_loss: 0.680| d_loss: 0.706| gp_loss: 0.059| r_loss: 0.073| p_loss: 0.113| v_loss: 0.025| per_loss: 0.425 | a_loss: 0.482
Train: Epoch [1443/3000], Step [150/158]| g_loss: 0.800| d_loss: 0.589| gp_loss: 0.060| r_loss: 0.081| p_loss: 0.124| v_loss: 0.028| per_loss: 0.440 | a_loss: 0.584
Train: Epoch [1444/3000], Step [30/158]| g_loss: 0.826| d_loss: 0.624| gp_loss: 0.172| r_loss: 0.084| p_loss: 0.133| v_loss: 0.029| per_loss: 0.463 | a_loss: 0.601
Train: Epoch [1444/3000], Step [60/158]| g_loss: 0.758| d_loss: 0.621| gp_loss: 0.057| r_loss: 0.074| p_loss: 0.115| v_loss: 0.028| per_loss: 0.493 | a_loss: 0.550
Train: Epoch [1444/3000], Step [90/158]| g_loss: 0.793| d_loss: 0.547| gp_loss: 0.055| r_loss: 0.077| p_loss: 0.115| v_loss: 0.029| per_loss: 0.468 | a_loss: 0.582
Train: Epoch [1444/3000], Step [120/158]| g_loss: 0.760| d_loss: 0.592| gp_loss: 0.057| r_loss: 0.073| p_loss: 0.116| v_loss: 0.028| per_loss: 0.468 | a_loss: 0.554
Train: Epoch [1444/3000], Step [150/158]| g_loss: 0.752| d_loss: 0.666| gp_loss: 0.059| r_loss: 0.077| p_loss: 0.119| v_loss: 0.027| per_loss: 0.470 | a_loss: 0.542
Train: Epoch [1445/3000], Step [30/158]| g_loss: 0.756| d_loss: 0.657| gp_loss: 0.156| r_loss: 0.072| p_loss: 0.118| v_loss: 0.027| per_loss: 0.508 | a_loss: 0.547
Train: Epoch [1445/3000], Step [60/158]| g_loss: 0.743| d_loss: 0.640| gp_loss: 0.053| r_loss: 0.077| p_loss: 0.122| v_loss: 0.028| per_loss: 0.424 | a_loss: 0.534
Train: Epoch [1445/3000], Step [90/158]| g_loss: 0.766| d_loss: 0.594| gp_loss: 0.058| r_loss: 0.076| p_loss: 0.120| v_loss: 0.027| per_loss: 0.467 | a_loss: 0.557
Train: Epoch [1445/3000], Step [120/158]| g_loss: 0.744| d_loss: 0.632| gp_loss: 0.057| r_loss: 0.078| p_loss: 0.124| v_loss: 0.027| per_loss: 0.458 | a_loss: 0.531
Train: Epoch [1445/3000], Step [150/158]| g_loss: 0.780| d_loss: 0.583| gp_loss: 0.057| r_loss: 0.075| p_loss: 0.119| v_loss: 0.027| per_loss: 0.509 | a_loss: 0.567
Train: Epoch [1446/3000], Step [30/158]| g_loss: 0.768| d_loss: 0.653| gp_loss: 0.146| r_loss: 0.076| p_loss: 0.121| v_loss: 0.027| per_loss: 0.520 | a_loss: 0.553
Train: Epoch [1446/3000], Step [60/158]| g_loss: 0.750| d_loss: 0.674| gp_loss: 0.052| r_loss: 0.074| p_loss: 0.118| v_loss: 0.027| per_loss: 0.480 | a_loss: 0.542
Train: Epoch [1446/3000], Step [90/158]| g_loss: 0.783| d_loss: 0.584| gp_loss: 0.059| r_loss: 0.079| p_loss: 0.125| v_loss: 0.030| per_loss: 0.479 | a_loss: 0.564
Train: Epoch [1446/3000], Step [120/158]| g_loss: 0.798| d_loss: 0.645| gp_loss: 0.056| r_loss: 0.075| p_loss: 0.123| v_loss: 0.027| per_loss: 0.480 | a_loss: 0.586
Train: Epoch [1446/3000], Step [150/158]| g_loss: 0.703| d_loss: 0.660| gp_loss: 0.056| r_loss: 0.080| p_loss: 0.129| v_loss: 0.028| per_loss: 0.470 | a_loss: 0.483
Train: Epoch [1447/3000], Step [30/158]| g_loss: 0.754| d_loss: 0.661| gp_loss: 0.133| r_loss: 0.076| p_loss: 0.127| v_loss: 0.029| per_loss: 0.487 | a_loss: 0.538
Train: Epoch [1447/3000], Step [60/158]| g_loss: 0.802| d_loss: 0.556| gp_loss: 0.057| r_loss: 0.076| p_loss: 0.126| v_loss: 0.027| per_loss: 0.438 | a_loss: 0.592
Train: Epoch [1447/3000], Step [90/158]| g_loss: 0.772| d_loss: 0.637| gp_loss: 0.060| r_loss: 0.086| p_loss: 0.134| v_loss: 0.027| per_loss: 0.492 | a_loss: 0.543
Train: Epoch [1447/3000], Step [120/158]| g_loss: 0.737| d_loss: 0.644| gp_loss: 0.055| r_loss: 0.079| p_loss: 0.124| v_loss: 0.028| per_loss: 0.477 | a_loss: 0.521
Train: Epoch [1447/3000], Step [150/158]| g_loss: 0.725| d_loss: 0.618| gp_loss: 0.054| r_loss: 0.073| p_loss: 0.115| v_loss: 0.027| per_loss: 0.418 | a_loss: 0.525
Train: Epoch [1448/3000], Step [30/158]| g_loss: 0.710| d_loss: 0.796| gp_loss: 0.157| r_loss: 0.077| p_loss: 0.117| v_loss: 0.028| per_loss: 0.475 | a_loss: 0.499
Train: Epoch [1448/3000], Step [60/158]| g_loss: 0.777| d_loss: 0.538| gp_loss: 0.053| r_loss: 0.073| p_loss: 0.115| v_loss: 0.027| per_loss: 0.516 | a_loss: 0.568
Train: Epoch [1448/3000], Step [90/158]| g_loss: 0.720| d_loss: 0.653| gp_loss: 0.054| r_loss: 0.078| p_loss: 0.120| v_loss: 0.028| per_loss: 0.461 | a_loss: 0.508
Train: Epoch [1448/3000], Step [120/158]| g_loss: 0.805| d_loss: 0.546| gp_loss: 0.058| r_loss: 0.076| p_loss: 0.117| v_loss: 0.027| per_loss: 0.452 | a_loss: 0.597
Train: Epoch [1448/3000], Step [150/158]| g_loss: 0.773| d_loss: 0.491| gp_loss: 0.059| r_loss: 0.072| p_loss: 0.111| v_loss: 0.027| per_loss: 0.432 | a_loss: 0.575
Train: Epoch [1449/3000], Step [30/158]| g_loss: 0.768| d_loss: 0.656| gp_loss: 0.144| r_loss: 0.074| p_loss: 0.112| v_loss: 0.026| per_loss: 0.464 | a_loss: 0.566
Train: Epoch [1449/3000], Step [60/158]| g_loss: 0.768| d_loss: 0.613| gp_loss: 0.056| r_loss: 0.075| p_loss: 0.119| v_loss: 0.028| per_loss: 0.450 | a_loss: 0.560
Train: Epoch [1449/3000], Step [90/158]| g_loss: 0.802| d_loss: 0.520| gp_loss: 0.055| r_loss: 0.074| p_loss: 0.115| v_loss: 0.028| per_loss: 0.463 | a_loss: 0.597
Train: Epoch [1449/3000], Step [120/158]| g_loss: 0.758| d_loss: 0.643| gp_loss: 0.057| r_loss: 0.075| p_loss: 0.119| v_loss: 0.029| per_loss: 0.468 | a_loss: 0.548
Train: Epoch [1449/3000], Step [150/158]| g_loss: 0.753| d_loss: 0.613| gp_loss: 0.058| r_loss: 0.077| p_loss: 0.125| v_loss: 0.027| per_loss: 0.479 | a_loss: 0.538
Train: Epoch [1450/3000], Step [30/158]| g_loss: 0.795| d_loss: 0.703| gp_loss: 0.161| r_loss: 0.081| p_loss: 0.128| v_loss: 0.029| per_loss: 0.523 | a_loss: 0.569
Train: Epoch [1450/3000], Step [60/158]| g_loss: 0.774| d_loss: 0.597| gp_loss: 0.059| r_loss: 0.077| p_loss: 0.123| v_loss: 0.027| per_loss: 0.424 | a_loss: 0.567
Train: Epoch [1450/3000], Step [90/158]| g_loss: 0.725| d_loss: 0.617| gp_loss: 0.058| r_loss: 0.076| p_loss: 0.121| v_loss: 0.028| per_loss: 0.482 | a_loss: 0.513
Train: Epoch [1450/3000], Step [120/158]| g_loss: 0.758| d_loss: 0.603| gp_loss: 0.054| r_loss: 0.074| p_loss: 0.115| v_loss: 0.026| per_loss: 0.462 | a_loss: 0.554
Train: Epoch [1450/3000], Step [150/158]| g_loss: 0.703| d_loss: 0.646| gp_loss: 0.059| r_loss: 0.071| p_loss: 0.112| v_loss: 0.027| per_loss: 0.470 | a_loss: 0.502
Test: Epoch [1450/3000]| g_loss: 0.641| r_loss: 0.398| p_loss: 0.305| v_loss: 0.024
Train: Epoch [1451/3000], Step [30/158]| g_loss: 0.739| d_loss: 0.590| gp_loss: 0.058| r_loss: 0.075| p_loss: 0.120| v_loss: 0.027| per_loss: 0.502 | a_loss: 0.528
Train: Epoch [1451/3000], Step [60/158]| g_loss: 0.763| d_loss: 0.576| gp_loss: 0.057| r_loss: 0.078| p_loss: 0.118| v_loss: 0.029| per_loss: 0.466 | a_loss: 0.550
Train: Epoch [1451/3000], Step [90/158]| g_loss: 0.753| d_loss: 0.644| gp_loss: 0.057| r_loss: 0.075| p_loss: 0.119| v_loss: 0.027| per_loss: 0.445 | a_loss: 0.547
Train: Epoch [1451/3000], Step [120/158]| g_loss: 0.730| d_loss: 0.618| gp_loss: 0.057| r_loss: 0.074| p_loss: 0.119| v_loss: 0.029| per_loss: 0.466 | a_loss: 0.521
Train: Epoch [1451/3000], Step [150/158]| g_loss: 0.753| d_loss: 0.575| gp_loss: 0.058| r_loss: 0.075| p_loss: 0.115| v_loss: 0.028| per_loss: 0.479 | a_loss: 0.545
Train: Epoch [1452/3000], Step [30/158]| g_loss: 0.707| d_loss: 0.739| gp_loss: 0.126| r_loss: 0.076| p_loss: 0.118| v_loss: 0.028| per_loss: 0.459 | a_loss: 0.498
Train: Epoch [1452/3000], Step [60/158]| g_loss: 0.741| d_loss: 0.631| gp_loss: 0.062| r_loss: 0.076| p_loss: 0.120| v_loss: 0.029| per_loss: 0.459 | a_loss: 0.529
Train: Epoch [1452/3000], Step [90/158]| g_loss: 0.749| d_loss: 0.571| gp_loss: 0.059| r_loss: 0.074| p_loss: 0.116| v_loss: 0.028| per_loss: 0.415 | a_loss: 0.547
Train: Epoch [1452/3000], Step [120/158]| g_loss: 0.837| d_loss: 0.550| gp_loss: 0.062| r_loss: 0.074| p_loss: 0.118| v_loss: 0.027| per_loss: 0.483 | a_loss: 0.629
Train: Epoch [1452/3000], Step [150/158]| g_loss: 0.720| d_loss: 0.609| gp_loss: 0.063| r_loss: 0.074| p_loss: 0.115| v_loss: 0.027| per_loss: 0.480 | a_loss: 0.514
Train: Epoch [1453/3000], Step [30/158]| g_loss: 0.844| d_loss: 0.597| gp_loss: 0.164| r_loss: 0.080| p_loss: 0.128| v_loss: 0.027| per_loss: 0.453 | a_loss: 0.628
Train: Epoch [1453/3000], Step [60/158]| g_loss: 0.738| d_loss: 0.672| gp_loss: 0.053| r_loss: 0.073| p_loss: 0.115| v_loss: 0.027| per_loss: 0.486 | a_loss: 0.531
Train: Epoch [1453/3000], Step [90/158]| g_loss: 0.729| d_loss: 0.563| gp_loss: 0.057| r_loss: 0.073| p_loss: 0.113| v_loss: 0.028| per_loss: 0.491 | a_loss: 0.523
Train: Epoch [1453/3000], Step [120/158]| g_loss: 0.754| d_loss: 0.629| gp_loss: 0.058| r_loss: 0.076| p_loss: 0.113| v_loss: 0.028| per_loss: 0.451 | a_loss: 0.548
Train: Epoch [1453/3000], Step [150/158]| g_loss: 0.737| d_loss: 0.653| gp_loss: 0.061| r_loss: 0.071| p_loss: 0.114| v_loss: 0.026| per_loss: 0.476 | a_loss: 0.535
Train: Epoch [1454/3000], Step [30/158]| g_loss: 0.752| d_loss: 0.687| gp_loss: 0.151| r_loss: 0.073| p_loss: 0.114| v_loss: 0.028| per_loss: 0.472 | a_loss: 0.547
Train: Epoch [1454/3000], Step [60/158]| g_loss: 0.781| d_loss: 0.578| gp_loss: 0.054| r_loss: 0.075| p_loss: 0.120| v_loss: 0.027| per_loss: 0.468 | a_loss: 0.572
Train: Epoch [1454/3000], Step [90/158]| g_loss: 0.679| d_loss: 0.636| gp_loss: 0.056| r_loss: 0.072| p_loss: 0.110| v_loss: 0.025| per_loss: 0.443 | a_loss: 0.482
Train: Epoch [1454/3000], Step [120/158]| g_loss: 0.752| d_loss: 0.650| gp_loss: 0.060| r_loss: 0.077| p_loss: 0.115| v_loss: 0.028| per_loss: 0.480 | a_loss: 0.541
Train: Epoch [1454/3000], Step [150/158]| g_loss: 0.767| d_loss: 0.557| gp_loss: 0.057| r_loss: 0.074| p_loss: 0.113| v_loss: 0.028| per_loss: 0.467 | a_loss: 0.562
Train: Epoch [1455/3000], Step [30/158]| g_loss: 0.756| d_loss: 0.642| gp_loss: 0.143| r_loss: 0.074| p_loss: 0.112| v_loss: 0.028| per_loss: 0.472 | a_loss: 0.551
Train: Epoch [1455/3000], Step [60/158]| g_loss: 0.777| d_loss: 0.576| gp_loss: 0.054| r_loss: 0.073| p_loss: 0.114| v_loss: 0.026| per_loss: 0.470 | a_loss: 0.573
Train: Epoch [1455/3000], Step [90/158]| g_loss: 0.788| d_loss: 0.508| gp_loss: 0.056| r_loss: 0.072| p_loss: 0.105| v_loss: 0.027| per_loss: 0.451 | a_loss: 0.591
Train: Epoch [1455/3000], Step [120/158]| g_loss: 0.667| d_loss: 0.687| gp_loss: 0.058| r_loss: 0.070| p_loss: 0.108| v_loss: 0.026| per_loss: 0.454 | a_loss: 0.471
Train: Epoch [1455/3000], Step [150/158]| g_loss: 0.697| d_loss: 0.603| gp_loss: 0.062| r_loss: 0.072| p_loss: 0.110| v_loss: 0.026| per_loss: 0.486 | a_loss: 0.495
Train: Epoch [1456/3000], Step [30/158]| g_loss: 0.789| d_loss: 0.724| gp_loss: 0.155| r_loss: 0.074| p_loss: 0.109| v_loss: 0.027| per_loss: 0.496 | a_loss: 0.583
Train: Epoch [1456/3000], Step [60/158]| g_loss: 0.743| d_loss: 0.587| gp_loss: 0.058| r_loss: 0.073| p_loss: 0.111| v_loss: 0.027| per_loss: 0.473 | a_loss: 0.540
Train: Epoch [1456/3000], Step [90/158]| g_loss: 0.708| d_loss: 0.626| gp_loss: 0.055| r_loss: 0.074| p_loss: 0.111| v_loss: 0.027| per_loss: 0.452 | a_loss: 0.507
Train: Epoch [1456/3000], Step [120/158]| g_loss: 0.762| d_loss: 0.576| gp_loss: 0.063| r_loss: 0.071| p_loss: 0.111| v_loss: 0.026| per_loss: 0.454 | a_loss: 0.563
Train: Epoch [1456/3000], Step [150/158]| g_loss: 0.769| d_loss: 0.594| gp_loss: 0.058| r_loss: 0.074| p_loss: 0.118| v_loss: 0.027| per_loss: 0.460 | a_loss: 0.563
Train: Epoch [1457/3000], Step [30/158]| g_loss: 0.756| d_loss: 0.748| gp_loss: 0.160| r_loss: 0.078| p_loss: 0.118| v_loss: 0.027| per_loss: 0.469 | a_loss: 0.545
Train: Epoch [1457/3000], Step [60/158]| g_loss: 0.793| d_loss: 0.565| gp_loss: 0.063| r_loss: 0.078| p_loss: 0.121| v_loss: 0.027| per_loss: 0.463 | a_loss: 0.581
Train: Epoch [1457/3000], Step [90/158]| g_loss: 0.796| d_loss: 0.543| gp_loss: 0.057| r_loss: 0.077| p_loss: 0.121| v_loss: 0.027| per_loss: 0.444 | a_loss: 0.587
Train: Epoch [1457/3000], Step [120/158]| g_loss: 0.725| d_loss: 0.646| gp_loss: 0.054| r_loss: 0.077| p_loss: 0.120| v_loss: 0.028| per_loss: 0.484 | a_loss: 0.512
Train: Epoch [1457/3000], Step [150/158]| g_loss: 0.734| d_loss: 0.649| gp_loss: 0.059| r_loss: 0.073| p_loss: 0.116| v_loss: 0.027| per_loss: 0.461 | a_loss: 0.530
Train: Epoch [1458/3000], Step [30/158]| g_loss: 0.753| d_loss: 0.654| gp_loss: 0.081| r_loss: 0.076| p_loss: 0.119| v_loss: 0.027| per_loss: 0.463 | a_loss: 0.544
Train: Epoch [1458/3000], Step [60/158]| g_loss: 0.721| d_loss: 0.626| gp_loss: 0.061| r_loss: 0.077| p_loss: 0.120| v_loss: 0.028| per_loss: 0.465 | a_loss: 0.510
Train: Epoch [1458/3000], Step [90/158]| g_loss: 0.761| d_loss: 0.574| gp_loss: 0.064| r_loss: 0.076| p_loss: 0.117| v_loss: 0.026| per_loss: 0.465 | a_loss: 0.554
Train: Epoch [1458/3000], Step [120/158]| g_loss: 0.723| d_loss: 0.702| gp_loss: 0.061| r_loss: 0.074| p_loss: 0.119| v_loss: 0.027| per_loss: 0.477 | a_loss: 0.515
Train: Epoch [1458/3000], Step [150/158]| g_loss: 0.834| d_loss: 0.497| gp_loss: 0.062| r_loss: 0.077| p_loss: 0.122| v_loss: 0.028| per_loss: 0.480 | a_loss: 0.620
Train: Epoch [1459/3000], Step [30/158]| g_loss: 0.744| d_loss: 0.763| gp_loss: 0.215| r_loss: 0.074| p_loss: 0.117| v_loss: 0.027| per_loss: 0.478 | a_loss: 0.537
Train: Epoch [1459/3000], Step [60/158]| g_loss: 0.757| d_loss: 0.615| gp_loss: 0.058| r_loss: 0.076| p_loss: 0.115| v_loss: 0.028| per_loss: 0.468 | a_loss: 0.548
Train: Epoch [1459/3000], Step [90/158]| g_loss: 0.753| d_loss: 0.563| gp_loss: 0.055| r_loss: 0.077| p_loss: 0.118| v_loss: 0.027| per_loss: 0.466 | a_loss: 0.543
Train: Epoch [1459/3000], Step [120/158]| g_loss: 0.818| d_loss: 0.533| gp_loss: 0.057| r_loss: 0.075| p_loss: 0.117| v_loss: 0.029| per_loss: 0.457 | a_loss: 0.610
Train: Epoch [1459/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.674| gp_loss: 0.057| r_loss: 0.070| p_loss: 0.108| v_loss: 0.027| per_loss: 0.440 | a_loss: 0.468
Train: Epoch [1460/3000], Step [30/158]| g_loss: 0.740| d_loss: 0.713| gp_loss: 0.118| r_loss: 0.076| p_loss: 0.116| v_loss: 0.027| per_loss: 0.432 | a_loss: 0.536
Train: Epoch [1460/3000], Step [60/158]| g_loss: 0.720| d_loss: 0.686| gp_loss: 0.058| r_loss: 0.075| p_loss: 0.117| v_loss: 0.027| per_loss: 0.448 | a_loss: 0.515
Train: Epoch [1460/3000], Step [90/158]| g_loss: 0.739| d_loss: 0.549| gp_loss: 0.058| r_loss: 0.074| p_loss: 0.111| v_loss: 0.027| per_loss: 0.468 | a_loss: 0.535
Train: Epoch [1460/3000], Step [120/158]| g_loss: 0.742| d_loss: 0.623| gp_loss: 0.060| r_loss: 0.074| p_loss: 0.117| v_loss: 0.025| per_loss: 0.444 | a_loss: 0.540
Train: Epoch [1460/3000], Step [150/158]| g_loss: 0.745| d_loss: 0.600| gp_loss: 0.060| r_loss: 0.073| p_loss: 0.112| v_loss: 0.026| per_loss: 0.499 | a_loss: 0.540
Train: Epoch [1461/3000], Step [30/158]| g_loss: 0.798| d_loss: 0.695| gp_loss: 0.161| r_loss: 0.077| p_loss: 0.123| v_loss: 0.027| per_loss: 0.436 | a_loss: 0.589
Train: Epoch [1461/3000], Step [60/158]| g_loss: 0.727| d_loss: 0.651| gp_loss: 0.056| r_loss: 0.075| p_loss: 0.121| v_loss: 0.027| per_loss: 0.446 | a_loss: 0.520
Train: Epoch [1461/3000], Step [90/158]| g_loss: 0.817| d_loss: 0.509| gp_loss: 0.059| r_loss: 0.073| p_loss: 0.112| v_loss: 0.027| per_loss: 0.482 | a_loss: 0.612
Train: Epoch [1461/3000], Step [120/158]| g_loss: 0.712| d_loss: 0.651| gp_loss: 0.059| r_loss: 0.072| p_loss: 0.109| v_loss: 0.026| per_loss: 0.420 | a_loss: 0.518
Train: Epoch [1461/3000], Step [150/158]| g_loss: 0.784| d_loss: 0.537| gp_loss: 0.063| r_loss: 0.072| p_loss: 0.113| v_loss: 0.028| per_loss: 0.479 | a_loss: 0.580
Train: Epoch [1462/3000], Step [30/158]| g_loss: 0.726| d_loss: 0.690| gp_loss: 0.115| r_loss: 0.075| p_loss: 0.113| v_loss: 0.027| per_loss: 0.443 | a_loss: 0.523
Train: Epoch [1462/3000], Step [60/158]| g_loss: 0.742| d_loss: 0.630| gp_loss: 0.061| r_loss: 0.072| p_loss: 0.113| v_loss: 0.026| per_loss: 0.506 | a_loss: 0.537
Train: Epoch [1462/3000], Step [90/158]| g_loss: 0.714| d_loss: 0.620| gp_loss: 0.059| r_loss: 0.073| p_loss: 0.115| v_loss: 0.027| per_loss: 0.444 | a_loss: 0.511
Train: Epoch [1462/3000], Step [120/158]| g_loss: 0.791| d_loss: 0.622| gp_loss: 0.058| r_loss: 0.076| p_loss: 0.119| v_loss: 0.027| per_loss: 0.450 | a_loss: 0.584
Train: Epoch [1462/3000], Step [150/158]| g_loss: 0.773| d_loss: 0.519| gp_loss: 0.058| r_loss: 0.075| p_loss: 0.116| v_loss: 0.027| per_loss: 0.434 | a_loss: 0.570
Train: Epoch [1463/3000], Step [30/158]| g_loss: 0.718| d_loss: 0.717| gp_loss: 0.120| r_loss: 0.078| p_loss: 0.127| v_loss: 0.028| per_loss: 0.455 | a_loss: 0.503
Train: Epoch [1463/3000], Step [60/158]| g_loss: 0.758| d_loss: 0.626| gp_loss: 0.057| r_loss: 0.075| p_loss: 0.120| v_loss: 0.027| per_loss: 0.437 | a_loss: 0.552
Train: Epoch [1463/3000], Step [90/158]| g_loss: 0.791| d_loss: 0.508| gp_loss: 0.058| r_loss: 0.072| p_loss: 0.111| v_loss: 0.027| per_loss: 0.473 | a_loss: 0.590
Train: Epoch [1463/3000], Step [120/158]| g_loss: 0.759| d_loss: 0.565| gp_loss: 0.058| r_loss: 0.071| p_loss: 0.107| v_loss: 0.026| per_loss: 0.465 | a_loss: 0.563
Train: Epoch [1463/3000], Step [150/158]| g_loss: 0.724| d_loss: 0.640| gp_loss: 0.060| r_loss: 0.075| p_loss: 0.112| v_loss: 0.027| per_loss: 0.472 | a_loss: 0.519
Train: Epoch [1464/3000], Step [30/158]| g_loss: 0.709| d_loss: 0.746| gp_loss: 0.202| r_loss: 0.071| p_loss: 0.110| v_loss: 0.026| per_loss: 0.430 | a_loss: 0.513
Train: Epoch [1464/3000], Step [60/158]| g_loss: 0.768| d_loss: 0.587| gp_loss: 0.057| r_loss: 0.074| p_loss: 0.113| v_loss: 0.027| per_loss: 0.480 | a_loss: 0.563
Train: Epoch [1464/3000], Step [90/158]| g_loss: 0.689| d_loss: 0.675| gp_loss: 0.052| r_loss: 0.071| p_loss: 0.114| v_loss: 0.026| per_loss: 0.475 | a_loss: 0.488
Train: Epoch [1464/3000], Step [120/158]| g_loss: 0.769| d_loss: 0.590| gp_loss: 0.060| r_loss: 0.074| p_loss: 0.119| v_loss: 0.027| per_loss: 0.474 | a_loss: 0.560
Train: Epoch [1464/3000], Step [150/158]| g_loss: 0.743| d_loss: 0.568| gp_loss: 0.056| r_loss: 0.073| p_loss: 0.110| v_loss: 0.026| per_loss: 0.433 | a_loss: 0.546
Train: Epoch [1465/3000], Step [30/158]| g_loss: 0.734| d_loss: 0.710| gp_loss: 0.130| r_loss: 0.077| p_loss: 0.118| v_loss: 0.028| per_loss: 0.454 | a_loss: 0.524
Train: Epoch [1465/3000], Step [60/158]| g_loss: 0.709| d_loss: 0.602| gp_loss: 0.058| r_loss: 0.070| p_loss: 0.107| v_loss: 0.026| per_loss: 0.462 | a_loss: 0.514
Train: Epoch [1465/3000], Step [90/158]| g_loss: 0.826| d_loss: 0.519| gp_loss: 0.060| r_loss: 0.072| p_loss: 0.112| v_loss: 0.026| per_loss: 0.475 | a_loss: 0.624
Train: Epoch [1465/3000], Step [120/158]| g_loss: 0.721| d_loss: 0.623| gp_loss: 0.055| r_loss: 0.073| p_loss: 0.118| v_loss: 0.026| per_loss: 0.467 | a_loss: 0.517
Train: Epoch [1465/3000], Step [150/158]| g_loss: 0.749| d_loss: 0.588| gp_loss: 0.061| r_loss: 0.076| p_loss: 0.119| v_loss: 0.027| per_loss: 0.428 | a_loss: 0.544
Train: Epoch [1466/3000], Step [30/158]| g_loss: 0.715| d_loss: 0.765| gp_loss: 0.172| r_loss: 0.077| p_loss: 0.119| v_loss: 0.027| per_loss: 0.448 | a_loss: 0.506
Train: Epoch [1466/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.698| gp_loss: 0.057| r_loss: 0.074| p_loss: 0.114| v_loss: 0.026| per_loss: 0.421 | a_loss: 0.474
Train: Epoch [1466/3000], Step [90/158]| g_loss: 0.791| d_loss: 0.616| gp_loss: 0.062| r_loss: 0.071| p_loss: 0.109| v_loss: 0.026| per_loss: 0.473 | a_loss: 0.592
Train: Epoch [1466/3000], Step [120/158]| g_loss: 0.745| d_loss: 0.537| gp_loss: 0.060| r_loss: 0.072| p_loss: 0.110| v_loss: 0.027| per_loss: 0.476 | a_loss: 0.543
Train: Epoch [1466/3000], Step [150/158]| g_loss: 0.815| d_loss: 0.468| gp_loss: 0.055| r_loss: 0.074| p_loss: 0.114| v_loss: 0.027| per_loss: 0.470 | a_loss: 0.610
Train: Epoch [1467/3000], Step [30/158]| g_loss: 0.746| d_loss: 0.651| gp_loss: 0.116| r_loss: 0.072| p_loss: 0.108| v_loss: 0.027| per_loss: 0.436 | a_loss: 0.549
Train: Epoch [1467/3000], Step [60/158]| g_loss: 0.749| d_loss: 0.617| gp_loss: 0.054| r_loss: 0.073| p_loss: 0.113| v_loss: 0.027| per_loss: 0.463 | a_loss: 0.547
Train: Epoch [1467/3000], Step [90/158]| g_loss: 0.762| d_loss: 0.590| gp_loss: 0.059| r_loss: 0.070| p_loss: 0.106| v_loss: 0.026| per_loss: 0.470 | a_loss: 0.566
Train: Epoch [1467/3000], Step [120/158]| g_loss: 0.694| d_loss: 0.617| gp_loss: 0.058| r_loss: 0.072| p_loss: 0.112| v_loss: 0.026| per_loss: 0.423 | a_loss: 0.498
Train: Epoch [1467/3000], Step [150/158]| g_loss: 0.771| d_loss: 0.593| gp_loss: 0.059| r_loss: 0.075| p_loss: 0.117| v_loss: 0.027| per_loss: 0.475 | a_loss: 0.563
Train: Epoch [1468/3000], Step [30/158]| g_loss: 0.753| d_loss: 0.653| gp_loss: 0.149| r_loss: 0.072| p_loss: 0.114| v_loss: 0.027| per_loss: 0.459 | a_loss: 0.551
Train: Epoch [1468/3000], Step [60/158]| g_loss: 0.751| d_loss: 0.593| gp_loss: 0.056| r_loss: 0.072| p_loss: 0.110| v_loss: 0.028| per_loss: 0.456 | a_loss: 0.551
Train: Epoch [1468/3000], Step [90/158]| g_loss: 0.774| d_loss: 0.531| gp_loss: 0.056| r_loss: 0.072| p_loss: 0.109| v_loss: 0.027| per_loss: 0.461 | a_loss: 0.574
Train: Epoch [1468/3000], Step [120/158]| g_loss: 0.744| d_loss: 0.616| gp_loss: 0.058| r_loss: 0.073| p_loss: 0.115| v_loss: 0.026| per_loss: 0.418 | a_loss: 0.546
Train: Epoch [1468/3000], Step [150/158]| g_loss: 0.716| d_loss: 0.662| gp_loss: 0.059| r_loss: 0.078| p_loss: 0.122| v_loss: 0.028| per_loss: 0.470 | a_loss: 0.503
Train: Epoch [1469/3000], Step [30/158]| g_loss: 0.758| d_loss: 0.739| gp_loss: 0.176| r_loss: 0.078| p_loss: 0.126| v_loss: 0.026| per_loss: 0.476 | a_loss: 0.544
Train: Epoch [1469/3000], Step [60/158]| g_loss: 0.766| d_loss: 0.593| gp_loss: 0.057| r_loss: 0.076| p_loss: 0.115| v_loss: 0.025| per_loss: 0.467 | a_loss: 0.561
Train: Epoch [1469/3000], Step [90/158]| g_loss: 0.764| d_loss: 0.587| gp_loss: 0.054| r_loss: 0.074| p_loss: 0.112| v_loss: 0.026| per_loss: 0.457 | a_loss: 0.562
Train: Epoch [1469/3000], Step [120/158]| g_loss: 0.800| d_loss: 0.580| gp_loss: 0.055| r_loss: 0.095| p_loss: 0.129| v_loss: 0.027| per_loss: 0.467 | a_loss: 0.566
Train: Epoch [1469/3000], Step [150/158]| g_loss: 0.705| d_loss: 0.641| gp_loss: 0.060| r_loss: 0.077| p_loss: 0.136| v_loss: 0.028| per_loss: 0.426 | a_loss: 0.490
Train: Epoch [1470/3000], Step [30/158]| g_loss: 0.822| d_loss: 0.600| gp_loss: 0.151| r_loss: 0.077| p_loss: 0.124| v_loss: 0.027| per_loss: 0.469 | a_loss: 0.609
Train: Epoch [1470/3000], Step [60/158]| g_loss: 0.741| d_loss: 0.598| gp_loss: 0.053| r_loss: 0.072| p_loss: 0.113| v_loss: 0.025| per_loss: 0.446 | a_loss: 0.542
Train: Epoch [1470/3000], Step [90/158]| g_loss: 0.771| d_loss: 0.545| gp_loss: 0.058| r_loss: 0.071| p_loss: 0.107| v_loss: 0.027| per_loss: 0.460 | a_loss: 0.573
Train: Epoch [1470/3000], Step [120/158]| g_loss: 0.728| d_loss: 0.689| gp_loss: 0.054| r_loss: 0.072| p_loss: 0.116| v_loss: 0.026| per_loss: 0.472 | a_loss: 0.525
Train: Epoch [1470/3000], Step [150/158]| g_loss: 0.689| d_loss: 0.647| gp_loss: 0.063| r_loss: 0.071| p_loss: 0.111| v_loss: 0.025| per_loss: 0.449 | a_loss: 0.492
Train: Epoch [1471/3000], Step [30/158]| g_loss: 0.734| d_loss: 0.758| gp_loss: 0.210| r_loss: 0.076| p_loss: 0.117| v_loss: 0.027| per_loss: 0.469 | a_loss: 0.526
Train: Epoch [1471/3000], Step [60/158]| g_loss: 0.826| d_loss: 0.475| gp_loss: 0.050| r_loss: 0.072| p_loss: 0.110| v_loss: 0.027| per_loss: 0.492 | a_loss: 0.623
Train: Epoch [1471/3000], Step [90/158]| g_loss: 0.659| d_loss: 0.782| gp_loss: 0.050| r_loss: 0.072| p_loss: 0.114| v_loss: 0.025| per_loss: 0.445 | a_loss: 0.461
Train: Epoch [1471/3000], Step [120/158]| g_loss: 0.789| d_loss: 0.545| gp_loss: 0.058| r_loss: 0.074| p_loss: 0.118| v_loss: 0.027| per_loss: 0.471 | a_loss: 0.582
Train: Epoch [1471/3000], Step [150/158]| g_loss: 0.741| d_loss: 0.598| gp_loss: 0.058| r_loss: 0.075| p_loss: 0.114| v_loss: 0.027| per_loss: 0.450 | a_loss: 0.537
Train: Epoch [1472/3000], Step [30/158]| g_loss: 0.737| d_loss: 0.665| gp_loss: 0.145| r_loss: 0.075| p_loss: 0.119| v_loss: 0.026| per_loss: 0.491 | a_loss: 0.527
Train: Epoch [1472/3000], Step [60/158]| g_loss: 0.858| d_loss: 0.450| gp_loss: 0.056| r_loss: 0.074| p_loss: 0.121| v_loss: 0.027| per_loss: 0.437 | a_loss: 0.653
Train: Epoch [1472/3000], Step [90/158]| g_loss: 0.734| d_loss: 0.666| gp_loss: 0.050| r_loss: 0.077| p_loss: 0.118| v_loss: 0.026| per_loss: 0.483 | a_loss: 0.524
Train: Epoch [1472/3000], Step [120/158]| g_loss: 0.722| d_loss: 0.644| gp_loss: 0.055| r_loss: 0.072| p_loss: 0.116| v_loss: 0.027| per_loss: 0.415 | a_loss: 0.523
Train: Epoch [1472/3000], Step [150/158]| g_loss: 0.721| d_loss: 0.625| gp_loss: 0.053| r_loss: 0.075| p_loss: 0.113| v_loss: 0.026| per_loss: 0.442 | a_loss: 0.520
Train: Epoch [1473/3000], Step [30/158]| g_loss: 0.709| d_loss: 0.752| gp_loss: 0.188| r_loss: 0.073| p_loss: 0.111| v_loss: 0.026| per_loss: 0.456 | a_loss: 0.508
Train: Epoch [1473/3000], Step [60/158]| g_loss: 0.786| d_loss: 0.583| gp_loss: 0.050| r_loss: 0.076| p_loss: 0.121| v_loss: 0.026| per_loss: 0.477 | a_loss: 0.575
Train: Epoch [1473/3000], Step [90/158]| g_loss: 0.682| d_loss: 0.680| gp_loss: 0.054| r_loss: 0.075| p_loss: 0.119| v_loss: 0.025| per_loss: 0.453 | a_loss: 0.477
Train: Epoch [1473/3000], Step [120/158]| g_loss: 0.761| d_loss: 0.534| gp_loss: 0.055| r_loss: 0.073| p_loss: 0.107| v_loss: 0.027| per_loss: 0.438 | a_loss: 0.564
Train: Epoch [1473/3000], Step [150/158]| g_loss: 0.804| d_loss: 0.593| gp_loss: 0.051| r_loss: 0.072| p_loss: 0.107| v_loss: 0.026| per_loss: 0.460 | a_loss: 0.607
Train: Epoch [1474/3000], Step [30/158]| g_loss: 0.695| d_loss: 0.743| gp_loss: 0.159| r_loss: 0.073| p_loss: 0.115| v_loss: 0.027| per_loss: 0.416 | a_loss: 0.496
Train: Epoch [1474/3000], Step [60/158]| g_loss: 0.744| d_loss: 0.578| gp_loss: 0.057| r_loss: 0.072| p_loss: 0.108| v_loss: 0.026| per_loss: 0.447 | a_loss: 0.548
Train: Epoch [1474/3000], Step [90/158]| g_loss: 0.738| d_loss: 0.635| gp_loss: 0.055| r_loss: 0.074| p_loss: 0.106| v_loss: 0.027| per_loss: 0.466 | a_loss: 0.538
Train: Epoch [1474/3000], Step [120/158]| g_loss: 0.783| d_loss: 0.553| gp_loss: 0.055| r_loss: 0.074| p_loss: 0.110| v_loss: 0.027| per_loss: 0.455 | a_loss: 0.582
Train: Epoch [1474/3000], Step [150/158]| g_loss: 0.758| d_loss: 0.592| gp_loss: 0.054| r_loss: 0.073| p_loss: 0.108| v_loss: 0.026| per_loss: 0.464 | a_loss: 0.558
Train: Epoch [1475/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.762| gp_loss: 0.118| r_loss: 0.070| p_loss: 0.107| v_loss: 0.026| per_loss: 0.473 | a_loss: 0.455
Train: Epoch [1475/3000], Step [60/158]| g_loss: 0.749| d_loss: 0.625| gp_loss: 0.052| r_loss: 0.072| p_loss: 0.108| v_loss: 0.026| per_loss: 0.442 | a_loss: 0.552
Train: Epoch [1475/3000], Step [90/158]| g_loss: 0.748| d_loss: 0.566| gp_loss: 0.058| r_loss: 0.073| p_loss: 0.114| v_loss: 0.027| per_loss: 0.486 | a_loss: 0.543
Train: Epoch [1475/3000], Step [120/158]| g_loss: 0.778| d_loss: 0.610| gp_loss: 0.053| r_loss: 0.075| p_loss: 0.121| v_loss: 0.027| per_loss: 0.460 | a_loss: 0.570
Train: Epoch [1475/3000], Step [150/158]| g_loss: 0.753| d_loss: 0.544| gp_loss: 0.054| r_loss: 0.072| p_loss: 0.110| v_loss: 0.027| per_loss: 0.446 | a_loss: 0.555
Train: Epoch [1476/3000], Step [30/158]| g_loss: 0.743| d_loss: 0.670| gp_loss: 0.147| r_loss: 0.072| p_loss: 0.112| v_loss: 0.026| per_loss: 0.448 | a_loss: 0.544
Train: Epoch [1476/3000], Step [60/158]| g_loss: 0.779| d_loss: 0.628| gp_loss: 0.054| r_loss: 0.075| p_loss: 0.111| v_loss: 0.026| per_loss: 0.450 | a_loss: 0.578
Train: Epoch [1476/3000], Step [90/158]| g_loss: 0.757| d_loss: 0.551| gp_loss: 0.055| r_loss: 0.073| p_loss: 0.115| v_loss: 0.027| per_loss: 0.458 | a_loss: 0.553
Train: Epoch [1476/3000], Step [120/158]| g_loss: 0.768| d_loss: 0.641| gp_loss: 0.054| r_loss: 0.076| p_loss: 0.123| v_loss: 0.027| per_loss: 0.431 | a_loss: 0.560
Train: Epoch [1476/3000], Step [150/158]| g_loss: 0.726| d_loss: 0.653| gp_loss: 0.054| r_loss: 0.074| p_loss: 0.118| v_loss: 0.026| per_loss: 0.444 | a_loss: 0.522
Train: Epoch [1477/3000], Step [30/158]| g_loss: 0.785| d_loss: 0.727| gp_loss: 0.193| r_loss: 0.073| p_loss: 0.115| v_loss: 0.027| per_loss: 0.534 | a_loss: 0.574
Train: Epoch [1477/3000], Step [60/158]| g_loss: 0.683| d_loss: 0.645| gp_loss: 0.052| r_loss: 0.075| p_loss: 0.112| v_loss: 0.025| per_loss: 0.447 | a_loss: 0.481
Train: Epoch [1477/3000], Step [90/158]| g_loss: 0.739| d_loss: 0.624| gp_loss: 0.054| r_loss: 0.073| p_loss: 0.113| v_loss: 0.026| per_loss: 0.446 | a_loss: 0.539
Train: Epoch [1477/3000], Step [120/158]| g_loss: 0.786| d_loss: 0.491| gp_loss: 0.054| r_loss: 0.077| p_loss: 0.122| v_loss: 0.027| per_loss: 0.431 | a_loss: 0.577
Train: Epoch [1477/3000], Step [150/158]| g_loss: 0.763| d_loss: 0.671| gp_loss: 0.050| r_loss: 0.075| p_loss: 0.120| v_loss: 0.026| per_loss: 0.453 | a_loss: 0.557
Train: Epoch [1478/3000], Step [30/158]| g_loss: 0.738| d_loss: 0.687| gp_loss: 0.124| r_loss: 0.071| p_loss: 0.112| v_loss: 0.026| per_loss: 0.446 | a_loss: 0.541
Train: Epoch [1478/3000], Step [60/158]| g_loss: 0.727| d_loss: 0.644| gp_loss: 0.051| r_loss: 0.072| p_loss: 0.111| v_loss: 0.026| per_loss: 0.449 | a_loss: 0.529
Train: Epoch [1478/3000], Step [90/158]| g_loss: 0.722| d_loss: 0.606| gp_loss: 0.054| r_loss: 0.073| p_loss: 0.114| v_loss: 0.026| per_loss: 0.462 | a_loss: 0.519
Train: Epoch [1478/3000], Step [120/158]| g_loss: 0.723| d_loss: 0.653| gp_loss: 0.056| r_loss: 0.073| p_loss: 0.111| v_loss: 0.025| per_loss: 0.461 | a_loss: 0.523
Train: Epoch [1478/3000], Step [150/158]| g_loss: 0.773| d_loss: 0.558| gp_loss: 0.059| r_loss: 0.075| p_loss: 0.119| v_loss: 0.028| per_loss: 0.426 | a_loss: 0.568
Train: Epoch [1479/3000], Step [30/158]| g_loss: 0.705| d_loss: 0.814| gp_loss: 0.173| r_loss: 0.073| p_loss: 0.118| v_loss: 0.025| per_loss: 0.465 | a_loss: 0.503
Train: Epoch [1479/3000], Step [60/158]| g_loss: 0.699| d_loss: 0.653| gp_loss: 0.049| r_loss: 0.074| p_loss: 0.112| v_loss: 0.026| per_loss: 0.468 | a_loss: 0.497
Train: Epoch [1479/3000], Step [90/158]| g_loss: 0.719| d_loss: 0.580| gp_loss: 0.055| r_loss: 0.072| p_loss: 0.109| v_loss: 0.027| per_loss: 0.442 | a_loss: 0.522
Train: Epoch [1479/3000], Step [120/158]| g_loss: 0.741| d_loss: 0.572| gp_loss: 0.054| r_loss: 0.070| p_loss: 0.105| v_loss: 0.026| per_loss: 0.433 | a_loss: 0.550
Train: Epoch [1479/3000], Step [150/158]| g_loss: 0.787| d_loss: 0.462| gp_loss: 0.058| r_loss: 0.074| p_loss: 0.112| v_loss: 0.027| per_loss: 0.468 | a_loss: 0.583
Train: Epoch [1480/3000], Step [30/158]| g_loss: 0.772| d_loss: 0.750| gp_loss: 0.197| r_loss: 0.078| p_loss: 0.115| v_loss: 0.026| per_loss: 0.480 | a_loss: 0.563
Train: Epoch [1480/3000], Step [60/158]| g_loss: 0.720| d_loss: 0.632| gp_loss: 0.051| r_loss: 0.071| p_loss: 0.112| v_loss: 0.025| per_loss: 0.436 | a_loss: 0.524
Train: Epoch [1480/3000], Step [90/158]| g_loss: 0.757| d_loss: 0.606| gp_loss: 0.051| r_loss: 0.078| p_loss: 0.122| v_loss: 0.026| per_loss: 0.449 | a_loss: 0.547
Train: Epoch [1480/3000], Step [120/158]| g_loss: 0.723| d_loss: 0.574| gp_loss: 0.054| r_loss: 0.073| p_loss: 0.116| v_loss: 0.027| per_loss: 0.464 | a_loss: 0.519
Train: Epoch [1480/3000], Step [150/158]| g_loss: 0.817| d_loss: 0.539| gp_loss: 0.057| r_loss: 0.081| p_loss: 0.121| v_loss: 0.027| per_loss: 0.448 | a_loss: 0.604
Train: Epoch [1481/3000], Step [30/158]| g_loss: 0.785| d_loss: 0.657| gp_loss: 0.129| r_loss: 0.073| p_loss: 0.113| v_loss: 0.027| per_loss: 0.501 | a_loss: 0.578
Train: Epoch [1481/3000], Step [60/158]| g_loss: 0.727| d_loss: 0.603| gp_loss: 0.055| r_loss: 0.075| p_loss: 0.113| v_loss: 0.027| per_loss: 0.475 | a_loss: 0.521
Train: Epoch [1481/3000], Step [90/158]| g_loss: 0.822| d_loss: 0.567| gp_loss: 0.053| r_loss: 0.075| p_loss: 0.118| v_loss: 0.027| per_loss: 0.439 | a_loss: 0.617
Train: Epoch [1481/3000], Step [120/158]| g_loss: 0.661| d_loss: 0.645| gp_loss: 0.055| r_loss: 0.070| p_loss: 0.107| v_loss: 0.025| per_loss: 0.467 | a_loss: 0.466
Train: Epoch [1481/3000], Step [150/158]| g_loss: 0.745| d_loss: 0.563| gp_loss: 0.059| r_loss: 0.072| p_loss: 0.109| v_loss: 0.025| per_loss: 0.420 | a_loss: 0.551
Train: Epoch [1482/3000], Step [30/158]| g_loss: 0.780| d_loss: 0.678| gp_loss: 0.186| r_loss: 0.076| p_loss: 0.118| v_loss: 0.026| per_loss: 0.443 | a_loss: 0.575
Train: Epoch [1482/3000], Step [60/158]| g_loss: 0.731| d_loss: 0.662| gp_loss: 0.051| r_loss: 0.072| p_loss: 0.114| v_loss: 0.026| per_loss: 0.473 | a_loss: 0.529
Train: Epoch [1482/3000], Step [90/158]| g_loss: 0.763| d_loss: 0.618| gp_loss: 0.052| r_loss: 0.074| p_loss: 0.114| v_loss: 0.028| per_loss: 0.469 | a_loss: 0.557
Train: Epoch [1482/3000], Step [120/158]| g_loss: 0.698| d_loss: 0.602| gp_loss: 0.054| r_loss: 0.071| p_loss: 0.108| v_loss: 0.027| per_loss: 0.479 | a_loss: 0.498
Train: Epoch [1482/3000], Step [150/158]| g_loss: 0.739| d_loss: 0.573| gp_loss: 0.055| r_loss: 0.072| p_loss: 0.110| v_loss: 0.027| per_loss: 0.450 | a_loss: 0.540
Train: Epoch [1483/3000], Step [30/158]| g_loss: 0.697| d_loss: 0.779| gp_loss: 0.123| r_loss: 0.074| p_loss: 0.117| v_loss: 0.026| per_loss: 0.468 | a_loss: 0.491
Train: Epoch [1483/3000], Step [60/158]| g_loss: 0.714| d_loss: 0.594| gp_loss: 0.057| r_loss: 0.072| p_loss: 0.112| v_loss: 0.026| per_loss: 0.455 | a_loss: 0.514
Train: Epoch [1483/3000], Step [90/158]| g_loss: 0.754| d_loss: 0.581| gp_loss: 0.055| r_loss: 0.069| p_loss: 0.110| v_loss: 0.026| per_loss: 0.465 | a_loss: 0.556
Train: Epoch [1483/3000], Step [120/158]| g_loss: 0.753| d_loss: 0.604| gp_loss: 0.054| r_loss: 0.072| p_loss: 0.112| v_loss: 0.026| per_loss: 0.446 | a_loss: 0.555
Train: Epoch [1483/3000], Step [150/158]| g_loss: 0.782| d_loss: 0.563| gp_loss: 0.057| r_loss: 0.075| p_loss: 0.112| v_loss: 0.027| per_loss: 0.501 | a_loss: 0.574
Train: Epoch [1484/3000], Step [30/158]| g_loss: 0.787| d_loss: 0.674| gp_loss: 0.149| r_loss: 0.071| p_loss: 0.113| v_loss: 0.026| per_loss: 0.479 | a_loss: 0.586
Train: Epoch [1484/3000], Step [60/158]| g_loss: 0.711| d_loss: 0.582| gp_loss: 0.054| r_loss: 0.074| p_loss: 0.119| v_loss: 0.027| per_loss: 0.432 | a_loss: 0.507
Train: Epoch [1484/3000], Step [90/158]| g_loss: 0.742| d_loss: 0.574| gp_loss: 0.058| r_loss: 0.073| p_loss: 0.113| v_loss: 0.026| per_loss: 0.444 | a_loss: 0.542
Train: Epoch [1484/3000], Step [120/158]| g_loss: 0.759| d_loss: 0.609| gp_loss: 0.056| r_loss: 0.074| p_loss: 0.117| v_loss: 0.026| per_loss: 0.452 | a_loss: 0.555
Train: Epoch [1484/3000], Step [150/158]| g_loss: 0.715| d_loss: 0.623| gp_loss: 0.056| r_loss: 0.071| p_loss: 0.110| v_loss: 0.027| per_loss: 0.441 | a_loss: 0.517
Train: Epoch [1485/3000], Step [30/158]| g_loss: 0.744| d_loss: 0.652| gp_loss: 0.140| r_loss: 0.075| p_loss: 0.113| v_loss: 0.027| per_loss: 0.457 | a_loss: 0.540
Train: Epoch [1485/3000], Step [60/158]| g_loss: 0.754| d_loss: 0.613| gp_loss: 0.056| r_loss: 0.074| p_loss: 0.112| v_loss: 0.027| per_loss: 0.413 | a_loss: 0.556
Train: Epoch [1485/3000], Step [90/158]| g_loss: 0.743| d_loss: 0.569| gp_loss: 0.055| r_loss: 0.072| p_loss: 0.111| v_loss: 0.027| per_loss: 0.438 | a_loss: 0.545
Train: Epoch [1485/3000], Step [120/158]| g_loss: 0.783| d_loss: 0.565| gp_loss: 0.057| r_loss: 0.073| p_loss: 0.109| v_loss: 0.028| per_loss: 0.448 | a_loss: 0.583
Train: Epoch [1485/3000], Step [150/158]| g_loss: 0.763| d_loss: 0.633| gp_loss: 0.056| r_loss: 0.072| p_loss: 0.113| v_loss: 0.026| per_loss: 0.481 | a_loss: 0.560
Train: Epoch [1486/3000], Step [30/158]| g_loss: 0.699| d_loss: 0.684| gp_loss: 0.111| r_loss: 0.073| p_loss: 0.121| v_loss: 0.026| per_loss: 0.424 | a_loss: 0.497
Train: Epoch [1486/3000], Step [60/158]| g_loss: 0.749| d_loss: 0.607| gp_loss: 0.057| r_loss: 0.077| p_loss: 0.119| v_loss: 0.027| per_loss: 0.419 | a_loss: 0.544
Train: Epoch [1486/3000], Step [90/158]| g_loss: 0.777| d_loss: 0.629| gp_loss: 0.060| r_loss: 0.075| p_loss: 0.118| v_loss: 0.026| per_loss: 0.455 | a_loss: 0.571
Train: Epoch [1486/3000], Step [120/158]| g_loss: 0.778| d_loss: 0.587| gp_loss: 0.059| r_loss: 0.075| p_loss: 0.118| v_loss: 0.026| per_loss: 0.468 | a_loss: 0.571
Train: Epoch [1486/3000], Step [150/158]| g_loss: 0.763| d_loss: 0.586| gp_loss: 0.060| r_loss: 0.076| p_loss: 0.116| v_loss: 0.028| per_loss: 0.459 | a_loss: 0.556
Train: Epoch [1487/3000], Step [30/158]| g_loss: 0.724| d_loss: 0.643| gp_loss: 0.116| r_loss: 0.069| p_loss: 0.104| v_loss: 0.028| per_loss: 0.471 | a_loss: 0.528
Train: Epoch [1487/3000], Step [60/158]| g_loss: 0.752| d_loss: 0.567| gp_loss: 0.057| r_loss: 0.069| p_loss: 0.104| v_loss: 0.026| per_loss: 0.455 | a_loss: 0.560
Train: Epoch [1487/3000], Step [90/158]| g_loss: 0.757| d_loss: 0.625| gp_loss: 0.061| r_loss: 0.072| p_loss: 0.109| v_loss: 0.027| per_loss: 0.453 | a_loss: 0.558
Train: Epoch [1487/3000], Step [120/158]| g_loss: 0.741| d_loss: 0.579| gp_loss: 0.062| r_loss: 0.074| p_loss: 0.117| v_loss: 0.027| per_loss: 0.454 | a_loss: 0.535
Train: Epoch [1487/3000], Step [150/158]| g_loss: 0.753| d_loss: 0.651| gp_loss: 0.058| r_loss: 0.074| p_loss: 0.114| v_loss: 0.025| per_loss: 0.466 | a_loss: 0.551
Train: Epoch [1488/3000], Step [30/158]| g_loss: 0.684| d_loss: 0.781| gp_loss: 0.174| r_loss: 0.071| p_loss: 0.112| v_loss: 0.026| per_loss: 0.464 | a_loss: 0.484
Train: Epoch [1488/3000], Step [60/158]| g_loss: 0.804| d_loss: 0.544| gp_loss: 0.058| r_loss: 0.071| p_loss: 0.111| v_loss: 0.027| per_loss: 0.469 | a_loss: 0.604
Train: Epoch [1488/3000], Step [90/158]| g_loss: 0.718| d_loss: 0.582| gp_loss: 0.055| r_loss: 0.072| p_loss: 0.112| v_loss: 0.027| per_loss: 0.466 | a_loss: 0.516
Train: Epoch [1488/3000], Step [120/158]| g_loss: 0.781| d_loss: 0.567| gp_loss: 0.060| r_loss: 0.072| p_loss: 0.110| v_loss: 0.028| per_loss: 0.474 | a_loss: 0.579
Train: Epoch [1488/3000], Step [150/158]| g_loss: 0.791| d_loss: 0.588| gp_loss: 0.059| r_loss: 0.076| p_loss: 0.116| v_loss: 0.028| per_loss: 0.470 | a_loss: 0.583
Train: Epoch [1489/3000], Step [30/158]| g_loss: 0.713| d_loss: 0.806| gp_loss: 0.217| r_loss: 0.077| p_loss: 0.121| v_loss: 0.028| per_loss: 0.405 | a_loss: 0.508
Train: Epoch [1489/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.684| gp_loss: 0.053| r_loss: 0.079| p_loss: 0.119| v_loss: 0.027| per_loss: 0.434 | a_loss: 0.463
Train: Epoch [1489/3000], Step [90/158]| g_loss: 0.747| d_loss: 0.595| gp_loss: 0.057| r_loss: 0.073| p_loss: 0.111| v_loss: 0.026| per_loss: 0.475 | a_loss: 0.546
Train: Epoch [1489/3000], Step [120/158]| g_loss: 0.728| d_loss: 0.600| gp_loss: 0.053| r_loss: 0.072| p_loss: 0.109| v_loss: 0.026| per_loss: 0.451 | a_loss: 0.530
Train: Epoch [1489/3000], Step [150/158]| g_loss: 0.816| d_loss: 0.500| gp_loss: 0.057| r_loss: 0.072| p_loss: 0.109| v_loss: 0.027| per_loss: 0.487 | a_loss: 0.614
Train: Epoch [1490/3000], Step [30/158]| g_loss: 0.727| d_loss: 0.702| gp_loss: 0.161| r_loss: 0.072| p_loss: 0.110| v_loss: 0.027| per_loss: 0.431 | a_loss: 0.529
Train: Epoch [1490/3000], Step [60/158]| g_loss: 0.725| d_loss: 0.645| gp_loss: 0.053| r_loss: 0.073| p_loss: 0.109| v_loss: 0.027| per_loss: 0.410 | a_loss: 0.529
Train: Epoch [1490/3000], Step [90/158]| g_loss: 0.693| d_loss: 0.644| gp_loss: 0.057| r_loss: 0.072| p_loss: 0.112| v_loss: 0.026| per_loss: 0.431 | a_loss: 0.495
Train: Epoch [1490/3000], Step [120/158]| g_loss: 0.804| d_loss: 0.552| gp_loss: 0.061| r_loss: 0.072| p_loss: 0.113| v_loss: 0.027| per_loss: 0.494 | a_loss: 0.599
Train: Epoch [1490/3000], Step [150/158]| g_loss: 0.758| d_loss: 0.543| gp_loss: 0.058| r_loss: 0.071| p_loss: 0.108| v_loss: 0.027| per_loss: 0.492 | a_loss: 0.556
Train: Epoch [1491/3000], Step [30/158]| g_loss: 0.742| d_loss: 0.681| gp_loss: 0.178| r_loss: 0.074| p_loss: 0.106| v_loss: 0.026| per_loss: 0.448 | a_loss: 0.545
Train: Epoch [1491/3000], Step [60/158]| g_loss: 0.714| d_loss: 0.666| gp_loss: 0.054| r_loss: 0.071| p_loss: 0.109| v_loss: 0.026| per_loss: 0.444 | a_loss: 0.518
Train: Epoch [1491/3000], Step [90/158]| g_loss: 0.796| d_loss: 0.590| gp_loss: 0.057| r_loss: 0.073| p_loss: 0.116| v_loss: 0.028| per_loss: 0.467 | a_loss: 0.591
Train: Epoch [1491/3000], Step [120/158]| g_loss: 0.759| d_loss: 0.586| gp_loss: 0.056| r_loss: 0.075| p_loss: 0.116| v_loss: 0.027| per_loss: 0.431 | a_loss: 0.555
Train: Epoch [1491/3000], Step [150/158]| g_loss: 0.745| d_loss: 0.630| gp_loss: 0.055| r_loss: 0.072| p_loss: 0.114| v_loss: 0.027| per_loss: 0.473 | a_loss: 0.541
Train: Epoch [1492/3000], Step [30/158]| g_loss: 0.752| d_loss: 0.717| gp_loss: 0.164| r_loss: 0.072| p_loss: 0.112| v_loss: 0.028| per_loss: 0.479 | a_loss: 0.548
Train: Epoch [1492/3000], Step [60/158]| g_loss: 0.760| d_loss: 0.582| gp_loss: 0.050| r_loss: 0.071| p_loss: 0.113| v_loss: 0.028| per_loss: 0.451 | a_loss: 0.559
Train: Epoch [1492/3000], Step [90/158]| g_loss: 0.718| d_loss: 0.635| gp_loss: 0.048| r_loss: 0.074| p_loss: 0.112| v_loss: 0.028| per_loss: 0.441 | a_loss: 0.516
Train: Epoch [1492/3000], Step [120/158]| g_loss: 0.736| d_loss: 0.558| gp_loss: 0.055| r_loss: 0.073| p_loss: 0.107| v_loss: 0.027| per_loss: 0.411 | a_loss: 0.542
Train: Epoch [1492/3000], Step [150/158]| g_loss: 0.766| d_loss: 0.535| gp_loss: 0.055| r_loss: 0.071| p_loss: 0.107| v_loss: 0.026| per_loss: 0.439 | a_loss: 0.572
Train: Epoch [1493/3000], Step [30/158]| g_loss: 0.765| d_loss: 0.632| gp_loss: 0.132| r_loss: 0.072| p_loss: 0.114| v_loss: 0.026| per_loss: 0.432 | a_loss: 0.567
Train: Epoch [1493/3000], Step [60/158]| g_loss: 0.725| d_loss: 0.579| gp_loss: 0.053| r_loss: 0.072| p_loss: 0.111| v_loss: 0.026| per_loss: 0.453 | a_loss: 0.525
Train: Epoch [1493/3000], Step [90/158]| g_loss: 0.773| d_loss: 0.639| gp_loss: 0.052| r_loss: 0.071| p_loss: 0.109| v_loss: 0.025| per_loss: 0.443 | a_loss: 0.578
Train: Epoch [1493/3000], Step [120/158]| g_loss: 0.750| d_loss: 0.544| gp_loss: 0.060| r_loss: 0.072| p_loss: 0.108| v_loss: 0.028| per_loss: 0.448 | a_loss: 0.551
Train: Epoch [1493/3000], Step [150/158]| g_loss: 0.722| d_loss: 0.674| gp_loss: 0.052| r_loss: 0.074| p_loss: 0.110| v_loss: 0.028| per_loss: 0.448 | a_loss: 0.521
Train: Epoch [1494/3000], Step [30/158]| g_loss: 0.728| d_loss: 0.715| gp_loss: 0.162| r_loss: 0.071| p_loss: 0.113| v_loss: 0.026| per_loss: 0.452 | a_loss: 0.529
Train: Epoch [1494/3000], Step [60/158]| g_loss: 0.761| d_loss: 0.554| gp_loss: 0.055| r_loss: 0.072| p_loss: 0.108| v_loss: 0.027| per_loss: 0.439 | a_loss: 0.564
Train: Epoch [1494/3000], Step [90/158]| g_loss: 0.731| d_loss: 0.605| gp_loss: 0.052| r_loss: 0.069| p_loss: 0.107| v_loss: 0.026| per_loss: 0.475 | a_loss: 0.535
Train: Epoch [1494/3000], Step [120/158]| g_loss: 0.743| d_loss: 0.559| gp_loss: 0.058| r_loss: 0.070| p_loss: 0.101| v_loss: 0.026| per_loss: 0.453 | a_loss: 0.552
Train: Epoch [1494/3000], Step [150/158]| g_loss: 0.732| d_loss: 0.582| gp_loss: 0.059| r_loss: 0.072| p_loss: 0.111| v_loss: 0.027| per_loss: 0.441 | a_loss: 0.533
Train: Epoch [1495/3000], Step [30/158]| g_loss: 0.707| d_loss: 0.760| gp_loss: 0.145| r_loss: 0.073| p_loss: 0.118| v_loss: 0.025| per_loss: 0.462 | a_loss: 0.505
Train: Epoch [1495/3000], Step [60/158]| g_loss: 0.785| d_loss: 0.684| gp_loss: 0.056| r_loss: 0.074| p_loss: 0.118| v_loss: 0.027| per_loss: 0.470 | a_loss: 0.578
Train: Epoch [1495/3000], Step [90/158]| g_loss: 0.758| d_loss: 0.496| gp_loss: 0.056| r_loss: 0.072| p_loss: 0.111| v_loss: 0.026| per_loss: 0.456 | a_loss: 0.559
Train: Epoch [1495/3000], Step [120/158]| g_loss: 0.789| d_loss: 0.586| gp_loss: 0.056| r_loss: 0.077| p_loss: 0.123| v_loss: 0.028| per_loss: 0.445 | a_loss: 0.578
Train: Epoch [1495/3000], Step [150/158]| g_loss: 0.727| d_loss: 0.681| gp_loss: 0.054| r_loss: 0.078| p_loss: 0.118| v_loss: 0.027| per_loss: 0.431 | a_loss: 0.520
Train: Epoch [1496/3000], Step [30/158]| g_loss: 0.773| d_loss: 0.617| gp_loss: 0.150| r_loss: 0.070| p_loss: 0.113| v_loss: 0.027| per_loss: 0.472 | a_loss: 0.572
Train: Epoch [1496/3000], Step [60/158]| g_loss: 0.781| d_loss: 0.569| gp_loss: 0.051| r_loss: 0.072| p_loss: 0.114| v_loss: 0.027| per_loss: 0.460 | a_loss: 0.579
Train: Epoch [1496/3000], Step [90/158]| g_loss: 0.739| d_loss: 0.606| gp_loss: 0.054| r_loss: 0.071| p_loss: 0.109| v_loss: 0.027| per_loss: 0.456 | a_loss: 0.541
Train: Epoch [1496/3000], Step [120/158]| g_loss: 0.707| d_loss: 0.675| gp_loss: 0.053| r_loss: 0.073| p_loss: 0.110| v_loss: 0.026| per_loss: 0.425 | a_loss: 0.511
Train: Epoch [1496/3000], Step [150/158]| g_loss: 0.715| d_loss: 0.613| gp_loss: 0.059| r_loss: 0.073| p_loss: 0.116| v_loss: 0.026| per_loss: 0.451 | a_loss: 0.513
Train: Epoch [1497/3000], Step [30/158]| g_loss: 0.746| d_loss: 0.729| gp_loss: 0.130| r_loss: 0.082| p_loss: 0.116| v_loss: 0.027| per_loss: 0.457 | a_loss: 0.534
Train: Epoch [1497/3000], Step [60/158]| g_loss: 0.742| d_loss: 0.560| gp_loss: 0.057| r_loss: 0.072| p_loss: 0.110| v_loss: 0.027| per_loss: 0.462 | a_loss: 0.542
Train: Epoch [1497/3000], Step [90/158]| g_loss: 0.756| d_loss: 0.534| gp_loss: 0.054| r_loss: 0.075| p_loss: 0.113| v_loss: 0.026| per_loss: 0.422 | a_loss: 0.556
Train: Epoch [1497/3000], Step [120/158]| g_loss: 0.788| d_loss: 0.586| gp_loss: 0.059| r_loss: 0.073| p_loss: 0.111| v_loss: 0.027| per_loss: 0.428 | a_loss: 0.590
Train: Epoch [1497/3000], Step [150/158]| g_loss: 0.760| d_loss: 0.621| gp_loss: 0.056| r_loss: 0.071| p_loss: 0.111| v_loss: 0.026| per_loss: 0.491 | a_loss: 0.558
Train: Epoch [1498/3000], Step [30/158]| g_loss: 0.747| d_loss: 0.660| gp_loss: 0.125| r_loss: 0.078| p_loss: 0.124| v_loss: 0.028| per_loss: 0.448 | a_loss: 0.533
Train: Epoch [1498/3000], Step [60/158]| g_loss: 0.745| d_loss: 0.592| gp_loss: 0.053| r_loss: 0.071| p_loss: 0.111| v_loss: 0.026| per_loss: 0.458 | a_loss: 0.548
Train: Epoch [1498/3000], Step [90/158]| g_loss: 0.730| d_loss: 0.609| gp_loss: 0.058| r_loss: 0.073| p_loss: 0.112| v_loss: 0.027| per_loss: 0.453 | a_loss: 0.529
Train: Epoch [1498/3000], Step [120/158]| g_loss: 0.761| d_loss: 0.532| gp_loss: 0.058| r_loss: 0.069| p_loss: 0.106| v_loss: 0.025| per_loss: 0.447 | a_loss: 0.569
Train: Epoch [1498/3000], Step [150/158]| g_loss: 0.731| d_loss: 0.632| gp_loss: 0.058| r_loss: 0.073| p_loss: 0.110| v_loss: 0.025| per_loss: 0.462 | a_loss: 0.531
Train: Epoch [1499/3000], Step [30/158]| g_loss: 0.794| d_loss: 0.754| gp_loss: 0.186| r_loss: 0.077| p_loss: 0.122| v_loss: 0.027| per_loss: 0.430 | a_loss: 0.587
Train: Epoch [1499/3000], Step [60/158]| g_loss: 0.723| d_loss: 0.571| gp_loss: 0.052| r_loss: 0.072| p_loss: 0.116| v_loss: 0.028| per_loss: 0.452 | a_loss: 0.519
Train: Epoch [1499/3000], Step [90/158]| g_loss: 0.722| d_loss: 0.580| gp_loss: 0.054| r_loss: 0.073| p_loss: 0.110| v_loss: 0.026| per_loss: 0.432 | a_loss: 0.525
Train: Epoch [1499/3000], Step [120/158]| g_loss: 0.760| d_loss: 0.598| gp_loss: 0.055| r_loss: 0.072| p_loss: 0.112| v_loss: 0.027| per_loss: 0.468 | a_loss: 0.559
Train: Epoch [1499/3000], Step [150/158]| g_loss: 0.740| d_loss: 0.600| gp_loss: 0.057| r_loss: 0.070| p_loss: 0.105| v_loss: 0.025| per_loss: 0.473 | a_loss: 0.545
Train: Epoch [1500/3000], Step [30/158]| g_loss: 0.720| d_loss: 0.691| gp_loss: 0.116| r_loss: 0.070| p_loss: 0.101| v_loss: 0.025| per_loss: 0.452 | a_loss: 0.530
Train: Epoch [1500/3000], Step [60/158]| g_loss: 0.656| d_loss: 0.695| gp_loss: 0.053| r_loss: 0.071| p_loss: 0.109| v_loss: 0.026| per_loss: 0.442 | a_loss: 0.461
Train: Epoch [1500/3000], Step [90/158]| g_loss: 0.762| d_loss: 0.546| gp_loss: 0.054| r_loss: 0.073| p_loss: 0.108| v_loss: 0.027| per_loss: 0.465 | a_loss: 0.561
Train: Epoch [1500/3000], Step [120/158]| g_loss: 0.734| d_loss: 0.565| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.106| v_loss: 0.027| per_loss: 0.435 | a_loss: 0.540
Train: Epoch [1500/3000], Step [150/158]| g_loss: 0.753| d_loss: 0.564| gp_loss: 0.061| r_loss: 0.069| p_loss: 0.109| v_loss: 0.026| per_loss: 0.425 | a_loss: 0.561
Test: Epoch [1500/3000]| g_loss: 0.668| r_loss: 0.413| p_loss: 0.301| v_loss: 0.023
Train: Epoch [1501/3000], Step [30/158]| g_loss: 0.706| d_loss: 0.652| gp_loss: 0.060| r_loss: 0.074| p_loss: 0.118| v_loss: 0.027| per_loss: 0.468 | a_loss: 0.500
Train: Epoch [1501/3000], Step [60/158]| g_loss: 0.699| d_loss: 0.670| gp_loss: 0.055| r_loss: 0.072| p_loss: 0.111| v_loss: 0.027| per_loss: 0.428 | a_loss: 0.503
Train: Epoch [1501/3000], Step [90/158]| g_loss: 0.710| d_loss: 0.637| gp_loss: 0.062| r_loss: 0.070| p_loss: 0.110| v_loss: 0.025| per_loss: 0.475 | a_loss: 0.512
Train: Epoch [1501/3000], Step [120/158]| g_loss: 0.802| d_loss: 0.522| gp_loss: 0.060| r_loss: 0.073| p_loss: 0.111| v_loss: 0.026| per_loss: 0.430 | a_loss: 0.603
Train: Epoch [1501/3000], Step [150/158]| g_loss: 0.745| d_loss: 0.566| gp_loss: 0.061| r_loss: 0.073| p_loss: 0.106| v_loss: 0.026| per_loss: 0.480 | a_loss: 0.545
Train: Epoch [1502/3000], Step [30/158]| g_loss: 0.836| d_loss: 0.635| gp_loss: 0.178| r_loss: 0.072| p_loss: 0.109| v_loss: 0.026| per_loss: 0.441 | a_loss: 0.639
Train: Epoch [1502/3000], Step [60/158]| g_loss: 0.689| d_loss: 0.666| gp_loss: 0.055| r_loss: 0.069| p_loss: 0.107| v_loss: 0.027| per_loss: 0.473 | a_loss: 0.493
Train: Epoch [1502/3000], Step [90/158]| g_loss: 0.739| d_loss: 0.578| gp_loss: 0.056| r_loss: 0.071| p_loss: 0.111| v_loss: 0.027| per_loss: 0.437 | a_loss: 0.541
Train: Epoch [1502/3000], Step [120/158]| g_loss: 0.741| d_loss: 0.631| gp_loss: 0.059| r_loss: 0.077| p_loss: 0.115| v_loss: 0.027| per_loss: 0.469 | a_loss: 0.532
Train: Epoch [1502/3000], Step [150/158]| g_loss: 0.763| d_loss: 0.544| gp_loss: 0.059| r_loss: 0.071| p_loss: 0.106| v_loss: 0.026| per_loss: 0.449 | a_loss: 0.567
Train: Epoch [1503/3000], Step [30/158]| g_loss: 0.756| d_loss: 0.672| gp_loss: 0.155| r_loss: 0.070| p_loss: 0.106| v_loss: 0.026| per_loss: 0.474 | a_loss: 0.560
Train: Epoch [1503/3000], Step [60/158]| g_loss: 0.765| d_loss: 0.591| gp_loss: 0.060| r_loss: 0.075| p_loss: 0.113| v_loss: 0.027| per_loss: 0.420 | a_loss: 0.566
Train: Epoch [1503/3000], Step [90/158]| g_loss: 0.770| d_loss: 0.534| gp_loss: 0.055| r_loss: 0.071| p_loss: 0.112| v_loss: 0.026| per_loss: 0.491 | a_loss: 0.568
Train: Epoch [1503/3000], Step [120/158]| g_loss: 0.777| d_loss: 0.600| gp_loss: 0.060| r_loss: 0.074| p_loss: 0.117| v_loss: 0.027| per_loss: 0.418 | a_loss: 0.575
Train: Epoch [1503/3000], Step [150/158]| g_loss: 0.769| d_loss: 0.580| gp_loss: 0.060| r_loss: 0.072| p_loss: 0.110| v_loss: 0.027| per_loss: 0.471 | a_loss: 0.568
Train: Epoch [1504/3000], Step [30/158]| g_loss: 0.764| d_loss: 0.690| gp_loss: 0.143| r_loss: 0.074| p_loss: 0.119| v_loss: 0.027| per_loss: 0.470 | a_loss: 0.557
Train: Epoch [1504/3000], Step [60/158]| g_loss: 0.711| d_loss: 0.677| gp_loss: 0.057| r_loss: 0.073| p_loss: 0.117| v_loss: 0.026| per_loss: 0.478 | a_loss: 0.506
Train: Epoch [1504/3000], Step [90/158]| g_loss: 0.730| d_loss: 0.549| gp_loss: 0.059| r_loss: 0.074| p_loss: 0.111| v_loss: 0.027| per_loss: 0.460 | a_loss: 0.528
Train: Epoch [1504/3000], Step [120/158]| g_loss: 0.744| d_loss: 0.579| gp_loss: 0.061| r_loss: 0.075| p_loss: 0.113| v_loss: 0.026| per_loss: 0.417 | a_loss: 0.545
Train: Epoch [1504/3000], Step [150/158]| g_loss: 0.759| d_loss: 0.601| gp_loss: 0.058| r_loss: 0.076| p_loss: 0.118| v_loss: 0.026| per_loss: 0.466 | a_loss: 0.551
Train: Epoch [1505/3000], Step [30/158]| g_loss: 0.759| d_loss: 0.719| gp_loss: 0.202| r_loss: 0.076| p_loss: 0.118| v_loss: 0.027| per_loss: 0.459 | a_loss: 0.552
Train: Epoch [1505/3000], Step [60/158]| g_loss: 0.733| d_loss: 0.641| gp_loss: 0.052| r_loss: 0.072| p_loss: 0.111| v_loss: 0.026| per_loss: 0.452 | a_loss: 0.535
Train: Epoch [1505/3000], Step [90/158]| g_loss: 0.725| d_loss: 0.583| gp_loss: 0.057| r_loss: 0.076| p_loss: 0.114| v_loss: 0.026| per_loss: 0.436 | a_loss: 0.522
Train: Epoch [1505/3000], Step [120/158]| g_loss: 0.708| d_loss: 0.617| gp_loss: 0.057| r_loss: 0.075| p_loss: 0.112| v_loss: 0.026| per_loss: 0.448 | a_loss: 0.507
Train: Epoch [1505/3000], Step [150/158]| g_loss: 0.765| d_loss: 0.543| gp_loss: 0.058| r_loss: 0.071| p_loss: 0.107| v_loss: 0.026| per_loss: 0.427 | a_loss: 0.571
Train: Epoch [1506/3000], Step [30/158]| g_loss: 0.744| d_loss: 0.661| gp_loss: 0.138| r_loss: 0.070| p_loss: 0.107| v_loss: 0.025| per_loss: 0.450 | a_loss: 0.550
Train: Epoch [1506/3000], Step [60/158]| g_loss: 0.741| d_loss: 0.609| gp_loss: 0.054| r_loss: 0.073| p_loss: 0.108| v_loss: 0.025| per_loss: 0.432 | a_loss: 0.545
Train: Epoch [1506/3000], Step [90/158]| g_loss: 0.653| d_loss: 0.690| gp_loss: 0.058| r_loss: 0.074| p_loss: 0.110| v_loss: 0.026| per_loss: 0.436 | a_loss: 0.454
Train: Epoch [1506/3000], Step [120/158]| g_loss: 0.836| d_loss: 0.527| gp_loss: 0.061| r_loss: 0.070| p_loss: 0.110| v_loss: 0.027| per_loss: 0.477 | a_loss: 0.636
Train: Epoch [1506/3000], Step [150/158]| g_loss: 0.731| d_loss: 0.567| gp_loss: 0.054| r_loss: 0.075| p_loss: 0.112| v_loss: 0.027| per_loss: 0.440 | a_loss: 0.530
Train: Epoch [1507/3000], Step [30/158]| g_loss: 0.719| d_loss: 0.719| gp_loss: 0.140| r_loss: 0.073| p_loss: 0.107| v_loss: 0.026| per_loss: 0.436 | a_loss: 0.523
Train: Epoch [1507/3000], Step [60/158]| g_loss: 0.705| d_loss: 0.655| gp_loss: 0.059| r_loss: 0.072| p_loss: 0.116| v_loss: 0.025| per_loss: 0.444 | a_loss: 0.505
Train: Epoch [1507/3000], Step [90/158]| g_loss: 0.761| d_loss: 0.585| gp_loss: 0.062| r_loss: 0.075| p_loss: 0.119| v_loss: 0.027| per_loss: 0.448 | a_loss: 0.555
Train: Epoch [1507/3000], Step [120/158]| g_loss: 0.829| d_loss: 0.552| gp_loss: 0.061| r_loss: 0.076| p_loss: 0.124| v_loss: 0.027| per_loss: 0.436 | a_loss: 0.620
Train: Epoch [1507/3000], Step [150/158]| g_loss: 0.740| d_loss: 0.646| gp_loss: 0.056| r_loss: 0.072| p_loss: 0.112| v_loss: 0.025| per_loss: 0.471 | a_loss: 0.539
Train: Epoch [1508/3000], Step [30/158]| g_loss: 0.786| d_loss: 0.653| gp_loss: 0.151| r_loss: 0.077| p_loss: 0.119| v_loss: 0.025| per_loss: 0.449 | a_loss: 0.579
Train: Epoch [1508/3000], Step [60/158]| g_loss: 0.763| d_loss: 0.528| gp_loss: 0.051| r_loss: 0.071| p_loss: 0.103| v_loss: 0.026| per_loss: 0.475 | a_loss: 0.567
Train: Epoch [1508/3000], Step [90/158]| g_loss: 0.771| d_loss: 0.588| gp_loss: 0.054| r_loss: 0.072| p_loss: 0.109| v_loss: 0.027| per_loss: 0.444 | a_loss: 0.573
Train: Epoch [1508/3000], Step [120/158]| g_loss: 0.673| d_loss: 0.654| gp_loss: 0.058| r_loss: 0.072| p_loss: 0.110| v_loss: 0.027| per_loss: 0.425 | a_loss: 0.476
Train: Epoch [1508/3000], Step [150/158]| g_loss: 0.746| d_loss: 0.635| gp_loss: 0.057| r_loss: 0.072| p_loss: 0.109| v_loss: 0.026| per_loss: 0.433 | a_loss: 0.550
Train: Epoch [1509/3000], Step [30/158]| g_loss: 0.767| d_loss: 0.627| gp_loss: 0.130| r_loss: 0.072| p_loss: 0.110| v_loss: 0.026| per_loss: 0.453 | a_loss: 0.568
Train: Epoch [1509/3000], Step [60/158]| g_loss: 0.708| d_loss: 0.628| gp_loss: 0.059| r_loss: 0.071| p_loss: 0.106| v_loss: 0.025| per_loss: 0.453 | a_loss: 0.514
Train: Epoch [1509/3000], Step [90/158]| g_loss: 0.691| d_loss: 0.649| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.111| v_loss: 0.026| per_loss: 0.409 | a_loss: 0.498
Train: Epoch [1509/3000], Step [120/158]| g_loss: 0.756| d_loss: 0.574| gp_loss: 0.061| r_loss: 0.071| p_loss: 0.111| v_loss: 0.027| per_loss: 0.447 | a_loss: 0.558
Train: Epoch [1509/3000], Step [150/158]| g_loss: 0.758| d_loss: 0.534| gp_loss: 0.058| r_loss: 0.073| p_loss: 0.113| v_loss: 0.027| per_loss: 0.428 | a_loss: 0.560
Train: Epoch [1510/3000], Step [30/158]| g_loss: 0.765| d_loss: 0.653| gp_loss: 0.132| r_loss: 0.071| p_loss: 0.107| v_loss: 0.027| per_loss: 0.461 | a_loss: 0.568
Train: Epoch [1510/3000], Step [60/158]| g_loss: 0.666| d_loss: 0.723| gp_loss: 0.056| r_loss: 0.073| p_loss: 0.110| v_loss: 0.027| per_loss: 0.457 | a_loss: 0.466
Train: Epoch [1510/3000], Step [90/158]| g_loss: 0.731| d_loss: 0.652| gp_loss: 0.060| r_loss: 0.069| p_loss: 0.109| v_loss: 0.025| per_loss: 0.428 | a_loss: 0.539
Train: Epoch [1510/3000], Step [120/158]| g_loss: 0.707| d_loss: 0.609| gp_loss: 0.058| r_loss: 0.074| p_loss: 0.115| v_loss: 0.026| per_loss: 0.460 | a_loss: 0.504
Train: Epoch [1510/3000], Step [150/158]| g_loss: 0.795| d_loss: 0.486| gp_loss: 0.061| r_loss: 0.072| p_loss: 0.112| v_loss: 0.027| per_loss: 0.432 | a_loss: 0.597
Train: Epoch [1511/3000], Step [30/158]| g_loss: 0.815| d_loss: 0.590| gp_loss: 0.142| r_loss: 0.071| p_loss: 0.112| v_loss: 0.026| per_loss: 0.429 | a_loss: 0.619
Train: Epoch [1511/3000], Step [60/158]| g_loss: 0.808| d_loss: 0.508| gp_loss: 0.055| r_loss: 0.070| p_loss: 0.108| v_loss: 0.027| per_loss: 0.445 | a_loss: 0.612
Train: Epoch [1511/3000], Step [90/158]| g_loss: 0.785| d_loss: 0.580| gp_loss: 0.057| r_loss: 0.070| p_loss: 0.107| v_loss: 0.027| per_loss: 0.471 | a_loss: 0.588
Train: Epoch [1511/3000], Step [120/158]| g_loss: 0.694| d_loss: 0.668| gp_loss: 0.057| r_loss: 0.073| p_loss: 0.113| v_loss: 0.027| per_loss: 0.455 | a_loss: 0.492
Train: Epoch [1511/3000], Step [150/158]| g_loss: 0.727| d_loss: 0.664| gp_loss: 0.060| r_loss: 0.073| p_loss: 0.118| v_loss: 0.027| per_loss: 0.431 | a_loss: 0.524
Train: Epoch [1512/3000], Step [30/158]| g_loss: 0.709| d_loss: 0.690| gp_loss: 0.129| r_loss: 0.075| p_loss: 0.113| v_loss: 0.028| per_loss: 0.442 | a_loss: 0.505
Train: Epoch [1512/3000], Step [60/158]| g_loss: 0.732| d_loss: 0.618| gp_loss: 0.057| r_loss: 0.075| p_loss: 0.114| v_loss: 0.026| per_loss: 0.432 | a_loss: 0.530
Train: Epoch [1512/3000], Step [90/158]| g_loss: 0.751| d_loss: 0.565| gp_loss: 0.059| r_loss: 0.069| p_loss: 0.112| v_loss: 0.026| per_loss: 0.447 | a_loss: 0.554
Train: Epoch [1512/3000], Step [120/158]| g_loss: 0.800| d_loss: 0.516| gp_loss: 0.058| r_loss: 0.072| p_loss: 0.108| v_loss: 0.026| per_loss: 0.451 | a_loss: 0.604
Train: Epoch [1512/3000], Step [150/158]| g_loss: 0.715| d_loss: 0.661| gp_loss: 0.061| r_loss: 0.072| p_loss: 0.116| v_loss: 0.027| per_loss: 0.451 | a_loss: 0.512
Train: Epoch [1513/3000], Step [30/158]| g_loss: 0.701| d_loss: 0.818| gp_loss: 0.215| r_loss: 0.070| p_loss: 0.108| v_loss: 0.026| per_loss: 0.436 | a_loss: 0.507
Train: Epoch [1513/3000], Step [60/158]| g_loss: 0.719| d_loss: 0.664| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.107| v_loss: 0.027| per_loss: 0.431 | a_loss: 0.525
Train: Epoch [1513/3000], Step [90/158]| g_loss: 0.731| d_loss: 0.541| gp_loss: 0.053| r_loss: 0.071| p_loss: 0.112| v_loss: 0.027| per_loss: 0.460 | a_loss: 0.532
Train: Epoch [1513/3000], Step [120/158]| g_loss: 0.754| d_loss: 0.544| gp_loss: 0.060| r_loss: 0.070| p_loss: 0.106| v_loss: 0.027| per_loss: 0.434 | a_loss: 0.560
Train: Epoch [1513/3000], Step [150/158]| g_loss: 0.789| d_loss: 0.571| gp_loss: 0.056| r_loss: 0.071| p_loss: 0.106| v_loss: 0.026| per_loss: 0.455 | a_loss: 0.593
Train: Epoch [1514/3000], Step [30/158]| g_loss: 0.742| d_loss: 0.658| gp_loss: 0.135| r_loss: 0.073| p_loss: 0.110| v_loss: 0.027| per_loss: 0.437 | a_loss: 0.543
Train: Epoch [1514/3000], Step [60/158]| g_loss: 0.779| d_loss: 0.504| gp_loss: 0.056| r_loss: 0.069| p_loss: 0.098| v_loss: 0.027| per_loss: 0.460 | a_loss: 0.587
Train: Epoch [1514/3000], Step [90/158]| g_loss: 0.729| d_loss: 0.592| gp_loss: 0.053| r_loss: 0.070| p_loss: 0.105| v_loss: 0.027| per_loss: 0.446 | a_loss: 0.535
Train: Epoch [1514/3000], Step [120/158]| g_loss: 0.701| d_loss: 0.653| gp_loss: 0.058| r_loss: 0.070| p_loss: 0.108| v_loss: 0.027| per_loss: 0.452 | a_loss: 0.505
Train: Epoch [1514/3000], Step [150/158]| g_loss: 0.751| d_loss: 0.639| gp_loss: 0.059| r_loss: 0.071| p_loss: 0.114| v_loss: 0.026| per_loss: 0.453 | a_loss: 0.551
Train: Epoch [1515/3000], Step [30/158]| g_loss: 0.710| d_loss: 0.716| gp_loss: 0.156| r_loss: 0.073| p_loss: 0.113| v_loss: 0.026| per_loss: 0.446 | a_loss: 0.510
Train: Epoch [1515/3000], Step [60/158]| g_loss: 0.730| d_loss: 0.597| gp_loss: 0.055| r_loss: 0.069| p_loss: 0.108| v_loss: 0.025| per_loss: 0.466 | a_loss: 0.535
Train: Epoch [1515/3000], Step [90/158]| g_loss: 0.775| d_loss: 0.529| gp_loss: 0.057| r_loss: 0.069| p_loss: 0.107| v_loss: 0.027| per_loss: 0.460 | a_loss: 0.579
Train: Epoch [1515/3000], Step [120/158]| g_loss: 0.768| d_loss: 0.562| gp_loss: 0.061| r_loss: 0.072| p_loss: 0.106| v_loss: 0.027| per_loss: 0.447 | a_loss: 0.571
Train: Epoch [1515/3000], Step [150/158]| g_loss: 0.734| d_loss: 0.592| gp_loss: 0.062| r_loss: 0.070| p_loss: 0.105| v_loss: 0.027| per_loss: 0.456 | a_loss: 0.539
Train: Epoch [1516/3000], Step [30/158]| g_loss: 0.738| d_loss: 0.742| gp_loss: 0.177| r_loss: 0.073| p_loss: 0.116| v_loss: 0.027| per_loss: 0.453 | a_loss: 0.535
Train: Epoch [1516/3000], Step [60/158]| g_loss: 0.771| d_loss: 0.632| gp_loss: 0.054| r_loss: 0.077| p_loss: 0.120| v_loss: 0.026| per_loss: 0.466 | a_loss: 0.562
Train: Epoch [1516/3000], Step [90/158]| g_loss: 0.723| d_loss: 0.576| gp_loss: 0.056| r_loss: 0.072| p_loss: 0.112| v_loss: 0.027| per_loss: 0.432 | a_loss: 0.524
Train: Epoch [1516/3000], Step [120/158]| g_loss: 0.802| d_loss: 0.565| gp_loss: 0.058| r_loss: 0.071| p_loss: 0.111| v_loss: 0.028| per_loss: 0.470 | a_loss: 0.601
Train: Epoch [1516/3000], Step [150/158]| g_loss: 0.722| d_loss: 0.613| gp_loss: 0.058| r_loss: 0.071| p_loss: 0.110| v_loss: 0.027| per_loss: 0.435 | a_loss: 0.525
Train: Epoch [1517/3000], Step [30/158]| g_loss: 0.739| d_loss: 0.696| gp_loss: 0.119| r_loss: 0.078| p_loss: 0.113| v_loss: 0.027| per_loss: 0.438 | a_loss: 0.534
Train: Epoch [1517/3000], Step [60/158]| g_loss: 0.767| d_loss: 0.531| gp_loss: 0.056| r_loss: 0.069| p_loss: 0.107| v_loss: 0.027| per_loss: 0.472 | a_loss: 0.570
Train: Epoch [1517/3000], Step [90/158]| g_loss: 0.761| d_loss: 0.577| gp_loss: 0.056| r_loss: 0.069| p_loss: 0.105| v_loss: 0.027| per_loss: 0.420 | a_loss: 0.570
Train: Epoch [1517/3000], Step [120/158]| g_loss: 0.734| d_loss: 0.616| gp_loss: 0.059| r_loss: 0.078| p_loss: 0.114| v_loss: 0.027| per_loss: 0.454 | a_loss: 0.526
Train: Epoch [1517/3000], Step [150/158]| g_loss: 0.727| d_loss: 0.685| gp_loss: 0.057| r_loss: 0.074| p_loss: 0.116| v_loss: 0.027| per_loss: 0.447 | a_loss: 0.524
Train: Epoch [1518/3000], Step [30/158]| g_loss: 0.763| d_loss: 0.644| gp_loss: 0.188| r_loss: 0.076| p_loss: 0.119| v_loss: 0.027| per_loss: 0.446 | a_loss: 0.556
Train: Epoch [1518/3000], Step [60/158]| g_loss: 0.769| d_loss: 0.636| gp_loss: 0.050| r_loss: 0.081| p_loss: 0.119| v_loss: 0.027| per_loss: 0.436 | a_loss: 0.558
Train: Epoch [1518/3000], Step [90/158]| g_loss: 0.717| d_loss: 0.597| gp_loss: 0.059| r_loss: 0.079| p_loss: 0.117| v_loss: 0.027| per_loss: 0.428 | a_loss: 0.509
Train: Epoch [1518/3000], Step [120/158]| g_loss: 0.724| d_loss: 0.619| gp_loss: 0.058| r_loss: 0.072| p_loss: 0.112| v_loss: 0.026| per_loss: 0.439 | a_loss: 0.526
Train: Epoch [1518/3000], Step [150/158]| g_loss: 0.729| d_loss: 0.636| gp_loss: 0.059| r_loss: 0.073| p_loss: 0.114| v_loss: 0.028| per_loss: 0.491 | a_loss: 0.521
Train: Epoch [1519/3000], Step [30/158]| g_loss: 0.781| d_loss: 0.662| gp_loss: 0.145| r_loss: 0.072| p_loss: 0.114| v_loss: 0.027| per_loss: 0.471 | a_loss: 0.577
Train: Epoch [1519/3000], Step [60/158]| g_loss: 0.728| d_loss: 0.572| gp_loss: 0.060| r_loss: 0.072| p_loss: 0.109| v_loss: 0.028| per_loss: 0.441 | a_loss: 0.530
Train: Epoch [1519/3000], Step [90/158]| g_loss: 0.756| d_loss: 0.570| gp_loss: 0.058| r_loss: 0.070| p_loss: 0.110| v_loss: 0.026| per_loss: 0.472 | a_loss: 0.558
Train: Epoch [1519/3000], Step [120/158]| g_loss: 0.756| d_loss: 0.611| gp_loss: 0.061| r_loss: 0.072| p_loss: 0.112| v_loss: 0.026| per_loss: 0.474 | a_loss: 0.556
Train: Epoch [1519/3000], Step [150/158]| g_loss: 0.720| d_loss: 0.589| gp_loss: 0.061| r_loss: 0.072| p_loss: 0.110| v_loss: 0.027| per_loss: 0.444 | a_loss: 0.522
Train: Epoch [1520/3000], Step [30/158]| g_loss: 0.717| d_loss: 0.739| gp_loss: 0.143| r_loss: 0.073| p_loss: 0.113| v_loss: 0.027| per_loss: 0.429 | a_loss: 0.518
Train: Epoch [1520/3000], Step [60/158]| g_loss: 0.733| d_loss: 0.616| gp_loss: 0.058| r_loss: 0.073| p_loss: 0.115| v_loss: 0.027| per_loss: 0.478 | a_loss: 0.528
Train: Epoch [1520/3000], Step [90/158]| g_loss: 0.739| d_loss: 0.699| gp_loss: 0.061| r_loss: 0.076| p_loss: 0.122| v_loss: 0.027| per_loss: 0.450 | a_loss: 0.529
Train: Epoch [1520/3000], Step [120/158]| g_loss: 0.773| d_loss: 0.605| gp_loss: 0.062| r_loss: 0.074| p_loss: 0.120| v_loss: 0.028| per_loss: 0.463 | a_loss: 0.566
Train: Epoch [1520/3000], Step [150/158]| g_loss: 0.786| d_loss: 0.543| gp_loss: 0.059| r_loss: 0.072| p_loss: 0.115| v_loss: 0.028| per_loss: 0.451 | a_loss: 0.583
Train: Epoch [1521/3000], Step [30/158]| g_loss: 0.799| d_loss: 0.648| gp_loss: 0.141| r_loss: 0.072| p_loss: 0.113| v_loss: 0.028| per_loss: 0.471 | a_loss: 0.596
Train: Epoch [1521/3000], Step [60/158]| g_loss: 0.758| d_loss: 0.562| gp_loss: 0.058| r_loss: 0.071| p_loss: 0.109| v_loss: 0.026| per_loss: 0.421 | a_loss: 0.564
Train: Epoch [1521/3000], Step [90/158]| g_loss: 0.770| d_loss: 0.589| gp_loss: 0.055| r_loss: 0.072| p_loss: 0.108| v_loss: 0.026| per_loss: 0.476 | a_loss: 0.570
Train: Epoch [1521/3000], Step [120/158]| g_loss: 0.688| d_loss: 0.681| gp_loss: 0.057| r_loss: 0.073| p_loss: 0.116| v_loss: 0.027| per_loss: 0.438 | a_loss: 0.487
Train: Epoch [1521/3000], Step [150/158]| g_loss: 0.737| d_loss: 0.610| gp_loss: 0.061| r_loss: 0.073| p_loss: 0.113| v_loss: 0.026| per_loss: 0.475 | a_loss: 0.534
Train: Epoch [1522/3000], Step [30/158]| g_loss: 0.710| d_loss: 0.800| gp_loss: 0.224| r_loss: 0.073| p_loss: 0.112| v_loss: 0.027| per_loss: 0.457 | a_loss: 0.508
Train: Epoch [1522/3000], Step [60/158]| g_loss: 0.729| d_loss: 0.623| gp_loss: 0.051| r_loss: 0.073| p_loss: 0.116| v_loss: 0.027| per_loss: 0.457 | a_loss: 0.525
Train: Epoch [1522/3000], Step [90/158]| g_loss: 0.673| d_loss: 0.655| gp_loss: 0.051| r_loss: 0.069| p_loss: 0.108| v_loss: 0.026| per_loss: 0.451 | a_loss: 0.478
Train: Epoch [1522/3000], Step [120/158]| g_loss: 0.809| d_loss: 0.546| gp_loss: 0.058| r_loss: 0.073| p_loss: 0.109| v_loss: 0.027| per_loss: 0.471 | a_loss: 0.608
Train: Epoch [1522/3000], Step [150/158]| g_loss: 0.781| d_loss: 0.492| gp_loss: 0.058| r_loss: 0.069| p_loss: 0.104| v_loss: 0.026| per_loss: 0.423 | a_loss: 0.592
Train: Epoch [1523/3000], Step [30/158]| g_loss: 0.734| d_loss: 0.690| gp_loss: 0.128| r_loss: 0.070| p_loss: 0.111| v_loss: 0.025| per_loss: 0.435 | a_loss: 0.540
Train: Epoch [1523/3000], Step [60/158]| g_loss: 0.770| d_loss: 0.519| gp_loss: 0.054| r_loss: 0.074| p_loss: 0.112| v_loss: 0.027| per_loss: 0.455 | a_loss: 0.568
Train: Epoch [1523/3000], Step [90/158]| g_loss: 0.753| d_loss: 0.624| gp_loss: 0.055| r_loss: 0.070| p_loss: 0.108| v_loss: 0.026| per_loss: 0.478 | a_loss: 0.555
Train: Epoch [1523/3000], Step [120/158]| g_loss: 0.735| d_loss: 0.652| gp_loss: 0.059| r_loss: 0.071| p_loss: 0.111| v_loss: 0.026| per_loss: 0.436 | a_loss: 0.539
Train: Epoch [1523/3000], Step [150/158]| g_loss: 0.784| d_loss: 0.575| gp_loss: 0.060| r_loss: 0.072| p_loss: 0.117| v_loss: 0.027| per_loss: 0.460 | a_loss: 0.581
Train: Epoch [1524/3000], Step [30/158]| g_loss: 0.754| d_loss: 0.629| gp_loss: 0.154| r_loss: 0.077| p_loss: 0.115| v_loss: 0.027| per_loss: 0.464 | a_loss: 0.545
Train: Epoch [1524/3000], Step [60/158]| g_loss: 0.835| d_loss: 0.537| gp_loss: 0.057| r_loss: 0.077| p_loss: 0.121| v_loss: 0.027| per_loss: 0.460 | a_loss: 0.625
Train: Epoch [1524/3000], Step [90/158]| g_loss: 0.784| d_loss: 0.625| gp_loss: 0.057| r_loss: 0.070| p_loss: 0.115| v_loss: 0.026| per_loss: 0.433 | a_loss: 0.588
Train: Epoch [1524/3000], Step [120/158]| g_loss: 0.729| d_loss: 0.674| gp_loss: 0.058| r_loss: 0.073| p_loss: 0.122| v_loss: 0.026| per_loss: 0.439 | a_loss: 0.525
Train: Epoch [1524/3000], Step [150/158]| g_loss: 0.720| d_loss: 0.701| gp_loss: 0.053| r_loss: 0.073| p_loss: 0.118| v_loss: 0.027| per_loss: 0.490 | a_loss: 0.512
Train: Epoch [1525/3000], Step [30/158]| g_loss: 0.765| d_loss: 0.593| gp_loss: 0.159| r_loss: 0.073| p_loss: 0.115| v_loss: 0.027| per_loss: 0.436 | a_loss: 0.564
Train: Epoch [1525/3000], Step [60/158]| g_loss: 0.701| d_loss: 0.702| gp_loss: 0.050| r_loss: 0.074| p_loss: 0.119| v_loss: 0.026| per_loss: 0.439 | a_loss: 0.498
Train: Epoch [1525/3000], Step [90/158]| g_loss: 0.729| d_loss: 0.602| gp_loss: 0.057| r_loss: 0.072| p_loss: 0.108| v_loss: 0.026| per_loss: 0.461 | a_loss: 0.531
Train: Epoch [1525/3000], Step [120/158]| g_loss: 0.738| d_loss: 0.640| gp_loss: 0.054| r_loss: 0.073| p_loss: 0.113| v_loss: 0.026| per_loss: 0.449 | a_loss: 0.538
Train: Epoch [1525/3000], Step [150/158]| g_loss: 0.738| d_loss: 0.619| gp_loss: 0.061| r_loss: 0.073| p_loss: 0.113| v_loss: 0.027| per_loss: 0.462 | a_loss: 0.535
Train: Epoch [1526/3000], Step [30/158]| g_loss: 0.710| d_loss: 0.687| gp_loss: 0.122| r_loss: 0.072| p_loss: 0.109| v_loss: 0.026| per_loss: 0.440 | a_loss: 0.513
Train: Epoch [1526/3000], Step [60/158]| g_loss: 0.770| d_loss: 0.535| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.107| v_loss: 0.026| per_loss: 0.427 | a_loss: 0.576
Train: Epoch [1526/3000], Step [90/158]| g_loss: 0.761| d_loss: 0.548| gp_loss: 0.052| r_loss: 0.072| p_loss: 0.109| v_loss: 0.026| per_loss: 0.464 | a_loss: 0.563
Train: Epoch [1526/3000], Step [120/158]| g_loss: 0.756| d_loss: 0.628| gp_loss: 0.057| r_loss: 0.073| p_loss: 0.112| v_loss: 0.027| per_loss: 0.459 | a_loss: 0.554
Train: Epoch [1526/3000], Step [150/158]| g_loss: 0.705| d_loss: 0.616| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.107| v_loss: 0.025| per_loss: 0.464 | a_loss: 0.513
Train: Epoch [1527/3000], Step [30/158]| g_loss: 0.769| d_loss: 0.737| gp_loss: 0.250| r_loss: 0.070| p_loss: 0.107| v_loss: 0.026| per_loss: 0.493 | a_loss: 0.571
Train: Epoch [1527/3000], Step [60/158]| g_loss: 0.722| d_loss: 0.675| gp_loss: 0.052| r_loss: 0.077| p_loss: 0.118| v_loss: 0.027| per_loss: 0.455 | a_loss: 0.512
Train: Epoch [1527/3000], Step [90/158]| g_loss: 0.709| d_loss: 0.685| gp_loss: 0.056| r_loss: 0.076| p_loss: 0.114| v_loss: 0.026| per_loss: 0.461 | a_loss: 0.503
Train: Epoch [1527/3000], Step [120/158]| g_loss: 0.829| d_loss: 0.516| gp_loss: 0.055| r_loss: 0.070| p_loss: 0.113| v_loss: 0.026| per_loss: 0.448 | a_loss: 0.632
Train: Epoch [1527/3000], Step [150/158]| g_loss: 0.743| d_loss: 0.601| gp_loss: 0.055| r_loss: 0.074| p_loss: 0.110| v_loss: 0.027| per_loss: 0.438 | a_loss: 0.544
Train: Epoch [1528/3000], Step [30/158]| g_loss: 0.764| d_loss: 0.625| gp_loss: 0.147| r_loss: 0.070| p_loss: 0.107| v_loss: 0.025| per_loss: 0.435 | a_loss: 0.572
Train: Epoch [1528/3000], Step [60/158]| g_loss: 0.742| d_loss: 0.541| gp_loss: 0.052| r_loss: 0.068| p_loss: 0.105| v_loss: 0.025| per_loss: 0.446 | a_loss: 0.552
Train: Epoch [1528/3000], Step [90/158]| g_loss: 0.727| d_loss: 0.605| gp_loss: 0.051| r_loss: 0.070| p_loss: 0.104| v_loss: 0.026| per_loss: 0.453 | a_loss: 0.534
Train: Epoch [1528/3000], Step [120/158]| g_loss: 0.718| d_loss: 0.691| gp_loss: 0.055| r_loss: 0.071| p_loss: 0.109| v_loss: 0.025| per_loss: 0.449 | a_loss: 0.522
Train: Epoch [1528/3000], Step [150/158]| g_loss: 0.790| d_loss: 0.507| gp_loss: 0.054| r_loss: 0.072| p_loss: 0.109| v_loss: 0.026| per_loss: 0.484 | a_loss: 0.588
Train: Epoch [1529/3000], Step [30/158]| g_loss: 0.770| d_loss: 0.613| gp_loss: 0.123| r_loss: 0.073| p_loss: 0.111| v_loss: 0.027| per_loss: 0.454 | a_loss: 0.569
Train: Epoch [1529/3000], Step [60/158]| g_loss: 0.751| d_loss: 0.553| gp_loss: 0.053| r_loss: 0.071| p_loss: 0.105| v_loss: 0.026| per_loss: 0.442 | a_loss: 0.557
Train: Epoch [1529/3000], Step [90/158]| g_loss: 0.797| d_loss: 0.557| gp_loss: 0.055| r_loss: 0.070| p_loss: 0.106| v_loss: 0.026| per_loss: 0.447 | a_loss: 0.603
Train: Epoch [1529/3000], Step [120/158]| g_loss: 0.734| d_loss: 0.594| gp_loss: 0.055| r_loss: 0.072| p_loss: 0.108| v_loss: 0.026| per_loss: 0.473 | a_loss: 0.535
Train: Epoch [1529/3000], Step [150/158]| g_loss: 0.739| d_loss: 0.625| gp_loss: 0.058| r_loss: 0.073| p_loss: 0.113| v_loss: 0.026| per_loss: 0.462 | a_loss: 0.538
Train: Epoch [1530/3000], Step [30/158]| g_loss: 0.795| d_loss: 0.616| gp_loss: 0.164| r_loss: 0.070| p_loss: 0.106| v_loss: 0.026| per_loss: 0.471 | a_loss: 0.599
Train: Epoch [1530/3000], Step [60/158]| g_loss: 0.786| d_loss: 0.512| gp_loss: 0.059| r_loss: 0.073| p_loss: 0.107| v_loss: 0.026| per_loss: 0.469 | a_loss: 0.587
Train: Epoch [1530/3000], Step [90/158]| g_loss: 0.801| d_loss: 0.515| gp_loss: 0.060| r_loss: 0.073| p_loss: 0.114| v_loss: 0.027| per_loss: 0.468 | a_loss: 0.597
Train: Epoch [1530/3000], Step [120/158]| g_loss: 0.812| d_loss: 0.512| gp_loss: 0.055| r_loss: 0.072| p_loss: 0.107| v_loss: 0.026| per_loss: 0.468 | a_loss: 0.614
Train: Epoch [1530/3000], Step [150/158]| g_loss: 0.681| d_loss: 0.771| gp_loss: 0.058| r_loss: 0.073| p_loss: 0.113| v_loss: 0.026| per_loss: 0.448 | a_loss: 0.481
Train: Epoch [1531/3000], Step [30/158]| g_loss: 0.752| d_loss: 0.721| gp_loss: 0.187| r_loss: 0.075| p_loss: 0.124| v_loss: 0.027| per_loss: 0.479 | a_loss: 0.540
Train: Epoch [1531/3000], Step [60/158]| g_loss: 0.746| d_loss: 0.604| gp_loss: 0.052| r_loss: 0.072| p_loss: 0.113| v_loss: 0.025| per_loss: 0.482 | a_loss: 0.544
Train: Epoch [1531/3000], Step [90/158]| g_loss: 0.739| d_loss: 0.589| gp_loss: 0.059| r_loss: 0.073| p_loss: 0.114| v_loss: 0.025| per_loss: 0.449 | a_loss: 0.539
Train: Epoch [1531/3000], Step [120/158]| g_loss: 0.824| d_loss: 0.515| gp_loss: 0.058| r_loss: 0.075| p_loss: 0.116| v_loss: 0.026| per_loss: 0.491 | a_loss: 0.615
Train: Epoch [1531/3000], Step [150/158]| g_loss: 0.772| d_loss: 0.576| gp_loss: 0.061| r_loss: 0.073| p_loss: 0.116| v_loss: 0.026| per_loss: 0.488 | a_loss: 0.566
Train: Epoch [1532/3000], Step [30/158]| g_loss: 0.706| d_loss: 0.752| gp_loss: 0.134| r_loss: 0.074| p_loss: 0.115| v_loss: 0.027| per_loss: 0.451 | a_loss: 0.502
Train: Epoch [1532/3000], Step [60/158]| g_loss: 0.744| d_loss: 0.590| gp_loss: 0.054| r_loss: 0.072| p_loss: 0.114| v_loss: 0.027| per_loss: 0.476 | a_loss: 0.541
Train: Epoch [1532/3000], Step [90/158]| g_loss: 0.779| d_loss: 0.599| gp_loss: 0.058| r_loss: 0.073| p_loss: 0.113| v_loss: 0.026| per_loss: 0.481 | a_loss: 0.575
Train: Epoch [1532/3000], Step [120/158]| g_loss: 0.752| d_loss: 0.529| gp_loss: 0.061| r_loss: 0.075| p_loss: 0.117| v_loss: 0.025| per_loss: 0.453 | a_loss: 0.549
Train: Epoch [1532/3000], Step [150/158]| g_loss: 0.783| d_loss: 0.543| gp_loss: 0.060| r_loss: 0.074| p_loss: 0.113| v_loss: 0.025| per_loss: 0.441 | a_loss: 0.584
Train: Epoch [1533/3000], Step [30/158]| g_loss: 0.794| d_loss: 0.592| gp_loss: 0.125| r_loss: 0.074| p_loss: 0.115| v_loss: 0.026| per_loss: 0.475 | a_loss: 0.589
Train: Epoch [1533/3000], Step [60/158]| g_loss: 0.766| d_loss: 0.612| gp_loss: 0.055| r_loss: 0.071| p_loss: 0.114| v_loss: 0.026| per_loss: 0.442 | a_loss: 0.567
Train: Epoch [1533/3000], Step [90/158]| g_loss: 0.719| d_loss: 0.677| gp_loss: 0.058| r_loss: 0.075| p_loss: 0.119| v_loss: 0.026| per_loss: 0.489 | a_loss: 0.509
Train: Epoch [1533/3000], Step [120/158]| g_loss: 0.803| d_loss: 0.587| gp_loss: 0.062| r_loss: 0.082| p_loss: 0.129| v_loss: 0.028| per_loss: 0.522 | a_loss: 0.576
Train: Epoch [1533/3000], Step [150/158]| g_loss: 0.747| d_loss: 0.562| gp_loss: 0.064| r_loss: 0.074| p_loss: 0.119| v_loss: 0.026| per_loss: 0.505 | a_loss: 0.536
Train: Epoch [1534/3000], Step [30/158]| g_loss: 0.767| d_loss: 0.680| gp_loss: 0.159| r_loss: 0.077| p_loss: 0.117| v_loss: 0.027| per_loss: 0.454 | a_loss: 0.559
Train: Epoch [1534/3000], Step [60/158]| g_loss: 0.750| d_loss: 0.610| gp_loss: 0.058| r_loss: 0.074| p_loss: 0.116| v_loss: 0.026| per_loss: 0.440 | a_loss: 0.548
Train: Epoch [1534/3000], Step [90/158]| g_loss: 0.762| d_loss: 0.634| gp_loss: 0.059| r_loss: 0.073| p_loss: 0.115| v_loss: 0.027| per_loss: 0.468 | a_loss: 0.558
Train: Epoch [1534/3000], Step [120/158]| g_loss: 0.765| d_loss: 0.577| gp_loss: 0.061| r_loss: 0.072| p_loss: 0.112| v_loss: 0.026| per_loss: 0.495 | a_loss: 0.561
Train: Epoch [1534/3000], Step [150/158]| g_loss: 0.718| d_loss: 0.668| gp_loss: 0.060| r_loss: 0.075| p_loss: 0.118| v_loss: 0.027| per_loss: 0.447 | a_loss: 0.512
Train: Epoch [1535/3000], Step [30/158]| g_loss: 0.763| d_loss: 0.644| gp_loss: 0.173| r_loss: 0.072| p_loss: 0.111| v_loss: 0.027| per_loss: 0.472 | a_loss: 0.561
Train: Epoch [1535/3000], Step [60/158]| g_loss: 0.769| d_loss: 0.563| gp_loss: 0.056| r_loss: 0.071| p_loss: 0.109| v_loss: 0.027| per_loss: 0.483 | a_loss: 0.568
Train: Epoch [1535/3000], Step [90/158]| g_loss: 0.726| d_loss: 0.649| gp_loss: 0.058| r_loss: 0.071| p_loss: 0.112| v_loss: 0.026| per_loss: 0.504 | a_loss: 0.523
Train: Epoch [1535/3000], Step [120/158]| g_loss: 0.793| d_loss: 0.519| gp_loss: 0.063| r_loss: 0.074| p_loss: 0.121| v_loss: 0.027| per_loss: 0.451 | a_loss: 0.586
Train: Epoch [1535/3000], Step [150/158]| g_loss: 0.725| d_loss: 0.673| gp_loss: 0.058| r_loss: 0.076| p_loss: 0.119| v_loss: 0.025| per_loss: 0.449 | a_loss: 0.519
Train: Epoch [1536/3000], Step [30/158]| g_loss: 0.835| d_loss: 0.664| gp_loss: 0.085| r_loss: 0.134| p_loss: 0.187| v_loss: 0.027| per_loss: 0.504 | a_loss: 0.529
Train: Epoch [1536/3000], Step [60/158]| g_loss: 0.825| d_loss: 0.589| gp_loss: 0.061| r_loss: 0.110| p_loss: 0.155| v_loss: 0.029| per_loss: 0.479 | a_loss: 0.561
Train: Epoch [1536/3000], Step [90/158]| g_loss: 0.826| d_loss: 0.563| gp_loss: 0.062| r_loss: 0.089| p_loss: 0.132| v_loss: 0.028| per_loss: 0.516 | a_loss: 0.593
Train: Epoch [1536/3000], Step [120/158]| g_loss: 0.765| d_loss: 0.531| gp_loss: 0.067| r_loss: 0.076| p_loss: 0.118| v_loss: 0.028| per_loss: 0.492 | a_loss: 0.553
Train: Epoch [1536/3000], Step [150/158]| g_loss: 0.755| d_loss: 0.646| gp_loss: 0.064| r_loss: 0.072| p_loss: 0.112| v_loss: 0.026| per_loss: 0.462 | a_loss: 0.554
Train: Epoch [1537/3000], Step [30/158]| g_loss: 0.731| d_loss: 0.754| gp_loss: 0.233| r_loss: 0.074| p_loss: 0.115| v_loss: 0.026| per_loss: 0.435 | a_loss: 0.531
Train: Epoch [1537/3000], Step [60/158]| g_loss: 0.700| d_loss: 0.634| gp_loss: 0.056| r_loss: 0.076| p_loss: 0.117| v_loss: 0.026| per_loss: 0.449 | a_loss: 0.494
Train: Epoch [1537/3000], Step [90/158]| g_loss: 0.742| d_loss: 0.594| gp_loss: 0.062| r_loss: 0.077| p_loss: 0.116| v_loss: 0.027| per_loss: 0.462 | a_loss: 0.535
Train: Epoch [1537/3000], Step [120/158]| g_loss: 0.742| d_loss: 0.629| gp_loss: 0.057| r_loss: 0.072| p_loss: 0.105| v_loss: 0.026| per_loss: 0.516 | a_loss: 0.540
Train: Epoch [1537/3000], Step [150/158]| g_loss: 0.724| d_loss: 0.559| gp_loss: 0.059| r_loss: 0.073| p_loss: 0.111| v_loss: 0.026| per_loss: 0.450 | a_loss: 0.525
Train: Epoch [1538/3000], Step [30/158]| g_loss: 0.790| d_loss: 0.685| gp_loss: 0.160| r_loss: 0.077| p_loss: 0.118| v_loss: 0.028| per_loss: 0.419 | a_loss: 0.584
Train: Epoch [1538/3000], Step [60/158]| g_loss: 0.740| d_loss: 0.604| gp_loss: 0.061| r_loss: 0.074| p_loss: 0.119| v_loss: 0.028| per_loss: 0.455 | a_loss: 0.533
Train: Epoch [1538/3000], Step [90/158]| g_loss: 0.802| d_loss: 0.594| gp_loss: 0.058| r_loss: 0.075| p_loss: 0.111| v_loss: 0.028| per_loss: 0.455 | a_loss: 0.599
Train: Epoch [1538/3000], Step [120/158]| g_loss: 0.704| d_loss: 0.646| gp_loss: 0.057| r_loss: 0.072| p_loss: 0.113| v_loss: 0.026| per_loss: 0.493 | a_loss: 0.500
Train: Epoch [1538/3000], Step [150/158]| g_loss: 0.751| d_loss: 0.514| gp_loss: 0.060| r_loss: 0.070| p_loss: 0.106| v_loss: 0.025| per_loss: 0.473 | a_loss: 0.556
Train: Epoch [1539/3000], Step [30/158]| g_loss: 0.794| d_loss: 0.663| gp_loss: 0.150| r_loss: 0.072| p_loss: 0.110| v_loss: 0.028| per_loss: 0.500 | a_loss: 0.590
Train: Epoch [1539/3000], Step [60/158]| g_loss: 0.757| d_loss: 0.592| gp_loss: 0.056| r_loss: 0.071| p_loss: 0.111| v_loss: 0.027| per_loss: 0.502 | a_loss: 0.553
Train: Epoch [1539/3000], Step [90/158]| g_loss: 0.752| d_loss: 0.548| gp_loss: 0.057| r_loss: 0.073| p_loss: 0.114| v_loss: 0.027| per_loss: 0.443 | a_loss: 0.551
Train: Epoch [1539/3000], Step [120/158]| g_loss: 0.751| d_loss: 0.644| gp_loss: 0.060| r_loss: 0.074| p_loss: 0.113| v_loss: 0.026| per_loss: 0.460 | a_loss: 0.548
Train: Epoch [1539/3000], Step [150/158]| g_loss: 0.781| d_loss: 0.563| gp_loss: 0.056| r_loss: 0.075| p_loss: 0.115| v_loss: 0.027| per_loss: 0.463 | a_loss: 0.575
Train: Epoch [1540/3000], Step [30/158]| g_loss: 0.702| d_loss: 0.745| gp_loss: 0.133| r_loss: 0.074| p_loss: 0.116| v_loss: 0.026| per_loss: 0.452 | a_loss: 0.499
Train: Epoch [1540/3000], Step [60/158]| g_loss: 0.761| d_loss: 0.556| gp_loss: 0.055| r_loss: 0.071| p_loss: 0.111| v_loss: 0.027| per_loss: 0.487 | a_loss: 0.559
Train: Epoch [1540/3000], Step [90/158]| g_loss: 0.757| d_loss: 0.625| gp_loss: 0.054| r_loss: 0.073| p_loss: 0.107| v_loss: 0.027| per_loss: 0.473 | a_loss: 0.556
Train: Epoch [1540/3000], Step [120/158]| g_loss: 0.775| d_loss: 0.504| gp_loss: 0.060| r_loss: 0.068| p_loss: 0.101| v_loss: 0.025| per_loss: 0.453 | a_loss: 0.586
Train: Epoch [1540/3000], Step [150/158]| g_loss: 0.754| d_loss: 0.584| gp_loss: 0.056| r_loss: 0.074| p_loss: 0.113| v_loss: 0.029| per_loss: 0.468 | a_loss: 0.549
Train: Epoch [1541/3000], Step [30/158]| g_loss: 0.852| d_loss: 0.556| gp_loss: 0.138| r_loss: 0.073| p_loss: 0.110| v_loss: 0.028| per_loss: 0.474 | a_loss: 0.649
Train: Epoch [1541/3000], Step [60/158]| g_loss: 0.731| d_loss: 0.609| gp_loss: 0.056| r_loss: 0.071| p_loss: 0.106| v_loss: 0.026| per_loss: 0.452 | a_loss: 0.535
Train: Epoch [1541/3000], Step [90/158]| g_loss: 0.806| d_loss: 0.511| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.110| v_loss: 0.026| per_loss: 0.477 | a_loss: 0.606
Train: Epoch [1541/3000], Step [120/158]| g_loss: 0.779| d_loss: 0.556| gp_loss: 0.056| r_loss: 0.071| p_loss: 0.110| v_loss: 0.026| per_loss: 0.469 | a_loss: 0.580
Train: Epoch [1541/3000], Step [150/158]| g_loss: 0.727| d_loss: 0.651| gp_loss: 0.060| r_loss: 0.073| p_loss: 0.114| v_loss: 0.026| per_loss: 0.501 | a_loss: 0.521
Train: Epoch [1542/3000], Step [30/158]| g_loss: 0.689| d_loss: 0.740| gp_loss: 0.105| r_loss: 0.069| p_loss: 0.116| v_loss: 0.026| per_loss: 0.452 | a_loss: 0.491
Train: Epoch [1542/3000], Step [60/158]| g_loss: 0.733| d_loss: 0.594| gp_loss: 0.061| r_loss: 0.075| p_loss: 0.113| v_loss: 0.028| per_loss: 0.449 | a_loss: 0.529
Train: Epoch [1542/3000], Step [90/158]| g_loss: 0.796| d_loss: 0.571| gp_loss: 0.063| r_loss: 0.075| p_loss: 0.115| v_loss: 0.028| per_loss: 0.466 | a_loss: 0.590
Train: Epoch [1542/3000], Step [120/158]| g_loss: 0.761| d_loss: 0.593| gp_loss: 0.060| r_loss: 0.076| p_loss: 0.117| v_loss: 0.028| per_loss: 0.509 | a_loss: 0.548
Train: Epoch [1542/3000], Step [150/158]| g_loss: 0.766| d_loss: 0.535| gp_loss: 0.065| r_loss: 0.072| p_loss: 0.112| v_loss: 0.027| per_loss: 0.466 | a_loss: 0.564
Train: Epoch [1543/3000], Step [30/158]| g_loss: 0.773| d_loss: 0.731| gp_loss: 0.189| r_loss: 0.074| p_loss: 0.115| v_loss: 0.027| per_loss: 0.475 | a_loss: 0.567
Train: Epoch [1543/3000], Step [60/158]| g_loss: 0.762| d_loss: 0.545| gp_loss: 0.059| r_loss: 0.075| p_loss: 0.113| v_loss: 0.028| per_loss: 0.473 | a_loss: 0.555
Train: Epoch [1543/3000], Step [90/158]| g_loss: 0.720| d_loss: 0.581| gp_loss: 0.059| r_loss: 0.072| p_loss: 0.105| v_loss: 0.026| per_loss: 0.443 | a_loss: 0.525
Train: Epoch [1543/3000], Step [120/158]| g_loss: 0.792| d_loss: 0.546| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.109| v_loss: 0.026| per_loss: 0.450 | a_loss: 0.596
Train: Epoch [1543/3000], Step [150/158]| g_loss: 0.745| d_loss: 0.612| gp_loss: 0.057| r_loss: 0.072| p_loss: 0.107| v_loss: 0.026| per_loss: 0.479 | a_loss: 0.546
Train: Epoch [1544/3000], Step [30/158]| g_loss: 0.770| d_loss: 0.630| gp_loss: 0.153| r_loss: 0.074| p_loss: 0.107| v_loss: 0.027| per_loss: 0.441 | a_loss: 0.571
Train: Epoch [1544/3000], Step [60/158]| g_loss: 0.756| d_loss: 0.579| gp_loss: 0.051| r_loss: 0.070| p_loss: 0.105| v_loss: 0.026| per_loss: 0.472 | a_loss: 0.560
Train: Epoch [1544/3000], Step [90/158]| g_loss: 0.678| d_loss: 0.682| gp_loss: 0.056| r_loss: 0.072| p_loss: 0.110| v_loss: 0.026| per_loss: 0.485 | a_loss: 0.477
Train: Epoch [1544/3000], Step [120/158]| g_loss: 0.756| d_loss: 0.526| gp_loss: 0.061| r_loss: 0.071| p_loss: 0.113| v_loss: 0.027| per_loss: 0.452 | a_loss: 0.557
Train: Epoch [1544/3000], Step [150/158]| g_loss: 0.778| d_loss: 0.654| gp_loss: 0.058| r_loss: 0.072| p_loss: 0.112| v_loss: 0.026| per_loss: 0.452 | a_loss: 0.578
Train: Epoch [1545/3000], Step [30/158]| g_loss: 0.757| d_loss: 0.638| gp_loss: 0.151| r_loss: 0.072| p_loss: 0.113| v_loss: 0.027| per_loss: 0.442 | a_loss: 0.558
Train: Epoch [1545/3000], Step [60/158]| g_loss: 0.726| d_loss: 0.584| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.104| v_loss: 0.026| per_loss: 0.438 | a_loss: 0.533
Train: Epoch [1545/3000], Step [90/158]| g_loss: 0.761| d_loss: 0.547| gp_loss: 0.058| r_loss: 0.071| p_loss: 0.111| v_loss: 0.027| per_loss: 0.495 | a_loss: 0.558
Train: Epoch [1545/3000], Step [120/158]| g_loss: 0.813| d_loss: 0.629| gp_loss: 0.060| r_loss: 0.077| p_loss: 0.120| v_loss: 0.028| per_loss: 0.450 | a_loss: 0.603
Train: Epoch [1545/3000], Step [150/158]| g_loss: 0.707| d_loss: 0.653| gp_loss: 0.060| r_loss: 0.072| p_loss: 0.110| v_loss: 0.027| per_loss: 0.496 | a_loss: 0.504
Train: Epoch [1546/3000], Step [30/158]| g_loss: 0.741| d_loss: 0.696| gp_loss: 0.150| r_loss: 0.074| p_loss: 0.115| v_loss: 0.027| per_loss: 0.441 | a_loss: 0.540
Train: Epoch [1546/3000], Step [60/158]| g_loss: 0.691| d_loss: 0.620| gp_loss: 0.058| r_loss: 0.071| p_loss: 0.113| v_loss: 0.027| per_loss: 0.467 | a_loss: 0.489
Train: Epoch [1546/3000], Step [90/158]| g_loss: 0.815| d_loss: 0.539| gp_loss: 0.059| r_loss: 0.072| p_loss: 0.107| v_loss: 0.026| per_loss: 0.468 | a_loss: 0.617
Train: Epoch [1546/3000], Step [120/158]| g_loss: 0.745| d_loss: 0.593| gp_loss: 0.058| r_loss: 0.070| p_loss: 0.102| v_loss: 0.027| per_loss: 0.453 | a_loss: 0.552
Train: Epoch [1546/3000], Step [150/158]| g_loss: 0.749| d_loss: 0.644| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.108| v_loss: 0.028| per_loss: 0.486 | a_loss: 0.547
Train: Epoch [1547/3000], Step [30/158]| g_loss: 0.735| d_loss: 0.770| gp_loss: 0.200| r_loss: 0.071| p_loss: 0.113| v_loss: 0.027| per_loss: 0.439 | a_loss: 0.537
Train: Epoch [1547/3000], Step [60/158]| g_loss: 0.724| d_loss: 0.572| gp_loss: 0.055| r_loss: 0.073| p_loss: 0.108| v_loss: 0.027| per_loss: 0.446 | a_loss: 0.526
Train: Epoch [1547/3000], Step [90/158]| g_loss: 0.747| d_loss: 0.595| gp_loss: 0.052| r_loss: 0.072| p_loss: 0.109| v_loss: 0.026| per_loss: 0.447 | a_loss: 0.551
Train: Epoch [1547/3000], Step [120/158]| g_loss: 0.754| d_loss: 0.589| gp_loss: 0.059| r_loss: 0.073| p_loss: 0.113| v_loss: 0.027| per_loss: 0.464 | a_loss: 0.551
Train: Epoch [1547/3000], Step [150/158]| g_loss: 0.749| d_loss: 0.650| gp_loss: 0.060| r_loss: 0.070| p_loss: 0.108| v_loss: 0.026| per_loss: 0.452 | a_loss: 0.554
Train: Epoch [1548/3000], Step [30/158]| g_loss: 0.696| d_loss: 0.693| gp_loss: 0.132| r_loss: 0.070| p_loss: 0.104| v_loss: 0.026| per_loss: 0.438 | a_loss: 0.504
Train: Epoch [1548/3000], Step [60/158]| g_loss: 0.766| d_loss: 0.551| gp_loss: 0.056| r_loss: 0.073| p_loss: 0.111| v_loss: 0.028| per_loss: 0.465 | a_loss: 0.563
Train: Epoch [1548/3000], Step [90/158]| g_loss: 0.785| d_loss: 0.583| gp_loss: 0.055| r_loss: 0.071| p_loss: 0.108| v_loss: 0.027| per_loss: 0.444 | a_loss: 0.588
Train: Epoch [1548/3000], Step [120/158]| g_loss: 0.697| d_loss: 0.661| gp_loss: 0.057| r_loss: 0.074| p_loss: 0.113| v_loss: 0.026| per_loss: 0.429 | a_loss: 0.497
Train: Epoch [1548/3000], Step [150/158]| g_loss: 0.791| d_loss: 0.600| gp_loss: 0.061| r_loss: 0.073| p_loss: 0.114| v_loss: 0.028| per_loss: 0.479 | a_loss: 0.585
Train: Epoch [1549/3000], Step [30/158]| g_loss: 0.700| d_loss: 0.785| gp_loss: 0.196| r_loss: 0.073| p_loss: 0.115| v_loss: 0.027| per_loss: 0.425 | a_loss: 0.499
Train: Epoch [1549/3000], Step [60/158]| g_loss: 0.704| d_loss: 0.626| gp_loss: 0.055| r_loss: 0.070| p_loss: 0.110| v_loss: 0.025| per_loss: 0.445 | a_loss: 0.510
Train: Epoch [1549/3000], Step [90/158]| g_loss: 0.739| d_loss: 0.598| gp_loss: 0.058| r_loss: 0.074| p_loss: 0.114| v_loss: 0.027| per_loss: 0.410 | a_loss: 0.540
Train: Epoch [1549/3000], Step [120/158]| g_loss: 0.768| d_loss: 0.614| gp_loss: 0.054| r_loss: 0.072| p_loss: 0.108| v_loss: 0.027| per_loss: 0.469 | a_loss: 0.568
Train: Epoch [1549/3000], Step [150/158]| g_loss: 0.740| d_loss: 0.590| gp_loss: 0.057| r_loss: 0.073| p_loss: 0.110| v_loss: 0.026| per_loss: 0.450 | a_loss: 0.541
Train: Epoch [1550/3000], Step [30/158]| g_loss: 0.749| d_loss: 0.641| gp_loss: 0.116| r_loss: 0.070| p_loss: 0.103| v_loss: 0.027| per_loss: 0.427 | a_loss: 0.559
Train: Epoch [1550/3000], Step [60/158]| g_loss: 0.720| d_loss: 0.595| gp_loss: 0.058| r_loss: 0.067| p_loss: 0.104| v_loss: 0.026| per_loss: 0.458 | a_loss: 0.529
Train: Epoch [1550/3000], Step [90/158]| g_loss: 0.783| d_loss: 0.641| gp_loss: 0.054| r_loss: 0.072| p_loss: 0.107| v_loss: 0.027| per_loss: 0.448 | a_loss: 0.586
Train: Epoch [1550/3000], Step [120/158]| g_loss: 0.733| d_loss: 0.549| gp_loss: 0.058| r_loss: 0.072| p_loss: 0.111| v_loss: 0.027| per_loss: 0.437 | a_loss: 0.535
Train: Epoch [1550/3000], Step [150/158]| g_loss: 0.761| d_loss: 0.601| gp_loss: 0.055| r_loss: 0.074| p_loss: 0.113| v_loss: 0.027| per_loss: 0.431 | a_loss: 0.560
Test: Epoch [1550/3000]| g_loss: 0.628| r_loss: 0.386| p_loss: 0.297| v_loss: 0.024
Train: Epoch [1551/3000], Step [30/158]| g_loss: 0.689| d_loss: 0.676| gp_loss: 0.055| r_loss: 0.071| p_loss: 0.105| v_loss: 0.026| per_loss: 0.480 | a_loss: 0.492
Train: Epoch [1551/3000], Step [60/158]| g_loss: 0.738| d_loss: 0.632| gp_loss: 0.059| r_loss: 0.073| p_loss: 0.115| v_loss: 0.025| per_loss: 0.421 | a_loss: 0.540
Train: Epoch [1551/3000], Step [90/158]| g_loss: 0.723| d_loss: 0.606| gp_loss: 0.057| r_loss: 0.072| p_loss: 0.115| v_loss: 0.027| per_loss: 0.438 | a_loss: 0.523
Train: Epoch [1551/3000], Step [120/158]| g_loss: 0.820| d_loss: 0.461| gp_loss: 0.056| r_loss: 0.074| p_loss: 0.108| v_loss: 0.027| per_loss: 0.430 | a_loss: 0.622
Train: Epoch [1551/3000], Step [150/158]| g_loss: 0.735| d_loss: 0.666| gp_loss: 0.053| r_loss: 0.074| p_loss: 0.113| v_loss: 0.027| per_loss: 0.443 | a_loss: 0.533
Train: Epoch [1552/3000], Step [30/158]| g_loss: 0.743| d_loss: 0.700| gp_loss: 0.127| r_loss: 0.070| p_loss: 0.106| v_loss: 0.026| per_loss: 0.459 | a_loss: 0.548
Train: Epoch [1552/3000], Step [60/158]| g_loss: 0.762| d_loss: 0.539| gp_loss: 0.052| r_loss: 0.071| p_loss: 0.110| v_loss: 0.028| per_loss: 0.450 | a_loss: 0.564
Train: Epoch [1552/3000], Step [90/158]| g_loss: 0.714| d_loss: 0.654| gp_loss: 0.055| r_loss: 0.072| p_loss: 0.111| v_loss: 0.026| per_loss: 0.427 | a_loss: 0.517
Train: Epoch [1552/3000], Step [120/158]| g_loss: 0.753| d_loss: 0.610| gp_loss: 0.056| r_loss: 0.072| p_loss: 0.116| v_loss: 0.027| per_loss: 0.426 | a_loss: 0.554
Train: Epoch [1552/3000], Step [150/158]| g_loss: 0.734| d_loss: 0.584| gp_loss: 0.057| r_loss: 0.075| p_loss: 0.115| v_loss: 0.028| per_loss: 0.425 | a_loss: 0.532
Train: Epoch [1553/3000], Step [30/158]| g_loss: 0.649| d_loss: 0.814| gp_loss: 0.145| r_loss: 0.071| p_loss: 0.111| v_loss: 0.026| per_loss: 0.430 | a_loss: 0.453
Train: Epoch [1553/3000], Step [60/158]| g_loss: 0.742| d_loss: 0.651| gp_loss: 0.055| r_loss: 0.071| p_loss: 0.107| v_loss: 0.025| per_loss: 0.431 | a_loss: 0.550
Train: Epoch [1553/3000], Step [90/158]| g_loss: 0.723| d_loss: 0.623| gp_loss: 0.058| r_loss: 0.076| p_loss: 0.120| v_loss: 0.026| per_loss: 0.444 | a_loss: 0.516
Train: Epoch [1553/3000], Step [120/158]| g_loss: 0.794| d_loss: 0.533| gp_loss: 0.061| r_loss: 0.085| p_loss: 0.122| v_loss: 0.027| per_loss: 0.455 | a_loss: 0.576
Train: Epoch [1553/3000], Step [150/158]| g_loss: 0.742| d_loss: 0.559| gp_loss: 0.059| r_loss: 0.073| p_loss: 0.110| v_loss: 0.026| per_loss: 0.419 | a_loss: 0.547
Train: Epoch [1554/3000], Step [30/158]| g_loss: 0.706| d_loss: 0.777| gp_loss: 0.124| r_loss: 0.073| p_loss: 0.112| v_loss: 0.026| per_loss: 0.430 | a_loss: 0.507
Train: Epoch [1554/3000], Step [60/158]| g_loss: 0.706| d_loss: 0.612| gp_loss: 0.054| r_loss: 0.071| p_loss: 0.107| v_loss: 0.027| per_loss: 0.437 | a_loss: 0.510
Train: Epoch [1554/3000], Step [90/158]| g_loss: 0.716| d_loss: 0.602| gp_loss: 0.057| r_loss: 0.073| p_loss: 0.115| v_loss: 0.027| per_loss: 0.411 | a_loss: 0.518
Train: Epoch [1554/3000], Step [120/158]| g_loss: 0.811| d_loss: 0.578| gp_loss: 0.059| r_loss: 0.071| p_loss: 0.109| v_loss: 0.026| per_loss: 0.488 | a_loss: 0.610
Train: Epoch [1554/3000], Step [150/158]| g_loss: 0.733| d_loss: 0.569| gp_loss: 0.059| r_loss: 0.073| p_loss: 0.109| v_loss: 0.027| per_loss: 0.425 | a_loss: 0.537
Train: Epoch [1555/3000], Step [30/158]| g_loss: 0.747| d_loss: 0.728| gp_loss: 0.154| r_loss: 0.072| p_loss: 0.114| v_loss: 0.026| per_loss: 0.429 | a_loss: 0.549
Train: Epoch [1555/3000], Step [60/158]| g_loss: 0.734| d_loss: 0.557| gp_loss: 0.059| r_loss: 0.070| p_loss: 0.105| v_loss: 0.024| per_loss: 0.439 | a_loss: 0.543
Train: Epoch [1555/3000], Step [90/158]| g_loss: 0.731| d_loss: 0.580| gp_loss: 0.053| r_loss: 0.067| p_loss: 0.101| v_loss: 0.026| per_loss: 0.426 | a_loss: 0.545
Train: Epoch [1555/3000], Step [120/158]| g_loss: 0.754| d_loss: 0.577| gp_loss: 0.055| r_loss: 0.073| p_loss: 0.107| v_loss: 0.027| per_loss: 0.478 | a_loss: 0.553
Train: Epoch [1555/3000], Step [150/158]| g_loss: 0.719| d_loss: 0.606| gp_loss: 0.058| r_loss: 0.068| p_loss: 0.106| v_loss: 0.027| per_loss: 0.475 | a_loss: 0.523
Train: Epoch [1556/3000], Step [30/158]| g_loss: 0.735| d_loss: 0.645| gp_loss: 0.122| r_loss: 0.071| p_loss: 0.108| v_loss: 0.026| per_loss: 0.456 | a_loss: 0.538
Train: Epoch [1556/3000], Step [60/158]| g_loss: 0.791| d_loss: 0.557| gp_loss: 0.058| r_loss: 0.074| p_loss: 0.109| v_loss: 0.026| per_loss: 0.445 | a_loss: 0.592
Train: Epoch [1556/3000], Step [90/158]| g_loss: 0.772| d_loss: 0.558| gp_loss: 0.059| r_loss: 0.069| p_loss: 0.104| v_loss: 0.026| per_loss: 0.424 | a_loss: 0.583
Train: Epoch [1556/3000], Step [120/158]| g_loss: 0.737| d_loss: 0.567| gp_loss: 0.059| r_loss: 0.077| p_loss: 0.114| v_loss: 0.026| per_loss: 0.438 | a_loss: 0.533
Train: Epoch [1556/3000], Step [150/158]| g_loss: 0.715| d_loss: 0.705| gp_loss: 0.059| r_loss: 0.074| p_loss: 0.118| v_loss: 0.027| per_loss: 0.440 | a_loss: 0.511
Train: Epoch [1557/3000], Step [30/158]| g_loss: 0.758| d_loss: 0.704| gp_loss: 0.145| r_loss: 0.073| p_loss: 0.110| v_loss: 0.026| per_loss: 0.459 | a_loss: 0.558
Train: Epoch [1557/3000], Step [60/158]| g_loss: 0.733| d_loss: 0.613| gp_loss: 0.058| r_loss: 0.075| p_loss: 0.109| v_loss: 0.027| per_loss: 0.458 | a_loss: 0.531
Train: Epoch [1557/3000], Step [90/158]| g_loss: 0.743| d_loss: 0.553| gp_loss: 0.061| r_loss: 0.070| p_loss: 0.104| v_loss: 0.026| per_loss: 0.482 | a_loss: 0.547
Train: Epoch [1557/3000], Step [120/158]| g_loss: 0.792| d_loss: 0.539| gp_loss: 0.061| r_loss: 0.072| p_loss: 0.108| v_loss: 0.027| per_loss: 0.433 | a_loss: 0.596
Train: Epoch [1557/3000], Step [150/158]| g_loss: 0.693| d_loss: 0.668| gp_loss: 0.061| r_loss: 0.070| p_loss: 0.107| v_loss: 0.025| per_loss: 0.439 | a_loss: 0.500
Train: Epoch [1558/3000], Step [30/158]| g_loss: 0.794| d_loss: 0.595| gp_loss: 0.134| r_loss: 0.070| p_loss: 0.112| v_loss: 0.027| per_loss: 0.441 | a_loss: 0.596
Train: Epoch [1558/3000], Step [60/158]| g_loss: 0.751| d_loss: 0.581| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.106| v_loss: 0.026| per_loss: 0.468 | a_loss: 0.554
Train: Epoch [1558/3000], Step [90/158]| g_loss: 0.753| d_loss: 0.632| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.108| v_loss: 0.026| per_loss: 0.422 | a_loss: 0.560
Train: Epoch [1558/3000], Step [120/158]| g_loss: 0.727| d_loss: 0.592| gp_loss: 0.061| r_loss: 0.072| p_loss: 0.108| v_loss: 0.026| per_loss: 0.425 | a_loss: 0.532
Train: Epoch [1558/3000], Step [150/158]| g_loss: 0.708| d_loss: 0.674| gp_loss: 0.057| r_loss: 0.074| p_loss: 0.113| v_loss: 0.026| per_loss: 0.450 | a_loss: 0.507
Train: Epoch [1559/3000], Step [30/158]| g_loss: 0.696| d_loss: 0.724| gp_loss: 0.128| r_loss: 0.073| p_loss: 0.117| v_loss: 0.027| per_loss: 0.425 | a_loss: 0.495
Train: Epoch [1559/3000], Step [60/158]| g_loss: 0.760| d_loss: 0.707| gp_loss: 0.055| r_loss: 0.076| p_loss: 0.119| v_loss: 0.026| per_loss: 0.441 | a_loss: 0.555
Train: Epoch [1559/3000], Step [90/158]| g_loss: 0.711| d_loss: 0.606| gp_loss: 0.061| r_loss: 0.076| p_loss: 0.116| v_loss: 0.027| per_loss: 0.485 | a_loss: 0.502
Train: Epoch [1559/3000], Step [120/158]| g_loss: 0.744| d_loss: 0.564| gp_loss: 0.055| r_loss: 0.070| p_loss: 0.109| v_loss: 0.025| per_loss: 0.433 | a_loss: 0.552
Train: Epoch [1559/3000], Step [150/158]| g_loss: 0.785| d_loss: 0.513| gp_loss: 0.063| r_loss: 0.073| p_loss: 0.111| v_loss: 0.027| per_loss: 0.486 | a_loss: 0.581
Train: Epoch [1560/3000], Step [30/158]| g_loss: 0.757| d_loss: 0.727| gp_loss: 0.214| r_loss: 0.072| p_loss: 0.113| v_loss: 0.027| per_loss: 0.447 | a_loss: 0.557
Train: Epoch [1560/3000], Step [60/158]| g_loss: 0.797| d_loss: 0.573| gp_loss: 0.055| r_loss: 0.074| p_loss: 0.117| v_loss: 0.027| per_loss: 0.442 | a_loss: 0.593
Train: Epoch [1560/3000], Step [90/158]| g_loss: 0.706| d_loss: 0.699| gp_loss: 0.055| r_loss: 0.073| p_loss: 0.119| v_loss: 0.026| per_loss: 0.482 | a_loss: 0.498
Train: Epoch [1560/3000], Step [120/158]| g_loss: 0.750| d_loss: 0.556| gp_loss: 0.057| r_loss: 0.073| p_loss: 0.121| v_loss: 0.026| per_loss: 0.439 | a_loss: 0.546
Train: Epoch [1560/3000], Step [150/158]| g_loss: 0.735| d_loss: 0.623| gp_loss: 0.054| r_loss: 0.072| p_loss: 0.109| v_loss: 0.025| per_loss: 0.442 | a_loss: 0.539
Train: Epoch [1561/3000], Step [30/158]| g_loss: 0.765| d_loss: 0.707| gp_loss: 0.143| r_loss: 0.072| p_loss: 0.107| v_loss: 0.026| per_loss: 0.451 | a_loss: 0.568
Train: Epoch [1561/3000], Step [60/158]| g_loss: 0.683| d_loss: 0.612| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.106| v_loss: 0.026| per_loss: 0.444 | a_loss: 0.488
Train: Epoch [1561/3000], Step [90/158]| g_loss: 0.760| d_loss: 0.578| gp_loss: 0.056| r_loss: 0.068| p_loss: 0.105| v_loss: 0.026| per_loss: 0.457 | a_loss: 0.568
Train: Epoch [1561/3000], Step [120/158]| g_loss: 0.740| d_loss: 0.571| gp_loss: 0.057| r_loss: 0.075| p_loss: 0.112| v_loss: 0.027| per_loss: 0.447 | a_loss: 0.537
Train: Epoch [1561/3000], Step [150/158]| g_loss: 0.769| d_loss: 0.581| gp_loss: 0.061| r_loss: 0.067| p_loss: 0.106| v_loss: 0.026| per_loss: 0.463 | a_loss: 0.576
Train: Epoch [1562/3000], Step [30/158]| g_loss: 0.721| d_loss: 0.673| gp_loss: 0.099| r_loss: 0.070| p_loss: 0.108| v_loss: 0.026| per_loss: 0.437 | a_loss: 0.527
Train: Epoch [1562/3000], Step [60/158]| g_loss: 0.800| d_loss: 0.499| gp_loss: 0.057| r_loss: 0.072| p_loss: 0.109| v_loss: 0.027| per_loss: 0.423 | a_loss: 0.605
Train: Epoch [1562/3000], Step [90/158]| g_loss: 0.755| d_loss: 0.592| gp_loss: 0.058| r_loss: 0.068| p_loss: 0.099| v_loss: 0.026| per_loss: 0.439 | a_loss: 0.568
Train: Epoch [1562/3000], Step [120/158]| g_loss: 0.708| d_loss: 0.665| gp_loss: 0.064| r_loss: 0.073| p_loss: 0.115| v_loss: 0.027| per_loss: 0.412 | a_loss: 0.510
Train: Epoch [1562/3000], Step [150/158]| g_loss: 0.701| d_loss: 0.700| gp_loss: 0.060| r_loss: 0.070| p_loss: 0.106| v_loss: 0.026| per_loss: 0.469 | a_loss: 0.506
Train: Epoch [1563/3000], Step [30/158]| g_loss: 0.759| d_loss: 0.739| gp_loss: 0.178| r_loss: 0.075| p_loss: 0.114| v_loss: 0.027| per_loss: 0.437 | a_loss: 0.557
Train: Epoch [1563/3000], Step [60/158]| g_loss: 0.736| d_loss: 0.567| gp_loss: 0.055| r_loss: 0.072| p_loss: 0.109| v_loss: 0.026| per_loss: 0.446 | a_loss: 0.539
Train: Epoch [1563/3000], Step [90/158]| g_loss: 0.761| d_loss: 0.515| gp_loss: 0.054| r_loss: 0.067| p_loss: 0.103| v_loss: 0.025| per_loss: 0.455 | a_loss: 0.572
Train: Epoch [1563/3000], Step [120/158]| g_loss: 0.734| d_loss: 0.661| gp_loss: 0.055| r_loss: 0.071| p_loss: 0.109| v_loss: 0.025| per_loss: 0.454 | a_loss: 0.538
Train: Epoch [1563/3000], Step [150/158]| g_loss: 0.708| d_loss: 0.676| gp_loss: 0.055| r_loss: 0.071| p_loss: 0.109| v_loss: 0.027| per_loss: 0.450 | a_loss: 0.512
Train: Epoch [1564/3000], Step [30/158]| g_loss: 0.688| d_loss: 0.804| gp_loss: 0.158| r_loss: 0.072| p_loss: 0.115| v_loss: 0.027| per_loss: 0.436 | a_loss: 0.488
Train: Epoch [1564/3000], Step [60/158]| g_loss: 0.709| d_loss: 0.607| gp_loss: 0.052| r_loss: 0.069| p_loss: 0.111| v_loss: 0.026| per_loss: 0.434 | a_loss: 0.515
Train: Epoch [1564/3000], Step [90/158]| g_loss: 0.734| d_loss: 0.574| gp_loss: 0.056| r_loss: 0.074| p_loss: 0.107| v_loss: 0.027| per_loss: 0.460 | a_loss: 0.533
Train: Epoch [1564/3000], Step [120/158]| g_loss: 0.778| d_loss: 0.641| gp_loss: 0.051| r_loss: 0.073| p_loss: 0.117| v_loss: 0.026| per_loss: 0.454 | a_loss: 0.575
Train: Epoch [1564/3000], Step [150/158]| g_loss: 0.739| d_loss: 0.562| gp_loss: 0.064| r_loss: 0.072| p_loss: 0.106| v_loss: 0.026| per_loss: 0.419 | a_loss: 0.545
Train: Epoch [1565/3000], Step [30/158]| g_loss: 0.719| d_loss: 0.710| gp_loss: 0.149| r_loss: 0.069| p_loss: 0.104| v_loss: 0.025| per_loss: 0.458 | a_loss: 0.528
Train: Epoch [1565/3000], Step [60/158]| g_loss: 0.753| d_loss: 0.574| gp_loss: 0.057| r_loss: 0.069| p_loss: 0.105| v_loss: 0.026| per_loss: 0.394 | a_loss: 0.565
Train: Epoch [1565/3000], Step [90/158]| g_loss: 0.774| d_loss: 0.525| gp_loss: 0.053| r_loss: 0.071| p_loss: 0.099| v_loss: 0.027| per_loss: 0.447 | a_loss: 0.581
Train: Epoch [1565/3000], Step [120/158]| g_loss: 0.817| d_loss: 0.545| gp_loss: 0.057| r_loss: 0.069| p_loss: 0.104| v_loss: 0.026| per_loss: 0.451 | a_loss: 0.624
Train: Epoch [1565/3000], Step [150/158]| g_loss: 0.670| d_loss: 0.699| gp_loss: 0.059| r_loss: 0.071| p_loss: 0.108| v_loss: 0.026| per_loss: 0.434 | a_loss: 0.476
Train: Epoch [1566/3000], Step [30/158]| g_loss: 0.695| d_loss: 0.728| gp_loss: 0.139| r_loss: 0.070| p_loss: 0.105| v_loss: 0.026| per_loss: 0.461 | a_loss: 0.500
Train: Epoch [1566/3000], Step [60/158]| g_loss: 0.722| d_loss: 0.605| gp_loss: 0.056| r_loss: 0.074| p_loss: 0.112| v_loss: 0.027| per_loss: 0.418 | a_loss: 0.524
Train: Epoch [1566/3000], Step [90/158]| g_loss: 0.746| d_loss: 0.614| gp_loss: 0.056| r_loss: 0.070| p_loss: 0.106| v_loss: 0.025| per_loss: 0.477 | a_loss: 0.551
Train: Epoch [1566/3000], Step [120/158]| g_loss: 0.724| d_loss: 0.591| gp_loss: 0.059| r_loss: 0.070| p_loss: 0.101| v_loss: 0.025| per_loss: 0.443 | a_loss: 0.534
Train: Epoch [1566/3000], Step [150/158]| g_loss: 0.760| d_loss: 0.590| gp_loss: 0.058| r_loss: 0.072| p_loss: 0.106| v_loss: 0.027| per_loss: 0.451 | a_loss: 0.563
Train: Epoch [1567/3000], Step [30/158]| g_loss: 0.685| d_loss: 0.711| gp_loss: 0.168| r_loss: 0.070| p_loss: 0.102| v_loss: 0.026| per_loss: 0.442 | a_loss: 0.495
Train: Epoch [1567/3000], Step [60/158]| g_loss: 0.698| d_loss: 0.655| gp_loss: 0.053| r_loss: 0.069| p_loss: 0.103| v_loss: 0.025| per_loss: 0.460 | a_loss: 0.507
Train: Epoch [1567/3000], Step [90/158]| g_loss: 0.792| d_loss: 0.529| gp_loss: 0.054| r_loss: 0.070| p_loss: 0.102| v_loss: 0.026| per_loss: 0.455 | a_loss: 0.600
Train: Epoch [1567/3000], Step [120/158]| g_loss: 0.773| d_loss: 0.508| gp_loss: 0.058| r_loss: 0.070| p_loss: 0.106| v_loss: 0.027| per_loss: 0.454 | a_loss: 0.578
Train: Epoch [1567/3000], Step [150/158]| g_loss: 0.702| d_loss: 0.653| gp_loss: 0.056| r_loss: 0.069| p_loss: 0.103| v_loss: 0.025| per_loss: 0.428 | a_loss: 0.513
Train: Epoch [1568/3000], Step [30/158]| g_loss: 0.733| d_loss: 0.690| gp_loss: 0.146| r_loss: 0.073| p_loss: 0.111| v_loss: 0.027| per_loss: 0.428 | a_loss: 0.534
Train: Epoch [1568/3000], Step [60/158]| g_loss: 0.781| d_loss: 0.633| gp_loss: 0.056| r_loss: 0.074| p_loss: 0.126| v_loss: 0.026| per_loss: 0.456 | a_loss: 0.573
Train: Epoch [1568/3000], Step [90/158]| g_loss: 0.711| d_loss: 0.656| gp_loss: 0.057| r_loss: 0.073| p_loss: 0.117| v_loss: 0.026| per_loss: 0.436 | a_loss: 0.510
Train: Epoch [1568/3000], Step [120/158]| g_loss: 0.722| d_loss: 0.630| gp_loss: 0.059| r_loss: 0.073| p_loss: 0.113| v_loss: 0.026| per_loss: 0.447 | a_loss: 0.522
Train: Epoch [1568/3000], Step [150/158]| g_loss: 0.755| d_loss: 0.608| gp_loss: 0.061| r_loss: 0.073| p_loss: 0.112| v_loss: 0.026| per_loss: 0.467 | a_loss: 0.553
Train: Epoch [1569/3000], Step [30/158]| g_loss: 0.736| d_loss: 0.651| gp_loss: 0.160| r_loss: 0.070| p_loss: 0.108| v_loss: 0.026| per_loss: 0.422 | a_loss: 0.544
Train: Epoch [1569/3000], Step [60/158]| g_loss: 0.758| d_loss: 0.633| gp_loss: 0.055| r_loss: 0.070| p_loss: 0.107| v_loss: 0.026| per_loss: 0.461 | a_loss: 0.562
Train: Epoch [1569/3000], Step [90/158]| g_loss: 0.685| d_loss: 0.645| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.111| v_loss: 0.025| per_loss: 0.427 | a_loss: 0.490
Train: Epoch [1569/3000], Step [120/158]| g_loss: 0.778| d_loss: 0.580| gp_loss: 0.053| r_loss: 0.072| p_loss: 0.109| v_loss: 0.027| per_loss: 0.438 | a_loss: 0.581
Train: Epoch [1569/3000], Step [150/158]| g_loss: 0.763| d_loss: 0.549| gp_loss: 0.059| r_loss: 0.071| p_loss: 0.110| v_loss: 0.026| per_loss: 0.451 | a_loss: 0.566
Train: Epoch [1570/3000], Step [30/158]| g_loss: 0.745| d_loss: 0.666| gp_loss: 0.107| r_loss: 0.073| p_loss: 0.115| v_loss: 0.027| per_loss: 0.447 | a_loss: 0.543
Train: Epoch [1570/3000], Step [60/158]| g_loss: 0.783| d_loss: 0.555| gp_loss: 0.060| r_loss: 0.072| p_loss: 0.113| v_loss: 0.027| per_loss: 0.447 | a_loss: 0.582
Train: Epoch [1570/3000], Step [90/158]| g_loss: 0.730| d_loss: 0.598| gp_loss: 0.057| r_loss: 0.074| p_loss: 0.112| v_loss: 0.026| per_loss: 0.499 | a_loss: 0.525
Train: Epoch [1570/3000], Step [120/158]| g_loss: 0.779| d_loss: 0.589| gp_loss: 0.062| r_loss: 0.075| p_loss: 0.120| v_loss: 0.027| per_loss: 0.421 | a_loss: 0.574
Train: Epoch [1570/3000], Step [150/158]| g_loss: 0.750| d_loss: 0.626| gp_loss: 0.057| r_loss: 0.074| p_loss: 0.115| v_loss: 0.027| per_loss: 0.450 | a_loss: 0.547
Train: Epoch [1571/3000], Step [30/158]| g_loss: 0.745| d_loss: 0.751| gp_loss: 0.141| r_loss: 0.076| p_loss: 0.121| v_loss: 0.028| per_loss: 0.439 | a_loss: 0.537
Train: Epoch [1571/3000], Step [60/158]| g_loss: 0.711| d_loss: 0.689| gp_loss: 0.061| r_loss: 0.075| p_loss: 0.118| v_loss: 0.026| per_loss: 0.466 | a_loss: 0.505
Train: Epoch [1571/3000], Step [90/158]| g_loss: 0.715| d_loss: 0.609| gp_loss: 0.060| r_loss: 0.075| p_loss: 0.121| v_loss: 0.026| per_loss: 0.449 | a_loss: 0.508
Train: Epoch [1571/3000], Step [120/158]| g_loss: 0.827| d_loss: 0.533| gp_loss: 0.060| r_loss: 0.083| p_loss: 0.133| v_loss: 0.027| per_loss: 0.451 | a_loss: 0.606
Train: Epoch [1571/3000], Step [150/158]| g_loss: 0.792| d_loss: 0.594| gp_loss: 0.056| r_loss: 0.080| p_loss: 0.143| v_loss: 0.027| per_loss: 0.465 | a_loss: 0.566
Train: Epoch [1572/3000], Step [30/158]| g_loss: 0.757| d_loss: 0.659| gp_loss: 0.138| r_loss: 0.079| p_loss: 0.126| v_loss: 0.027| per_loss: 0.454 | a_loss: 0.543
Train: Epoch [1572/3000], Step [60/158]| g_loss: 0.769| d_loss: 0.549| gp_loss: 0.055| r_loss: 0.074| p_loss: 0.113| v_loss: 0.028| per_loss: 0.467 | a_loss: 0.564
Train: Epoch [1572/3000], Step [90/158]| g_loss: 0.778| d_loss: 0.564| gp_loss: 0.057| r_loss: 0.067| p_loss: 0.103| v_loss: 0.026| per_loss: 0.487 | a_loss: 0.585
Train: Epoch [1572/3000], Step [120/158]| g_loss: 0.743| d_loss: 0.608| gp_loss: 0.059| r_loss: 0.073| p_loss: 0.107| v_loss: 0.027| per_loss: 0.447 | a_loss: 0.545
Train: Epoch [1572/3000], Step [150/158]| g_loss: 0.705| d_loss: 0.655| gp_loss: 0.055| r_loss: 0.072| p_loss: 0.114| v_loss: 0.025| per_loss: 0.428 | a_loss: 0.508
Train: Epoch [1573/3000], Step [30/158]| g_loss: 0.778| d_loss: 0.641| gp_loss: 0.132| r_loss: 0.073| p_loss: 0.113| v_loss: 0.026| per_loss: 0.456 | a_loss: 0.577
Train: Epoch [1573/3000], Step [60/158]| g_loss: 0.800| d_loss: 0.586| gp_loss: 0.058| r_loss: 0.073| p_loss: 0.115| v_loss: 0.026| per_loss: 0.450 | a_loss: 0.598
Train: Epoch [1573/3000], Step [90/158]| g_loss: 0.706| d_loss: 0.674| gp_loss: 0.059| r_loss: 0.070| p_loss: 0.112| v_loss: 0.026| per_loss: 0.429 | a_loss: 0.511
Train: Epoch [1573/3000], Step [120/158]| g_loss: 0.672| d_loss: 0.662| gp_loss: 0.056| r_loss: 0.070| p_loss: 0.107| v_loss: 0.027| per_loss: 0.487 | a_loss: 0.474
Train: Epoch [1573/3000], Step [150/158]| g_loss: 0.752| d_loss: 0.596| gp_loss: 0.061| r_loss: 0.073| p_loss: 0.105| v_loss: 0.028| per_loss: 0.447 | a_loss: 0.554
Train: Epoch [1574/3000], Step [30/158]| g_loss: 0.696| d_loss: 0.799| gp_loss: 0.175| r_loss: 0.072| p_loss: 0.112| v_loss: 0.027| per_loss: 0.408 | a_loss: 0.500
Train: Epoch [1574/3000], Step [60/158]| g_loss: 0.738| d_loss: 0.605| gp_loss: 0.059| r_loss: 0.072| p_loss: 0.109| v_loss: 0.028| per_loss: 0.447 | a_loss: 0.540
Train: Epoch [1574/3000], Step [90/158]| g_loss: 0.721| d_loss: 0.595| gp_loss: 0.055| r_loss: 0.070| p_loss: 0.105| v_loss: 0.025| per_loss: 0.450 | a_loss: 0.528
Train: Epoch [1574/3000], Step [120/158]| g_loss: 0.711| d_loss: 0.604| gp_loss: 0.056| r_loss: 0.071| p_loss: 0.104| v_loss: 0.025| per_loss: 0.454 | a_loss: 0.518
Train: Epoch [1574/3000], Step [150/158]| g_loss: 0.795| d_loss: 0.490| gp_loss: 0.059| r_loss: 0.069| p_loss: 0.108| v_loss: 0.026| per_loss: 0.463 | a_loss: 0.600
Train: Epoch [1575/3000], Step [30/158]| g_loss: 0.765| d_loss: 0.759| gp_loss: 0.226| r_loss: 0.069| p_loss: 0.105| v_loss: 0.025| per_loss: 0.462 | a_loss: 0.573
Train: Epoch [1575/3000], Step [60/158]| g_loss: 0.744| d_loss: 0.626| gp_loss: 0.052| r_loss: 0.071| p_loss: 0.109| v_loss: 0.027| per_loss: 0.440 | a_loss: 0.547
Train: Epoch [1575/3000], Step [90/158]| g_loss: 0.780| d_loss: 0.605| gp_loss: 0.054| r_loss: 0.074| p_loss: 0.112| v_loss: 0.027| per_loss: 0.448 | a_loss: 0.578
Train: Epoch [1575/3000], Step [120/158]| g_loss: 0.753| d_loss: 0.585| gp_loss: 0.056| r_loss: 0.071| p_loss: 0.107| v_loss: 0.027| per_loss: 0.479 | a_loss: 0.554
Train: Epoch [1575/3000], Step [150/158]| g_loss: 0.707| d_loss: 0.645| gp_loss: 0.060| r_loss: 0.072| p_loss: 0.109| v_loss: 0.026| per_loss: 0.412 | a_loss: 0.514
Train: Epoch [1576/3000], Step [30/158]| g_loss: 0.716| d_loss: 0.707| gp_loss: 0.167| r_loss: 0.070| p_loss: 0.110| v_loss: 0.026| per_loss: 0.422 | a_loss: 0.523
Train: Epoch [1576/3000], Step [60/158]| g_loss: 0.781| d_loss: 0.586| gp_loss: 0.057| r_loss: 0.072| p_loss: 0.111| v_loss: 0.026| per_loss: 0.458 | a_loss: 0.581
Train: Epoch [1576/3000], Step [90/158]| g_loss: 0.767| d_loss: 0.605| gp_loss: 0.054| r_loss: 0.069| p_loss: 0.105| v_loss: 0.026| per_loss: 0.482 | a_loss: 0.571
Train: Epoch [1576/3000], Step [120/158]| g_loss: 0.718| d_loss: 0.632| gp_loss: 0.052| r_loss: 0.072| p_loss: 0.110| v_loss: 0.026| per_loss: 0.441 | a_loss: 0.521
Train: Epoch [1576/3000], Step [150/158]| g_loss: 0.770| d_loss: 0.511| gp_loss: 0.054| r_loss: 0.072| p_loss: 0.110| v_loss: 0.026| per_loss: 0.426 | a_loss: 0.574
Train: Epoch [1577/3000], Step [30/158]| g_loss: 0.682| d_loss: 0.801| gp_loss: 0.075| r_loss: 0.083| p_loss: 0.120| v_loss: 0.027| per_loss: 0.458 | a_loss: 0.465
Train: Epoch [1577/3000], Step [60/158]| g_loss: 0.692| d_loss: 0.642| gp_loss: 0.056| r_loss: 0.071| p_loss: 0.108| v_loss: 0.027| per_loss: 0.430 | a_loss: 0.497
Train: Epoch [1577/3000], Step [90/158]| g_loss: 0.704| d_loss: 0.615| gp_loss: 0.055| r_loss: 0.071| p_loss: 0.105| v_loss: 0.024| per_loss: 0.447 | a_loss: 0.511
Train: Epoch [1577/3000], Step [120/158]| g_loss: 0.752| d_loss: 0.553| gp_loss: 0.058| r_loss: 0.071| p_loss: 0.107| v_loss: 0.026| per_loss: 0.430 | a_loss: 0.558
Train: Epoch [1577/3000], Step [150/158]| g_loss: 0.751| d_loss: 0.589| gp_loss: 0.060| r_loss: 0.068| p_loss: 0.103| v_loss: 0.025| per_loss: 0.474 | a_loss: 0.558
Train: Epoch [1578/3000], Step [30/158]| g_loss: 0.733| d_loss: 0.747| gp_loss: 0.177| r_loss: 0.070| p_loss: 0.104| v_loss: 0.025| per_loss: 0.412 | a_loss: 0.545
Train: Epoch [1578/3000], Step [60/158]| g_loss: 0.730| d_loss: 0.583| gp_loss: 0.055| r_loss: 0.071| p_loss: 0.103| v_loss: 0.026| per_loss: 0.474 | a_loss: 0.534
Train: Epoch [1578/3000], Step [90/158]| g_loss: 0.763| d_loss: 0.539| gp_loss: 0.057| r_loss: 0.069| p_loss: 0.100| v_loss: 0.027| per_loss: 0.431 | a_loss: 0.575
Train: Epoch [1578/3000], Step [120/158]| g_loss: 0.721| d_loss: 0.564| gp_loss: 0.056| r_loss: 0.068| p_loss: 0.106| v_loss: 0.026| per_loss: 0.466 | a_loss: 0.527
Train: Epoch [1578/3000], Step [150/158]| g_loss: 0.744| d_loss: 0.578| gp_loss: 0.060| r_loss: 0.067| p_loss: 0.103| v_loss: 0.025| per_loss: 0.448 | a_loss: 0.555
Train: Epoch [1579/3000], Step [30/158]| g_loss: 0.748| d_loss: 0.716| gp_loss: 0.141| r_loss: 0.075| p_loss: 0.112| v_loss: 0.026| per_loss: 0.428 | a_loss: 0.549
Train: Epoch [1579/3000], Step [60/158]| g_loss: 0.753| d_loss: 0.653| gp_loss: 0.053| r_loss: 0.077| p_loss: 0.124| v_loss: 0.027| per_loss: 0.456 | a_loss: 0.541
Train: Epoch [1579/3000], Step [90/158]| g_loss: 0.735| d_loss: 0.615| gp_loss: 0.056| r_loss: 0.070| p_loss: 0.112| v_loss: 0.025| per_loss: 0.427 | a_loss: 0.541
Train: Epoch [1579/3000], Step [120/158]| g_loss: 0.736| d_loss: 0.598| gp_loss: 0.058| r_loss: 0.072| p_loss: 0.110| v_loss: 0.026| per_loss: 0.475 | a_loss: 0.535
Train: Epoch [1579/3000], Step [150/158]| g_loss: 0.735| d_loss: 0.597| gp_loss: 0.056| r_loss: 0.071| p_loss: 0.110| v_loss: 0.027| per_loss: 0.478 | a_loss: 0.534
Train: Epoch [1580/3000], Step [30/158]| g_loss: 0.786| d_loss: 0.700| gp_loss: 0.191| r_loss: 0.071| p_loss: 0.105| v_loss: 0.026| per_loss: 0.494 | a_loss: 0.586
Train: Epoch [1580/3000], Step [60/158]| g_loss: 0.714| d_loss: 0.637| gp_loss: 0.050| r_loss: 0.073| p_loss: 0.111| v_loss: 0.026| per_loss: 0.434 | a_loss: 0.516
Train: Epoch [1580/3000], Step [90/158]| g_loss: 0.778| d_loss: 0.570| gp_loss: 0.056| r_loss: 0.068| p_loss: 0.109| v_loss: 0.026| per_loss: 0.436 | a_loss: 0.586
Train: Epoch [1580/3000], Step [120/158]| g_loss: 0.714| d_loss: 0.601| gp_loss: 0.052| r_loss: 0.070| p_loss: 0.107| v_loss: 0.026| per_loss: 0.455 | a_loss: 0.519
Train: Epoch [1580/3000], Step [150/158]| g_loss: 0.723| d_loss: 0.568| gp_loss: 0.059| r_loss: 0.071| p_loss: 0.104| v_loss: 0.025| per_loss: 0.428 | a_loss: 0.533
Train: Epoch [1581/3000], Step [30/158]| g_loss: 0.675| d_loss: 0.821| gp_loss: 0.164| r_loss: 0.068| p_loss: 0.107| v_loss: 0.026| per_loss: 0.440 | a_loss: 0.484
Train: Epoch [1581/3000], Step [60/158]| g_loss: 0.712| d_loss: 0.680| gp_loss: 0.055| r_loss: 0.069| p_loss: 0.107| v_loss: 0.025| per_loss: 0.433 | a_loss: 0.522
Train: Epoch [1581/3000], Step [90/158]| g_loss: 0.766| d_loss: 0.568| gp_loss: 0.054| r_loss: 0.071| p_loss: 0.105| v_loss: 0.025| per_loss: 0.446 | a_loss: 0.574
Train: Epoch [1581/3000], Step [120/158]| g_loss: 0.736| d_loss: 0.591| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.108| v_loss: 0.026| per_loss: 0.465 | a_loss: 0.538
Train: Epoch [1581/3000], Step [150/158]| g_loss: 0.738| d_loss: 0.573| gp_loss: 0.058| r_loss: 0.072| p_loss: 0.104| v_loss: 0.026| per_loss: 0.451 | a_loss: 0.542
Train: Epoch [1582/3000], Step [30/158]| g_loss: 0.744| d_loss: 0.628| gp_loss: 0.147| r_loss: 0.071| p_loss: 0.108| v_loss: 0.027| per_loss: 0.413 | a_loss: 0.552
Train: Epoch [1582/3000], Step [60/158]| g_loss: 0.743| d_loss: 0.629| gp_loss: 0.053| r_loss: 0.068| p_loss: 0.106| v_loss: 0.025| per_loss: 0.460 | a_loss: 0.551
Train: Epoch [1582/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.693| gp_loss: 0.054| r_loss: 0.069| p_loss: 0.104| v_loss: 0.025| per_loss: 0.448 | a_loss: 0.463
Train: Epoch [1582/3000], Step [120/158]| g_loss: 0.750| d_loss: 0.652| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.100| v_loss: 0.025| per_loss: 0.430 | a_loss: 0.564
Train: Epoch [1582/3000], Step [150/158]| g_loss: 0.743| d_loss: 0.545| gp_loss: 0.057| r_loss: 0.068| p_loss: 0.104| v_loss: 0.025| per_loss: 0.454 | a_loss: 0.552
Train: Epoch [1583/3000], Step [30/158]| g_loss: 0.710| d_loss: 0.713| gp_loss: 0.143| r_loss: 0.072| p_loss: 0.107| v_loss: 0.026| per_loss: 0.429 | a_loss: 0.515
Train: Epoch [1583/3000], Step [60/158]| g_loss: 0.774| d_loss: 0.580| gp_loss: 0.053| r_loss: 0.070| p_loss: 0.112| v_loss: 0.025| per_loss: 0.471 | a_loss: 0.576
Train: Epoch [1583/3000], Step [90/158]| g_loss: 0.742| d_loss: 0.574| gp_loss: 0.056| r_loss: 0.070| p_loss: 0.106| v_loss: 0.025| per_loss: 0.449 | a_loss: 0.549
Train: Epoch [1583/3000], Step [120/158]| g_loss: 0.752| d_loss: 0.548| gp_loss: 0.057| r_loss: 0.069| p_loss: 0.102| v_loss: 0.025| per_loss: 0.447 | a_loss: 0.561
Train: Epoch [1583/3000], Step [150/158]| g_loss: 0.713| d_loss: 0.620| gp_loss: 0.056| r_loss: 0.071| p_loss: 0.106| v_loss: 0.026| per_loss: 0.439 | a_loss: 0.520
Train: Epoch [1584/3000], Step [30/158]| g_loss: 0.753| d_loss: 0.676| gp_loss: 0.102| r_loss: 0.071| p_loss: 0.108| v_loss: 0.025| per_loss: 0.459 | a_loss: 0.557
Train: Epoch [1584/3000], Step [60/158]| g_loss: 0.774| d_loss: 0.511| gp_loss: 0.056| r_loss: 0.071| p_loss: 0.104| v_loss: 0.025| per_loss: 0.457 | a_loss: 0.580
Train: Epoch [1584/3000], Step [90/158]| g_loss: 0.740| d_loss: 0.529| gp_loss: 0.057| r_loss: 0.066| p_loss: 0.099| v_loss: 0.025| per_loss: 0.464 | a_loss: 0.553
Train: Epoch [1584/3000], Step [120/158]| g_loss: 0.721| d_loss: 0.627| gp_loss: 0.055| r_loss: 0.070| p_loss: 0.105| v_loss: 0.026| per_loss: 0.461 | a_loss: 0.526
Train: Epoch [1584/3000], Step [150/158]| g_loss: 0.727| d_loss: 0.680| gp_loss: 0.061| r_loss: 0.072| p_loss: 0.116| v_loss: 0.025| per_loss: 0.444 | a_loss: 0.527
Train: Epoch [1585/3000], Step [30/158]| g_loss: 0.777| d_loss: 0.722| gp_loss: 0.148| r_loss: 0.075| p_loss: 0.127| v_loss: 0.026| per_loss: 0.474 | a_loss: 0.564
Train: Epoch [1585/3000], Step [60/158]| g_loss: 0.740| d_loss: 0.656| gp_loss: 0.061| r_loss: 0.078| p_loss: 0.123| v_loss: 0.026| per_loss: 0.439 | a_loss: 0.531
Train: Epoch [1585/3000], Step [90/158]| g_loss: 0.726| d_loss: 0.598| gp_loss: 0.061| r_loss: 0.072| p_loss: 0.116| v_loss: 0.025| per_loss: 0.462 | a_loss: 0.525
Train: Epoch [1585/3000], Step [120/158]| g_loss: 0.780| d_loss: 0.614| gp_loss: 0.056| r_loss: 0.073| p_loss: 0.118| v_loss: 0.026| per_loss: 0.503 | a_loss: 0.571
Train: Epoch [1585/3000], Step [150/158]| g_loss: 0.768| d_loss: 0.580| gp_loss: 0.059| r_loss: 0.072| p_loss: 0.111| v_loss: 0.026| per_loss: 0.483 | a_loss: 0.566
Train: Epoch [1586/3000], Step [30/158]| g_loss: 0.759| d_loss: 0.678| gp_loss: 0.140| r_loss: 0.071| p_loss: 0.106| v_loss: 0.025| per_loss: 0.467 | a_loss: 0.563
Train: Epoch [1586/3000], Step [60/158]| g_loss: 0.713| d_loss: 0.668| gp_loss: 0.054| r_loss: 0.073| p_loss: 0.114| v_loss: 0.026| per_loss: 0.443 | a_loss: 0.512
Train: Epoch [1586/3000], Step [90/158]| g_loss: 0.744| d_loss: 0.551| gp_loss: 0.055| r_loss: 0.070| p_loss: 0.113| v_loss: 0.027| per_loss: 0.442 | a_loss: 0.547
Train: Epoch [1586/3000], Step [120/158]| g_loss: 0.703| d_loss: 0.662| gp_loss: 0.055| r_loss: 0.071| p_loss: 0.113| v_loss: 0.026| per_loss: 0.454 | a_loss: 0.504
Train: Epoch [1586/3000], Step [150/158]| g_loss: 0.758| d_loss: 0.562| gp_loss: 0.060| r_loss: 0.069| p_loss: 0.102| v_loss: 0.026| per_loss: 0.469 | a_loss: 0.566
Train: Epoch [1587/3000], Step [30/158]| g_loss: 0.767| d_loss: 0.671| gp_loss: 0.183| r_loss: 0.071| p_loss: 0.106| v_loss: 0.025| per_loss: 0.466 | a_loss: 0.572
Train: Epoch [1587/3000], Step [60/158]| g_loss: 0.729| d_loss: 0.635| gp_loss: 0.052| r_loss: 0.069| p_loss: 0.107| v_loss: 0.024| per_loss: 0.426 | a_loss: 0.539
Train: Epoch [1587/3000], Step [90/158]| g_loss: 0.674| d_loss: 0.691| gp_loss: 0.057| r_loss: 0.073| p_loss: 0.111| v_loss: 0.026| per_loss: 0.427 | a_loss: 0.477
Train: Epoch [1587/3000], Step [120/158]| g_loss: 0.755| d_loss: 0.533| gp_loss: 0.056| r_loss: 0.070| p_loss: 0.104| v_loss: 0.026| per_loss: 0.469 | a_loss: 0.560
Train: Epoch [1587/3000], Step [150/158]| g_loss: 0.770| d_loss: 0.562| gp_loss: 0.060| r_loss: 0.069| p_loss: 0.105| v_loss: 0.024| per_loss: 0.470 | a_loss: 0.578
Train: Epoch [1588/3000], Step [30/158]| g_loss: 0.752| d_loss: 0.656| gp_loss: 0.173| r_loss: 0.072| p_loss: 0.105| v_loss: 0.026| per_loss: 0.504 | a_loss: 0.551
Train: Epoch [1588/3000], Step [60/158]| g_loss: 0.740| d_loss: 0.597| gp_loss: 0.054| r_loss: 0.072| p_loss: 0.109| v_loss: 0.027| per_loss: 0.438 | a_loss: 0.542
Train: Epoch [1588/3000], Step [90/158]| g_loss: 0.772| d_loss: 0.565| gp_loss: 0.051| r_loss: 0.071| p_loss: 0.107| v_loss: 0.026| per_loss: 0.464 | a_loss: 0.575
Train: Epoch [1588/3000], Step [120/158]| g_loss: 0.701| d_loss: 0.652| gp_loss: 0.058| r_loss: 0.077| p_loss: 0.119| v_loss: 0.025| per_loss: 0.419 | a_loss: 0.498
Train: Epoch [1588/3000], Step [150/158]| g_loss: 0.772| d_loss: 0.588| gp_loss: 0.059| r_loss: 0.070| p_loss: 0.112| v_loss: 0.024| per_loss: 0.486 | a_loss: 0.572
Train: Epoch [1589/3000], Step [30/158]| g_loss: 0.752| d_loss: 0.727| gp_loss: 0.196| r_loss: 0.069| p_loss: 0.106| v_loss: 0.024| per_loss: 0.459 | a_loss: 0.560
Train: Epoch [1589/3000], Step [60/158]| g_loss: 0.737| d_loss: 0.579| gp_loss: 0.048| r_loss: 0.074| p_loss: 0.111| v_loss: 0.027| per_loss: 0.452 | a_loss: 0.536
Train: Epoch [1589/3000], Step [90/158]| g_loss: 0.795| d_loss: 0.543| gp_loss: 0.052| r_loss: 0.066| p_loss: 0.099| v_loss: 0.025| per_loss: 0.472 | a_loss: 0.608
Train: Epoch [1589/3000], Step [120/158]| g_loss: 0.731| d_loss: 0.619| gp_loss: 0.056| r_loss: 0.072| p_loss: 0.104| v_loss: 0.026| per_loss: 0.452 | a_loss: 0.536
Train: Epoch [1589/3000], Step [150/158]| g_loss: 0.688| d_loss: 0.652| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.103| v_loss: 0.025| per_loss: 0.482 | a_loss: 0.495
Train: Epoch [1590/3000], Step [30/158]| g_loss: 0.734| d_loss: 0.739| gp_loss: 0.137| r_loss: 0.071| p_loss: 0.112| v_loss: 0.027| per_loss: 0.451 | a_loss: 0.535
Train: Epoch [1590/3000], Step [60/158]| g_loss: 0.718| d_loss: 0.576| gp_loss: 0.054| r_loss: 0.073| p_loss: 0.111| v_loss: 0.027| per_loss: 0.458 | a_loss: 0.517
Train: Epoch [1590/3000], Step [90/158]| g_loss: 0.796| d_loss: 0.621| gp_loss: 0.053| r_loss: 0.075| p_loss: 0.118| v_loss: 0.026| per_loss: 0.457 | a_loss: 0.590
Train: Epoch [1590/3000], Step [120/158]| g_loss: 0.693| d_loss: 0.648| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.112| v_loss: 0.024| per_loss: 0.452 | a_loss: 0.497
Train: Epoch [1590/3000], Step [150/158]| g_loss: 0.746| d_loss: 0.622| gp_loss: 0.057| r_loss: 0.079| p_loss: 0.115| v_loss: 0.026| per_loss: 0.490 | a_loss: 0.534
Train: Epoch [1591/3000], Step [30/158]| g_loss: 0.765| d_loss: 0.679| gp_loss: 0.146| r_loss: 0.072| p_loss: 0.109| v_loss: 0.026| per_loss: 0.480 | a_loss: 0.564
Train: Epoch [1591/3000], Step [60/158]| g_loss: 0.742| d_loss: 0.527| gp_loss: 0.057| r_loss: 0.073| p_loss: 0.112| v_loss: 0.026| per_loss: 0.482 | a_loss: 0.538
Train: Epoch [1591/3000], Step [90/158]| g_loss: 0.693| d_loss: 0.676| gp_loss: 0.054| r_loss: 0.069| p_loss: 0.107| v_loss: 0.025| per_loss: 0.440 | a_loss: 0.500
Train: Epoch [1591/3000], Step [120/158]| g_loss: 0.744| d_loss: 0.585| gp_loss: 0.058| r_loss: 0.072| p_loss: 0.109| v_loss: 0.026| per_loss: 0.427 | a_loss: 0.549
Train: Epoch [1591/3000], Step [150/158]| g_loss: 0.761| d_loss: 0.606| gp_loss: 0.060| r_loss: 0.071| p_loss: 0.105| v_loss: 0.026| per_loss: 0.450 | a_loss: 0.568
Train: Epoch [1592/3000], Step [30/158]| g_loss: 0.785| d_loss: 0.655| gp_loss: 0.135| r_loss: 0.072| p_loss: 0.111| v_loss: 0.026| per_loss: 0.452 | a_loss: 0.586
Train: Epoch [1592/3000], Step [60/158]| g_loss: 0.707| d_loss: 0.571| gp_loss: 0.055| r_loss: 0.071| p_loss: 0.104| v_loss: 0.026| per_loss: 0.443 | a_loss: 0.513
Train: Epoch [1592/3000], Step [90/158]| g_loss: 0.724| d_loss: 0.635| gp_loss: 0.057| r_loss: 0.073| p_loss: 0.111| v_loss: 0.026| per_loss: 0.446 | a_loss: 0.525
Train: Epoch [1592/3000], Step [120/158]| g_loss: 0.780| d_loss: 0.620| gp_loss: 0.060| r_loss: 0.074| p_loss: 0.118| v_loss: 0.026| per_loss: 0.441 | a_loss: 0.578
Train: Epoch [1592/3000], Step [150/158]| g_loss: 0.736| d_loss: 0.599| gp_loss: 0.058| r_loss: 0.072| p_loss: 0.109| v_loss: 0.027| per_loss: 0.483 | a_loss: 0.534
Train: Epoch [1593/3000], Step [30/158]| g_loss: 0.696| d_loss: 0.705| gp_loss: 0.126| r_loss: 0.072| p_loss: 0.114| v_loss: 0.024| per_loss: 0.416 | a_loss: 0.501
Train: Epoch [1593/3000], Step [60/158]| g_loss: 0.757| d_loss: 0.658| gp_loss: 0.056| r_loss: 0.074| p_loss: 0.108| v_loss: 0.026| per_loss: 0.488 | a_loss: 0.554
Train: Epoch [1593/3000], Step [90/158]| g_loss: 0.677| d_loss: 0.589| gp_loss: 0.055| r_loss: 0.070| p_loss: 0.102| v_loss: 0.026| per_loss: 0.448 | a_loss: 0.486
Train: Epoch [1593/3000], Step [120/158]| g_loss: 0.791| d_loss: 0.532| gp_loss: 0.056| r_loss: 0.068| p_loss: 0.101| v_loss: 0.027| per_loss: 0.461 | a_loss: 0.599
Train: Epoch [1593/3000], Step [150/158]| g_loss: 0.748| d_loss: 0.653| gp_loss: 0.054| r_loss: 0.071| p_loss: 0.111| v_loss: 0.027| per_loss: 0.455 | a_loss: 0.548
Train: Epoch [1594/3000], Step [30/158]| g_loss: 0.721| d_loss: 0.653| gp_loss: 0.121| r_loss: 0.069| p_loss: 0.101| v_loss: 0.026| per_loss: 0.440 | a_loss: 0.531
Train: Epoch [1594/3000], Step [60/158]| g_loss: 0.763| d_loss: 0.567| gp_loss: 0.059| r_loss: 0.070| p_loss: 0.109| v_loss: 0.026| per_loss: 0.479 | a_loss: 0.565
Train: Epoch [1594/3000], Step [90/158]| g_loss: 0.705| d_loss: 0.662| gp_loss: 0.056| r_loss: 0.071| p_loss: 0.107| v_loss: 0.026| per_loss: 0.474 | a_loss: 0.507
Train: Epoch [1594/3000], Step [120/158]| g_loss: 0.765| d_loss: 0.593| gp_loss: 0.061| r_loss: 0.071| p_loss: 0.110| v_loss: 0.026| per_loss: 0.465 | a_loss: 0.566
Train: Epoch [1594/3000], Step [150/158]| g_loss: 0.737| d_loss: 0.640| gp_loss: 0.056| r_loss: 0.071| p_loss: 0.108| v_loss: 0.026| per_loss: 0.434 | a_loss: 0.543
Train: Epoch [1595/3000], Step [30/158]| g_loss: 0.713| d_loss: 0.730| gp_loss: 0.192| r_loss: 0.071| p_loss: 0.111| v_loss: 0.025| per_loss: 0.436 | a_loss: 0.518
Train: Epoch [1595/3000], Step [60/158]| g_loss: 0.747| d_loss: 0.691| gp_loss: 0.054| r_loss: 0.074| p_loss: 0.113| v_loss: 0.026| per_loss: 0.477 | a_loss: 0.542
Train: Epoch [1595/3000], Step [90/158]| g_loss: 0.753| d_loss: 0.588| gp_loss: 0.055| r_loss: 0.075| p_loss: 0.115| v_loss: 0.027| per_loss: 0.461 | a_loss: 0.548
Train: Epoch [1595/3000], Step [120/158]| g_loss: 0.676| d_loss: 0.669| gp_loss: 0.055| r_loss: 0.072| p_loss: 0.111| v_loss: 0.027| per_loss: 0.437 | a_loss: 0.478
Train: Epoch [1595/3000], Step [150/158]| g_loss: 0.804| d_loss: 0.504| gp_loss: 0.060| r_loss: 0.072| p_loss: 0.107| v_loss: 0.028| per_loss: 0.449 | a_loss: 0.606
Train: Epoch [1596/3000], Step [30/158]| g_loss: 0.765| d_loss: 0.680| gp_loss: 0.168| r_loss: 0.071| p_loss: 0.110| v_loss: 0.026| per_loss: 0.475 | a_loss: 0.566
Train: Epoch [1596/3000], Step [60/158]| g_loss: 0.752| d_loss: 0.539| gp_loss: 0.050| r_loss: 0.071| p_loss: 0.108| v_loss: 0.027| per_loss: 0.507 | a_loss: 0.549
Train: Epoch [1596/3000], Step [90/158]| g_loss: 0.771| d_loss: 0.595| gp_loss: 0.052| r_loss: 0.072| p_loss: 0.106| v_loss: 0.026| per_loss: 0.468 | a_loss: 0.573
Train: Epoch [1596/3000], Step [120/158]| g_loss: 0.753| d_loss: 0.599| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.103| v_loss: 0.026| per_loss: 0.394 | a_loss: 0.569
Train: Epoch [1596/3000], Step [150/158]| g_loss: 0.689| d_loss: 0.669| gp_loss: 0.055| r_loss: 0.073| p_loss: 0.111| v_loss: 0.027| per_loss: 0.427 | a_loss: 0.492
Train: Epoch [1597/3000], Step [30/158]| g_loss: 0.751| d_loss: 0.648| gp_loss: 0.136| r_loss: 0.069| p_loss: 0.109| v_loss: 0.026| per_loss: 0.484 | a_loss: 0.553
Train: Epoch [1597/3000], Step [60/158]| g_loss: 0.725| d_loss: 0.608| gp_loss: 0.051| r_loss: 0.073| p_loss: 0.111| v_loss: 0.026| per_loss: 0.453 | a_loss: 0.525
Train: Epoch [1597/3000], Step [90/158]| g_loss: 0.773| d_loss: 0.599| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.111| v_loss: 0.025| per_loss: 0.436 | a_loss: 0.578
Train: Epoch [1597/3000], Step [120/158]| g_loss: 0.743| d_loss: 0.658| gp_loss: 0.052| r_loss: 0.071| p_loss: 0.114| v_loss: 0.026| per_loss: 0.456 | a_loss: 0.543
Train: Epoch [1597/3000], Step [150/158]| g_loss: 0.690| d_loss: 0.608| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.104| v_loss: 0.027| per_loss: 0.442 | a_loss: 0.495
Train: Epoch [1598/3000], Step [30/158]| g_loss: 0.683| d_loss: 0.751| gp_loss: 0.148| r_loss: 0.070| p_loss: 0.109| v_loss: 0.026| per_loss: 0.415 | a_loss: 0.491
Train: Epoch [1598/3000], Step [60/158]| g_loss: 0.779| d_loss: 0.546| gp_loss: 0.056| r_loss: 0.073| p_loss: 0.117| v_loss: 0.027| per_loss: 0.471 | a_loss: 0.573
Train: Epoch [1598/3000], Step [90/158]| g_loss: 0.720| d_loss: 0.698| gp_loss: 0.055| r_loss: 0.076| p_loss: 0.122| v_loss: 0.026| per_loss: 0.419 | a_loss: 0.515
Train: Epoch [1598/3000], Step [120/158]| g_loss: 0.735| d_loss: 0.615| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.116| v_loss: 0.026| per_loss: 0.477 | a_loss: 0.532
Train: Epoch [1598/3000], Step [150/158]| g_loss: 0.752| d_loss: 0.595| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.108| v_loss: 0.026| per_loss: 0.481 | a_loss: 0.552
Train: Epoch [1599/3000], Step [30/158]| g_loss: 0.746| d_loss: 0.759| gp_loss: 0.197| r_loss: 0.071| p_loss: 0.110| v_loss: 0.026| per_loss: 0.442 | a_loss: 0.549
Train: Epoch [1599/3000], Step [60/158]| g_loss: 0.717| d_loss: 0.624| gp_loss: 0.051| r_loss: 0.071| p_loss: 0.106| v_loss: 0.026| per_loss: 0.467 | a_loss: 0.521
Train: Epoch [1599/3000], Step [90/158]| g_loss: 0.752| d_loss: 0.558| gp_loss: 0.050| r_loss: 0.072| p_loss: 0.110| v_loss: 0.028| per_loss: 0.501 | a_loss: 0.547
Train: Epoch [1599/3000], Step [120/158]| g_loss: 0.759| d_loss: 0.574| gp_loss: 0.051| r_loss: 0.069| p_loss: 0.106| v_loss: 0.025| per_loss: 0.455 | a_loss: 0.566
Train: Epoch [1599/3000], Step [150/158]| g_loss: 0.774| d_loss: 0.617| gp_loss: 0.054| r_loss: 0.069| p_loss: 0.105| v_loss: 0.025| per_loss: 0.453 | a_loss: 0.581
Train: Epoch [1600/3000], Step [30/158]| g_loss: 0.699| d_loss: 0.767| gp_loss: 0.166| r_loss: 0.072| p_loss: 0.111| v_loss: 0.027| per_loss: 0.484 | a_loss: 0.495
Train: Epoch [1600/3000], Step [60/158]| g_loss: 0.678| d_loss: 0.694| gp_loss: 0.053| r_loss: 0.074| p_loss: 0.119| v_loss: 0.027| per_loss: 0.453 | a_loss: 0.472
Train: Epoch [1600/3000], Step [90/158]| g_loss: 0.690| d_loss: 0.651| gp_loss: 0.054| r_loss: 0.071| p_loss: 0.109| v_loss: 0.025| per_loss: 0.457 | a_loss: 0.494
Train: Epoch [1600/3000], Step [120/158]| g_loss: 0.803| d_loss: 0.546| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.113| v_loss: 0.026| per_loss: 0.427 | a_loss: 0.608
Train: Epoch [1600/3000], Step [150/158]| g_loss: 0.735| d_loss: 0.556| gp_loss: 0.055| r_loss: 0.070| p_loss: 0.106| v_loss: 0.025| per_loss: 0.438 | a_loss: 0.542
Test: Epoch [1600/3000]| g_loss: 0.641| r_loss: 0.387| p_loss: 0.292| v_loss: 0.023
Train: Epoch [1601/3000], Step [30/158]| g_loss: 0.731| d_loss: 0.633| gp_loss: 0.052| r_loss: 0.072| p_loss: 0.109| v_loss: 0.026| per_loss: 0.443 | a_loss: 0.534
Train: Epoch [1601/3000], Step [60/158]| g_loss: 0.741| d_loss: 0.556| gp_loss: 0.053| r_loss: 0.071| p_loss: 0.106| v_loss: 0.026| per_loss: 0.449 | a_loss: 0.546
Train: Epoch [1601/3000], Step [90/158]| g_loss: 0.751| d_loss: 0.605| gp_loss: 0.053| r_loss: 0.069| p_loss: 0.104| v_loss: 0.025| per_loss: 0.432 | a_loss: 0.562
Train: Epoch [1601/3000], Step [120/158]| g_loss: 0.642| d_loss: 0.691| gp_loss: 0.056| r_loss: 0.071| p_loss: 0.103| v_loss: 0.026| per_loss: 0.415 | a_loss: 0.452
Train: Epoch [1601/3000], Step [150/158]| g_loss: 0.782| d_loss: 0.513| gp_loss: 0.061| r_loss: 0.071| p_loss: 0.108| v_loss: 0.026| per_loss: 0.475 | a_loss: 0.584
Train: Epoch [1602/3000], Step [30/158]| g_loss: 0.718| d_loss: 0.771| gp_loss: 0.187| r_loss: 0.071| p_loss: 0.111| v_loss: 0.024| per_loss: 0.427 | a_loss: 0.525
Train: Epoch [1602/3000], Step [60/158]| g_loss: 0.745| d_loss: 0.580| gp_loss: 0.052| r_loss: 0.074| p_loss: 0.112| v_loss: 0.024| per_loss: 0.437 | a_loss: 0.548
Train: Epoch [1602/3000], Step [90/158]| g_loss: 0.779| d_loss: 0.554| gp_loss: 0.054| r_loss: 0.071| p_loss: 0.109| v_loss: 0.026| per_loss: 0.498 | a_loss: 0.578
Train: Epoch [1602/3000], Step [120/158]| g_loss: 0.742| d_loss: 0.644| gp_loss: 0.057| r_loss: 0.069| p_loss: 0.104| v_loss: 0.025| per_loss: 0.438 | a_loss: 0.552
Train: Epoch [1602/3000], Step [150/158]| g_loss: 0.686| d_loss: 0.674| gp_loss: 0.054| r_loss: 0.071| p_loss: 0.104| v_loss: 0.027| per_loss: 0.488 | a_loss: 0.487
Train: Epoch [1603/3000], Step [30/158]| g_loss: 0.733| d_loss: 0.673| gp_loss: 0.139| r_loss: 0.070| p_loss: 0.105| v_loss: 0.026| per_loss: 0.473 | a_loss: 0.537
Train: Epoch [1603/3000], Step [60/158]| g_loss: 0.756| d_loss: 0.583| gp_loss: 0.053| r_loss: 0.067| p_loss: 0.099| v_loss: 0.026| per_loss: 0.452 | a_loss: 0.569
Train: Epoch [1603/3000], Step [90/158]| g_loss: 0.684| d_loss: 0.687| gp_loss: 0.052| r_loss: 0.069| p_loss: 0.105| v_loss: 0.024| per_loss: 0.432 | a_loss: 0.495
Train: Epoch [1603/3000], Step [120/158]| g_loss: 0.764| d_loss: 0.577| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.106| v_loss: 0.026| per_loss: 0.482 | a_loss: 0.565
Train: Epoch [1603/3000], Step [150/158]| g_loss: 0.792| d_loss: 0.524| gp_loss: 0.060| r_loss: 0.071| p_loss: 0.109| v_loss: 0.026| per_loss: 0.461 | a_loss: 0.594
Train: Epoch [1604/3000], Step [30/158]| g_loss: 0.725| d_loss: 0.697| gp_loss: 0.144| r_loss: 0.071| p_loss: 0.103| v_loss: 0.025| per_loss: 0.463 | a_loss: 0.531
Train: Epoch [1604/3000], Step [60/158]| g_loss: 0.787| d_loss: 0.521| gp_loss: 0.055| r_loss: 0.076| p_loss: 0.117| v_loss: 0.026| per_loss: 0.425 | a_loss: 0.584
Train: Epoch [1604/3000], Step [90/158]| g_loss: 0.724| d_loss: 0.648| gp_loss: 0.054| r_loss: 0.071| p_loss: 0.109| v_loss: 0.026| per_loss: 0.469 | a_loss: 0.526
Train: Epoch [1604/3000], Step [120/158]| g_loss: 0.688| d_loss: 0.639| gp_loss: 0.053| r_loss: 0.069| p_loss: 0.105| v_loss: 0.024| per_loss: 0.464 | a_loss: 0.495
Train: Epoch [1604/3000], Step [150/158]| g_loss: 0.765| d_loss: 0.564| gp_loss: 0.060| r_loss: 0.072| p_loss: 0.109| v_loss: 0.026| per_loss: 0.426 | a_loss: 0.570
Train: Epoch [1605/3000], Step [30/158]| g_loss: 0.723| d_loss: 0.731| gp_loss: 0.120| r_loss: 0.072| p_loss: 0.109| v_loss: 0.025| per_loss: 0.456 | a_loss: 0.525
Train: Epoch [1605/3000], Step [60/158]| g_loss: 0.730| d_loss: 0.568| gp_loss: 0.060| r_loss: 0.069| p_loss: 0.104| v_loss: 0.026| per_loss: 0.446 | a_loss: 0.538
Train: Epoch [1605/3000], Step [90/158]| g_loss: 0.732| d_loss: 0.594| gp_loss: 0.051| r_loss: 0.068| p_loss: 0.109| v_loss: 0.026| per_loss: 0.443 | a_loss: 0.538
Train: Epoch [1605/3000], Step [120/158]| g_loss: 0.784| d_loss: 0.593| gp_loss: 0.057| r_loss: 0.072| p_loss: 0.111| v_loss: 0.026| per_loss: 0.478 | a_loss: 0.583
Train: Epoch [1605/3000], Step [150/158]| g_loss: 0.760| d_loss: 0.579| gp_loss: 0.061| r_loss: 0.071| p_loss: 0.106| v_loss: 0.026| per_loss: 0.466 | a_loss: 0.565
Train: Epoch [1606/3000], Step [30/158]| g_loss: 0.738| d_loss: 0.783| gp_loss: 0.202| r_loss: 0.071| p_loss: 0.113| v_loss: 0.025| per_loss: 0.443 | a_loss: 0.541
Train: Epoch [1606/3000], Step [60/158]| g_loss: 0.711| d_loss: 0.697| gp_loss: 0.051| r_loss: 0.072| p_loss: 0.120| v_loss: 0.025| per_loss: 0.444 | a_loss: 0.510
Train: Epoch [1606/3000], Step [90/158]| g_loss: 0.684| d_loss: 0.609| gp_loss: 0.052| r_loss: 0.071| p_loss: 0.105| v_loss: 0.025| per_loss: 0.449 | a_loss: 0.490
Train: Epoch [1606/3000], Step [120/158]| g_loss: 0.723| d_loss: 0.618| gp_loss: 0.054| r_loss: 0.068| p_loss: 0.106| v_loss: 0.026| per_loss: 0.424 | a_loss: 0.534
Train: Epoch [1606/3000], Step [150/158]| g_loss: 0.775| d_loss: 0.550| gp_loss: 0.057| r_loss: 0.070| p_loss: 0.106| v_loss: 0.025| per_loss: 0.415 | a_loss: 0.585
Train: Epoch [1607/3000], Step [30/158]| g_loss: 0.705| d_loss: 0.704| gp_loss: 0.100| r_loss: 0.071| p_loss: 0.106| v_loss: 0.026| per_loss: 0.433 | a_loss: 0.511
Train: Epoch [1607/3000], Step [60/158]| g_loss: 0.700| d_loss: 0.605| gp_loss: 0.055| r_loss: 0.071| p_loss: 0.105| v_loss: 0.025| per_loss: 0.414 | a_loss: 0.510
Train: Epoch [1607/3000], Step [90/158]| g_loss: 0.690| d_loss: 0.633| gp_loss: 0.055| r_loss: 0.071| p_loss: 0.106| v_loss: 0.026| per_loss: 0.423 | a_loss: 0.497
Train: Epoch [1607/3000], Step [120/158]| g_loss: 0.783| d_loss: 0.502| gp_loss: 0.059| r_loss: 0.069| p_loss: 0.105| v_loss: 0.026| per_loss: 0.402 | a_loss: 0.595
Train: Epoch [1607/3000], Step [150/158]| g_loss: 0.756| d_loss: 0.640| gp_loss: 0.057| r_loss: 0.068| p_loss: 0.107| v_loss: 0.025| per_loss: 0.391 | a_loss: 0.571
Train: Epoch [1608/3000], Step [30/158]| g_loss: 0.734| d_loss: 0.624| gp_loss: 0.141| r_loss: 0.069| p_loss: 0.104| v_loss: 0.025| per_loss: 0.388 | a_loss: 0.549
Train: Epoch [1608/3000], Step [60/158]| g_loss: 0.754| d_loss: 0.597| gp_loss: 0.055| r_loss: 0.069| p_loss: 0.099| v_loss: 0.025| per_loss: 0.375 | a_loss: 0.573
Train: Epoch [1608/3000], Step [90/158]| g_loss: 0.718| d_loss: 0.611| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.102| v_loss: 0.025| per_loss: 0.394 | a_loss: 0.534
Train: Epoch [1608/3000], Step [120/158]| g_loss: 0.721| d_loss: 0.620| gp_loss: 0.058| r_loss: 0.071| p_loss: 0.110| v_loss: 0.026| per_loss: 0.406 | a_loss: 0.529
Train: Epoch [1608/3000], Step [150/158]| g_loss: 0.690| d_loss: 0.623| gp_loss: 0.059| r_loss: 0.068| p_loss: 0.100| v_loss: 0.024| per_loss: 0.383 | a_loss: 0.510
Train: Epoch [1609/3000], Step [30/158]| g_loss: 0.689| d_loss: 0.739| gp_loss: 0.156| r_loss: 0.069| p_loss: 0.102| v_loss: 0.025| per_loss: 0.372 | a_loss: 0.506
Train: Epoch [1609/3000], Step [60/158]| g_loss: 0.671| d_loss: 0.659| gp_loss: 0.054| r_loss: 0.068| p_loss: 0.101| v_loss: 0.025| per_loss: 0.381 | a_loss: 0.489
Train: Epoch [1609/3000], Step [90/158]| g_loss: 0.677| d_loss: 0.619| gp_loss: 0.056| r_loss: 0.068| p_loss: 0.099| v_loss: 0.025| per_loss: 0.377 | a_loss: 0.497
Train: Epoch [1609/3000], Step [120/158]| g_loss: 0.785| d_loss: 0.533| gp_loss: 0.061| r_loss: 0.069| p_loss: 0.107| v_loss: 0.025| per_loss: 0.360 | a_loss: 0.601
Train: Epoch [1609/3000], Step [150/158]| g_loss: 0.702| d_loss: 0.641| gp_loss: 0.056| r_loss: 0.071| p_loss: 0.110| v_loss: 0.025| per_loss: 0.344 | a_loss: 0.517
Train: Epoch [1610/3000], Step [30/158]| g_loss: 0.767| d_loss: 0.648| gp_loss: 0.146| r_loss: 0.068| p_loss: 0.101| v_loss: 0.026| per_loss: 0.370 | a_loss: 0.586
Train: Epoch [1610/3000], Step [60/158]| g_loss: 0.732| d_loss: 0.589| gp_loss: 0.052| r_loss: 0.069| p_loss: 0.101| v_loss: 0.026| per_loss: 0.372 | a_loss: 0.549
Train: Epoch [1610/3000], Step [90/158]| g_loss: 0.710| d_loss: 0.643| gp_loss: 0.055| r_loss: 0.069| p_loss: 0.103| v_loss: 0.026| per_loss: 0.364 | a_loss: 0.527
Train: Epoch [1610/3000], Step [120/158]| g_loss: 0.741| d_loss: 0.526| gp_loss: 0.058| r_loss: 0.066| p_loss: 0.099| v_loss: 0.025| per_loss: 0.355 | a_loss: 0.566
Train: Epoch [1610/3000], Step [150/158]| g_loss: 0.694| d_loss: 0.655| gp_loss: 0.057| r_loss: 0.069| p_loss: 0.109| v_loss: 0.025| per_loss: 0.375 | a_loss: 0.508
Train: Epoch [1611/3000], Step [30/158]| g_loss: 0.680| d_loss: 0.746| gp_loss: 0.118| r_loss: 0.069| p_loss: 0.106| v_loss: 0.024| per_loss: 0.357 | a_loss: 0.498
Train: Epoch [1611/3000], Step [60/158]| g_loss: 0.708| d_loss: 0.547| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.110| v_loss: 0.026| per_loss: 0.372 | a_loss: 0.519
Train: Epoch [1611/3000], Step [90/158]| g_loss: 0.745| d_loss: 0.611| gp_loss: 0.056| r_loss: 0.069| p_loss: 0.103| v_loss: 0.025| per_loss: 0.358 | a_loss: 0.564
Train: Epoch [1611/3000], Step [120/158]| g_loss: 0.688| d_loss: 0.659| gp_loss: 0.059| r_loss: 0.070| p_loss: 0.106| v_loss: 0.025| per_loss: 0.363 | a_loss: 0.503
Train: Epoch [1611/3000], Step [150/158]| g_loss: 0.717| d_loss: 0.592| gp_loss: 0.062| r_loss: 0.070| p_loss: 0.104| v_loss: 0.026| per_loss: 0.367 | a_loss: 0.532
Train: Epoch [1612/3000], Step [30/158]| g_loss: 0.669| d_loss: 0.769| gp_loss: 0.163| r_loss: 0.070| p_loss: 0.106| v_loss: 0.025| per_loss: 0.345 | a_loss: 0.485
Train: Epoch [1612/3000], Step [60/158]| g_loss: 0.782| d_loss: 0.562| gp_loss: 0.059| r_loss: 0.072| p_loss: 0.104| v_loss: 0.026| per_loss: 0.374 | a_loss: 0.595
Train: Epoch [1612/3000], Step [90/158]| g_loss: 0.681| d_loss: 0.694| gp_loss: 0.057| r_loss: 0.070| p_loss: 0.111| v_loss: 0.025| per_loss: 0.364 | a_loss: 0.493
Train: Epoch [1612/3000], Step [120/158]| g_loss: 0.779| d_loss: 0.524| gp_loss: 0.058| r_loss: 0.071| p_loss: 0.107| v_loss: 0.026| per_loss: 0.375 | a_loss: 0.591
Train: Epoch [1612/3000], Step [150/158]| g_loss: 0.720| d_loss: 0.586| gp_loss: 0.058| r_loss: 0.068| p_loss: 0.103| v_loss: 0.024| per_loss: 0.353 | a_loss: 0.540
Train: Epoch [1613/3000], Step [30/158]| g_loss: 0.698| d_loss: 0.708| gp_loss: 0.153| r_loss: 0.066| p_loss: 0.101| v_loss: 0.024| per_loss: 0.366 | a_loss: 0.520
Train: Epoch [1613/3000], Step [60/158]| g_loss: 0.851| d_loss: 0.467| gp_loss: 0.057| r_loss: 0.070| p_loss: 0.107| v_loss: 0.026| per_loss: 0.348 | a_loss: 0.666
Train: Epoch [1613/3000], Step [90/158]| g_loss: 0.713| d_loss: 0.615| gp_loss: 0.054| r_loss: 0.069| p_loss: 0.102| v_loss: 0.025| per_loss: 0.370 | a_loss: 0.531
Train: Epoch [1613/3000], Step [120/158]| g_loss: 0.664| d_loss: 0.685| gp_loss: 0.057| r_loss: 0.066| p_loss: 0.102| v_loss: 0.025| per_loss: 0.361 | a_loss: 0.485
Train: Epoch [1613/3000], Step [150/158]| g_loss: 0.673| d_loss: 0.654| gp_loss: 0.059| r_loss: 0.068| p_loss: 0.099| v_loss: 0.026| per_loss: 0.359 | a_loss: 0.494
Train: Epoch [1614/3000], Step [30/158]| g_loss: 0.760| d_loss: 0.694| gp_loss: 0.203| r_loss: 0.069| p_loss: 0.097| v_loss: 0.025| per_loss: 0.367 | a_loss: 0.580
Train: Epoch [1614/3000], Step [60/158]| g_loss: 0.683| d_loss: 0.625| gp_loss: 0.051| r_loss: 0.068| p_loss: 0.099| v_loss: 0.025| per_loss: 0.365 | a_loss: 0.504
Train: Epoch [1614/3000], Step [90/158]| g_loss: 0.703| d_loss: 0.584| gp_loss: 0.055| r_loss: 0.070| p_loss: 0.108| v_loss: 0.026| per_loss: 0.368 | a_loss: 0.517
Train: Epoch [1614/3000], Step [120/158]| g_loss: 0.776| d_loss: 0.570| gp_loss: 0.054| r_loss: 0.070| p_loss: 0.106| v_loss: 0.026| per_loss: 0.353 | a_loss: 0.592
Train: Epoch [1614/3000], Step [150/158]| g_loss: 0.674| d_loss: 0.657| gp_loss: 0.056| r_loss: 0.070| p_loss: 0.106| v_loss: 0.025| per_loss: 0.357 | a_loss: 0.492
Train: Epoch [1615/3000], Step [30/158]| g_loss: 0.726| d_loss: 0.733| gp_loss: 0.135| r_loss: 0.069| p_loss: 0.107| v_loss: 0.025| per_loss: 0.396 | a_loss: 0.538
Train: Epoch [1615/3000], Step [60/158]| g_loss: 0.675| d_loss: 0.668| gp_loss: 0.055| r_loss: 0.070| p_loss: 0.106| v_loss: 0.025| per_loss: 0.350 | a_loss: 0.491
Train: Epoch [1615/3000], Step [90/158]| g_loss: 0.716| d_loss: 0.597| gp_loss: 0.058| r_loss: 0.073| p_loss: 0.113| v_loss: 0.026| per_loss: 0.379 | a_loss: 0.523
Train: Epoch [1615/3000], Step [120/158]| g_loss: 0.743| d_loss: 0.613| gp_loss: 0.053| r_loss: 0.074| p_loss: 0.112| v_loss: 0.026| per_loss: 0.346 | a_loss: 0.553
Train: Epoch [1615/3000], Step [150/158]| g_loss: 0.744| d_loss: 0.513| gp_loss: 0.060| r_loss: 0.067| p_loss: 0.101| v_loss: 0.026| per_loss: 0.367 | a_loss: 0.564
Train: Epoch [1616/3000], Step [30/158]| g_loss: 0.739| d_loss: 0.785| gp_loss: 0.221| r_loss: 0.072| p_loss: 0.105| v_loss: 0.025| per_loss: 0.357 | a_loss: 0.554
Train: Epoch [1616/3000], Step [60/158]| g_loss: 0.764| d_loss: 0.542| gp_loss: 0.051| r_loss: 0.071| p_loss: 0.103| v_loss: 0.026| per_loss: 0.348 | a_loss: 0.580
Train: Epoch [1616/3000], Step [90/158]| g_loss: 0.728| d_loss: 0.630| gp_loss: 0.051| r_loss: 0.068| p_loss: 0.104| v_loss: 0.025| per_loss: 0.365 | a_loss: 0.547
Train: Epoch [1616/3000], Step [120/158]| g_loss: 0.737| d_loss: 0.553| gp_loss: 0.054| r_loss: 0.068| p_loss: 0.100| v_loss: 0.025| per_loss: 0.353 | a_loss: 0.558
Train: Epoch [1616/3000], Step [150/158]| g_loss: 0.703| d_loss: 0.629| gp_loss: 0.052| r_loss: 0.069| p_loss: 0.101| v_loss: 0.025| per_loss: 0.368 | a_loss: 0.522
Train: Epoch [1617/3000], Step [30/158]| g_loss: 0.730| d_loss: 0.676| gp_loss: 0.143| r_loss: 0.076| p_loss: 0.117| v_loss: 0.026| per_loss: 0.351 | a_loss: 0.534
Train: Epoch [1617/3000], Step [60/158]| g_loss: 0.729| d_loss: 0.552| gp_loss: 0.051| r_loss: 0.073| p_loss: 0.109| v_loss: 0.024| per_loss: 0.346 | a_loss: 0.542
Train: Epoch [1617/3000], Step [90/158]| g_loss: 0.717| d_loss: 0.603| gp_loss: 0.055| r_loss: 0.070| p_loss: 0.102| v_loss: 0.025| per_loss: 0.369 | a_loss: 0.535
Train: Epoch [1617/3000], Step [120/158]| g_loss: 0.678| d_loss: 0.679| gp_loss: 0.055| r_loss: 0.069| p_loss: 0.104| v_loss: 0.024| per_loss: 0.341 | a_loss: 0.499
Train: Epoch [1617/3000], Step [150/158]| g_loss: 0.755| d_loss: 0.573| gp_loss: 0.060| r_loss: 0.070| p_loss: 0.109| v_loss: 0.026| per_loss: 0.364 | a_loss: 0.567
Train: Epoch [1618/3000], Step [30/158]| g_loss: 0.716| d_loss: 0.745| gp_loss: 0.161| r_loss: 0.075| p_loss: 0.115| v_loss: 0.025| per_loss: 0.348 | a_loss: 0.523
Train: Epoch [1618/3000], Step [60/158]| g_loss: 0.688| d_loss: 0.629| gp_loss: 0.056| r_loss: 0.069| p_loss: 0.106| v_loss: 0.025| per_loss: 0.346 | a_loss: 0.506
Train: Epoch [1618/3000], Step [90/158]| g_loss: 0.757| d_loss: 0.594| gp_loss: 0.054| r_loss: 0.071| p_loss: 0.105| v_loss: 0.025| per_loss: 0.376 | a_loss: 0.571
Train: Epoch [1618/3000], Step [120/158]| g_loss: 0.775| d_loss: 0.564| gp_loss: 0.062| r_loss: 0.069| p_loss: 0.107| v_loss: 0.026| per_loss: 0.362 | a_loss: 0.591
Train: Epoch [1618/3000], Step [150/158]| g_loss: 0.692| d_loss: 0.619| gp_loss: 0.053| r_loss: 0.072| p_loss: 0.106| v_loss: 0.025| per_loss: 0.357 | a_loss: 0.507
Train: Epoch [1619/3000], Step [30/158]| g_loss: 0.716| d_loss: 0.705| gp_loss: 0.168| r_loss: 0.073| p_loss: 0.110| v_loss: 0.024| per_loss: 0.350 | a_loss: 0.528
Train: Epoch [1619/3000], Step [60/158]| g_loss: 0.726| d_loss: 0.625| gp_loss: 0.053| r_loss: 0.068| p_loss: 0.105| v_loss: 0.025| per_loss: 0.338 | a_loss: 0.546
Train: Epoch [1619/3000], Step [90/158]| g_loss: 0.678| d_loss: 0.622| gp_loss: 0.055| r_loss: 0.070| p_loss: 0.102| v_loss: 0.025| per_loss: 0.367 | a_loss: 0.494
Train: Epoch [1619/3000], Step [120/158]| g_loss: 0.801| d_loss: 0.594| gp_loss: 0.055| r_loss: 0.070| p_loss: 0.106| v_loss: 0.025| per_loss: 0.350 | a_loss: 0.618
Train: Epoch [1619/3000], Step [150/158]| g_loss: 0.742| d_loss: 0.562| gp_loss: 0.054| r_loss: 0.071| p_loss: 0.109| v_loss: 0.027| per_loss: 0.379 | a_loss: 0.552
Train: Epoch [1620/3000], Step [30/158]| g_loss: 0.632| d_loss: 0.771| gp_loss: 0.109| r_loss: 0.069| p_loss: 0.108| v_loss: 0.024| per_loss: 0.354 | a_loss: 0.449
Train: Epoch [1620/3000], Step [60/158]| g_loss: 0.814| d_loss: 0.566| gp_loss: 0.056| r_loss: 0.069| p_loss: 0.107| v_loss: 0.025| per_loss: 0.357 | a_loss: 0.631
Train: Epoch [1620/3000], Step [90/158]| g_loss: 0.703| d_loss: 0.536| gp_loss: 0.056| r_loss: 0.071| p_loss: 0.104| v_loss: 0.025| per_loss: 0.335 | a_loss: 0.521
Train: Epoch [1620/3000], Step [120/158]| g_loss: 0.798| d_loss: 0.572| gp_loss: 0.056| r_loss: 0.069| p_loss: 0.107| v_loss: 0.026| per_loss: 0.357 | a_loss: 0.614
Train: Epoch [1620/3000], Step [150/158]| g_loss: 0.656| d_loss: 0.676| gp_loss: 0.057| r_loss: 0.069| p_loss: 0.099| v_loss: 0.025| per_loss: 0.365 | a_loss: 0.476
Train: Epoch [1621/3000], Step [30/158]| g_loss: 0.673| d_loss: 0.733| gp_loss: 0.132| r_loss: 0.067| p_loss: 0.101| v_loss: 0.026| per_loss: 0.373 | a_loss: 0.493
Train: Epoch [1621/3000], Step [60/158]| g_loss: 0.729| d_loss: 0.600| gp_loss: 0.056| r_loss: 0.071| p_loss: 0.104| v_loss: 0.026| per_loss: 0.352 | a_loss: 0.545
Train: Epoch [1621/3000], Step [90/158]| g_loss: 0.745| d_loss: 0.574| gp_loss: 0.058| r_loss: 0.067| p_loss: 0.108| v_loss: 0.026| per_loss: 0.346 | a_loss: 0.563
Train: Epoch [1621/3000], Step [120/158]| g_loss: 0.753| d_loss: 0.586| gp_loss: 0.057| r_loss: 0.069| p_loss: 0.106| v_loss: 0.025| per_loss: 0.379 | a_loss: 0.567
Train: Epoch [1621/3000], Step [150/158]| g_loss: 0.752| d_loss: 0.621| gp_loss: 0.056| r_loss: 0.069| p_loss: 0.104| v_loss: 0.024| per_loss: 0.354 | a_loss: 0.572
Train: Epoch [1622/3000], Step [30/158]| g_loss: 0.676| d_loss: 0.825| gp_loss: 0.189| r_loss: 0.069| p_loss: 0.107| v_loss: 0.026| per_loss: 0.355 | a_loss: 0.492
Train: Epoch [1622/3000], Step [60/158]| g_loss: 0.820| d_loss: 0.469| gp_loss: 0.059| r_loss: 0.066| p_loss: 0.110| v_loss: 0.026| per_loss: 0.357 | a_loss: 0.638
Train: Epoch [1622/3000], Step [90/158]| g_loss: 0.691| d_loss: 0.656| gp_loss: 0.052| r_loss: 0.072| p_loss: 0.110| v_loss: 0.027| per_loss: 0.350 | a_loss: 0.502
Train: Epoch [1622/3000], Step [120/158]| g_loss: 0.782| d_loss: 0.625| gp_loss: 0.053| r_loss: 0.069| p_loss: 0.102| v_loss: 0.025| per_loss: 0.362 | a_loss: 0.601
Train: Epoch [1622/3000], Step [150/158]| g_loss: 0.673| d_loss: 0.636| gp_loss: 0.054| r_loss: 0.071| p_loss: 0.108| v_loss: 0.026| per_loss: 0.344 | a_loss: 0.487
Train: Epoch [1623/3000], Step [30/158]| g_loss: 0.747| d_loss: 0.665| gp_loss: 0.155| r_loss: 0.069| p_loss: 0.103| v_loss: 0.026| per_loss: 0.358 | a_loss: 0.565
Train: Epoch [1623/3000], Step [60/158]| g_loss: 0.690| d_loss: 0.674| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.101| v_loss: 0.025| per_loss: 0.323 | a_loss: 0.515
Train: Epoch [1623/3000], Step [90/158]| g_loss: 0.710| d_loss: 0.522| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.102| v_loss: 0.027| per_loss: 0.350 | a_loss: 0.529
Train: Epoch [1623/3000], Step [120/158]| g_loss: 0.775| d_loss: 0.591| gp_loss: 0.057| r_loss: 0.072| p_loss: 0.107| v_loss: 0.026| per_loss: 0.373 | a_loss: 0.587
Train: Epoch [1623/3000], Step [150/158]| g_loss: 0.714| d_loss: 0.665| gp_loss: 0.056| r_loss: 0.074| p_loss: 0.113| v_loss: 0.026| per_loss: 0.349 | a_loss: 0.523
Train: Epoch [1624/3000], Step [30/158]| g_loss: 0.705| d_loss: 0.725| gp_loss: 0.144| r_loss: 0.070| p_loss: 0.113| v_loss: 0.026| per_loss: 0.346 | a_loss: 0.518
Train: Epoch [1624/3000], Step [60/158]| g_loss: 0.770| d_loss: 0.531| gp_loss: 0.058| r_loss: 0.069| p_loss: 0.105| v_loss: 0.027| per_loss: 0.352 | a_loss: 0.586
Train: Epoch [1624/3000], Step [90/158]| g_loss: 0.737| d_loss: 0.631| gp_loss: 0.054| r_loss: 0.069| p_loss: 0.108| v_loss: 0.025| per_loss: 0.346 | a_loss: 0.554
Train: Epoch [1624/3000], Step [120/158]| g_loss: 0.754| d_loss: 0.610| gp_loss: 0.059| r_loss: 0.074| p_loss: 0.110| v_loss: 0.026| per_loss: 0.371 | a_loss: 0.562
Train: Epoch [1624/3000], Step [150/158]| g_loss: 0.719| d_loss: 0.642| gp_loss: 0.057| r_loss: 0.070| p_loss: 0.105| v_loss: 0.027| per_loss: 0.358 | a_loss: 0.533
Train: Epoch [1625/3000], Step [30/158]| g_loss: 0.704| d_loss: 0.707| gp_loss: 0.125| r_loss: 0.072| p_loss: 0.110| v_loss: 0.027| per_loss: 0.351 | a_loss: 0.516
Train: Epoch [1625/3000], Step [60/158]| g_loss: 0.718| d_loss: 0.614| gp_loss: 0.057| r_loss: 0.070| p_loss: 0.105| v_loss: 0.025| per_loss: 0.358 | a_loss: 0.534
Train: Epoch [1625/3000], Step [90/158]| g_loss: 0.727| d_loss: 0.572| gp_loss: 0.057| r_loss: 0.067| p_loss: 0.098| v_loss: 0.025| per_loss: 0.335 | a_loss: 0.552
Train: Epoch [1625/3000], Step [120/158]| g_loss: 0.705| d_loss: 0.627| gp_loss: 0.057| r_loss: 0.069| p_loss: 0.105| v_loss: 0.025| per_loss: 0.343 | a_loss: 0.525
Train: Epoch [1625/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.666| gp_loss: 0.059| r_loss: 0.068| p_loss: 0.105| v_loss: 0.026| per_loss: 0.351 | a_loss: 0.479
Train: Epoch [1626/3000], Step [30/158]| g_loss: 0.735| d_loss: 0.680| gp_loss: 0.169| r_loss: 0.071| p_loss: 0.108| v_loss: 0.026| per_loss: 0.342 | a_loss: 0.550
Train: Epoch [1626/3000], Step [60/158]| g_loss: 0.728| d_loss: 0.581| gp_loss: 0.055| r_loss: 0.067| p_loss: 0.098| v_loss: 0.026| per_loss: 0.344 | a_loss: 0.552
Train: Epoch [1626/3000], Step [90/158]| g_loss: 0.711| d_loss: 0.669| gp_loss: 0.056| r_loss: 0.071| p_loss: 0.103| v_loss: 0.026| per_loss: 0.361 | a_loss: 0.527
Train: Epoch [1626/3000], Step [120/158]| g_loss: 0.718| d_loss: 0.577| gp_loss: 0.058| r_loss: 0.070| p_loss: 0.107| v_loss: 0.027| per_loss: 0.350 | a_loss: 0.533
Train: Epoch [1626/3000], Step [150/158]| g_loss: 0.750| d_loss: 0.603| gp_loss: 0.057| r_loss: 0.068| p_loss: 0.110| v_loss: 0.027| per_loss: 0.342 | a_loss: 0.565
Train: Epoch [1627/3000], Step [30/158]| g_loss: 0.748| d_loss: 0.742| gp_loss: 0.189| r_loss: 0.072| p_loss: 0.114| v_loss: 0.026| per_loss: 0.365 | a_loss: 0.557
Train: Epoch [1627/3000], Step [60/158]| g_loss: 0.741| d_loss: 0.589| gp_loss: 0.052| r_loss: 0.070| p_loss: 0.108| v_loss: 0.027| per_loss: 0.334 | a_loss: 0.557
Train: Epoch [1627/3000], Step [90/158]| g_loss: 0.660| d_loss: 0.669| gp_loss: 0.049| r_loss: 0.067| p_loss: 0.098| v_loss: 0.025| per_loss: 0.349 | a_loss: 0.484
Train: Epoch [1627/3000], Step [120/158]| g_loss: 0.692| d_loss: 0.617| gp_loss: 0.057| r_loss: 0.069| p_loss: 0.104| v_loss: 0.026| per_loss: 0.360 | a_loss: 0.509
Train: Epoch [1627/3000], Step [150/158]| g_loss: 0.719| d_loss: 0.594| gp_loss: 0.056| r_loss: 0.066| p_loss: 0.099| v_loss: 0.026| per_loss: 0.354 | a_loss: 0.543
Train: Epoch [1628/3000], Step [30/158]| g_loss: 0.741| d_loss: 0.691| gp_loss: 0.146| r_loss: 0.070| p_loss: 0.100| v_loss: 0.025| per_loss: 0.359 | a_loss: 0.560
Train: Epoch [1628/3000], Step [60/158]| g_loss: 0.719| d_loss: 0.555| gp_loss: 0.054| r_loss: 0.068| p_loss: 0.099| v_loss: 0.027| per_loss: 0.343 | a_loss: 0.541
Train: Epoch [1628/3000], Step [90/158]| g_loss: 0.774| d_loss: 0.595| gp_loss: 0.051| r_loss: 0.068| p_loss: 0.105| v_loss: 0.025| per_loss: 0.357 | a_loss: 0.593
Train: Epoch [1628/3000], Step [120/158]| g_loss: 0.661| d_loss: 0.648| gp_loss: 0.053| r_loss: 0.066| p_loss: 0.100| v_loss: 0.026| per_loss: 0.358 | a_loss: 0.483
Train: Epoch [1628/3000], Step [150/158]| g_loss: 0.697| d_loss: 0.628| gp_loss: 0.058| r_loss: 0.069| p_loss: 0.099| v_loss: 0.026| per_loss: 0.344 | a_loss: 0.519
Train: Epoch [1629/3000], Step [30/158]| g_loss: 0.742| d_loss: 0.636| gp_loss: 0.134| r_loss: 0.069| p_loss: 0.102| v_loss: 0.026| per_loss: 0.352 | a_loss: 0.561
Train: Epoch [1629/3000], Step [60/158]| g_loss: 0.728| d_loss: 0.574| gp_loss: 0.053| r_loss: 0.070| p_loss: 0.100| v_loss: 0.025| per_loss: 0.351 | a_loss: 0.548
Train: Epoch [1629/3000], Step [90/158]| g_loss: 0.738| d_loss: 0.625| gp_loss: 0.055| r_loss: 0.066| p_loss: 0.100| v_loss: 0.026| per_loss: 0.339 | a_loss: 0.562
Train: Epoch [1629/3000], Step [120/158]| g_loss: 0.689| d_loss: 0.681| gp_loss: 0.054| r_loss: 0.067| p_loss: 0.107| v_loss: 0.025| per_loss: 0.347 | a_loss: 0.509
Train: Epoch [1629/3000], Step [150/158]| g_loss: 0.720| d_loss: 0.611| gp_loss: 0.056| r_loss: 0.071| p_loss: 0.107| v_loss: 0.027| per_loss: 0.351 | a_loss: 0.533
Train: Epoch [1630/3000], Step [30/158]| g_loss: 0.731| d_loss: 0.688| gp_loss: 0.202| r_loss: 0.069| p_loss: 0.104| v_loss: 0.026| per_loss: 0.353 | a_loss: 0.549
Train: Epoch [1630/3000], Step [60/158]| g_loss: 0.751| d_loss: 0.634| gp_loss: 0.051| r_loss: 0.069| p_loss: 0.109| v_loss: 0.025| per_loss: 0.349 | a_loss: 0.567
Train: Epoch [1630/3000], Step [90/158]| g_loss: 0.720| d_loss: 0.535| gp_loss: 0.051| r_loss: 0.065| p_loss: 0.097| v_loss: 0.025| per_loss: 0.355 | a_loss: 0.546
Train: Epoch [1630/3000], Step [120/158]| g_loss: 0.695| d_loss: 0.667| gp_loss: 0.053| r_loss: 0.070| p_loss: 0.106| v_loss: 0.026| per_loss: 0.347 | a_loss: 0.512
Train: Epoch [1630/3000], Step [150/158]| g_loss: 0.719| d_loss: 0.675| gp_loss: 0.058| r_loss: 0.068| p_loss: 0.101| v_loss: 0.025| per_loss: 0.364 | a_loss: 0.539
Train: Epoch [1631/3000], Step [30/158]| g_loss: 0.694| d_loss: 0.660| gp_loss: 0.126| r_loss: 0.067| p_loss: 0.102| v_loss: 0.025| per_loss: 0.359 | a_loss: 0.516
Train: Epoch [1631/3000], Step [60/158]| g_loss: 0.717| d_loss: 0.636| gp_loss: 0.057| r_loss: 0.068| p_loss: 0.103| v_loss: 0.025| per_loss: 0.355 | a_loss: 0.536
Train: Epoch [1631/3000], Step [90/158]| g_loss: 0.705| d_loss: 0.627| gp_loss: 0.054| r_loss: 0.071| p_loss: 0.107| v_loss: 0.026| per_loss: 0.355 | a_loss: 0.519
Train: Epoch [1631/3000], Step [120/158]| g_loss: 0.715| d_loss: 0.693| gp_loss: 0.055| r_loss: 0.071| p_loss: 0.111| v_loss: 0.025| per_loss: 0.348 | a_loss: 0.528
Train: Epoch [1631/3000], Step [150/158]| g_loss: 0.709| d_loss: 0.557| gp_loss: 0.058| r_loss: 0.069| p_loss: 0.105| v_loss: 0.026| per_loss: 0.335 | a_loss: 0.527
Train: Epoch [1632/3000], Step [30/158]| g_loss: 0.783| d_loss: 0.616| gp_loss: 0.140| r_loss: 0.070| p_loss: 0.107| v_loss: 0.026| per_loss: 0.355 | a_loss: 0.598
Train: Epoch [1632/3000], Step [60/158]| g_loss: 0.697| d_loss: 0.622| gp_loss: 0.056| r_loss: 0.069| p_loss: 0.102| v_loss: 0.025| per_loss: 0.345 | a_loss: 0.517
Train: Epoch [1632/3000], Step [90/158]| g_loss: 0.722| d_loss: 0.641| gp_loss: 0.053| r_loss: 0.068| p_loss: 0.102| v_loss: 0.026| per_loss: 0.355 | a_loss: 0.543
Train: Epoch [1632/3000], Step [120/158]| g_loss: 0.739| d_loss: 0.542| gp_loss: 0.058| r_loss: 0.068| p_loss: 0.102| v_loss: 0.025| per_loss: 0.347 | a_loss: 0.560
Train: Epoch [1632/3000], Step [150/158]| g_loss: 0.775| d_loss: 0.634| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.107| v_loss: 0.025| per_loss: 0.340 | a_loss: 0.594
Train: Epoch [1633/3000], Step [30/158]| g_loss: 0.695| d_loss: 0.692| gp_loss: 0.135| r_loss: 0.070| p_loss: 0.109| v_loss: 0.026| per_loss: 0.360 | a_loss: 0.507
Train: Epoch [1633/3000], Step [60/158]| g_loss: 0.689| d_loss: 0.671| gp_loss: 0.056| r_loss: 0.069| p_loss: 0.108| v_loss: 0.026| per_loss: 0.364 | a_loss: 0.505
Train: Epoch [1633/3000], Step [90/158]| g_loss: 0.770| d_loss: 0.553| gp_loss: 0.056| r_loss: 0.069| p_loss: 0.102| v_loss: 0.026| per_loss: 0.355 | a_loss: 0.588
Train: Epoch [1633/3000], Step [120/158]| g_loss: 0.801| d_loss: 0.548| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.105| v_loss: 0.026| per_loss: 0.346 | a_loss: 0.620
Train: Epoch [1633/3000], Step [150/158]| g_loss: 0.637| d_loss: 0.667| gp_loss: 0.058| r_loss: 0.070| p_loss: 0.103| v_loss: 0.025| per_loss: 0.338 | a_loss: 0.457
Train: Epoch [1634/3000], Step [30/158]| g_loss: 0.749| d_loss: 0.733| gp_loss: 0.170| r_loss: 0.070| p_loss: 0.103| v_loss: 0.025| per_loss: 0.350 | a_loss: 0.568
Train: Epoch [1634/3000], Step [60/158]| g_loss: 0.686| d_loss: 0.650| gp_loss: 0.053| r_loss: 0.070| p_loss: 0.106| v_loss: 0.026| per_loss: 0.352 | a_loss: 0.501
Train: Epoch [1634/3000], Step [90/158]| g_loss: 0.669| d_loss: 0.645| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.102| v_loss: 0.025| per_loss: 0.340 | a_loss: 0.491
Train: Epoch [1634/3000], Step [120/158]| g_loss: 0.721| d_loss: 0.611| gp_loss: 0.060| r_loss: 0.067| p_loss: 0.104| v_loss: 0.025| per_loss: 0.325 | a_loss: 0.545
Train: Epoch [1634/3000], Step [150/158]| g_loss: 0.770| d_loss: 0.530| gp_loss: 0.061| r_loss: 0.067| p_loss: 0.097| v_loss: 0.025| per_loss: 0.347 | a_loss: 0.595
Train: Epoch [1635/3000], Step [30/158]| g_loss: 0.759| d_loss: 0.652| gp_loss: 0.138| r_loss: 0.069| p_loss: 0.107| v_loss: 0.028| per_loss: 0.340 | a_loss: 0.574
Train: Epoch [1635/3000], Step [60/158]| g_loss: 0.768| d_loss: 0.534| gp_loss: 0.057| r_loss: 0.074| p_loss: 0.111| v_loss: 0.026| per_loss: 0.370 | a_loss: 0.576
Train: Epoch [1635/3000], Step [90/158]| g_loss: 0.754| d_loss: 0.547| gp_loss: 0.055| r_loss: 0.069| p_loss: 0.105| v_loss: 0.026| per_loss: 0.338 | a_loss: 0.573
Train: Epoch [1635/3000], Step [120/158]| g_loss: 0.681| d_loss: 0.666| gp_loss: 0.053| r_loss: 0.069| p_loss: 0.105| v_loss: 0.025| per_loss: 0.337 | a_loss: 0.502
Train: Epoch [1635/3000], Step [150/158]| g_loss: 0.718| d_loss: 0.639| gp_loss: 0.056| r_loss: 0.070| p_loss: 0.102| v_loss: 0.025| per_loss: 0.344 | a_loss: 0.538
Train: Epoch [1636/3000], Step [30/158]| g_loss: 0.717| d_loss: 0.674| gp_loss: 0.129| r_loss: 0.071| p_loss: 0.110| v_loss: 0.026| per_loss: 0.356 | a_loss: 0.530
Train: Epoch [1636/3000], Step [60/158]| g_loss: 0.717| d_loss: 0.691| gp_loss: 0.053| r_loss: 0.071| p_loss: 0.109| v_loss: 0.025| per_loss: 0.355 | a_loss: 0.531
Train: Epoch [1636/3000], Step [90/158]| g_loss: 0.726| d_loss: 0.604| gp_loss: 0.056| r_loss: 0.073| p_loss: 0.109| v_loss: 0.026| per_loss: 0.348 | a_loss: 0.538
Train: Epoch [1636/3000], Step [120/158]| g_loss: 0.731| d_loss: 0.620| gp_loss: 0.056| r_loss: 0.072| p_loss: 0.112| v_loss: 0.026| per_loss: 0.348 | a_loss: 0.542
Train: Epoch [1636/3000], Step [150/158]| g_loss: 0.718| d_loss: 0.573| gp_loss: 0.057| r_loss: 0.070| p_loss: 0.104| v_loss: 0.025| per_loss: 0.353 | a_loss: 0.535
Train: Epoch [1637/3000], Step [30/158]| g_loss: 0.755| d_loss: 0.694| gp_loss: 0.153| r_loss: 0.072| p_loss: 0.109| v_loss: 0.026| per_loss: 0.341 | a_loss: 0.569
Train: Epoch [1637/3000], Step [60/158]| g_loss: 0.714| d_loss: 0.589| gp_loss: 0.053| r_loss: 0.069| p_loss: 0.103| v_loss: 0.026| per_loss: 0.356 | a_loss: 0.532
Train: Epoch [1637/3000], Step [90/158]| g_loss: 0.708| d_loss: 0.582| gp_loss: 0.056| r_loss: 0.068| p_loss: 0.104| v_loss: 0.025| per_loss: 0.350 | a_loss: 0.527
Train: Epoch [1637/3000], Step [120/158]| g_loss: 0.742| d_loss: 0.593| gp_loss: 0.059| r_loss: 0.067| p_loss: 0.099| v_loss: 0.026| per_loss: 0.338 | a_loss: 0.565
Train: Epoch [1637/3000], Step [150/158]| g_loss: 0.699| d_loss: 0.632| gp_loss: 0.055| r_loss: 0.067| p_loss: 0.103| v_loss: 0.024| per_loss: 0.344 | a_loss: 0.522
Train: Epoch [1638/3000], Step [30/158]| g_loss: 0.713| d_loss: 0.664| gp_loss: 0.127| r_loss: 0.072| p_loss: 0.105| v_loss: 0.025| per_loss: 0.351 | a_loss: 0.528
Train: Epoch [1638/3000], Step [60/158]| g_loss: 0.738| d_loss: 0.621| gp_loss: 0.058| r_loss: 0.069| p_loss: 0.106| v_loss: 0.026| per_loss: 0.343 | a_loss: 0.557
Train: Epoch [1638/3000], Step [90/158]| g_loss: 0.730| d_loss: 0.535| gp_loss: 0.057| r_loss: 0.069| p_loss: 0.101| v_loss: 0.025| per_loss: 0.350 | a_loss: 0.551
Train: Epoch [1638/3000], Step [120/158]| g_loss: 0.725| d_loss: 0.649| gp_loss: 0.060| r_loss: 0.069| p_loss: 0.105| v_loss: 0.026| per_loss: 0.341 | a_loss: 0.544
Train: Epoch [1638/3000], Step [150/158]| g_loss: 0.699| d_loss: 0.629| gp_loss: 0.063| r_loss: 0.069| p_loss: 0.107| v_loss: 0.025| per_loss: 0.344 | a_loss: 0.516
Train: Epoch [1639/3000], Step [30/158]| g_loss: 0.726| d_loss: 0.720| gp_loss: 0.155| r_loss: 0.068| p_loss: 0.110| v_loss: 0.026| per_loss: 0.346 | a_loss: 0.543
Train: Epoch [1639/3000], Step [60/158]| g_loss: 0.727| d_loss: 0.627| gp_loss: 0.054| r_loss: 0.069| p_loss: 0.108| v_loss: 0.025| per_loss: 0.335 | a_loss: 0.546
Train: Epoch [1639/3000], Step [90/158]| g_loss: 0.722| d_loss: 0.630| gp_loss: 0.058| r_loss: 0.070| p_loss: 0.103| v_loss: 0.025| per_loss: 0.357 | a_loss: 0.539
Train: Epoch [1639/3000], Step [120/158]| g_loss: 0.732| d_loss: 0.573| gp_loss: 0.060| r_loss: 0.070| p_loss: 0.109| v_loss: 0.025| per_loss: 0.351 | a_loss: 0.548
Train: Epoch [1639/3000], Step [150/158]| g_loss: 0.794| d_loss: 0.479| gp_loss: 0.062| r_loss: 0.071| p_loss: 0.109| v_loss: 0.025| per_loss: 0.343 | a_loss: 0.609
Train: Epoch [1640/3000], Step [30/158]| g_loss: 0.697| d_loss: 0.790| gp_loss: 0.149| r_loss: 0.070| p_loss: 0.110| v_loss: 0.026| per_loss: 0.353 | a_loss: 0.511
Train: Epoch [1640/3000], Step [60/158]| g_loss: 0.751| d_loss: 0.697| gp_loss: 0.052| r_loss: 0.074| p_loss: 0.108| v_loss: 0.028| per_loss: 0.352 | a_loss: 0.560
Train: Epoch [1640/3000], Step [90/158]| g_loss: 0.666| d_loss: 0.677| gp_loss: 0.059| r_loss: 0.070| p_loss: 0.110| v_loss: 0.025| per_loss: 0.353 | a_loss: 0.481
Train: Epoch [1640/3000], Step [120/158]| g_loss: 0.683| d_loss: 0.662| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.108| v_loss: 0.025| per_loss: 0.334 | a_loss: 0.499
Train: Epoch [1640/3000], Step [150/158]| g_loss: 0.778| d_loss: 0.493| gp_loss: 0.068| r_loss: 0.069| p_loss: 0.108| v_loss: 0.026| per_loss: 0.352 | a_loss: 0.594
Train: Epoch [1641/3000], Step [30/158]| g_loss: 0.759| d_loss: 0.703| gp_loss: 0.174| r_loss: 0.071| p_loss: 0.106| v_loss: 0.025| per_loss: 0.355 | a_loss: 0.574
Train: Epoch [1641/3000], Step [60/158]| g_loss: 0.710| d_loss: 0.631| gp_loss: 0.052| r_loss: 0.069| p_loss: 0.102| v_loss: 0.026| per_loss: 0.351 | a_loss: 0.529
Train: Epoch [1641/3000], Step [90/158]| g_loss: 0.741| d_loss: 0.595| gp_loss: 0.051| r_loss: 0.068| p_loss: 0.101| v_loss: 0.025| per_loss: 0.346 | a_loss: 0.563
Train: Epoch [1641/3000], Step [120/158]| g_loss: 0.694| d_loss: 0.597| gp_loss: 0.051| r_loss: 0.068| p_loss: 0.103| v_loss: 0.025| per_loss: 0.351 | a_loss: 0.514
Train: Epoch [1641/3000], Step [150/158]| g_loss: 0.728| d_loss: 0.631| gp_loss: 0.055| r_loss: 0.070| p_loss: 0.107| v_loss: 0.026| per_loss: 0.323 | a_loss: 0.546
Train: Epoch [1642/3000], Step [30/158]| g_loss: 0.664| d_loss: 0.751| gp_loss: 0.124| r_loss: 0.067| p_loss: 0.104| v_loss: 0.025| per_loss: 0.353 | a_loss: 0.485
Train: Epoch [1642/3000], Step [60/158]| g_loss: 0.723| d_loss: 0.524| gp_loss: 0.058| r_loss: 0.067| p_loss: 0.097| v_loss: 0.025| per_loss: 0.356 | a_loss: 0.548
Train: Epoch [1642/3000], Step [90/158]| g_loss: 0.776| d_loss: 0.564| gp_loss: 0.054| r_loss: 0.068| p_loss: 0.102| v_loss: 0.023| per_loss: 0.355 | a_loss: 0.598
Train: Epoch [1642/3000], Step [120/158]| g_loss: 0.695| d_loss: 0.609| gp_loss: 0.055| r_loss: 0.070| p_loss: 0.103| v_loss: 0.025| per_loss: 0.324 | a_loss: 0.516
Train: Epoch [1642/3000], Step [150/158]| g_loss: 0.701| d_loss: 0.645| gp_loss: 0.058| r_loss: 0.067| p_loss: 0.104| v_loss: 0.026| per_loss: 0.343 | a_loss: 0.522
Train: Epoch [1643/3000], Step [30/158]| g_loss: 0.737| d_loss: 0.742| gp_loss: 0.181| r_loss: 0.068| p_loss: 0.104| v_loss: 0.026| per_loss: 0.352 | a_loss: 0.555
Train: Epoch [1643/3000], Step [60/158]| g_loss: 0.695| d_loss: 0.622| gp_loss: 0.052| r_loss: 0.069| p_loss: 0.104| v_loss: 0.025| per_loss: 0.335 | a_loss: 0.516
Train: Epoch [1643/3000], Step [90/158]| g_loss: 0.720| d_loss: 0.588| gp_loss: 0.055| r_loss: 0.070| p_loss: 0.107| v_loss: 0.025| per_loss: 0.346 | a_loss: 0.537
Train: Epoch [1643/3000], Step [120/158]| g_loss: 0.724| d_loss: 0.564| gp_loss: 0.058| r_loss: 0.069| p_loss: 0.102| v_loss: 0.025| per_loss: 0.336 | a_loss: 0.546
Train: Epoch [1643/3000], Step [150/158]| g_loss: 0.738| d_loss: 0.598| gp_loss: 0.056| r_loss: 0.068| p_loss: 0.103| v_loss: 0.026| per_loss: 0.342 | a_loss: 0.559
Train: Epoch [1644/3000], Step [30/158]| g_loss: 0.687| d_loss: 0.745| gp_loss: 0.188| r_loss: 0.068| p_loss: 0.103| v_loss: 0.025| per_loss: 0.342 | a_loss: 0.508
Train: Epoch [1644/3000], Step [60/158]| g_loss: 0.720| d_loss: 0.560| gp_loss: 0.052| r_loss: 0.067| p_loss: 0.097| v_loss: 0.024| per_loss: 0.341 | a_loss: 0.546
Train: Epoch [1644/3000], Step [90/158]| g_loss: 0.762| d_loss: 0.591| gp_loss: 0.058| r_loss: 0.068| p_loss: 0.102| v_loss: 0.025| per_loss: 0.359 | a_loss: 0.582
Train: Epoch [1644/3000], Step [120/158]| g_loss: 0.731| d_loss: 0.635| gp_loss: 0.054| r_loss: 0.067| p_loss: 0.106| v_loss: 0.025| per_loss: 0.341 | a_loss: 0.551
Train: Epoch [1644/3000], Step [150/158]| g_loss: 0.673| d_loss: 0.604| gp_loss: 0.057| r_loss: 0.068| p_loss: 0.102| v_loss: 0.026| per_loss: 0.342 | a_loss: 0.493
Train: Epoch [1645/3000], Step [30/158]| g_loss: 0.754| d_loss: 0.676| gp_loss: 0.157| r_loss: 0.071| p_loss: 0.111| v_loss: 0.025| per_loss: 0.349 | a_loss: 0.568
Train: Epoch [1645/3000], Step [60/158]| g_loss: 0.746| d_loss: 0.596| gp_loss: 0.050| r_loss: 0.069| p_loss: 0.106| v_loss: 0.024| per_loss: 0.319 | a_loss: 0.568
Train: Epoch [1645/3000], Step [90/158]| g_loss: 0.673| d_loss: 0.632| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.102| v_loss: 0.025| per_loss: 0.355 | a_loss: 0.493
Train: Epoch [1645/3000], Step [120/158]| g_loss: 0.728| d_loss: 0.592| gp_loss: 0.056| r_loss: 0.065| p_loss: 0.100| v_loss: 0.024| per_loss: 0.362 | a_loss: 0.552
Train: Epoch [1645/3000], Step [150/158]| g_loss: 0.695| d_loss: 0.719| gp_loss: 0.054| r_loss: 0.070| p_loss: 0.107| v_loss: 0.026| per_loss: 0.327 | a_loss: 0.513
Train: Epoch [1646/3000], Step [30/158]| g_loss: 0.702| d_loss: 0.691| gp_loss: 0.107| r_loss: 0.071| p_loss: 0.107| v_loss: 0.025| per_loss: 0.339 | a_loss: 0.518
Train: Epoch [1646/3000], Step [60/158]| g_loss: 0.703| d_loss: 0.610| gp_loss: 0.055| r_loss: 0.067| p_loss: 0.103| v_loss: 0.025| per_loss: 0.345 | a_loss: 0.526
Train: Epoch [1646/3000], Step [90/158]| g_loss: 0.711| d_loss: 0.567| gp_loss: 0.055| r_loss: 0.067| p_loss: 0.101| v_loss: 0.024| per_loss: 0.366 | a_loss: 0.534
Train: Epoch [1646/3000], Step [120/158]| g_loss: 0.725| d_loss: 0.605| gp_loss: 0.057| r_loss: 0.067| p_loss: 0.103| v_loss: 0.025| per_loss: 0.334 | a_loss: 0.548
Train: Epoch [1646/3000], Step [150/158]| g_loss: 0.757| d_loss: 0.574| gp_loss: 0.061| r_loss: 0.069| p_loss: 0.110| v_loss: 0.025| per_loss: 0.346 | a_loss: 0.573
Train: Epoch [1647/3000], Step [30/158]| g_loss: 0.773| d_loss: 0.672| gp_loss: 0.154| r_loss: 0.068| p_loss: 0.109| v_loss: 0.026| per_loss: 0.355 | a_loss: 0.589
Train: Epoch [1647/3000], Step [60/158]| g_loss: 0.705| d_loss: 0.577| gp_loss: 0.056| r_loss: 0.067| p_loss: 0.101| v_loss: 0.025| per_loss: 0.352 | a_loss: 0.528
Train: Epoch [1647/3000], Step [90/158]| g_loss: 0.729| d_loss: 0.551| gp_loss: 0.053| r_loss: 0.068| p_loss: 0.101| v_loss: 0.025| per_loss: 0.348 | a_loss: 0.551
Train: Epoch [1647/3000], Step [120/158]| g_loss: 0.732| d_loss: 0.565| gp_loss: 0.054| r_loss: 0.067| p_loss: 0.098| v_loss: 0.024| per_loss: 0.344 | a_loss: 0.558
Train: Epoch [1647/3000], Step [150/158]| g_loss: 0.743| d_loss: 0.641| gp_loss: 0.054| r_loss: 0.068| p_loss: 0.105| v_loss: 0.026| per_loss: 0.333 | a_loss: 0.563
Train: Epoch [1648/3000], Step [30/158]| g_loss: 0.683| d_loss: 0.734| gp_loss: 0.190| r_loss: 0.067| p_loss: 0.101| v_loss: 0.024| per_loss: 0.337 | a_loss: 0.507
Train: Epoch [1648/3000], Step [60/158]| g_loss: 0.720| d_loss: 0.552| gp_loss: 0.052| r_loss: 0.065| p_loss: 0.099| v_loss: 0.025| per_loss: 0.348 | a_loss: 0.545
Train: Epoch [1648/3000], Step [90/158]| g_loss: 0.743| d_loss: 0.612| gp_loss: 0.053| r_loss: 0.068| p_loss: 0.103| v_loss: 0.025| per_loss: 0.359 | a_loss: 0.562
Train: Epoch [1648/3000], Step [120/158]| g_loss: 0.764| d_loss: 0.569| gp_loss: 0.056| r_loss: 0.069| p_loss: 0.104| v_loss: 0.025| per_loss: 0.355 | a_loss: 0.582
Train: Epoch [1648/3000], Step [150/158]| g_loss: 0.680| d_loss: 0.709| gp_loss: 0.052| r_loss: 0.070| p_loss: 0.109| v_loss: 0.026| per_loss: 0.335 | a_loss: 0.496
Train: Epoch [1649/3000], Step [30/158]| g_loss: 0.695| d_loss: 0.676| gp_loss: 0.151| r_loss: 0.071| p_loss: 0.108| v_loss: 0.025| per_loss: 0.362 | a_loss: 0.510
Train: Epoch [1649/3000], Step [60/158]| g_loss: 0.768| d_loss: 0.628| gp_loss: 0.051| r_loss: 0.071| p_loss: 0.107| v_loss: 0.026| per_loss: 0.356 | a_loss: 0.583
Train: Epoch [1649/3000], Step [90/158]| g_loss: 0.687| d_loss: 0.647| gp_loss: 0.053| r_loss: 0.070| p_loss: 0.113| v_loss: 0.026| per_loss: 0.361 | a_loss: 0.499
Train: Epoch [1649/3000], Step [120/158]| g_loss: 0.737| d_loss: 0.548| gp_loss: 0.056| r_loss: 0.068| p_loss: 0.103| v_loss: 0.026| per_loss: 0.338 | a_loss: 0.558
Train: Epoch [1649/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.693| gp_loss: 0.054| r_loss: 0.071| p_loss: 0.111| v_loss: 0.024| per_loss: 0.346 | a_loss: 0.479
Train: Epoch [1650/3000], Step [30/158]| g_loss: 0.710| d_loss: 0.755| gp_loss: 0.178| r_loss: 0.071| p_loss: 0.111| v_loss: 0.025| per_loss: 0.346 | a_loss: 0.524
Train: Epoch [1650/3000], Step [60/158]| g_loss: 0.711| d_loss: 0.553| gp_loss: 0.051| r_loss: 0.066| p_loss: 0.100| v_loss: 0.024| per_loss: 0.344 | a_loss: 0.537
Train: Epoch [1650/3000], Step [90/158]| g_loss: 0.714| d_loss: 0.592| gp_loss: 0.052| r_loss: 0.071| p_loss: 0.101| v_loss: 0.025| per_loss: 0.349 | a_loss: 0.532
Train: Epoch [1650/3000], Step [120/158]| g_loss: 0.756| d_loss: 0.610| gp_loss: 0.053| r_loss: 0.072| p_loss: 0.107| v_loss: 0.025| per_loss: 0.330 | a_loss: 0.573
Train: Epoch [1650/3000], Step [150/158]| g_loss: 0.709| d_loss: 0.571| gp_loss: 0.054| r_loss: 0.069| p_loss: 0.106| v_loss: 0.026| per_loss: 0.369 | a_loss: 0.523
Test: Epoch [1650/3000]| g_loss: 0.646| r_loss: 0.396| p_loss: 0.313| v_loss: 0.023
Train: Epoch [1651/3000], Step [30/158]| g_loss: 0.693| d_loss: 0.551| gp_loss: 0.057| r_loss: 0.066| p_loss: 0.098| v_loss: 0.024| per_loss: 0.340 | a_loss: 0.519
Train: Epoch [1651/3000], Step [60/158]| g_loss: 0.766| d_loss: 0.621| gp_loss: 0.054| r_loss: 0.072| p_loss: 0.109| v_loss: 0.025| per_loss: 0.345 | a_loss: 0.580
Train: Epoch [1651/3000], Step [90/158]| g_loss: 0.686| d_loss: 0.561| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.104| v_loss: 0.025| per_loss: 0.361 | a_loss: 0.506
Train: Epoch [1651/3000], Step [120/158]| g_loss: 0.731| d_loss: 0.680| gp_loss: 0.057| r_loss: 0.073| p_loss: 0.113| v_loss: 0.026| per_loss: 0.351 | a_loss: 0.541
Train: Epoch [1651/3000], Step [150/158]| g_loss: 0.725| d_loss: 0.576| gp_loss: 0.059| r_loss: 0.072| p_loss: 0.107| v_loss: 0.025| per_loss: 0.346 | a_loss: 0.540
Train: Epoch [1652/3000], Step [30/158]| g_loss: 0.749| d_loss: 0.685| gp_loss: 0.137| r_loss: 0.073| p_loss: 0.110| v_loss: 0.026| per_loss: 0.356 | a_loss: 0.560
Train: Epoch [1652/3000], Step [60/158]| g_loss: 0.749| d_loss: 0.551| gp_loss: 0.055| r_loss: 0.069| p_loss: 0.106| v_loss: 0.025| per_loss: 0.368 | a_loss: 0.565
Train: Epoch [1652/3000], Step [90/158]| g_loss: 0.713| d_loss: 0.597| gp_loss: 0.054| r_loss: 0.068| p_loss: 0.103| v_loss: 0.025| per_loss: 0.354 | a_loss: 0.533
Train: Epoch [1652/3000], Step [120/158]| g_loss: 0.689| d_loss: 0.649| gp_loss: 0.057| r_loss: 0.070| p_loss: 0.112| v_loss: 0.025| per_loss: 0.351 | a_loss: 0.504
Train: Epoch [1652/3000], Step [150/158]| g_loss: 0.743| d_loss: 0.629| gp_loss: 0.059| r_loss: 0.070| p_loss: 0.110| v_loss: 0.026| per_loss: 0.344 | a_loss: 0.558
Train: Epoch [1653/3000], Step [30/158]| g_loss: 0.744| d_loss: 0.695| gp_loss: 0.148| r_loss: 0.070| p_loss: 0.110| v_loss: 0.025| per_loss: 0.332 | a_loss: 0.560
Train: Epoch [1653/3000], Step [60/158]| g_loss: 0.713| d_loss: 0.692| gp_loss: 0.055| r_loss: 0.073| p_loss: 0.111| v_loss: 0.026| per_loss: 0.361 | a_loss: 0.523
Train: Epoch [1653/3000], Step [90/158]| g_loss: 0.642| d_loss: 0.638| gp_loss: 0.057| r_loss: 0.067| p_loss: 0.105| v_loss: 0.025| per_loss: 0.349 | a_loss: 0.463
Train: Epoch [1653/3000], Step [120/158]| g_loss: 0.754| d_loss: 0.536| gp_loss: 0.060| r_loss: 0.070| p_loss: 0.108| v_loss: 0.025| per_loss: 0.358 | a_loss: 0.569
Train: Epoch [1653/3000], Step [150/158]| g_loss: 0.731| d_loss: 0.639| gp_loss: 0.059| r_loss: 0.071| p_loss: 0.112| v_loss: 0.026| per_loss: 0.352 | a_loss: 0.543
Train: Epoch [1654/3000], Step [30/158]| g_loss: 0.735| d_loss: 0.694| gp_loss: 0.129| r_loss: 0.069| p_loss: 0.108| v_loss: 0.025| per_loss: 0.352 | a_loss: 0.551
Train: Epoch [1654/3000], Step [60/158]| g_loss: 0.696| d_loss: 0.589| gp_loss: 0.054| r_loss: 0.071| p_loss: 0.107| v_loss: 0.025| per_loss: 0.349 | a_loss: 0.512
Train: Epoch [1654/3000], Step [90/158]| g_loss: 0.759| d_loss: 0.588| gp_loss: 0.060| r_loss: 0.069| p_loss: 0.104| v_loss: 0.025| per_loss: 0.338 | a_loss: 0.579
Train: Epoch [1654/3000], Step [120/158]| g_loss: 0.726| d_loss: 0.620| gp_loss: 0.058| r_loss: 0.069| p_loss: 0.112| v_loss: 0.026| per_loss: 0.349 | a_loss: 0.539
Train: Epoch [1654/3000], Step [150/158]| g_loss: 0.731| d_loss: 0.577| gp_loss: 0.059| r_loss: 0.071| p_loss: 0.114| v_loss: 0.026| per_loss: 0.357 | a_loss: 0.542
Train: Epoch [1655/3000], Step [30/158]| g_loss: 0.749| d_loss: 0.733| gp_loss: 0.184| r_loss: 0.072| p_loss: 0.112| v_loss: 0.026| per_loss: 0.378 | a_loss: 0.557
Train: Epoch [1655/3000], Step [60/158]| g_loss: 0.706| d_loss: 0.646| gp_loss: 0.053| r_loss: 0.071| p_loss: 0.107| v_loss: 0.025| per_loss: 0.353 | a_loss: 0.522
Train: Epoch [1655/3000], Step [90/158]| g_loss: 0.688| d_loss: 0.672| gp_loss: 0.054| r_loss: 0.070| p_loss: 0.105| v_loss: 0.024| per_loss: 0.340 | a_loss: 0.507
Train: Epoch [1655/3000], Step [120/158]| g_loss: 0.701| d_loss: 0.603| gp_loss: 0.061| r_loss: 0.068| p_loss: 0.102| v_loss: 0.025| per_loss: 0.345 | a_loss: 0.522
Train: Epoch [1655/3000], Step [150/158]| g_loss: 0.755| d_loss: 0.520| gp_loss: 0.059| r_loss: 0.068| p_loss: 0.105| v_loss: 0.026| per_loss: 0.368 | a_loss: 0.572
Train: Epoch [1656/3000], Step [30/158]| g_loss: 0.785| d_loss: 0.617| gp_loss: 0.140| r_loss: 0.071| p_loss: 0.109| v_loss: 0.025| per_loss: 0.356 | a_loss: 0.599
Train: Epoch [1656/3000], Step [60/158]| g_loss: 0.735| d_loss: 0.592| gp_loss: 0.057| r_loss: 0.066| p_loss: 0.100| v_loss: 0.026| per_loss: 0.348 | a_loss: 0.558
Train: Epoch [1656/3000], Step [90/158]| g_loss: 0.705| d_loss: 0.619| gp_loss: 0.056| r_loss: 0.069| p_loss: 0.105| v_loss: 0.025| per_loss: 0.343 | a_loss: 0.524
Train: Epoch [1656/3000], Step [120/158]| g_loss: 0.778| d_loss: 0.481| gp_loss: 0.062| r_loss: 0.069| p_loss: 0.103| v_loss: 0.025| per_loss: 0.347 | a_loss: 0.598
Train: Epoch [1656/3000], Step [150/158]| g_loss: 0.708| d_loss: 0.700| gp_loss: 0.056| r_loss: 0.072| p_loss: 0.113| v_loss: 0.026| per_loss: 0.349 | a_loss: 0.518
Train: Epoch [1657/3000], Step [30/158]| g_loss: 0.672| d_loss: 0.739| gp_loss: 0.089| r_loss: 0.069| p_loss: 0.109| v_loss: 0.025| per_loss: 0.355 | a_loss: 0.488
Train: Epoch [1657/3000], Step [60/158]| g_loss: 0.740| d_loss: 0.641| gp_loss: 0.061| r_loss: 0.073| p_loss: 0.109| v_loss: 0.026| per_loss: 0.342 | a_loss: 0.552
Train: Epoch [1657/3000], Step [90/158]| g_loss: 0.691| d_loss: 0.632| gp_loss: 0.060| r_loss: 0.068| p_loss: 0.107| v_loss: 0.026| per_loss: 0.355 | a_loss: 0.508
Train: Epoch [1657/3000], Step [120/158]| g_loss: 0.704| d_loss: 0.648| gp_loss: 0.062| r_loss: 0.068| p_loss: 0.108| v_loss: 0.026| per_loss: 0.338 | a_loss: 0.523
Train: Epoch [1657/3000], Step [150/158]| g_loss: 0.718| d_loss: 0.581| gp_loss: 0.063| r_loss: 0.069| p_loss: 0.105| v_loss: 0.025| per_loss: 0.333 | a_loss: 0.538
Train: Epoch [1658/3000], Step [30/158]| g_loss: 0.742| d_loss: 0.690| gp_loss: 0.169| r_loss: 0.068| p_loss: 0.106| v_loss: 0.026| per_loss: 0.337 | a_loss: 0.561
Train: Epoch [1658/3000], Step [60/158]| g_loss: 0.725| d_loss: 0.642| gp_loss: 0.052| r_loss: 0.069| p_loss: 0.104| v_loss: 0.025| per_loss: 0.347 | a_loss: 0.545
Train: Epoch [1658/3000], Step [90/158]| g_loss: 0.656| d_loss: 0.647| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.108| v_loss: 0.025| per_loss: 0.342 | a_loss: 0.474
Train: Epoch [1658/3000], Step [120/158]| g_loss: 0.790| d_loss: 0.563| gp_loss: 0.061| r_loss: 0.072| p_loss: 0.106| v_loss: 0.026| per_loss: 0.341 | a_loss: 0.604
Train: Epoch [1658/3000], Step [150/158]| g_loss: 0.727| d_loss: 0.601| gp_loss: 0.062| r_loss: 0.070| p_loss: 0.109| v_loss: 0.025| per_loss: 0.351 | a_loss: 0.543
Train: Epoch [1659/3000], Step [30/158]| g_loss: 0.715| d_loss: 0.737| gp_loss: 0.159| r_loss: 0.070| p_loss: 0.105| v_loss: 0.025| per_loss: 0.359 | a_loss: 0.531
Train: Epoch [1659/3000], Step [60/158]| g_loss: 0.659| d_loss: 0.679| gp_loss: 0.057| r_loss: 0.068| p_loss: 0.104| v_loss: 0.025| per_loss: 0.332 | a_loss: 0.481
Train: Epoch [1659/3000], Step [90/158]| g_loss: 0.716| d_loss: 0.601| gp_loss: 0.058| r_loss: 0.071| p_loss: 0.103| v_loss: 0.025| per_loss: 0.326 | a_loss: 0.536
Train: Epoch [1659/3000], Step [120/158]| g_loss: 0.732| d_loss: 0.532| gp_loss: 0.057| r_loss: 0.067| p_loss: 0.101| v_loss: 0.025| per_loss: 0.349 | a_loss: 0.553
Train: Epoch [1659/3000], Step [150/158]| g_loss: 0.787| d_loss: 0.537| gp_loss: 0.056| r_loss: 0.066| p_loss: 0.100| v_loss: 0.025| per_loss: 0.354 | a_loss: 0.610
Train: Epoch [1660/3000], Step [30/158]| g_loss: 0.748| d_loss: 0.696| gp_loss: 0.208| r_loss: 0.068| p_loss: 0.105| v_loss: 0.027| per_loss: 0.351 | a_loss: 0.565
Train: Epoch [1660/3000], Step [60/158]| g_loss: 0.736| d_loss: 0.637| gp_loss: 0.050| r_loss: 0.067| p_loss: 0.103| v_loss: 0.026| per_loss: 0.339 | a_loss: 0.558
Train: Epoch [1660/3000], Step [90/158]| g_loss: 0.643| d_loss: 0.646| gp_loss: 0.053| r_loss: 0.071| p_loss: 0.100| v_loss: 0.025| per_loss: 0.333 | a_loss: 0.464
Train: Epoch [1660/3000], Step [120/158]| g_loss: 0.737| d_loss: 0.632| gp_loss: 0.054| r_loss: 0.067| p_loss: 0.101| v_loss: 0.024| per_loss: 0.360 | a_loss: 0.559
Train: Epoch [1660/3000], Step [150/158]| g_loss: 0.670| d_loss: 0.595| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.100| v_loss: 0.025| per_loss: 0.344 | a_loss: 0.492
Train: Epoch [1661/3000], Step [30/158]| g_loss: 0.734| d_loss: 0.709| gp_loss: 0.157| r_loss: 0.066| p_loss: 0.100| v_loss: 0.024| per_loss: 0.343 | a_loss: 0.559
Train: Epoch [1661/3000], Step [60/158]| g_loss: 0.681| d_loss: 0.622| gp_loss: 0.052| r_loss: 0.066| p_loss: 0.099| v_loss: 0.025| per_loss: 0.340 | a_loss: 0.507
Train: Epoch [1661/3000], Step [90/158]| g_loss: 0.759| d_loss: 0.561| gp_loss: 0.050| r_loss: 0.076| p_loss: 0.104| v_loss: 0.025| per_loss: 0.365 | a_loss: 0.569
Train: Epoch [1661/3000], Step [120/158]| g_loss: 0.671| d_loss: 0.635| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.100| v_loss: 0.025| per_loss: 0.326 | a_loss: 0.495
Train: Epoch [1661/3000], Step [150/158]| g_loss: 0.715| d_loss: 0.577| gp_loss: 0.054| r_loss: 0.070| p_loss: 0.100| v_loss: 0.025| per_loss: 0.341 | a_loss: 0.536
Train: Epoch [1662/3000], Step [30/158]| g_loss: 0.752| d_loss: 0.723| gp_loss: 0.200| r_loss: 0.066| p_loss: 0.099| v_loss: 0.024| per_loss: 0.337 | a_loss: 0.578
Train: Epoch [1662/3000], Step [60/158]| g_loss: 0.662| d_loss: 0.669| gp_loss: 0.051| r_loss: 0.068| p_loss: 0.101| v_loss: 0.024| per_loss: 0.354 | a_loss: 0.484
Train: Epoch [1662/3000], Step [90/158]| g_loss: 0.680| d_loss: 0.619| gp_loss: 0.052| r_loss: 0.068| p_loss: 0.102| v_loss: 0.025| per_loss: 0.348 | a_loss: 0.501
Train: Epoch [1662/3000], Step [120/158]| g_loss: 0.735| d_loss: 0.589| gp_loss: 0.057| r_loss: 0.067| p_loss: 0.098| v_loss: 0.025| per_loss: 0.338 | a_loss: 0.560
Train: Epoch [1662/3000], Step [150/158]| g_loss: 0.769| d_loss: 0.512| gp_loss: 0.052| r_loss: 0.066| p_loss: 0.099| v_loss: 0.026| per_loss: 0.328 | a_loss: 0.595
Train: Epoch [1663/3000], Step [30/158]| g_loss: 0.705| d_loss: 0.680| gp_loss: 0.120| r_loss: 0.064| p_loss: 0.097| v_loss: 0.025| per_loss: 0.352 | a_loss: 0.532
Train: Epoch [1663/3000], Step [60/158]| g_loss: 0.754| d_loss: 0.541| gp_loss: 0.051| r_loss: 0.067| p_loss: 0.099| v_loss: 0.025| per_loss: 0.335 | a_loss: 0.579
Train: Epoch [1663/3000], Step [90/158]| g_loss: 0.692| d_loss: 0.669| gp_loss: 0.050| r_loss: 0.069| p_loss: 0.100| v_loss: 0.025| per_loss: 0.360 | a_loss: 0.513
Train: Epoch [1663/3000], Step [120/158]| g_loss: 0.743| d_loss: 0.585| gp_loss: 0.059| r_loss: 0.069| p_loss: 0.103| v_loss: 0.025| per_loss: 0.348 | a_loss: 0.562
Train: Epoch [1663/3000], Step [150/158]| g_loss: 0.660| d_loss: 0.725| gp_loss: 0.057| r_loss: 0.070| p_loss: 0.109| v_loss: 0.024| per_loss: 0.339 | a_loss: 0.478
Train: Epoch [1664/3000], Step [30/158]| g_loss: 0.761| d_loss: 0.629| gp_loss: 0.132| r_loss: 0.067| p_loss: 0.101| v_loss: 0.025| per_loss: 0.341 | a_loss: 0.584
Train: Epoch [1664/3000], Step [60/158]| g_loss: 0.687| d_loss: 0.637| gp_loss: 0.055| r_loss: 0.069| p_loss: 0.106| v_loss: 0.024| per_loss: 0.346 | a_loss: 0.506
Train: Epoch [1664/3000], Step [90/158]| g_loss: 0.750| d_loss: 0.569| gp_loss: 0.056| r_loss: 0.072| p_loss: 0.103| v_loss: 0.025| per_loss: 0.373 | a_loss: 0.564
Train: Epoch [1664/3000], Step [120/158]| g_loss: 0.740| d_loss: 0.578| gp_loss: 0.057| r_loss: 0.068| p_loss: 0.104| v_loss: 0.025| per_loss: 0.337 | a_loss: 0.561
Train: Epoch [1664/3000], Step [150/158]| g_loss: 0.673| d_loss: 0.654| gp_loss: 0.057| r_loss: 0.069| p_loss: 0.104| v_loss: 0.026| per_loss: 0.353 | a_loss: 0.491
Train: Epoch [1665/3000], Step [30/158]| g_loss: 0.699| d_loss: 0.765| gp_loss: 0.164| r_loss: 0.067| p_loss: 0.102| v_loss: 0.025| per_loss: 0.351 | a_loss: 0.521
Train: Epoch [1665/3000], Step [60/158]| g_loss: 0.702| d_loss: 0.605| gp_loss: 0.052| r_loss: 0.066| p_loss: 0.103| v_loss: 0.025| per_loss: 0.342 | a_loss: 0.525
Train: Epoch [1665/3000], Step [90/158]| g_loss: 0.764| d_loss: 0.551| gp_loss: 0.054| r_loss: 0.067| p_loss: 0.102| v_loss: 0.023| per_loss: 0.340 | a_loss: 0.589
Train: Epoch [1665/3000], Step [120/158]| g_loss: 0.739| d_loss: 0.574| gp_loss: 0.056| r_loss: 0.070| p_loss: 0.103| v_loss: 0.025| per_loss: 0.343 | a_loss: 0.559
Train: Epoch [1665/3000], Step [150/158]| g_loss: 0.714| d_loss: 0.678| gp_loss: 0.057| r_loss: 0.072| p_loss: 0.108| v_loss: 0.025| per_loss: 0.339 | a_loss: 0.528
Train: Epoch [1666/3000], Step [30/158]| g_loss: 0.701| d_loss: 0.736| gp_loss: 0.202| r_loss: 0.069| p_loss: 0.107| v_loss: 0.025| per_loss: 0.329 | a_loss: 0.520
Train: Epoch [1666/3000], Step [60/158]| g_loss: 0.732| d_loss: 0.642| gp_loss: 0.050| r_loss: 0.068| p_loss: 0.100| v_loss: 0.024| per_loss: 0.328 | a_loss: 0.556
Train: Epoch [1666/3000], Step [90/158]| g_loss: 0.734| d_loss: 0.534| gp_loss: 0.053| r_loss: 0.068| p_loss: 0.102| v_loss: 0.025| per_loss: 0.362 | a_loss: 0.554
Train: Epoch [1666/3000], Step [120/158]| g_loss: 0.728| d_loss: 0.591| gp_loss: 0.053| r_loss: 0.065| p_loss: 0.098| v_loss: 0.024| per_loss: 0.347 | a_loss: 0.555
Train: Epoch [1666/3000], Step [150/158]| g_loss: 0.727| d_loss: 0.624| gp_loss: 0.053| r_loss: 0.067| p_loss: 0.104| v_loss: 0.025| per_loss: 0.322 | a_loss: 0.551
Train: Epoch [1667/3000], Step [30/158]| g_loss: 0.704| d_loss: 0.733| gp_loss: 0.170| r_loss: 0.072| p_loss: 0.108| v_loss: 0.026| per_loss: 0.332 | a_loss: 0.519
Train: Epoch [1667/3000], Step [60/158]| g_loss: 0.682| d_loss: 0.682| gp_loss: 0.051| r_loss: 0.071| p_loss: 0.107| v_loss: 0.025| per_loss: 0.343 | a_loss: 0.499
Train: Epoch [1667/3000], Step [90/158]| g_loss: 0.723| d_loss: 0.617| gp_loss: 0.054| r_loss: 0.069| p_loss: 0.101| v_loss: 0.025| per_loss: 0.331 | a_loss: 0.545
Train: Epoch [1667/3000], Step [120/158]| g_loss: 0.737| d_loss: 0.504| gp_loss: 0.054| r_loss: 0.070| p_loss: 0.101| v_loss: 0.025| per_loss: 0.362 | a_loss: 0.555
Train: Epoch [1667/3000], Step [150/158]| g_loss: 0.723| d_loss: 0.673| gp_loss: 0.050| r_loss: 0.070| p_loss: 0.109| v_loss: 0.026| per_loss: 0.354 | a_loss: 0.537
Train: Epoch [1668/3000], Step [30/158]| g_loss: 0.733| d_loss: 0.706| gp_loss: 0.204| r_loss: 0.066| p_loss: 0.098| v_loss: 0.025| per_loss: 0.331 | a_loss: 0.561
Train: Epoch [1668/3000], Step [60/158]| g_loss: 0.699| d_loss: 0.621| gp_loss: 0.047| r_loss: 0.068| p_loss: 0.107| v_loss: 0.025| per_loss: 0.349 | a_loss: 0.518
Train: Epoch [1668/3000], Step [90/158]| g_loss: 0.763| d_loss: 0.625| gp_loss: 0.051| r_loss: 0.070| p_loss: 0.106| v_loss: 0.026| per_loss: 0.340 | a_loss: 0.580
Train: Epoch [1668/3000], Step [120/158]| g_loss: 0.671| d_loss: 0.581| gp_loss: 0.051| r_loss: 0.065| p_loss: 0.097| v_loss: 0.024| per_loss: 0.336 | a_loss: 0.499
Train: Epoch [1668/3000], Step [150/158]| g_loss: 0.729| d_loss: 0.665| gp_loss: 0.051| r_loss: 0.068| p_loss: 0.098| v_loss: 0.025| per_loss: 0.353 | a_loss: 0.552
Train: Epoch [1669/3000], Step [30/158]| g_loss: 0.635| d_loss: 0.746| gp_loss: 0.110| r_loss: 0.068| p_loss: 0.101| v_loss: 0.024| per_loss: 0.345 | a_loss: 0.458
Train: Epoch [1669/3000], Step [60/158]| g_loss: 0.684| d_loss: 0.664| gp_loss: 0.053| r_loss: 0.067| p_loss: 0.100| v_loss: 0.025| per_loss: 0.328 | a_loss: 0.509
Train: Epoch [1669/3000], Step [90/158]| g_loss: 0.741| d_loss: 0.509| gp_loss: 0.056| r_loss: 0.065| p_loss: 0.097| v_loss: 0.025| per_loss: 0.321 | a_loss: 0.570
Train: Epoch [1669/3000], Step [120/158]| g_loss: 0.776| d_loss: 0.566| gp_loss: 0.053| r_loss: 0.065| p_loss: 0.100| v_loss: 0.025| per_loss: 0.353 | a_loss: 0.602
Train: Epoch [1669/3000], Step [150/158]| g_loss: 0.743| d_loss: 0.554| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.098| v_loss: 0.026| per_loss: 0.346 | a_loss: 0.566
Train: Epoch [1670/3000], Step [30/158]| g_loss: 0.648| d_loss: 0.751| gp_loss: 0.107| r_loss: 0.067| p_loss: 0.099| v_loss: 0.025| per_loss: 0.342 | a_loss: 0.472
Train: Epoch [1670/3000], Step [60/158]| g_loss: 0.661| d_loss: 0.609| gp_loss: 0.054| r_loss: 0.066| p_loss: 0.096| v_loss: 0.025| per_loss: 0.355 | a_loss: 0.486
Train: Epoch [1670/3000], Step [90/158]| g_loss: 0.736| d_loss: 0.589| gp_loss: 0.057| r_loss: 0.066| p_loss: 0.101| v_loss: 0.024| per_loss: 0.358 | a_loss: 0.559
Train: Epoch [1670/3000], Step [120/158]| g_loss: 0.710| d_loss: 0.663| gp_loss: 0.055| r_loss: 0.069| p_loss: 0.111| v_loss: 0.025| per_loss: 0.325 | a_loss: 0.528
Train: Epoch [1670/3000], Step [150/158]| g_loss: 0.750| d_loss: 0.574| gp_loss: 0.058| r_loss: 0.068| p_loss: 0.107| v_loss: 0.026| per_loss: 0.346 | a_loss: 0.567
Train: Epoch [1671/3000], Step [30/158]| g_loss: 0.749| d_loss: 0.627| gp_loss: 0.151| r_loss: 0.071| p_loss: 0.109| v_loss: 0.026| per_loss: 0.360 | a_loss: 0.562
Train: Epoch [1671/3000], Step [60/158]| g_loss: 0.742| d_loss: 0.633| gp_loss: 0.053| r_loss: 0.069| p_loss: 0.106| v_loss: 0.025| per_loss: 0.329 | a_loss: 0.563
Train: Epoch [1671/3000], Step [90/158]| g_loss: 0.672| d_loss: 0.617| gp_loss: 0.054| r_loss: 0.064| p_loss: 0.096| v_loss: 0.024| per_loss: 0.330 | a_loss: 0.502
Train: Epoch [1671/3000], Step [120/158]| g_loss: 0.733| d_loss: 0.578| gp_loss: 0.058| r_loss: 0.066| p_loss: 0.099| v_loss: 0.024| per_loss: 0.337 | a_loss: 0.560
Train: Epoch [1671/3000], Step [150/158]| g_loss: 0.691| d_loss: 0.609| gp_loss: 0.057| r_loss: 0.068| p_loss: 0.103| v_loss: 0.025| per_loss: 0.359 | a_loss: 0.511
Train: Epoch [1672/3000], Step [30/158]| g_loss: 0.744| d_loss: 0.726| gp_loss: 0.191| r_loss: 0.066| p_loss: 0.103| v_loss: 0.025| per_loss: 0.336 | a_loss: 0.568
Train: Epoch [1672/3000], Step [60/158]| g_loss: 0.704| d_loss: 0.651| gp_loss: 0.052| r_loss: 0.071| p_loss: 0.108| v_loss: 0.026| per_loss: 0.337 | a_loss: 0.519
Train: Epoch [1672/3000], Step [90/158]| g_loss: 0.702| d_loss: 0.631| gp_loss: 0.050| r_loss: 0.069| p_loss: 0.105| v_loss: 0.024| per_loss: 0.347 | a_loss: 0.521
Train: Epoch [1672/3000], Step [120/158]| g_loss: 0.722| d_loss: 0.570| gp_loss: 0.054| r_loss: 0.067| p_loss: 0.099| v_loss: 0.025| per_loss: 0.359 | a_loss: 0.545
Train: Epoch [1672/3000], Step [150/158]| g_loss: 0.692| d_loss: 0.633| gp_loss: 0.056| r_loss: 0.068| p_loss: 0.103| v_loss: 0.024| per_loss: 0.334 | a_loss: 0.515
Train: Epoch [1673/3000], Step [30/158]| g_loss: 0.711| d_loss: 0.644| gp_loss: 0.114| r_loss: 0.066| p_loss: 0.096| v_loss: 0.024| per_loss: 0.349 | a_loss: 0.539
Train: Epoch [1673/3000], Step [60/158]| g_loss: 0.751| d_loss: 0.565| gp_loss: 0.058| r_loss: 0.067| p_loss: 0.100| v_loss: 0.025| per_loss: 0.333 | a_loss: 0.576
Train: Epoch [1673/3000], Step [90/158]| g_loss: 0.709| d_loss: 0.601| gp_loss: 0.057| r_loss: 0.066| p_loss: 0.100| v_loss: 0.025| per_loss: 0.353 | a_loss: 0.533
Train: Epoch [1673/3000], Step [120/158]| g_loss: 0.736| d_loss: 0.619| gp_loss: 0.053| r_loss: 0.067| p_loss: 0.101| v_loss: 0.025| per_loss: 0.352 | a_loss: 0.558
Train: Epoch [1673/3000], Step [150/158]| g_loss: 0.701| d_loss: 0.682| gp_loss: 0.054| r_loss: 0.072| p_loss: 0.107| v_loss: 0.025| per_loss: 0.337 | a_loss: 0.517
Train: Epoch [1674/3000], Step [30/158]| g_loss: 0.665| d_loss: 0.733| gp_loss: 0.072| r_loss: 0.068| p_loss: 0.105| v_loss: 0.025| per_loss: 0.355 | a_loss: 0.485
Train: Epoch [1674/3000], Step [60/158]| g_loss: 0.710| d_loss: 0.589| gp_loss: 0.058| r_loss: 0.064| p_loss: 0.095| v_loss: 0.024| per_loss: 0.357 | a_loss: 0.539
Train: Epoch [1674/3000], Step [90/158]| g_loss: 0.672| d_loss: 0.632| gp_loss: 0.058| r_loss: 0.070| p_loss: 0.103| v_loss: 0.025| per_loss: 0.351 | a_loss: 0.491
Train: Epoch [1674/3000], Step [120/158]| g_loss: 0.733| d_loss: 0.557| gp_loss: 0.058| r_loss: 0.068| p_loss: 0.101| v_loss: 0.025| per_loss: 0.338 | a_loss: 0.557
Train: Epoch [1674/3000], Step [150/158]| g_loss: 0.734| d_loss: 0.593| gp_loss: 0.061| r_loss: 0.067| p_loss: 0.104| v_loss: 0.025| per_loss: 0.344 | a_loss: 0.556
Train: Epoch [1675/3000], Step [30/158]| g_loss: 0.750| d_loss: 0.691| gp_loss: 0.194| r_loss: 0.070| p_loss: 0.103| v_loss: 0.025| per_loss: 0.361 | a_loss: 0.567
Train: Epoch [1675/3000], Step [60/158]| g_loss: 0.701| d_loss: 0.613| gp_loss: 0.054| r_loss: 0.066| p_loss: 0.101| v_loss: 0.025| per_loss: 0.346 | a_loss: 0.525
Train: Epoch [1675/3000], Step [90/158]| g_loss: 0.704| d_loss: 0.673| gp_loss: 0.056| r_loss: 0.066| p_loss: 0.101| v_loss: 0.024| per_loss: 0.336 | a_loss: 0.529
Train: Epoch [1675/3000], Step [120/158]| g_loss: 0.683| d_loss: 0.597| gp_loss: 0.057| r_loss: 0.068| p_loss: 0.099| v_loss: 0.024| per_loss: 0.355 | a_loss: 0.506
Train: Epoch [1675/3000], Step [150/158]| g_loss: 0.743| d_loss: 0.583| gp_loss: 0.059| r_loss: 0.067| p_loss: 0.100| v_loss: 0.025| per_loss: 0.333 | a_loss: 0.567
Train: Epoch [1676/3000], Step [30/158]| g_loss: 0.702| d_loss: 0.618| gp_loss: 0.093| r_loss: 0.069| p_loss: 0.112| v_loss: 0.026| per_loss: 0.329 | a_loss: 0.518
Train: Epoch [1676/3000], Step [60/158]| g_loss: 0.775| d_loss: 0.580| gp_loss: 0.057| r_loss: 0.067| p_loss: 0.102| v_loss: 0.024| per_loss: 0.344 | a_loss: 0.599
Train: Epoch [1676/3000], Step [90/158]| g_loss: 0.709| d_loss: 0.616| gp_loss: 0.059| r_loss: 0.065| p_loss: 0.100| v_loss: 0.024| per_loss: 0.342 | a_loss: 0.536
Train: Epoch [1676/3000], Step [120/158]| g_loss: 0.734| d_loss: 0.537| gp_loss: 0.056| r_loss: 0.066| p_loss: 0.097| v_loss: 0.025| per_loss: 0.361 | a_loss: 0.559
Train: Epoch [1676/3000], Step [150/158]| g_loss: 0.648| d_loss: 0.708| gp_loss: 0.061| r_loss: 0.069| p_loss: 0.105| v_loss: 0.025| per_loss: 0.338 | a_loss: 0.468
Train: Epoch [1677/3000], Step [30/158]| g_loss: 0.737| d_loss: 0.730| gp_loss: 0.176| r_loss: 0.071| p_loss: 0.111| v_loss: 0.024| per_loss: 0.354 | a_loss: 0.551
Train: Epoch [1677/3000], Step [60/158]| g_loss: 0.738| d_loss: 0.549| gp_loss: 0.058| r_loss: 0.066| p_loss: 0.104| v_loss: 0.025| per_loss: 0.343 | a_loss: 0.561
Train: Epoch [1677/3000], Step [90/158]| g_loss: 0.699| d_loss: 0.633| gp_loss: 0.056| r_loss: 0.066| p_loss: 0.102| v_loss: 0.024| per_loss: 0.362 | a_loss: 0.521
Train: Epoch [1677/3000], Step [120/158]| g_loss: 0.644| d_loss: 0.683| gp_loss: 0.060| r_loss: 0.070| p_loss: 0.106| v_loss: 0.025| per_loss: 0.339 | a_loss: 0.462
Train: Epoch [1677/3000], Step [150/158]| g_loss: 0.713| d_loss: 0.580| gp_loss: 0.062| r_loss: 0.066| p_loss: 0.099| v_loss: 0.025| per_loss: 0.346 | a_loss: 0.537
Train: Epoch [1678/3000], Step [30/158]| g_loss: 0.755| d_loss: 0.632| gp_loss: 0.125| r_loss: 0.066| p_loss: 0.101| v_loss: 0.025| per_loss: 0.362 | a_loss: 0.577
Train: Epoch [1678/3000], Step [60/158]| g_loss: 0.753| d_loss: 0.575| gp_loss: 0.059| r_loss: 0.067| p_loss: 0.099| v_loss: 0.025| per_loss: 0.345 | a_loss: 0.577
Train: Epoch [1678/3000], Step [90/158]| g_loss: 0.687| d_loss: 0.648| gp_loss: 0.058| r_loss: 0.070| p_loss: 0.105| v_loss: 0.026| per_loss: 0.347 | a_loss: 0.504
Train: Epoch [1678/3000], Step [120/158]| g_loss: 0.700| d_loss: 0.614| gp_loss: 0.062| r_loss: 0.067| p_loss: 0.102| v_loss: 0.025| per_loss: 0.328 | a_loss: 0.524
Train: Epoch [1678/3000], Step [150/158]| g_loss: 0.694| d_loss: 0.633| gp_loss: 0.059| r_loss: 0.067| p_loss: 0.098| v_loss: 0.023| per_loss: 0.348 | a_loss: 0.519
Train: Epoch [1679/3000], Step [30/158]| g_loss: 0.720| d_loss: 0.700| gp_loss: 0.188| r_loss: 0.067| p_loss: 0.100| v_loss: 0.025| per_loss: 0.347 | a_loss: 0.543
Train: Epoch [1679/3000], Step [60/158]| g_loss: 0.726| d_loss: 0.617| gp_loss: 0.057| r_loss: 0.066| p_loss: 0.100| v_loss: 0.025| per_loss: 0.360 | a_loss: 0.549
Train: Epoch [1679/3000], Step [90/158]| g_loss: 0.738| d_loss: 0.572| gp_loss: 0.056| r_loss: 0.067| p_loss: 0.100| v_loss: 0.025| per_loss: 0.351 | a_loss: 0.561
Train: Epoch [1679/3000], Step [120/158]| g_loss: 0.740| d_loss: 0.595| gp_loss: 0.057| r_loss: 0.069| p_loss: 0.104| v_loss: 0.025| per_loss: 0.343 | a_loss: 0.560
Train: Epoch [1679/3000], Step [150/158]| g_loss: 0.699| d_loss: 0.630| gp_loss: 0.060| r_loss: 0.068| p_loss: 0.101| v_loss: 0.024| per_loss: 0.334 | a_loss: 0.523
Train: Epoch [1680/3000], Step [30/158]| g_loss: 0.692| d_loss: 0.715| gp_loss: 0.197| r_loss: 0.067| p_loss: 0.102| v_loss: 0.025| per_loss: 0.318 | a_loss: 0.518
Train: Epoch [1680/3000], Step [60/158]| g_loss: 0.724| d_loss: 0.621| gp_loss: 0.055| r_loss: 0.065| p_loss: 0.099| v_loss: 0.026| per_loss: 0.350 | a_loss: 0.548
Train: Epoch [1680/3000], Step [90/158]| g_loss: 0.682| d_loss: 0.634| gp_loss: 0.054| r_loss: 0.069| p_loss: 0.102| v_loss: 0.025| per_loss: 0.353 | a_loss: 0.502
Train: Epoch [1680/3000], Step [120/158]| g_loss: 0.758| d_loss: 0.532| gp_loss: 0.055| r_loss: 0.069| p_loss: 0.102| v_loss: 0.025| per_loss: 0.335 | a_loss: 0.579
Train: Epoch [1680/3000], Step [150/158]| g_loss: 0.690| d_loss: 0.625| gp_loss: 0.059| r_loss: 0.067| p_loss: 0.102| v_loss: 0.024| per_loss: 0.333 | a_loss: 0.515
Train: Epoch [1681/3000], Step [30/158]| g_loss: 0.739| d_loss: 0.720| gp_loss: 0.170| r_loss: 0.069| p_loss: 0.106| v_loss: 0.026| per_loss: 0.347 | a_loss: 0.557
Train: Epoch [1681/3000], Step [60/158]| g_loss: 0.728| d_loss: 0.536| gp_loss: 0.053| r_loss: 0.068| p_loss: 0.101| v_loss: 0.025| per_loss: 0.340 | a_loss: 0.551
Train: Epoch [1681/3000], Step [90/158]| g_loss: 0.750| d_loss: 0.584| gp_loss: 0.054| r_loss: 0.064| p_loss: 0.099| v_loss: 0.024| per_loss: 0.324 | a_loss: 0.580
Train: Epoch [1681/3000], Step [120/158]| g_loss: 0.679| d_loss: 0.626| gp_loss: 0.056| r_loss: 0.068| p_loss: 0.101| v_loss: 0.025| per_loss: 0.345 | a_loss: 0.501
Train: Epoch [1681/3000], Step [150/158]| g_loss: 0.673| d_loss: 0.690| gp_loss: 0.058| r_loss: 0.067| p_loss: 0.102| v_loss: 0.025| per_loss: 0.352 | a_loss: 0.494
Train: Epoch [1682/3000], Step [30/158]| g_loss: 0.644| d_loss: 0.771| gp_loss: 0.117| r_loss: 0.064| p_loss: 0.098| v_loss: 0.025| per_loss: 0.325 | a_loss: 0.474
Train: Epoch [1682/3000], Step [60/158]| g_loss: 0.740| d_loss: 0.626| gp_loss: 0.060| r_loss: 0.071| p_loss: 0.105| v_loss: 0.026| per_loss: 0.333 | a_loss: 0.558
Train: Epoch [1682/3000], Step [90/158]| g_loss: 0.746| d_loss: 0.527| gp_loss: 0.060| r_loss: 0.071| p_loss: 0.107| v_loss: 0.027| per_loss: 0.358 | a_loss: 0.558
Train: Epoch [1682/3000], Step [120/158]| g_loss: 0.757| d_loss: 0.531| gp_loss: 0.058| r_loss: 0.065| p_loss: 0.100| v_loss: 0.025| per_loss: 0.338 | a_loss: 0.583
Train: Epoch [1682/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.665| gp_loss: 0.061| r_loss: 0.069| p_loss: 0.101| v_loss: 0.024| per_loss: 0.343 | a_loss: 0.482
Train: Epoch [1683/3000], Step [30/158]| g_loss: 0.736| d_loss: 0.673| gp_loss: 0.138| r_loss: 0.067| p_loss: 0.100| v_loss: 0.024| per_loss: 0.361 | a_loss: 0.558
Train: Epoch [1683/3000], Step [60/158]| g_loss: 0.732| d_loss: 0.577| gp_loss: 0.053| r_loss: 0.066| p_loss: 0.101| v_loss: 0.025| per_loss: 0.341 | a_loss: 0.557
Train: Epoch [1683/3000], Step [90/158]| g_loss: 0.708| d_loss: 0.603| gp_loss: 0.058| r_loss: 0.068| p_loss: 0.103| v_loss: 0.025| per_loss: 0.331 | a_loss: 0.530
Train: Epoch [1683/3000], Step [120/158]| g_loss: 0.735| d_loss: 0.627| gp_loss: 0.056| r_loss: 0.067| p_loss: 0.097| v_loss: 0.025| per_loss: 0.333 | a_loss: 0.562
Train: Epoch [1683/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.631| gp_loss: 0.060| r_loss: 0.071| p_loss: 0.104| v_loss: 0.026| per_loss: 0.334 | a_loss: 0.493
Train: Epoch [1684/3000], Step [30/158]| g_loss: 0.750| d_loss: 0.715| gp_loss: 0.227| r_loss: 0.066| p_loss: 0.098| v_loss: 0.025| per_loss: 0.334 | a_loss: 0.576
Train: Epoch [1684/3000], Step [60/158]| g_loss: 0.736| d_loss: 0.555| gp_loss: 0.050| r_loss: 0.066| p_loss: 0.100| v_loss: 0.024| per_loss: 0.333 | a_loss: 0.562
Train: Epoch [1684/3000], Step [90/158]| g_loss: 0.772| d_loss: 0.523| gp_loss: 0.052| r_loss: 0.065| p_loss: 0.095| v_loss: 0.024| per_loss: 0.339 | a_loss: 0.602
Train: Epoch [1684/3000], Step [120/158]| g_loss: 0.641| d_loss: 0.714| gp_loss: 0.054| r_loss: 0.067| p_loss: 0.102| v_loss: 0.024| per_loss: 0.339 | a_loss: 0.466
Train: Epoch [1684/3000], Step [150/158]| g_loss: 0.684| d_loss: 0.693| gp_loss: 0.057| r_loss: 0.065| p_loss: 0.101| v_loss: 0.025| per_loss: 0.345 | a_loss: 0.509
Train: Epoch [1685/3000], Step [30/158]| g_loss: 0.706| d_loss: 0.718| gp_loss: 0.096| r_loss: 0.068| p_loss: 0.104| v_loss: 0.024| per_loss: 0.322 | a_loss: 0.530
Train: Epoch [1685/3000], Step [60/158]| g_loss: 0.680| d_loss: 0.625| gp_loss: 0.058| r_loss: 0.063| p_loss: 0.102| v_loss: 0.025| per_loss: 0.344 | a_loss: 0.507
Train: Epoch [1685/3000], Step [90/158]| g_loss: 0.702| d_loss: 0.578| gp_loss: 0.061| r_loss: 0.067| p_loss: 0.100| v_loss: 0.025| per_loss: 0.347 | a_loss: 0.526
Train: Epoch [1685/3000], Step [120/158]| g_loss: 0.714| d_loss: 0.678| gp_loss: 0.058| r_loss: 0.069| p_loss: 0.107| v_loss: 0.025| per_loss: 0.333 | a_loss: 0.534
Train: Epoch [1685/3000], Step [150/158]| g_loss: 0.701| d_loss: 0.583| gp_loss: 0.057| r_loss: 0.072| p_loss: 0.101| v_loss: 0.025| per_loss: 0.334 | a_loss: 0.521
Train: Epoch [1686/3000], Step [30/158]| g_loss: 0.693| d_loss: 0.724| gp_loss: 0.140| r_loss: 0.066| p_loss: 0.100| v_loss: 0.025| per_loss: 0.353 | a_loss: 0.517
Train: Epoch [1686/3000], Step [60/158]| g_loss: 0.735| d_loss: 0.542| gp_loss: 0.058| r_loss: 0.064| p_loss: 0.095| v_loss: 0.024| per_loss: 0.334 | a_loss: 0.567
Train: Epoch [1686/3000], Step [90/158]| g_loss: 0.739| d_loss: 0.578| gp_loss: 0.056| r_loss: 0.069| p_loss: 0.104| v_loss: 0.026| per_loss: 0.349 | a_loss: 0.557
Train: Epoch [1686/3000], Step [120/158]| g_loss: 0.727| d_loss: 0.584| gp_loss: 0.059| r_loss: 0.067| p_loss: 0.102| v_loss: 0.025| per_loss: 0.330 | a_loss: 0.551
Train: Epoch [1686/3000], Step [150/158]| g_loss: 0.772| d_loss: 0.638| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.108| v_loss: 0.026| per_loss: 0.337 | a_loss: 0.588
Train: Epoch [1687/3000], Step [30/158]| g_loss: 0.677| d_loss: 0.778| gp_loss: 0.149| r_loss: 0.069| p_loss: 0.104| v_loss: 0.025| per_loss: 0.322 | a_loss: 0.499
Train: Epoch [1687/3000], Step [60/158]| g_loss: 0.678| d_loss: 0.610| gp_loss: 0.058| r_loss: 0.067| p_loss: 0.098| v_loss: 0.024| per_loss: 0.343 | a_loss: 0.503
Train: Epoch [1687/3000], Step [90/158]| g_loss: 0.659| d_loss: 0.668| gp_loss: 0.057| r_loss: 0.065| p_loss: 0.099| v_loss: 0.024| per_loss: 0.341 | a_loss: 0.487
Train: Epoch [1687/3000], Step [120/158]| g_loss: 0.773| d_loss: 0.525| gp_loss: 0.060| r_loss: 0.066| p_loss: 0.097| v_loss: 0.025| per_loss: 0.368 | a_loss: 0.597
Train: Epoch [1687/3000], Step [150/158]| g_loss: 0.696| d_loss: 0.586| gp_loss: 0.058| r_loss: 0.065| p_loss: 0.099| v_loss: 0.024| per_loss: 0.319 | a_loss: 0.525
Train: Epoch [1688/3000], Step [30/158]| g_loss: 0.713| d_loss: 0.686| gp_loss: 0.142| r_loss: 0.063| p_loss: 0.096| v_loss: 0.025| per_loss: 0.346 | a_loss: 0.543
Train: Epoch [1688/3000], Step [60/158]| g_loss: 0.761| d_loss: 0.536| gp_loss: 0.051| r_loss: 0.066| p_loss: 0.098| v_loss: 0.025| per_loss: 0.344 | a_loss: 0.586
Train: Epoch [1688/3000], Step [90/158]| g_loss: 0.716| d_loss: 0.624| gp_loss: 0.055| r_loss: 0.067| p_loss: 0.099| v_loss: 0.024| per_loss: 0.336 | a_loss: 0.541
Train: Epoch [1688/3000], Step [120/158]| g_loss: 0.687| d_loss: 0.624| gp_loss: 0.056| r_loss: 0.069| p_loss: 0.103| v_loss: 0.025| per_loss: 0.336 | a_loss: 0.507
Train: Epoch [1688/3000], Step [150/158]| g_loss: 0.739| d_loss: 0.605| gp_loss: 0.060| r_loss: 0.066| p_loss: 0.098| v_loss: 0.025| per_loss: 0.333 | a_loss: 0.566
Train: Epoch [1689/3000], Step [30/158]| g_loss: 0.719| d_loss: 0.654| gp_loss: 0.143| r_loss: 0.063| p_loss: 0.095| v_loss: 0.024| per_loss: 0.316 | a_loss: 0.553
Train: Epoch [1689/3000], Step [60/158]| g_loss: 0.721| d_loss: 0.572| gp_loss: 0.054| r_loss: 0.068| p_loss: 0.100| v_loss: 0.024| per_loss: 0.337 | a_loss: 0.545
Train: Epoch [1689/3000], Step [90/158]| g_loss: 0.703| d_loss: 0.634| gp_loss: 0.053| r_loss: 0.064| p_loss: 0.097| v_loss: 0.024| per_loss: 0.322 | a_loss: 0.534
Train: Epoch [1689/3000], Step [120/158]| g_loss: 0.694| d_loss: 0.636| gp_loss: 0.057| r_loss: 0.064| p_loss: 0.096| v_loss: 0.024| per_loss: 0.346 | a_loss: 0.523
Train: Epoch [1689/3000], Step [150/158]| g_loss: 0.691| d_loss: 0.647| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.097| v_loss: 0.025| per_loss: 0.356 | a_loss: 0.514
Train: Epoch [1690/3000], Step [30/158]| g_loss: 0.728| d_loss: 0.634| gp_loss: 0.159| r_loss: 0.066| p_loss: 0.096| v_loss: 0.025| per_loss: 0.334 | a_loss: 0.556
Train: Epoch [1690/3000], Step [60/158]| g_loss: 0.683| d_loss: 0.615| gp_loss: 0.052| r_loss: 0.066| p_loss: 0.098| v_loss: 0.024| per_loss: 0.346 | a_loss: 0.509
Train: Epoch [1690/3000], Step [90/158]| g_loss: 0.734| d_loss: 0.579| gp_loss: 0.053| r_loss: 0.064| p_loss: 0.094| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.567
Train: Epoch [1690/3000], Step [120/158]| g_loss: 0.681| d_loss: 0.668| gp_loss: 0.054| r_loss: 0.067| p_loss: 0.100| v_loss: 0.024| per_loss: 0.344 | a_loss: 0.506
Train: Epoch [1690/3000], Step [150/158]| g_loss: 0.727| d_loss: 0.613| gp_loss: 0.057| r_loss: 0.067| p_loss: 0.102| v_loss: 0.025| per_loss: 0.342 | a_loss: 0.550
Train: Epoch [1691/3000], Step [30/158]| g_loss: 0.724| d_loss: 0.700| gp_loss: 0.169| r_loss: 0.064| p_loss: 0.099| v_loss: 0.024| per_loss: 0.322 | a_loss: 0.554
Train: Epoch [1691/3000], Step [60/158]| g_loss: 0.710| d_loss: 0.578| gp_loss: 0.050| r_loss: 0.068| p_loss: 0.097| v_loss: 0.025| per_loss: 0.329 | a_loss: 0.536
Train: Epoch [1691/3000], Step [90/158]| g_loss: 0.666| d_loss: 0.634| gp_loss: 0.053| r_loss: 0.066| p_loss: 0.097| v_loss: 0.024| per_loss: 0.347 | a_loss: 0.492
Train: Epoch [1691/3000], Step [120/158]| g_loss: 0.687| d_loss: 0.628| gp_loss: 0.057| r_loss: 0.065| p_loss: 0.095| v_loss: 0.023| per_loss: 0.349 | a_loss: 0.516
Train: Epoch [1691/3000], Step [150/158]| g_loss: 0.697| d_loss: 0.668| gp_loss: 0.056| r_loss: 0.068| p_loss: 0.104| v_loss: 0.025| per_loss: 0.346 | a_loss: 0.518
Train: Epoch [1692/3000], Step [30/158]| g_loss: 0.778| d_loss: 0.659| gp_loss: 0.145| r_loss: 0.071| p_loss: 0.107| v_loss: 0.025| per_loss: 0.350 | a_loss: 0.595
Train: Epoch [1692/3000], Step [60/158]| g_loss: 0.649| d_loss: 0.720| gp_loss: 0.055| r_loss: 0.067| p_loss: 0.100| v_loss: 0.024| per_loss: 0.333 | a_loss: 0.475
Train: Epoch [1692/3000], Step [90/158]| g_loss: 0.686| d_loss: 0.609| gp_loss: 0.057| r_loss: 0.072| p_loss: 0.107| v_loss: 0.025| per_loss: 0.346 | a_loss: 0.501
Train: Epoch [1692/3000], Step [120/158]| g_loss: 0.696| d_loss: 0.636| gp_loss: 0.058| r_loss: 0.066| p_loss: 0.100| v_loss: 0.025| per_loss: 0.330 | a_loss: 0.522
Train: Epoch [1692/3000], Step [150/158]| g_loss: 0.746| d_loss: 0.543| gp_loss: 0.063| r_loss: 0.066| p_loss: 0.100| v_loss: 0.024| per_loss: 0.336 | a_loss: 0.572
Train: Epoch [1693/3000], Step [30/158]| g_loss: 0.755| d_loss: 0.691| gp_loss: 0.141| r_loss: 0.068| p_loss: 0.110| v_loss: 0.024| per_loss: 0.338 | a_loss: 0.574
Train: Epoch [1693/3000], Step [60/158]| g_loss: 0.681| d_loss: 0.636| gp_loss: 0.054| r_loss: 0.068| p_loss: 0.105| v_loss: 0.025| per_loss: 0.335 | a_loss: 0.502
Train: Epoch [1693/3000], Step [90/158]| g_loss: 0.718| d_loss: 0.589| gp_loss: 0.057| r_loss: 0.069| p_loss: 0.102| v_loss: 0.024| per_loss: 0.336 | a_loss: 0.541
Train: Epoch [1693/3000], Step [120/158]| g_loss: 0.721| d_loss: 0.539| gp_loss: 0.056| r_loss: 0.067| p_loss: 0.099| v_loss: 0.024| per_loss: 0.345 | a_loss: 0.545
Train: Epoch [1693/3000], Step [150/158]| g_loss: 0.727| d_loss: 0.587| gp_loss: 0.058| r_loss: 0.064| p_loss: 0.097| v_loss: 0.025| per_loss: 0.339 | a_loss: 0.556
Train: Epoch [1694/3000], Step [30/158]| g_loss: 0.710| d_loss: 0.759| gp_loss: 0.169| r_loss: 0.068| p_loss: 0.099| v_loss: 0.025| per_loss: 0.352 | a_loss: 0.532
Train: Epoch [1694/3000], Step [60/158]| g_loss: 0.733| d_loss: 0.516| gp_loss: 0.054| r_loss: 0.066| p_loss: 0.098| v_loss: 0.025| per_loss: 0.346 | a_loss: 0.559
Train: Epoch [1694/3000], Step [90/158]| g_loss: 0.763| d_loss: 0.561| gp_loss: 0.054| r_loss: 0.066| p_loss: 0.099| v_loss: 0.025| per_loss: 0.321 | a_loss: 0.591
Train: Epoch [1694/3000], Step [120/158]| g_loss: 0.745| d_loss: 0.659| gp_loss: 0.055| r_loss: 0.069| p_loss: 0.108| v_loss: 0.025| per_loss: 0.324 | a_loss: 0.565
Train: Epoch [1694/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.696| gp_loss: 0.060| r_loss: 0.068| p_loss: 0.103| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.483
Train: Epoch [1695/3000], Step [30/158]| g_loss: 0.696| d_loss: 0.671| gp_loss: 0.117| r_loss: 0.067| p_loss: 0.099| v_loss: 0.025| per_loss: 0.337 | a_loss: 0.521
Train: Epoch [1695/3000], Step [60/158]| g_loss: 0.706| d_loss: 0.645| gp_loss: 0.051| r_loss: 0.069| p_loss: 0.106| v_loss: 0.025| per_loss: 0.331 | a_loss: 0.527
Train: Epoch [1695/3000], Step [90/158]| g_loss: 0.692| d_loss: 0.701| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.105| v_loss: 0.025| per_loss: 0.330 | a_loss: 0.515
Train: Epoch [1695/3000], Step [120/158]| g_loss: 0.689| d_loss: 0.569| gp_loss: 0.060| r_loss: 0.068| p_loss: 0.100| v_loss: 0.024| per_loss: 0.339 | a_loss: 0.514
Train: Epoch [1695/3000], Step [150/158]| g_loss: 0.777| d_loss: 0.577| gp_loss: 0.060| r_loss: 0.069| p_loss: 0.104| v_loss: 0.026| per_loss: 0.326 | a_loss: 0.597
Train: Epoch [1696/3000], Step [30/158]| g_loss: 0.687| d_loss: 0.702| gp_loss: 0.175| r_loss: 0.066| p_loss: 0.100| v_loss: 0.024| per_loss: 0.322 | a_loss: 0.515
Train: Epoch [1696/3000], Step [60/158]| g_loss: 0.709| d_loss: 0.618| gp_loss: 0.056| r_loss: 0.065| p_loss: 0.098| v_loss: 0.025| per_loss: 0.340 | a_loss: 0.535
Train: Epoch [1696/3000], Step [90/158]| g_loss: 0.740| d_loss: 0.524| gp_loss: 0.053| r_loss: 0.068| p_loss: 0.095| v_loss: 0.024| per_loss: 0.334 | a_loss: 0.566
Train: Epoch [1696/3000], Step [120/158]| g_loss: 0.692| d_loss: 0.642| gp_loss: 0.053| r_loss: 0.067| p_loss: 0.099| v_loss: 0.025| per_loss: 0.336 | a_loss: 0.517
Train: Epoch [1696/3000], Step [150/158]| g_loss: 0.690| d_loss: 0.635| gp_loss: 0.057| r_loss: 0.066| p_loss: 0.096| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.521
Train: Epoch [1697/3000], Step [30/158]| g_loss: 0.693| d_loss: 0.681| gp_loss: 0.151| r_loss: 0.065| p_loss: 0.097| v_loss: 0.024| per_loss: 0.326 | a_loss: 0.522
Train: Epoch [1697/3000], Step [60/158]| g_loss: 0.738| d_loss: 0.572| gp_loss: 0.054| r_loss: 0.066| p_loss: 0.097| v_loss: 0.025| per_loss: 0.336 | a_loss: 0.565
Train: Epoch [1697/3000], Step [90/158]| g_loss: 0.785| d_loss: 0.502| gp_loss: 0.055| r_loss: 0.069| p_loss: 0.102| v_loss: 0.025| per_loss: 0.347 | a_loss: 0.605
Train: Epoch [1697/3000], Step [120/158]| g_loss: 0.695| d_loss: 0.674| gp_loss: 0.054| r_loss: 0.064| p_loss: 0.094| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.528
Train: Epoch [1697/3000], Step [150/158]| g_loss: 0.686| d_loss: 0.674| gp_loss: 0.059| r_loss: 0.067| p_loss: 0.107| v_loss: 0.024| per_loss: 0.341 | a_loss: 0.507
Train: Epoch [1698/3000], Step [30/158]| g_loss: 0.709| d_loss: 0.662| gp_loss: 0.137| r_loss: 0.068| p_loss: 0.099| v_loss: 0.025| per_loss: 0.348 | a_loss: 0.532
Train: Epoch [1698/3000], Step [60/158]| g_loss: 0.734| d_loss: 0.592| gp_loss: 0.052| r_loss: 0.068| p_loss: 0.098| v_loss: 0.025| per_loss: 0.323 | a_loss: 0.560
Train: Epoch [1698/3000], Step [90/158]| g_loss: 0.695| d_loss: 0.693| gp_loss: 0.053| r_loss: 0.064| p_loss: 0.096| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.527
Train: Epoch [1698/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.648| gp_loss: 0.055| r_loss: 0.067| p_loss: 0.098| v_loss: 0.025| per_loss: 0.347 | a_loss: 0.491
Train: Epoch [1698/3000], Step [150/158]| g_loss: 0.682| d_loss: 0.603| gp_loss: 0.060| r_loss: 0.063| p_loss: 0.094| v_loss: 0.024| per_loss: 0.337 | a_loss: 0.514
Train: Epoch [1699/3000], Step [30/158]| g_loss: 0.712| d_loss: 0.724| gp_loss: 0.154| r_loss: 0.068| p_loss: 0.104| v_loss: 0.025| per_loss: 0.344 | a_loss: 0.532
Train: Epoch [1699/3000], Step [60/158]| g_loss: 0.707| d_loss: 0.601| gp_loss: 0.053| r_loss: 0.067| p_loss: 0.101| v_loss: 0.025| per_loss: 0.321 | a_loss: 0.532
Train: Epoch [1699/3000], Step [90/158]| g_loss: 0.680| d_loss: 0.617| gp_loss: 0.052| r_loss: 0.067| p_loss: 0.099| v_loss: 0.024| per_loss: 0.335 | a_loss: 0.506
Train: Epoch [1699/3000], Step [120/158]| g_loss: 0.770| d_loss: 0.539| gp_loss: 0.057| r_loss: 0.068| p_loss: 0.099| v_loss: 0.025| per_loss: 0.342 | a_loss: 0.593
Train: Epoch [1699/3000], Step [150/158]| g_loss: 0.679| d_loss: 0.669| gp_loss: 0.057| r_loss: 0.063| p_loss: 0.095| v_loss: 0.024| per_loss: 0.328 | a_loss: 0.512
Train: Epoch [1700/3000], Step [30/158]| g_loss: 0.742| d_loss: 0.716| gp_loss: 0.174| r_loss: 0.066| p_loss: 0.094| v_loss: 0.024| per_loss: 0.312 | a_loss: 0.574
Train: Epoch [1700/3000], Step [60/158]| g_loss: 0.646| d_loss: 0.586| gp_loss: 0.052| r_loss: 0.065| p_loss: 0.097| v_loss: 0.024| per_loss: 0.335 | a_loss: 0.475
Train: Epoch [1700/3000], Step [90/158]| g_loss: 0.702| d_loss: 0.651| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.098| v_loss: 0.024| per_loss: 0.331 | a_loss: 0.528
Train: Epoch [1700/3000], Step [120/158]| g_loss: 0.730| d_loss: 0.595| gp_loss: 0.055| r_loss: 0.066| p_loss: 0.098| v_loss: 0.024| per_loss: 0.341 | a_loss: 0.557
Train: Epoch [1700/3000], Step [150/158]| g_loss: 0.766| d_loss: 0.578| gp_loss: 0.058| r_loss: 0.068| p_loss: 0.100| v_loss: 0.025| per_loss: 0.336 | a_loss: 0.589
Test: Epoch [1700/3000]| g_loss: 0.629| r_loss: 0.385| p_loss: 0.304| v_loss: 0.023
Train: Epoch [1701/3000], Step [30/158]| g_loss: 0.670| d_loss: 0.599| gp_loss: 0.054| r_loss: 0.066| p_loss: 0.100| v_loss: 0.024| per_loss: 0.345 | a_loss: 0.495
Train: Epoch [1701/3000], Step [60/158]| g_loss: 0.769| d_loss: 0.536| gp_loss: 0.052| r_loss: 0.068| p_loss: 0.101| v_loss: 0.025| per_loss: 0.337 | a_loss: 0.592
Train: Epoch [1701/3000], Step [90/158]| g_loss: 0.691| d_loss: 0.688| gp_loss: 0.051| r_loss: 0.064| p_loss: 0.094| v_loss: 0.023| per_loss: 0.345 | a_loss: 0.523
Train: Epoch [1701/3000], Step [120/158]| g_loss: 0.721| d_loss: 0.601| gp_loss: 0.056| r_loss: 0.065| p_loss: 0.095| v_loss: 0.024| per_loss: 0.338 | a_loss: 0.551
Train: Epoch [1701/3000], Step [150/158]| g_loss: 0.709| d_loss: 0.644| gp_loss: 0.052| r_loss: 0.067| p_loss: 0.101| v_loss: 0.025| per_loss: 0.325 | a_loss: 0.534
Train: Epoch [1702/3000], Step [30/158]| g_loss: 0.684| d_loss: 0.699| gp_loss: 0.155| r_loss: 0.067| p_loss: 0.099| v_loss: 0.024| per_loss: 0.331 | a_loss: 0.511
Train: Epoch [1702/3000], Step [60/158]| g_loss: 0.692| d_loss: 0.564| gp_loss: 0.049| r_loss: 0.065| p_loss: 0.094| v_loss: 0.024| per_loss: 0.326 | a_loss: 0.523
Train: Epoch [1702/3000], Step [90/158]| g_loss: 0.656| d_loss: 0.685| gp_loss: 0.052| r_loss: 0.066| p_loss: 0.096| v_loss: 0.024| per_loss: 0.337 | a_loss: 0.485
Train: Epoch [1702/3000], Step [120/158]| g_loss: 0.750| d_loss: 0.651| gp_loss: 0.056| r_loss: 0.068| p_loss: 0.098| v_loss: 0.024| per_loss: 0.338 | a_loss: 0.574
Train: Epoch [1702/3000], Step [150/158]| g_loss: 0.706| d_loss: 0.569| gp_loss: 0.056| r_loss: 0.066| p_loss: 0.099| v_loss: 0.025| per_loss: 0.351 | a_loss: 0.530
Train: Epoch [1703/3000], Step [30/158]| g_loss: 0.708| d_loss: 0.665| gp_loss: 0.126| r_loss: 0.065| p_loss: 0.096| v_loss: 0.024| per_loss: 0.341 | a_loss: 0.536
Train: Epoch [1703/3000], Step [60/158]| g_loss: 0.672| d_loss: 0.648| gp_loss: 0.054| r_loss: 0.066| p_loss: 0.095| v_loss: 0.025| per_loss: 0.329 | a_loss: 0.501
Train: Epoch [1703/3000], Step [90/158]| g_loss: 0.786| d_loss: 0.504| gp_loss: 0.057| r_loss: 0.064| p_loss: 0.096| v_loss: 0.024| per_loss: 0.342 | a_loss: 0.615
Train: Epoch [1703/3000], Step [120/158]| g_loss: 0.728| d_loss: 0.604| gp_loss: 0.054| r_loss: 0.066| p_loss: 0.097| v_loss: 0.023| per_loss: 0.330 | a_loss: 0.558
Train: Epoch [1703/3000], Step [150/158]| g_loss: 0.707| d_loss: 0.614| gp_loss: 0.057| r_loss: 0.066| p_loss: 0.100| v_loss: 0.025| per_loss: 0.342 | a_loss: 0.532
Train: Epoch [1704/3000], Step [30/158]| g_loss: 0.687| d_loss: 0.696| gp_loss: 0.156| r_loss: 0.065| p_loss: 0.096| v_loss: 0.025| per_loss: 0.339 | a_loss: 0.516
Train: Epoch [1704/3000], Step [60/158]| g_loss: 0.688| d_loss: 0.610| gp_loss: 0.054| r_loss: 0.065| p_loss: 0.094| v_loss: 0.023| per_loss: 0.340 | a_loss: 0.519
Train: Epoch [1704/3000], Step [90/158]| g_loss: 0.734| d_loss: 0.593| gp_loss: 0.055| r_loss: 0.064| p_loss: 0.092| v_loss: 0.023| per_loss: 0.313 | a_loss: 0.570
Train: Epoch [1704/3000], Step [120/158]| g_loss: 0.705| d_loss: 0.581| gp_loss: 0.057| r_loss: 0.065| p_loss: 0.094| v_loss: 0.024| per_loss: 0.325 | a_loss: 0.536
Train: Epoch [1704/3000], Step [150/158]| g_loss: 0.654| d_loss: 0.694| gp_loss: 0.058| r_loss: 0.065| p_loss: 0.097| v_loss: 0.023| per_loss: 0.328 | a_loss: 0.484
Train: Epoch [1705/3000], Step [30/158]| g_loss: 0.712| d_loss: 0.723| gp_loss: 0.197| r_loss: 0.066| p_loss: 0.099| v_loss: 0.025| per_loss: 0.329 | a_loss: 0.539
Train: Epoch [1705/3000], Step [60/158]| g_loss: 0.717| d_loss: 0.571| gp_loss: 0.053| r_loss: 0.066| p_loss: 0.096| v_loss: 0.024| per_loss: 0.342 | a_loss: 0.545
Train: Epoch [1705/3000], Step [90/158]| g_loss: 0.665| d_loss: 0.665| gp_loss: 0.052| r_loss: 0.066| p_loss: 0.099| v_loss: 0.025| per_loss: 0.322 | a_loss: 0.493
Train: Epoch [1705/3000], Step [120/158]| g_loss: 0.690| d_loss: 0.606| gp_loss: 0.057| r_loss: 0.065| p_loss: 0.097| v_loss: 0.024| per_loss: 0.326 | a_loss: 0.520
Train: Epoch [1705/3000], Step [150/158]| g_loss: 0.782| d_loss: 0.563| gp_loss: 0.056| r_loss: 0.064| p_loss: 0.095| v_loss: 0.024| per_loss: 0.343 | a_loss: 0.612
Train: Epoch [1706/3000], Step [30/158]| g_loss: 0.639| d_loss: 0.780| gp_loss: 0.145| r_loss: 0.066| p_loss: 0.099| v_loss: 0.024| per_loss: 0.322 | a_loss: 0.467
Train: Epoch [1706/3000], Step [60/158]| g_loss: 0.746| d_loss: 0.550| gp_loss: 0.054| r_loss: 0.067| p_loss: 0.096| v_loss: 0.025| per_loss: 0.328 | a_loss: 0.572
Train: Epoch [1706/3000], Step [90/158]| g_loss: 0.722| d_loss: 0.598| gp_loss: 0.055| r_loss: 0.066| p_loss: 0.096| v_loss: 0.025| per_loss: 0.330 | a_loss: 0.550
Train: Epoch [1706/3000], Step [120/158]| g_loss: 0.701| d_loss: 0.555| gp_loss: 0.057| r_loss: 0.064| p_loss: 0.094| v_loss: 0.024| per_loss: 0.344 | a_loss: 0.532
Train: Epoch [1706/3000], Step [150/158]| g_loss: 0.699| d_loss: 0.682| gp_loss: 0.054| r_loss: 0.065| p_loss: 0.100| v_loss: 0.024| per_loss: 0.333 | a_loss: 0.527
Train: Epoch [1707/3000], Step [30/158]| g_loss: 0.712| d_loss: 0.650| gp_loss: 0.152| r_loss: 0.066| p_loss: 0.094| v_loss: 0.024| per_loss: 0.340 | a_loss: 0.540
Train: Epoch [1707/3000], Step [60/158]| g_loss: 0.740| d_loss: 0.666| gp_loss: 0.053| r_loss: 0.067| p_loss: 0.102| v_loss: 0.024| per_loss: 0.332 | a_loss: 0.565
Train: Epoch [1707/3000], Step [90/158]| g_loss: 0.642| d_loss: 0.670| gp_loss: 0.055| r_loss: 0.065| p_loss: 0.097| v_loss: 0.023| per_loss: 0.305 | a_loss: 0.475
Train: Epoch [1707/3000], Step [120/158]| g_loss: 0.654| d_loss: 0.646| gp_loss: 0.053| r_loss: 0.069| p_loss: 0.100| v_loss: 0.026| per_loss: 0.333 | a_loss: 0.476
Train: Epoch [1707/3000], Step [150/158]| g_loss: 0.755| d_loss: 0.574| gp_loss: 0.057| r_loss: 0.065| p_loss: 0.101| v_loss: 0.025| per_loss: 0.340 | a_loss: 0.581
Train: Epoch [1708/3000], Step [30/158]| g_loss: 0.675| d_loss: 0.718| gp_loss: 0.131| r_loss: 0.067| p_loss: 0.100| v_loss: 0.024| per_loss: 0.349 | a_loss: 0.499
Train: Epoch [1708/3000], Step [60/158]| g_loss: 0.720| d_loss: 0.614| gp_loss: 0.057| r_loss: 0.064| p_loss: 0.096| v_loss: 0.024| per_loss: 0.333 | a_loss: 0.551
Train: Epoch [1708/3000], Step [90/158]| g_loss: 0.717| d_loss: 0.579| gp_loss: 0.056| r_loss: 0.065| p_loss: 0.095| v_loss: 0.024| per_loss: 0.331 | a_loss: 0.547
Train: Epoch [1708/3000], Step [120/158]| g_loss: 0.714| d_loss: 0.613| gp_loss: 0.057| r_loss: 0.066| p_loss: 0.097| v_loss: 0.025| per_loss: 0.331 | a_loss: 0.542
Train: Epoch [1708/3000], Step [150/158]| g_loss: 0.684| d_loss: 0.620| gp_loss: 0.058| r_loss: 0.067| p_loss: 0.099| v_loss: 0.024| per_loss: 0.321 | a_loss: 0.512
Train: Epoch [1709/3000], Step [30/158]| g_loss: 0.741| d_loss: 0.647| gp_loss: 0.146| r_loss: 0.064| p_loss: 0.096| v_loss: 0.025| per_loss: 0.347 | a_loss: 0.569
Train: Epoch [1709/3000], Step [60/158]| g_loss: 0.651| d_loss: 0.730| gp_loss: 0.053| r_loss: 0.067| p_loss: 0.105| v_loss: 0.024| per_loss: 0.334 | a_loss: 0.474
Train: Epoch [1709/3000], Step [90/158]| g_loss: 0.702| d_loss: 0.561| gp_loss: 0.059| r_loss: 0.066| p_loss: 0.100| v_loss: 0.025| per_loss: 0.331 | a_loss: 0.527
Train: Epoch [1709/3000], Step [120/158]| g_loss: 0.759| d_loss: 0.544| gp_loss: 0.056| r_loss: 0.067| p_loss: 0.099| v_loss: 0.026| per_loss: 0.338 | a_loss: 0.583
Train: Epoch [1709/3000], Step [150/158]| g_loss: 0.706| d_loss: 0.621| gp_loss: 0.063| r_loss: 0.064| p_loss: 0.093| v_loss: 0.023| per_loss: 0.336 | a_loss: 0.538
Train: Epoch [1710/3000], Step [30/158]| g_loss: 0.696| d_loss: 0.766| gp_loss: 0.163| r_loss: 0.072| p_loss: 0.096| v_loss: 0.024| per_loss: 0.323 | a_loss: 0.519
Train: Epoch [1710/3000], Step [60/158]| g_loss: 0.640| d_loss: 0.657| gp_loss: 0.048| r_loss: 0.067| p_loss: 0.100| v_loss: 0.024| per_loss: 0.331 | a_loss: 0.466
Train: Epoch [1710/3000], Step [90/158]| g_loss: 0.713| d_loss: 0.558| gp_loss: 0.060| r_loss: 0.064| p_loss: 0.093| v_loss: 0.024| per_loss: 0.344 | a_loss: 0.545
Train: Epoch [1710/3000], Step [120/158]| g_loss: 0.702| d_loss: 0.652| gp_loss: 0.061| r_loss: 0.066| p_loss: 0.098| v_loss: 0.024| per_loss: 0.338 | a_loss: 0.528
Train: Epoch [1710/3000], Step [150/158]| g_loss: 0.789| d_loss: 0.481| gp_loss: 0.063| r_loss: 0.070| p_loss: 0.100| v_loss: 0.026| per_loss: 0.336 | a_loss: 0.609
Train: Epoch [1711/3000], Step [30/158]| g_loss: 0.719| d_loss: 0.746| gp_loss: 0.147| r_loss: 0.066| p_loss: 0.105| v_loss: 0.024| per_loss: 0.325 | a_loss: 0.544
Train: Epoch [1711/3000], Step [60/158]| g_loss: 0.674| d_loss: 0.620| gp_loss: 0.054| r_loss: 0.066| p_loss: 0.095| v_loss: 0.024| per_loss: 0.326 | a_loss: 0.504
Train: Epoch [1711/3000], Step [90/158]| g_loss: 0.778| d_loss: 0.518| gp_loss: 0.057| r_loss: 0.067| p_loss: 0.100| v_loss: 0.025| per_loss: 0.332 | a_loss: 0.603
Train: Epoch [1711/3000], Step [120/158]| g_loss: 0.646| d_loss: 0.689| gp_loss: 0.053| r_loss: 0.065| p_loss: 0.094| v_loss: 0.024| per_loss: 0.326 | a_loss: 0.478
Train: Epoch [1711/3000], Step [150/158]| g_loss: 0.721| d_loss: 0.556| gp_loss: 0.058| r_loss: 0.065| p_loss: 0.094| v_loss: 0.025| per_loss: 0.342 | a_loss: 0.549
Train: Epoch [1712/3000], Step [30/158]| g_loss: 0.694| d_loss: 0.702| gp_loss: 0.174| r_loss: 0.063| p_loss: 0.093| v_loss: 0.023| per_loss: 0.330 | a_loss: 0.529
Train: Epoch [1712/3000], Step [60/158]| g_loss: 0.717| d_loss: 0.641| gp_loss: 0.054| r_loss: 0.066| p_loss: 0.097| v_loss: 0.025| per_loss: 0.333 | a_loss: 0.545
Train: Epoch [1712/3000], Step [90/158]| g_loss: 0.740| d_loss: 0.589| gp_loss: 0.056| r_loss: 0.067| p_loss: 0.099| v_loss: 0.025| per_loss: 0.342 | a_loss: 0.563
Train: Epoch [1712/3000], Step [120/158]| g_loss: 0.700| d_loss: 0.612| gp_loss: 0.057| r_loss: 0.062| p_loss: 0.094| v_loss: 0.024| per_loss: 0.332 | a_loss: 0.534
Train: Epoch [1712/3000], Step [150/158]| g_loss: 0.681| d_loss: 0.608| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.102| v_loss: 0.025| per_loss: 0.329 | a_loss: 0.505
Train: Epoch [1713/3000], Step [30/158]| g_loss: 0.721| d_loss: 0.695| gp_loss: 0.156| r_loss: 0.065| p_loss: 0.097| v_loss: 0.024| per_loss: 0.328 | a_loss: 0.550
Train: Epoch [1713/3000], Step [60/158]| g_loss: 0.676| d_loss: 0.660| gp_loss: 0.053| r_loss: 0.064| p_loss: 0.098| v_loss: 0.024| per_loss: 0.337 | a_loss: 0.505
Train: Epoch [1713/3000], Step [90/158]| g_loss: 0.706| d_loss: 0.589| gp_loss: 0.056| r_loss: 0.065| p_loss: 0.096| v_loss: 0.024| per_loss: 0.340 | a_loss: 0.535
Train: Epoch [1713/3000], Step [120/158]| g_loss: 0.786| d_loss: 0.480| gp_loss: 0.061| r_loss: 0.070| p_loss: 0.102| v_loss: 0.026| per_loss: 0.337 | a_loss: 0.606
Train: Epoch [1713/3000], Step [150/158]| g_loss: 0.723| d_loss: 0.636| gp_loss: 0.056| r_loss: 0.064| p_loss: 0.101| v_loss: 0.024| per_loss: 0.331 | a_loss: 0.551
Train: Epoch [1714/3000], Step [30/158]| g_loss: 0.679| d_loss: 0.751| gp_loss: 0.167| r_loss: 0.067| p_loss: 0.101| v_loss: 0.025| per_loss: 0.321 | a_loss: 0.505
Train: Epoch [1714/3000], Step [60/158]| g_loss: 0.755| d_loss: 0.615| gp_loss: 0.051| r_loss: 0.067| p_loss: 0.102| v_loss: 0.026| per_loss: 0.343 | a_loss: 0.577
Train: Epoch [1714/3000], Step [90/158]| g_loss: 0.670| d_loss: 0.640| gp_loss: 0.057| r_loss: 0.066| p_loss: 0.098| v_loss: 0.024| per_loss: 0.340 | a_loss: 0.497
Train: Epoch [1714/3000], Step [120/158]| g_loss: 0.731| d_loss: 0.596| gp_loss: 0.056| r_loss: 0.064| p_loss: 0.096| v_loss: 0.024| per_loss: 0.337 | a_loss: 0.562
Train: Epoch [1714/3000], Step [150/158]| g_loss: 0.699| d_loss: 0.598| gp_loss: 0.056| r_loss: 0.066| p_loss: 0.100| v_loss: 0.024| per_loss: 0.336 | a_loss: 0.525
Train: Epoch [1715/3000], Step [30/158]| g_loss: 0.680| d_loss: 0.769| gp_loss: 0.171| r_loss: 0.064| p_loss: 0.098| v_loss: 0.024| per_loss: 0.317 | a_loss: 0.511
Train: Epoch [1715/3000], Step [60/158]| g_loss: 0.730| d_loss: 0.546| gp_loss: 0.050| r_loss: 0.065| p_loss: 0.094| v_loss: 0.025| per_loss: 0.351 | a_loss: 0.558
Train: Epoch [1715/3000], Step [90/158]| g_loss: 0.762| d_loss: 0.575| gp_loss: 0.053| r_loss: 0.066| p_loss: 0.100| v_loss: 0.025| per_loss: 0.327 | a_loss: 0.589
Train: Epoch [1715/3000], Step [120/158]| g_loss: 0.682| d_loss: 0.577| gp_loss: 0.054| r_loss: 0.068| p_loss: 0.097| v_loss: 0.025| per_loss: 0.324 | a_loss: 0.508
Train: Epoch [1715/3000], Step [150/158]| g_loss: 0.700| d_loss: 0.685| gp_loss: 0.054| r_loss: 0.064| p_loss: 0.097| v_loss: 0.024| per_loss: 0.345 | a_loss: 0.529
Train: Epoch [1716/3000], Step [30/158]| g_loss: 0.656| d_loss: 0.756| gp_loss: 0.068| r_loss: 0.068| p_loss: 0.110| v_loss: 0.024| per_loss: 0.354 | a_loss: 0.474
Train: Epoch [1716/3000], Step [60/158]| g_loss: 0.698| d_loss: 0.684| gp_loss: 0.060| r_loss: 0.066| p_loss: 0.102| v_loss: 0.024| per_loss: 0.320 | a_loss: 0.525
Train: Epoch [1716/3000], Step [90/158]| g_loss: 0.621| d_loss: 0.687| gp_loss: 0.061| r_loss: 0.068| p_loss: 0.106| v_loss: 0.025| per_loss: 0.336 | a_loss: 0.441
Train: Epoch [1716/3000], Step [120/158]| g_loss: 0.796| d_loss: 0.508| gp_loss: 0.064| r_loss: 0.067| p_loss: 0.101| v_loss: 0.024| per_loss: 0.343 | a_loss: 0.620
Train: Epoch [1716/3000], Step [150/158]| g_loss: 0.718| d_loss: 0.511| gp_loss: 0.060| r_loss: 0.067| p_loss: 0.096| v_loss: 0.025| per_loss: 0.328 | a_loss: 0.545
Train: Epoch [1717/3000], Step [30/158]| g_loss: 0.698| d_loss: 0.736| gp_loss: 0.152| r_loss: 0.066| p_loss: 0.098| v_loss: 0.025| per_loss: 0.332 | a_loss: 0.526
Train: Epoch [1717/3000], Step [60/158]| g_loss: 0.696| d_loss: 0.655| gp_loss: 0.059| r_loss: 0.069| p_loss: 0.104| v_loss: 0.025| per_loss: 0.338 | a_loss: 0.517
Train: Epoch [1717/3000], Step [90/158]| g_loss: 0.688| d_loss: 0.632| gp_loss: 0.057| r_loss: 0.066| p_loss: 0.102| v_loss: 0.024| per_loss: 0.349 | a_loss: 0.512
Train: Epoch [1717/3000], Step [120/158]| g_loss: 0.747| d_loss: 0.549| gp_loss: 0.063| r_loss: 0.066| p_loss: 0.095| v_loss: 0.024| per_loss: 0.328 | a_loss: 0.577
Train: Epoch [1717/3000], Step [150/158]| g_loss: 0.732| d_loss: 0.566| gp_loss: 0.059| r_loss: 0.066| p_loss: 0.100| v_loss: 0.025| per_loss: 0.331 | a_loss: 0.558
Train: Epoch [1718/3000], Step [30/158]| g_loss: 0.705| d_loss: 0.678| gp_loss: 0.158| r_loss: 0.067| p_loss: 0.098| v_loss: 0.025| per_loss: 0.323 | a_loss: 0.532
Train: Epoch [1718/3000], Step [60/158]| g_loss: 0.743| d_loss: 0.583| gp_loss: 0.058| r_loss: 0.065| p_loss: 0.099| v_loss: 0.024| per_loss: 0.335 | a_loss: 0.572
Train: Epoch [1718/3000], Step [90/158]| g_loss: 0.676| d_loss: 0.646| gp_loss: 0.057| r_loss: 0.067| p_loss: 0.098| v_loss: 0.025| per_loss: 0.346 | a_loss: 0.501
Train: Epoch [1718/3000], Step [120/158]| g_loss: 0.727| d_loss: 0.592| gp_loss: 0.060| r_loss: 0.066| p_loss: 0.098| v_loss: 0.024| per_loss: 0.331 | a_loss: 0.555
Train: Epoch [1718/3000], Step [150/158]| g_loss: 0.679| d_loss: 0.659| gp_loss: 0.059| r_loss: 0.064| p_loss: 0.100| v_loss: 0.024| per_loss: 0.334 | a_loss: 0.506
Train: Epoch [1719/3000], Step [30/158]| g_loss: 0.755| d_loss: 0.680| gp_loss: 0.160| r_loss: 0.071| p_loss: 0.103| v_loss: 0.025| per_loss: 0.341 | a_loss: 0.574
Train: Epoch [1719/3000], Step [60/158]| g_loss: 0.699| d_loss: 0.577| gp_loss: 0.054| r_loss: 0.071| p_loss: 0.105| v_loss: 0.024| per_loss: 0.339 | a_loss: 0.517
Train: Epoch [1719/3000], Step [90/158]| g_loss: 0.713| d_loss: 0.647| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.104| v_loss: 0.025| per_loss: 0.350 | a_loss: 0.533
Train: Epoch [1719/3000], Step [120/158]| g_loss: 0.707| d_loss: 0.589| gp_loss: 0.057| r_loss: 0.064| p_loss: 0.095| v_loss: 0.024| per_loss: 0.342 | a_loss: 0.538
Train: Epoch [1719/3000], Step [150/158]| g_loss: 0.743| d_loss: 0.620| gp_loss: 0.062| r_loss: 0.067| p_loss: 0.099| v_loss: 0.025| per_loss: 0.319 | a_loss: 0.570
Train: Epoch [1720/3000], Step [30/158]| g_loss: 0.702| d_loss: 0.713| gp_loss: 0.222| r_loss: 0.068| p_loss: 0.101| v_loss: 0.025| per_loss: 0.327 | a_loss: 0.525
Train: Epoch [1720/3000], Step [60/158]| g_loss: 0.748| d_loss: 0.624| gp_loss: 0.054| r_loss: 0.066| p_loss: 0.098| v_loss: 0.024| per_loss: 0.333 | a_loss: 0.575
Train: Epoch [1720/3000], Step [90/158]| g_loss: 0.699| d_loss: 0.592| gp_loss: 0.052| r_loss: 0.068| p_loss: 0.098| v_loss: 0.024| per_loss: 0.339 | a_loss: 0.524
Train: Epoch [1720/3000], Step [120/158]| g_loss: 0.715| d_loss: 0.611| gp_loss: 0.059| r_loss: 0.066| p_loss: 0.099| v_loss: 0.024| per_loss: 0.330 | a_loss: 0.542
Train: Epoch [1720/3000], Step [150/158]| g_loss: 0.648| d_loss: 0.647| gp_loss: 0.056| r_loss: 0.063| p_loss: 0.095| v_loss: 0.024| per_loss: 0.349 | a_loss: 0.479
Train: Epoch [1721/3000], Step [30/158]| g_loss: 0.698| d_loss: 0.696| gp_loss: 0.097| r_loss: 0.067| p_loss: 0.099| v_loss: 0.025| per_loss: 0.330 | a_loss: 0.524
Train: Epoch [1721/3000], Step [60/158]| g_loss: 0.746| d_loss: 0.605| gp_loss: 0.053| r_loss: 0.067| p_loss: 0.099| v_loss: 0.024| per_loss: 0.333 | a_loss: 0.572
Train: Epoch [1721/3000], Step [90/158]| g_loss: 0.684| d_loss: 0.613| gp_loss: 0.058| r_loss: 0.065| p_loss: 0.096| v_loss: 0.024| per_loss: 0.335 | a_loss: 0.513
Train: Epoch [1721/3000], Step [120/158]| g_loss: 0.700| d_loss: 0.661| gp_loss: 0.058| r_loss: 0.065| p_loss: 0.098| v_loss: 0.024| per_loss: 0.337 | a_loss: 0.527
Train: Epoch [1721/3000], Step [150/158]| g_loss: 0.676| d_loss: 0.612| gp_loss: 0.061| r_loss: 0.067| p_loss: 0.100| v_loss: 0.024| per_loss: 0.323 | a_loss: 0.503
Train: Epoch [1722/3000], Step [30/158]| g_loss: 0.781| d_loss: 0.639| gp_loss: 0.153| r_loss: 0.066| p_loss: 0.101| v_loss: 0.025| per_loss: 0.331 | a_loss: 0.606
Train: Epoch [1722/3000], Step [60/158]| g_loss: 0.723| d_loss: 0.590| gp_loss: 0.056| r_loss: 0.066| p_loss: 0.098| v_loss: 0.024| per_loss: 0.326 | a_loss: 0.552
Train: Epoch [1722/3000], Step [90/158]| g_loss: 0.685| d_loss: 0.628| gp_loss: 0.057| r_loss: 0.067| p_loss: 0.098| v_loss: 0.025| per_loss: 0.337 | a_loss: 0.511
Train: Epoch [1722/3000], Step [120/158]| g_loss: 0.693| d_loss: 0.643| gp_loss: 0.059| r_loss: 0.068| p_loss: 0.101| v_loss: 0.024| per_loss: 0.345 | a_loss: 0.516
Train: Epoch [1722/3000], Step [150/158]| g_loss: 0.685| d_loss: 0.642| gp_loss: 0.060| r_loss: 0.068| p_loss: 0.101| v_loss: 0.024| per_loss: 0.319 | a_loss: 0.510
Train: Epoch [1723/3000], Step [30/158]| g_loss: 0.733| d_loss: 0.665| gp_loss: 0.173| r_loss: 0.068| p_loss: 0.098| v_loss: 0.025| per_loss: 0.321 | a_loss: 0.559
Train: Epoch [1723/3000], Step [60/158]| g_loss: 0.674| d_loss: 0.652| gp_loss: 0.055| r_loss: 0.065| p_loss: 0.093| v_loss: 0.024| per_loss: 0.325 | a_loss: 0.506
Train: Epoch [1723/3000], Step [90/158]| g_loss: 0.683| d_loss: 0.596| gp_loss: 0.059| r_loss: 0.066| p_loss: 0.097| v_loss: 0.025| per_loss: 0.338 | a_loss: 0.510
Train: Epoch [1723/3000], Step [120/158]| g_loss: 0.737| d_loss: 0.701| gp_loss: 0.053| r_loss: 0.068| p_loss: 0.100| v_loss: 0.024| per_loss: 0.339 | a_loss: 0.560
Train: Epoch [1723/3000], Step [150/158]| g_loss: 0.672| d_loss: 0.635| gp_loss: 0.058| r_loss: 0.071| p_loss: 0.103| v_loss: 0.025| per_loss: 0.325 | a_loss: 0.493
Train: Epoch [1724/3000], Step [30/158]| g_loss: 0.728| d_loss: 0.715| gp_loss: 0.162| r_loss: 0.067| p_loss: 0.103| v_loss: 0.023| per_loss: 0.338 | a_loss: 0.552
Train: Epoch [1724/3000], Step [60/158]| g_loss: 0.721| d_loss: 0.497| gp_loss: 0.054| r_loss: 0.068| p_loss: 0.098| v_loss: 0.025| per_loss: 0.323 | a_loss: 0.547
Train: Epoch [1724/3000], Step [90/158]| g_loss: 0.693| d_loss: 0.640| gp_loss: 0.053| r_loss: 0.065| p_loss: 0.097| v_loss: 0.023| per_loss: 0.328 | a_loss: 0.523
Train: Epoch [1724/3000], Step [120/158]| g_loss: 0.708| d_loss: 0.657| gp_loss: 0.059| r_loss: 0.064| p_loss: 0.094| v_loss: 0.024| per_loss: 0.327 | a_loss: 0.540
Train: Epoch [1724/3000], Step [150/158]| g_loss: 0.700| d_loss: 0.616| gp_loss: 0.058| r_loss: 0.066| p_loss: 0.100| v_loss: 0.025| per_loss: 0.341 | a_loss: 0.525
Train: Epoch [1725/3000], Step [30/158]| g_loss: 0.693| d_loss: 0.722| gp_loss: 0.102| r_loss: 0.067| p_loss: 0.102| v_loss: 0.025| per_loss: 0.325 | a_loss: 0.518
Train: Epoch [1725/3000], Step [60/158]| g_loss: 0.682| d_loss: 0.621| gp_loss: 0.057| r_loss: 0.071| p_loss: 0.106| v_loss: 0.024| per_loss: 0.331 | a_loss: 0.501
Train: Epoch [1725/3000], Step [90/158]| g_loss: 0.759| d_loss: 0.581| gp_loss: 0.055| r_loss: 0.066| p_loss: 0.093| v_loss: 0.024| per_loss: 0.347 | a_loss: 0.587
Train: Epoch [1725/3000], Step [120/158]| g_loss: 0.716| d_loss: 0.528| gp_loss: 0.060| r_loss: 0.065| p_loss: 0.097| v_loss: 0.024| per_loss: 0.339 | a_loss: 0.544
Train: Epoch [1725/3000], Step [150/158]| g_loss: 0.695| d_loss: 0.646| gp_loss: 0.058| r_loss: 0.063| p_loss: 0.094| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.530
Train: Epoch [1726/3000], Step [30/158]| g_loss: 0.701| d_loss: 0.693| gp_loss: 0.157| r_loss: 0.066| p_loss: 0.097| v_loss: 0.025| per_loss: 0.322 | a_loss: 0.529
Train: Epoch [1726/3000], Step [60/158]| g_loss: 0.778| d_loss: 0.504| gp_loss: 0.057| r_loss: 0.067| p_loss: 0.103| v_loss: 0.024| per_loss: 0.351 | a_loss: 0.600
Train: Epoch [1726/3000], Step [90/158]| g_loss: 0.703| d_loss: 0.640| gp_loss: 0.051| r_loss: 0.065| p_loss: 0.095| v_loss: 0.024| per_loss: 0.328 | a_loss: 0.534
Train: Epoch [1726/3000], Step [120/158]| g_loss: 0.700| d_loss: 0.684| gp_loss: 0.055| r_loss: 0.064| p_loss: 0.097| v_loss: 0.024| per_loss: 0.333 | a_loss: 0.530
Train: Epoch [1726/3000], Step [150/158]| g_loss: 0.680| d_loss: 0.604| gp_loss: 0.059| r_loss: 0.065| p_loss: 0.094| v_loss: 0.024| per_loss: 0.322 | a_loss: 0.512
Train: Epoch [1727/3000], Step [30/158]| g_loss: 0.729| d_loss: 0.699| gp_loss: 0.162| r_loss: 0.065| p_loss: 0.101| v_loss: 0.024| per_loss: 0.338 | a_loss: 0.555
Train: Epoch [1727/3000], Step [60/158]| g_loss: 0.706| d_loss: 0.642| gp_loss: 0.052| r_loss: 0.069| p_loss: 0.099| v_loss: 0.024| per_loss: 0.335 | a_loss: 0.530
Train: Epoch [1727/3000], Step [90/158]| g_loss: 0.653| d_loss: 0.669| gp_loss: 0.057| r_loss: 0.064| p_loss: 0.096| v_loss: 0.023| per_loss: 0.327 | a_loss: 0.485
Train: Epoch [1727/3000], Step [120/158]| g_loss: 0.680| d_loss: 0.620| gp_loss: 0.056| r_loss: 0.064| p_loss: 0.098| v_loss: 0.025| per_loss: 0.314 | a_loss: 0.511
Train: Epoch [1727/3000], Step [150/158]| g_loss: 0.738| d_loss: 0.555| gp_loss: 0.060| r_loss: 0.066| p_loss: 0.097| v_loss: 0.024| per_loss: 0.341 | a_loss: 0.566
Train: Epoch [1728/3000], Step [30/158]| g_loss: 0.719| d_loss: 0.691| gp_loss: 0.114| r_loss: 0.064| p_loss: 0.096| v_loss: 0.024| per_loss: 0.347 | a_loss: 0.548
Train: Epoch [1728/3000], Step [60/158]| g_loss: 0.684| d_loss: 0.639| gp_loss: 0.060| r_loss: 0.066| p_loss: 0.099| v_loss: 0.024| per_loss: 0.336 | a_loss: 0.512
Train: Epoch [1728/3000], Step [90/158]| g_loss: 0.713| d_loss: 0.629| gp_loss: 0.058| r_loss: 0.068| p_loss: 0.098| v_loss: 0.026| per_loss: 0.337 | a_loss: 0.537
Train: Epoch [1728/3000], Step [120/158]| g_loss: 0.699| d_loss: 0.583| gp_loss: 0.060| r_loss: 0.066| p_loss: 0.097| v_loss: 0.024| per_loss: 0.334 | a_loss: 0.527
Train: Epoch [1728/3000], Step [150/158]| g_loss: 0.727| d_loss: 0.609| gp_loss: 0.059| r_loss: 0.065| p_loss: 0.103| v_loss: 0.025| per_loss: 0.317 | a_loss: 0.554
Train: Epoch [1729/3000], Step [30/158]| g_loss: 0.706| d_loss: 0.657| gp_loss: 0.108| r_loss: 0.064| p_loss: 0.097| v_loss: 0.024| per_loss: 0.339 | a_loss: 0.535
Train: Epoch [1729/3000], Step [60/158]| g_loss: 0.703| d_loss: 0.602| gp_loss: 0.059| r_loss: 0.064| p_loss: 0.097| v_loss: 0.024| per_loss: 0.338 | a_loss: 0.533
Train: Epoch [1729/3000], Step [90/158]| g_loss: 0.708| d_loss: 0.574| gp_loss: 0.060| r_loss: 0.065| p_loss: 0.092| v_loss: 0.024| per_loss: 0.332 | a_loss: 0.540
Train: Epoch [1729/3000], Step [120/158]| g_loss: 0.679| d_loss: 0.634| gp_loss: 0.059| r_loss: 0.069| p_loss: 0.101| v_loss: 0.024| per_loss: 0.322 | a_loss: 0.503
Train: Epoch [1729/3000], Step [150/158]| g_loss: 0.723| d_loss: 0.590| gp_loss: 0.064| r_loss: 0.065| p_loss: 0.097| v_loss: 0.024| per_loss: 0.328 | a_loss: 0.553
Train: Epoch [1730/3000], Step [30/158]| g_loss: 0.708| d_loss: 0.746| gp_loss: 0.163| r_loss: 0.066| p_loss: 0.100| v_loss: 0.025| per_loss: 0.336 | a_loss: 0.534
Train: Epoch [1730/3000], Step [60/158]| g_loss: 0.672| d_loss: 0.617| gp_loss: 0.054| r_loss: 0.064| p_loss: 0.097| v_loss: 0.024| per_loss: 0.327 | a_loss: 0.503
Train: Epoch [1730/3000], Step [90/158]| g_loss: 0.693| d_loss: 0.632| gp_loss: 0.058| r_loss: 0.067| p_loss: 0.100| v_loss: 0.024| per_loss: 0.323 | a_loss: 0.520
Train: Epoch [1730/3000], Step [120/158]| g_loss: 0.755| d_loss: 0.568| gp_loss: 0.062| r_loss: 0.065| p_loss: 0.096| v_loss: 0.024| per_loss: 0.340 | a_loss: 0.584
Train: Epoch [1730/3000], Step [150/158]| g_loss: 0.748| d_loss: 0.554| gp_loss: 0.059| r_loss: 0.065| p_loss: 0.096| v_loss: 0.024| per_loss: 0.328 | a_loss: 0.578
Train: Epoch [1731/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.778| gp_loss: 0.205| r_loss: 0.066| p_loss: 0.095| v_loss: 0.024| per_loss: 0.316 | a_loss: 0.494
Train: Epoch [1731/3000], Step [60/158]| g_loss: 0.694| d_loss: 0.680| gp_loss: 0.053| r_loss: 0.065| p_loss: 0.095| v_loss: 0.024| per_loss: 0.330 | a_loss: 0.525
Train: Epoch [1731/3000], Step [90/158]| g_loss: 0.709| d_loss: 0.603| gp_loss: 0.055| r_loss: 0.067| p_loss: 0.094| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.539
Train: Epoch [1731/3000], Step [120/158]| g_loss: 0.712| d_loss: 0.588| gp_loss: 0.051| r_loss: 0.062| p_loss: 0.095| v_loss: 0.024| per_loss: 0.341 | a_loss: 0.544
Train: Epoch [1731/3000], Step [150/158]| g_loss: 0.715| d_loss: 0.555| gp_loss: 0.057| r_loss: 0.066| p_loss: 0.098| v_loss: 0.024| per_loss: 0.327 | a_loss: 0.543
Train: Epoch [1732/3000], Step [30/158]| g_loss: 0.677| d_loss: 0.786| gp_loss: 0.132| r_loss: 0.065| p_loss: 0.095| v_loss: 0.024| per_loss: 0.336 | a_loss: 0.507
Train: Epoch [1732/3000], Step [60/158]| g_loss: 0.644| d_loss: 0.638| gp_loss: 0.052| r_loss: 0.064| p_loss: 0.096| v_loss: 0.024| per_loss: 0.326 | a_loss: 0.475
Train: Epoch [1732/3000], Step [90/158]| g_loss: 0.750| d_loss: 0.485| gp_loss: 0.055| r_loss: 0.065| p_loss: 0.095| v_loss: 0.024| per_loss: 0.315 | a_loss: 0.581
Train: Epoch [1732/3000], Step [120/158]| g_loss: 0.759| d_loss: 0.617| gp_loss: 0.055| r_loss: 0.066| p_loss: 0.096| v_loss: 0.025| per_loss: 0.335 | a_loss: 0.587
Train: Epoch [1732/3000], Step [150/158]| g_loss: 0.684| d_loss: 0.651| gp_loss: 0.055| r_loss: 0.063| p_loss: 0.098| v_loss: 0.023| per_loss: 0.339 | a_loss: 0.515
Train: Epoch [1733/3000], Step [30/158]| g_loss: 0.681| d_loss: 0.678| gp_loss: 0.161| r_loss: 0.066| p_loss: 0.101| v_loss: 0.024| per_loss: 0.325 | a_loss: 0.508
Train: Epoch [1733/3000], Step [60/158]| g_loss: 0.709| d_loss: 0.614| gp_loss: 0.056| r_loss: 0.065| p_loss: 0.098| v_loss: 0.024| per_loss: 0.322 | a_loss: 0.539
Train: Epoch [1733/3000], Step [90/158]| g_loss: 0.732| d_loss: 0.666| gp_loss: 0.057| r_loss: 0.068| p_loss: 0.101| v_loss: 0.024| per_loss: 0.335 | a_loss: 0.555
Train: Epoch [1733/3000], Step [120/158]| g_loss: 0.675| d_loss: 0.635| gp_loss: 0.057| r_loss: 0.067| p_loss: 0.102| v_loss: 0.024| per_loss: 0.344 | a_loss: 0.498
Train: Epoch [1733/3000], Step [150/158]| g_loss: 0.680| d_loss: 0.624| gp_loss: 0.060| r_loss: 0.064| p_loss: 0.096| v_loss: 0.024| per_loss: 0.327 | a_loss: 0.512
Train: Epoch [1734/3000], Step [30/158]| g_loss: 0.734| d_loss: 0.689| gp_loss: 0.160| r_loss: 0.067| p_loss: 0.099| v_loss: 0.026| per_loss: 0.335 | a_loss: 0.558
Train: Epoch [1734/3000], Step [60/158]| g_loss: 0.691| d_loss: 0.570| gp_loss: 0.054| r_loss: 0.064| p_loss: 0.097| v_loss: 0.024| per_loss: 0.340 | a_loss: 0.521
Train: Epoch [1734/3000], Step [90/158]| g_loss: 0.685| d_loss: 0.650| gp_loss: 0.054| r_loss: 0.064| p_loss: 0.093| v_loss: 0.023| per_loss: 0.335 | a_loss: 0.519
Train: Epoch [1734/3000], Step [120/158]| g_loss: 0.709| d_loss: 0.552| gp_loss: 0.057| r_loss: 0.064| p_loss: 0.095| v_loss: 0.024| per_loss: 0.323 | a_loss: 0.541
Train: Epoch [1734/3000], Step [150/158]| g_loss: 0.681| d_loss: 0.674| gp_loss: 0.058| r_loss: 0.065| p_loss: 0.094| v_loss: 0.024| per_loss: 0.307 | a_loss: 0.515
Train: Epoch [1735/3000], Step [30/158]| g_loss: 0.702| d_loss: 0.726| gp_loss: 0.119| r_loss: 0.066| p_loss: 0.097| v_loss: 0.024| per_loss: 0.329 | a_loss: 0.530
Train: Epoch [1735/3000], Step [60/158]| g_loss: 0.700| d_loss: 0.615| gp_loss: 0.057| r_loss: 0.067| p_loss: 0.103| v_loss: 0.025| per_loss: 0.337 | a_loss: 0.523
Train: Epoch [1735/3000], Step [90/158]| g_loss: 0.706| d_loss: 0.633| gp_loss: 0.059| r_loss: 0.066| p_loss: 0.103| v_loss: 0.025| per_loss: 0.328 | a_loss: 0.531
Train: Epoch [1735/3000], Step [120/158]| g_loss: 0.712| d_loss: 0.604| gp_loss: 0.058| r_loss: 0.063| p_loss: 0.095| v_loss: 0.024| per_loss: 0.334 | a_loss: 0.544
Train: Epoch [1735/3000], Step [150/158]| g_loss: 0.756| d_loss: 0.529| gp_loss: 0.059| r_loss: 0.066| p_loss: 0.098| v_loss: 0.024| per_loss: 0.319 | a_loss: 0.585
Train: Epoch [1736/3000], Step [30/158]| g_loss: 0.705| d_loss: 0.743| gp_loss: 0.174| r_loss: 0.067| p_loss: 0.095| v_loss: 0.024| per_loss: 0.332 | a_loss: 0.533
Train: Epoch [1736/3000], Step [60/158]| g_loss: 0.671| d_loss: 0.610| gp_loss: 0.054| r_loss: 0.066| p_loss: 0.094| v_loss: 0.025| per_loss: 0.336 | a_loss: 0.499
Train: Epoch [1736/3000], Step [90/158]| g_loss: 0.706| d_loss: 0.599| gp_loss: 0.058| r_loss: 0.064| p_loss: 0.098| v_loss: 0.025| per_loss: 0.317 | a_loss: 0.536
Train: Epoch [1736/3000], Step [120/158]| g_loss: 0.794| d_loss: 0.526| gp_loss: 0.058| r_loss: 0.066| p_loss: 0.099| v_loss: 0.024| per_loss: 0.353 | a_loss: 0.618
Train: Epoch [1736/3000], Step [150/158]| g_loss: 0.694| d_loss: 0.642| gp_loss: 0.056| r_loss: 0.067| p_loss: 0.100| v_loss: 0.024| per_loss: 0.337 | a_loss: 0.520
Train: Epoch [1737/3000], Step [30/158]| g_loss: 0.684| d_loss: 0.710| gp_loss: 0.131| r_loss: 0.065| p_loss: 0.095| v_loss: 0.024| per_loss: 0.340 | a_loss: 0.513
Train: Epoch [1737/3000], Step [60/158]| g_loss: 0.756| d_loss: 0.562| gp_loss: 0.052| r_loss: 0.065| p_loss: 0.092| v_loss: 0.024| per_loss: 0.326 | a_loss: 0.589
Train: Epoch [1737/3000], Step [90/158]| g_loss: 0.724| d_loss: 0.544| gp_loss: 0.058| r_loss: 0.063| p_loss: 0.092| v_loss: 0.025| per_loss: 0.318 | a_loss: 0.558
Train: Epoch [1737/3000], Step [120/158]| g_loss: 0.699| d_loss: 0.692| gp_loss: 0.057| r_loss: 0.065| p_loss: 0.099| v_loss: 0.025| per_loss: 0.337 | a_loss: 0.527
Train: Epoch [1737/3000], Step [150/158]| g_loss: 0.693| d_loss: 0.590| gp_loss: 0.059| r_loss: 0.065| p_loss: 0.097| v_loss: 0.024| per_loss: 0.314 | a_loss: 0.524
Train: Epoch [1738/3000], Step [30/158]| g_loss: 0.658| d_loss: 0.807| gp_loss: 0.160| r_loss: 0.069| p_loss: 0.106| v_loss: 0.024| per_loss: 0.332 | a_loss: 0.479
Train: Epoch [1738/3000], Step [60/158]| g_loss: 0.655| d_loss: 0.661| gp_loss: 0.058| r_loss: 0.067| p_loss: 0.101| v_loss: 0.024| per_loss: 0.329 | a_loss: 0.481
Train: Epoch [1738/3000], Step [90/158]| g_loss: 0.738| d_loss: 0.592| gp_loss: 0.059| r_loss: 0.070| p_loss: 0.106| v_loss: 0.026| per_loss: 0.332 | a_loss: 0.556
Train: Epoch [1738/3000], Step [120/158]| g_loss: 0.770| d_loss: 0.494| gp_loss: 0.059| r_loss: 0.069| p_loss: 0.097| v_loss: 0.025| per_loss: 0.331 | a_loss: 0.594
Train: Epoch [1738/3000], Step [150/158]| g_loss: 0.762| d_loss: 0.596| gp_loss: 0.057| r_loss: 0.065| p_loss: 0.097| v_loss: 0.025| per_loss: 0.323 | a_loss: 0.592
Train: Epoch [1739/3000], Step [30/158]| g_loss: 0.671| d_loss: 0.719| gp_loss: 0.161| r_loss: 0.066| p_loss: 0.097| v_loss: 0.024| per_loss: 0.329 | a_loss: 0.500
Train: Epoch [1739/3000], Step [60/158]| g_loss: 0.692| d_loss: 0.589| gp_loss: 0.055| r_loss: 0.064| p_loss: 0.093| v_loss: 0.024| per_loss: 0.326 | a_loss: 0.525
Train: Epoch [1739/3000], Step [90/158]| g_loss: 0.712| d_loss: 0.633| gp_loss: 0.056| r_loss: 0.067| p_loss: 0.097| v_loss: 0.024| per_loss: 0.318 | a_loss: 0.541
Train: Epoch [1739/3000], Step [120/158]| g_loss: 0.685| d_loss: 0.690| gp_loss: 0.058| r_loss: 0.065| p_loss: 0.096| v_loss: 0.024| per_loss: 0.333 | a_loss: 0.514
Train: Epoch [1739/3000], Step [150/158]| g_loss: 0.746| d_loss: 0.533| gp_loss: 0.059| r_loss: 0.063| p_loss: 0.098| v_loss: 0.025| per_loss: 0.338 | a_loss: 0.575
Train: Epoch [1740/3000], Step [30/158]| g_loss: 0.650| d_loss: 0.827| gp_loss: 0.212| r_loss: 0.062| p_loss: 0.093| v_loss: 0.024| per_loss: 0.322 | a_loss: 0.485
Train: Epoch [1740/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.637| gp_loss: 0.048| r_loss: 0.061| p_loss: 0.086| v_loss: 0.024| per_loss: 0.326 | a_loss: 0.512
Train: Epoch [1740/3000], Step [90/158]| g_loss: 0.709| d_loss: 0.573| gp_loss: 0.055| r_loss: 0.064| p_loss: 0.094| v_loss: 0.025| per_loss: 0.342 | a_loss: 0.539
Train: Epoch [1740/3000], Step [120/158]| g_loss: 0.771| d_loss: 0.533| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.098| v_loss: 0.025| per_loss: 0.307 | a_loss: 0.598
Train: Epoch [1740/3000], Step [150/158]| g_loss: 0.692| d_loss: 0.640| gp_loss: 0.054| r_loss: 0.065| p_loss: 0.098| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.521
Train: Epoch [1741/3000], Step [30/158]| g_loss: 0.745| d_loss: 0.664| gp_loss: 0.118| r_loss: 0.066| p_loss: 0.097| v_loss: 0.025| per_loss: 0.350 | a_loss: 0.570
Train: Epoch [1741/3000], Step [60/158]| g_loss: 0.717| d_loss: 0.621| gp_loss: 0.052| r_loss: 0.067| p_loss: 0.100| v_loss: 0.025| per_loss: 0.315 | a_loss: 0.543
Train: Epoch [1741/3000], Step [90/158]| g_loss: 0.695| d_loss: 0.579| gp_loss: 0.056| r_loss: 0.066| p_loss: 0.095| v_loss: 0.025| per_loss: 0.341 | a_loss: 0.522
Train: Epoch [1741/3000], Step [120/158]| g_loss: 0.687| d_loss: 0.601| gp_loss: 0.052| r_loss: 0.063| p_loss: 0.095| v_loss: 0.024| per_loss: 0.329 | a_loss: 0.520
Train: Epoch [1741/3000], Step [150/158]| g_loss: 0.676| d_loss: 0.670| gp_loss: 0.058| r_loss: 0.064| p_loss: 0.094| v_loss: 0.024| per_loss: 0.317 | a_loss: 0.509
Train: Epoch [1742/3000], Step [30/158]| g_loss: 0.717| d_loss: 0.625| gp_loss: 0.113| r_loss: 0.067| p_loss: 0.096| v_loss: 0.024| per_loss: 0.302 | a_loss: 0.547
Train: Epoch [1742/3000], Step [60/158]| g_loss: 0.722| d_loss: 0.598| gp_loss: 0.056| r_loss: 0.066| p_loss: 0.099| v_loss: 0.024| per_loss: 0.341 | a_loss: 0.549
Train: Epoch [1742/3000], Step [90/158]| g_loss: 0.790| d_loss: 0.560| gp_loss: 0.060| r_loss: 0.063| p_loss: 0.093| v_loss: 0.024| per_loss: 0.329 | a_loss: 0.623
Train: Epoch [1742/3000], Step [120/158]| g_loss: 0.721| d_loss: 0.623| gp_loss: 0.057| r_loss: 0.084| p_loss: 0.132| v_loss: 0.025| per_loss: 0.338 | a_loss: 0.512
Train: Epoch [1742/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.739| gp_loss: 0.057| r_loss: 0.079| p_loss: 0.115| v_loss: 0.025| per_loss: 0.345 | a_loss: 0.466
Train: Epoch [1743/3000], Step [30/158]| g_loss: 0.724| d_loss: 0.691| gp_loss: 0.129| r_loss: 0.068| p_loss: 0.106| v_loss: 0.024| per_loss: 0.334 | a_loss: 0.545
Train: Epoch [1743/3000], Step [60/158]| g_loss: 0.687| d_loss: 0.621| gp_loss: 0.059| r_loss: 0.072| p_loss: 0.105| v_loss: 0.024| per_loss: 0.325 | a_loss: 0.506
Train: Epoch [1743/3000], Step [90/158]| g_loss: 0.690| d_loss: 0.601| gp_loss: 0.059| r_loss: 0.066| p_loss: 0.098| v_loss: 0.024| per_loss: 0.335 | a_loss: 0.516
Train: Epoch [1743/3000], Step [120/158]| g_loss: 0.751| d_loss: 0.580| gp_loss: 0.059| r_loss: 0.066| p_loss: 0.099| v_loss: 0.025| per_loss: 0.332 | a_loss: 0.578
Train: Epoch [1743/3000], Step [150/158]| g_loss: 0.706| d_loss: 0.626| gp_loss: 0.061| r_loss: 0.067| p_loss: 0.096| v_loss: 0.026| per_loss: 0.326 | a_loss: 0.533
Train: Epoch [1744/3000], Step [30/158]| g_loss: 0.668| d_loss: 0.758| gp_loss: 0.136| r_loss: 0.066| p_loss: 0.100| v_loss: 0.025| per_loss: 0.328 | a_loss: 0.494
Train: Epoch [1744/3000], Step [60/158]| g_loss: 0.694| d_loss: 0.581| gp_loss: 0.057| r_loss: 0.064| p_loss: 0.095| v_loss: 0.025| per_loss: 0.333 | a_loss: 0.524
Train: Epoch [1744/3000], Step [90/158]| g_loss: 0.718| d_loss: 0.618| gp_loss: 0.058| r_loss: 0.065| p_loss: 0.094| v_loss: 0.025| per_loss: 0.346 | a_loss: 0.546
Train: Epoch [1744/3000], Step [120/158]| g_loss: 0.643| d_loss: 0.677| gp_loss: 0.060| r_loss: 0.066| p_loss: 0.098| v_loss: 0.024| per_loss: 0.327 | a_loss: 0.471
Train: Epoch [1744/3000], Step [150/158]| g_loss: 0.771| d_loss: 0.524| gp_loss: 0.063| r_loss: 0.067| p_loss: 0.099| v_loss: 0.026| per_loss: 0.331 | a_loss: 0.596
Train: Epoch [1745/3000], Step [30/158]| g_loss: 0.747| d_loss: 0.641| gp_loss: 0.159| r_loss: 0.068| p_loss: 0.095| v_loss: 0.025| per_loss: 0.324 | a_loss: 0.574
Train: Epoch [1745/3000], Step [60/158]| g_loss: 0.683| d_loss: 0.665| gp_loss: 0.052| r_loss: 0.066| p_loss: 0.097| v_loss: 0.025| per_loss: 0.312 | a_loss: 0.512
Train: Epoch [1745/3000], Step [90/158]| g_loss: 0.719| d_loss: 0.585| gp_loss: 0.058| r_loss: 0.064| p_loss: 0.097| v_loss: 0.025| per_loss: 0.330 | a_loss: 0.548
Train: Epoch [1745/3000], Step [120/158]| g_loss: 0.671| d_loss: 0.674| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.100| v_loss: 0.024| per_loss: 0.329 | a_loss: 0.496
Train: Epoch [1745/3000], Step [150/158]| g_loss: 0.725| d_loss: 0.553| gp_loss: 0.059| r_loss: 0.064| p_loss: 0.094| v_loss: 0.025| per_loss: 0.332 | a_loss: 0.556
Train: Epoch [1746/3000], Step [30/158]| g_loss: 0.742| d_loss: 0.653| gp_loss: 0.133| r_loss: 0.064| p_loss: 0.095| v_loss: 0.024| per_loss: 0.322 | a_loss: 0.575
Train: Epoch [1746/3000], Step [60/158]| g_loss: 0.679| d_loss: 0.669| gp_loss: 0.055| r_loss: 0.062| p_loss: 0.092| v_loss: 0.024| per_loss: 0.321 | a_loss: 0.516
Train: Epoch [1746/3000], Step [90/158]| g_loss: 0.708| d_loss: 0.608| gp_loss: 0.056| r_loss: 0.066| p_loss: 0.094| v_loss: 0.025| per_loss: 0.334 | a_loss: 0.537
Train: Epoch [1746/3000], Step [120/158]| g_loss: 0.695| d_loss: 0.623| gp_loss: 0.056| r_loss: 0.067| p_loss: 0.098| v_loss: 0.025| per_loss: 0.320 | a_loss: 0.523
Train: Epoch [1746/3000], Step [150/158]| g_loss: 0.683| d_loss: 0.602| gp_loss: 0.060| r_loss: 0.063| p_loss: 0.096| v_loss: 0.024| per_loss: 0.333 | a_loss: 0.513
Train: Epoch [1747/3000], Step [30/158]| g_loss: 0.739| d_loss: 0.738| gp_loss: 0.176| r_loss: 0.068| p_loss: 0.103| v_loss: 0.025| per_loss: 0.334 | a_loss: 0.561
Train: Epoch [1747/3000], Step [60/158]| g_loss: 0.695| d_loss: 0.582| gp_loss: 0.056| r_loss: 0.067| p_loss: 0.095| v_loss: 0.024| per_loss: 0.319 | a_loss: 0.525
Train: Epoch [1747/3000], Step [90/158]| g_loss: 0.734| d_loss: 0.587| gp_loss: 0.057| r_loss: 0.064| p_loss: 0.098| v_loss: 0.025| per_loss: 0.340 | a_loss: 0.562
Train: Epoch [1747/3000], Step [120/158]| g_loss: 0.701| d_loss: 0.600| gp_loss: 0.054| r_loss: 0.066| p_loss: 0.092| v_loss: 0.024| per_loss: 0.326 | a_loss: 0.532
Train: Epoch [1747/3000], Step [150/158]| g_loss: 0.685| d_loss: 0.666| gp_loss: 0.055| r_loss: 0.064| p_loss: 0.095| v_loss: 0.024| per_loss: 0.331 | a_loss: 0.516
Train: Epoch [1748/3000], Step [30/158]| g_loss: 0.745| d_loss: 0.637| gp_loss: 0.159| r_loss: 0.064| p_loss: 0.093| v_loss: 0.024| per_loss: 0.342 | a_loss: 0.576
Train: Epoch [1748/3000], Step [60/158]| g_loss: 0.661| d_loss: 0.674| gp_loss: 0.050| r_loss: 0.064| p_loss: 0.098| v_loss: 0.025| per_loss: 0.325 | a_loss: 0.491
Train: Epoch [1748/3000], Step [90/158]| g_loss: 0.666| d_loss: 0.650| gp_loss: 0.055| r_loss: 0.067| p_loss: 0.097| v_loss: 0.025| per_loss: 0.329 | a_loss: 0.493
Train: Epoch [1748/3000], Step [120/158]| g_loss: 0.734| d_loss: 0.612| gp_loss: 0.059| r_loss: 0.063| p_loss: 0.091| v_loss: 0.024| per_loss: 0.338 | a_loss: 0.568
Train: Epoch [1748/3000], Step [150/158]| g_loss: 0.702| d_loss: 0.589| gp_loss: 0.057| r_loss: 0.066| p_loss: 0.098| v_loss: 0.024| per_loss: 0.327 | a_loss: 0.530
Train: Epoch [1749/3000], Step [30/158]| g_loss: 0.699| d_loss: 0.702| gp_loss: 0.183| r_loss: 0.062| p_loss: 0.088| v_loss: 0.023| per_loss: 0.313 | a_loss: 0.539
Train: Epoch [1749/3000], Step [60/158]| g_loss: 0.703| d_loss: 0.650| gp_loss: 0.052| r_loss: 0.064| p_loss: 0.097| v_loss: 0.024| per_loss: 0.329 | a_loss: 0.533
Train: Epoch [1749/3000], Step [90/158]| g_loss: 0.713| d_loss: 0.591| gp_loss: 0.054| r_loss: 0.064| p_loss: 0.094| v_loss: 0.024| per_loss: 0.336 | a_loss: 0.544
Train: Epoch [1749/3000], Step [120/158]| g_loss: 0.712| d_loss: 0.647| gp_loss: 0.057| r_loss: 0.066| p_loss: 0.099| v_loss: 0.025| per_loss: 0.318 | a_loss: 0.540
Train: Epoch [1749/3000], Step [150/158]| g_loss: 0.710| d_loss: 0.567| gp_loss: 0.055| r_loss: 0.064| p_loss: 0.095| v_loss: 0.024| per_loss: 0.328 | a_loss: 0.541
Train: Epoch [1750/3000], Step [30/158]| g_loss: 0.690| d_loss: 0.750| gp_loss: 0.152| r_loss: 0.064| p_loss: 0.096| v_loss: 0.024| per_loss: 0.342 | a_loss: 0.519
Train: Epoch [1750/3000], Step [60/158]| g_loss: 0.724| d_loss: 0.603| gp_loss: 0.052| r_loss: 0.067| p_loss: 0.090| v_loss: 0.024| per_loss: 0.314 | a_loss: 0.558
Train: Epoch [1750/3000], Step [90/158]| g_loss: 0.704| d_loss: 0.596| gp_loss: 0.051| r_loss: 0.065| p_loss: 0.097| v_loss: 0.024| per_loss: 0.328 | a_loss: 0.534
Train: Epoch [1750/3000], Step [120/158]| g_loss: 0.674| d_loss: 0.621| gp_loss: 0.055| r_loss: 0.063| p_loss: 0.093| v_loss: 0.024| per_loss: 0.339 | a_loss: 0.507
Train: Epoch [1750/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.602| gp_loss: 0.057| r_loss: 0.063| p_loss: 0.094| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.498
Test: Epoch [1750/3000]| g_loss: 0.637| r_loss: 0.387| p_loss: 0.299| v_loss: 0.023
Train: Epoch [1751/3000], Step [30/158]| g_loss: 0.710| d_loss: 0.573| gp_loss: 0.054| r_loss: 0.061| p_loss: 0.089| v_loss: 0.023| per_loss: 0.326 | a_loss: 0.549
Train: Epoch [1751/3000], Step [60/158]| g_loss: 0.709| d_loss: 0.594| gp_loss: 0.054| r_loss: 0.061| p_loss: 0.087| v_loss: 0.024| per_loss: 0.334 | a_loss: 0.547
Train: Epoch [1751/3000], Step [90/158]| g_loss: 0.689| d_loss: 0.590| gp_loss: 0.052| r_loss: 0.065| p_loss: 0.092| v_loss: 0.024| per_loss: 0.305 | a_loss: 0.523
Train: Epoch [1751/3000], Step [120/158]| g_loss: 0.695| d_loss: 0.696| gp_loss: 0.055| r_loss: 0.067| p_loss: 0.097| v_loss: 0.024| per_loss: 0.321 | a_loss: 0.524
Train: Epoch [1751/3000], Step [150/158]| g_loss: 0.660| d_loss: 0.633| gp_loss: 0.057| r_loss: 0.063| p_loss: 0.094| v_loss: 0.024| per_loss: 0.332 | a_loss: 0.493
Train: Epoch [1752/3000], Step [30/158]| g_loss: 0.717| d_loss: 0.664| gp_loss: 0.167| r_loss: 0.064| p_loss: 0.088| v_loss: 0.024| per_loss: 0.318 | a_loss: 0.554
Train: Epoch [1752/3000], Step [60/158]| g_loss: 0.661| d_loss: 0.650| gp_loss: 0.053| r_loss: 0.064| p_loss: 0.095| v_loss: 0.023| per_loss: 0.330 | a_loss: 0.493
Train: Epoch [1752/3000], Step [90/158]| g_loss: 0.684| d_loss: 0.560| gp_loss: 0.056| r_loss: 0.062| p_loss: 0.087| v_loss: 0.023| per_loss: 0.336 | a_loss: 0.522
Train: Epoch [1752/3000], Step [120/158]| g_loss: 0.778| d_loss: 0.588| gp_loss: 0.056| r_loss: 0.063| p_loss: 0.094| v_loss: 0.024| per_loss: 0.321 | a_loss: 0.612
Train: Epoch [1752/3000], Step [150/158]| g_loss: 0.677| d_loss: 0.634| gp_loss: 0.055| r_loss: 0.062| p_loss: 0.094| v_loss: 0.024| per_loss: 0.322 | a_loss: 0.512
Train: Epoch [1753/3000], Step [30/158]| g_loss: 0.724| d_loss: 0.727| gp_loss: 0.183| r_loss: 0.067| p_loss: 0.095| v_loss: 0.024| per_loss: 0.339 | a_loss: 0.552
Train: Epoch [1753/3000], Step [60/158]| g_loss: 0.672| d_loss: 0.616| gp_loss: 0.048| r_loss: 0.062| p_loss: 0.094| v_loss: 0.023| per_loss: 0.307 | a_loss: 0.509
Train: Epoch [1753/3000], Step [90/158]| g_loss: 0.689| d_loss: 0.664| gp_loss: 0.053| r_loss: 0.063| p_loss: 0.094| v_loss: 0.023| per_loss: 0.337 | a_loss: 0.522
Train: Epoch [1753/3000], Step [120/158]| g_loss: 0.708| d_loss: 0.647| gp_loss: 0.056| r_loss: 0.067| p_loss: 0.100| v_loss: 0.024| per_loss: 0.323 | a_loss: 0.535
Train: Epoch [1753/3000], Step [150/158]| g_loss: 0.710| d_loss: 0.548| gp_loss: 0.055| r_loss: 0.064| p_loss: 0.092| v_loss: 0.024| per_loss: 0.327 | a_loss: 0.543
Train: Epoch [1754/3000], Step [30/158]| g_loss: 0.726| d_loss: 0.677| gp_loss: 0.131| r_loss: 0.061| p_loss: 0.093| v_loss: 0.024| per_loss: 0.326 | a_loss: 0.561
Train: Epoch [1754/3000], Step [60/158]| g_loss: 0.709| d_loss: 0.542| gp_loss: 0.052| r_loss: 0.065| p_loss: 0.092| v_loss: 0.024| per_loss: 0.334 | a_loss: 0.541
Train: Epoch [1754/3000], Step [90/158]| g_loss: 0.741| d_loss: 0.543| gp_loss: 0.051| r_loss: 0.064| p_loss: 0.094| v_loss: 0.024| per_loss: 0.326 | a_loss: 0.573
Train: Epoch [1754/3000], Step [120/158]| g_loss: 0.669| d_loss: 0.625| gp_loss: 0.050| r_loss: 0.067| p_loss: 0.094| v_loss: 0.023| per_loss: 0.331 | a_loss: 0.500
Train: Epoch [1754/3000], Step [150/158]| g_loss: 0.690| d_loss: 0.673| gp_loss: 0.053| r_loss: 0.063| p_loss: 0.092| v_loss: 0.023| per_loss: 0.327 | a_loss: 0.526
Train: Epoch [1755/3000], Step [30/158]| g_loss: 0.685| d_loss: 0.672| gp_loss: 0.131| r_loss: 0.067| p_loss: 0.092| v_loss: 0.024| per_loss: 0.331 | a_loss: 0.515
Train: Epoch [1755/3000], Step [60/158]| g_loss: 0.747| d_loss: 0.561| gp_loss: 0.056| r_loss: 0.065| p_loss: 0.095| v_loss: 0.024| per_loss: 0.324 | a_loss: 0.577
Train: Epoch [1755/3000], Step [90/158]| g_loss: 0.702| d_loss: 0.669| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.099| v_loss: 0.025| per_loss: 0.325 | a_loss: 0.527
Train: Epoch [1755/3000], Step [120/158]| g_loss: 0.702| d_loss: 0.617| gp_loss: 0.055| r_loss: 0.065| p_loss: 0.097| v_loss: 0.024| per_loss: 0.328 | a_loss: 0.531
Train: Epoch [1755/3000], Step [150/158]| g_loss: 0.715| d_loss: 0.601| gp_loss: 0.058| r_loss: 0.065| p_loss: 0.094| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.548
Train: Epoch [1756/3000], Step [30/158]| g_loss: 0.743| d_loss: 0.635| gp_loss: 0.153| r_loss: 0.068| p_loss: 0.098| v_loss: 0.023| per_loss: 0.315 | a_loss: 0.571
Train: Epoch [1756/3000], Step [60/158]| g_loss: 0.701| d_loss: 0.592| gp_loss: 0.051| r_loss: 0.066| p_loss: 0.096| v_loss: 0.023| per_loss: 0.333 | a_loss: 0.530
Train: Epoch [1756/3000], Step [90/158]| g_loss: 0.731| d_loss: 0.576| gp_loss: 0.053| r_loss: 0.064| p_loss: 0.091| v_loss: 0.023| per_loss: 0.340 | a_loss: 0.563
Train: Epoch [1756/3000], Step [120/158]| g_loss: 0.681| d_loss: 0.683| gp_loss: 0.056| r_loss: 0.063| p_loss: 0.095| v_loss: 0.023| per_loss: 0.304 | a_loss: 0.517
Train: Epoch [1756/3000], Step [150/158]| g_loss: 0.670| d_loss: 0.654| gp_loss: 0.058| r_loss: 0.067| p_loss: 0.095| v_loss: 0.024| per_loss: 0.334 | a_loss: 0.498
Train: Epoch [1757/3000], Step [30/158]| g_loss: 0.638| d_loss: 0.767| gp_loss: 0.128| r_loss: 0.064| p_loss: 0.097| v_loss: 0.024| per_loss: 0.327 | a_loss: 0.469
Train: Epoch [1757/3000], Step [60/158]| g_loss: 0.710| d_loss: 0.659| gp_loss: 0.059| r_loss: 0.068| p_loss: 0.099| v_loss: 0.025| per_loss: 0.323 | a_loss: 0.536
Train: Epoch [1757/3000], Step [90/158]| g_loss: 0.709| d_loss: 0.568| gp_loss: 0.057| r_loss: 0.064| p_loss: 0.098| v_loss: 0.023| per_loss: 0.330 | a_loss: 0.539
Train: Epoch [1757/3000], Step [120/158]| g_loss: 0.661| d_loss: 0.690| gp_loss: 0.058| r_loss: 0.063| p_loss: 0.094| v_loss: 0.023| per_loss: 0.321 | a_loss: 0.496
Train: Epoch [1757/3000], Step [150/158]| g_loss: 0.765| d_loss: 0.583| gp_loss: 0.062| r_loss: 0.066| p_loss: 0.101| v_loss: 0.024| per_loss: 0.334 | a_loss: 0.591
Train: Epoch [1758/3000], Step [30/158]| g_loss: 0.753| d_loss: 0.602| gp_loss: 0.129| r_loss: 0.067| p_loss: 0.099| v_loss: 0.023| per_loss: 0.336 | a_loss: 0.580
Train: Epoch [1758/3000], Step [60/158]| g_loss: 0.750| d_loss: 0.565| gp_loss: 0.057| r_loss: 0.069| p_loss: 0.098| v_loss: 0.025| per_loss: 0.340 | a_loss: 0.574
Train: Epoch [1758/3000], Step [90/158]| g_loss: 0.672| d_loss: 0.683| gp_loss: 0.054| r_loss: 0.066| p_loss: 0.100| v_loss: 0.025| per_loss: 0.327 | a_loss: 0.498
Train: Epoch [1758/3000], Step [120/158]| g_loss: 0.700| d_loss: 0.624| gp_loss: 0.059| r_loss: 0.064| p_loss: 0.101| v_loss: 0.023| per_loss: 0.321 | a_loss: 0.529
Train: Epoch [1758/3000], Step [150/158]| g_loss: 0.704| d_loss: 0.596| gp_loss: 0.058| r_loss: 0.066| p_loss: 0.095| v_loss: 0.023| per_loss: 0.335 | a_loss: 0.533
Train: Epoch [1759/3000], Step [30/158]| g_loss: 0.726| d_loss: 0.666| gp_loss: 0.132| r_loss: 0.068| p_loss: 0.104| v_loss: 0.024| per_loss: 0.327 | a_loss: 0.550
Train: Epoch [1759/3000], Step [60/158]| g_loss: 0.663| d_loss: 0.704| gp_loss: 0.057| r_loss: 0.066| p_loss: 0.100| v_loss: 0.024| per_loss: 0.322 | a_loss: 0.490
Train: Epoch [1759/3000], Step [90/158]| g_loss: 0.717| d_loss: 0.628| gp_loss: 0.056| r_loss: 0.064| p_loss: 0.096| v_loss: 0.024| per_loss: 0.345 | a_loss: 0.546
Train: Epoch [1759/3000], Step [120/158]| g_loss: 0.705| d_loss: 0.640| gp_loss: 0.061| r_loss: 0.072| p_loss: 0.098| v_loss: 0.023| per_loss: 0.318 | a_loss: 0.529
Train: Epoch [1759/3000], Step [150/158]| g_loss: 0.774| d_loss: 0.530| gp_loss: 0.061| r_loss: 0.065| p_loss: 0.100| v_loss: 0.025| per_loss: 0.334 | a_loss: 0.601
Train: Epoch [1760/3000], Step [30/158]| g_loss: 0.706| d_loss: 0.656| gp_loss: 0.168| r_loss: 0.063| p_loss: 0.090| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.543
Train: Epoch [1760/3000], Step [60/158]| g_loss: 0.745| d_loss: 0.661| gp_loss: 0.054| r_loss: 0.066| p_loss: 0.096| v_loss: 0.024| per_loss: 0.345 | a_loss: 0.574
Train: Epoch [1760/3000], Step [90/158]| g_loss: 0.618| d_loss: 0.735| gp_loss: 0.052| r_loss: 0.063| p_loss: 0.095| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.452
Train: Epoch [1760/3000], Step [120/158]| g_loss: 0.676| d_loss: 0.508| gp_loss: 0.060| r_loss: 0.063| p_loss: 0.090| v_loss: 0.024| per_loss: 0.323 | a_loss: 0.512
Train: Epoch [1760/3000], Step [150/158]| g_loss: 0.769| d_loss: 0.550| gp_loss: 0.055| r_loss: 0.066| p_loss: 0.092| v_loss: 0.024| per_loss: 0.312 | a_loss: 0.602
Train: Epoch [1761/3000], Step [30/158]| g_loss: 0.665| d_loss: 0.724| gp_loss: 0.151| r_loss: 0.061| p_loss: 0.091| v_loss: 0.023| per_loss: 0.314 | a_loss: 0.503
Train: Epoch [1761/3000], Step [60/158]| g_loss: 0.745| d_loss: 0.569| gp_loss: 0.055| r_loss: 0.062| p_loss: 0.088| v_loss: 0.024| per_loss: 0.319 | a_loss: 0.584
Train: Epoch [1761/3000], Step [90/158]| g_loss: 0.709| d_loss: 0.618| gp_loss: 0.052| r_loss: 0.064| p_loss: 0.091| v_loss: 0.024| per_loss: 0.335 | a_loss: 0.542
Train: Epoch [1761/3000], Step [120/158]| g_loss: 0.699| d_loss: 0.571| gp_loss: 0.058| r_loss: 0.063| p_loss: 0.093| v_loss: 0.023| per_loss: 0.315 | a_loss: 0.535
Train: Epoch [1761/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.681| gp_loss: 0.056| r_loss: 0.064| p_loss: 0.091| v_loss: 0.024| per_loss: 0.346 | a_loss: 0.507
Train: Epoch [1762/3000], Step [30/158]| g_loss: 0.703| d_loss: 0.722| gp_loss: 0.148| r_loss: 0.065| p_loss: 0.093| v_loss: 0.024| per_loss: 0.327 | a_loss: 0.535
Train: Epoch [1762/3000], Step [60/158]| g_loss: 0.659| d_loss: 0.688| gp_loss: 0.049| r_loss: 0.063| p_loss: 0.097| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.492
Train: Epoch [1762/3000], Step [90/158]| g_loss: 0.726| d_loss: 0.579| gp_loss: 0.055| r_loss: 0.064| p_loss: 0.097| v_loss: 0.025| per_loss: 0.321 | a_loss: 0.556
Train: Epoch [1762/3000], Step [120/158]| g_loss: 0.720| d_loss: 0.537| gp_loss: 0.055| r_loss: 0.065| p_loss: 0.094| v_loss: 0.024| per_loss: 0.335 | a_loss: 0.551
Train: Epoch [1762/3000], Step [150/158]| g_loss: 0.713| d_loss: 0.592| gp_loss: 0.057| r_loss: 0.062| p_loss: 0.092| v_loss: 0.024| per_loss: 0.326 | a_loss: 0.548
Train: Epoch [1763/3000], Step [30/158]| g_loss: 0.700| d_loss: 0.776| gp_loss: 0.189| r_loss: 0.067| p_loss: 0.102| v_loss: 0.024| per_loss: 0.324 | a_loss: 0.526
Train: Epoch [1763/3000], Step [60/158]| g_loss: 0.739| d_loss: 0.502| gp_loss: 0.052| r_loss: 0.063| p_loss: 0.090| v_loss: 0.023| per_loss: 0.335 | a_loss: 0.574
Train: Epoch [1763/3000], Step [90/158]| g_loss: 0.705| d_loss: 0.668| gp_loss: 0.053| r_loss: 0.062| p_loss: 0.092| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.541
Train: Epoch [1763/3000], Step [120/158]| g_loss: 0.676| d_loss: 0.619| gp_loss: 0.054| r_loss: 0.064| p_loss: 0.094| v_loss: 0.024| per_loss: 0.331 | a_loss: 0.509
Train: Epoch [1763/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.611| gp_loss: 0.058| r_loss: 0.064| p_loss: 0.093| v_loss: 0.024| per_loss: 0.316 | a_loss: 0.498
Train: Epoch [1764/3000], Step [30/158]| g_loss: 0.696| d_loss: 0.692| gp_loss: 0.118| r_loss: 0.062| p_loss: 0.093| v_loss: 0.024| per_loss: 0.315 | a_loss: 0.533
Train: Epoch [1764/3000], Step [60/158]| g_loss: 0.684| d_loss: 0.669| gp_loss: 0.055| r_loss: 0.066| p_loss: 0.096| v_loss: 0.024| per_loss: 0.319 | a_loss: 0.514
Train: Epoch [1764/3000], Step [90/158]| g_loss: 0.726| d_loss: 0.603| gp_loss: 0.061| r_loss: 0.067| p_loss: 0.097| v_loss: 0.024| per_loss: 0.333 | a_loss: 0.554
Train: Epoch [1764/3000], Step [120/158]| g_loss: 0.662| d_loss: 0.629| gp_loss: 0.056| r_loss: 0.064| p_loss: 0.097| v_loss: 0.024| per_loss: 0.321 | a_loss: 0.494
Train: Epoch [1764/3000], Step [150/158]| g_loss: 0.771| d_loss: 0.548| gp_loss: 0.059| r_loss: 0.066| p_loss: 0.097| v_loss: 0.024| per_loss: 0.325 | a_loss: 0.599
Train: Epoch [1765/3000], Step [30/158]| g_loss: 0.683| d_loss: 0.774| gp_loss: 0.153| r_loss: 0.063| p_loss: 0.090| v_loss: 0.023| per_loss: 0.340 | a_loss: 0.518
Train: Epoch [1765/3000], Step [60/158]| g_loss: 0.681| d_loss: 0.621| gp_loss: 0.056| r_loss: 0.066| p_loss: 0.099| v_loss: 0.024| per_loss: 0.309 | a_loss: 0.511
Train: Epoch [1765/3000], Step [90/158]| g_loss: 0.684| d_loss: 0.589| gp_loss: 0.059| r_loss: 0.063| p_loss: 0.094| v_loss: 0.025| per_loss: 0.329 | a_loss: 0.516
Train: Epoch [1765/3000], Step [120/158]| g_loss: 0.758| d_loss: 0.541| gp_loss: 0.059| r_loss: 0.063| p_loss: 0.092| v_loss: 0.023| per_loss: 0.328 | a_loss: 0.593
Train: Epoch [1765/3000], Step [150/158]| g_loss: 0.711| d_loss: 0.620| gp_loss: 0.058| r_loss: 0.064| p_loss: 0.094| v_loss: 0.025| per_loss: 0.325 | a_loss: 0.543
Train: Epoch [1766/3000], Step [30/158]| g_loss: 0.704| d_loss: 0.678| gp_loss: 0.126| r_loss: 0.063| p_loss: 0.094| v_loss: 0.024| per_loss: 0.342 | a_loss: 0.535
Train: Epoch [1766/3000], Step [60/158]| g_loss: 0.741| d_loss: 0.588| gp_loss: 0.055| r_loss: 0.068| p_loss: 0.098| v_loss: 0.024| per_loss: 0.327 | a_loss: 0.567
Train: Epoch [1766/3000], Step [90/158]| g_loss: 0.674| d_loss: 0.636| gp_loss: 0.060| r_loss: 0.066| p_loss: 0.095| v_loss: 0.024| per_loss: 0.321 | a_loss: 0.505
Train: Epoch [1766/3000], Step [120/158]| g_loss: 0.725| d_loss: 0.657| gp_loss: 0.056| r_loss: 0.066| p_loss: 0.099| v_loss: 0.024| per_loss: 0.323 | a_loss: 0.553
Train: Epoch [1766/3000], Step [150/158]| g_loss: 0.688| d_loss: 0.517| gp_loss: 0.059| r_loss: 0.067| p_loss: 0.093| v_loss: 0.024| per_loss: 0.325 | a_loss: 0.518
Train: Epoch [1767/3000], Step [30/158]| g_loss: 0.752| d_loss: 0.703| gp_loss: 0.156| r_loss: 0.065| p_loss: 0.092| v_loss: 0.024| per_loss: 0.318 | a_loss: 0.586
Train: Epoch [1767/3000], Step [60/158]| g_loss: 0.705| d_loss: 0.564| gp_loss: 0.054| r_loss: 0.065| p_loss: 0.095| v_loss: 0.024| per_loss: 0.333 | a_loss: 0.535
Train: Epoch [1767/3000], Step [90/158]| g_loss: 0.698| d_loss: 0.603| gp_loss: 0.057| r_loss: 0.063| p_loss: 0.087| v_loss: 0.023| per_loss: 0.321 | a_loss: 0.537
Train: Epoch [1767/3000], Step [120/158]| g_loss: 0.671| d_loss: 0.641| gp_loss: 0.056| r_loss: 0.065| p_loss: 0.095| v_loss: 0.024| per_loss: 0.315 | a_loss: 0.504
Train: Epoch [1767/3000], Step [150/158]| g_loss: 0.701| d_loss: 0.623| gp_loss: 0.057| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.328 | a_loss: 0.545
Train: Epoch [1768/3000], Step [30/158]| g_loss: 0.684| d_loss: 0.777| gp_loss: 0.194| r_loss: 0.068| p_loss: 0.097| v_loss: 0.024| per_loss: 0.337 | a_loss: 0.509
Train: Epoch [1768/3000], Step [60/158]| g_loss: 0.705| d_loss: 0.549| gp_loss: 0.053| r_loss: 0.063| p_loss: 0.091| v_loss: 0.023| per_loss: 0.322 | a_loss: 0.541
Train: Epoch [1768/3000], Step [90/158]| g_loss: 0.704| d_loss: 0.639| gp_loss: 0.053| r_loss: 0.065| p_loss: 0.095| v_loss: 0.023| per_loss: 0.318 | a_loss: 0.537
Train: Epoch [1768/3000], Step [120/158]| g_loss: 0.693| d_loss: 0.640| gp_loss: 0.055| r_loss: 0.064| p_loss: 0.094| v_loss: 0.024| per_loss: 0.310 | a_loss: 0.527
Train: Epoch [1768/3000], Step [150/158]| g_loss: 0.684| d_loss: 0.614| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.088| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.523
Train: Epoch [1769/3000], Step [30/158]| g_loss: 0.681| d_loss: 0.676| gp_loss: 0.150| r_loss: 0.065| p_loss: 0.090| v_loss: 0.025| per_loss: 0.329 | a_loss: 0.513
Train: Epoch [1769/3000], Step [60/158]| g_loss: 0.696| d_loss: 0.620| gp_loss: 0.054| r_loss: 0.066| p_loss: 0.093| v_loss: 0.024| per_loss: 0.337 | a_loss: 0.526
Train: Epoch [1769/3000], Step [90/158]| g_loss: 0.715| d_loss: 0.588| gp_loss: 0.056| r_loss: 0.063| p_loss: 0.092| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.551
Train: Epoch [1769/3000], Step [120/158]| g_loss: 0.682| d_loss: 0.603| gp_loss: 0.056| r_loss: 0.063| p_loss: 0.090| v_loss: 0.024| per_loss: 0.321 | a_loss: 0.517
Train: Epoch [1769/3000], Step [150/158]| g_loss: 0.700| d_loss: 0.580| gp_loss: 0.059| r_loss: 0.058| p_loss: 0.087| v_loss: 0.022| per_loss: 0.305 | a_loss: 0.546
Train: Epoch [1770/3000], Step [30/158]| g_loss: 0.748| d_loss: 0.599| gp_loss: 0.126| r_loss: 0.062| p_loss: 0.086| v_loss: 0.024| per_loss: 0.327 | a_loss: 0.587
Train: Epoch [1770/3000], Step [60/158]| g_loss: 0.711| d_loss: 0.616| gp_loss: 0.054| r_loss: 0.062| p_loss: 0.085| v_loss: 0.023| per_loss: 0.315 | a_loss: 0.553
Train: Epoch [1770/3000], Step [90/158]| g_loss: 0.687| d_loss: 0.657| gp_loss: 0.055| r_loss: 0.064| p_loss: 0.094| v_loss: 0.024| per_loss: 0.311 | a_loss: 0.522
Train: Epoch [1770/3000], Step [120/158]| g_loss: 0.673| d_loss: 0.667| gp_loss: 0.056| r_loss: 0.062| p_loss: 0.093| v_loss: 0.024| per_loss: 0.317 | a_loss: 0.509
Train: Epoch [1770/3000], Step [150/158]| g_loss: 0.660| d_loss: 0.578| gp_loss: 0.061| r_loss: 0.063| p_loss: 0.093| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.496
Train: Epoch [1771/3000], Step [30/158]| g_loss: 0.699| d_loss: 0.691| gp_loss: 0.128| r_loss: 0.065| p_loss: 0.097| v_loss: 0.024| per_loss: 0.318 | a_loss: 0.530
Train: Epoch [1771/3000], Step [60/158]| g_loss: 0.662| d_loss: 0.673| gp_loss: 0.056| r_loss: 0.063| p_loss: 0.092| v_loss: 0.023| per_loss: 0.332 | a_loss: 0.497
Train: Epoch [1771/3000], Step [90/158]| g_loss: 0.673| d_loss: 0.646| gp_loss: 0.059| r_loss: 0.064| p_loss: 0.092| v_loss: 0.023| per_loss: 0.334 | a_loss: 0.506
Train: Epoch [1771/3000], Step [120/158]| g_loss: 0.738| d_loss: 0.576| gp_loss: 0.064| r_loss: 0.066| p_loss: 0.095| v_loss: 0.025| per_loss: 0.329 | a_loss: 0.566
Train: Epoch [1771/3000], Step [150/158]| g_loss: 0.733| d_loss: 0.565| gp_loss: 0.063| r_loss: 0.066| p_loss: 0.097| v_loss: 0.023| per_loss: 0.332 | a_loss: 0.562
Train: Epoch [1772/3000], Step [30/158]| g_loss: 0.691| d_loss: 0.706| gp_loss: 0.126| r_loss: 0.068| p_loss: 0.099| v_loss: 0.024| per_loss: 0.327 | a_loss: 0.517
Train: Epoch [1772/3000], Step [60/158]| g_loss: 0.670| d_loss: 0.656| gp_loss: 0.055| r_loss: 0.065| p_loss: 0.095| v_loss: 0.024| per_loss: 0.321 | a_loss: 0.502
Train: Epoch [1772/3000], Step [90/158]| g_loss: 0.751| d_loss: 0.572| gp_loss: 0.060| r_loss: 0.064| p_loss: 0.096| v_loss: 0.024| per_loss: 0.325 | a_loss: 0.582
Train: Epoch [1772/3000], Step [120/158]| g_loss: 0.644| d_loss: 0.643| gp_loss: 0.057| r_loss: 0.062| p_loss: 0.094| v_loss: 0.023| per_loss: 0.318 | a_loss: 0.481
Train: Epoch [1772/3000], Step [150/158]| g_loss: 0.705| d_loss: 0.602| gp_loss: 0.059| r_loss: 0.066| p_loss: 0.095| v_loss: 0.023| per_loss: 0.328 | a_loss: 0.536
Train: Epoch [1773/3000], Step [30/158]| g_loss: 0.705| d_loss: 0.768| gp_loss: 0.218| r_loss: 0.062| p_loss: 0.090| v_loss: 0.023| per_loss: 0.313 | a_loss: 0.544
Train: Epoch [1773/3000], Step [60/158]| g_loss: 0.685| d_loss: 0.616| gp_loss: 0.054| r_loss: 0.062| p_loss: 0.091| v_loss: 0.023| per_loss: 0.342 | a_loss: 0.521
Train: Epoch [1773/3000], Step [90/158]| g_loss: 0.771| d_loss: 0.534| gp_loss: 0.059| r_loss: 0.065| p_loss: 0.092| v_loss: 0.024| per_loss: 0.327 | a_loss: 0.603
Train: Epoch [1773/3000], Step [120/158]| g_loss: 0.693| d_loss: 0.594| gp_loss: 0.053| r_loss: 0.066| p_loss: 0.090| v_loss: 0.024| per_loss: 0.320 | a_loss: 0.526
Train: Epoch [1773/3000], Step [150/158]| g_loss: 0.688| d_loss: 0.658| gp_loss: 0.056| r_loss: 0.062| p_loss: 0.093| v_loss: 0.024| per_loss: 0.297 | a_loss: 0.526
Train: Epoch [1774/3000], Step [30/158]| g_loss: 0.670| d_loss: 0.782| gp_loss: 0.192| r_loss: 0.065| p_loss: 0.098| v_loss: 0.025| per_loss: 0.322 | a_loss: 0.499
Train: Epoch [1774/3000], Step [60/158]| g_loss: 0.668| d_loss: 0.635| gp_loss: 0.054| r_loss: 0.063| p_loss: 0.090| v_loss: 0.023| per_loss: 0.305 | a_loss: 0.506
Train: Epoch [1774/3000], Step [90/158]| g_loss: 0.667| d_loss: 0.612| gp_loss: 0.056| r_loss: 0.062| p_loss: 0.087| v_loss: 0.023| per_loss: 0.309 | a_loss: 0.508
Train: Epoch [1774/3000], Step [120/158]| g_loss: 0.710| d_loss: 0.605| gp_loss: 0.057| r_loss: 0.063| p_loss: 0.092| v_loss: 0.023| per_loss: 0.341 | a_loss: 0.544
Train: Epoch [1774/3000], Step [150/158]| g_loss: 0.750| d_loss: 0.557| gp_loss: 0.054| r_loss: 0.063| p_loss: 0.090| v_loss: 0.024| per_loss: 0.323 | a_loss: 0.586
Train: Epoch [1775/3000], Step [30/158]| g_loss: 0.670| d_loss: 0.725| gp_loss: 0.128| r_loss: 0.062| p_loss: 0.091| v_loss: 0.023| per_loss: 0.310 | a_loss: 0.508
Train: Epoch [1775/3000], Step [60/158]| g_loss: 0.701| d_loss: 0.601| gp_loss: 0.058| r_loss: 0.061| p_loss: 0.086| v_loss: 0.023| per_loss: 0.335 | a_loss: 0.540
Train: Epoch [1775/3000], Step [90/158]| g_loss: 0.692| d_loss: 0.628| gp_loss: 0.056| r_loss: 0.065| p_loss: 0.092| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.525
Train: Epoch [1775/3000], Step [120/158]| g_loss: 0.660| d_loss: 0.624| gp_loss: 0.056| r_loss: 0.063| p_loss: 0.093| v_loss: 0.025| per_loss: 0.330 | a_loss: 0.493
Train: Epoch [1775/3000], Step [150/158]| g_loss: 0.717| d_loss: 0.565| gp_loss: 0.059| r_loss: 0.063| p_loss: 0.094| v_loss: 0.024| per_loss: 0.304 | a_loss: 0.553
Train: Epoch [1776/3000], Step [30/158]| g_loss: 0.736| d_loss: 0.773| gp_loss: 0.218| r_loss: 0.064| p_loss: 0.093| v_loss: 0.023| per_loss: 0.322 | a_loss: 0.571
Train: Epoch [1776/3000], Step [60/158]| g_loss: 0.671| d_loss: 0.580| gp_loss: 0.052| r_loss: 0.062| p_loss: 0.089| v_loss: 0.024| per_loss: 0.328 | a_loss: 0.508
Train: Epoch [1776/3000], Step [90/158]| g_loss: 0.695| d_loss: 0.643| gp_loss: 0.048| r_loss: 0.064| p_loss: 0.094| v_loss: 0.024| per_loss: 0.310 | a_loss: 0.529
Train: Epoch [1776/3000], Step [120/158]| g_loss: 0.718| d_loss: 0.590| gp_loss: 0.056| r_loss: 0.063| p_loss: 0.091| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.553
Train: Epoch [1776/3000], Step [150/158]| g_loss: 0.718| d_loss: 0.625| gp_loss: 0.056| r_loss: 0.063| p_loss: 0.094| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.552
Train: Epoch [1777/3000], Step [30/158]| g_loss: 0.675| d_loss: 0.685| gp_loss: 0.119| r_loss: 0.063| p_loss: 0.092| v_loss: 0.024| per_loss: 0.334 | a_loss: 0.510
Train: Epoch [1777/3000], Step [60/158]| g_loss: 0.686| d_loss: 0.619| gp_loss: 0.050| r_loss: 0.065| p_loss: 0.095| v_loss: 0.024| per_loss: 0.326 | a_loss: 0.517
Train: Epoch [1777/3000], Step [90/158]| g_loss: 0.747| d_loss: 0.610| gp_loss: 0.054| r_loss: 0.063| p_loss: 0.092| v_loss: 0.023| per_loss: 0.324 | a_loss: 0.583
Train: Epoch [1777/3000], Step [120/158]| g_loss: 0.709| d_loss: 0.553| gp_loss: 0.057| r_loss: 0.066| p_loss: 0.092| v_loss: 0.024| per_loss: 0.336 | a_loss: 0.539
Train: Epoch [1777/3000], Step [150/158]| g_loss: 0.702| d_loss: 0.626| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.089| v_loss: 0.023| per_loss: 0.302 | a_loss: 0.543
Train: Epoch [1778/3000], Step [30/158]| g_loss: 0.611| d_loss: 0.788| gp_loss: 0.147| r_loss: 0.063| p_loss: 0.093| v_loss: 0.024| per_loss: 0.321 | a_loss: 0.446
Train: Epoch [1778/3000], Step [60/158]| g_loss: 0.660| d_loss: 0.686| gp_loss: 0.056| r_loss: 0.064| p_loss: 0.092| v_loss: 0.024| per_loss: 0.313 | a_loss: 0.495
Train: Epoch [1778/3000], Step [90/158]| g_loss: 0.706| d_loss: 0.513| gp_loss: 0.059| r_loss: 0.062| p_loss: 0.090| v_loss: 0.023| per_loss: 0.316 | a_loss: 0.545
Train: Epoch [1778/3000], Step [120/158]| g_loss: 0.712| d_loss: 0.659| gp_loss: 0.056| r_loss: 0.064| p_loss: 0.090| v_loss: 0.024| per_loss: 0.329 | a_loss: 0.547
Train: Epoch [1778/3000], Step [150/158]| g_loss: 0.699| d_loss: 0.559| gp_loss: 0.058| r_loss: 0.063| p_loss: 0.092| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.535
Train: Epoch [1779/3000], Step [30/158]| g_loss: 0.699| d_loss: 0.627| gp_loss: 0.113| r_loss: 0.063| p_loss: 0.089| v_loss: 0.023| per_loss: 0.318 | a_loss: 0.537
Train: Epoch [1779/3000], Step [60/158]| g_loss: 0.714| d_loss: 0.568| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.087| v_loss: 0.023| per_loss: 0.317 | a_loss: 0.556
Train: Epoch [1779/3000], Step [90/158]| g_loss: 0.691| d_loss: 0.582| gp_loss: 0.058| r_loss: 0.061| p_loss: 0.087| v_loss: 0.023| per_loss: 0.330 | a_loss: 0.530
Train: Epoch [1779/3000], Step [120/158]| g_loss: 0.727| d_loss: 0.621| gp_loss: 0.060| r_loss: 0.063| p_loss: 0.091| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.562
Train: Epoch [1779/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.602| gp_loss: 0.057| r_loss: 0.061| p_loss: 0.088| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.509
Train: Epoch [1780/3000], Step [30/158]| g_loss: 0.650| d_loss: 0.801| gp_loss: 0.242| r_loss: 0.064| p_loss: 0.091| v_loss: 0.023| per_loss: 0.321 | a_loss: 0.486
Train: Epoch [1780/3000], Step [60/158]| g_loss: 0.788| d_loss: 0.570| gp_loss: 0.053| r_loss: 0.060| p_loss: 0.083| v_loss: 0.023| per_loss: 0.342 | a_loss: 0.629
Train: Epoch [1780/3000], Step [90/158]| g_loss: 0.678| d_loss: 0.621| gp_loss: 0.053| r_loss: 0.060| p_loss: 0.085| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.522
Train: Epoch [1780/3000], Step [120/158]| g_loss: 0.695| d_loss: 0.588| gp_loss: 0.054| r_loss: 0.063| p_loss: 0.089| v_loss: 0.023| per_loss: 0.301 | a_loss: 0.534
Train: Epoch [1780/3000], Step [150/158]| g_loss: 0.680| d_loss: 0.636| gp_loss: 0.055| r_loss: 0.064| p_loss: 0.089| v_loss: 0.024| per_loss: 0.314 | a_loss: 0.517
Train: Epoch [1781/3000], Step [30/158]| g_loss: 0.670| d_loss: 0.714| gp_loss: 0.157| r_loss: 0.061| p_loss: 0.088| v_loss: 0.023| per_loss: 0.340 | a_loss: 0.508
Train: Epoch [1781/3000], Step [60/158]| g_loss: 0.663| d_loss: 0.620| gp_loss: 0.053| r_loss: 0.061| p_loss: 0.090| v_loss: 0.023| per_loss: 0.324 | a_loss: 0.501
Train: Epoch [1781/3000], Step [90/158]| g_loss: 0.749| d_loss: 0.524| gp_loss: 0.054| r_loss: 0.061| p_loss: 0.088| v_loss: 0.023| per_loss: 0.307 | a_loss: 0.590
Train: Epoch [1781/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.630| gp_loss: 0.056| r_loss: 0.064| p_loss: 0.089| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.503
Train: Epoch [1781/3000], Step [150/158]| g_loss: 0.652| d_loss: 0.671| gp_loss: 0.054| r_loss: 0.062| p_loss: 0.091| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.490
Train: Epoch [1782/3000], Step [30/158]| g_loss: 0.687| d_loss: 0.670| gp_loss: 0.111| r_loss: 0.062| p_loss: 0.091| v_loss: 0.023| per_loss: 0.335 | a_loss: 0.523
Train: Epoch [1782/3000], Step [60/158]| g_loss: 0.746| d_loss: 0.519| gp_loss: 0.053| r_loss: 0.064| p_loss: 0.090| v_loss: 0.024| per_loss: 0.325 | a_loss: 0.581
Train: Epoch [1782/3000], Step [90/158]| g_loss: 0.692| d_loss: 0.682| gp_loss: 0.054| r_loss: 0.064| p_loss: 0.092| v_loss: 0.024| per_loss: 0.336 | a_loss: 0.525
Train: Epoch [1782/3000], Step [120/158]| g_loss: 0.659| d_loss: 0.607| gp_loss: 0.061| r_loss: 0.060| p_loss: 0.087| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.502
Train: Epoch [1782/3000], Step [150/158]| g_loss: 0.671| d_loss: 0.634| gp_loss: 0.060| r_loss: 0.064| p_loss: 0.098| v_loss: 0.024| per_loss: 0.318 | a_loss: 0.502
Train: Epoch [1783/3000], Step [30/158]| g_loss: 0.722| d_loss: 0.730| gp_loss: 0.198| r_loss: 0.066| p_loss: 0.096| v_loss: 0.023| per_loss: 0.316 | a_loss: 0.554
Train: Epoch [1783/3000], Step [60/158]| g_loss: 0.769| d_loss: 0.533| gp_loss: 0.050| r_loss: 0.064| p_loss: 0.093| v_loss: 0.023| per_loss: 0.313 | a_loss: 0.605
Train: Epoch [1783/3000], Step [90/158]| g_loss: 0.659| d_loss: 0.632| gp_loss: 0.053| r_loss: 0.065| p_loss: 0.094| v_loss: 0.024| per_loss: 0.334 | a_loss: 0.490
Train: Epoch [1783/3000], Step [120/158]| g_loss: 0.680| d_loss: 0.641| gp_loss: 0.058| r_loss: 0.062| p_loss: 0.089| v_loss: 0.023| per_loss: 0.324 | a_loss: 0.518
Train: Epoch [1783/3000], Step [150/158]| g_loss: 0.656| d_loss: 0.681| gp_loss: 0.059| r_loss: 0.065| p_loss: 0.096| v_loss: 0.023| per_loss: 0.335 | a_loss: 0.487
Train: Epoch [1784/3000], Step [30/158]| g_loss: 0.754| d_loss: 0.674| gp_loss: 0.144| r_loss: 0.064| p_loss: 0.097| v_loss: 0.024| per_loss: 0.332 | a_loss: 0.583
Train: Epoch [1784/3000], Step [60/158]| g_loss: 0.661| d_loss: 0.606| gp_loss: 0.053| r_loss: 0.065| p_loss: 0.095| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.492
Train: Epoch [1784/3000], Step [90/158]| g_loss: 0.716| d_loss: 0.649| gp_loss: 0.051| r_loss: 0.065| p_loss: 0.096| v_loss: 0.023| per_loss: 0.318 | a_loss: 0.548
Train: Epoch [1784/3000], Step [120/158]| g_loss: 0.662| d_loss: 0.606| gp_loss: 0.055| r_loss: 0.065| p_loss: 0.097| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.493
Train: Epoch [1784/3000], Step [150/158]| g_loss: 0.730| d_loss: 0.581| gp_loss: 0.060| r_loss: 0.065| p_loss: 0.094| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.562
Train: Epoch [1785/3000], Step [30/158]| g_loss: 0.688| d_loss: 0.684| gp_loss: 0.117| r_loss: 0.062| p_loss: 0.095| v_loss: 0.023| per_loss: 0.328 | a_loss: 0.523
Train: Epoch [1785/3000], Step [60/158]| g_loss: 0.749| d_loss: 0.559| gp_loss: 0.060| r_loss: 0.067| p_loss: 0.100| v_loss: 0.024| per_loss: 0.336 | a_loss: 0.574
Train: Epoch [1785/3000], Step [90/158]| g_loss: 0.694| d_loss: 0.645| gp_loss: 0.056| r_loss: 0.064| p_loss: 0.098| v_loss: 0.023| per_loss: 0.332 | a_loss: 0.524
Train: Epoch [1785/3000], Step [120/158]| g_loss: 0.627| d_loss: 0.735| gp_loss: 0.054| r_loss: 0.065| p_loss: 0.101| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.457
Train: Epoch [1785/3000], Step [150/158]| g_loss: 0.694| d_loss: 0.571| gp_loss: 0.059| r_loss: 0.061| p_loss: 0.088| v_loss: 0.023| per_loss: 0.317 | a_loss: 0.534
Train: Epoch [1786/3000], Step [30/158]| g_loss: 0.719| d_loss: 0.705| gp_loss: 0.171| r_loss: 0.064| p_loss: 0.090| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.554
Train: Epoch [1786/3000], Step [60/158]| g_loss: 0.685| d_loss: 0.579| gp_loss: 0.056| r_loss: 0.063| p_loss: 0.088| v_loss: 0.024| per_loss: 0.309 | a_loss: 0.523
Train: Epoch [1786/3000], Step [90/158]| g_loss: 0.727| d_loss: 0.578| gp_loss: 0.056| r_loss: 0.062| p_loss: 0.088| v_loss: 0.023| per_loss: 0.338 | a_loss: 0.564
Train: Epoch [1786/3000], Step [120/158]| g_loss: 0.727| d_loss: 0.538| gp_loss: 0.056| r_loss: 0.062| p_loss: 0.091| v_loss: 0.023| per_loss: 0.330 | a_loss: 0.563
Train: Epoch [1786/3000], Step [150/158]| g_loss: 0.639| d_loss: 0.703| gp_loss: 0.052| r_loss: 0.063| p_loss: 0.095| v_loss: 0.023| per_loss: 0.335 | a_loss: 0.472
Train: Epoch [1787/3000], Step [30/158]| g_loss: 0.701| d_loss: 0.765| gp_loss: 0.224| r_loss: 0.062| p_loss: 0.090| v_loss: 0.022| per_loss: 0.324 | a_loss: 0.539
Train: Epoch [1787/3000], Step [60/158]| g_loss: 0.647| d_loss: 0.682| gp_loss: 0.049| r_loss: 0.063| p_loss: 0.095| v_loss: 0.024| per_loss: 0.314 | a_loss: 0.482
Train: Epoch [1787/3000], Step [90/158]| g_loss: 0.706| d_loss: 0.542| gp_loss: 0.054| r_loss: 0.061| p_loss: 0.087| v_loss: 0.023| per_loss: 0.309 | a_loss: 0.547
Train: Epoch [1787/3000], Step [120/158]| g_loss: 0.767| d_loss: 0.523| gp_loss: 0.055| r_loss: 0.064| p_loss: 0.092| v_loss: 0.024| per_loss: 0.327 | a_loss: 0.600
Train: Epoch [1787/3000], Step [150/158]| g_loss: 0.666| d_loss: 0.719| gp_loss: 0.052| r_loss: 0.064| p_loss: 0.092| v_loss: 0.022| per_loss: 0.341 | a_loss: 0.499
Train: Epoch [1788/3000], Step [30/158]| g_loss: 0.718| d_loss: 0.669| gp_loss: 0.150| r_loss: 0.062| p_loss: 0.090| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.557
Train: Epoch [1788/3000], Step [60/158]| g_loss: 0.666| d_loss: 0.583| gp_loss: 0.053| r_loss: 0.063| p_loss: 0.091| v_loss: 0.024| per_loss: 0.327 | a_loss: 0.500
Train: Epoch [1788/3000], Step [90/158]| g_loss: 0.684| d_loss: 0.596| gp_loss: 0.049| r_loss: 0.064| p_loss: 0.090| v_loss: 0.024| per_loss: 0.331 | a_loss: 0.518
Train: Epoch [1788/3000], Step [120/158]| g_loss: 0.736| d_loss: 0.579| gp_loss: 0.053| r_loss: 0.066| p_loss: 0.096| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.566
Train: Epoch [1788/3000], Step [150/158]| g_loss: 0.653| d_loss: 0.643| gp_loss: 0.056| r_loss: 0.062| p_loss: 0.093| v_loss: 0.023| per_loss: 0.312 | a_loss: 0.491
Train: Epoch [1789/3000], Step [30/158]| g_loss: 0.724| d_loss: 0.686| gp_loss: 0.149| r_loss: 0.060| p_loss: 0.089| v_loss: 0.023| per_loss: 0.311 | a_loss: 0.565
Train: Epoch [1789/3000], Step [60/158]| g_loss: 0.729| d_loss: 0.623| gp_loss: 0.050| r_loss: 0.065| p_loss: 0.096| v_loss: 0.024| per_loss: 0.329 | a_loss: 0.560
Train: Epoch [1789/3000], Step [90/158]| g_loss: 0.680| d_loss: 0.612| gp_loss: 0.050| r_loss: 0.065| p_loss: 0.097| v_loss: 0.024| per_loss: 0.314 | a_loss: 0.511
Train: Epoch [1789/3000], Step [120/158]| g_loss: 0.720| d_loss: 0.559| gp_loss: 0.053| r_loss: 0.063| p_loss: 0.092| v_loss: 0.023| per_loss: 0.327 | a_loss: 0.556
Train: Epoch [1789/3000], Step [150/158]| g_loss: 0.641| d_loss: 0.665| gp_loss: 0.052| r_loss: 0.064| p_loss: 0.089| v_loss: 0.023| per_loss: 0.317 | a_loss: 0.478
Train: Epoch [1790/3000], Step [30/158]| g_loss: 0.662| d_loss: 0.739| gp_loss: 0.146| r_loss: 0.065| p_loss: 0.093| v_loss: 0.024| per_loss: 0.340 | a_loss: 0.493
Train: Epoch [1790/3000], Step [60/158]| g_loss: 0.686| d_loss: 0.717| gp_loss: 0.055| r_loss: 0.062| p_loss: 0.094| v_loss: 0.024| per_loss: 0.316 | a_loss: 0.521
Train: Epoch [1790/3000], Step [90/158]| g_loss: 0.745| d_loss: 0.481| gp_loss: 0.058| r_loss: 0.064| p_loss: 0.091| v_loss: 0.024| per_loss: 0.315 | a_loss: 0.580
Train: Epoch [1790/3000], Step [120/158]| g_loss: 0.709| d_loss: 0.611| gp_loss: 0.057| r_loss: 0.064| p_loss: 0.097| v_loss: 0.023| per_loss: 0.328 | a_loss: 0.540
Train: Epoch [1790/3000], Step [150/158]| g_loss: 0.690| d_loss: 0.694| gp_loss: 0.056| r_loss: 0.062| p_loss: 0.093| v_loss: 0.023| per_loss: 0.317 | a_loss: 0.527
Train: Epoch [1791/3000], Step [30/158]| g_loss: 0.695| d_loss: 0.720| gp_loss: 0.141| r_loss: 0.064| p_loss: 0.092| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.529
Train: Epoch [1791/3000], Step [60/158]| g_loss: 0.686| d_loss: 0.540| gp_loss: 0.056| r_loss: 0.063| p_loss: 0.091| v_loss: 0.023| per_loss: 0.328 | a_loss: 0.522
Train: Epoch [1791/3000], Step [90/158]| g_loss: 0.726| d_loss: 0.573| gp_loss: 0.054| r_loss: 0.062| p_loss: 0.088| v_loss: 0.023| per_loss: 0.321 | a_loss: 0.565
Train: Epoch [1791/3000], Step [120/158]| g_loss: 0.719| d_loss: 0.609| gp_loss: 0.054| r_loss: 0.062| p_loss: 0.091| v_loss: 0.024| per_loss: 0.322 | a_loss: 0.555
Train: Epoch [1791/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.640| gp_loss: 0.056| r_loss: 0.063| p_loss: 0.093| v_loss: 0.023| per_loss: 0.311 | a_loss: 0.498
Train: Epoch [1792/3000], Step [30/158]| g_loss: 0.680| d_loss: 0.745| gp_loss: 0.172| r_loss: 0.065| p_loss: 0.092| v_loss: 0.023| per_loss: 0.338 | a_loss: 0.512
Train: Epoch [1792/3000], Step [60/158]| g_loss: 0.644| d_loss: 0.657| gp_loss: 0.058| r_loss: 0.065| p_loss: 0.092| v_loss: 0.023| per_loss: 0.330 | a_loss: 0.477
Train: Epoch [1792/3000], Step [90/158]| g_loss: 0.706| d_loss: 0.603| gp_loss: 0.058| r_loss: 0.063| p_loss: 0.092| v_loss: 0.023| per_loss: 0.311 | a_loss: 0.543
Train: Epoch [1792/3000], Step [120/158]| g_loss: 0.696| d_loss: 0.578| gp_loss: 0.055| r_loss: 0.065| p_loss: 0.095| v_loss: 0.024| per_loss: 0.322 | a_loss: 0.527
Train: Epoch [1792/3000], Step [150/158]| g_loss: 0.749| d_loss: 0.580| gp_loss: 0.059| r_loss: 0.062| p_loss: 0.094| v_loss: 0.024| per_loss: 0.322 | a_loss: 0.583
Train: Epoch [1793/3000], Step [30/158]| g_loss: 0.724| d_loss: 0.652| gp_loss: 0.142| r_loss: 0.063| p_loss: 0.091| v_loss: 0.023| per_loss: 0.313 | a_loss: 0.560
Train: Epoch [1793/3000], Step [60/158]| g_loss: 0.682| d_loss: 0.660| gp_loss: 0.052| r_loss: 0.063| p_loss: 0.092| v_loss: 0.023| per_loss: 0.332 | a_loss: 0.517
Train: Epoch [1793/3000], Step [90/158]| g_loss: 0.680| d_loss: 0.612| gp_loss: 0.055| r_loss: 0.062| p_loss: 0.092| v_loss: 0.024| per_loss: 0.311 | a_loss: 0.517
Train: Epoch [1793/3000], Step [120/158]| g_loss: 0.689| d_loss: 0.662| gp_loss: 0.055| r_loss: 0.064| p_loss: 0.095| v_loss: 0.023| per_loss: 0.332 | a_loss: 0.522
Train: Epoch [1793/3000], Step [150/158]| g_loss: 0.724| d_loss: 0.565| gp_loss: 0.058| r_loss: 0.064| p_loss: 0.093| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.558
Train: Epoch [1794/3000], Step [30/158]| g_loss: 0.690| d_loss: 0.737| gp_loss: 0.164| r_loss: 0.069| p_loss: 0.091| v_loss: 0.023| per_loss: 0.315 | a_loss: 0.520
Train: Epoch [1794/3000], Step [60/158]| g_loss: 0.693| d_loss: 0.583| gp_loss: 0.055| r_loss: 0.065| p_loss: 0.089| v_loss: 0.024| per_loss: 0.317 | a_loss: 0.527
Train: Epoch [1794/3000], Step [90/158]| g_loss: 0.695| d_loss: 0.622| gp_loss: 0.054| r_loss: 0.062| p_loss: 0.094| v_loss: 0.023| per_loss: 0.327 | a_loss: 0.531
Train: Epoch [1794/3000], Step [120/158]| g_loss: 0.687| d_loss: 0.618| gp_loss: 0.058| r_loss: 0.061| p_loss: 0.092| v_loss: 0.023| per_loss: 0.339 | a_loss: 0.523
Train: Epoch [1794/3000], Step [150/158]| g_loss: 0.713| d_loss: 0.581| gp_loss: 0.056| r_loss: 0.064| p_loss: 0.092| v_loss: 0.023| per_loss: 0.324 | a_loss: 0.548
Train: Epoch [1795/3000], Step [30/158]| g_loss: 0.713| d_loss: 0.657| gp_loss: 0.122| r_loss: 0.066| p_loss: 0.096| v_loss: 0.023| per_loss: 0.313 | a_loss: 0.544
Train: Epoch [1795/3000], Step [60/158]| g_loss: 0.682| d_loss: 0.675| gp_loss: 0.054| r_loss: 0.064| p_loss: 0.092| v_loss: 0.024| per_loss: 0.324 | a_loss: 0.516
Train: Epoch [1795/3000], Step [90/158]| g_loss: 0.643| d_loss: 0.618| gp_loss: 0.056| r_loss: 0.059| p_loss: 0.088| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.485
Train: Epoch [1795/3000], Step [120/158]| g_loss: 0.723| d_loss: 0.630| gp_loss: 0.060| r_loss: 0.065| p_loss: 0.097| v_loss: 0.025| per_loss: 0.337 | a_loss: 0.551
Train: Epoch [1795/3000], Step [150/158]| g_loss: 0.700| d_loss: 0.542| gp_loss: 0.063| r_loss: 0.063| p_loss: 0.092| v_loss: 0.023| per_loss: 0.322 | a_loss: 0.536
Train: Epoch [1796/3000], Step [30/158]| g_loss: 0.645| d_loss: 0.777| gp_loss: 0.139| r_loss: 0.064| p_loss: 0.095| v_loss: 0.023| per_loss: 0.318 | a_loss: 0.480
Train: Epoch [1796/3000], Step [60/158]| g_loss: 0.705| d_loss: 0.612| gp_loss: 0.060| r_loss: 0.062| p_loss: 0.090| v_loss: 0.024| per_loss: 0.328 | a_loss: 0.542
Train: Epoch [1796/3000], Step [90/158]| g_loss: 0.692| d_loss: 0.573| gp_loss: 0.058| r_loss: 0.066| p_loss: 0.097| v_loss: 0.025| per_loss: 0.331 | a_loss: 0.520
Train: Epoch [1796/3000], Step [120/158]| g_loss: 0.748| d_loss: 0.521| gp_loss: 0.064| r_loss: 0.066| p_loss: 0.094| v_loss: 0.024| per_loss: 0.317 | a_loss: 0.579
Train: Epoch [1796/3000], Step [150/158]| g_loss: 0.731| d_loss: 0.700| gp_loss: 0.060| r_loss: 0.064| p_loss: 0.093| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.565
Train: Epoch [1797/3000], Step [30/158]| g_loss: 0.687| d_loss: 0.751| gp_loss: 0.173| r_loss: 0.063| p_loss: 0.091| v_loss: 0.023| per_loss: 0.321 | a_loss: 0.523
Train: Epoch [1797/3000], Step [60/158]| g_loss: 0.694| d_loss: 0.554| gp_loss: 0.057| r_loss: 0.062| p_loss: 0.089| v_loss: 0.024| per_loss: 0.334 | a_loss: 0.530
Train: Epoch [1797/3000], Step [90/158]| g_loss: 0.711| d_loss: 0.621| gp_loss: 0.053| r_loss: 0.063| p_loss: 0.089| v_loss: 0.023| per_loss: 0.311 | a_loss: 0.549
Train: Epoch [1797/3000], Step [120/158]| g_loss: 0.654| d_loss: 0.668| gp_loss: 0.057| r_loss: 0.065| p_loss: 0.093| v_loss: 0.024| per_loss: 0.319 | a_loss: 0.487
Train: Epoch [1797/3000], Step [150/158]| g_loss: 0.705| d_loss: 0.576| gp_loss: 0.058| r_loss: 0.066| p_loss: 0.099| v_loss: 0.024| per_loss: 0.329 | a_loss: 0.532
Train: Epoch [1798/3000], Step [30/158]| g_loss: 0.705| d_loss: 0.685| gp_loss: 0.137| r_loss: 0.063| p_loss: 0.091| v_loss: 0.024| per_loss: 0.315 | a_loss: 0.541
Train: Epoch [1798/3000], Step [60/158]| g_loss: 0.687| d_loss: 0.619| gp_loss: 0.054| r_loss: 0.061| p_loss: 0.088| v_loss: 0.023| per_loss: 0.322 | a_loss: 0.527
Train: Epoch [1798/3000], Step [90/158]| g_loss: 0.702| d_loss: 0.607| gp_loss: 0.056| r_loss: 0.067| p_loss: 0.097| v_loss: 0.023| per_loss: 0.328 | a_loss: 0.530
Train: Epoch [1798/3000], Step [120/158]| g_loss: 0.716| d_loss: 0.642| gp_loss: 0.058| r_loss: 0.065| p_loss: 0.095| v_loss: 0.024| per_loss: 0.329 | a_loss: 0.547
Train: Epoch [1798/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.596| gp_loss: 0.061| r_loss: 0.067| p_loss: 0.097| v_loss: 0.024| per_loss: 0.319 | a_loss: 0.487
Train: Epoch [1799/3000], Step [30/158]| g_loss: 0.713| d_loss: 0.693| gp_loss: 0.180| r_loss: 0.066| p_loss: 0.095| v_loss: 0.024| per_loss: 0.324 | a_loss: 0.543
Train: Epoch [1799/3000], Step [60/158]| g_loss: 0.720| d_loss: 0.643| gp_loss: 0.055| r_loss: 0.065| p_loss: 0.092| v_loss: 0.023| per_loss: 0.317 | a_loss: 0.554
Train: Epoch [1799/3000], Step [90/158]| g_loss: 0.746| d_loss: 0.520| gp_loss: 0.052| r_loss: 0.071| p_loss: 0.097| v_loss: 0.024| per_loss: 0.348 | a_loss: 0.568
Train: Epoch [1799/3000], Step [120/158]| g_loss: 0.690| d_loss: 0.644| gp_loss: 0.054| r_loss: 0.066| p_loss: 0.096| v_loss: 0.023| per_loss: 0.326 | a_loss: 0.520
Train: Epoch [1799/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.684| gp_loss: 0.058| r_loss: 0.067| p_loss: 0.097| v_loss: 0.023| per_loss: 0.306 | a_loss: 0.506
Train: Epoch [1800/3000], Step [30/158]| g_loss: 0.659| d_loss: 0.687| gp_loss: 0.144| r_loss: 0.063| p_loss: 0.092| v_loss: 0.023| per_loss: 0.327 | a_loss: 0.494
Train: Epoch [1800/3000], Step [60/158]| g_loss: 0.762| d_loss: 0.580| gp_loss: 0.053| r_loss: 0.063| p_loss: 0.092| v_loss: 0.024| per_loss: 0.329 | a_loss: 0.596
Train: Epoch [1800/3000], Step [90/158]| g_loss: 0.678| d_loss: 0.642| gp_loss: 0.054| r_loss: 0.063| p_loss: 0.094| v_loss: 0.023| per_loss: 0.322 | a_loss: 0.512
Train: Epoch [1800/3000], Step [120/158]| g_loss: 0.661| d_loss: 0.658| gp_loss: 0.054| r_loss: 0.062| p_loss: 0.094| v_loss: 0.023| per_loss: 0.324 | a_loss: 0.496
Train: Epoch [1800/3000], Step [150/158]| g_loss: 0.706| d_loss: 0.636| gp_loss: 0.059| r_loss: 0.067| p_loss: 0.096| v_loss: 0.024| per_loss: 0.338 | a_loss: 0.534
Test: Epoch [1800/3000]| g_loss: 0.627| r_loss: 0.385| p_loss: 0.300| v_loss: 0.022
Train: Epoch [1801/3000], Step [30/158]| g_loss: 0.664| d_loss: 0.638| gp_loss: 0.056| r_loss: 0.068| p_loss: 0.099| v_loss: 0.024| per_loss: 0.347 | a_loss: 0.488
Train: Epoch [1801/3000], Step [60/158]| g_loss: 0.686| d_loss: 0.576| gp_loss: 0.056| r_loss: 0.060| p_loss: 0.089| v_loss: 0.024| per_loss: 0.333 | a_loss: 0.524
Train: Epoch [1801/3000], Step [90/158]| g_loss: 0.663| d_loss: 0.650| gp_loss: 0.059| r_loss: 0.061| p_loss: 0.091| v_loss: 0.022| per_loss: 0.328 | a_loss: 0.502
Train: Epoch [1801/3000], Step [120/158]| g_loss: 0.656| d_loss: 0.660| gp_loss: 0.061| r_loss: 0.069| p_loss: 0.100| v_loss: 0.025| per_loss: 0.323 | a_loss: 0.480
Train: Epoch [1801/3000], Step [150/158]| g_loss: 0.743| d_loss: 0.542| gp_loss: 0.058| r_loss: 0.068| p_loss: 0.097| v_loss: 0.024| per_loss: 0.318 | a_loss: 0.570
Train: Epoch [1802/3000], Step [30/158]| g_loss: 0.757| d_loss: 0.635| gp_loss: 0.173| r_loss: 0.058| p_loss: 0.086| v_loss: 0.023| per_loss: 0.326 | a_loss: 0.601
Train: Epoch [1802/3000], Step [60/158]| g_loss: 0.725| d_loss: 0.604| gp_loss: 0.055| r_loss: 0.062| p_loss: 0.090| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.565
Train: Epoch [1802/3000], Step [90/158]| g_loss: 0.683| d_loss: 0.606| gp_loss: 0.055| r_loss: 0.066| p_loss: 0.091| v_loss: 0.024| per_loss: 0.335 | a_loss: 0.515
Train: Epoch [1802/3000], Step [120/158]| g_loss: 0.660| d_loss: 0.697| gp_loss: 0.059| r_loss: 0.062| p_loss: 0.087| v_loss: 0.024| per_loss: 0.338 | a_loss: 0.497
Train: Epoch [1802/3000], Step [150/158]| g_loss: 0.691| d_loss: 0.598| gp_loss: 0.060| r_loss: 0.062| p_loss: 0.088| v_loss: 0.023| per_loss: 0.310 | a_loss: 0.532
Train: Epoch [1803/3000], Step [30/158]| g_loss: 0.671| d_loss: 0.758| gp_loss: 0.143| r_loss: 0.061| p_loss: 0.092| v_loss: 0.023| per_loss: 0.331 | a_loss: 0.507
Train: Epoch [1803/3000], Step [60/158]| g_loss: 0.684| d_loss: 0.593| gp_loss: 0.059| r_loss: 0.064| p_loss: 0.092| v_loss: 0.024| per_loss: 0.327 | a_loss: 0.519
Train: Epoch [1803/3000], Step [90/158]| g_loss: 0.688| d_loss: 0.653| gp_loss: 0.056| r_loss: 0.063| p_loss: 0.093| v_loss: 0.024| per_loss: 0.323 | a_loss: 0.523
Train: Epoch [1803/3000], Step [120/158]| g_loss: 0.689| d_loss: 0.547| gp_loss: 0.060| r_loss: 0.064| p_loss: 0.092| v_loss: 0.024| per_loss: 0.344 | a_loss: 0.520
Train: Epoch [1803/3000], Step [150/158]| g_loss: 0.786| d_loss: 0.527| gp_loss: 0.062| r_loss: 0.066| p_loss: 0.092| v_loss: 0.024| per_loss: 0.329 | a_loss: 0.618
Train: Epoch [1804/3000], Step [30/158]| g_loss: 0.730| d_loss: 0.672| gp_loss: 0.154| r_loss: 0.065| p_loss: 0.094| v_loss: 0.024| per_loss: 0.328 | a_loss: 0.561
Train: Epoch [1804/3000], Step [60/158]| g_loss: 0.747| d_loss: 0.575| gp_loss: 0.052| r_loss: 0.061| p_loss: 0.087| v_loss: 0.023| per_loss: 0.339 | a_loss: 0.585
Train: Epoch [1804/3000], Step [90/158]| g_loss: 0.692| d_loss: 0.557| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.089| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.531
Train: Epoch [1804/3000], Step [120/158]| g_loss: 0.754| d_loss: 0.644| gp_loss: 0.054| r_loss: 0.063| p_loss: 0.092| v_loss: 0.023| per_loss: 0.328 | a_loss: 0.590
Train: Epoch [1804/3000], Step [150/158]| g_loss: 0.592| d_loss: 0.748| gp_loss: 0.055| r_loss: 0.062| p_loss: 0.092| v_loss: 0.023| per_loss: 0.322 | a_loss: 0.428
Train: Epoch [1805/3000], Step [30/158]| g_loss: 0.668| d_loss: 0.655| gp_loss: 0.156| r_loss: 0.061| p_loss: 0.091| v_loss: 0.024| per_loss: 0.337 | a_loss: 0.504
Train: Epoch [1805/3000], Step [60/158]| g_loss: 0.696| d_loss: 0.663| gp_loss: 0.055| r_loss: 0.061| p_loss: 0.089| v_loss: 0.022| per_loss: 0.330 | a_loss: 0.536
Train: Epoch [1805/3000], Step [90/158]| g_loss: 0.683| d_loss: 0.576| gp_loss: 0.057| r_loss: 0.061| p_loss: 0.087| v_loss: 0.024| per_loss: 0.312 | a_loss: 0.523
Train: Epoch [1805/3000], Step [120/158]| g_loss: 0.684| d_loss: 0.645| gp_loss: 0.058| r_loss: 0.065| p_loss: 0.089| v_loss: 0.023| per_loss: 0.346 | a_loss: 0.516
Train: Epoch [1805/3000], Step [150/158]| g_loss: 0.663| d_loss: 0.662| gp_loss: 0.057| r_loss: 0.065| p_loss: 0.097| v_loss: 0.024| per_loss: 0.310 | a_loss: 0.495
Train: Epoch [1806/3000], Step [30/158]| g_loss: 0.724| d_loss: 0.722| gp_loss: 0.185| r_loss: 0.064| p_loss: 0.099| v_loss: 0.024| per_loss: 0.314 | a_loss: 0.556
Train: Epoch [1806/3000], Step [60/158]| g_loss: 0.687| d_loss: 0.572| gp_loss: 0.054| r_loss: 0.065| p_loss: 0.088| v_loss: 0.023| per_loss: 0.330 | a_loss: 0.522
Train: Epoch [1806/3000], Step [90/158]| g_loss: 0.689| d_loss: 0.638| gp_loss: 0.054| r_loss: 0.064| p_loss: 0.094| v_loss: 0.024| per_loss: 0.348 | a_loss: 0.519
Train: Epoch [1806/3000], Step [120/158]| g_loss: 0.740| d_loss: 0.596| gp_loss: 0.059| r_loss: 0.064| p_loss: 0.094| v_loss: 0.024| per_loss: 0.327 | a_loss: 0.572
Train: Epoch [1806/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.625| gp_loss: 0.055| r_loss: 0.063| p_loss: 0.092| v_loss: 0.023| per_loss: 0.336 | a_loss: 0.495
Train: Epoch [1807/3000], Step [30/158]| g_loss: 0.682| d_loss: 0.707| gp_loss: 0.167| r_loss: 0.065| p_loss: 0.095| v_loss: 0.023| per_loss: 0.316 | a_loss: 0.515
Train: Epoch [1807/3000], Step [60/158]| g_loss: 0.743| d_loss: 0.509| gp_loss: 0.056| r_loss: 0.069| p_loss: 0.093| v_loss: 0.024| per_loss: 0.334 | a_loss: 0.570
Train: Epoch [1807/3000], Step [90/158]| g_loss: 0.702| d_loss: 0.595| gp_loss: 0.054| r_loss: 0.063| p_loss: 0.096| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.536
Train: Epoch [1807/3000], Step [120/158]| g_loss: 0.734| d_loss: 0.634| gp_loss: 0.056| r_loss: 0.064| p_loss: 0.091| v_loss: 0.023| per_loss: 0.321 | a_loss: 0.570
Train: Epoch [1807/3000], Step [150/158]| g_loss: 0.655| d_loss: 0.681| gp_loss: 0.059| r_loss: 0.064| p_loss: 0.092| v_loss: 0.024| per_loss: 0.329 | a_loss: 0.488
Train: Epoch [1808/3000], Step [30/158]| g_loss: 0.627| d_loss: 0.806| gp_loss: 0.188| r_loss: 0.064| p_loss: 0.092| v_loss: 0.022| per_loss: 0.330 | a_loss: 0.461
Train: Epoch [1808/3000], Step [60/158]| g_loss: 0.688| d_loss: 0.605| gp_loss: 0.053| r_loss: 0.061| p_loss: 0.093| v_loss: 0.023| per_loss: 0.326 | a_loss: 0.525
Train: Epoch [1808/3000], Step [90/158]| g_loss: 0.686| d_loss: 0.632| gp_loss: 0.055| r_loss: 0.063| p_loss: 0.093| v_loss: 0.023| per_loss: 0.322 | a_loss: 0.521
Train: Epoch [1808/3000], Step [120/158]| g_loss: 0.755| d_loss: 0.569| gp_loss: 0.053| r_loss: 0.064| p_loss: 0.093| v_loss: 0.024| per_loss: 0.346 | a_loss: 0.586
Train: Epoch [1808/3000], Step [150/158]| g_loss: 0.701| d_loss: 0.566| gp_loss: 0.058| r_loss: 0.064| p_loss: 0.096| v_loss: 0.024| per_loss: 0.330 | a_loss: 0.532
Train: Epoch [1809/3000], Step [30/158]| g_loss: 0.729| d_loss: 0.796| gp_loss: 0.229| r_loss: 0.063| p_loss: 0.092| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.565
Train: Epoch [1809/3000], Step [60/158]| g_loss: 0.664| d_loss: 0.632| gp_loss: 0.050| r_loss: 0.065| p_loss: 0.095| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.498
Train: Epoch [1809/3000], Step [90/158]| g_loss: 0.690| d_loss: 0.552| gp_loss: 0.051| r_loss: 0.061| p_loss: 0.089| v_loss: 0.023| per_loss: 0.343 | a_loss: 0.528
Train: Epoch [1809/3000], Step [120/158]| g_loss: 0.750| d_loss: 0.566| gp_loss: 0.053| r_loss: 0.064| p_loss: 0.090| v_loss: 0.024| per_loss: 0.331 | a_loss: 0.585
Train: Epoch [1809/3000], Step [150/158]| g_loss: 0.654| d_loss: 0.697| gp_loss: 0.051| r_loss: 0.062| p_loss: 0.094| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.490
Train: Epoch [1810/3000], Step [30/158]| g_loss: 0.716| d_loss: 0.709| gp_loss: 0.149| r_loss: 0.067| p_loss: 0.098| v_loss: 0.024| per_loss: 0.336 | a_loss: 0.542
Train: Epoch [1810/3000], Step [60/158]| g_loss: 0.651| d_loss: 0.624| gp_loss: 0.050| r_loss: 0.061| p_loss: 0.094| v_loss: 0.023| per_loss: 0.313 | a_loss: 0.489
Train: Epoch [1810/3000], Step [90/158]| g_loss: 0.690| d_loss: 0.615| gp_loss: 0.049| r_loss: 0.066| p_loss: 0.095| v_loss: 0.024| per_loss: 0.318 | a_loss: 0.522
Train: Epoch [1810/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.620| gp_loss: 0.055| r_loss: 0.064| p_loss: 0.090| v_loss: 0.023| per_loss: 0.338 | a_loss: 0.501
Train: Epoch [1810/3000], Step [150/158]| g_loss: 0.695| d_loss: 0.570| gp_loss: 0.057| r_loss: 0.061| p_loss: 0.090| v_loss: 0.024| per_loss: 0.323 | a_loss: 0.533
Train: Epoch [1811/3000], Step [30/158]| g_loss: 0.682| d_loss: 0.755| gp_loss: 0.191| r_loss: 0.063| p_loss: 0.093| v_loss: 0.024| per_loss: 0.324 | a_loss: 0.517
Train: Epoch [1811/3000], Step [60/158]| g_loss: 0.704| d_loss: 0.611| gp_loss: 0.050| r_loss: 0.062| p_loss: 0.090| v_loss: 0.023| per_loss: 0.332 | a_loss: 0.541
Train: Epoch [1811/3000], Step [90/158]| g_loss: 0.735| d_loss: 0.591| gp_loss: 0.056| r_loss: 0.063| p_loss: 0.093| v_loss: 0.024| per_loss: 0.326 | a_loss: 0.569
Train: Epoch [1811/3000], Step [120/158]| g_loss: 0.694| d_loss: 0.586| gp_loss: 0.051| r_loss: 0.066| p_loss: 0.095| v_loss: 0.023| per_loss: 0.332 | a_loss: 0.525
Train: Epoch [1811/3000], Step [150/158]| g_loss: 0.715| d_loss: 0.620| gp_loss: 0.055| r_loss: 0.067| p_loss: 0.100| v_loss: 0.023| per_loss: 0.346 | a_loss: 0.540
Train: Epoch [1812/3000], Step [30/158]| g_loss: 0.714| d_loss: 0.673| gp_loss: 0.146| r_loss: 0.064| p_loss: 0.100| v_loss: 0.023| per_loss: 0.332 | a_loss: 0.545
Train: Epoch [1812/3000], Step [60/158]| g_loss: 0.699| d_loss: 0.606| gp_loss: 0.054| r_loss: 0.062| p_loss: 0.092| v_loss: 0.025| per_loss: 0.350 | a_loss: 0.532
Train: Epoch [1812/3000], Step [90/158]| g_loss: 0.739| d_loss: 0.557| gp_loss: 0.051| r_loss: 0.062| p_loss: 0.092| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.575
Train: Epoch [1812/3000], Step [120/158]| g_loss: 0.756| d_loss: 0.552| gp_loss: 0.054| r_loss: 0.065| p_loss: 0.095| v_loss: 0.024| per_loss: 0.334 | a_loss: 0.586
Train: Epoch [1812/3000], Step [150/158]| g_loss: 0.605| d_loss: 0.744| gp_loss: 0.053| r_loss: 0.063| p_loss: 0.094| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.441
Train: Epoch [1813/3000], Step [30/158]| g_loss: 0.722| d_loss: 0.658| gp_loss: 0.137| r_loss: 0.063| p_loss: 0.090| v_loss: 0.024| per_loss: 0.336 | a_loss: 0.557
Train: Epoch [1813/3000], Step [60/158]| g_loss: 0.679| d_loss: 0.615| gp_loss: 0.053| r_loss: 0.062| p_loss: 0.092| v_loss: 0.023| per_loss: 0.322 | a_loss: 0.516
Train: Epoch [1813/3000], Step [90/158]| g_loss: 0.694| d_loss: 0.665| gp_loss: 0.055| r_loss: 0.065| p_loss: 0.094| v_loss: 0.024| per_loss: 0.328 | a_loss: 0.525
Train: Epoch [1813/3000], Step [120/158]| g_loss: 0.639| d_loss: 0.643| gp_loss: 0.060| r_loss: 0.064| p_loss: 0.092| v_loss: 0.024| per_loss: 0.321 | a_loss: 0.474
Train: Epoch [1813/3000], Step [150/158]| g_loss: 0.744| d_loss: 0.614| gp_loss: 0.058| r_loss: 0.064| p_loss: 0.099| v_loss: 0.024| per_loss: 0.325 | a_loss: 0.573
Train: Epoch [1814/3000], Step [30/158]| g_loss: 0.726| d_loss: 0.665| gp_loss: 0.165| r_loss: 0.067| p_loss: 0.099| v_loss: 0.025| per_loss: 0.347 | a_loss: 0.551
Train: Epoch [1814/3000], Step [60/158]| g_loss: 0.735| d_loss: 0.588| gp_loss: 0.049| r_loss: 0.069| p_loss: 0.100| v_loss: 0.025| per_loss: 0.330 | a_loss: 0.558
Train: Epoch [1814/3000], Step [90/158]| g_loss: 0.719| d_loss: 0.573| gp_loss: 0.052| r_loss: 0.062| p_loss: 0.094| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.556
Train: Epoch [1814/3000], Step [120/158]| g_loss: 0.650| d_loss: 0.768| gp_loss: 0.053| r_loss: 0.067| p_loss: 0.099| v_loss: 0.023| per_loss: 0.342 | a_loss: 0.477
Train: Epoch [1814/3000], Step [150/158]| g_loss: 0.703| d_loss: 0.577| gp_loss: 0.056| r_loss: 0.064| p_loss: 0.095| v_loss: 0.024| per_loss: 0.332 | a_loss: 0.535
Train: Epoch [1815/3000], Step [30/158]| g_loss: 0.746| d_loss: 0.659| gp_loss: 0.142| r_loss: 0.063| p_loss: 0.092| v_loss: 0.023| per_loss: 0.333 | a_loss: 0.580
Train: Epoch [1815/3000], Step [60/158]| g_loss: 0.681| d_loss: 0.600| gp_loss: 0.051| r_loss: 0.064| p_loss: 0.093| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.514
Train: Epoch [1815/3000], Step [90/158]| g_loss: 0.686| d_loss: 0.632| gp_loss: 0.053| r_loss: 0.063| p_loss: 0.095| v_loss: 0.024| per_loss: 0.327 | a_loss: 0.519
Train: Epoch [1815/3000], Step [120/158]| g_loss: 0.746| d_loss: 0.604| gp_loss: 0.056| r_loss: 0.067| p_loss: 0.100| v_loss: 0.024| per_loss: 0.322 | a_loss: 0.573
Train: Epoch [1815/3000], Step [150/158]| g_loss: 0.651| d_loss: 0.620| gp_loss: 0.055| r_loss: 0.065| p_loss: 0.097| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.482
Train: Epoch [1816/3000], Step [30/158]| g_loss: 0.703| d_loss: 0.698| gp_loss: 0.106| r_loss: 0.064| p_loss: 0.092| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.537
Train: Epoch [1816/3000], Step [60/158]| g_loss: 0.695| d_loss: 0.656| gp_loss: 0.054| r_loss: 0.061| p_loss: 0.093| v_loss: 0.023| per_loss: 0.324 | a_loss: 0.533
Train: Epoch [1816/3000], Step [90/158]| g_loss: 0.712| d_loss: 0.574| gp_loss: 0.059| r_loss: 0.067| p_loss: 0.096| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.541
Train: Epoch [1816/3000], Step [120/158]| g_loss: 0.676| d_loss: 0.647| gp_loss: 0.059| r_loss: 0.070| p_loss: 0.101| v_loss: 0.024| per_loss: 0.326 | a_loss: 0.499
Train: Epoch [1816/3000], Step [150/158]| g_loss: 0.752| d_loss: 0.565| gp_loss: 0.062| r_loss: 0.064| p_loss: 0.093| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.586
Train: Epoch [1817/3000], Step [30/158]| g_loss: 0.684| d_loss: 0.726| gp_loss: 0.132| r_loss: 0.062| p_loss: 0.092| v_loss: 0.023| per_loss: 0.333 | a_loss: 0.520
Train: Epoch [1817/3000], Step [60/158]| g_loss: 0.649| d_loss: 0.638| gp_loss: 0.056| r_loss: 0.062| p_loss: 0.088| v_loss: 0.023| per_loss: 0.316 | a_loss: 0.489
Train: Epoch [1817/3000], Step [90/158]| g_loss: 0.729| d_loss: 0.524| gp_loss: 0.056| r_loss: 0.062| p_loss: 0.089| v_loss: 0.024| per_loss: 0.325 | a_loss: 0.566
Train: Epoch [1817/3000], Step [120/158]| g_loss: 0.683| d_loss: 0.595| gp_loss: 0.057| r_loss: 0.064| p_loss: 0.093| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.519
Train: Epoch [1817/3000], Step [150/158]| g_loss: 0.717| d_loss: 0.638| gp_loss: 0.059| r_loss: 0.067| p_loss: 0.096| v_loss: 0.023| per_loss: 0.335 | a_loss: 0.546
Train: Epoch [1818/3000], Step [30/158]| g_loss: 0.642| d_loss: 0.763| gp_loss: 0.167| r_loss: 0.062| p_loss: 0.088| v_loss: 0.024| per_loss: 0.328 | a_loss: 0.479
Train: Epoch [1818/3000], Step [60/158]| g_loss: 0.760| d_loss: 0.483| gp_loss: 0.060| r_loss: 0.063| p_loss: 0.089| v_loss: 0.023| per_loss: 0.321 | a_loss: 0.597
Train: Epoch [1818/3000], Step [90/158]| g_loss: 0.735| d_loss: 0.602| gp_loss: 0.057| r_loss: 0.065| p_loss: 0.088| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.571
Train: Epoch [1818/3000], Step [120/158]| g_loss: 0.652| d_loss: 0.717| gp_loss: 0.057| r_loss: 0.063| p_loss: 0.091| v_loss: 0.024| per_loss: 0.337 | a_loss: 0.486
Train: Epoch [1818/3000], Step [150/158]| g_loss: 0.650| d_loss: 0.602| gp_loss: 0.060| r_loss: 0.059| p_loss: 0.087| v_loss: 0.022| per_loss: 0.324 | a_loss: 0.493
Train: Epoch [1819/3000], Step [30/158]| g_loss: 0.713| d_loss: 0.742| gp_loss: 0.216| r_loss: 0.065| p_loss: 0.095| v_loss: 0.024| per_loss: 0.322 | a_loss: 0.545
Train: Epoch [1819/3000], Step [60/158]| g_loss: 0.703| d_loss: 0.551| gp_loss: 0.051| r_loss: 0.061| p_loss: 0.086| v_loss: 0.023| per_loss: 0.314 | a_loss: 0.545
Train: Epoch [1819/3000], Step [90/158]| g_loss: 0.690| d_loss: 0.642| gp_loss: 0.053| r_loss: 0.062| p_loss: 0.090| v_loss: 0.023| per_loss: 0.312 | a_loss: 0.529
Train: Epoch [1819/3000], Step [120/158]| g_loss: 0.665| d_loss: 0.638| gp_loss: 0.055| r_loss: 0.064| p_loss: 0.091| v_loss: 0.023| per_loss: 0.326 | a_loss: 0.499
Train: Epoch [1819/3000], Step [150/158]| g_loss: 0.695| d_loss: 0.624| gp_loss: 0.056| r_loss: 0.066| p_loss: 0.091| v_loss: 0.022| per_loss: 0.320 | a_loss: 0.529
Train: Epoch [1820/3000], Step [30/158]| g_loss: 0.703| d_loss: 0.670| gp_loss: 0.151| r_loss: 0.062| p_loss: 0.092| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.539
Train: Epoch [1820/3000], Step [60/158]| g_loss: 0.744| d_loss: 0.512| gp_loss: 0.055| r_loss: 0.064| p_loss: 0.090| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.580
Train: Epoch [1820/3000], Step [90/158]| g_loss: 0.695| d_loss: 0.639| gp_loss: 0.054| r_loss: 0.063| p_loss: 0.089| v_loss: 0.023| per_loss: 0.303 | a_loss: 0.534
Train: Epoch [1820/3000], Step [120/158]| g_loss: 0.642| d_loss: 0.759| gp_loss: 0.056| r_loss: 0.062| p_loss: 0.091| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.479
Train: Epoch [1820/3000], Step [150/158]| g_loss: 0.679| d_loss: 0.542| gp_loss: 0.058| r_loss: 0.061| p_loss: 0.087| v_loss: 0.024| per_loss: 0.327 | a_loss: 0.518
Train: Epoch [1821/3000], Step [30/158]| g_loss: 0.662| d_loss: 0.773| gp_loss: 0.129| r_loss: 0.060| p_loss: 0.091| v_loss: 0.022| per_loss: 0.336 | a_loss: 0.501
Train: Epoch [1821/3000], Step [60/158]| g_loss: 0.706| d_loss: 0.613| gp_loss: 0.057| r_loss: 0.067| p_loss: 0.094| v_loss: 0.023| per_loss: 0.331 | a_loss: 0.535
Train: Epoch [1821/3000], Step [90/158]| g_loss: 0.642| d_loss: 0.687| gp_loss: 0.055| r_loss: 0.061| p_loss: 0.091| v_loss: 0.023| per_loss: 0.313 | a_loss: 0.480
Train: Epoch [1821/3000], Step [120/158]| g_loss: 0.717| d_loss: 0.570| gp_loss: 0.060| r_loss: 0.063| p_loss: 0.094| v_loss: 0.023| per_loss: 0.313 | a_loss: 0.552
Train: Epoch [1821/3000], Step [150/158]| g_loss: 0.717| d_loss: 0.575| gp_loss: 0.055| r_loss: 0.064| p_loss: 0.096| v_loss: 0.024| per_loss: 0.334 | a_loss: 0.547
Train: Epoch [1822/3000], Step [30/158]| g_loss: 0.717| d_loss: 0.725| gp_loss: 0.214| r_loss: 0.061| p_loss: 0.087| v_loss: 0.023| per_loss: 0.309 | a_loss: 0.558
Train: Epoch [1822/3000], Step [60/158]| g_loss: 0.683| d_loss: 0.634| gp_loss: 0.049| r_loss: 0.060| p_loss: 0.084| v_loss: 0.022| per_loss: 0.325 | a_loss: 0.525
Train: Epoch [1822/3000], Step [90/158]| g_loss: 0.701| d_loss: 0.625| gp_loss: 0.051| r_loss: 0.061| p_loss: 0.087| v_loss: 0.023| per_loss: 0.328 | a_loss: 0.540
Train: Epoch [1822/3000], Step [120/158]| g_loss: 0.710| d_loss: 0.579| gp_loss: 0.054| r_loss: 0.065| p_loss: 0.093| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.544
Train: Epoch [1822/3000], Step [150/158]| g_loss: 0.709| d_loss: 0.589| gp_loss: 0.055| r_loss: 0.061| p_loss: 0.087| v_loss: 0.023| per_loss: 0.326 | a_loss: 0.549
Train: Epoch [1823/3000], Step [30/158]| g_loss: 0.685| d_loss: 0.612| gp_loss: 0.123| r_loss: 0.065| p_loss: 0.091| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.518
Train: Epoch [1823/3000], Step [60/158]| g_loss: 0.739| d_loss: 0.599| gp_loss: 0.051| r_loss: 0.060| p_loss: 0.088| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.580
Train: Epoch [1823/3000], Step [90/158]| g_loss: 0.705| d_loss: 0.614| gp_loss: 0.053| r_loss: 0.059| p_loss: 0.083| v_loss: 0.022| per_loss: 0.324 | a_loss: 0.550
Train: Epoch [1823/3000], Step [120/158]| g_loss: 0.689| d_loss: 0.667| gp_loss: 0.055| r_loss: 0.062| p_loss: 0.085| v_loss: 0.023| per_loss: 0.307 | a_loss: 0.531
Train: Epoch [1823/3000], Step [150/158]| g_loss: 0.657| d_loss: 0.610| gp_loss: 0.058| r_loss: 0.063| p_loss: 0.088| v_loss: 0.023| per_loss: 0.333 | a_loss: 0.494
Train: Epoch [1824/3000], Step [30/158]| g_loss: 0.668| d_loss: 0.710| gp_loss: 0.156| r_loss: 0.065| p_loss: 0.094| v_loss: 0.022| per_loss: 0.327 | a_loss: 0.502
Train: Epoch [1824/3000], Step [60/158]| g_loss: 0.725| d_loss: 0.589| gp_loss: 0.053| r_loss: 0.065| p_loss: 0.089| v_loss: 0.024| per_loss: 0.325 | a_loss: 0.559
Train: Epoch [1824/3000], Step [90/158]| g_loss: 0.658| d_loss: 0.680| gp_loss: 0.050| r_loss: 0.063| p_loss: 0.093| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.495
Train: Epoch [1824/3000], Step [120/158]| g_loss: 0.714| d_loss: 0.561| gp_loss: 0.059| r_loss: 0.068| p_loss: 0.099| v_loss: 0.024| per_loss: 0.330 | a_loss: 0.540
Train: Epoch [1824/3000], Step [150/158]| g_loss: 0.689| d_loss: 0.634| gp_loss: 0.055| r_loss: 0.064| p_loss: 0.091| v_loss: 0.023| per_loss: 0.324 | a_loss: 0.524
Train: Epoch [1825/3000], Step [30/158]| g_loss: 0.684| d_loss: 0.783| gp_loss: 0.206| r_loss: 0.062| p_loss: 0.092| v_loss: 0.022| per_loss: 0.307 | a_loss: 0.524
Train: Epoch [1825/3000], Step [60/158]| g_loss: 0.654| d_loss: 0.662| gp_loss: 0.051| r_loss: 0.067| p_loss: 0.091| v_loss: 0.023| per_loss: 0.308 | a_loss: 0.488
Train: Epoch [1825/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.742| gp_loss: 0.050| r_loss: 0.064| p_loss: 0.092| v_loss: 0.022| per_loss: 0.326 | a_loss: 0.492
Train: Epoch [1825/3000], Step [120/158]| g_loss: 0.696| d_loss: 0.590| gp_loss: 0.053| r_loss: 0.064| p_loss: 0.091| v_loss: 0.023| per_loss: 0.346 | a_loss: 0.529
Train: Epoch [1825/3000], Step [150/158]| g_loss: 0.745| d_loss: 0.455| gp_loss: 0.061| r_loss: 0.062| p_loss: 0.089| v_loss: 0.024| per_loss: 0.328 | a_loss: 0.583
Train: Epoch [1826/3000], Step [30/158]| g_loss: 0.726| d_loss: 0.667| gp_loss: 0.106| r_loss: 0.063| p_loss: 0.090| v_loss: 0.024| per_loss: 0.318 | a_loss: 0.563
Train: Epoch [1826/3000], Step [60/158]| g_loss: 0.658| d_loss: 0.662| gp_loss: 0.052| r_loss: 0.061| p_loss: 0.088| v_loss: 0.023| per_loss: 0.324 | a_loss: 0.498
Train: Epoch [1826/3000], Step [90/158]| g_loss: 0.691| d_loss: 0.622| gp_loss: 0.052| r_loss: 0.063| p_loss: 0.085| v_loss: 0.022| per_loss: 0.318 | a_loss: 0.531
Train: Epoch [1826/3000], Step [120/158]| g_loss: 0.725| d_loss: 0.547| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.087| v_loss: 0.023| per_loss: 0.326 | a_loss: 0.564
Train: Epoch [1826/3000], Step [150/158]| g_loss: 0.672| d_loss: 0.635| gp_loss: 0.059| r_loss: 0.060| p_loss: 0.086| v_loss: 0.023| per_loss: 0.308 | a_loss: 0.516
Train: Epoch [1827/3000], Step [30/158]| g_loss: 0.719| d_loss: 0.670| gp_loss: 0.169| r_loss: 0.059| p_loss: 0.084| v_loss: 0.023| per_loss: 0.317 | a_loss: 0.563
Train: Epoch [1827/3000], Step [60/158]| g_loss: 0.653| d_loss: 0.630| gp_loss: 0.052| r_loss: 0.062| p_loss: 0.087| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.494
Train: Epoch [1827/3000], Step [90/158]| g_loss: 0.678| d_loss: 0.683| gp_loss: 0.053| r_loss: 0.061| p_loss: 0.088| v_loss: 0.023| per_loss: 0.339 | a_loss: 0.516
Train: Epoch [1827/3000], Step [120/158]| g_loss: 0.719| d_loss: 0.548| gp_loss: 0.056| r_loss: 0.063| p_loss: 0.086| v_loss: 0.024| per_loss: 0.311 | a_loss: 0.558
Train: Epoch [1827/3000], Step [150/158]| g_loss: 0.692| d_loss: 0.591| gp_loss: 0.056| r_loss: 0.064| p_loss: 0.090| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.527
Train: Epoch [1828/3000], Step [30/158]| g_loss: 0.709| d_loss: 0.797| gp_loss: 0.212| r_loss: 0.062| p_loss: 0.091| v_loss: 0.023| per_loss: 0.326 | a_loss: 0.546
Train: Epoch [1828/3000], Step [60/158]| g_loss: 0.644| d_loss: 0.616| gp_loss: 0.049| r_loss: 0.061| p_loss: 0.091| v_loss: 0.023| per_loss: 0.309 | a_loss: 0.484
Train: Epoch [1828/3000], Step [90/158]| g_loss: 0.734| d_loss: 0.541| gp_loss: 0.060| r_loss: 0.062| p_loss: 0.087| v_loss: 0.023| per_loss: 0.318 | a_loss: 0.574
Train: Epoch [1828/3000], Step [120/158]| g_loss: 0.648| d_loss: 0.656| gp_loss: 0.051| r_loss: 0.064| p_loss: 0.089| v_loss: 0.023| per_loss: 0.310 | a_loss: 0.486
Train: Epoch [1828/3000], Step [150/158]| g_loss: 0.727| d_loss: 0.573| gp_loss: 0.058| r_loss: 0.064| p_loss: 0.090| v_loss: 0.024| per_loss: 0.323 | a_loss: 0.562
Train: Epoch [1829/3000], Step [30/158]| g_loss: 0.690| d_loss: 0.694| gp_loss: 0.144| r_loss: 0.061| p_loss: 0.088| v_loss: 0.022| per_loss: 0.330 | a_loss: 0.530
Train: Epoch [1829/3000], Step [60/158]| g_loss: 0.745| d_loss: 0.571| gp_loss: 0.055| r_loss: 0.066| p_loss: 0.096| v_loss: 0.024| per_loss: 0.335 | a_loss: 0.573
Train: Epoch [1829/3000], Step [90/158]| g_loss: 0.690| d_loss: 0.666| gp_loss: 0.056| r_loss: 0.066| p_loss: 0.096| v_loss: 0.024| per_loss: 0.314 | a_loss: 0.522
Train: Epoch [1829/3000], Step [120/158]| g_loss: 0.684| d_loss: 0.641| gp_loss: 0.055| r_loss: 0.063| p_loss: 0.092| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.520
Train: Epoch [1829/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.575| gp_loss: 0.059| r_loss: 0.061| p_loss: 0.092| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.497
Train: Epoch [1830/3000], Step [30/158]| g_loss: 0.737| d_loss: 0.688| gp_loss: 0.137| r_loss: 0.064| p_loss: 0.094| v_loss: 0.024| per_loss: 0.337 | a_loss: 0.567
Train: Epoch [1830/3000], Step [60/158]| g_loss: 0.708| d_loss: 0.571| gp_loss: 0.058| r_loss: 0.062| p_loss: 0.089| v_loss: 0.023| per_loss: 0.313 | a_loss: 0.547
Train: Epoch [1830/3000], Step [90/158]| g_loss: 0.721| d_loss: 0.625| gp_loss: 0.055| r_loss: 0.060| p_loss: 0.087| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.563
Train: Epoch [1830/3000], Step [120/158]| g_loss: 0.688| d_loss: 0.607| gp_loss: 0.057| r_loss: 0.063| p_loss: 0.090| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.525
Train: Epoch [1830/3000], Step [150/158]| g_loss: 0.710| d_loss: 0.621| gp_loss: 0.056| r_loss: 0.068| p_loss: 0.106| v_loss: 0.024| per_loss: 0.330 | a_loss: 0.532
Train: Epoch [1831/3000], Step [30/158]| g_loss: 0.643| d_loss: 0.833| gp_loss: 0.131| r_loss: 0.065| p_loss: 0.099| v_loss: 0.023| per_loss: 0.328 | a_loss: 0.472
Train: Epoch [1831/3000], Step [60/158]| g_loss: 0.689| d_loss: 0.605| gp_loss: 0.058| r_loss: 0.067| p_loss: 0.100| v_loss: 0.023| per_loss: 0.319 | a_loss: 0.517
Train: Epoch [1831/3000], Step [90/158]| g_loss: 0.740| d_loss: 0.561| gp_loss: 0.056| r_loss: 0.062| p_loss: 0.090| v_loss: 0.023| per_loss: 0.335 | a_loss: 0.576
Train: Epoch [1831/3000], Step [120/158]| g_loss: 0.698| d_loss: 0.603| gp_loss: 0.054| r_loss: 0.064| p_loss: 0.088| v_loss: 0.023| per_loss: 0.321 | a_loss: 0.535
Train: Epoch [1831/3000], Step [150/158]| g_loss: 0.672| d_loss: 0.609| gp_loss: 0.059| r_loss: 0.064| p_loss: 0.093| v_loss: 0.023| per_loss: 0.308 | a_loss: 0.508
Train: Epoch [1832/3000], Step [30/158]| g_loss: 0.703| d_loss: 0.704| gp_loss: 0.143| r_loss: 0.066| p_loss: 0.094| v_loss: 0.023| per_loss: 0.327 | a_loss: 0.534
Train: Epoch [1832/3000], Step [60/158]| g_loss: 0.686| d_loss: 0.679| gp_loss: 0.053| r_loss: 0.064| p_loss: 0.090| v_loss: 0.023| per_loss: 0.318 | a_loss: 0.523
Train: Epoch [1832/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.611| gp_loss: 0.051| r_loss: 0.061| p_loss: 0.085| v_loss: 0.023| per_loss: 0.318 | a_loss: 0.499
Train: Epoch [1832/3000], Step [120/158]| g_loss: 0.722| d_loss: 0.588| gp_loss: 0.057| r_loss: 0.062| p_loss: 0.088| v_loss: 0.023| per_loss: 0.305 | a_loss: 0.562
Train: Epoch [1832/3000], Step [150/158]| g_loss: 0.721| d_loss: 0.534| gp_loss: 0.054| r_loss: 0.061| p_loss: 0.086| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.562
Train: Epoch [1833/3000], Step [30/158]| g_loss: 0.761| d_loss: 0.601| gp_loss: 0.112| r_loss: 0.059| p_loss: 0.085| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.606
Train: Epoch [1833/3000], Step [60/158]| g_loss: 0.713| d_loss: 0.568| gp_loss: 0.054| r_loss: 0.060| p_loss: 0.082| v_loss: 0.023| per_loss: 0.321 | a_loss: 0.556
Train: Epoch [1833/3000], Step [90/158]| g_loss: 0.694| d_loss: 0.609| gp_loss: 0.055| r_loss: 0.063| p_loss: 0.089| v_loss: 0.024| per_loss: 0.301 | a_loss: 0.533
Train: Epoch [1833/3000], Step [120/158]| g_loss: 0.676| d_loss: 0.656| gp_loss: 0.060| r_loss: 0.061| p_loss: 0.084| v_loss: 0.022| per_loss: 0.333 | a_loss: 0.518
Train: Epoch [1833/3000], Step [150/158]| g_loss: 0.654| d_loss: 0.629| gp_loss: 0.060| r_loss: 0.060| p_loss: 0.088| v_loss: 0.023| per_loss: 0.307 | a_loss: 0.497
Train: Epoch [1834/3000], Step [30/158]| g_loss: 0.643| d_loss: 0.721| gp_loss: 0.116| r_loss: 0.061| p_loss: 0.089| v_loss: 0.023| per_loss: 0.319 | a_loss: 0.482
Train: Epoch [1834/3000], Step [60/158]| g_loss: 0.711| d_loss: 0.642| gp_loss: 0.060| r_loss: 0.064| p_loss: 0.095| v_loss: 0.024| per_loss: 0.312 | a_loss: 0.545
Train: Epoch [1834/3000], Step [90/158]| g_loss: 0.711| d_loss: 0.541| gp_loss: 0.064| r_loss: 0.063| p_loss: 0.091| v_loss: 0.023| per_loss: 0.327 | a_loss: 0.547
Train: Epoch [1834/3000], Step [120/158]| g_loss: 0.689| d_loss: 0.655| gp_loss: 0.059| r_loss: 0.063| p_loss: 0.094| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.524
Train: Epoch [1834/3000], Step [150/158]| g_loss: 0.724| d_loss: 0.575| gp_loss: 0.063| r_loss: 0.061| p_loss: 0.085| v_loss: 0.023| per_loss: 0.316 | a_loss: 0.566
Train: Epoch [1835/3000], Step [30/158]| g_loss: 0.673| d_loss: 0.712| gp_loss: 0.130| r_loss: 0.066| p_loss: 0.094| v_loss: 0.023| per_loss: 0.340 | a_loss: 0.504
Train: Epoch [1835/3000], Step [60/158]| g_loss: 0.680| d_loss: 0.579| gp_loss: 0.058| r_loss: 0.062| p_loss: 0.091| v_loss: 0.023| per_loss: 0.313 | a_loss: 0.518
Train: Epoch [1835/3000], Step [90/158]| g_loss: 0.708| d_loss: 0.618| gp_loss: 0.061| r_loss: 0.061| p_loss: 0.090| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.548
Train: Epoch [1835/3000], Step [120/158]| g_loss: 0.679| d_loss: 0.620| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.088| v_loss: 0.024| per_loss: 0.318 | a_loss: 0.519
Train: Epoch [1835/3000], Step [150/158]| g_loss: 0.734| d_loss: 0.531| gp_loss: 0.065| r_loss: 0.065| p_loss: 0.090| v_loss: 0.024| per_loss: 0.311 | a_loss: 0.569
Train: Epoch [1836/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.847| gp_loss: 0.169| r_loss: 0.068| p_loss: 0.098| v_loss: 0.024| per_loss: 0.308 | a_loss: 0.491
Train: Epoch [1836/3000], Step [60/158]| g_loss: 0.720| d_loss: 0.589| gp_loss: 0.062| r_loss: 0.066| p_loss: 0.095| v_loss: 0.024| per_loss: 0.315 | a_loss: 0.551
Train: Epoch [1836/3000], Step [90/158]| g_loss: 0.723| d_loss: 0.566| gp_loss: 0.058| r_loss: 0.064| p_loss: 0.091| v_loss: 0.024| per_loss: 0.317 | a_loss: 0.558
Train: Epoch [1836/3000], Step [120/158]| g_loss: 0.654| d_loss: 0.592| gp_loss: 0.059| r_loss: 0.060| p_loss: 0.086| v_loss: 0.022| per_loss: 0.333 | a_loss: 0.495
Train: Epoch [1836/3000], Step [150/158]| g_loss: 0.711| d_loss: 0.604| gp_loss: 0.058| r_loss: 0.062| p_loss: 0.088| v_loss: 0.024| per_loss: 0.327 | a_loss: 0.549
Train: Epoch [1837/3000], Step [30/158]| g_loss: 0.692| d_loss: 0.724| gp_loss: 0.127| r_loss: 0.063| p_loss: 0.091| v_loss: 0.024| per_loss: 0.332 | a_loss: 0.525
Train: Epoch [1837/3000], Step [60/158]| g_loss: 0.686| d_loss: 0.584| gp_loss: 0.059| r_loss: 0.060| p_loss: 0.087| v_loss: 0.023| per_loss: 0.304 | a_loss: 0.529
Train: Epoch [1837/3000], Step [90/158]| g_loss: 0.679| d_loss: 0.563| gp_loss: 0.059| r_loss: 0.062| p_loss: 0.083| v_loss: 0.023| per_loss: 0.330 | a_loss: 0.520
Train: Epoch [1837/3000], Step [120/158]| g_loss: 0.699| d_loss: 0.642| gp_loss: 0.060| r_loss: 0.063| p_loss: 0.089| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.537
Train: Epoch [1837/3000], Step [150/158]| g_loss: 0.717| d_loss: 0.530| gp_loss: 0.059| r_loss: 0.062| p_loss: 0.087| v_loss: 0.023| per_loss: 0.306 | a_loss: 0.559
Train: Epoch [1838/3000], Step [30/158]| g_loss: 0.629| d_loss: 0.887| gp_loss: 0.199| r_loss: 0.059| p_loss: 0.086| v_loss: 0.023| per_loss: 0.312 | a_loss: 0.473
Train: Epoch [1838/3000], Step [60/158]| g_loss: 0.677| d_loss: 0.554| gp_loss: 0.057| r_loss: 0.060| p_loss: 0.087| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.518
Train: Epoch [1838/3000], Step [90/158]| g_loss: 0.708| d_loss: 0.565| gp_loss: 0.058| r_loss: 0.061| p_loss: 0.086| v_loss: 0.023| per_loss: 0.313 | a_loss: 0.550
Train: Epoch [1838/3000], Step [120/158]| g_loss: 0.713| d_loss: 0.593| gp_loss: 0.059| r_loss: 0.067| p_loss: 0.092| v_loss: 0.024| per_loss: 0.320 | a_loss: 0.544
Train: Epoch [1838/3000], Step [150/158]| g_loss: 0.720| d_loss: 0.611| gp_loss: 0.061| r_loss: 0.062| p_loss: 0.092| v_loss: 0.023| per_loss: 0.318 | a_loss: 0.557
Train: Epoch [1839/3000], Step [30/158]| g_loss: 0.692| d_loss: 0.758| gp_loss: 0.211| r_loss: 0.058| p_loss: 0.084| v_loss: 0.023| per_loss: 0.317 | a_loss: 0.537
Train: Epoch [1839/3000], Step [60/158]| g_loss: 0.688| d_loss: 0.591| gp_loss: 0.053| r_loss: 0.060| p_loss: 0.082| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.534
Train: Epoch [1839/3000], Step [90/158]| g_loss: 0.706| d_loss: 0.517| gp_loss: 0.054| r_loss: 0.060| p_loss: 0.083| v_loss: 0.023| per_loss: 0.327 | a_loss: 0.549
Train: Epoch [1839/3000], Step [120/158]| g_loss: 0.752| d_loss: 0.551| gp_loss: 0.054| r_loss: 0.061| p_loss: 0.088| v_loss: 0.023| per_loss: 0.316 | a_loss: 0.592
Train: Epoch [1839/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.708| gp_loss: 0.053| r_loss: 0.062| p_loss: 0.088| v_loss: 0.023| per_loss: 0.335 | a_loss: 0.496
Train: Epoch [1840/3000], Step [30/158]| g_loss: 0.622| d_loss: 0.758| gp_loss: 0.127| r_loss: 0.060| p_loss: 0.086| v_loss: 0.022| per_loss: 0.337 | a_loss: 0.463
Train: Epoch [1840/3000], Step [60/158]| g_loss: 0.679| d_loss: 0.649| gp_loss: 0.058| r_loss: 0.060| p_loss: 0.085| v_loss: 0.023| per_loss: 0.310 | a_loss: 0.523
Train: Epoch [1840/3000], Step [90/158]| g_loss: 0.689| d_loss: 0.609| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.092| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.527
Train: Epoch [1840/3000], Step [120/158]| g_loss: 0.718| d_loss: 0.648| gp_loss: 0.057| r_loss: 0.066| p_loss: 0.091| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.550
Train: Epoch [1840/3000], Step [150/158]| g_loss: 0.709| d_loss: 0.559| gp_loss: 0.060| r_loss: 0.063| p_loss: 0.090| v_loss: 0.023| per_loss: 0.316 | a_loss: 0.545
Train: Epoch [1841/3000], Step [30/158]| g_loss: 0.704| d_loss: 0.666| gp_loss: 0.142| r_loss: 0.062| p_loss: 0.092| v_loss: 0.024| per_loss: 0.310 | a_loss: 0.542
Train: Epoch [1841/3000], Step [60/158]| g_loss: 0.727| d_loss: 0.576| gp_loss: 0.052| r_loss: 0.062| p_loss: 0.089| v_loss: 0.023| per_loss: 0.313 | a_loss: 0.566
Train: Epoch [1841/3000], Step [90/158]| g_loss: 0.685| d_loss: 0.595| gp_loss: 0.054| r_loss: 0.060| p_loss: 0.085| v_loss: 0.022| per_loss: 0.324 | a_loss: 0.528
Train: Epoch [1841/3000], Step [120/158]| g_loss: 0.638| d_loss: 0.675| gp_loss: 0.054| r_loss: 0.058| p_loss: 0.082| v_loss: 0.022| per_loss: 0.304 | a_loss: 0.487
Train: Epoch [1841/3000], Step [150/158]| g_loss: 0.718| d_loss: 0.603| gp_loss: 0.059| r_loss: 0.061| p_loss: 0.087| v_loss: 0.023| per_loss: 0.333 | a_loss: 0.557
Train: Epoch [1842/3000], Step [30/158]| g_loss: 0.670| d_loss: 0.694| gp_loss: 0.135| r_loss: 0.061| p_loss: 0.091| v_loss: 0.023| per_loss: 0.326 | a_loss: 0.508
Train: Epoch [1842/3000], Step [60/158]| g_loss: 0.694| d_loss: 0.637| gp_loss: 0.055| r_loss: 0.062| p_loss: 0.092| v_loss: 0.023| per_loss: 0.321 | a_loss: 0.530
Train: Epoch [1842/3000], Step [90/158]| g_loss: 0.672| d_loss: 0.656| gp_loss: 0.054| r_loss: 0.062| p_loss: 0.093| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.508
Train: Epoch [1842/3000], Step [120/158]| g_loss: 0.716| d_loss: 0.562| gp_loss: 0.059| r_loss: 0.062| p_loss: 0.085| v_loss: 0.022| per_loss: 0.307 | a_loss: 0.559
Train: Epoch [1842/3000], Step [150/158]| g_loss: 0.671| d_loss: 0.562| gp_loss: 0.062| r_loss: 0.060| p_loss: 0.089| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.512
Train: Epoch [1843/3000], Step [30/158]| g_loss: 0.719| d_loss: 0.688| gp_loss: 0.154| r_loss: 0.061| p_loss: 0.088| v_loss: 0.023| per_loss: 0.303 | a_loss: 0.561
Train: Epoch [1843/3000], Step [60/158]| g_loss: 0.696| d_loss: 0.590| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.087| v_loss: 0.023| per_loss: 0.326 | a_loss: 0.536
Train: Epoch [1843/3000], Step [90/158]| g_loss: 0.693| d_loss: 0.611| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.083| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.540
Train: Epoch [1843/3000], Step [120/158]| g_loss: 0.638| d_loss: 0.694| gp_loss: 0.056| r_loss: 0.062| p_loss: 0.086| v_loss: 0.023| per_loss: 0.317 | a_loss: 0.479
Train: Epoch [1843/3000], Step [150/158]| g_loss: 0.720| d_loss: 0.600| gp_loss: 0.059| r_loss: 0.061| p_loss: 0.083| v_loss: 0.023| per_loss: 0.319 | a_loss: 0.563
Train: Epoch [1844/3000], Step [30/158]| g_loss: 0.706| d_loss: 0.669| gp_loss: 0.174| r_loss: 0.059| p_loss: 0.087| v_loss: 0.022| per_loss: 0.331 | a_loss: 0.547
Train: Epoch [1844/3000], Step [60/158]| g_loss: 0.657| d_loss: 0.656| gp_loss: 0.054| r_loss: 0.059| p_loss: 0.085| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.502
Train: Epoch [1844/3000], Step [90/158]| g_loss: 0.702| d_loss: 0.650| gp_loss: 0.059| r_loss: 0.064| p_loss: 0.087| v_loss: 0.024| per_loss: 0.314 | a_loss: 0.540
Train: Epoch [1844/3000], Step [120/158]| g_loss: 0.659| d_loss: 0.679| gp_loss: 0.054| r_loss: 0.066| p_loss: 0.099| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.488
Train: Epoch [1844/3000], Step [150/158]| g_loss: 0.733| d_loss: 0.563| gp_loss: 0.058| r_loss: 0.068| p_loss: 0.096| v_loss: 0.023| per_loss: 0.327 | a_loss: 0.561
Train: Epoch [1845/3000], Step [30/158]| g_loss: 0.711| d_loss: 0.671| gp_loss: 0.140| r_loss: 0.065| p_loss: 0.092| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.545
Train: Epoch [1845/3000], Step [60/158]| g_loss: 0.718| d_loss: 0.571| gp_loss: 0.056| r_loss: 0.067| p_loss: 0.092| v_loss: 0.023| per_loss: 0.335 | a_loss: 0.548
Train: Epoch [1845/3000], Step [90/158]| g_loss: 0.742| d_loss: 0.613| gp_loss: 0.055| r_loss: 0.077| p_loss: 0.105| v_loss: 0.024| per_loss: 0.327 | a_loss: 0.556
Train: Epoch [1845/3000], Step [120/158]| g_loss: 0.707| d_loss: 0.598| gp_loss: 0.056| r_loss: 0.074| p_loss: 0.105| v_loss: 0.023| per_loss: 0.311 | a_loss: 0.526
Train: Epoch [1845/3000], Step [150/158]| g_loss: 0.693| d_loss: 0.612| gp_loss: 0.061| r_loss: 0.064| p_loss: 0.097| v_loss: 0.023| per_loss: 0.326 | a_loss: 0.525
Train: Epoch [1846/3000], Step [30/158]| g_loss: 0.647| d_loss: 0.773| gp_loss: 0.111| r_loss: 0.066| p_loss: 0.094| v_loss: 0.022| per_loss: 0.320 | a_loss: 0.480
Train: Epoch [1846/3000], Step [60/158]| g_loss: 0.656| d_loss: 0.565| gp_loss: 0.058| r_loss: 0.062| p_loss: 0.087| v_loss: 0.022| per_loss: 0.320 | a_loss: 0.496
Train: Epoch [1846/3000], Step [90/158]| g_loss: 0.711| d_loss: 0.642| gp_loss: 0.058| r_loss: 0.064| p_loss: 0.092| v_loss: 0.023| per_loss: 0.314 | a_loss: 0.546
Train: Epoch [1846/3000], Step [120/158]| g_loss: 0.653| d_loss: 0.602| gp_loss: 0.059| r_loss: 0.059| p_loss: 0.085| v_loss: 0.023| per_loss: 0.336 | a_loss: 0.494
Train: Epoch [1846/3000], Step [150/158]| g_loss: 0.707| d_loss: 0.618| gp_loss: 0.058| r_loss: 0.062| p_loss: 0.090| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.546
Train: Epoch [1847/3000], Step [30/158]| g_loss: 0.713| d_loss: 0.680| gp_loss: 0.182| r_loss: 0.057| p_loss: 0.081| v_loss: 0.022| per_loss: 0.302 | a_loss: 0.564
Train: Epoch [1847/3000], Step [60/158]| g_loss: 0.665| d_loss: 0.687| gp_loss: 0.053| r_loss: 0.061| p_loss: 0.086| v_loss: 0.023| per_loss: 0.311 | a_loss: 0.506
Train: Epoch [1847/3000], Step [90/158]| g_loss: 0.669| d_loss: 0.597| gp_loss: 0.057| r_loss: 0.062| p_loss: 0.088| v_loss: 0.023| per_loss: 0.330 | a_loss: 0.507
Train: Epoch [1847/3000], Step [120/158]| g_loss: 0.712| d_loss: 0.616| gp_loss: 0.057| r_loss: 0.062| p_loss: 0.089| v_loss: 0.022| per_loss: 0.322 | a_loss: 0.551
Train: Epoch [1847/3000], Step [150/158]| g_loss: 0.692| d_loss: 0.588| gp_loss: 0.057| r_loss: 0.063| p_loss: 0.089| v_loss: 0.023| per_loss: 0.343 | a_loss: 0.527
Train: Epoch [1848/3000], Step [30/158]| g_loss: 0.700| d_loss: 0.801| gp_loss: 0.172| r_loss: 0.062| p_loss: 0.088| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.538
Train: Epoch [1848/3000], Step [60/158]| g_loss: 0.683| d_loss: 0.545| gp_loss: 0.054| r_loss: 0.062| p_loss: 0.086| v_loss: 0.023| per_loss: 0.315 | a_loss: 0.523
Train: Epoch [1848/3000], Step [90/158]| g_loss: 0.682| d_loss: 0.584| gp_loss: 0.052| r_loss: 0.060| p_loss: 0.086| v_loss: 0.023| per_loss: 0.310 | a_loss: 0.525
Train: Epoch [1848/3000], Step [120/158]| g_loss: 0.706| d_loss: 0.629| gp_loss: 0.054| r_loss: 0.059| p_loss: 0.082| v_loss: 0.022| per_loss: 0.325 | a_loss: 0.552
Train: Epoch [1848/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.599| gp_loss: 0.054| r_loss: 0.059| p_loss: 0.087| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.503
Train: Epoch [1849/3000], Step [30/158]| g_loss: 0.727| d_loss: 0.684| gp_loss: 0.137| r_loss: 0.061| p_loss: 0.090| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.566
Train: Epoch [1849/3000], Step [60/158]| g_loss: 0.647| d_loss: 0.632| gp_loss: 0.055| r_loss: 0.058| p_loss: 0.082| v_loss: 0.021| per_loss: 0.318 | a_loss: 0.494
Train: Epoch [1849/3000], Step [90/158]| g_loss: 0.674| d_loss: 0.632| gp_loss: 0.055| r_loss: 0.063| p_loss: 0.088| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.511
Train: Epoch [1849/3000], Step [120/158]| g_loss: 0.773| d_loss: 0.496| gp_loss: 0.058| r_loss: 0.063| p_loss: 0.091| v_loss: 0.023| per_loss: 0.309 | a_loss: 0.610
Train: Epoch [1849/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.678| gp_loss: 0.057| r_loss: 0.059| p_loss: 0.088| v_loss: 0.023| per_loss: 0.333 | a_loss: 0.515
Train: Epoch [1850/3000], Step [30/158]| g_loss: 0.682| d_loss: 0.677| gp_loss: 0.127| r_loss: 0.059| p_loss: 0.086| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.526
Train: Epoch [1850/3000], Step [60/158]| g_loss: 0.670| d_loss: 0.620| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.086| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.511
Train: Epoch [1850/3000], Step [90/158]| g_loss: 0.665| d_loss: 0.693| gp_loss: 0.058| r_loss: 0.061| p_loss: 0.089| v_loss: 0.023| per_loss: 0.305 | a_loss: 0.507
Train: Epoch [1850/3000], Step [120/158]| g_loss: 0.674| d_loss: 0.650| gp_loss: 0.055| r_loss: 0.065| p_loss: 0.094| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.507
Train: Epoch [1850/3000], Step [150/158]| g_loss: 0.744| d_loss: 0.497| gp_loss: 0.060| r_loss: 0.062| p_loss: 0.087| v_loss: 0.023| per_loss: 0.338 | a_loss: 0.583
Test: Epoch [1850/3000]| g_loss: 0.625| r_loss: 0.371| p_loss: 0.296| v_loss: 0.022
Train: Epoch [1851/3000], Step [30/158]| g_loss: 0.708| d_loss: 0.647| gp_loss: 0.053| r_loss: 0.060| p_loss: 0.082| v_loss: 0.023| per_loss: 0.335 | a_loss: 0.551
Train: Epoch [1851/3000], Step [60/158]| g_loss: 0.662| d_loss: 0.593| gp_loss: 0.053| r_loss: 0.059| p_loss: 0.087| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.507
Train: Epoch [1851/3000], Step [90/158]| g_loss: 0.671| d_loss: 0.657| gp_loss: 0.052| r_loss: 0.062| p_loss: 0.085| v_loss: 0.023| per_loss: 0.299 | a_loss: 0.513
Train: Epoch [1851/3000], Step [120/158]| g_loss: 0.735| d_loss: 0.569| gp_loss: 0.058| r_loss: 0.058| p_loss: 0.082| v_loss: 0.021| per_loss: 0.320 | a_loss: 0.583
Train: Epoch [1851/3000], Step [150/158]| g_loss: 0.684| d_loss: 0.579| gp_loss: 0.058| r_loss: 0.063| p_loss: 0.090| v_loss: 0.024| per_loss: 0.316 | a_loss: 0.521
Train: Epoch [1852/3000], Step [30/158]| g_loss: 0.690| d_loss: 0.720| gp_loss: 0.135| r_loss: 0.062| p_loss: 0.089| v_loss: 0.022| per_loss: 0.302 | a_loss: 0.532
Train: Epoch [1852/3000], Step [60/158]| g_loss: 0.665| d_loss: 0.743| gp_loss: 0.054| r_loss: 0.062| p_loss: 0.088| v_loss: 0.023| per_loss: 0.334 | a_loss: 0.503
Train: Epoch [1852/3000], Step [90/158]| g_loss: 0.618| d_loss: 0.629| gp_loss: 0.058| r_loss: 0.062| p_loss: 0.090| v_loss: 0.024| per_loss: 0.322 | a_loss: 0.455
Train: Epoch [1852/3000], Step [120/158]| g_loss: 0.698| d_loss: 0.488| gp_loss: 0.059| r_loss: 0.063| p_loss: 0.087| v_loss: 0.023| per_loss: 0.321 | a_loss: 0.537
Train: Epoch [1852/3000], Step [150/158]| g_loss: 0.782| d_loss: 0.520| gp_loss: 0.058| r_loss: 0.059| p_loss: 0.085| v_loss: 0.023| per_loss: 0.334 | a_loss: 0.624
Train: Epoch [1853/3000], Step [30/158]| g_loss: 0.715| d_loss: 0.735| gp_loss: 0.148| r_loss: 0.063| p_loss: 0.093| v_loss: 0.024| per_loss: 0.313 | a_loss: 0.550
Train: Epoch [1853/3000], Step [60/158]| g_loss: 0.721| d_loss: 0.532| gp_loss: 0.058| r_loss: 0.060| p_loss: 0.085| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.562
Train: Epoch [1853/3000], Step [90/158]| g_loss: 0.746| d_loss: 0.515| gp_loss: 0.055| r_loss: 0.067| p_loss: 0.098| v_loss: 0.023| per_loss: 0.318 | a_loss: 0.575
Train: Epoch [1853/3000], Step [120/158]| g_loss: 0.723| d_loss: 0.629| gp_loss: 0.057| r_loss: 0.063| p_loss: 0.089| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.562
Train: Epoch [1853/3000], Step [150/158]| g_loss: 0.641| d_loss: 0.674| gp_loss: 0.057| r_loss: 0.060| p_loss: 0.084| v_loss: 0.021| per_loss: 0.317 | a_loss: 0.487
Train: Epoch [1854/3000], Step [30/158]| g_loss: 0.596| d_loss: 0.805| gp_loss: 0.090| r_loss: 0.061| p_loss: 0.091| v_loss: 0.022| per_loss: 0.326 | a_loss: 0.435
Train: Epoch [1854/3000], Step [60/158]| g_loss: 0.730| d_loss: 0.588| gp_loss: 0.059| r_loss: 0.062| p_loss: 0.093| v_loss: 0.024| per_loss: 0.342 | a_loss: 0.564
Train: Epoch [1854/3000], Step [90/158]| g_loss: 0.701| d_loss: 0.557| gp_loss: 0.064| r_loss: 0.060| p_loss: 0.089| v_loss: 0.022| per_loss: 0.337 | a_loss: 0.540
Train: Epoch [1854/3000], Step [120/158]| g_loss: 0.718| d_loss: 0.617| gp_loss: 0.058| r_loss: 0.062| p_loss: 0.087| v_loss: 0.022| per_loss: 0.324 | a_loss: 0.558
Train: Epoch [1854/3000], Step [150/158]| g_loss: 0.679| d_loss: 0.635| gp_loss: 0.062| r_loss: 0.063| p_loss: 0.088| v_loss: 0.023| per_loss: 0.299 | a_loss: 0.519
Train: Epoch [1855/3000], Step [30/158]| g_loss: 0.706| d_loss: 0.657| gp_loss: 0.172| r_loss: 0.063| p_loss: 0.092| v_loss: 0.024| per_loss: 0.321 | a_loss: 0.541
Train: Epoch [1855/3000], Step [60/158]| g_loss: 0.759| d_loss: 0.566| gp_loss: 0.056| r_loss: 0.062| p_loss: 0.087| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.599
Train: Epoch [1855/3000], Step [90/158]| g_loss: 0.665| d_loss: 0.634| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.086| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.505
Train: Epoch [1855/3000], Step [120/158]| g_loss: 0.647| d_loss: 0.730| gp_loss: 0.057| r_loss: 0.061| p_loss: 0.085| v_loss: 0.022| per_loss: 0.334 | a_loss: 0.489
Train: Epoch [1855/3000], Step [150/158]| g_loss: 0.639| d_loss: 0.609| gp_loss: 0.061| r_loss: 0.059| p_loss: 0.089| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.483
Train: Epoch [1856/3000], Step [30/158]| g_loss: 0.744| d_loss: 0.633| gp_loss: 0.175| r_loss: 0.062| p_loss: 0.089| v_loss: 0.023| per_loss: 0.331 | a_loss: 0.582
Train: Epoch [1856/3000], Step [60/158]| g_loss: 0.670| d_loss: 0.665| gp_loss: 0.053| r_loss: 0.061| p_loss: 0.089| v_loss: 0.022| per_loss: 0.326 | a_loss: 0.510
Train: Epoch [1856/3000], Step [90/158]| g_loss: 0.667| d_loss: 0.628| gp_loss: 0.057| r_loss: 0.062| p_loss: 0.089| v_loss: 0.024| per_loss: 0.319 | a_loss: 0.504
Train: Epoch [1856/3000], Step [120/158]| g_loss: 0.748| d_loss: 0.584| gp_loss: 0.060| r_loss: 0.063| p_loss: 0.089| v_loss: 0.023| per_loss: 0.332 | a_loss: 0.584
Train: Epoch [1856/3000], Step [150/158]| g_loss: 0.725| d_loss: 0.604| gp_loss: 0.057| r_loss: 0.063| p_loss: 0.087| v_loss: 0.022| per_loss: 0.322 | a_loss: 0.564
Train: Epoch [1857/3000], Step [30/158]| g_loss: 0.674| d_loss: 0.742| gp_loss: 0.167| r_loss: 0.062| p_loss: 0.088| v_loss: 0.023| per_loss: 0.316 | a_loss: 0.514
Train: Epoch [1857/3000], Step [60/158]| g_loss: 0.647| d_loss: 0.699| gp_loss: 0.050| r_loss: 0.061| p_loss: 0.092| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.485
Train: Epoch [1857/3000], Step [90/158]| g_loss: 0.676| d_loss: 0.565| gp_loss: 0.057| r_loss: 0.060| p_loss: 0.088| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.517
Train: Epoch [1857/3000], Step [120/158]| g_loss: 0.668| d_loss: 0.651| gp_loss: 0.058| r_loss: 0.064| p_loss: 0.093| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.503
Train: Epoch [1857/3000], Step [150/158]| g_loss: 0.741| d_loss: 0.547| gp_loss: 0.059| r_loss: 0.062| p_loss: 0.088| v_loss: 0.023| per_loss: 0.331 | a_loss: 0.578
Train: Epoch [1858/3000], Step [30/158]| g_loss: 0.714| d_loss: 0.680| gp_loss: 0.138| r_loss: 0.063| p_loss: 0.092| v_loss: 0.024| per_loss: 0.319 | a_loss: 0.548
Train: Epoch [1858/3000], Step [60/158]| g_loss: 0.687| d_loss: 0.581| gp_loss: 0.055| r_loss: 0.061| p_loss: 0.083| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.531
Train: Epoch [1858/3000], Step [90/158]| g_loss: 0.707| d_loss: 0.640| gp_loss: 0.055| r_loss: 0.061| p_loss: 0.088| v_loss: 0.023| per_loss: 0.333 | a_loss: 0.546
Train: Epoch [1858/3000], Step [120/158]| g_loss: 0.698| d_loss: 0.505| gp_loss: 0.062| r_loss: 0.060| p_loss: 0.089| v_loss: 0.022| per_loss: 0.329 | a_loss: 0.538
Train: Epoch [1858/3000], Step [150/158]| g_loss: 0.681| d_loss: 0.726| gp_loss: 0.054| r_loss: 0.061| p_loss: 0.088| v_loss: 0.022| per_loss: 0.330 | a_loss: 0.520
Train: Epoch [1859/3000], Step [30/158]| g_loss: 0.716| d_loss: 0.675| gp_loss: 0.165| r_loss: 0.063| p_loss: 0.088| v_loss: 0.023| per_loss: 0.324 | a_loss: 0.554
Train: Epoch [1859/3000], Step [60/158]| g_loss: 0.709| d_loss: 0.559| gp_loss: 0.053| r_loss: 0.059| p_loss: 0.085| v_loss: 0.022| per_loss: 0.336 | a_loss: 0.552
Train: Epoch [1859/3000], Step [90/158]| g_loss: 0.673| d_loss: 0.656| gp_loss: 0.053| r_loss: 0.061| p_loss: 0.088| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.514
Train: Epoch [1859/3000], Step [120/158]| g_loss: 0.679| d_loss: 0.625| gp_loss: 0.056| r_loss: 0.063| p_loss: 0.094| v_loss: 0.023| per_loss: 0.328 | a_loss: 0.513
Train: Epoch [1859/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.670| gp_loss: 0.060| r_loss: 0.061| p_loss: 0.088| v_loss: 0.022| per_loss: 0.322 | a_loss: 0.502
Train: Epoch [1860/3000], Step [30/158]| g_loss: 0.716| d_loss: 0.650| gp_loss: 0.126| r_loss: 0.061| p_loss: 0.087| v_loss: 0.024| per_loss: 0.323 | a_loss: 0.556
Train: Epoch [1860/3000], Step [60/158]| g_loss: 0.682| d_loss: 0.623| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.087| v_loss: 0.023| per_loss: 0.333 | a_loss: 0.522
Train: Epoch [1860/3000], Step [90/158]| g_loss: 0.695| d_loss: 0.659| gp_loss: 0.057| r_loss: 0.061| p_loss: 0.086| v_loss: 0.023| per_loss: 0.317 | a_loss: 0.536
Train: Epoch [1860/3000], Step [120/158]| g_loss: 0.639| d_loss: 0.671| gp_loss: 0.056| r_loss: 0.062| p_loss: 0.090| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.476
Train: Epoch [1860/3000], Step [150/158]| g_loss: 0.708| d_loss: 0.556| gp_loss: 0.062| r_loss: 0.062| p_loss: 0.092| v_loss: 0.023| per_loss: 0.313 | a_loss: 0.545
Train: Epoch [1861/3000], Step [30/158]| g_loss: 0.709| d_loss: 0.706| gp_loss: 0.189| r_loss: 0.062| p_loss: 0.089| v_loss: 0.023| per_loss: 0.304 | a_loss: 0.549
Train: Epoch [1861/3000], Step [60/158]| g_loss: 0.704| d_loss: 0.616| gp_loss: 0.049| r_loss: 0.060| p_loss: 0.083| v_loss: 0.023| per_loss: 0.327 | a_loss: 0.546
Train: Epoch [1861/3000], Step [90/158]| g_loss: 0.640| d_loss: 0.694| gp_loss: 0.052| r_loss: 0.060| p_loss: 0.085| v_loss: 0.023| per_loss: 0.313 | a_loss: 0.483
Train: Epoch [1861/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.539| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.082| v_loss: 0.022| per_loss: 0.324 | a_loss: 0.522
Train: Epoch [1861/3000], Step [150/158]| g_loss: 0.720| d_loss: 0.575| gp_loss: 0.059| r_loss: 0.063| p_loss: 0.086| v_loss: 0.023| per_loss: 0.330 | a_loss: 0.559
Train: Epoch [1862/3000], Step [30/158]| g_loss: 0.727| d_loss: 0.705| gp_loss: 0.171| r_loss: 0.064| p_loss: 0.089| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.565
Train: Epoch [1862/3000], Step [60/158]| g_loss: 0.711| d_loss: 0.596| gp_loss: 0.051| r_loss: 0.064| p_loss: 0.091| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.547
Train: Epoch [1862/3000], Step [90/158]| g_loss: 0.648| d_loss: 0.645| gp_loss: 0.051| r_loss: 0.063| p_loss: 0.085| v_loss: 0.022| per_loss: 0.304 | a_loss: 0.489
Train: Epoch [1862/3000], Step [120/158]| g_loss: 0.662| d_loss: 0.646| gp_loss: 0.052| r_loss: 0.063| p_loss: 0.092| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.499
Train: Epoch [1862/3000], Step [150/158]| g_loss: 0.702| d_loss: 0.532| gp_loss: 0.058| r_loss: 0.060| p_loss: 0.086| v_loss: 0.023| per_loss: 0.334 | a_loss: 0.544
Train: Epoch [1863/3000], Step [30/158]| g_loss: 0.704| d_loss: 0.741| gp_loss: 0.168| r_loss: 0.062| p_loss: 0.088| v_loss: 0.023| per_loss: 0.321 | a_loss: 0.543
Train: Epoch [1863/3000], Step [60/158]| g_loss: 0.672| d_loss: 0.670| gp_loss: 0.050| r_loss: 0.062| p_loss: 0.087| v_loss: 0.023| per_loss: 0.331 | a_loss: 0.510
Train: Epoch [1863/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.675| gp_loss: 0.056| r_loss: 0.062| p_loss: 0.088| v_loss: 0.023| per_loss: 0.317 | a_loss: 0.497
Train: Epoch [1863/3000], Step [120/158]| g_loss: 0.714| d_loss: 0.536| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.082| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.560
Train: Epoch [1863/3000], Step [150/158]| g_loss: 0.712| d_loss: 0.653| gp_loss: 0.055| r_loss: 0.061| p_loss: 0.090| v_loss: 0.022| per_loss: 0.331 | a_loss: 0.551
Train: Epoch [1864/3000], Step [30/158]| g_loss: 0.678| d_loss: 0.802| gp_loss: 0.174| r_loss: 0.062| p_loss: 0.096| v_loss: 0.023| per_loss: 0.335 | a_loss: 0.510
Train: Epoch [1864/3000], Step [60/158]| g_loss: 0.674| d_loss: 0.559| gp_loss: 0.052| r_loss: 0.062| p_loss: 0.092| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.511
Train: Epoch [1864/3000], Step [90/158]| g_loss: 0.766| d_loss: 0.567| gp_loss: 0.055| r_loss: 0.062| p_loss: 0.084| v_loss: 0.023| per_loss: 0.318 | a_loss: 0.607
Train: Epoch [1864/3000], Step [120/158]| g_loss: 0.680| d_loss: 0.620| gp_loss: 0.054| r_loss: 0.061| p_loss: 0.086| v_loss: 0.023| per_loss: 0.309 | a_loss: 0.521
Train: Epoch [1864/3000], Step [150/158]| g_loss: 0.688| d_loss: 0.579| gp_loss: 0.054| r_loss: 0.059| p_loss: 0.083| v_loss: 0.023| per_loss: 0.326 | a_loss: 0.531
Train: Epoch [1865/3000], Step [30/158]| g_loss: 0.679| d_loss: 0.755| gp_loss: 0.174| r_loss: 0.063| p_loss: 0.087| v_loss: 0.023| per_loss: 0.319 | a_loss: 0.518
Train: Epoch [1865/3000], Step [60/158]| g_loss: 0.720| d_loss: 0.585| gp_loss: 0.052| r_loss: 0.061| p_loss: 0.086| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.561
Train: Epoch [1865/3000], Step [90/158]| g_loss: 0.693| d_loss: 0.545| gp_loss: 0.052| r_loss: 0.061| p_loss: 0.085| v_loss: 0.023| per_loss: 0.328 | a_loss: 0.534
Train: Epoch [1865/3000], Step [120/158]| g_loss: 0.726| d_loss: 0.598| gp_loss: 0.053| r_loss: 0.062| p_loss: 0.088| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.567
Train: Epoch [1865/3000], Step [150/158]| g_loss: 0.657| d_loss: 0.665| gp_loss: 0.052| r_loss: 0.061| p_loss: 0.088| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.498
Train: Epoch [1866/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.657| gp_loss: 0.124| r_loss: 0.062| p_loss: 0.086| v_loss: 0.022| per_loss: 0.325 | a_loss: 0.503
Train: Epoch [1866/3000], Step [60/158]| g_loss: 0.678| d_loss: 0.676| gp_loss: 0.054| r_loss: 0.059| p_loss: 0.084| v_loss: 0.023| per_loss: 0.309 | a_loss: 0.524
Train: Epoch [1866/3000], Step [90/158]| g_loss: 0.700| d_loss: 0.573| gp_loss: 0.055| r_loss: 0.060| p_loss: 0.084| v_loss: 0.022| per_loss: 0.327 | a_loss: 0.543
Train: Epoch [1866/3000], Step [120/158]| g_loss: 0.698| d_loss: 0.644| gp_loss: 0.055| r_loss: 0.063| p_loss: 0.090| v_loss: 0.023| per_loss: 0.332 | a_loss: 0.533
Train: Epoch [1866/3000], Step [150/158]| g_loss: 0.672| d_loss: 0.582| gp_loss: 0.059| r_loss: 0.060| p_loss: 0.089| v_loss: 0.023| per_loss: 0.307 | a_loss: 0.514
Train: Epoch [1867/3000], Step [30/158]| g_loss: 0.714| d_loss: 0.685| gp_loss: 0.163| r_loss: 0.060| p_loss: 0.086| v_loss: 0.022| per_loss: 0.303 | a_loss: 0.559
Train: Epoch [1867/3000], Step [60/158]| g_loss: 0.633| d_loss: 0.658| gp_loss: 0.054| r_loss: 0.060| p_loss: 0.083| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.478
Train: Epoch [1867/3000], Step [90/158]| g_loss: 0.678| d_loss: 0.637| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.082| v_loss: 0.022| per_loss: 0.333 | a_loss: 0.522
Train: Epoch [1867/3000], Step [120/158]| g_loss: 0.728| d_loss: 0.504| gp_loss: 0.059| r_loss: 0.060| p_loss: 0.086| v_loss: 0.023| per_loss: 0.317 | a_loss: 0.571
Train: Epoch [1867/3000], Step [150/158]| g_loss: 0.704| d_loss: 0.642| gp_loss: 0.058| r_loss: 0.064| p_loss: 0.088| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.542
Train: Epoch [1868/3000], Step [30/158]| g_loss: 0.696| d_loss: 0.675| gp_loss: 0.151| r_loss: 0.062| p_loss: 0.086| v_loss: 0.022| per_loss: 0.318 | a_loss: 0.537
Train: Epoch [1868/3000], Step [60/158]| g_loss: 0.745| d_loss: 0.522| gp_loss: 0.055| r_loss: 0.061| p_loss: 0.086| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.587
Train: Epoch [1868/3000], Step [90/158]| g_loss: 0.642| d_loss: 0.760| gp_loss: 0.053| r_loss: 0.062| p_loss: 0.088| v_loss: 0.022| per_loss: 0.322 | a_loss: 0.483
Train: Epoch [1868/3000], Step [120/158]| g_loss: 0.715| d_loss: 0.506| gp_loss: 0.061| r_loss: 0.063| p_loss: 0.087| v_loss: 0.023| per_loss: 0.336 | a_loss: 0.552
Train: Epoch [1868/3000], Step [150/158]| g_loss: 0.696| d_loss: 0.655| gp_loss: 0.058| r_loss: 0.059| p_loss: 0.091| v_loss: 0.023| per_loss: 0.313 | a_loss: 0.537
Train: Epoch [1869/3000], Step [30/158]| g_loss: 0.638| d_loss: 0.764| gp_loss: 0.148| r_loss: 0.062| p_loss: 0.092| v_loss: 0.023| per_loss: 0.304 | a_loss: 0.476
Train: Epoch [1869/3000], Step [60/158]| g_loss: 0.749| d_loss: 0.515| gp_loss: 0.061| r_loss: 0.062| p_loss: 0.090| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.588
Train: Epoch [1869/3000], Step [90/158]| g_loss: 0.726| d_loss: 0.618| gp_loss: 0.058| r_loss: 0.062| p_loss: 0.092| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.562
Train: Epoch [1869/3000], Step [120/158]| g_loss: 0.678| d_loss: 0.711| gp_loss: 0.054| r_loss: 0.063| p_loss: 0.093| v_loss: 0.024| per_loss: 0.342 | a_loss: 0.510
Train: Epoch [1869/3000], Step [150/158]| g_loss: 0.692| d_loss: 0.609| gp_loss: 0.060| r_loss: 0.064| p_loss: 0.094| v_loss: 0.023| per_loss: 0.315 | a_loss: 0.527
Train: Epoch [1870/3000], Step [30/158]| g_loss: 0.733| d_loss: 0.618| gp_loss: 0.138| r_loss: 0.063| p_loss: 0.093| v_loss: 0.023| per_loss: 0.315 | a_loss: 0.569
Train: Epoch [1870/3000], Step [60/158]| g_loss: 0.675| d_loss: 0.652| gp_loss: 0.053| r_loss: 0.060| p_loss: 0.087| v_loss: 0.022| per_loss: 0.333 | a_loss: 0.516
Train: Epoch [1870/3000], Step [90/158]| g_loss: 0.653| d_loss: 0.609| gp_loss: 0.060| r_loss: 0.060| p_loss: 0.089| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.494
Train: Epoch [1870/3000], Step [120/158]| g_loss: 0.702| d_loss: 0.656| gp_loss: 0.056| r_loss: 0.064| p_loss: 0.093| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.536
Train: Epoch [1870/3000], Step [150/158]| g_loss: 0.700| d_loss: 0.550| gp_loss: 0.063| r_loss: 0.059| p_loss: 0.081| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.547
Train: Epoch [1871/3000], Step [30/158]| g_loss: 0.683| d_loss: 0.746| gp_loss: 0.184| r_loss: 0.060| p_loss: 0.082| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.529
Train: Epoch [1871/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.609| gp_loss: 0.054| r_loss: 0.058| p_loss: 0.084| v_loss: 0.023| per_loss: 0.317 | a_loss: 0.518
Train: Epoch [1871/3000], Step [90/158]| g_loss: 0.719| d_loss: 0.535| gp_loss: 0.053| r_loss: 0.057| p_loss: 0.081| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.568
Train: Epoch [1871/3000], Step [120/158]| g_loss: 0.688| d_loss: 0.638| gp_loss: 0.055| r_loss: 0.062| p_loss: 0.090| v_loss: 0.023| per_loss: 0.311 | a_loss: 0.527
Train: Epoch [1871/3000], Step [150/158]| g_loss: 0.725| d_loss: 0.578| gp_loss: 0.055| r_loss: 0.061| p_loss: 0.085| v_loss: 0.023| per_loss: 0.332 | a_loss: 0.566
Train: Epoch [1872/3000], Step [30/158]| g_loss: 0.642| d_loss: 0.757| gp_loss: 0.146| r_loss: 0.058| p_loss: 0.086| v_loss: 0.023| per_loss: 0.318 | a_loss: 0.487
Train: Epoch [1872/3000], Step [60/158]| g_loss: 0.644| d_loss: 0.625| gp_loss: 0.054| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.303 | a_loss: 0.492
Train: Epoch [1872/3000], Step [90/158]| g_loss: 0.687| d_loss: 0.633| gp_loss: 0.052| r_loss: 0.062| p_loss: 0.086| v_loss: 0.023| per_loss: 0.327 | a_loss: 0.526
Train: Epoch [1872/3000], Step [120/158]| g_loss: 0.729| d_loss: 0.518| gp_loss: 0.055| r_loss: 0.061| p_loss: 0.085| v_loss: 0.023| per_loss: 0.315 | a_loss: 0.571
Train: Epoch [1872/3000], Step [150/158]| g_loss: 0.706| d_loss: 0.594| gp_loss: 0.057| r_loss: 0.063| p_loss: 0.085| v_loss: 0.023| per_loss: 0.312 | a_loss: 0.547
Train: Epoch [1873/3000], Step [30/158]| g_loss: 0.699| d_loss: 0.643| gp_loss: 0.099| r_loss: 0.059| p_loss: 0.085| v_loss: 0.023| per_loss: 0.300 | a_loss: 0.545
Train: Epoch [1873/3000], Step [60/158]| g_loss: 0.677| d_loss: 0.655| gp_loss: 0.058| r_loss: 0.062| p_loss: 0.088| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.517
Train: Epoch [1873/3000], Step [90/158]| g_loss: 0.658| d_loss: 0.669| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.088| v_loss: 0.022| per_loss: 0.326 | a_loss: 0.499
Train: Epoch [1873/3000], Step [120/158]| g_loss: 0.690| d_loss: 0.566| gp_loss: 0.062| r_loss: 0.059| p_loss: 0.088| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.532
Train: Epoch [1873/3000], Step [150/158]| g_loss: 0.719| d_loss: 0.617| gp_loss: 0.060| r_loss: 0.060| p_loss: 0.085| v_loss: 0.023| per_loss: 0.324 | a_loss: 0.562
Train: Epoch [1874/3000], Step [30/158]| g_loss: 0.707| d_loss: 0.697| gp_loss: 0.131| r_loss: 0.064| p_loss: 0.092| v_loss: 0.023| per_loss: 0.315 | a_loss: 0.543
Train: Epoch [1874/3000], Step [60/158]| g_loss: 0.649| d_loss: 0.655| gp_loss: 0.055| r_loss: 0.060| p_loss: 0.085| v_loss: 0.022| per_loss: 0.332 | a_loss: 0.491
Train: Epoch [1874/3000], Step [90/158]| g_loss: 0.716| d_loss: 0.559| gp_loss: 0.059| r_loss: 0.061| p_loss: 0.088| v_loss: 0.023| per_loss: 0.317 | a_loss: 0.556
Train: Epoch [1874/3000], Step [120/158]| g_loss: 0.682| d_loss: 0.588| gp_loss: 0.058| r_loss: 0.061| p_loss: 0.087| v_loss: 0.023| per_loss: 0.316 | a_loss: 0.523
Train: Epoch [1874/3000], Step [150/158]| g_loss: 0.706| d_loss: 0.631| gp_loss: 0.062| r_loss: 0.058| p_loss: 0.087| v_loss: 0.022| per_loss: 0.307 | a_loss: 0.552
Train: Epoch [1875/3000], Step [30/158]| g_loss: 0.730| d_loss: 0.639| gp_loss: 0.171| r_loss: 0.066| p_loss: 0.095| v_loss: 0.024| per_loss: 0.309 | a_loss: 0.561
Train: Epoch [1875/3000], Step [60/158]| g_loss: 0.725| d_loss: 0.613| gp_loss: 0.055| r_loss: 0.065| p_loss: 0.093| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.558
Train: Epoch [1875/3000], Step [90/158]| g_loss: 0.677| d_loss: 0.628| gp_loss: 0.059| r_loss: 0.061| p_loss: 0.090| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.517
Train: Epoch [1875/3000], Step [120/158]| g_loss: 0.662| d_loss: 0.676| gp_loss: 0.053| r_loss: 0.060| p_loss: 0.088| v_loss: 0.022| per_loss: 0.331 | a_loss: 0.502
Train: Epoch [1875/3000], Step [150/158]| g_loss: 0.697| d_loss: 0.559| gp_loss: 0.058| r_loss: 0.062| p_loss: 0.088| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.537
Train: Epoch [1876/3000], Step [30/158]| g_loss: 0.680| d_loss: 0.756| gp_loss: 0.164| r_loss: 0.065| p_loss: 0.093| v_loss: 0.023| per_loss: 0.315 | a_loss: 0.514
Train: Epoch [1876/3000], Step [60/158]| g_loss: 0.748| d_loss: 0.603| gp_loss: 0.056| r_loss: 0.060| p_loss: 0.081| v_loss: 0.022| per_loss: 0.311 | a_loss: 0.594
Train: Epoch [1876/3000], Step [90/158]| g_loss: 0.656| d_loss: 0.594| gp_loss: 0.054| r_loss: 0.060| p_loss: 0.085| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.499
Train: Epoch [1876/3000], Step [120/158]| g_loss: 0.683| d_loss: 0.604| gp_loss: 0.054| r_loss: 0.062| p_loss: 0.088| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.524
Train: Epoch [1876/3000], Step [150/158]| g_loss: 0.731| d_loss: 0.587| gp_loss: 0.059| r_loss: 0.062| p_loss: 0.086| v_loss: 0.023| per_loss: 0.322 | a_loss: 0.570
Train: Epoch [1877/3000], Step [30/158]| g_loss: 0.674| d_loss: 0.661| gp_loss: 0.101| r_loss: 0.060| p_loss: 0.088| v_loss: 0.022| per_loss: 0.347 | a_loss: 0.513
Train: Epoch [1877/3000], Step [60/158]| g_loss: 0.704| d_loss: 0.581| gp_loss: 0.060| r_loss: 0.059| p_loss: 0.083| v_loss: 0.022| per_loss: 0.306 | a_loss: 0.551
Train: Epoch [1877/3000], Step [90/158]| g_loss: 0.709| d_loss: 0.533| gp_loss: 0.059| r_loss: 0.059| p_loss: 0.082| v_loss: 0.023| per_loss: 0.324 | a_loss: 0.555
Train: Epoch [1877/3000], Step [120/158]| g_loss: 0.686| d_loss: 0.723| gp_loss: 0.056| r_loss: 0.062| p_loss: 0.086| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.527
Train: Epoch [1877/3000], Step [150/158]| g_loss: 0.631| d_loss: 0.661| gp_loss: 0.060| r_loss: 0.061| p_loss: 0.089| v_loss: 0.022| per_loss: 0.298 | a_loss: 0.474
Train: Epoch [1878/3000], Step [30/158]| g_loss: 0.677| d_loss: 0.717| gp_loss: 0.138| r_loss: 0.063| p_loss: 0.089| v_loss: 0.023| per_loss: 0.321 | a_loss: 0.513
Train: Epoch [1878/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.598| gp_loss: 0.059| r_loss: 0.060| p_loss: 0.085| v_loss: 0.023| per_loss: 0.324 | a_loss: 0.515
Train: Epoch [1878/3000], Step [90/158]| g_loss: 0.666| d_loss: 0.669| gp_loss: 0.058| r_loss: 0.059| p_loss: 0.086| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.511
Train: Epoch [1878/3000], Step [120/158]| g_loss: 0.735| d_loss: 0.550| gp_loss: 0.064| r_loss: 0.060| p_loss: 0.086| v_loss: 0.023| per_loss: 0.310 | a_loss: 0.578
Train: Epoch [1878/3000], Step [150/158]| g_loss: 0.656| d_loss: 0.621| gp_loss: 0.060| r_loss: 0.059| p_loss: 0.086| v_loss: 0.022| per_loss: 0.324 | a_loss: 0.500
Train: Epoch [1879/3000], Step [30/158]| g_loss: 0.733| d_loss: 0.834| gp_loss: 0.289| r_loss: 0.063| p_loss: 0.088| v_loss: 0.023| per_loss: 0.307 | a_loss: 0.573
Train: Epoch [1879/3000], Step [60/158]| g_loss: 0.663| d_loss: 0.574| gp_loss: 0.049| r_loss: 0.061| p_loss: 0.086| v_loss: 0.022| per_loss: 0.303 | a_loss: 0.506
Train: Epoch [1879/3000], Step [90/158]| g_loss: 0.627| d_loss: 0.665| gp_loss: 0.049| r_loss: 0.057| p_loss: 0.082| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.476
Train: Epoch [1879/3000], Step [120/158]| g_loss: 0.664| d_loss: 0.660| gp_loss: 0.054| r_loss: 0.058| p_loss: 0.083| v_loss: 0.022| per_loss: 0.326 | a_loss: 0.509
Train: Epoch [1879/3000], Step [150/158]| g_loss: 0.745| d_loss: 0.524| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.087| v_loss: 0.022| per_loss: 0.318 | a_loss: 0.586
Train: Epoch [1880/3000], Step [30/158]| g_loss: 0.704| d_loss: 0.710| gp_loss: 0.117| r_loss: 0.065| p_loss: 0.097| v_loss: 0.023| per_loss: 0.328 | a_loss: 0.534
Train: Epoch [1880/3000], Step [60/158]| g_loss: 0.695| d_loss: 0.654| gp_loss: 0.051| r_loss: 0.063| p_loss: 0.096| v_loss: 0.022| per_loss: 0.323 | a_loss: 0.530
Train: Epoch [1880/3000], Step [90/158]| g_loss: 0.683| d_loss: 0.577| gp_loss: 0.057| r_loss: 0.063| p_loss: 0.092| v_loss: 0.023| per_loss: 0.303 | a_loss: 0.521
Train: Epoch [1880/3000], Step [120/158]| g_loss: 0.730| d_loss: 0.563| gp_loss: 0.054| r_loss: 0.061| p_loss: 0.085| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.573
Train: Epoch [1880/3000], Step [150/158]| g_loss: 0.689| d_loss: 0.625| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.087| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.531
Train: Epoch [1881/3000], Step [30/158]| g_loss: 0.662| d_loss: 0.692| gp_loss: 0.152| r_loss: 0.059| p_loss: 0.086| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.506
Train: Epoch [1881/3000], Step [60/158]| g_loss: 0.760| d_loss: 0.485| gp_loss: 0.054| r_loss: 0.059| p_loss: 0.085| v_loss: 0.023| per_loss: 0.318 | a_loss: 0.604
Train: Epoch [1881/3000], Step [90/158]| g_loss: 0.699| d_loss: 0.690| gp_loss: 0.052| r_loss: 0.063| p_loss: 0.091| v_loss: 0.022| per_loss: 0.307 | a_loss: 0.538
Train: Epoch [1881/3000], Step [120/158]| g_loss: 0.683| d_loss: 0.607| gp_loss: 0.056| r_loss: 0.060| p_loss: 0.083| v_loss: 0.022| per_loss: 0.320 | a_loss: 0.527
Train: Epoch [1881/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.686| gp_loss: 0.054| r_loss: 0.061| p_loss: 0.085| v_loss: 0.022| per_loss: 0.292 | a_loss: 0.504
Train: Epoch [1882/3000], Step [30/158]| g_loss: 0.695| d_loss: 0.660| gp_loss: 0.156| r_loss: 0.061| p_loss: 0.089| v_loss: 0.022| per_loss: 0.325 | a_loss: 0.535
Train: Epoch [1882/3000], Step [60/158]| g_loss: 0.702| d_loss: 0.627| gp_loss: 0.054| r_loss: 0.061| p_loss: 0.091| v_loss: 0.022| per_loss: 0.303 | a_loss: 0.542
Train: Epoch [1882/3000], Step [90/158]| g_loss: 0.728| d_loss: 0.561| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.083| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.576
Train: Epoch [1882/3000], Step [120/158]| g_loss: 0.682| d_loss: 0.628| gp_loss: 0.054| r_loss: 0.064| p_loss: 0.089| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.520
Train: Epoch [1882/3000], Step [150/158]| g_loss: 0.651| d_loss: 0.672| gp_loss: 0.055| r_loss: 0.060| p_loss: 0.086| v_loss: 0.022| per_loss: 0.334 | a_loss: 0.493
Train: Epoch [1883/3000], Step [30/158]| g_loss: 0.636| d_loss: 0.776| gp_loss: 0.169| r_loss: 0.059| p_loss: 0.082| v_loss: 0.021| per_loss: 0.328 | a_loss: 0.482
Train: Epoch [1883/3000], Step [60/158]| g_loss: 0.712| d_loss: 0.476| gp_loss: 0.055| r_loss: 0.063| p_loss: 0.086| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.550
Train: Epoch [1883/3000], Step [90/158]| g_loss: 0.729| d_loss: 0.628| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.085| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.571
Train: Epoch [1883/3000], Step [120/158]| g_loss: 0.692| d_loss: 0.641| gp_loss: 0.058| r_loss: 0.059| p_loss: 0.091| v_loss: 0.022| per_loss: 0.303 | a_loss: 0.535
Train: Epoch [1883/3000], Step [150/158]| g_loss: 0.656| d_loss: 0.612| gp_loss: 0.059| r_loss: 0.061| p_loss: 0.084| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.500
Train: Epoch [1884/3000], Step [30/158]| g_loss: 0.697| d_loss: 0.659| gp_loss: 0.117| r_loss: 0.061| p_loss: 0.086| v_loss: 0.023| per_loss: 0.307 | a_loss: 0.539
Train: Epoch [1884/3000], Step [60/158]| g_loss: 0.687| d_loss: 0.669| gp_loss: 0.056| r_loss: 0.063| p_loss: 0.088| v_loss: 0.023| per_loss: 0.310 | a_loss: 0.526
Train: Epoch [1884/3000], Step [90/158]| g_loss: 0.655| d_loss: 0.599| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.085| v_loss: 0.023| per_loss: 0.324 | a_loss: 0.498
Train: Epoch [1884/3000], Step [120/158]| g_loss: 0.739| d_loss: 0.524| gp_loss: 0.062| r_loss: 0.059| p_loss: 0.085| v_loss: 0.023| per_loss: 0.335 | a_loss: 0.581
Train: Epoch [1884/3000], Step [150/158]| g_loss: 0.652| d_loss: 0.668| gp_loss: 0.057| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.499
Train: Epoch [1885/3000], Step [30/158]| g_loss: 0.699| d_loss: 0.716| gp_loss: 0.166| r_loss: 0.061| p_loss: 0.087| v_loss: 0.022| per_loss: 0.320 | a_loss: 0.540
Train: Epoch [1885/3000], Step [60/158]| g_loss: 0.698| d_loss: 0.580| gp_loss: 0.055| r_loss: 0.063| p_loss: 0.087| v_loss: 0.023| per_loss: 0.314 | a_loss: 0.537
Train: Epoch [1885/3000], Step [90/158]| g_loss: 0.659| d_loss: 0.651| gp_loss: 0.057| r_loss: 0.060| p_loss: 0.087| v_loss: 0.023| per_loss: 0.322 | a_loss: 0.501
Train: Epoch [1885/3000], Step [120/158]| g_loss: 0.741| d_loss: 0.512| gp_loss: 0.060| r_loss: 0.061| p_loss: 0.089| v_loss: 0.023| per_loss: 0.302 | a_loss: 0.583
Train: Epoch [1885/3000], Step [150/158]| g_loss: 0.707| d_loss: 0.653| gp_loss: 0.056| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.327 | a_loss: 0.552
Train: Epoch [1886/3000], Step [30/158]| g_loss: 0.714| d_loss: 0.684| gp_loss: 0.160| r_loss: 0.062| p_loss: 0.086| v_loss: 0.023| per_loss: 0.324 | a_loss: 0.553
Train: Epoch [1886/3000], Step [60/158]| g_loss: 0.678| d_loss: 0.608| gp_loss: 0.051| r_loss: 0.058| p_loss: 0.082| v_loss: 0.022| per_loss: 0.332 | a_loss: 0.524
Train: Epoch [1886/3000], Step [90/158]| g_loss: 0.683| d_loss: 0.650| gp_loss: 0.052| r_loss: 0.062| p_loss: 0.086| v_loss: 0.022| per_loss: 0.322 | a_loss: 0.524
Train: Epoch [1886/3000], Step [120/158]| g_loss: 0.684| d_loss: 0.549| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.079| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.536
Train: Epoch [1886/3000], Step [150/158]| g_loss: 0.673| d_loss: 0.682| gp_loss: 0.058| r_loss: 0.059| p_loss: 0.084| v_loss: 0.023| per_loss: 0.310 | a_loss: 0.519
Train: Epoch [1887/3000], Step [30/158]| g_loss: 0.713| d_loss: 0.697| gp_loss: 0.204| r_loss: 0.059| p_loss: 0.080| v_loss: 0.022| per_loss: 0.299 | a_loss: 0.562
Train: Epoch [1887/3000], Step [60/158]| g_loss: 0.653| d_loss: 0.669| gp_loss: 0.050| r_loss: 0.056| p_loss: 0.083| v_loss: 0.022| per_loss: 0.306 | a_loss: 0.503
Train: Epoch [1887/3000], Step [90/158]| g_loss: 0.625| d_loss: 0.650| gp_loss: 0.054| r_loss: 0.059| p_loss: 0.081| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.472
Train: Epoch [1887/3000], Step [120/158]| g_loss: 0.698| d_loss: 0.603| gp_loss: 0.054| r_loss: 0.063| p_loss: 0.088| v_loss: 0.023| per_loss: 0.319 | a_loss: 0.536
Train: Epoch [1887/3000], Step [150/158]| g_loss: 0.738| d_loss: 0.560| gp_loss: 0.056| r_loss: 0.060| p_loss: 0.085| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.583
Train: Epoch [1888/3000], Step [30/158]| g_loss: 0.666| d_loss: 0.740| gp_loss: 0.133| r_loss: 0.068| p_loss: 0.094| v_loss: 0.023| per_loss: 0.321 | a_loss: 0.496
Train: Epoch [1888/3000], Step [60/158]| g_loss: 0.689| d_loss: 0.571| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.088| v_loss: 0.023| per_loss: 0.328 | a_loss: 0.529
Train: Epoch [1888/3000], Step [90/158]| g_loss: 0.685| d_loss: 0.600| gp_loss: 0.057| r_loss: 0.058| p_loss: 0.084| v_loss: 0.022| per_loss: 0.323 | a_loss: 0.530
Train: Epoch [1888/3000], Step [120/158]| g_loss: 0.699| d_loss: 0.648| gp_loss: 0.054| r_loss: 0.060| p_loss: 0.087| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.542
Train: Epoch [1888/3000], Step [150/158]| g_loss: 0.650| d_loss: 0.648| gp_loss: 0.056| r_loss: 0.062| p_loss: 0.090| v_loss: 0.022| per_loss: 0.303 | a_loss: 0.491
Train: Epoch [1889/3000], Step [30/158]| g_loss: 0.694| d_loss: 0.684| gp_loss: 0.141| r_loss: 0.061| p_loss: 0.085| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.538
Train: Epoch [1889/3000], Step [60/158]| g_loss: 0.699| d_loss: 0.636| gp_loss: 0.054| r_loss: 0.059| p_loss: 0.083| v_loss: 0.023| per_loss: 0.324 | a_loss: 0.543
Train: Epoch [1889/3000], Step [90/158]| g_loss: 0.668| d_loss: 0.657| gp_loss: 0.055| r_loss: 0.058| p_loss: 0.084| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.515
Train: Epoch [1889/3000], Step [120/158]| g_loss: 0.692| d_loss: 0.553| gp_loss: 0.057| r_loss: 0.060| p_loss: 0.085| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.536
Train: Epoch [1889/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.586| gp_loss: 0.059| r_loss: 0.061| p_loss: 0.087| v_loss: 0.023| per_loss: 0.318 | a_loss: 0.516
Train: Epoch [1890/3000], Step [30/158]| g_loss: 0.717| d_loss: 0.668| gp_loss: 0.164| r_loss: 0.062| p_loss: 0.087| v_loss: 0.022| per_loss: 0.330 | a_loss: 0.557
Train: Epoch [1890/3000], Step [60/158]| g_loss: 0.691| d_loss: 0.617| gp_loss: 0.053| r_loss: 0.061| p_loss: 0.088| v_loss: 0.023| per_loss: 0.313 | a_loss: 0.532
Train: Epoch [1890/3000], Step [90/158]| g_loss: 0.708| d_loss: 0.615| gp_loss: 0.054| r_loss: 0.061| p_loss: 0.086| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.551
Train: Epoch [1890/3000], Step [120/158]| g_loss: 0.699| d_loss: 0.608| gp_loss: 0.055| r_loss: 0.062| p_loss: 0.087| v_loss: 0.023| per_loss: 0.315 | a_loss: 0.538
Train: Epoch [1890/3000], Step [150/158]| g_loss: 0.654| d_loss: 0.634| gp_loss: 0.056| r_loss: 0.059| p_loss: 0.086| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.499
Train: Epoch [1891/3000], Step [30/158]| g_loss: 0.707| d_loss: 0.702| gp_loss: 0.171| r_loss: 0.059| p_loss: 0.086| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.550
Train: Epoch [1891/3000], Step [60/158]| g_loss: 0.691| d_loss: 0.632| gp_loss: 0.051| r_loss: 0.061| p_loss: 0.087| v_loss: 0.022| per_loss: 0.345 | a_loss: 0.530
Train: Epoch [1891/3000], Step [90/158]| g_loss: 0.676| d_loss: 0.611| gp_loss: 0.051| r_loss: 0.064| p_loss: 0.091| v_loss: 0.023| per_loss: 0.292 | a_loss: 0.514
Train: Epoch [1891/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.633| gp_loss: 0.056| r_loss: 0.062| p_loss: 0.086| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.519
Train: Epoch [1891/3000], Step [150/158]| g_loss: 0.698| d_loss: 0.632| gp_loss: 0.057| r_loss: 0.063| p_loss: 0.087| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.538
Train: Epoch [1892/3000], Step [30/158]| g_loss: 0.681| d_loss: 0.649| gp_loss: 0.150| r_loss: 0.058| p_loss: 0.083| v_loss: 0.022| per_loss: 0.325 | a_loss: 0.527
Train: Epoch [1892/3000], Step [60/158]| g_loss: 0.674| d_loss: 0.601| gp_loss: 0.051| r_loss: 0.058| p_loss: 0.080| v_loss: 0.022| per_loss: 0.307 | a_loss: 0.524
Train: Epoch [1892/3000], Step [90/158]| g_loss: 0.619| d_loss: 0.717| gp_loss: 0.054| r_loss: 0.060| p_loss: 0.086| v_loss: 0.022| per_loss: 0.299 | a_loss: 0.465
Train: Epoch [1892/3000], Step [120/158]| g_loss: 0.697| d_loss: 0.587| gp_loss: 0.061| r_loss: 0.062| p_loss: 0.085| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.539
Train: Epoch [1892/3000], Step [150/158]| g_loss: 0.763| d_loss: 0.540| gp_loss: 0.056| r_loss: 0.064| p_loss: 0.090| v_loss: 0.023| per_loss: 0.322 | a_loss: 0.599
Train: Epoch [1893/3000], Step [30/158]| g_loss: 0.700| d_loss: 0.665| gp_loss: 0.152| r_loss: 0.061| p_loss: 0.087| v_loss: 0.024| per_loss: 0.311 | a_loss: 0.541
Train: Epoch [1893/3000], Step [60/158]| g_loss: 0.662| d_loss: 0.592| gp_loss: 0.051| r_loss: 0.058| p_loss: 0.084| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.509
Train: Epoch [1893/3000], Step [90/158]| g_loss: 0.674| d_loss: 0.649| gp_loss: 0.052| r_loss: 0.058| p_loss: 0.082| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.522
Train: Epoch [1893/3000], Step [120/158]| g_loss: 0.692| d_loss: 0.583| gp_loss: 0.058| r_loss: 0.059| p_loss: 0.079| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.542
Train: Epoch [1893/3000], Step [150/158]| g_loss: 0.682| d_loss: 0.620| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.318 | a_loss: 0.527
Train: Epoch [1894/3000], Step [30/158]| g_loss: 0.690| d_loss: 0.695| gp_loss: 0.151| r_loss: 0.060| p_loss: 0.085| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.533
Train: Epoch [1894/3000], Step [60/158]| g_loss: 0.658| d_loss: 0.678| gp_loss: 0.052| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.327 | a_loss: 0.502
Train: Epoch [1894/3000], Step [90/158]| g_loss: 0.692| d_loss: 0.580| gp_loss: 0.058| r_loss: 0.060| p_loss: 0.087| v_loss: 0.023| per_loss: 0.316 | a_loss: 0.534
Train: Epoch [1894/3000], Step [120/158]| g_loss: 0.708| d_loss: 0.574| gp_loss: 0.056| r_loss: 0.062| p_loss: 0.087| v_loss: 0.023| per_loss: 0.314 | a_loss: 0.547
Train: Epoch [1894/3000], Step [150/158]| g_loss: 0.699| d_loss: 0.622| gp_loss: 0.058| r_loss: 0.063| p_loss: 0.091| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.536
Train: Epoch [1895/3000], Step [30/158]| g_loss: 0.714| d_loss: 0.667| gp_loss: 0.171| r_loss: 0.062| p_loss: 0.088| v_loss: 0.023| per_loss: 0.331 | a_loss: 0.552
Train: Epoch [1895/3000], Step [60/158]| g_loss: 0.725| d_loss: 0.519| gp_loss: 0.054| r_loss: 0.057| p_loss: 0.084| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.573
Train: Epoch [1895/3000], Step [90/158]| g_loss: 0.684| d_loss: 0.628| gp_loss: 0.053| r_loss: 0.060| p_loss: 0.087| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.524
Train: Epoch [1895/3000], Step [120/158]| g_loss: 0.658| d_loss: 0.648| gp_loss: 0.055| r_loss: 0.060| p_loss: 0.082| v_loss: 0.021| per_loss: 0.321 | a_loss: 0.504
Train: Epoch [1895/3000], Step [150/158]| g_loss: 0.663| d_loss: 0.680| gp_loss: 0.054| r_loss: 0.061| p_loss: 0.087| v_loss: 0.022| per_loss: 0.300 | a_loss: 0.507
Train: Epoch [1896/3000], Step [30/158]| g_loss: 0.710| d_loss: 0.702| gp_loss: 0.188| r_loss: 0.063| p_loss: 0.088| v_loss: 0.023| per_loss: 0.321 | a_loss: 0.548
Train: Epoch [1896/3000], Step [60/158]| g_loss: 0.679| d_loss: 0.663| gp_loss: 0.051| r_loss: 0.066| p_loss: 0.099| v_loss: 0.022| per_loss: 0.332 | a_loss: 0.508
Train: Epoch [1896/3000], Step [90/158]| g_loss: 0.681| d_loss: 0.572| gp_loss: 0.052| r_loss: 0.069| p_loss: 0.110| v_loss: 0.024| per_loss: 0.336 | a_loss: 0.500
Train: Epoch [1896/3000], Step [120/158]| g_loss: 0.685| d_loss: 0.629| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.091| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.524
Train: Epoch [1896/3000], Step [150/158]| g_loss: 0.744| d_loss: 0.526| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.083| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.589
Train: Epoch [1897/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.731| gp_loss: 0.109| r_loss: 0.062| p_loss: 0.090| v_loss: 0.022| per_loss: 0.301 | a_loss: 0.504
Train: Epoch [1897/3000], Step [60/158]| g_loss: 0.670| d_loss: 0.622| gp_loss: 0.054| r_loss: 0.064| p_loss: 0.093| v_loss: 0.023| per_loss: 0.316 | a_loss: 0.506
Train: Epoch [1897/3000], Step [90/158]| g_loss: 0.722| d_loss: 0.574| gp_loss: 0.062| r_loss: 0.063| p_loss: 0.090| v_loss: 0.023| per_loss: 0.321 | a_loss: 0.559
Train: Epoch [1897/3000], Step [120/158]| g_loss: 0.722| d_loss: 0.574| gp_loss: 0.055| r_loss: 0.061| p_loss: 0.089| v_loss: 0.024| per_loss: 0.324 | a_loss: 0.560
Train: Epoch [1897/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.694| gp_loss: 0.057| r_loss: 0.058| p_loss: 0.084| v_loss: 0.022| per_loss: 0.322 | a_loss: 0.508
Train: Epoch [1898/3000], Step [30/158]| g_loss: 0.701| d_loss: 0.625| gp_loss: 0.144| r_loss: 0.058| p_loss: 0.083| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.548
Train: Epoch [1898/3000], Step [60/158]| g_loss: 0.634| d_loss: 0.728| gp_loss: 0.052| r_loss: 0.065| p_loss: 0.092| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.469
Train: Epoch [1898/3000], Step [90/158]| g_loss: 0.686| d_loss: 0.566| gp_loss: 0.055| r_loss: 0.060| p_loss: 0.088| v_loss: 0.023| per_loss: 0.315 | a_loss: 0.527
Train: Epoch [1898/3000], Step [120/158]| g_loss: 0.724| d_loss: 0.502| gp_loss: 0.059| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.576
Train: Epoch [1898/3000], Step [150/158]| g_loss: 0.727| d_loss: 0.647| gp_loss: 0.058| r_loss: 0.064| p_loss: 0.089| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.564
Train: Epoch [1899/3000], Step [30/158]| g_loss: 0.692| d_loss: 0.718| gp_loss: 0.178| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.537
Train: Epoch [1899/3000], Step [60/158]| g_loss: 0.680| d_loss: 0.660| gp_loss: 0.053| r_loss: 0.060| p_loss: 0.086| v_loss: 0.023| per_loss: 0.318 | a_loss: 0.523
Train: Epoch [1899/3000], Step [90/158]| g_loss: 0.682| d_loss: 0.643| gp_loss: 0.054| r_loss: 0.061| p_loss: 0.085| v_loss: 0.023| per_loss: 0.314 | a_loss: 0.525
Train: Epoch [1899/3000], Step [120/158]| g_loss: 0.671| d_loss: 0.634| gp_loss: 0.054| r_loss: 0.058| p_loss: 0.083| v_loss: 0.022| per_loss: 0.327 | a_loss: 0.516
Train: Epoch [1899/3000], Step [150/158]| g_loss: 0.666| d_loss: 0.582| gp_loss: 0.059| r_loss: 0.059| p_loss: 0.087| v_loss: 0.023| per_loss: 0.318 | a_loss: 0.509
Train: Epoch [1900/3000], Step [30/158]| g_loss: 0.714| d_loss: 0.645| gp_loss: 0.066| r_loss: 0.062| p_loss: 0.090| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.553
Train: Epoch [1900/3000], Step [60/158]| g_loss: 0.663| d_loss: 0.634| gp_loss: 0.059| r_loss: 0.061| p_loss: 0.088| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.505
Train: Epoch [1900/3000], Step [90/158]| g_loss: 0.694| d_loss: 0.654| gp_loss: 0.057| r_loss: 0.062| p_loss: 0.091| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.533
Train: Epoch [1900/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.607| gp_loss: 0.063| r_loss: 0.060| p_loss: 0.095| v_loss: 0.023| per_loss: 0.332 | a_loss: 0.513
Train: Epoch [1900/3000], Step [150/158]| g_loss: 0.680| d_loss: 0.622| gp_loss: 0.059| r_loss: 0.062| p_loss: 0.087| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.519
Test: Epoch [1900/3000]| g_loss: 0.612| r_loss: 0.373| p_loss: 0.300| v_loss: 0.021
Train: Epoch [1901/3000], Step [30/158]| g_loss: 0.678| d_loss: 0.598| gp_loss: 0.057| r_loss: 0.061| p_loss: 0.087| v_loss: 0.023| per_loss: 0.344 | a_loss: 0.516
Train: Epoch [1901/3000], Step [60/158]| g_loss: 0.719| d_loss: 0.584| gp_loss: 0.055| r_loss: 0.060| p_loss: 0.086| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.561
Train: Epoch [1901/3000], Step [90/158]| g_loss: 0.662| d_loss: 0.651| gp_loss: 0.059| r_loss: 0.059| p_loss: 0.083| v_loss: 0.023| per_loss: 0.304 | a_loss: 0.508
Train: Epoch [1901/3000], Step [120/158]| g_loss: 0.679| d_loss: 0.615| gp_loss: 0.059| r_loss: 0.059| p_loss: 0.082| v_loss: 0.022| per_loss: 0.311 | a_loss: 0.527
Train: Epoch [1901/3000], Step [150/158]| g_loss: 0.642| d_loss: 0.648| gp_loss: 0.058| r_loss: 0.059| p_loss: 0.083| v_loss: 0.022| per_loss: 0.326 | a_loss: 0.487
Train: Epoch [1902/3000], Step [30/158]| g_loss: 0.743| d_loss: 0.654| gp_loss: 0.179| r_loss: 0.060| p_loss: 0.085| v_loss: 0.022| per_loss: 0.322 | a_loss: 0.587
Train: Epoch [1902/3000], Step [60/158]| g_loss: 0.675| d_loss: 0.569| gp_loss: 0.053| r_loss: 0.057| p_loss: 0.084| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.522
Train: Epoch [1902/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.623| gp_loss: 0.054| r_loss: 0.058| p_loss: 0.079| v_loss: 0.022| per_loss: 0.318 | a_loss: 0.503
Train: Epoch [1902/3000], Step [120/158]| g_loss: 0.684| d_loss: 0.675| gp_loss: 0.058| r_loss: 0.061| p_loss: 0.082| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.529
Train: Epoch [1902/3000], Step [150/158]| g_loss: 0.668| d_loss: 0.581| gp_loss: 0.061| r_loss: 0.058| p_loss: 0.079| v_loss: 0.022| per_loss: 0.326 | a_loss: 0.515
Train: Epoch [1903/3000], Step [30/158]| g_loss: 0.686| d_loss: 0.749| gp_loss: 0.117| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.532
Train: Epoch [1903/3000], Step [60/158]| g_loss: 0.634| d_loss: 0.647| gp_loss: 0.056| r_loss: 0.058| p_loss: 0.086| v_loss: 0.022| per_loss: 0.342 | a_loss: 0.477
Train: Epoch [1903/3000], Step [90/158]| g_loss: 0.709| d_loss: 0.578| gp_loss: 0.059| r_loss: 0.060| p_loss: 0.088| v_loss: 0.024| per_loss: 0.322 | a_loss: 0.550
Train: Epoch [1903/3000], Step [120/158]| g_loss: 0.714| d_loss: 0.612| gp_loss: 0.055| r_loss: 0.062| p_loss: 0.087| v_loss: 0.023| per_loss: 0.330 | a_loss: 0.552
Train: Epoch [1903/3000], Step [150/158]| g_loss: 0.717| d_loss: 0.575| gp_loss: 0.063| r_loss: 0.063| p_loss: 0.089| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.555
Train: Epoch [1904/3000], Step [30/158]| g_loss: 0.632| d_loss: 0.784| gp_loss: 0.141| r_loss: 0.060| p_loss: 0.090| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.472
Train: Epoch [1904/3000], Step [60/158]| g_loss: 0.735| d_loss: 0.525| gp_loss: 0.058| r_loss: 0.065| p_loss: 0.090| v_loss: 0.023| per_loss: 0.316 | a_loss: 0.570
Train: Epoch [1904/3000], Step [90/158]| g_loss: 0.749| d_loss: 0.547| gp_loss: 0.056| r_loss: 0.059| p_loss: 0.082| v_loss: 0.022| per_loss: 0.329 | a_loss: 0.594
Train: Epoch [1904/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.609| gp_loss: 0.061| r_loss: 0.059| p_loss: 0.086| v_loss: 0.023| per_loss: 0.332 | a_loss: 0.519
Train: Epoch [1904/3000], Step [150/158]| g_loss: 0.679| d_loss: 0.697| gp_loss: 0.059| r_loss: 0.059| p_loss: 0.085| v_loss: 0.022| per_loss: 0.322 | a_loss: 0.523
Train: Epoch [1905/3000], Step [30/158]| g_loss: 0.664| d_loss: 0.694| gp_loss: 0.147| r_loss: 0.059| p_loss: 0.083| v_loss: 0.022| per_loss: 0.326 | a_loss: 0.508
Train: Epoch [1905/3000], Step [60/158]| g_loss: 0.701| d_loss: 0.661| gp_loss: 0.054| r_loss: 0.061| p_loss: 0.085| v_loss: 0.021| per_loss: 0.317 | a_loss: 0.543
Train: Epoch [1905/3000], Step [90/158]| g_loss: 0.664| d_loss: 0.609| gp_loss: 0.058| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.509
Train: Epoch [1905/3000], Step [120/158]| g_loss: 0.688| d_loss: 0.592| gp_loss: 0.059| r_loss: 0.062| p_loss: 0.083| v_loss: 0.022| per_loss: 0.334 | a_loss: 0.529
Train: Epoch [1905/3000], Step [150/158]| g_loss: 0.671| d_loss: 0.584| gp_loss: 0.061| r_loss: 0.059| p_loss: 0.084| v_loss: 0.023| per_loss: 0.319 | a_loss: 0.515
Train: Epoch [1906/3000], Step [30/158]| g_loss: 0.685| d_loss: 0.738| gp_loss: 0.136| r_loss: 0.060| p_loss: 0.087| v_loss: 0.023| per_loss: 0.316 | a_loss: 0.527
Train: Epoch [1906/3000], Step [60/158]| g_loss: 0.689| d_loss: 0.587| gp_loss: 0.060| r_loss: 0.062| p_loss: 0.086| v_loss: 0.023| per_loss: 0.307 | a_loss: 0.531
Train: Epoch [1906/3000], Step [90/158]| g_loss: 0.684| d_loss: 0.610| gp_loss: 0.059| r_loss: 0.059| p_loss: 0.086| v_loss: 0.022| per_loss: 0.325 | a_loss: 0.527
Train: Epoch [1906/3000], Step [120/158]| g_loss: 0.732| d_loss: 0.560| gp_loss: 0.067| r_loss: 0.060| p_loss: 0.086| v_loss: 0.023| per_loss: 0.338 | a_loss: 0.573
Train: Epoch [1906/3000], Step [150/158]| g_loss: 0.694| d_loss: 0.623| gp_loss: 0.061| r_loss: 0.064| p_loss: 0.091| v_loss: 0.022| per_loss: 0.318 | a_loss: 0.531
Train: Epoch [1907/3000], Step [30/158]| g_loss: 0.728| d_loss: 0.625| gp_loss: 0.168| r_loss: 0.061| p_loss: 0.086| v_loss: 0.024| per_loss: 0.337 | a_loss: 0.567
Train: Epoch [1907/3000], Step [60/158]| g_loss: 0.704| d_loss: 0.696| gp_loss: 0.051| r_loss: 0.059| p_loss: 0.083| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.552
Train: Epoch [1907/3000], Step [90/158]| g_loss: 0.643| d_loss: 0.682| gp_loss: 0.057| r_loss: 0.060| p_loss: 0.085| v_loss: 0.022| per_loss: 0.338 | a_loss: 0.484
Train: Epoch [1907/3000], Step [120/158]| g_loss: 0.660| d_loss: 0.585| gp_loss: 0.060| r_loss: 0.058| p_loss: 0.081| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.508
Train: Epoch [1907/3000], Step [150/158]| g_loss: 0.708| d_loss: 0.586| gp_loss: 0.059| r_loss: 0.063| p_loss: 0.089| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.545
Train: Epoch [1908/3000], Step [30/158]| g_loss: 0.725| d_loss: 0.670| gp_loss: 0.162| r_loss: 0.061| p_loss: 0.087| v_loss: 0.022| per_loss: 0.326 | a_loss: 0.566
Train: Epoch [1908/3000], Step [60/158]| g_loss: 0.707| d_loss: 0.590| gp_loss: 0.059| r_loss: 0.059| p_loss: 0.085| v_loss: 0.023| per_loss: 0.327 | a_loss: 0.551
Train: Epoch [1908/3000], Step [90/158]| g_loss: 0.681| d_loss: 0.640| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.082| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.528
Train: Epoch [1908/3000], Step [120/158]| g_loss: 0.679| d_loss: 0.550| gp_loss: 0.052| r_loss: 0.060| p_loss: 0.085| v_loss: 0.023| per_loss: 0.317 | a_loss: 0.522
Train: Epoch [1908/3000], Step [150/158]| g_loss: 0.705| d_loss: 0.633| gp_loss: 0.057| r_loss: 0.060| p_loss: 0.085| v_loss: 0.022| per_loss: 0.332 | a_loss: 0.548
Train: Epoch [1909/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.751| gp_loss: 0.176| r_loss: 0.061| p_loss: 0.088| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.493
Train: Epoch [1909/3000], Step [60/158]| g_loss: 0.686| d_loss: 0.618| gp_loss: 0.053| r_loss: 0.060| p_loss: 0.084| v_loss: 0.022| per_loss: 0.337 | a_loss: 0.528
Train: Epoch [1909/3000], Step [90/158]| g_loss: 0.682| d_loss: 0.642| gp_loss: 0.054| r_loss: 0.059| p_loss: 0.084| v_loss: 0.023| per_loss: 0.314 | a_loss: 0.526
Train: Epoch [1909/3000], Step [120/158]| g_loss: 0.708| d_loss: 0.627| gp_loss: 0.060| r_loss: 0.060| p_loss: 0.084| v_loss: 0.023| per_loss: 0.336 | a_loss: 0.550
Train: Epoch [1909/3000], Step [150/158]| g_loss: 0.692| d_loss: 0.591| gp_loss: 0.061| r_loss: 0.060| p_loss: 0.085| v_loss: 0.022| per_loss: 0.323 | a_loss: 0.535
Train: Epoch [1910/3000], Step [30/158]| g_loss: 0.694| d_loss: 0.691| gp_loss: 0.121| r_loss: 0.061| p_loss: 0.087| v_loss: 0.022| per_loss: 0.322 | a_loss: 0.536
Train: Epoch [1910/3000], Step [60/158]| g_loss: 0.669| d_loss: 0.612| gp_loss: 0.055| r_loss: 0.061| p_loss: 0.088| v_loss: 0.023| per_loss: 0.321 | a_loss: 0.510
Train: Epoch [1910/3000], Step [90/158]| g_loss: 0.713| d_loss: 0.595| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.083| v_loss: 0.023| per_loss: 0.319 | a_loss: 0.558
Train: Epoch [1910/3000], Step [120/158]| g_loss: 0.738| d_loss: 0.562| gp_loss: 0.059| r_loss: 0.065| p_loss: 0.092| v_loss: 0.023| per_loss: 0.321 | a_loss: 0.572
Train: Epoch [1910/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.643| gp_loss: 0.053| r_loss: 0.065| p_loss: 0.087| v_loss: 0.023| per_loss: 0.319 | a_loss: 0.512
Train: Epoch [1911/3000], Step [30/158]| g_loss: 0.684| d_loss: 0.745| gp_loss: 0.137| r_loss: 0.063| p_loss: 0.091| v_loss: 0.023| per_loss: 0.318 | a_loss: 0.522
Train: Epoch [1911/3000], Step [60/158]| g_loss: 0.674| d_loss: 0.579| gp_loss: 0.054| r_loss: 0.064| p_loss: 0.090| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.510
Train: Epoch [1911/3000], Step [90/158]| g_loss: 0.687| d_loss: 0.616| gp_loss: 0.062| r_loss: 0.062| p_loss: 0.089| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.527
Train: Epoch [1911/3000], Step [120/158]| g_loss: 0.729| d_loss: 0.563| gp_loss: 0.059| r_loss: 0.061| p_loss: 0.089| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.568
Train: Epoch [1911/3000], Step [150/158]| g_loss: 0.668| d_loss: 0.670| gp_loss: 0.053| r_loss: 0.058| p_loss: 0.083| v_loss: 0.022| per_loss: 0.311 | a_loss: 0.515
Train: Epoch [1912/3000], Step [30/158]| g_loss: 0.684| d_loss: 0.705| gp_loss: 0.181| r_loss: 0.060| p_loss: 0.084| v_loss: 0.023| per_loss: 0.330 | a_loss: 0.526
Train: Epoch [1912/3000], Step [60/158]| g_loss: 0.699| d_loss: 0.559| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.083| v_loss: 0.022| per_loss: 0.302 | a_loss: 0.546
Train: Epoch [1912/3000], Step [90/158]| g_loss: 0.703| d_loss: 0.639| gp_loss: 0.055| r_loss: 0.057| p_loss: 0.082| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.551
Train: Epoch [1912/3000], Step [120/158]| g_loss: 0.687| d_loss: 0.592| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.084| v_loss: 0.023| per_loss: 0.336 | a_loss: 0.528
Train: Epoch [1912/3000], Step [150/158]| g_loss: 0.697| d_loss: 0.617| gp_loss: 0.056| r_loss: 0.060| p_loss: 0.084| v_loss: 0.022| per_loss: 0.326 | a_loss: 0.540
Train: Epoch [1913/3000], Step [30/158]| g_loss: 0.634| d_loss: 0.777| gp_loss: 0.097| r_loss: 0.061| p_loss: 0.089| v_loss: 0.023| per_loss: 0.299 | a_loss: 0.475
Train: Epoch [1913/3000], Step [60/158]| g_loss: 0.644| d_loss: 0.634| gp_loss: 0.056| r_loss: 0.063| p_loss: 0.087| v_loss: 0.023| per_loss: 0.339 | a_loss: 0.481
Train: Epoch [1913/3000], Step [90/158]| g_loss: 0.716| d_loss: 0.601| gp_loss: 0.064| r_loss: 0.062| p_loss: 0.089| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.556
Train: Epoch [1913/3000], Step [120/158]| g_loss: 0.707| d_loss: 0.565| gp_loss: 0.056| r_loss: 0.059| p_loss: 0.085| v_loss: 0.022| per_loss: 0.334 | a_loss: 0.550
Train: Epoch [1913/3000], Step [150/158]| g_loss: 0.685| d_loss: 0.593| gp_loss: 0.059| r_loss: 0.058| p_loss: 0.085| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.531
Train: Epoch [1914/3000], Step [30/158]| g_loss: 0.685| d_loss: 0.699| gp_loss: 0.165| r_loss: 0.061| p_loss: 0.086| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.525
Train: Epoch [1914/3000], Step [60/158]| g_loss: 0.723| d_loss: 0.629| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.082| v_loss: 0.022| per_loss: 0.304 | a_loss: 0.570
Train: Epoch [1914/3000], Step [90/158]| g_loss: 0.667| d_loss: 0.529| gp_loss: 0.057| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.326 | a_loss: 0.511
Train: Epoch [1914/3000], Step [120/158]| g_loss: 0.747| d_loss: 0.595| gp_loss: 0.056| r_loss: 0.060| p_loss: 0.085| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.592
Train: Epoch [1914/3000], Step [150/158]| g_loss: 0.660| d_loss: 0.670| gp_loss: 0.059| r_loss: 0.061| p_loss: 0.086| v_loss: 0.023| per_loss: 0.317 | a_loss: 0.501
Train: Epoch [1915/3000], Step [30/158]| g_loss: 0.677| d_loss: 0.709| gp_loss: 0.156| r_loss: 0.059| p_loss: 0.085| v_loss: 0.023| per_loss: 0.311 | a_loss: 0.522
Train: Epoch [1915/3000], Step [60/158]| g_loss: 0.703| d_loss: 0.580| gp_loss: 0.055| r_loss: 0.060| p_loss: 0.084| v_loss: 0.023| per_loss: 0.322 | a_loss: 0.546
Train: Epoch [1915/3000], Step [90/158]| g_loss: 0.683| d_loss: 0.574| gp_loss: 0.056| r_loss: 0.062| p_loss: 0.081| v_loss: 0.022| per_loss: 0.329 | a_loss: 0.526
Train: Epoch [1915/3000], Step [120/158]| g_loss: 0.727| d_loss: 0.607| gp_loss: 0.057| r_loss: 0.058| p_loss: 0.082| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.576
Train: Epoch [1915/3000], Step [150/158]| g_loss: 0.680| d_loss: 0.677| gp_loss: 0.054| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.325 | a_loss: 0.525
Train: Epoch [1916/3000], Step [30/158]| g_loss: 0.659| d_loss: 0.714| gp_loss: 0.174| r_loss: 0.060| p_loss: 0.085| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.501
Train: Epoch [1916/3000], Step [60/158]| g_loss: 0.638| d_loss: 0.659| gp_loss: 0.054| r_loss: 0.058| p_loss: 0.084| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.485
Train: Epoch [1916/3000], Step [90/158]| g_loss: 0.696| d_loss: 0.605| gp_loss: 0.057| r_loss: 0.061| p_loss: 0.085| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.537
Train: Epoch [1916/3000], Step [120/158]| g_loss: 0.702| d_loss: 0.542| gp_loss: 0.056| r_loss: 0.059| p_loss: 0.082| v_loss: 0.022| per_loss: 0.318 | a_loss: 0.549
Train: Epoch [1916/3000], Step [150/158]| g_loss: 0.674| d_loss: 0.686| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.081| v_loss: 0.022| per_loss: 0.323 | a_loss: 0.520
Train: Epoch [1917/3000], Step [30/158]| g_loss: 0.694| d_loss: 0.675| gp_loss: 0.148| r_loss: 0.059| p_loss: 0.083| v_loss: 0.022| per_loss: 0.323 | a_loss: 0.540
Train: Epoch [1917/3000], Step [60/158]| g_loss: 0.708| d_loss: 0.567| gp_loss: 0.056| r_loss: 0.059| p_loss: 0.083| v_loss: 0.022| per_loss: 0.328 | a_loss: 0.552
Train: Epoch [1917/3000], Step [90/158]| g_loss: 0.653| d_loss: 0.678| gp_loss: 0.055| r_loss: 0.060| p_loss: 0.085| v_loss: 0.022| per_loss: 0.322 | a_loss: 0.496
Train: Epoch [1917/3000], Step [120/158]| g_loss: 0.649| d_loss: 0.686| gp_loss: 0.057| r_loss: 0.063| p_loss: 0.089| v_loss: 0.022| per_loss: 0.325 | a_loss: 0.487
Train: Epoch [1917/3000], Step [150/158]| g_loss: 0.681| d_loss: 0.543| gp_loss: 0.059| r_loss: 0.059| p_loss: 0.085| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.525
Train: Epoch [1918/3000], Step [30/158]| g_loss: 0.728| d_loss: 0.672| gp_loss: 0.187| r_loss: 0.063| p_loss: 0.086| v_loss: 0.024| per_loss: 0.322 | a_loss: 0.567
Train: Epoch [1918/3000], Step [60/158]| g_loss: 0.726| d_loss: 0.607| gp_loss: 0.053| r_loss: 0.059| p_loss: 0.084| v_loss: 0.023| per_loss: 0.335 | a_loss: 0.568
Train: Epoch [1918/3000], Step [90/158]| g_loss: 0.713| d_loss: 0.623| gp_loss: 0.052| r_loss: 0.061| p_loss: 0.090| v_loss: 0.022| per_loss: 0.303 | a_loss: 0.555
Train: Epoch [1918/3000], Step [120/158]| g_loss: 0.664| d_loss: 0.666| gp_loss: 0.050| r_loss: 0.061| p_loss: 0.085| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.507
Train: Epoch [1918/3000], Step [150/158]| g_loss: 0.634| d_loss: 0.691| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.087| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.476
Train: Epoch [1919/3000], Step [30/158]| g_loss: 0.697| d_loss: 0.645| gp_loss: 0.145| r_loss: 0.062| p_loss: 0.089| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.536
Train: Epoch [1919/3000], Step [60/158]| g_loss: 0.705| d_loss: 0.597| gp_loss: 0.050| r_loss: 0.060| p_loss: 0.088| v_loss: 0.023| per_loss: 0.318 | a_loss: 0.546
Train: Epoch [1919/3000], Step [90/158]| g_loss: 0.677| d_loss: 0.613| gp_loss: 0.055| r_loss: 0.058| p_loss: 0.081| v_loss: 0.022| per_loss: 0.303 | a_loss: 0.526
Train: Epoch [1919/3000], Step [120/158]| g_loss: 0.678| d_loss: 0.600| gp_loss: 0.054| r_loss: 0.058| p_loss: 0.081| v_loss: 0.022| per_loss: 0.328 | a_loss: 0.525
Train: Epoch [1919/3000], Step [150/158]| g_loss: 0.677| d_loss: 0.620| gp_loss: 0.058| r_loss: 0.065| p_loss: 0.088| v_loss: 0.023| per_loss: 0.324 | a_loss: 0.513
Train: Epoch [1920/3000], Step [30/158]| g_loss: 0.688| d_loss: 0.772| gp_loss: 0.180| r_loss: 0.059| p_loss: 0.083| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.534
Train: Epoch [1920/3000], Step [60/158]| g_loss: 0.645| d_loss: 0.612| gp_loss: 0.054| r_loss: 0.061| p_loss: 0.088| v_loss: 0.023| per_loss: 0.337 | a_loss: 0.484
Train: Epoch [1920/3000], Step [90/158]| g_loss: 0.669| d_loss: 0.602| gp_loss: 0.056| r_loss: 0.058| p_loss: 0.083| v_loss: 0.022| per_loss: 0.331 | a_loss: 0.514
Train: Epoch [1920/3000], Step [120/158]| g_loss: 0.695| d_loss: 0.643| gp_loss: 0.056| r_loss: 0.059| p_loss: 0.082| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.540
Train: Epoch [1920/3000], Step [150/158]| g_loss: 0.710| d_loss: 0.610| gp_loss: 0.057| r_loss: 0.061| p_loss: 0.085| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.554
Train: Epoch [1921/3000], Step [30/158]| g_loss: 0.693| d_loss: 0.690| gp_loss: 0.127| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.540
Train: Epoch [1921/3000], Step [60/158]| g_loss: 0.675| d_loss: 0.605| gp_loss: 0.057| r_loss: 0.059| p_loss: 0.086| v_loss: 0.023| per_loss: 0.337 | a_loss: 0.516
Train: Epoch [1921/3000], Step [90/158]| g_loss: 0.700| d_loss: 0.580| gp_loss: 0.054| r_loss: 0.061| p_loss: 0.086| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.542
Train: Epoch [1921/3000], Step [120/158]| g_loss: 0.694| d_loss: 0.592| gp_loss: 0.056| r_loss: 0.060| p_loss: 0.083| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.540
Train: Epoch [1921/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.615| gp_loss: 0.057| r_loss: 0.060| p_loss: 0.087| v_loss: 0.023| per_loss: 0.321 | a_loss: 0.503
Train: Epoch [1922/3000], Step [30/158]| g_loss: 0.747| d_loss: 0.632| gp_loss: 0.168| r_loss: 0.062| p_loss: 0.087| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.587
Train: Epoch [1922/3000], Step [60/158]| g_loss: 0.695| d_loss: 0.585| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.339 | a_loss: 0.544
Train: Epoch [1922/3000], Step [90/158]| g_loss: 0.658| d_loss: 0.718| gp_loss: 0.052| r_loss: 0.063| p_loss: 0.089| v_loss: 0.023| per_loss: 0.322 | a_loss: 0.496
Train: Epoch [1922/3000], Step [120/158]| g_loss: 0.709| d_loss: 0.556| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.084| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.553
Train: Epoch [1922/3000], Step [150/158]| g_loss: 0.691| d_loss: 0.616| gp_loss: 0.054| r_loss: 0.060| p_loss: 0.088| v_loss: 0.024| per_loss: 0.322 | a_loss: 0.531
Train: Epoch [1923/3000], Step [30/158]| g_loss: 0.683| d_loss: 0.703| gp_loss: 0.140| r_loss: 0.060| p_loss: 0.083| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.528
Train: Epoch [1923/3000], Step [60/158]| g_loss: 0.688| d_loss: 0.551| gp_loss: 0.055| r_loss: 0.058| p_loss: 0.082| v_loss: 0.022| per_loss: 0.323 | a_loss: 0.535
Train: Epoch [1923/3000], Step [90/158]| g_loss: 0.683| d_loss: 0.629| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.082| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.530
Train: Epoch [1923/3000], Step [120/158]| g_loss: 0.724| d_loss: 0.575| gp_loss: 0.058| r_loss: 0.061| p_loss: 0.084| v_loss: 0.023| per_loss: 0.321 | a_loss: 0.566
Train: Epoch [1923/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.664| gp_loss: 0.057| r_loss: 0.060| p_loss: 0.091| v_loss: 0.022| per_loss: 0.300 | a_loss: 0.500
Train: Epoch [1924/3000], Step [30/158]| g_loss: 0.710| d_loss: 0.700| gp_loss: 0.138| r_loss: 0.059| p_loss: 0.087| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.554
Train: Epoch [1924/3000], Step [60/158]| g_loss: 0.641| d_loss: 0.577| gp_loss: 0.056| r_loss: 0.059| p_loss: 0.083| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.489
Train: Epoch [1924/3000], Step [90/158]| g_loss: 0.691| d_loss: 0.637| gp_loss: 0.057| r_loss: 0.060| p_loss: 0.084| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.537
Train: Epoch [1924/3000], Step [120/158]| g_loss: 0.687| d_loss: 0.626| gp_loss: 0.060| r_loss: 0.061| p_loss: 0.085| v_loss: 0.024| per_loss: 0.320 | a_loss: 0.528
Train: Epoch [1924/3000], Step [150/158]| g_loss: 0.702| d_loss: 0.580| gp_loss: 0.059| r_loss: 0.060| p_loss: 0.085| v_loss: 0.023| per_loss: 0.312 | a_loss: 0.546
Train: Epoch [1925/3000], Step [30/158]| g_loss: 0.698| d_loss: 0.673| gp_loss: 0.173| r_loss: 0.060| p_loss: 0.083| v_loss: 0.022| per_loss: 0.329 | a_loss: 0.542
Train: Epoch [1925/3000], Step [60/158]| g_loss: 0.727| d_loss: 0.620| gp_loss: 0.054| r_loss: 0.060| p_loss: 0.081| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.575
Train: Epoch [1925/3000], Step [90/158]| g_loss: 0.643| d_loss: 0.680| gp_loss: 0.051| r_loss: 0.061| p_loss: 0.085| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.487
Train: Epoch [1925/3000], Step [120/158]| g_loss: 0.705| d_loss: 0.543| gp_loss: 0.056| r_loss: 0.058| p_loss: 0.081| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.553
Train: Epoch [1925/3000], Step [150/158]| g_loss: 0.697| d_loss: 0.592| gp_loss: 0.057| r_loss: 0.060| p_loss: 0.083| v_loss: 0.022| per_loss: 0.300 | a_loss: 0.544
Train: Epoch [1926/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.722| gp_loss: 0.094| r_loss: 0.059| p_loss: 0.089| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.494
Train: Epoch [1926/3000], Step [60/158]| g_loss: 0.692| d_loss: 0.585| gp_loss: 0.055| r_loss: 0.057| p_loss: 0.083| v_loss: 0.022| per_loss: 0.303 | a_loss: 0.541
Train: Epoch [1926/3000], Step [90/158]| g_loss: 0.687| d_loss: 0.617| gp_loss: 0.061| r_loss: 0.059| p_loss: 0.082| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.532
Train: Epoch [1926/3000], Step [120/158]| g_loss: 0.704| d_loss: 0.580| gp_loss: 0.058| r_loss: 0.058| p_loss: 0.085| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.548
Train: Epoch [1926/3000], Step [150/158]| g_loss: 0.648| d_loss: 0.664| gp_loss: 0.055| r_loss: 0.061| p_loss: 0.080| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.494
Train: Epoch [1927/3000], Step [30/158]| g_loss: 0.672| d_loss: 0.748| gp_loss: 0.162| r_loss: 0.059| p_loss: 0.086| v_loss: 0.022| per_loss: 0.323 | a_loss: 0.516
Train: Epoch [1927/3000], Step [60/158]| g_loss: 0.698| d_loss: 0.615| gp_loss: 0.061| r_loss: 0.060| p_loss: 0.087| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.540
Train: Epoch [1927/3000], Step [90/158]| g_loss: 0.695| d_loss: 0.538| gp_loss: 0.059| r_loss: 0.060| p_loss: 0.084| v_loss: 0.023| per_loss: 0.318 | a_loss: 0.538
Train: Epoch [1927/3000], Step [120/158]| g_loss: 0.744| d_loss: 0.575| gp_loss: 0.057| r_loss: 0.064| p_loss: 0.087| v_loss: 0.023| per_loss: 0.309 | a_loss: 0.583
Train: Epoch [1927/3000], Step [150/158]| g_loss: 0.641| d_loss: 0.691| gp_loss: 0.056| r_loss: 0.060| p_loss: 0.088| v_loss: 0.022| per_loss: 0.322 | a_loss: 0.484
Train: Epoch [1928/3000], Step [30/158]| g_loss: 0.710| d_loss: 0.666| gp_loss: 0.148| r_loss: 0.062| p_loss: 0.088| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.550
Train: Epoch [1928/3000], Step [60/158]| g_loss: 0.724| d_loss: 0.532| gp_loss: 0.054| r_loss: 0.062| p_loss: 0.089| v_loss: 0.023| per_loss: 0.324 | a_loss: 0.562
Train: Epoch [1928/3000], Step [90/158]| g_loss: 0.708| d_loss: 0.647| gp_loss: 0.054| r_loss: 0.057| p_loss: 0.082| v_loss: 0.022| per_loss: 0.328 | a_loss: 0.556
Train: Epoch [1928/3000], Step [120/158]| g_loss: 0.635| d_loss: 0.651| gp_loss: 0.056| r_loss: 0.058| p_loss: 0.081| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.483
Train: Epoch [1928/3000], Step [150/158]| g_loss: 0.685| d_loss: 0.605| gp_loss: 0.059| r_loss: 0.061| p_loss: 0.085| v_loss: 0.022| per_loss: 0.304 | a_loss: 0.528
Train: Epoch [1929/3000], Step [30/158]| g_loss: 0.664| d_loss: 0.668| gp_loss: 0.172| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.321 | a_loss: 0.517
Train: Epoch [1929/3000], Step [60/158]| g_loss: 0.731| d_loss: 0.599| gp_loss: 0.055| r_loss: 0.063| p_loss: 0.088| v_loss: 0.023| per_loss: 0.309 | a_loss: 0.570
Train: Epoch [1929/3000], Step [90/158]| g_loss: 0.686| d_loss: 0.607| gp_loss: 0.050| r_loss: 0.060| p_loss: 0.084| v_loss: 0.022| per_loss: 0.304 | a_loss: 0.531
Train: Epoch [1929/3000], Step [120/158]| g_loss: 0.695| d_loss: 0.625| gp_loss: 0.056| r_loss: 0.067| p_loss: 0.091| v_loss: 0.023| per_loss: 0.314 | a_loss: 0.528
Train: Epoch [1929/3000], Step [150/158]| g_loss: 0.704| d_loss: 0.634| gp_loss: 0.058| r_loss: 0.064| p_loss: 0.091| v_loss: 0.022| per_loss: 0.326 | a_loss: 0.541
Train: Epoch [1930/3000], Step [30/158]| g_loss: 0.615| d_loss: 0.801| gp_loss: 0.170| r_loss: 0.061| p_loss: 0.088| v_loss: 0.022| per_loss: 0.320 | a_loss: 0.455
Train: Epoch [1930/3000], Step [60/158]| g_loss: 0.676| d_loss: 0.554| gp_loss: 0.055| r_loss: 0.058| p_loss: 0.082| v_loss: 0.022| per_loss: 0.320 | a_loss: 0.523
Train: Epoch [1930/3000], Step [90/158]| g_loss: 0.690| d_loss: 0.637| gp_loss: 0.055| r_loss: 0.062| p_loss: 0.091| v_loss: 0.022| per_loss: 0.305 | a_loss: 0.531
Train: Epoch [1930/3000], Step [120/158]| g_loss: 0.725| d_loss: 0.598| gp_loss: 0.058| r_loss: 0.062| p_loss: 0.085| v_loss: 0.022| per_loss: 0.323 | a_loss: 0.566
Train: Epoch [1930/3000], Step [150/158]| g_loss: 0.677| d_loss: 0.585| gp_loss: 0.058| r_loss: 0.060| p_loss: 0.083| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.521
Train: Epoch [1931/3000], Step [30/158]| g_loss: 0.690| d_loss: 0.716| gp_loss: 0.163| r_loss: 0.059| p_loss: 0.083| v_loss: 0.022| per_loss: 0.306 | a_loss: 0.536
Train: Epoch [1931/3000], Step [60/158]| g_loss: 0.686| d_loss: 0.659| gp_loss: 0.053| r_loss: 0.065| p_loss: 0.089| v_loss: 0.023| per_loss: 0.322 | a_loss: 0.522
Train: Epoch [1931/3000], Step [90/158]| g_loss: 0.675| d_loss: 0.531| gp_loss: 0.059| r_loss: 0.063| p_loss: 0.091| v_loss: 0.022| per_loss: 0.320 | a_loss: 0.512
Train: Epoch [1931/3000], Step [120/158]| g_loss: 0.723| d_loss: 0.599| gp_loss: 0.058| r_loss: 0.058| p_loss: 0.083| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.570
Train: Epoch [1931/3000], Step [150/158]| g_loss: 0.692| d_loss: 0.612| gp_loss: 0.057| r_loss: 0.058| p_loss: 0.081| v_loss: 0.022| per_loss: 0.328 | a_loss: 0.538
Train: Epoch [1932/3000], Step [30/158]| g_loss: 0.649| d_loss: 0.757| gp_loss: 0.165| r_loss: 0.061| p_loss: 0.088| v_loss: 0.023| per_loss: 0.328 | a_loss: 0.488
Train: Epoch [1932/3000], Step [60/158]| g_loss: 0.722| d_loss: 0.590| gp_loss: 0.056| r_loss: 0.060| p_loss: 0.085| v_loss: 0.022| per_loss: 0.328 | a_loss: 0.565
Train: Epoch [1932/3000], Step [90/158]| g_loss: 0.685| d_loss: 0.628| gp_loss: 0.058| r_loss: 0.061| p_loss: 0.086| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.528
Train: Epoch [1932/3000], Step [120/158]| g_loss: 0.660| d_loss: 0.617| gp_loss: 0.055| r_loss: 0.061| p_loss: 0.088| v_loss: 0.023| per_loss: 0.313 | a_loss: 0.501
Train: Epoch [1932/3000], Step [150/158]| g_loss: 0.733| d_loss: 0.576| gp_loss: 0.062| r_loss: 0.057| p_loss: 0.080| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.581
Train: Epoch [1933/3000], Step [30/158]| g_loss: 0.706| d_loss: 0.736| gp_loss: 0.179| r_loss: 0.059| p_loss: 0.085| v_loss: 0.023| per_loss: 0.346 | a_loss: 0.547
Train: Epoch [1933/3000], Step [60/158]| g_loss: 0.646| d_loss: 0.709| gp_loss: 0.052| r_loss: 0.060| p_loss: 0.086| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.491
Train: Epoch [1933/3000], Step [90/158]| g_loss: 0.640| d_loss: 0.643| gp_loss: 0.055| r_loss: 0.062| p_loss: 0.087| v_loss: 0.022| per_loss: 0.324 | a_loss: 0.480
Train: Epoch [1933/3000], Step [120/158]| g_loss: 0.744| d_loss: 0.485| gp_loss: 0.058| r_loss: 0.065| p_loss: 0.087| v_loss: 0.023| per_loss: 0.319 | a_loss: 0.581
Train: Epoch [1933/3000], Step [150/158]| g_loss: 0.747| d_loss: 0.547| gp_loss: 0.055| r_loss: 0.061| p_loss: 0.085| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.590
Train: Epoch [1934/3000], Step [30/158]| g_loss: 0.683| d_loss: 0.688| gp_loss: 0.123| r_loss: 0.061| p_loss: 0.084| v_loss: 0.023| per_loss: 0.324 | a_loss: 0.524
Train: Epoch [1934/3000], Step [60/158]| g_loss: 0.670| d_loss: 0.576| gp_loss: 0.053| r_loss: 0.060| p_loss: 0.084| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.514
Train: Epoch [1934/3000], Step [90/158]| g_loss: 0.766| d_loss: 0.567| gp_loss: 0.060| r_loss: 0.063| p_loss: 0.086| v_loss: 0.023| per_loss: 0.314 | a_loss: 0.605
Train: Epoch [1934/3000], Step [120/158]| g_loss: 0.704| d_loss: 0.576| gp_loss: 0.053| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.311 | a_loss: 0.551
Train: Epoch [1934/3000], Step [150/158]| g_loss: 0.671| d_loss: 0.712| gp_loss: 0.056| r_loss: 0.060| p_loss: 0.086| v_loss: 0.022| per_loss: 0.307 | a_loss: 0.516
Train: Epoch [1935/3000], Step [30/158]| g_loss: 0.628| d_loss: 0.787| gp_loss: 0.169| r_loss: 0.059| p_loss: 0.088| v_loss: 0.023| per_loss: 0.315 | a_loss: 0.470
Train: Epoch [1935/3000], Step [60/158]| g_loss: 0.640| d_loss: 0.663| gp_loss: 0.054| r_loss: 0.058| p_loss: 0.082| v_loss: 0.023| per_loss: 0.312 | a_loss: 0.487
Train: Epoch [1935/3000], Step [90/158]| g_loss: 0.664| d_loss: 0.636| gp_loss: 0.057| r_loss: 0.059| p_loss: 0.081| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.511
Train: Epoch [1935/3000], Step [120/158]| g_loss: 0.738| d_loss: 0.524| gp_loss: 0.054| r_loss: 0.060| p_loss: 0.088| v_loss: 0.023| per_loss: 0.312 | a_loss: 0.579
Train: Epoch [1935/3000], Step [150/158]| g_loss: 0.710| d_loss: 0.588| gp_loss: 0.054| r_loss: 0.059| p_loss: 0.083| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.556
Train: Epoch [1936/3000], Step [30/158]| g_loss: 0.669| d_loss: 0.695| gp_loss: 0.113| r_loss: 0.058| p_loss: 0.080| v_loss: 0.022| per_loss: 0.318 | a_loss: 0.517
Train: Epoch [1936/3000], Step [60/158]| g_loss: 0.697| d_loss: 0.593| gp_loss: 0.058| r_loss: 0.059| p_loss: 0.082| v_loss: 0.022| per_loss: 0.305 | a_loss: 0.545
Train: Epoch [1936/3000], Step [90/158]| g_loss: 0.709| d_loss: 0.537| gp_loss: 0.057| r_loss: 0.058| p_loss: 0.081| v_loss: 0.023| per_loss: 0.321 | a_loss: 0.555
Train: Epoch [1936/3000], Step [120/158]| g_loss: 0.669| d_loss: 0.595| gp_loss: 0.053| r_loss: 0.059| p_loss: 0.083| v_loss: 0.023| per_loss: 0.317 | a_loss: 0.515
Train: Epoch [1936/3000], Step [150/158]| g_loss: 0.671| d_loss: 0.662| gp_loss: 0.060| r_loss: 0.060| p_loss: 0.084| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.515
Train: Epoch [1937/3000], Step [30/158]| g_loss: 0.660| d_loss: 0.693| gp_loss: 0.114| r_loss: 0.060| p_loss: 0.086| v_loss: 0.022| per_loss: 0.326 | a_loss: 0.503
Train: Epoch [1937/3000], Step [60/158]| g_loss: 0.724| d_loss: 0.536| gp_loss: 0.056| r_loss: 0.060| p_loss: 0.079| v_loss: 0.022| per_loss: 0.324 | a_loss: 0.570
Train: Epoch [1937/3000], Step [90/158]| g_loss: 0.676| d_loss: 0.644| gp_loss: 0.059| r_loss: 0.061| p_loss: 0.086| v_loss: 0.023| per_loss: 0.313 | a_loss: 0.518
Train: Epoch [1937/3000], Step [120/158]| g_loss: 0.665| d_loss: 0.647| gp_loss: 0.059| r_loss: 0.057| p_loss: 0.082| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.513
Train: Epoch [1937/3000], Step [150/158]| g_loss: 0.700| d_loss: 0.648| gp_loss: 0.062| r_loss: 0.062| p_loss: 0.091| v_loss: 0.023| per_loss: 0.322 | a_loss: 0.537
Train: Epoch [1938/3000], Step [30/158]| g_loss: 0.690| d_loss: 0.731| gp_loss: 0.202| r_loss: 0.063| p_loss: 0.092| v_loss: 0.023| per_loss: 0.316 | a_loss: 0.527
Train: Epoch [1938/3000], Step [60/158]| g_loss: 0.653| d_loss: 0.619| gp_loss: 0.054| r_loss: 0.058| p_loss: 0.084| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.500
Train: Epoch [1938/3000], Step [90/158]| g_loss: 0.692| d_loss: 0.634| gp_loss: 0.059| r_loss: 0.063| p_loss: 0.088| v_loss: 0.022| per_loss: 0.324 | a_loss: 0.531
Train: Epoch [1938/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.586| gp_loss: 0.060| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.326 | a_loss: 0.521
Train: Epoch [1938/3000], Step [150/158]| g_loss: 0.765| d_loss: 0.627| gp_loss: 0.056| r_loss: 0.060| p_loss: 0.085| v_loss: 0.023| per_loss: 0.332 | a_loss: 0.606
Train: Epoch [1939/3000], Step [30/158]| g_loss: 0.644| d_loss: 0.725| gp_loss: 0.110| r_loss: 0.060| p_loss: 0.088| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.485
Train: Epoch [1939/3000], Step [60/158]| g_loss: 0.672| d_loss: 0.601| gp_loss: 0.056| r_loss: 0.060| p_loss: 0.084| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.515
Train: Epoch [1939/3000], Step [90/158]| g_loss: 0.641| d_loss: 0.681| gp_loss: 0.059| r_loss: 0.061| p_loss: 0.087| v_loss: 0.023| per_loss: 0.324 | a_loss: 0.481
Train: Epoch [1939/3000], Step [120/158]| g_loss: 0.706| d_loss: 0.590| gp_loss: 0.059| r_loss: 0.060| p_loss: 0.086| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.551
Train: Epoch [1939/3000], Step [150/158]| g_loss: 0.674| d_loss: 0.584| gp_loss: 0.065| r_loss: 0.058| p_loss: 0.084| v_loss: 0.022| per_loss: 0.311 | a_loss: 0.521
Train: Epoch [1940/3000], Step [30/158]| g_loss: 0.671| d_loss: 0.820| gp_loss: 0.186| r_loss: 0.062| p_loss: 0.082| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.515
Train: Epoch [1940/3000], Step [60/158]| g_loss: 0.699| d_loss: 0.539| gp_loss: 0.057| r_loss: 0.057| p_loss: 0.081| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.548
Train: Epoch [1940/3000], Step [90/158]| g_loss: 0.722| d_loss: 0.589| gp_loss: 0.056| r_loss: 0.064| p_loss: 0.091| v_loss: 0.022| per_loss: 0.323 | a_loss: 0.558
Train: Epoch [1940/3000], Step [120/158]| g_loss: 0.707| d_loss: 0.578| gp_loss: 0.056| r_loss: 0.063| p_loss: 0.085| v_loss: 0.023| per_loss: 0.312 | a_loss: 0.548
Train: Epoch [1940/3000], Step [150/158]| g_loss: 0.699| d_loss: 0.614| gp_loss: 0.056| r_loss: 0.059| p_loss: 0.089| v_loss: 0.022| per_loss: 0.323 | a_loss: 0.540
Train: Epoch [1941/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.747| gp_loss: 0.190| r_loss: 0.058| p_loss: 0.082| v_loss: 0.022| per_loss: 0.305 | a_loss: 0.511
Train: Epoch [1941/3000], Step [60/158]| g_loss: 0.657| d_loss: 0.654| gp_loss: 0.051| r_loss: 0.060| p_loss: 0.084| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.503
Train: Epoch [1941/3000], Step [90/158]| g_loss: 0.684| d_loss: 0.627| gp_loss: 0.057| r_loss: 0.060| p_loss: 0.084| v_loss: 0.022| per_loss: 0.324 | a_loss: 0.528
Train: Epoch [1941/3000], Step [120/158]| g_loss: 0.702| d_loss: 0.532| gp_loss: 0.057| r_loss: 0.058| p_loss: 0.082| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.549
Train: Epoch [1941/3000], Step [150/158]| g_loss: 0.712| d_loss: 0.600| gp_loss: 0.055| r_loss: 0.060| p_loss: 0.079| v_loss: 0.021| per_loss: 0.319 | a_loss: 0.559
Train: Epoch [1942/3000], Step [30/158]| g_loss: 0.705| d_loss: 0.616| gp_loss: 0.141| r_loss: 0.058| p_loss: 0.079| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.554
Train: Epoch [1942/3000], Step [60/158]| g_loss: 0.700| d_loss: 0.637| gp_loss: 0.052| r_loss: 0.060| p_loss: 0.085| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.544
Train: Epoch [1942/3000], Step [90/158]| g_loss: 0.660| d_loss: 0.616| gp_loss: 0.054| r_loss: 0.058| p_loss: 0.080| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.508
Train: Epoch [1942/3000], Step [120/158]| g_loss: 0.658| d_loss: 0.636| gp_loss: 0.058| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.323 | a_loss: 0.503
Train: Epoch [1942/3000], Step [150/158]| g_loss: 0.723| d_loss: 0.618| gp_loss: 0.057| r_loss: 0.062| p_loss: 0.085| v_loss: 0.023| per_loss: 0.309 | a_loss: 0.565
Train: Epoch [1943/3000], Step [30/158]| g_loss: 0.649| d_loss: 0.784| gp_loss: 0.106| r_loss: 0.061| p_loss: 0.087| v_loss: 0.022| per_loss: 0.346 | a_loss: 0.489
Train: Epoch [1943/3000], Step [60/158]| g_loss: 0.676| d_loss: 0.682| gp_loss: 0.058| r_loss: 0.062| p_loss: 0.090| v_loss: 0.023| per_loss: 0.316 | a_loss: 0.515
Train: Epoch [1943/3000], Step [90/158]| g_loss: 0.643| d_loss: 0.602| gp_loss: 0.057| r_loss: 0.062| p_loss: 0.089| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.484
Train: Epoch [1943/3000], Step [120/158]| g_loss: 0.733| d_loss: 0.557| gp_loss: 0.059| r_loss: 0.063| p_loss: 0.092| v_loss: 0.023| per_loss: 0.317 | a_loss: 0.570
Train: Epoch [1943/3000], Step [150/158]| g_loss: 0.694| d_loss: 0.596| gp_loss: 0.059| r_loss: 0.063| p_loss: 0.086| v_loss: 0.022| per_loss: 0.318 | a_loss: 0.534
Train: Epoch [1944/3000], Step [30/158]| g_loss: 0.673| d_loss: 0.718| gp_loss: 0.120| r_loss: 0.060| p_loss: 0.084| v_loss: 0.023| per_loss: 0.324 | a_loss: 0.516
Train: Epoch [1944/3000], Step [60/158]| g_loss: 0.659| d_loss: 0.636| gp_loss: 0.059| r_loss: 0.058| p_loss: 0.084| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.505
Train: Epoch [1944/3000], Step [90/158]| g_loss: 0.729| d_loss: 0.516| gp_loss: 0.060| r_loss: 0.061| p_loss: 0.083| v_loss: 0.021| per_loss: 0.321 | a_loss: 0.574
Train: Epoch [1944/3000], Step [120/158]| g_loss: 0.664| d_loss: 0.592| gp_loss: 0.061| r_loss: 0.056| p_loss: 0.076| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.517
Train: Epoch [1944/3000], Step [150/158]| g_loss: 0.733| d_loss: 0.619| gp_loss: 0.063| r_loss: 0.061| p_loss: 0.087| v_loss: 0.023| per_loss: 0.315 | a_loss: 0.575
Train: Epoch [1945/3000], Step [30/158]| g_loss: 0.705| d_loss: 0.724| gp_loss: 0.186| r_loss: 0.058| p_loss: 0.084| v_loss: 0.022| per_loss: 0.307 | a_loss: 0.553
Train: Epoch [1945/3000], Step [60/158]| g_loss: 0.687| d_loss: 0.582| gp_loss: 0.054| r_loss: 0.061| p_loss: 0.087| v_loss: 0.023| per_loss: 0.322 | a_loss: 0.527
Train: Epoch [1945/3000], Step [90/158]| g_loss: 0.703| d_loss: 0.638| gp_loss: 0.052| r_loss: 0.060| p_loss: 0.086| v_loss: 0.022| per_loss: 0.331 | a_loss: 0.545
Train: Epoch [1945/3000], Step [120/158]| g_loss: 0.695| d_loss: 0.612| gp_loss: 0.060| r_loss: 0.060| p_loss: 0.087| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.539
Train: Epoch [1945/3000], Step [150/158]| g_loss: 0.654| d_loss: 0.667| gp_loss: 0.057| r_loss: 0.060| p_loss: 0.085| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.498
Train: Epoch [1946/3000], Step [30/158]| g_loss: 0.661| d_loss: 0.717| gp_loss: 0.105| r_loss: 0.059| p_loss: 0.086| v_loss: 0.023| per_loss: 0.315 | a_loss: 0.505
Train: Epoch [1946/3000], Step [60/158]| g_loss: 0.657| d_loss: 0.619| gp_loss: 0.055| r_loss: 0.060| p_loss: 0.089| v_loss: 0.023| per_loss: 0.318 | a_loss: 0.497
Train: Epoch [1946/3000], Step [90/158]| g_loss: 0.716| d_loss: 0.571| gp_loss: 0.058| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.561
Train: Epoch [1946/3000], Step [120/158]| g_loss: 0.701| d_loss: 0.614| gp_loss: 0.058| r_loss: 0.058| p_loss: 0.084| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.546
Train: Epoch [1946/3000], Step [150/158]| g_loss: 0.688| d_loss: 0.591| gp_loss: 0.058| r_loss: 0.059| p_loss: 0.080| v_loss: 0.021| per_loss: 0.316 | a_loss: 0.537
Train: Epoch [1947/3000], Step [30/158]| g_loss: 0.712| d_loss: 0.666| gp_loss: 0.162| r_loss: 0.061| p_loss: 0.085| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.555
Train: Epoch [1947/3000], Step [60/158]| g_loss: 0.696| d_loss: 0.707| gp_loss: 0.052| r_loss: 0.059| p_loss: 0.085| v_loss: 0.023| per_loss: 0.326 | a_loss: 0.540
Train: Epoch [1947/3000], Step [90/158]| g_loss: 0.597| d_loss: 0.613| gp_loss: 0.055| r_loss: 0.058| p_loss: 0.081| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.445
Train: Epoch [1947/3000], Step [120/158]| g_loss: 0.736| d_loss: 0.472| gp_loss: 0.061| r_loss: 0.058| p_loss: 0.078| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.587
Train: Epoch [1947/3000], Step [150/158]| g_loss: 0.652| d_loss: 0.710| gp_loss: 0.057| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.318 | a_loss: 0.497
Train: Epoch [1948/3000], Step [30/158]| g_loss: 0.704| d_loss: 0.743| gp_loss: 0.190| r_loss: 0.060| p_loss: 0.083| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.549
Train: Epoch [1948/3000], Step [60/158]| g_loss: 0.674| d_loss: 0.599| gp_loss: 0.052| r_loss: 0.056| p_loss: 0.079| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.523
Train: Epoch [1948/3000], Step [90/158]| g_loss: 0.709| d_loss: 0.584| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.083| v_loss: 0.023| per_loss: 0.310 | a_loss: 0.555
Train: Epoch [1948/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.653| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.087| v_loss: 0.022| per_loss: 0.304 | a_loss: 0.520
Train: Epoch [1948/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.617| gp_loss: 0.057| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.504
Train: Epoch [1949/3000], Step [30/158]| g_loss: 0.708| d_loss: 0.664| gp_loss: 0.130| r_loss: 0.060| p_loss: 0.086| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.551
Train: Epoch [1949/3000], Step [60/158]| g_loss: 0.707| d_loss: 0.549| gp_loss: 0.055| r_loss: 0.061| p_loss: 0.085| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.551
Train: Epoch [1949/3000], Step [90/158]| g_loss: 0.713| d_loss: 0.555| gp_loss: 0.053| r_loss: 0.057| p_loss: 0.078| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.564
Train: Epoch [1949/3000], Step [120/158]| g_loss: 0.703| d_loss: 0.611| gp_loss: 0.054| r_loss: 0.062| p_loss: 0.085| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.543
Train: Epoch [1949/3000], Step [150/158]| g_loss: 0.672| d_loss: 0.702| gp_loss: 0.055| r_loss: 0.058| p_loss: 0.086| v_loss: 0.022| per_loss: 0.306 | a_loss: 0.519
Train: Epoch [1950/3000], Step [30/158]| g_loss: 0.653| d_loss: 0.717| gp_loss: 0.128| r_loss: 0.061| p_loss: 0.090| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.493
Train: Epoch [1950/3000], Step [60/158]| g_loss: 0.718| d_loss: 0.596| gp_loss: 0.056| r_loss: 0.062| p_loss: 0.091| v_loss: 0.023| per_loss: 0.317 | a_loss: 0.555
Train: Epoch [1950/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.652| gp_loss: 0.053| r_loss: 0.058| p_loss: 0.084| v_loss: 0.022| per_loss: 0.305 | a_loss: 0.505
Train: Epoch [1950/3000], Step [120/158]| g_loss: 0.657| d_loss: 0.626| gp_loss: 0.060| r_loss: 0.059| p_loss: 0.083| v_loss: 0.022| per_loss: 0.323 | a_loss: 0.503
Train: Epoch [1950/3000], Step [150/158]| g_loss: 0.650| d_loss: 0.653| gp_loss: 0.059| r_loss: 0.060| p_loss: 0.086| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.493
Test: Epoch [1950/3000]| g_loss: 0.635| r_loss: 0.387| p_loss: 0.308| v_loss: 0.023
Train: Epoch [1951/3000], Step [30/158]| g_loss: 0.703| d_loss: 0.661| gp_loss: 0.050| r_loss: 0.060| p_loss: 0.087| v_loss: 0.023| per_loss: 0.310 | a_loss: 0.545
Train: Epoch [1951/3000], Step [60/158]| g_loss: 0.668| d_loss: 0.573| gp_loss: 0.051| r_loss: 0.061| p_loss: 0.086| v_loss: 0.023| per_loss: 0.328 | a_loss: 0.509
Train: Epoch [1951/3000], Step [90/158]| g_loss: 0.680| d_loss: 0.670| gp_loss: 0.049| r_loss: 0.057| p_loss: 0.081| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.531
Train: Epoch [1951/3000], Step [120/158]| g_loss: 0.670| d_loss: 0.548| gp_loss: 0.052| r_loss: 0.057| p_loss: 0.080| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.518
Train: Epoch [1951/3000], Step [150/158]| g_loss: 0.694| d_loss: 0.644| gp_loss: 0.054| r_loss: 0.060| p_loss: 0.085| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.541
Train: Epoch [1952/3000], Step [30/158]| g_loss: 0.656| d_loss: 0.784| gp_loss: 0.103| r_loss: 0.059| p_loss: 0.088| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.499
Train: Epoch [1952/3000], Step [60/158]| g_loss: 0.609| d_loss: 0.728| gp_loss: 0.054| r_loss: 0.061| p_loss: 0.087| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.452
Train: Epoch [1952/3000], Step [90/158]| g_loss: 0.665| d_loss: 0.611| gp_loss: 0.056| r_loss: 0.060| p_loss: 0.086| v_loss: 0.023| per_loss: 0.328 | a_loss: 0.506
Train: Epoch [1952/3000], Step [120/158]| g_loss: 0.713| d_loss: 0.506| gp_loss: 0.056| r_loss: 0.058| p_loss: 0.082| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.561
Train: Epoch [1952/3000], Step [150/158]| g_loss: 0.724| d_loss: 0.541| gp_loss: 0.059| r_loss: 0.059| p_loss: 0.081| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.572
Train: Epoch [1953/3000], Step [30/158]| g_loss: 0.676| d_loss: 0.712| gp_loss: 0.131| r_loss: 0.058| p_loss: 0.080| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.524
Train: Epoch [1953/3000], Step [60/158]| g_loss: 0.642| d_loss: 0.659| gp_loss: 0.053| r_loss: 0.058| p_loss: 0.081| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.491
Train: Epoch [1953/3000], Step [90/158]| g_loss: 0.712| d_loss: 0.560| gp_loss: 0.056| r_loss: 0.059| p_loss: 0.083| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.559
Train: Epoch [1953/3000], Step [120/158]| g_loss: 0.733| d_loss: 0.581| gp_loss: 0.057| r_loss: 0.058| p_loss: 0.081| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.581
Train: Epoch [1953/3000], Step [150/158]| g_loss: 0.698| d_loss: 0.585| gp_loss: 0.059| r_loss: 0.057| p_loss: 0.081| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.546
Train: Epoch [1954/3000], Step [30/158]| g_loss: 0.643| d_loss: 0.779| gp_loss: 0.143| r_loss: 0.060| p_loss: 0.088| v_loss: 0.023| per_loss: 0.322 | a_loss: 0.484
Train: Epoch [1954/3000], Step [60/158]| g_loss: 0.725| d_loss: 0.508| gp_loss: 0.055| r_loss: 0.060| p_loss: 0.083| v_loss: 0.022| per_loss: 0.302 | a_loss: 0.571
Train: Epoch [1954/3000], Step [90/158]| g_loss: 0.745| d_loss: 0.586| gp_loss: 0.055| r_loss: 0.061| p_loss: 0.083| v_loss: 0.023| per_loss: 0.327 | a_loss: 0.587
Train: Epoch [1954/3000], Step [120/158]| g_loss: 0.648| d_loss: 0.678| gp_loss: 0.054| r_loss: 0.057| p_loss: 0.079| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.501
Train: Epoch [1954/3000], Step [150/158]| g_loss: 0.643| d_loss: 0.659| gp_loss: 0.059| r_loss: 0.058| p_loss: 0.084| v_loss: 0.021| per_loss: 0.334 | a_loss: 0.489
Train: Epoch [1955/3000], Step [30/158]| g_loss: 0.668| d_loss: 0.706| gp_loss: 0.161| r_loss: 0.058| p_loss: 0.081| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.515
Train: Epoch [1955/3000], Step [60/158]| g_loss: 0.714| d_loss: 0.562| gp_loss: 0.057| r_loss: 0.059| p_loss: 0.082| v_loss: 0.022| per_loss: 0.300 | a_loss: 0.562
Train: Epoch [1955/3000], Step [90/158]| g_loss: 0.628| d_loss: 0.688| gp_loss: 0.053| r_loss: 0.059| p_loss: 0.083| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.475
Train: Epoch [1955/3000], Step [120/158]| g_loss: 0.638| d_loss: 0.636| gp_loss: 0.056| r_loss: 0.058| p_loss: 0.083| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.487
Train: Epoch [1955/3000], Step [150/158]| g_loss: 0.713| d_loss: 0.589| gp_loss: 0.064| r_loss: 0.062| p_loss: 0.088| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.554
Train: Epoch [1956/3000], Step [30/158]| g_loss: 0.660| d_loss: 0.759| gp_loss: 0.115| r_loss: 0.063| p_loss: 0.094| v_loss: 0.023| per_loss: 0.312 | a_loss: 0.496
Train: Epoch [1956/3000], Step [60/158]| g_loss: 0.730| d_loss: 0.562| gp_loss: 0.059| r_loss: 0.062| p_loss: 0.089| v_loss: 0.023| per_loss: 0.306 | a_loss: 0.570
Train: Epoch [1956/3000], Step [90/158]| g_loss: 0.692| d_loss: 0.556| gp_loss: 0.056| r_loss: 0.062| p_loss: 0.095| v_loss: 0.022| per_loss: 0.298 | a_loss: 0.531
Train: Epoch [1956/3000], Step [120/158]| g_loss: 0.714| d_loss: 0.570| gp_loss: 0.057| r_loss: 0.063| p_loss: 0.092| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.552
Train: Epoch [1956/3000], Step [150/158]| g_loss: 0.714| d_loss: 0.667| gp_loss: 0.060| r_loss: 0.061| p_loss: 0.084| v_loss: 0.022| per_loss: 0.325 | a_loss: 0.557
Train: Epoch [1957/3000], Step [30/158]| g_loss: 0.624| d_loss: 0.749| gp_loss: 0.076| r_loss: 0.059| p_loss: 0.084| v_loss: 0.021| per_loss: 0.328 | a_loss: 0.469
Train: Epoch [1957/3000], Step [60/158]| g_loss: 0.684| d_loss: 0.684| gp_loss: 0.060| r_loss: 0.062| p_loss: 0.089| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.523
Train: Epoch [1957/3000], Step [90/158]| g_loss: 0.669| d_loss: 0.595| gp_loss: 0.061| r_loss: 0.059| p_loss: 0.085| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.516
Train: Epoch [1957/3000], Step [120/158]| g_loss: 0.691| d_loss: 0.591| gp_loss: 0.062| r_loss: 0.059| p_loss: 0.086| v_loss: 0.023| per_loss: 0.316 | a_loss: 0.534
Train: Epoch [1957/3000], Step [150/158]| g_loss: 0.701| d_loss: 0.613| gp_loss: 0.058| r_loss: 0.060| p_loss: 0.086| v_loss: 0.023| per_loss: 0.308 | a_loss: 0.544
Train: Epoch [1958/3000], Step [30/158]| g_loss: 0.666| d_loss: 0.710| gp_loss: 0.160| r_loss: 0.060| p_loss: 0.084| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.511
Train: Epoch [1958/3000], Step [60/158]| g_loss: 0.679| d_loss: 0.635| gp_loss: 0.056| r_loss: 0.058| p_loss: 0.084| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.525
Train: Epoch [1958/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.616| gp_loss: 0.057| r_loss: 0.061| p_loss: 0.083| v_loss: 0.022| per_loss: 0.324 | a_loss: 0.498
Train: Epoch [1958/3000], Step [120/158]| g_loss: 0.681| d_loss: 0.557| gp_loss: 0.058| r_loss: 0.057| p_loss: 0.079| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.534
Train: Epoch [1958/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.586| gp_loss: 0.060| r_loss: 0.057| p_loss: 0.082| v_loss: 0.022| per_loss: 0.318 | a_loss: 0.517
Train: Epoch [1959/3000], Step [30/158]| g_loss: 0.696| d_loss: 0.766| gp_loss: 0.185| r_loss: 0.056| p_loss: 0.083| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.545
Train: Epoch [1959/3000], Step [60/158]| g_loss: 0.671| d_loss: 0.608| gp_loss: 0.054| r_loss: 0.059| p_loss: 0.082| v_loss: 0.021| per_loss: 0.321 | a_loss: 0.517
Train: Epoch [1959/3000], Step [90/158]| g_loss: 0.690| d_loss: 0.585| gp_loss: 0.058| r_loss: 0.058| p_loss: 0.081| v_loss: 0.022| per_loss: 0.301 | a_loss: 0.540
Train: Epoch [1959/3000], Step [120/158]| g_loss: 0.651| d_loss: 0.599| gp_loss: 0.058| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.299 | a_loss: 0.499
Train: Epoch [1959/3000], Step [150/158]| g_loss: 0.691| d_loss: 0.608| gp_loss: 0.058| r_loss: 0.058| p_loss: 0.080| v_loss: 0.021| per_loss: 0.317 | a_loss: 0.540
Train: Epoch [1960/3000], Step [30/158]| g_loss: 0.689| d_loss: 0.688| gp_loss: 0.134| r_loss: 0.058| p_loss: 0.081| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.539
Train: Epoch [1960/3000], Step [60/158]| g_loss: 0.703| d_loss: 0.586| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.085| v_loss: 0.022| per_loss: 0.302 | a_loss: 0.551
Train: Epoch [1960/3000], Step [90/158]| g_loss: 0.666| d_loss: 0.687| gp_loss: 0.056| r_loss: 0.060| p_loss: 0.087| v_loss: 0.023| per_loss: 0.331 | a_loss: 0.507
Train: Epoch [1960/3000], Step [120/158]| g_loss: 0.665| d_loss: 0.594| gp_loss: 0.058| r_loss: 0.059| p_loss: 0.083| v_loss: 0.021| per_loss: 0.317 | a_loss: 0.512
Train: Epoch [1960/3000], Step [150/158]| g_loss: 0.742| d_loss: 0.551| gp_loss: 0.057| r_loss: 0.064| p_loss: 0.082| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.584
Train: Epoch [1961/3000], Step [30/158]| g_loss: 0.693| d_loss: 0.737| gp_loss: 0.188| r_loss: 0.061| p_loss: 0.085| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.537
Train: Epoch [1961/3000], Step [60/158]| g_loss: 0.653| d_loss: 0.590| gp_loss: 0.052| r_loss: 0.058| p_loss: 0.082| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.500
Train: Epoch [1961/3000], Step [90/158]| g_loss: 0.704| d_loss: 0.658| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.086| v_loss: 0.022| per_loss: 0.323 | a_loss: 0.548
Train: Epoch [1961/3000], Step [120/158]| g_loss: 0.654| d_loss: 0.683| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.083| v_loss: 0.022| per_loss: 0.325 | a_loss: 0.499
Train: Epoch [1961/3000], Step [150/158]| g_loss: 0.708| d_loss: 0.563| gp_loss: 0.062| r_loss: 0.063| p_loss: 0.089| v_loss: 0.024| per_loss: 0.304 | a_loss: 0.546
Train: Epoch [1962/3000], Step [30/158]| g_loss: 0.723| d_loss: 0.648| gp_loss: 0.151| r_loss: 0.059| p_loss: 0.086| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.568
Train: Epoch [1962/3000], Step [60/158]| g_loss: 0.721| d_loss: 0.579| gp_loss: 0.054| r_loss: 0.060| p_loss: 0.084| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.566
Train: Epoch [1962/3000], Step [90/158]| g_loss: 0.691| d_loss: 0.561| gp_loss: 0.051| r_loss: 0.058| p_loss: 0.083| v_loss: 0.022| per_loss: 0.329 | a_loss: 0.536
Train: Epoch [1962/3000], Step [120/158]| g_loss: 0.707| d_loss: 0.637| gp_loss: 0.052| r_loss: 0.061| p_loss: 0.085| v_loss: 0.022| per_loss: 0.325 | a_loss: 0.549
Train: Epoch [1962/3000], Step [150/158]| g_loss: 0.625| d_loss: 0.702| gp_loss: 0.054| r_loss: 0.060| p_loss: 0.087| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.469
Train: Epoch [1963/3000], Step [30/158]| g_loss: 0.685| d_loss: 0.668| gp_loss: 0.127| r_loss: 0.059| p_loss: 0.081| v_loss: 0.022| per_loss: 0.306 | a_loss: 0.533
Train: Epoch [1963/3000], Step [60/158]| g_loss: 0.655| d_loss: 0.657| gp_loss: 0.055| r_loss: 0.058| p_loss: 0.085| v_loss: 0.022| per_loss: 0.323 | a_loss: 0.501
Train: Epoch [1963/3000], Step [90/158]| g_loss: 0.638| d_loss: 0.654| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.080| v_loss: 0.022| per_loss: 0.296 | a_loss: 0.490
Train: Epoch [1963/3000], Step [120/158]| g_loss: 0.628| d_loss: 0.686| gp_loss: 0.058| r_loss: 0.059| p_loss: 0.082| v_loss: 0.022| per_loss: 0.307 | a_loss: 0.476
Train: Epoch [1963/3000], Step [150/158]| g_loss: 0.722| d_loss: 0.498| gp_loss: 0.058| r_loss: 0.058| p_loss: 0.080| v_loss: 0.023| per_loss: 0.335 | a_loss: 0.567
Train: Epoch [1964/3000], Step [30/158]| g_loss: 0.710| d_loss: 0.654| gp_loss: 0.090| r_loss: 0.058| p_loss: 0.083| v_loss: 0.022| per_loss: 0.311 | a_loss: 0.558
Train: Epoch [1964/3000], Step [60/158]| g_loss: 0.685| d_loss: 0.642| gp_loss: 0.059| r_loss: 0.060| p_loss: 0.084| v_loss: 0.023| per_loss: 0.323 | a_loss: 0.527
Train: Epoch [1964/3000], Step [90/158]| g_loss: 0.713| d_loss: 0.581| gp_loss: 0.058| r_loss: 0.058| p_loss: 0.082| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.560
Train: Epoch [1964/3000], Step [120/158]| g_loss: 0.680| d_loss: 0.631| gp_loss: 0.061| r_loss: 0.057| p_loss: 0.081| v_loss: 0.022| per_loss: 0.326 | a_loss: 0.528
Train: Epoch [1964/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.619| gp_loss: 0.061| r_loss: 0.059| p_loss: 0.084| v_loss: 0.023| per_loss: 0.313 | a_loss: 0.507
Train: Epoch [1965/3000], Step [30/158]| g_loss: 0.691| d_loss: 0.682| gp_loss: 0.138| r_loss: 0.057| p_loss: 0.080| v_loss: 0.022| per_loss: 0.336 | a_loss: 0.538
Train: Epoch [1965/3000], Step [60/158]| g_loss: 0.663| d_loss: 0.683| gp_loss: 0.058| r_loss: 0.059| p_loss: 0.083| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.509
Train: Epoch [1965/3000], Step [90/158]| g_loss: 0.655| d_loss: 0.602| gp_loss: 0.062| r_loss: 0.060| p_loss: 0.085| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.499
Train: Epoch [1965/3000], Step [120/158]| g_loss: 0.720| d_loss: 0.601| gp_loss: 0.063| r_loss: 0.059| p_loss: 0.086| v_loss: 0.022| per_loss: 0.305 | a_loss: 0.565
Train: Epoch [1965/3000], Step [150/158]| g_loss: 0.729| d_loss: 0.535| gp_loss: 0.059| r_loss: 0.059| p_loss: 0.083| v_loss: 0.023| per_loss: 0.317 | a_loss: 0.574
Train: Epoch [1966/3000], Step [30/158]| g_loss: 0.660| d_loss: 0.791| gp_loss: 0.071| r_loss: 0.064| p_loss: 0.103| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.491
Train: Epoch [1966/3000], Step [60/158]| g_loss: 0.660| d_loss: 0.611| gp_loss: 0.058| r_loss: 0.060| p_loss: 0.089| v_loss: 0.022| per_loss: 0.311 | a_loss: 0.502
Train: Epoch [1966/3000], Step [90/158]| g_loss: 0.717| d_loss: 0.553| gp_loss: 0.059| r_loss: 0.063| p_loss: 0.089| v_loss: 0.023| per_loss: 0.326 | a_loss: 0.554
Train: Epoch [1966/3000], Step [120/158]| g_loss: 0.714| d_loss: 0.596| gp_loss: 0.064| r_loss: 0.059| p_loss: 0.083| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.560
Train: Epoch [1966/3000], Step [150/158]| g_loss: 0.672| d_loss: 0.638| gp_loss: 0.062| r_loss: 0.058| p_loss: 0.082| v_loss: 0.022| per_loss: 0.302 | a_loss: 0.521
Train: Epoch [1967/3000], Step [30/158]| g_loss: 0.627| d_loss: 0.750| gp_loss: 0.167| r_loss: 0.059| p_loss: 0.083| v_loss: 0.023| per_loss: 0.315 | a_loss: 0.472
Train: Epoch [1967/3000], Step [60/158]| g_loss: 0.703| d_loss: 0.583| gp_loss: 0.061| r_loss: 0.062| p_loss: 0.084| v_loss: 0.022| per_loss: 0.325 | a_loss: 0.544
Train: Epoch [1967/3000], Step [90/158]| g_loss: 0.737| d_loss: 0.519| gp_loss: 0.060| r_loss: 0.057| p_loss: 0.081| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.584
Train: Epoch [1967/3000], Step [120/158]| g_loss: 0.673| d_loss: 0.653| gp_loss: 0.058| r_loss: 0.056| p_loss: 0.081| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.523
Train: Epoch [1967/3000], Step [150/158]| g_loss: 0.686| d_loss: 0.600| gp_loss: 0.060| r_loss: 0.056| p_loss: 0.081| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.535
Train: Epoch [1968/3000], Step [30/158]| g_loss: 0.651| d_loss: 0.691| gp_loss: 0.106| r_loss: 0.060| p_loss: 0.084| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.495
Train: Epoch [1968/3000], Step [60/158]| g_loss: 0.715| d_loss: 0.622| gp_loss: 0.060| r_loss: 0.058| p_loss: 0.086| v_loss: 0.023| per_loss: 0.314 | a_loss: 0.561
Train: Epoch [1968/3000], Step [90/158]| g_loss: 0.638| d_loss: 0.684| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.082| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.488
Train: Epoch [1968/3000], Step [120/158]| g_loss: 0.694| d_loss: 0.584| gp_loss: 0.065| r_loss: 0.058| p_loss: 0.081| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.542
Train: Epoch [1968/3000], Step [150/158]| g_loss: 0.656| d_loss: 0.599| gp_loss: 0.063| r_loss: 0.057| p_loss: 0.075| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.508
Train: Epoch [1969/3000], Step [30/158]| g_loss: 0.670| d_loss: 0.727| gp_loss: 0.131| r_loss: 0.059| p_loss: 0.082| v_loss: 0.023| per_loss: 0.311 | a_loss: 0.517
Train: Epoch [1969/3000], Step [60/158]| g_loss: 0.718| d_loss: 0.530| gp_loss: 0.061| r_loss: 0.057| p_loss: 0.079| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.568
Train: Epoch [1969/3000], Step [90/158]| g_loss: 0.674| d_loss: 0.662| gp_loss: 0.058| r_loss: 0.056| p_loss: 0.075| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.529
Train: Epoch [1969/3000], Step [120/158]| g_loss: 0.673| d_loss: 0.550| gp_loss: 0.061| r_loss: 0.059| p_loss: 0.079| v_loss: 0.022| per_loss: 0.294 | a_loss: 0.522
Train: Epoch [1969/3000], Step [150/158]| g_loss: 0.696| d_loss: 0.660| gp_loss: 0.060| r_loss: 0.061| p_loss: 0.091| v_loss: 0.023| per_loss: 0.338 | a_loss: 0.533
Train: Epoch [1970/3000], Step [30/158]| g_loss: 0.704| d_loss: 0.758| gp_loss: 0.116| r_loss: 0.069| p_loss: 0.103| v_loss: 0.022| per_loss: 0.311 | a_loss: 0.531
Train: Epoch [1970/3000], Step [60/158]| g_loss: 0.678| d_loss: 0.542| gp_loss: 0.057| r_loss: 0.061| p_loss: 0.089| v_loss: 0.023| per_loss: 0.315 | a_loss: 0.519
Train: Epoch [1970/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.692| gp_loss: 0.059| r_loss: 0.063| p_loss: 0.093| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.494
Train: Epoch [1970/3000], Step [120/158]| g_loss: 0.719| d_loss: 0.612| gp_loss: 0.069| r_loss: 0.064| p_loss: 0.088| v_loss: 0.023| per_loss: 0.331 | a_loss: 0.555
Train: Epoch [1970/3000], Step [150/158]| g_loss: 0.686| d_loss: 0.601| gp_loss: 0.064| r_loss: 0.058| p_loss: 0.083| v_loss: 0.021| per_loss: 0.323 | a_loss: 0.533
Train: Epoch [1971/3000], Step [30/158]| g_loss: 0.644| d_loss: 0.799| gp_loss: 0.112| r_loss: 0.060| p_loss: 0.087| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.488
Train: Epoch [1971/3000], Step [60/158]| g_loss: 0.675| d_loss: 0.587| gp_loss: 0.065| r_loss: 0.061| p_loss: 0.087| v_loss: 0.023| per_loss: 0.311 | a_loss: 0.517
Train: Epoch [1971/3000], Step [90/158]| g_loss: 0.692| d_loss: 0.598| gp_loss: 0.063| r_loss: 0.063| p_loss: 0.089| v_loss: 0.023| per_loss: 0.322 | a_loss: 0.530
Train: Epoch [1971/3000], Step [120/158]| g_loss: 0.699| d_loss: 0.624| gp_loss: 0.065| r_loss: 0.060| p_loss: 0.088| v_loss: 0.023| per_loss: 0.313 | a_loss: 0.541
Train: Epoch [1971/3000], Step [150/158]| g_loss: 0.687| d_loss: 0.555| gp_loss: 0.067| r_loss: 0.059| p_loss: 0.083| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.535
Train: Epoch [1972/3000], Step [30/158]| g_loss: 0.740| d_loss: 0.709| gp_loss: 0.209| r_loss: 0.062| p_loss: 0.086| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.582
Train: Epoch [1972/3000], Step [60/158]| g_loss: 0.660| d_loss: 0.635| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.083| v_loss: 0.022| per_loss: 0.296 | a_loss: 0.507
Train: Epoch [1972/3000], Step [90/158]| g_loss: 0.695| d_loss: 0.617| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.079| v_loss: 0.022| per_loss: 0.320 | a_loss: 0.546
Train: Epoch [1972/3000], Step [120/158]| g_loss: 0.664| d_loss: 0.612| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.518
Train: Epoch [1972/3000], Step [150/158]| g_loss: 0.689| d_loss: 0.596| gp_loss: 0.056| r_loss: 0.060| p_loss: 0.080| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.535
Train: Epoch [1973/3000], Step [30/158]| g_loss: 0.657| d_loss: 0.690| gp_loss: 0.123| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.320 | a_loss: 0.512
Train: Epoch [1973/3000], Step [60/158]| g_loss: 0.714| d_loss: 0.502| gp_loss: 0.056| r_loss: 0.059| p_loss: 0.083| v_loss: 0.022| per_loss: 0.300 | a_loss: 0.562
Train: Epoch [1973/3000], Step [90/158]| g_loss: 0.752| d_loss: 0.621| gp_loss: 0.055| r_loss: 0.060| p_loss: 0.081| v_loss: 0.022| per_loss: 0.311 | a_loss: 0.599
Train: Epoch [1973/3000], Step [120/158]| g_loss: 0.662| d_loss: 0.641| gp_loss: 0.059| r_loss: 0.058| p_loss: 0.078| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.513
Train: Epoch [1973/3000], Step [150/158]| g_loss: 0.622| d_loss: 0.699| gp_loss: 0.057| r_loss: 0.061| p_loss: 0.082| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.467
Train: Epoch [1974/3000], Step [30/158]| g_loss: 0.686| d_loss: 0.715| gp_loss: 0.192| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.531
Train: Epoch [1974/3000], Step [60/158]| g_loss: 0.613| d_loss: 0.636| gp_loss: 0.053| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.469
Train: Epoch [1974/3000], Step [90/158]| g_loss: 0.714| d_loss: 0.581| gp_loss: 0.058| r_loss: 0.061| p_loss: 0.080| v_loss: 0.022| per_loss: 0.295 | a_loss: 0.561
Train: Epoch [1974/3000], Step [120/158]| g_loss: 0.632| d_loss: 0.723| gp_loss: 0.055| r_loss: 0.057| p_loss: 0.078| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.484
Train: Epoch [1974/3000], Step [150/158]| g_loss: 0.656| d_loss: 0.555| gp_loss: 0.062| r_loss: 0.055| p_loss: 0.078| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.508
Train: Epoch [1975/3000], Step [30/158]| g_loss: 0.730| d_loss: 0.653| gp_loss: 0.180| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.583
Train: Epoch [1975/3000], Step [60/158]| g_loss: 0.692| d_loss: 0.591| gp_loss: 0.054| r_loss: 0.057| p_loss: 0.080| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.542
Train: Epoch [1975/3000], Step [90/158]| g_loss: 0.690| d_loss: 0.639| gp_loss: 0.053| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.318 | a_loss: 0.543
Train: Epoch [1975/3000], Step [120/158]| g_loss: 0.654| d_loss: 0.672| gp_loss: 0.055| r_loss: 0.058| p_loss: 0.080| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.503
Train: Epoch [1975/3000], Step [150/158]| g_loss: 0.670| d_loss: 0.613| gp_loss: 0.057| r_loss: 0.060| p_loss: 0.083| v_loss: 0.022| per_loss: 0.306 | a_loss: 0.516
Train: Epoch [1976/3000], Step [30/158]| g_loss: 0.648| d_loss: 0.736| gp_loss: 0.133| r_loss: 0.058| p_loss: 0.080| v_loss: 0.022| per_loss: 0.307 | a_loss: 0.498
Train: Epoch [1976/3000], Step [60/158]| g_loss: 0.668| d_loss: 0.601| gp_loss: 0.053| r_loss: 0.055| p_loss: 0.078| v_loss: 0.020| per_loss: 0.312 | a_loss: 0.522
Train: Epoch [1976/3000], Step [90/158]| g_loss: 0.730| d_loss: 0.524| gp_loss: 0.057| r_loss: 0.061| p_loss: 0.082| v_loss: 0.022| per_loss: 0.303 | a_loss: 0.575
Train: Epoch [1976/3000], Step [120/158]| g_loss: 0.703| d_loss: 0.651| gp_loss: 0.056| r_loss: 0.059| p_loss: 0.081| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.550
Train: Epoch [1976/3000], Step [150/158]| g_loss: 0.652| d_loss: 0.642| gp_loss: 0.057| r_loss: 0.058| p_loss: 0.080| v_loss: 0.022| per_loss: 0.302 | a_loss: 0.502
Train: Epoch [1977/3000], Step [30/158]| g_loss: 0.649| d_loss: 0.762| gp_loss: 0.206| r_loss: 0.058| p_loss: 0.081| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.497
Train: Epoch [1977/3000], Step [60/158]| g_loss: 0.692| d_loss: 0.578| gp_loss: 0.057| r_loss: 0.057| p_loss: 0.079| v_loss: 0.022| per_loss: 0.302 | a_loss: 0.544
Train: Epoch [1977/3000], Step [90/158]| g_loss: 0.632| d_loss: 0.745| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.082| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.481
Train: Epoch [1977/3000], Step [120/158]| g_loss: 0.675| d_loss: 0.615| gp_loss: 0.056| r_loss: 0.059| p_loss: 0.080| v_loss: 0.022| per_loss: 0.301 | a_loss: 0.524
Train: Epoch [1977/3000], Step [150/158]| g_loss: 0.720| d_loss: 0.535| gp_loss: 0.057| r_loss: 0.057| p_loss: 0.079| v_loss: 0.022| per_loss: 0.329 | a_loss: 0.568
Train: Epoch [1978/3000], Step [30/158]| g_loss: 0.668| d_loss: 0.718| gp_loss: 0.153| r_loss: 0.056| p_loss: 0.075| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.523
Train: Epoch [1978/3000], Step [60/158]| g_loss: 0.670| d_loss: 0.655| gp_loss: 0.051| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.316 | a_loss: 0.523
Train: Epoch [1978/3000], Step [90/158]| g_loss: 0.651| d_loss: 0.564| gp_loss: 0.053| r_loss: 0.057| p_loss: 0.077| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.504
Train: Epoch [1978/3000], Step [120/158]| g_loss: 0.709| d_loss: 0.599| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.080| v_loss: 0.022| per_loss: 0.296 | a_loss: 0.561
Train: Epoch [1978/3000], Step [150/158]| g_loss: 0.712| d_loss: 0.592| gp_loss: 0.056| r_loss: 0.060| p_loss: 0.081| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.559
Train: Epoch [1979/3000], Step [30/158]| g_loss: 0.692| d_loss: 0.784| gp_loss: 0.196| r_loss: 0.060| p_loss: 0.085| v_loss: 0.022| per_loss: 0.302 | a_loss: 0.538
Train: Epoch [1979/3000], Step [60/158]| g_loss: 0.678| d_loss: 0.635| gp_loss: 0.050| r_loss: 0.059| p_loss: 0.082| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.525
Train: Epoch [1979/3000], Step [90/158]| g_loss: 0.681| d_loss: 0.502| gp_loss: 0.054| r_loss: 0.059| p_loss: 0.079| v_loss: 0.022| per_loss: 0.320 | a_loss: 0.529
Train: Epoch [1979/3000], Step [120/158]| g_loss: 0.689| d_loss: 0.725| gp_loss: 0.050| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.541
Train: Epoch [1979/3000], Step [150/158]| g_loss: 0.632| d_loss: 0.568| gp_loss: 0.053| r_loss: 0.056| p_loss: 0.079| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.486
Train: Epoch [1980/3000], Step [30/158]| g_loss: 0.675| d_loss: 0.696| gp_loss: 0.157| r_loss: 0.054| p_loss: 0.074| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.533
Train: Epoch [1980/3000], Step [60/158]| g_loss: 0.683| d_loss: 0.626| gp_loss: 0.049| r_loss: 0.057| p_loss: 0.081| v_loss: 0.022| per_loss: 0.322 | a_loss: 0.531
Train: Epoch [1980/3000], Step [90/158]| g_loss: 0.642| d_loss: 0.675| gp_loss: 0.050| r_loss: 0.059| p_loss: 0.082| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.490
Train: Epoch [1980/3000], Step [120/158]| g_loss: 0.610| d_loss: 0.686| gp_loss: 0.051| r_loss: 0.057| p_loss: 0.077| v_loss: 0.021| per_loss: 0.294 | a_loss: 0.464
Train: Epoch [1980/3000], Step [150/158]| g_loss: 0.771| d_loss: 0.468| gp_loss: 0.061| r_loss: 0.059| p_loss: 0.081| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.617
Train: Epoch [1981/3000], Step [30/158]| g_loss: 0.724| d_loss: 0.641| gp_loss: 0.100| r_loss: 0.056| p_loss: 0.079| v_loss: 0.022| per_loss: 0.299 | a_loss: 0.576
Train: Epoch [1981/3000], Step [60/158]| g_loss: 0.646| d_loss: 0.694| gp_loss: 0.056| r_loss: 0.060| p_loss: 0.081| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.494
Train: Epoch [1981/3000], Step [90/158]| g_loss: 0.656| d_loss: 0.632| gp_loss: 0.057| r_loss: 0.058| p_loss: 0.085| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.502
Train: Epoch [1981/3000], Step [120/158]| g_loss: 0.736| d_loss: 0.503| gp_loss: 0.054| r_loss: 0.063| p_loss: 0.082| v_loss: 0.023| per_loss: 0.314 | a_loss: 0.578
Train: Epoch [1981/3000], Step [150/158]| g_loss: 0.654| d_loss: 0.683| gp_loss: 0.058| r_loss: 0.059| p_loss: 0.086| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.499
Train: Epoch [1982/3000], Step [30/158]| g_loss: 0.661| d_loss: 0.704| gp_loss: 0.170| r_loss: 0.060| p_loss: 0.082| v_loss: 0.023| per_loss: 0.324 | a_loss: 0.506
Train: Epoch [1982/3000], Step [60/158]| g_loss: 0.736| d_loss: 0.559| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.083| v_loss: 0.022| per_loss: 0.304 | a_loss: 0.583
Train: Epoch [1982/3000], Step [90/158]| g_loss: 0.682| d_loss: 0.626| gp_loss: 0.054| r_loss: 0.057| p_loss: 0.081| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.533
Train: Epoch [1982/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.613| gp_loss: 0.060| r_loss: 0.061| p_loss: 0.087| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.509
Train: Epoch [1982/3000], Step [150/158]| g_loss: 0.681| d_loss: 0.703| gp_loss: 0.056| r_loss: 0.063| p_loss: 0.088| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.521
Train: Epoch [1983/3000], Step [30/158]| g_loss: 0.685| d_loss: 0.685| gp_loss: 0.132| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.530
Train: Epoch [1983/3000], Step [60/158]| g_loss: 0.666| d_loss: 0.638| gp_loss: 0.054| r_loss: 0.057| p_loss: 0.081| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.516
Train: Epoch [1983/3000], Step [90/158]| g_loss: 0.717| d_loss: 0.554| gp_loss: 0.058| r_loss: 0.060| p_loss: 0.082| v_loss: 0.021| per_loss: 0.317 | a_loss: 0.564
Train: Epoch [1983/3000], Step [120/158]| g_loss: 0.652| d_loss: 0.726| gp_loss: 0.054| r_loss: 0.059| p_loss: 0.087| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.496
Train: Epoch [1983/3000], Step [150/158]| g_loss: 0.671| d_loss: 0.542| gp_loss: 0.060| r_loss: 0.059| p_loss: 0.085| v_loss: 0.022| per_loss: 0.301 | a_loss: 0.517
Train: Epoch [1984/3000], Step [30/158]| g_loss: 0.690| d_loss: 0.686| gp_loss: 0.144| r_loss: 0.060| p_loss: 0.084| v_loss: 0.022| per_loss: 0.297 | a_loss: 0.537
Train: Epoch [1984/3000], Step [60/158]| g_loss: 0.659| d_loss: 0.651| gp_loss: 0.060| r_loss: 0.058| p_loss: 0.081| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.509
Train: Epoch [1984/3000], Step [90/158]| g_loss: 0.705| d_loss: 0.511| gp_loss: 0.057| r_loss: 0.059| p_loss: 0.081| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.552
Train: Epoch [1984/3000], Step [120/158]| g_loss: 0.726| d_loss: 0.644| gp_loss: 0.055| r_loss: 0.057| p_loss: 0.081| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.577
Train: Epoch [1984/3000], Step [150/158]| g_loss: 0.625| d_loss: 0.662| gp_loss: 0.062| r_loss: 0.056| p_loss: 0.080| v_loss: 0.022| per_loss: 0.300 | a_loss: 0.476
Train: Epoch [1985/3000], Step [30/158]| g_loss: 0.688| d_loss: 0.653| gp_loss: 0.144| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.543
Train: Epoch [1985/3000], Step [60/158]| g_loss: 0.654| d_loss: 0.717| gp_loss: 0.057| r_loss: 0.058| p_loss: 0.081| v_loss: 0.022| per_loss: 0.305 | a_loss: 0.504
Train: Epoch [1985/3000], Step [90/158]| g_loss: 0.699| d_loss: 0.585| gp_loss: 0.058| r_loss: 0.060| p_loss: 0.082| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.544
Train: Epoch [1985/3000], Step [120/158]| g_loss: 0.703| d_loss: 0.616| gp_loss: 0.058| r_loss: 0.061| p_loss: 0.087| v_loss: 0.023| per_loss: 0.329 | a_loss: 0.543
Train: Epoch [1985/3000], Step [150/158]| g_loss: 0.688| d_loss: 0.611| gp_loss: 0.061| r_loss: 0.062| p_loss: 0.088| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.528
Train: Epoch [1986/3000], Step [30/158]| g_loss: 0.721| d_loss: 0.643| gp_loss: 0.202| r_loss: 0.056| p_loss: 0.079| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.572
Train: Epoch [1986/3000], Step [60/158]| g_loss: 0.678| d_loss: 0.566| gp_loss: 0.052| r_loss: 0.058| p_loss: 0.081| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.529
Train: Epoch [1986/3000], Step [90/158]| g_loss: 0.720| d_loss: 0.654| gp_loss: 0.053| r_loss: 0.056| p_loss: 0.076| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.575
Train: Epoch [1986/3000], Step [120/158]| g_loss: 0.656| d_loss: 0.686| gp_loss: 0.050| r_loss: 0.059| p_loss: 0.083| v_loss: 0.023| per_loss: 0.327 | a_loss: 0.500
Train: Epoch [1986/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.626| gp_loss: 0.056| r_loss: 0.060| p_loss: 0.087| v_loss: 0.022| per_loss: 0.300 | a_loss: 0.507
Train: Epoch [1987/3000], Step [30/158]| g_loss: 0.672| d_loss: 0.704| gp_loss: 0.134| r_loss: 0.065| p_loss: 0.089| v_loss: 0.022| per_loss: 0.322 | a_loss: 0.508
Train: Epoch [1987/3000], Step [60/158]| g_loss: 0.684| d_loss: 0.670| gp_loss: 0.053| r_loss: 0.064| p_loss: 0.092| v_loss: 0.023| per_loss: 0.326 | a_loss: 0.518
Train: Epoch [1987/3000], Step [90/158]| g_loss: 0.667| d_loss: 0.591| gp_loss: 0.056| r_loss: 0.059| p_loss: 0.082| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.515
Train: Epoch [1987/3000], Step [120/158]| g_loss: 0.727| d_loss: 0.591| gp_loss: 0.054| r_loss: 0.061| p_loss: 0.092| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.568
Train: Epoch [1987/3000], Step [150/158]| g_loss: 0.668| d_loss: 0.651| gp_loss: 0.055| r_loss: 0.065| p_loss: 0.089| v_loss: 0.022| per_loss: 0.295 | a_loss: 0.507
Train: Epoch [1988/3000], Step [30/158]| g_loss: 0.724| d_loss: 0.684| gp_loss: 0.222| r_loss: 0.060| p_loss: 0.084| v_loss: 0.022| per_loss: 0.307 | a_loss: 0.570
Train: Epoch [1988/3000], Step [60/158]| g_loss: 0.674| d_loss: 0.654| gp_loss: 0.049| r_loss: 0.059| p_loss: 0.081| v_loss: 0.022| per_loss: 0.299 | a_loss: 0.523
Train: Epoch [1988/3000], Step [90/158]| g_loss: 0.634| d_loss: 0.656| gp_loss: 0.049| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.487
Train: Epoch [1988/3000], Step [120/158]| g_loss: 0.683| d_loss: 0.599| gp_loss: 0.053| r_loss: 0.057| p_loss: 0.078| v_loss: 0.021| per_loss: 0.294 | a_loss: 0.535
Train: Epoch [1988/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.640| gp_loss: 0.055| r_loss: 0.056| p_loss: 0.080| v_loss: 0.022| per_loss: 0.329 | a_loss: 0.524
Train: Epoch [1989/3000], Step [30/158]| g_loss: 0.633| d_loss: 0.714| gp_loss: 0.114| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.294 | a_loss: 0.486
Train: Epoch [1989/3000], Step [60/158]| g_loss: 0.700| d_loss: 0.609| gp_loss: 0.055| r_loss: 0.058| p_loss: 0.080| v_loss: 0.022| per_loss: 0.299 | a_loss: 0.550
Train: Epoch [1989/3000], Step [90/158]| g_loss: 0.709| d_loss: 0.527| gp_loss: 0.056| r_loss: 0.058| p_loss: 0.080| v_loss: 0.022| per_loss: 0.301 | a_loss: 0.558
Train: Epoch [1989/3000], Step [120/158]| g_loss: 0.687| d_loss: 0.649| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.082| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.536
Train: Epoch [1989/3000], Step [150/158]| g_loss: 0.684| d_loss: 0.600| gp_loss: 0.054| r_loss: 0.059| p_loss: 0.086| v_loss: 0.022| per_loss: 0.327 | a_loss: 0.527
Train: Epoch [1990/3000], Step [30/158]| g_loss: 0.707| d_loss: 0.618| gp_loss: 0.128| r_loss: 0.060| p_loss: 0.081| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.554
Train: Epoch [1990/3000], Step [60/158]| g_loss: 0.742| d_loss: 0.503| gp_loss: 0.050| r_loss: 0.056| p_loss: 0.076| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.594
Train: Epoch [1990/3000], Step [90/158]| g_loss: 0.652| d_loss: 0.728| gp_loss: 0.053| r_loss: 0.054| p_loss: 0.078| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.506
Train: Epoch [1990/3000], Step [120/158]| g_loss: 0.625| d_loss: 0.694| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.082| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.476
Train: Epoch [1990/3000], Step [150/158]| g_loss: 0.650| d_loss: 0.585| gp_loss: 0.057| r_loss: 0.057| p_loss: 0.078| v_loss: 0.022| per_loss: 0.304 | a_loss: 0.501
Train: Epoch [1991/3000], Step [30/158]| g_loss: 0.700| d_loss: 0.762| gp_loss: 0.185| r_loss: 0.057| p_loss: 0.083| v_loss: 0.022| per_loss: 0.304 | a_loss: 0.549
Train: Epoch [1991/3000], Step [60/158]| g_loss: 0.664| d_loss: 0.578| gp_loss: 0.054| r_loss: 0.059| p_loss: 0.079| v_loss: 0.022| per_loss: 0.295 | a_loss: 0.514
Train: Epoch [1991/3000], Step [90/158]| g_loss: 0.700| d_loss: 0.555| gp_loss: 0.054| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.555
Train: Epoch [1991/3000], Step [120/158]| g_loss: 0.711| d_loss: 0.608| gp_loss: 0.052| r_loss: 0.057| p_loss: 0.078| v_loss: 0.021| per_loss: 0.326 | a_loss: 0.561
Train: Epoch [1991/3000], Step [150/158]| g_loss: 0.639| d_loss: 0.683| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.080| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.487
Train: Epoch [1992/3000], Step [30/158]| g_loss: 0.698| d_loss: 0.681| gp_loss: 0.138| r_loss: 0.056| p_loss: 0.079| v_loss: 0.021| per_loss: 0.330 | a_loss: 0.549
Train: Epoch [1992/3000], Step [60/158]| g_loss: 0.612| d_loss: 0.725| gp_loss: 0.053| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.464
Train: Epoch [1992/3000], Step [90/158]| g_loss: 0.693| d_loss: 0.602| gp_loss: 0.056| r_loss: 0.059| p_loss: 0.082| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.541
Train: Epoch [1992/3000], Step [120/158]| g_loss: 0.645| d_loss: 0.655| gp_loss: 0.057| r_loss: 0.058| p_loss: 0.080| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.494
Train: Epoch [1992/3000], Step [150/158]| g_loss: 0.719| d_loss: 0.469| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.079| v_loss: 0.023| per_loss: 0.308 | a_loss: 0.570
Train: Epoch [1993/3000], Step [30/158]| g_loss: 0.677| d_loss: 0.723| gp_loss: 0.098| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.528
Train: Epoch [1993/3000], Step [60/158]| g_loss: 0.665| d_loss: 0.640| gp_loss: 0.057| r_loss: 0.058| p_loss: 0.080| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.515
Train: Epoch [1993/3000], Step [90/158]| g_loss: 0.649| d_loss: 0.701| gp_loss: 0.055| r_loss: 0.057| p_loss: 0.080| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.498
Train: Epoch [1993/3000], Step [120/158]| g_loss: 0.626| d_loss: 0.582| gp_loss: 0.060| r_loss: 0.056| p_loss: 0.076| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.481
Train: Epoch [1993/3000], Step [150/158]| g_loss: 0.712| d_loss: 0.547| gp_loss: 0.061| r_loss: 0.057| p_loss: 0.081| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.560
Train: Epoch [1994/3000], Step [30/158]| g_loss: 0.681| d_loss: 0.698| gp_loss: 0.141| r_loss: 0.055| p_loss: 0.077| v_loss: 0.022| per_loss: 0.305 | a_loss: 0.536
Train: Epoch [1994/3000], Step [60/158]| g_loss: 0.679| d_loss: 0.623| gp_loss: 0.056| r_loss: 0.059| p_loss: 0.082| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.525
Train: Epoch [1994/3000], Step [90/158]| g_loss: 0.704| d_loss: 0.598| gp_loss: 0.057| r_loss: 0.060| p_loss: 0.082| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.549
Train: Epoch [1994/3000], Step [120/158]| g_loss: 0.704| d_loss: 0.610| gp_loss: 0.057| r_loss: 0.057| p_loss: 0.078| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.557
Train: Epoch [1994/3000], Step [150/158]| g_loss: 0.656| d_loss: 0.614| gp_loss: 0.058| r_loss: 0.054| p_loss: 0.074| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.511
Train: Epoch [1995/3000], Step [30/158]| g_loss: 0.677| d_loss: 0.658| gp_loss: 0.171| r_loss: 0.056| p_loss: 0.075| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.533
Train: Epoch [1995/3000], Step [60/158]| g_loss: 0.678| d_loss: 0.684| gp_loss: 0.051| r_loss: 0.055| p_loss: 0.078| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.530
Train: Epoch [1995/3000], Step [90/158]| g_loss: 0.624| d_loss: 0.652| gp_loss: 0.055| r_loss: 0.058| p_loss: 0.079| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.474
Train: Epoch [1995/3000], Step [120/158]| g_loss: 0.691| d_loss: 0.546| gp_loss: 0.062| r_loss: 0.058| p_loss: 0.078| v_loss: 0.022| per_loss: 0.304 | a_loss: 0.541
Train: Epoch [1995/3000], Step [150/158]| g_loss: 0.679| d_loss: 0.630| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.533
Train: Epoch [1996/3000], Step [30/158]| g_loss: 0.673| d_loss: 0.704| gp_loss: 0.131| r_loss: 0.054| p_loss: 0.076| v_loss: 0.022| per_loss: 0.323 | a_loss: 0.527
Train: Epoch [1996/3000], Step [60/158]| g_loss: 0.677| d_loss: 0.545| gp_loss: 0.057| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.534
Train: Epoch [1996/3000], Step [90/158]| g_loss: 0.688| d_loss: 0.559| gp_loss: 0.053| r_loss: 0.055| p_loss: 0.078| v_loss: 0.021| per_loss: 0.319 | a_loss: 0.541
Train: Epoch [1996/3000], Step [120/158]| g_loss: 0.680| d_loss: 0.647| gp_loss: 0.060| r_loss: 0.058| p_loss: 0.081| v_loss: 0.022| per_loss: 0.306 | a_loss: 0.529
Train: Epoch [1996/3000], Step [150/158]| g_loss: 0.687| d_loss: 0.660| gp_loss: 0.060| r_loss: 0.058| p_loss: 0.079| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.537
Train: Epoch [1997/3000], Step [30/158]| g_loss: 0.675| d_loss: 0.660| gp_loss: 0.141| r_loss: 0.055| p_loss: 0.079| v_loss: 0.022| per_loss: 0.303 | a_loss: 0.529
Train: Epoch [1997/3000], Step [60/158]| g_loss: 0.652| d_loss: 0.607| gp_loss: 0.057| r_loss: 0.055| p_loss: 0.080| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.503
Train: Epoch [1997/3000], Step [90/158]| g_loss: 0.689| d_loss: 0.638| gp_loss: 0.058| r_loss: 0.059| p_loss: 0.080| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.538
Train: Epoch [1997/3000], Step [120/158]| g_loss: 0.667| d_loss: 0.689| gp_loss: 0.057| r_loss: 0.058| p_loss: 0.080| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.516
Train: Epoch [1997/3000], Step [150/158]| g_loss: 0.668| d_loss: 0.579| gp_loss: 0.062| r_loss: 0.058| p_loss: 0.082| v_loss: 0.023| per_loss: 0.314 | a_loss: 0.514
Train: Epoch [1998/3000], Step [30/158]| g_loss: 0.707| d_loss: 0.657| gp_loss: 0.101| r_loss: 0.057| p_loss: 0.085| v_loss: 0.022| per_loss: 0.326 | a_loss: 0.553
Train: Epoch [1998/3000], Step [60/158]| g_loss: 0.664| d_loss: 0.649| gp_loss: 0.061| r_loss: 0.058| p_loss: 0.084| v_loss: 0.022| per_loss: 0.327 | a_loss: 0.509
Train: Epoch [1998/3000], Step [90/158]| g_loss: 0.708| d_loss: 0.601| gp_loss: 0.057| r_loss: 0.061| p_loss: 0.094| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.547
Train: Epoch [1998/3000], Step [120/158]| g_loss: 0.651| d_loss: 0.633| gp_loss: 0.060| r_loss: 0.059| p_loss: 0.088| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.495
Train: Epoch [1998/3000], Step [150/158]| g_loss: 0.713| d_loss: 0.600| gp_loss: 0.064| r_loss: 0.061| p_loss: 0.084| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.558
Train: Epoch [1999/3000], Step [30/158]| g_loss: 0.696| d_loss: 0.661| gp_loss: 0.151| r_loss: 0.055| p_loss: 0.078| v_loss: 0.021| per_loss: 0.323 | a_loss: 0.548
Train: Epoch [1999/3000], Step [60/158]| g_loss: 0.722| d_loss: 0.534| gp_loss: 0.055| r_loss: 0.057| p_loss: 0.077| v_loss: 0.022| per_loss: 0.303 | a_loss: 0.575
Train: Epoch [1999/3000], Step [90/158]| g_loss: 0.665| d_loss: 0.616| gp_loss: 0.055| r_loss: 0.054| p_loss: 0.076| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.522
Train: Epoch [1999/3000], Step [120/158]| g_loss: 0.667| d_loss: 0.680| gp_loss: 0.056| r_loss: 0.059| p_loss: 0.079| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.516
Train: Epoch [1999/3000], Step [150/158]| g_loss: 0.645| d_loss: 0.653| gp_loss: 0.057| r_loss: 0.059| p_loss: 0.082| v_loss: 0.022| per_loss: 0.307 | a_loss: 0.492
Train: Epoch [2000/3000], Step [30/158]| g_loss: 0.641| d_loss: 0.775| gp_loss: 0.185| r_loss: 0.057| p_loss: 0.083| v_loss: 0.023| per_loss: 0.327 | a_loss: 0.486
Train: Epoch [2000/3000], Step [60/158]| g_loss: 0.665| d_loss: 0.585| gp_loss: 0.054| r_loss: 0.058| p_loss: 0.080| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.516
Train: Epoch [2000/3000], Step [90/158]| g_loss: 0.724| d_loss: 0.580| gp_loss: 0.059| r_loss: 0.055| p_loss: 0.081| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.577
Train: Epoch [2000/3000], Step [120/158]| g_loss: 0.699| d_loss: 0.601| gp_loss: 0.055| r_loss: 0.058| p_loss: 0.080| v_loss: 0.022| per_loss: 0.311 | a_loss: 0.548
Train: Epoch [2000/3000], Step [150/158]| g_loss: 0.681| d_loss: 0.586| gp_loss: 0.058| r_loss: 0.058| p_loss: 0.081| v_loss: 0.022| per_loss: 0.324 | a_loss: 0.527
Test: Epoch [2000/3000]| g_loss: 0.609| r_loss: 0.372| p_loss: 0.302| v_loss: 0.021
Train: Epoch [2001/3000], Step [30/158]| g_loss: 0.648| d_loss: 0.721| gp_loss: 0.058| r_loss: 0.058| p_loss: 0.082| v_loss: 0.022| per_loss: 0.326 | a_loss: 0.494
Train: Epoch [2001/3000], Step [60/158]| g_loss: 0.619| d_loss: 0.631| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.083| v_loss: 0.023| per_loss: 0.298 | a_loss: 0.466
Train: Epoch [2001/3000], Step [90/158]| g_loss: 0.642| d_loss: 0.641| gp_loss: 0.057| r_loss: 0.056| p_loss: 0.079| v_loss: 0.020| per_loss: 0.318 | a_loss: 0.494
Train: Epoch [2001/3000], Step [120/158]| g_loss: 0.708| d_loss: 0.549| gp_loss: 0.062| r_loss: 0.057| p_loss: 0.076| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.560
Train: Epoch [2001/3000], Step [150/158]| g_loss: 0.691| d_loss: 0.564| gp_loss: 0.061| r_loss: 0.056| p_loss: 0.081| v_loss: 0.022| per_loss: 0.307 | a_loss: 0.542
Train: Epoch [2002/3000], Step [30/158]| g_loss: 0.675| d_loss: 0.731| gp_loss: 0.146| r_loss: 0.057| p_loss: 0.083| v_loss: 0.021| per_loss: 0.316 | a_loss: 0.524
Train: Epoch [2002/3000], Step [60/158]| g_loss: 0.672| d_loss: 0.618| gp_loss: 0.058| r_loss: 0.057| p_loss: 0.078| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.525
Train: Epoch [2002/3000], Step [90/158]| g_loss: 0.731| d_loss: 0.552| gp_loss: 0.057| r_loss: 0.058| p_loss: 0.079| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.580
Train: Epoch [2002/3000], Step [120/158]| g_loss: 0.660| d_loss: 0.624| gp_loss: 0.060| r_loss: 0.054| p_loss: 0.078| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.515
Train: Epoch [2002/3000], Step [150/158]| g_loss: 0.725| d_loss: 0.653| gp_loss: 0.059| r_loss: 0.059| p_loss: 0.081| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.572
Train: Epoch [2003/3000], Step [30/158]| g_loss: 0.641| d_loss: 0.824| gp_loss: 0.213| r_loss: 0.058| p_loss: 0.083| v_loss: 0.021| per_loss: 0.318 | a_loss: 0.488
Train: Epoch [2003/3000], Step [60/158]| g_loss: 0.669| d_loss: 0.575| gp_loss: 0.052| r_loss: 0.058| p_loss: 0.080| v_loss: 0.023| per_loss: 0.320 | a_loss: 0.516
Train: Epoch [2003/3000], Step [90/158]| g_loss: 0.740| d_loss: 0.543| gp_loss: 0.052| r_loss: 0.057| p_loss: 0.076| v_loss: 0.021| per_loss: 0.319 | a_loss: 0.592
Train: Epoch [2003/3000], Step [120/158]| g_loss: 0.639| d_loss: 0.696| gp_loss: 0.050| r_loss: 0.057| p_loss: 0.080| v_loss: 0.022| per_loss: 0.300 | a_loss: 0.490
Train: Epoch [2003/3000], Step [150/158]| g_loss: 0.649| d_loss: 0.610| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.078| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.504
Train: Epoch [2004/3000], Step [30/158]| g_loss: 0.716| d_loss: 0.596| gp_loss: 0.144| r_loss: 0.056| p_loss: 0.077| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.567
Train: Epoch [2004/3000], Step [60/158]| g_loss: 0.705| d_loss: 0.659| gp_loss: 0.051| r_loss: 0.057| p_loss: 0.083| v_loss: 0.022| per_loss: 0.307 | a_loss: 0.553
Train: Epoch [2004/3000], Step [90/158]| g_loss: 0.696| d_loss: 0.608| gp_loss: 0.050| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.548
Train: Epoch [2004/3000], Step [120/158]| g_loss: 0.667| d_loss: 0.631| gp_loss: 0.052| r_loss: 0.057| p_loss: 0.077| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.519
Train: Epoch [2004/3000], Step [150/158]| g_loss: 0.648| d_loss: 0.671| gp_loss: 0.057| r_loss: 0.060| p_loss: 0.085| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.493
Train: Epoch [2005/3000], Step [30/158]| g_loss: 0.653| d_loss: 0.766| gp_loss: 0.120| r_loss: 0.058| p_loss: 0.085| v_loss: 0.022| per_loss: 0.306 | a_loss: 0.500
Train: Epoch [2005/3000], Step [60/158]| g_loss: 0.635| d_loss: 0.617| gp_loss: 0.054| r_loss: 0.057| p_loss: 0.078| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.486
Train: Epoch [2005/3000], Step [90/158]| g_loss: 0.662| d_loss: 0.611| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.079| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.512
Train: Epoch [2005/3000], Step [120/158]| g_loss: 0.665| d_loss: 0.605| gp_loss: 0.059| r_loss: 0.057| p_loss: 0.079| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.516
Train: Epoch [2005/3000], Step [150/158]| g_loss: 0.709| d_loss: 0.632| gp_loss: 0.059| r_loss: 0.061| p_loss: 0.082| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.553
Train: Epoch [2006/3000], Step [30/158]| g_loss: 0.702| d_loss: 0.724| gp_loss: 0.267| r_loss: 0.055| p_loss: 0.077| v_loss: 0.022| per_loss: 0.336 | a_loss: 0.553
Train: Epoch [2006/3000], Step [60/158]| g_loss: 0.718| d_loss: 0.618| gp_loss: 0.046| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.573
Train: Epoch [2006/3000], Step [90/158]| g_loss: 0.666| d_loss: 0.662| gp_loss: 0.052| r_loss: 0.058| p_loss: 0.079| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.516
Train: Epoch [2006/3000], Step [120/158]| g_loss: 0.667| d_loss: 0.563| gp_loss: 0.051| r_loss: 0.067| p_loss: 0.101| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.498
Train: Epoch [2006/3000], Step [150/158]| g_loss: 0.647| d_loss: 0.712| gp_loss: 0.053| r_loss: 0.061| p_loss: 0.089| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.489
Train: Epoch [2007/3000], Step [30/158]| g_loss: 0.659| d_loss: 0.709| gp_loss: 0.131| r_loss: 0.062| p_loss: 0.091| v_loss: 0.022| per_loss: 0.303 | a_loss: 0.500
Train: Epoch [2007/3000], Step [60/158]| g_loss: 0.702| d_loss: 0.535| gp_loss: 0.052| r_loss: 0.059| p_loss: 0.087| v_loss: 0.022| per_loss: 0.307 | a_loss: 0.546
Train: Epoch [2007/3000], Step [90/158]| g_loss: 0.695| d_loss: 0.608| gp_loss: 0.052| r_loss: 0.061| p_loss: 0.083| v_loss: 0.022| per_loss: 0.301 | a_loss: 0.541
Train: Epoch [2007/3000], Step [120/158]| g_loss: 0.654| d_loss: 0.622| gp_loss: 0.054| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.325 | a_loss: 0.508
Train: Epoch [2007/3000], Step [150/158]| g_loss: 0.674| d_loss: 0.698| gp_loss: 0.055| r_loss: 0.057| p_loss: 0.077| v_loss: 0.021| per_loss: 0.318 | a_loss: 0.525
Train: Epoch [2008/3000], Step [30/158]| g_loss: 0.671| d_loss: 0.659| gp_loss: 0.187| r_loss: 0.060| p_loss: 0.080| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.517
Train: Epoch [2008/3000], Step [60/158]| g_loss: 0.700| d_loss: 0.637| gp_loss: 0.050| r_loss: 0.057| p_loss: 0.080| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.551
Train: Epoch [2008/3000], Step [90/158]| g_loss: 0.667| d_loss: 0.600| gp_loss: 0.053| r_loss: 0.055| p_loss: 0.077| v_loss: 0.022| per_loss: 0.300 | a_loss: 0.521
Train: Epoch [2008/3000], Step [120/158]| g_loss: 0.679| d_loss: 0.614| gp_loss: 0.055| r_loss: 0.056| p_loss: 0.078| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.532
Train: Epoch [2008/3000], Step [150/158]| g_loss: 0.693| d_loss: 0.597| gp_loss: 0.055| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.546
Train: Epoch [2009/3000], Step [30/158]| g_loss: 0.623| d_loss: 0.807| gp_loss: 0.162| r_loss: 0.055| p_loss: 0.074| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.479
Train: Epoch [2009/3000], Step [60/158]| g_loss: 0.677| d_loss: 0.546| gp_loss: 0.051| r_loss: 0.055| p_loss: 0.080| v_loss: 0.022| per_loss: 0.318 | a_loss: 0.527
Train: Epoch [2009/3000], Step [90/158]| g_loss: 0.674| d_loss: 0.609| gp_loss: 0.053| r_loss: 0.057| p_loss: 0.075| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.525
Train: Epoch [2009/3000], Step [120/158]| g_loss: 0.706| d_loss: 0.608| gp_loss: 0.054| r_loss: 0.057| p_loss: 0.079| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.556
Train: Epoch [2009/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.657| gp_loss: 0.058| r_loss: 0.058| p_loss: 0.080| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.517
Train: Epoch [2010/3000], Step [30/158]| g_loss: 0.653| d_loss: 0.749| gp_loss: 0.153| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.506
Train: Epoch [2010/3000], Step [60/158]| g_loss: 0.648| d_loss: 0.563| gp_loss: 0.055| r_loss: 0.055| p_loss: 0.073| v_loss: 0.021| per_loss: 0.321 | a_loss: 0.504
Train: Epoch [2010/3000], Step [90/158]| g_loss: 0.758| d_loss: 0.508| gp_loss: 0.053| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.613
Train: Epoch [2010/3000], Step [120/158]| g_loss: 0.661| d_loss: 0.584| gp_loss: 0.051| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.316 | a_loss: 0.515
Train: Epoch [2010/3000], Step [150/158]| g_loss: 0.688| d_loss: 0.685| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.079| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.539
Train: Epoch [2011/3000], Step [30/158]| g_loss: 0.636| d_loss: 0.680| gp_loss: 0.138| r_loss: 0.057| p_loss: 0.080| v_loss: 0.022| per_loss: 0.304 | a_loss: 0.487
Train: Epoch [2011/3000], Step [60/158]| g_loss: 0.665| d_loss: 0.672| gp_loss: 0.053| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.318 | a_loss: 0.518
Train: Epoch [2011/3000], Step [90/158]| g_loss: 0.666| d_loss: 0.616| gp_loss: 0.053| r_loss: 0.055| p_loss: 0.078| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.519
Train: Epoch [2011/3000], Step [120/158]| g_loss: 0.704| d_loss: 0.584| gp_loss: 0.057| r_loss: 0.058| p_loss: 0.076| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.555
Train: Epoch [2011/3000], Step [150/158]| g_loss: 0.686| d_loss: 0.614| gp_loss: 0.055| r_loss: 0.055| p_loss: 0.079| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.539
Train: Epoch [2012/3000], Step [30/158]| g_loss: 0.676| d_loss: 0.735| gp_loss: 0.156| r_loss: 0.056| p_loss: 0.081| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.527
Train: Epoch [2012/3000], Step [60/158]| g_loss: 0.665| d_loss: 0.570| gp_loss: 0.051| r_loss: 0.058| p_loss: 0.081| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.515
Train: Epoch [2012/3000], Step [90/158]| g_loss: 0.693| d_loss: 0.633| gp_loss: 0.057| r_loss: 0.061| p_loss: 0.084| v_loss: 0.022| per_loss: 0.298 | a_loss: 0.538
Train: Epoch [2012/3000], Step [120/158]| g_loss: 0.683| d_loss: 0.687| gp_loss: 0.053| r_loss: 0.061| p_loss: 0.085| v_loss: 0.022| per_loss: 0.332 | a_loss: 0.524
Train: Epoch [2012/3000], Step [150/158]| g_loss: 0.706| d_loss: 0.574| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.087| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.549
Train: Epoch [2013/3000], Step [30/158]| g_loss: 0.717| d_loss: 0.696| gp_loss: 0.193| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.568
Train: Epoch [2013/3000], Step [60/158]| g_loss: 0.667| d_loss: 0.638| gp_loss: 0.050| r_loss: 0.058| p_loss: 0.081| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.517
Train: Epoch [2013/3000], Step [90/158]| g_loss: 0.649| d_loss: 0.730| gp_loss: 0.048| r_loss: 0.061| p_loss: 0.084| v_loss: 0.023| per_loss: 0.314 | a_loss: 0.492
Train: Epoch [2013/3000], Step [120/158]| g_loss: 0.668| d_loss: 0.488| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.079| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.518
Train: Epoch [2013/3000], Step [150/158]| g_loss: 0.703| d_loss: 0.609| gp_loss: 0.053| r_loss: 0.053| p_loss: 0.073| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.562
Train: Epoch [2014/3000], Step [30/158]| g_loss: 0.683| d_loss: 0.631| gp_loss: 0.129| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.540
Train: Epoch [2014/3000], Step [60/158]| g_loss: 0.700| d_loss: 0.604| gp_loss: 0.052| r_loss: 0.059| p_loss: 0.078| v_loss: 0.022| per_loss: 0.324 | a_loss: 0.547
Train: Epoch [2014/3000], Step [90/158]| g_loss: 0.691| d_loss: 0.641| gp_loss: 0.054| r_loss: 0.053| p_loss: 0.075| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.547
Train: Epoch [2014/3000], Step [120/158]| g_loss: 0.641| d_loss: 0.588| gp_loss: 0.051| r_loss: 0.057| p_loss: 0.079| v_loss: 0.021| per_loss: 0.324 | a_loss: 0.491
Train: Epoch [2014/3000], Step [150/158]| g_loss: 0.676| d_loss: 0.639| gp_loss: 0.059| r_loss: 0.057| p_loss: 0.081| v_loss: 0.021| per_loss: 0.293 | a_loss: 0.527
Train: Epoch [2015/3000], Step [30/158]| g_loss: 0.655| d_loss: 0.827| gp_loss: 0.154| r_loss: 0.058| p_loss: 0.082| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.504
Train: Epoch [2015/3000], Step [60/158]| g_loss: 0.602| d_loss: 0.683| gp_loss: 0.054| r_loss: 0.055| p_loss: 0.078| v_loss: 0.021| per_loss: 0.331 | a_loss: 0.453
Train: Epoch [2015/3000], Step [90/158]| g_loss: 0.665| d_loss: 0.610| gp_loss: 0.051| r_loss: 0.059| p_loss: 0.083| v_loss: 0.023| per_loss: 0.306 | a_loss: 0.511
Train: Epoch [2015/3000], Step [120/158]| g_loss: 0.699| d_loss: 0.495| gp_loss: 0.060| r_loss: 0.056| p_loss: 0.080| v_loss: 0.022| per_loss: 0.304 | a_loss: 0.550
Train: Epoch [2015/3000], Step [150/158]| g_loss: 0.725| d_loss: 0.522| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.076| v_loss: 0.022| per_loss: 0.307 | a_loss: 0.578
Train: Epoch [2016/3000], Step [30/158]| g_loss: 0.716| d_loss: 0.633| gp_loss: 0.125| r_loss: 0.057| p_loss: 0.075| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.570
Train: Epoch [2016/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.698| gp_loss: 0.055| r_loss: 0.057| p_loss: 0.081| v_loss: 0.022| per_loss: 0.306 | a_loss: 0.523
Train: Epoch [2016/3000], Step [90/158]| g_loss: 0.662| d_loss: 0.584| gp_loss: 0.051| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.321 | a_loss: 0.515
Train: Epoch [2016/3000], Step [120/158]| g_loss: 0.708| d_loss: 0.583| gp_loss: 0.057| r_loss: 0.056| p_loss: 0.079| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.561
Train: Epoch [2016/3000], Step [150/158]| g_loss: 0.670| d_loss: 0.626| gp_loss: 0.057| r_loss: 0.055| p_loss: 0.078| v_loss: 0.022| per_loss: 0.306 | a_loss: 0.524
Train: Epoch [2017/3000], Step [30/158]| g_loss: 0.699| d_loss: 0.656| gp_loss: 0.148| r_loss: 0.058| p_loss: 0.080| v_loss: 0.022| per_loss: 0.322 | a_loss: 0.547
Train: Epoch [2017/3000], Step [60/158]| g_loss: 0.696| d_loss: 0.611| gp_loss: 0.054| r_loss: 0.057| p_loss: 0.081| v_loss: 0.022| per_loss: 0.302 | a_loss: 0.546
Train: Epoch [2017/3000], Step [90/158]| g_loss: 0.671| d_loss: 0.583| gp_loss: 0.059| r_loss: 0.057| p_loss: 0.078| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.523
Train: Epoch [2017/3000], Step [120/158]| g_loss: 0.663| d_loss: 0.620| gp_loss: 0.055| r_loss: 0.053| p_loss: 0.075| v_loss: 0.021| per_loss: 0.325 | a_loss: 0.518
Train: Epoch [2017/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.640| gp_loss: 0.057| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.515
Train: Epoch [2018/3000], Step [30/158]| g_loss: 0.669| d_loss: 0.709| gp_loss: 0.145| r_loss: 0.056| p_loss: 0.079| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.522
Train: Epoch [2018/3000], Step [60/158]| g_loss: 0.664| d_loss: 0.626| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.078| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.515
Train: Epoch [2018/3000], Step [90/158]| g_loss: 0.664| d_loss: 0.681| gp_loss: 0.057| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.321 | a_loss: 0.514
Train: Epoch [2018/3000], Step [120/158]| g_loss: 0.659| d_loss: 0.553| gp_loss: 0.060| r_loss: 0.057| p_loss: 0.080| v_loss: 0.022| per_loss: 0.298 | a_loss: 0.509
Train: Epoch [2018/3000], Step [150/158]| g_loss: 0.758| d_loss: 0.527| gp_loss: 0.061| r_loss: 0.060| p_loss: 0.086| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.602
Train: Epoch [2019/3000], Step [30/158]| g_loss: 0.672| d_loss: 0.779| gp_loss: 0.140| r_loss: 0.059| p_loss: 0.087| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.516
Train: Epoch [2019/3000], Step [60/158]| g_loss: 0.649| d_loss: 0.627| gp_loss: 0.055| r_loss: 0.058| p_loss: 0.082| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.498
Train: Epoch [2019/3000], Step [90/158]| g_loss: 0.665| d_loss: 0.613| gp_loss: 0.054| r_loss: 0.057| p_loss: 0.080| v_loss: 0.022| per_loss: 0.328 | a_loss: 0.514
Train: Epoch [2019/3000], Step [120/158]| g_loss: 0.672| d_loss: 0.640| gp_loss: 0.058| r_loss: 0.056| p_loss: 0.079| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.524
Train: Epoch [2019/3000], Step [150/158]| g_loss: 0.709| d_loss: 0.518| gp_loss: 0.063| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.298 | a_loss: 0.566
Train: Epoch [2020/3000], Step [30/158]| g_loss: 0.685| d_loss: 0.724| gp_loss: 0.157| r_loss: 0.057| p_loss: 0.081| v_loss: 0.023| per_loss: 0.327 | a_loss: 0.532
Train: Epoch [2020/3000], Step [60/158]| g_loss: 0.646| d_loss: 0.619| gp_loss: 0.053| r_loss: 0.054| p_loss: 0.076| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.502
Train: Epoch [2020/3000], Step [90/158]| g_loss: 0.664| d_loss: 0.671| gp_loss: 0.055| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.517
Train: Epoch [2020/3000], Step [120/158]| g_loss: 0.753| d_loss: 0.520| gp_loss: 0.060| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.599
Train: Epoch [2020/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.677| gp_loss: 0.058| r_loss: 0.057| p_loss: 0.080| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.514
Train: Epoch [2021/3000], Step [30/158]| g_loss: 0.643| d_loss: 0.745| gp_loss: 0.205| r_loss: 0.057| p_loss: 0.080| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.493
Train: Epoch [2021/3000], Step [60/158]| g_loss: 0.662| d_loss: 0.648| gp_loss: 0.051| r_loss: 0.057| p_loss: 0.081| v_loss: 0.022| per_loss: 0.304 | a_loss: 0.512
Train: Epoch [2021/3000], Step [90/158]| g_loss: 0.636| d_loss: 0.738| gp_loss: 0.053| r_loss: 0.057| p_loss: 0.080| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.487
Train: Epoch [2021/3000], Step [120/158]| g_loss: 0.659| d_loss: 0.561| gp_loss: 0.057| r_loss: 0.056| p_loss: 0.079| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.509
Train: Epoch [2021/3000], Step [150/158]| g_loss: 0.748| d_loss: 0.519| gp_loss: 0.056| r_loss: 0.058| p_loss: 0.079| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.596
Train: Epoch [2022/3000], Step [30/158]| g_loss: 0.711| d_loss: 0.699| gp_loss: 0.138| r_loss: 0.057| p_loss: 0.080| v_loss: 0.022| per_loss: 0.323 | a_loss: 0.559
Train: Epoch [2022/3000], Step [60/158]| g_loss: 0.654| d_loss: 0.550| gp_loss: 0.055| r_loss: 0.053| p_loss: 0.075| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.513
Train: Epoch [2022/3000], Step [90/158]| g_loss: 0.674| d_loss: 0.670| gp_loss: 0.051| r_loss: 0.056| p_loss: 0.074| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.528
Train: Epoch [2022/3000], Step [120/158]| g_loss: 0.712| d_loss: 0.531| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.077| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.564
Train: Epoch [2022/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.645| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.081| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.524
Train: Epoch [2023/3000], Step [30/158]| g_loss: 0.687| d_loss: 0.671| gp_loss: 0.103| r_loss: 0.059| p_loss: 0.088| v_loss: 0.023| per_loss: 0.330 | a_loss: 0.529
Train: Epoch [2023/3000], Step [60/158]| g_loss: 0.719| d_loss: 0.568| gp_loss: 0.055| r_loss: 0.064| p_loss: 0.093| v_loss: 0.023| per_loss: 0.306 | a_loss: 0.555
Train: Epoch [2023/3000], Step [90/158]| g_loss: 0.699| d_loss: 0.579| gp_loss: 0.057| r_loss: 0.059| p_loss: 0.086| v_loss: 0.022| per_loss: 0.334 | a_loss: 0.541
Train: Epoch [2023/3000], Step [120/158]| g_loss: 0.716| d_loss: 0.576| gp_loss: 0.055| r_loss: 0.057| p_loss: 0.078| v_loss: 0.022| per_loss: 0.320 | a_loss: 0.566
Train: Epoch [2023/3000], Step [150/158]| g_loss: 0.666| d_loss: 0.699| gp_loss: 0.058| r_loss: 0.059| p_loss: 0.082| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.513
Train: Epoch [2024/3000], Step [30/158]| g_loss: 0.627| d_loss: 0.791| gp_loss: 0.170| r_loss: 0.056| p_loss: 0.081| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.480
Train: Epoch [2024/3000], Step [60/158]| g_loss: 0.676| d_loss: 0.592| gp_loss: 0.057| r_loss: 0.061| p_loss: 0.085| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.519
Train: Epoch [2024/3000], Step [90/158]| g_loss: 0.650| d_loss: 0.652| gp_loss: 0.057| r_loss: 0.060| p_loss: 0.086| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.494
Train: Epoch [2024/3000], Step [120/158]| g_loss: 0.724| d_loss: 0.534| gp_loss: 0.057| r_loss: 0.059| p_loss: 0.081| v_loss: 0.023| per_loss: 0.325 | a_loss: 0.569
Train: Epoch [2024/3000], Step [150/158]| g_loss: 0.708| d_loss: 0.597| gp_loss: 0.053| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.319 | a_loss: 0.563
Train: Epoch [2025/3000], Step [30/158]| g_loss: 0.637| d_loss: 0.750| gp_loss: 0.176| r_loss: 0.055| p_loss: 0.081| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.488
Train: Epoch [2025/3000], Step [60/158]| g_loss: 0.672| d_loss: 0.650| gp_loss: 0.056| r_loss: 0.058| p_loss: 0.080| v_loss: 0.022| per_loss: 0.295 | a_loss: 0.523
Train: Epoch [2025/3000], Step [90/158]| g_loss: 0.671| d_loss: 0.609| gp_loss: 0.054| r_loss: 0.058| p_loss: 0.079| v_loss: 0.021| per_loss: 0.318 | a_loss: 0.521
Train: Epoch [2025/3000], Step [120/158]| g_loss: 0.654| d_loss: 0.601| gp_loss: 0.057| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.508
Train: Epoch [2025/3000], Step [150/158]| g_loss: 0.692| d_loss: 0.590| gp_loss: 0.061| r_loss: 0.056| p_loss: 0.076| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.546
Train: Epoch [2026/3000], Step [30/158]| g_loss: 0.624| d_loss: 0.781| gp_loss: 0.100| r_loss: 0.061| p_loss: 0.085| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.467
Train: Epoch [2026/3000], Step [60/158]| g_loss: 0.660| d_loss: 0.590| gp_loss: 0.062| r_loss: 0.059| p_loss: 0.085| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.505
Train: Epoch [2026/3000], Step [90/158]| g_loss: 0.691| d_loss: 0.601| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.076| v_loss: 0.021| per_loss: 0.333 | a_loss: 0.542
Train: Epoch [2026/3000], Step [120/158]| g_loss: 0.723| d_loss: 0.507| gp_loss: 0.058| r_loss: 0.055| p_loss: 0.079| v_loss: 0.021| per_loss: 0.316 | a_loss: 0.576
Train: Epoch [2026/3000], Step [150/158]| g_loss: 0.690| d_loss: 0.618| gp_loss: 0.059| r_loss: 0.056| p_loss: 0.078| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.541
Train: Epoch [2027/3000], Step [30/158]| g_loss: 0.699| d_loss: 0.674| gp_loss: 0.165| r_loss: 0.056| p_loss: 0.078| v_loss: 0.022| per_loss: 0.320 | a_loss: 0.550
Train: Epoch [2027/3000], Step [60/158]| g_loss: 0.665| d_loss: 0.701| gp_loss: 0.052| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.522
Train: Epoch [2027/3000], Step [90/158]| g_loss: 0.665| d_loss: 0.589| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.078| v_loss: 0.022| per_loss: 0.329 | a_loss: 0.516
Train: Epoch [2027/3000], Step [120/158]| g_loss: 0.683| d_loss: 0.600| gp_loss: 0.057| r_loss: 0.060| p_loss: 0.081| v_loss: 0.023| per_loss: 0.312 | a_loss: 0.529
Train: Epoch [2027/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.640| gp_loss: 0.057| r_loss: 0.055| p_loss: 0.076| v_loss: 0.020| per_loss: 0.309 | a_loss: 0.516
Train: Epoch [2028/3000], Step [30/158]| g_loss: 0.643| d_loss: 0.806| gp_loss: 0.174| r_loss: 0.058| p_loss: 0.079| v_loss: 0.021| per_loss: 0.324 | a_loss: 0.491
Train: Epoch [2028/3000], Step [60/158]| g_loss: 0.684| d_loss: 0.564| gp_loss: 0.060| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.318 | a_loss: 0.535
Train: Epoch [2028/3000], Step [90/158]| g_loss: 0.668| d_loss: 0.621| gp_loss: 0.052| r_loss: 0.057| p_loss: 0.082| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.517
Train: Epoch [2028/3000], Step [120/158]| g_loss: 0.690| d_loss: 0.565| gp_loss: 0.056| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.320 | a_loss: 0.545
Train: Epoch [2028/3000], Step [150/158]| g_loss: 0.670| d_loss: 0.581| gp_loss: 0.055| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.525
Train: Epoch [2029/3000], Step [30/158]| g_loss: 0.678| d_loss: 0.729| gp_loss: 0.135| r_loss: 0.054| p_loss: 0.073| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.535
Train: Epoch [2029/3000], Step [60/158]| g_loss: 0.631| d_loss: 0.612| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.074| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.484
Train: Epoch [2029/3000], Step [90/158]| g_loss: 0.686| d_loss: 0.596| gp_loss: 0.060| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.540
Train: Epoch [2029/3000], Step [120/158]| g_loss: 0.686| d_loss: 0.620| gp_loss: 0.057| r_loss: 0.058| p_loss: 0.074| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.540
Train: Epoch [2029/3000], Step [150/158]| g_loss: 0.678| d_loss: 0.561| gp_loss: 0.059| r_loss: 0.055| p_loss: 0.078| v_loss: 0.021| per_loss: 0.323 | a_loss: 0.531
Train: Epoch [2030/3000], Step [30/158]| g_loss: 0.677| d_loss: 0.678| gp_loss: 0.182| r_loss: 0.053| p_loss: 0.072| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.535
Train: Epoch [2030/3000], Step [60/158]| g_loss: 0.689| d_loss: 0.680| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.542
Train: Epoch [2030/3000], Step [90/158]| g_loss: 0.664| d_loss: 0.572| gp_loss: 0.059| r_loss: 0.056| p_loss: 0.075| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.518
Train: Epoch [2030/3000], Step [120/158]| g_loss: 0.646| d_loss: 0.727| gp_loss: 0.057| r_loss: 0.057| p_loss: 0.080| v_loss: 0.022| per_loss: 0.326 | a_loss: 0.494
Train: Epoch [2030/3000], Step [150/158]| g_loss: 0.677| d_loss: 0.570| gp_loss: 0.057| r_loss: 0.056| p_loss: 0.079| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.530
Train: Epoch [2031/3000], Step [30/158]| g_loss: 0.703| d_loss: 0.741| gp_loss: 0.203| r_loss: 0.054| p_loss: 0.077| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.558
Train: Epoch [2031/3000], Step [60/158]| g_loss: 0.680| d_loss: 0.575| gp_loss: 0.051| r_loss: 0.058| p_loss: 0.080| v_loss: 0.023| per_loss: 0.332 | a_loss: 0.526
Train: Epoch [2031/3000], Step [90/158]| g_loss: 0.651| d_loss: 0.728| gp_loss: 0.051| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.505
Train: Epoch [2031/3000], Step [120/158]| g_loss: 0.642| d_loss: 0.606| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.075| v_loss: 0.021| per_loss: 0.316 | a_loss: 0.495
Train: Epoch [2031/3000], Step [150/158]| g_loss: 0.719| d_loss: 0.561| gp_loss: 0.058| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.320 | a_loss: 0.571
Train: Epoch [2032/3000], Step [30/158]| g_loss: 0.632| d_loss: 0.768| gp_loss: 0.113| r_loss: 0.055| p_loss: 0.078| v_loss: 0.021| per_loss: 0.318 | a_loss: 0.485
Train: Epoch [2032/3000], Step [60/158]| g_loss: 0.631| d_loss: 0.663| gp_loss: 0.054| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.318 | a_loss: 0.486
Train: Epoch [2032/3000], Step [90/158]| g_loss: 0.681| d_loss: 0.629| gp_loss: 0.052| r_loss: 0.057| p_loss: 0.081| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.529
Train: Epoch [2032/3000], Step [120/158]| g_loss: 0.676| d_loss: 0.567| gp_loss: 0.057| r_loss: 0.054| p_loss: 0.076| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.531
Train: Epoch [2032/3000], Step [150/158]| g_loss: 0.718| d_loss: 0.537| gp_loss: 0.060| r_loss: 0.058| p_loss: 0.079| v_loss: 0.022| per_loss: 0.318 | a_loss: 0.567
Train: Epoch [2033/3000], Step [30/158]| g_loss: 0.719| d_loss: 0.713| gp_loss: 0.190| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.321 | a_loss: 0.571
Train: Epoch [2033/3000], Step [60/158]| g_loss: 0.684| d_loss: 0.616| gp_loss: 0.053| r_loss: 0.064| p_loss: 0.090| v_loss: 0.021| per_loss: 0.319 | a_loss: 0.522
Train: Epoch [2033/3000], Step [90/158]| g_loss: 0.700| d_loss: 0.571| gp_loss: 0.055| r_loss: 0.057| p_loss: 0.083| v_loss: 0.020| per_loss: 0.335 | a_loss: 0.548
Train: Epoch [2033/3000], Step [120/158]| g_loss: 0.698| d_loss: 0.640| gp_loss: 0.052| r_loss: 0.059| p_loss: 0.086| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.544
Train: Epoch [2033/3000], Step [150/158]| g_loss: 0.651| d_loss: 0.586| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.081| v_loss: 0.023| per_loss: 0.315 | a_loss: 0.500
Train: Epoch [2034/3000], Step [30/158]| g_loss: 0.630| d_loss: 0.775| gp_loss: 0.106| r_loss: 0.057| p_loss: 0.081| v_loss: 0.021| per_loss: 0.317 | a_loss: 0.479
Train: Epoch [2034/3000], Step [60/158]| g_loss: 0.669| d_loss: 0.637| gp_loss: 0.056| r_loss: 0.059| p_loss: 0.084| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.515
Train: Epoch [2034/3000], Step [90/158]| g_loss: 0.656| d_loss: 0.614| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.081| v_loss: 0.021| per_loss: 0.324 | a_loss: 0.506
Train: Epoch [2034/3000], Step [120/158]| g_loss: 0.645| d_loss: 0.568| gp_loss: 0.052| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.499
Train: Epoch [2034/3000], Step [150/158]| g_loss: 0.751| d_loss: 0.571| gp_loss: 0.061| r_loss: 0.059| p_loss: 0.079| v_loss: 0.022| per_loss: 0.322 | a_loss: 0.599
Train: Epoch [2035/3000], Step [30/158]| g_loss: 0.686| d_loss: 0.709| gp_loss: 0.186| r_loss: 0.055| p_loss: 0.074| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.541
Train: Epoch [2035/3000], Step [60/158]| g_loss: 0.648| d_loss: 0.642| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.079| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.500
Train: Epoch [2035/3000], Step [90/158]| g_loss: 0.727| d_loss: 0.538| gp_loss: 0.057| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.316 | a_loss: 0.581
Train: Epoch [2035/3000], Step [120/158]| g_loss: 0.686| d_loss: 0.647| gp_loss: 0.052| r_loss: 0.057| p_loss: 0.080| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.538
Train: Epoch [2035/3000], Step [150/158]| g_loss: 0.616| d_loss: 0.648| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.079| v_loss: 0.022| per_loss: 0.327 | a_loss: 0.468
Train: Epoch [2036/3000], Step [30/158]| g_loss: 0.675| d_loss: 0.738| gp_loss: 0.183| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.317 | a_loss: 0.530
Train: Epoch [2036/3000], Step [60/158]| g_loss: 0.649| d_loss: 0.675| gp_loss: 0.052| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.504
Train: Epoch [2036/3000], Step [90/158]| g_loss: 0.655| d_loss: 0.601| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.077| v_loss: 0.023| per_loss: 0.317 | a_loss: 0.508
Train: Epoch [2036/3000], Step [120/158]| g_loss: 0.672| d_loss: 0.665| gp_loss: 0.053| r_loss: 0.057| p_loss: 0.076| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.525
Train: Epoch [2036/3000], Step [150/158]| g_loss: 0.693| d_loss: 0.491| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.076| v_loss: 0.022| per_loss: 0.299 | a_loss: 0.547
Train: Epoch [2037/3000], Step [30/158]| g_loss: 0.645| d_loss: 0.674| gp_loss: 0.065| r_loss: 0.054| p_loss: 0.078| v_loss: 0.021| per_loss: 0.320 | a_loss: 0.499
Train: Epoch [2037/3000], Step [60/158]| g_loss: 0.707| d_loss: 0.601| gp_loss: 0.059| r_loss: 0.058| p_loss: 0.080| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.555
Train: Epoch [2037/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.634| gp_loss: 0.058| r_loss: 0.055| p_loss: 0.074| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.512
Train: Epoch [2037/3000], Step [120/158]| g_loss: 0.680| d_loss: 0.634| gp_loss: 0.058| r_loss: 0.056| p_loss: 0.075| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.536
Train: Epoch [2037/3000], Step [150/158]| g_loss: 0.621| d_loss: 0.647| gp_loss: 0.058| r_loss: 0.055| p_loss: 0.078| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.475
Train: Epoch [2038/3000], Step [30/158]| g_loss: 0.719| d_loss: 0.676| gp_loss: 0.177| r_loss: 0.056| p_loss: 0.078| v_loss: 0.022| per_loss: 0.320 | a_loss: 0.571
Train: Epoch [2038/3000], Step [60/158]| g_loss: 0.672| d_loss: 0.640| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.076| v_loss: 0.022| per_loss: 0.311 | a_loss: 0.523
Train: Epoch [2038/3000], Step [90/158]| g_loss: 0.628| d_loss: 0.677| gp_loss: 0.058| r_loss: 0.055| p_loss: 0.078| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.483
Train: Epoch [2038/3000], Step [120/158]| g_loss: 0.671| d_loss: 0.648| gp_loss: 0.059| r_loss: 0.054| p_loss: 0.079| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.526
Train: Epoch [2038/3000], Step [150/158]| g_loss: 0.651| d_loss: 0.616| gp_loss: 0.061| r_loss: 0.056| p_loss: 0.079| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.503
Train: Epoch [2039/3000], Step [30/158]| g_loss: 0.736| d_loss: 0.607| gp_loss: 0.149| r_loss: 0.058| p_loss: 0.079| v_loss: 0.022| per_loss: 0.332 | a_loss: 0.583
Train: Epoch [2039/3000], Step [60/158]| g_loss: 0.663| d_loss: 0.613| gp_loss: 0.053| r_loss: 0.058| p_loss: 0.081| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.512
Train: Epoch [2039/3000], Step [90/158]| g_loss: 0.682| d_loss: 0.603| gp_loss: 0.058| r_loss: 0.060| p_loss: 0.082| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.529
Train: Epoch [2039/3000], Step [120/158]| g_loss: 0.647| d_loss: 0.679| gp_loss: 0.057| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.304 | a_loss: 0.495
Train: Epoch [2039/3000], Step [150/158]| g_loss: 0.704| d_loss: 0.524| gp_loss: 0.062| r_loss: 0.062| p_loss: 0.082| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.549
Train: Epoch [2040/3000], Step [30/158]| g_loss: 0.642| d_loss: 0.765| gp_loss: 0.059| r_loss: 0.062| p_loss: 0.084| v_loss: 0.021| per_loss: 0.317 | a_loss: 0.486
Train: Epoch [2040/3000], Step [60/158]| g_loss: 0.689| d_loss: 0.570| gp_loss: 0.061| r_loss: 0.063| p_loss: 0.090| v_loss: 0.022| per_loss: 0.306 | a_loss: 0.529
Train: Epoch [2040/3000], Step [90/158]| g_loss: 0.708| d_loss: 0.585| gp_loss: 0.061| r_loss: 0.057| p_loss: 0.082| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.557
Train: Epoch [2040/3000], Step [120/158]| g_loss: 0.667| d_loss: 0.625| gp_loss: 0.060| r_loss: 0.057| p_loss: 0.080| v_loss: 0.021| per_loss: 0.318 | a_loss: 0.518
Train: Epoch [2040/3000], Step [150/158]| g_loss: 0.657| d_loss: 0.651| gp_loss: 0.063| r_loss: 0.057| p_loss: 0.078| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.508
Train: Epoch [2041/3000], Step [30/158]| g_loss: 0.669| d_loss: 0.697| gp_loss: 0.182| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.524
Train: Epoch [2041/3000], Step [60/158]| g_loss: 0.707| d_loss: 0.614| gp_loss: 0.057| r_loss: 0.055| p_loss: 0.078| v_loss: 0.021| per_loss: 0.320 | a_loss: 0.559
Train: Epoch [2041/3000], Step [90/158]| g_loss: 0.646| d_loss: 0.630| gp_loss: 0.059| r_loss: 0.058| p_loss: 0.079| v_loss: 0.022| per_loss: 0.324 | a_loss: 0.495
Train: Epoch [2041/3000], Step [120/158]| g_loss: 0.655| d_loss: 0.683| gp_loss: 0.060| r_loss: 0.057| p_loss: 0.078| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.508
Train: Epoch [2041/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.562| gp_loss: 0.061| r_loss: 0.054| p_loss: 0.074| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.515
Train: Epoch [2042/3000], Step [30/158]| g_loss: 0.645| d_loss: 0.863| gp_loss: 0.240| r_loss: 0.057| p_loss: 0.080| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.495
Train: Epoch [2042/3000], Step [60/158]| g_loss: 0.680| d_loss: 0.596| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.536
Train: Epoch [2042/3000], Step [90/158]| g_loss: 0.669| d_loss: 0.618| gp_loss: 0.053| r_loss: 0.059| p_loss: 0.077| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.521
Train: Epoch [2042/3000], Step [120/158]| g_loss: 0.685| d_loss: 0.610| gp_loss: 0.057| r_loss: 0.057| p_loss: 0.079| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.536
Train: Epoch [2042/3000], Step [150/158]| g_loss: 0.681| d_loss: 0.574| gp_loss: 0.057| r_loss: 0.056| p_loss: 0.078| v_loss: 0.022| per_loss: 0.318 | a_loss: 0.532
Train: Epoch [2043/3000], Step [30/158]| g_loss: 0.690| d_loss: 0.745| gp_loss: 0.163| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.547
Train: Epoch [2043/3000], Step [60/158]| g_loss: 0.651| d_loss: 0.591| gp_loss: 0.053| r_loss: 0.057| p_loss: 0.078| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.502
Train: Epoch [2043/3000], Step [90/158]| g_loss: 0.687| d_loss: 0.567| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.074| v_loss: 0.022| per_loss: 0.320 | a_loss: 0.540
Train: Epoch [2043/3000], Step [120/158]| g_loss: 0.651| d_loss: 0.671| gp_loss: 0.058| r_loss: 0.056| p_loss: 0.076| v_loss: 0.021| per_loss: 0.319 | a_loss: 0.503
Train: Epoch [2043/3000], Step [150/158]| g_loss: 0.682| d_loss: 0.565| gp_loss: 0.058| r_loss: 0.054| p_loss: 0.076| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.537
Train: Epoch [2044/3000], Step [30/158]| g_loss: 0.694| d_loss: 0.702| gp_loss: 0.168| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.551
Train: Epoch [2044/3000], Step [60/158]| g_loss: 0.684| d_loss: 0.609| gp_loss: 0.053| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.329 | a_loss: 0.539
Train: Epoch [2044/3000], Step [90/158]| g_loss: 0.627| d_loss: 0.691| gp_loss: 0.054| r_loss: 0.055| p_loss: 0.078| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.481
Train: Epoch [2044/3000], Step [120/158]| g_loss: 0.699| d_loss: 0.547| gp_loss: 0.057| r_loss: 0.057| p_loss: 0.076| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.550
Train: Epoch [2044/3000], Step [150/158]| g_loss: 0.635| d_loss: 0.660| gp_loss: 0.057| r_loss: 0.054| p_loss: 0.072| v_loss: 0.021| per_loss: 0.292 | a_loss: 0.495
Train: Epoch [2045/3000], Step [30/158]| g_loss: 0.657| d_loss: 0.679| gp_loss: 0.121| r_loss: 0.055| p_loss: 0.075| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.511
Train: Epoch [2045/3000], Step [60/158]| g_loss: 0.680| d_loss: 0.655| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.079| v_loss: 0.023| per_loss: 0.326 | a_loss: 0.529
Train: Epoch [2045/3000], Step [90/158]| g_loss: 0.667| d_loss: 0.592| gp_loss: 0.054| r_loss: 0.055| p_loss: 0.074| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.522
Train: Epoch [2045/3000], Step [120/158]| g_loss: 0.668| d_loss: 0.643| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.079| v_loss: 0.022| per_loss: 0.301 | a_loss: 0.519
Train: Epoch [2045/3000], Step [150/158]| g_loss: 0.676| d_loss: 0.617| gp_loss: 0.062| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.530
Train: Epoch [2046/3000], Step [30/158]| g_loss: 0.655| d_loss: 0.757| gp_loss: 0.129| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.291 | a_loss: 0.510
Train: Epoch [2046/3000], Step [60/158]| g_loss: 0.657| d_loss: 0.615| gp_loss: 0.057| r_loss: 0.056| p_loss: 0.078| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.508
Train: Epoch [2046/3000], Step [90/158]| g_loss: 0.681| d_loss: 0.542| gp_loss: 0.060| r_loss: 0.057| p_loss: 0.078| v_loss: 0.021| per_loss: 0.323 | a_loss: 0.531
Train: Epoch [2046/3000], Step [120/158]| g_loss: 0.724| d_loss: 0.595| gp_loss: 0.057| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.578
Train: Epoch [2046/3000], Step [150/158]| g_loss: 0.666| d_loss: 0.610| gp_loss: 0.061| r_loss: 0.057| p_loss: 0.078| v_loss: 0.021| per_loss: 0.296 | a_loss: 0.520
Train: Epoch [2047/3000], Step [30/158]| g_loss: 0.607| d_loss: 0.785| gp_loss: 0.163| r_loss: 0.055| p_loss: 0.081| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.458
Train: Epoch [2047/3000], Step [60/158]| g_loss: 0.719| d_loss: 0.636| gp_loss: 0.057| r_loss: 0.058| p_loss: 0.083| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.566
Train: Epoch [2047/3000], Step [90/158]| g_loss: 0.685| d_loss: 0.596| gp_loss: 0.059| r_loss: 0.055| p_loss: 0.080| v_loss: 0.022| per_loss: 0.326 | a_loss: 0.536
Train: Epoch [2047/3000], Step [120/158]| g_loss: 0.658| d_loss: 0.631| gp_loss: 0.063| r_loss: 0.058| p_loss: 0.079| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.508
Train: Epoch [2047/3000], Step [150/158]| g_loss: 0.684| d_loss: 0.629| gp_loss: 0.062| r_loss: 0.058| p_loss: 0.081| v_loss: 0.022| per_loss: 0.303 | a_loss: 0.532
Train: Epoch [2048/3000], Step [30/158]| g_loss: 0.709| d_loss: 0.720| gp_loss: 0.153| r_loss: 0.055| p_loss: 0.080| v_loss: 0.021| per_loss: 0.317 | a_loss: 0.561
Train: Epoch [2048/3000], Step [60/158]| g_loss: 0.624| d_loss: 0.665| gp_loss: 0.054| r_loss: 0.057| p_loss: 0.082| v_loss: 0.022| per_loss: 0.302 | a_loss: 0.474
Train: Epoch [2048/3000], Step [90/158]| g_loss: 0.645| d_loss: 0.650| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.319 | a_loss: 0.497
Train: Epoch [2048/3000], Step [120/158]| g_loss: 0.684| d_loss: 0.593| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.319 | a_loss: 0.536
Train: Epoch [2048/3000], Step [150/158]| g_loss: 0.680| d_loss: 0.550| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.076| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.533
Train: Epoch [2049/3000], Step [30/158]| g_loss: 0.660| d_loss: 0.749| gp_loss: 0.149| r_loss: 0.055| p_loss: 0.074| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.516
Train: Epoch [2049/3000], Step [60/158]| g_loss: 0.686| d_loss: 0.555| gp_loss: 0.054| r_loss: 0.058| p_loss: 0.076| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.537
Train: Epoch [2049/3000], Step [90/158]| g_loss: 0.681| d_loss: 0.555| gp_loss: 0.058| r_loss: 0.058| p_loss: 0.081| v_loss: 0.022| per_loss: 0.306 | a_loss: 0.530
Train: Epoch [2049/3000], Step [120/158]| g_loss: 0.676| d_loss: 0.596| gp_loss: 0.060| r_loss: 0.054| p_loss: 0.074| v_loss: 0.021| per_loss: 0.319 | a_loss: 0.532
Train: Epoch [2049/3000], Step [150/158]| g_loss: 0.692| d_loss: 0.602| gp_loss: 0.061| r_loss: 0.056| p_loss: 0.079| v_loss: 0.021| per_loss: 0.317 | a_loss: 0.544
Train: Epoch [2050/3000], Step [30/158]| g_loss: 0.679| d_loss: 0.647| gp_loss: 0.124| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.533
Train: Epoch [2050/3000], Step [60/158]| g_loss: 0.730| d_loss: 0.531| gp_loss: 0.057| r_loss: 0.056| p_loss: 0.075| v_loss: 0.021| per_loss: 0.327 | a_loss: 0.583
Train: Epoch [2050/3000], Step [90/158]| g_loss: 0.664| d_loss: 0.709| gp_loss: 0.058| r_loss: 0.058| p_loss: 0.079| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.514
Train: Epoch [2050/3000], Step [120/158]| g_loss: 0.616| d_loss: 0.606| gp_loss: 0.059| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.292 | a_loss: 0.473
Train: Epoch [2050/3000], Step [150/158]| g_loss: 0.672| d_loss: 0.674| gp_loss: 0.064| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.317 | a_loss: 0.523
Test: Epoch [2050/3000]| g_loss: 0.624| r_loss: 0.382| p_loss: 0.299| v_loss: 0.021
Train: Epoch [2051/3000], Step [30/158]| g_loss: 0.710| d_loss: 0.529| gp_loss: 0.058| r_loss: 0.055| p_loss: 0.076| v_loss: 0.022| per_loss: 0.311 | a_loss: 0.564
Train: Epoch [2051/3000], Step [60/158]| g_loss: 0.677| d_loss: 0.615| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.081| v_loss: 0.022| per_loss: 0.325 | a_loss: 0.526
Train: Epoch [2051/3000], Step [90/158]| g_loss: 0.669| d_loss: 0.641| gp_loss: 0.057| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.523
Train: Epoch [2051/3000], Step [120/158]| g_loss: 0.688| d_loss: 0.642| gp_loss: 0.055| r_loss: 0.057| p_loss: 0.079| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.537
Train: Epoch [2051/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.666| gp_loss: 0.059| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.531
Train: Epoch [2052/3000], Step [30/158]| g_loss: 0.657| d_loss: 0.665| gp_loss: 0.150| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.509
Train: Epoch [2052/3000], Step [60/158]| g_loss: 0.681| d_loss: 0.601| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.079| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.533
Train: Epoch [2052/3000], Step [90/158]| g_loss: 0.668| d_loss: 0.626| gp_loss: 0.054| r_loss: 0.055| p_loss: 0.074| v_loss: 0.021| per_loss: 0.316 | a_loss: 0.524
Train: Epoch [2052/3000], Step [120/158]| g_loss: 0.650| d_loss: 0.648| gp_loss: 0.058| r_loss: 0.057| p_loss: 0.077| v_loss: 0.021| per_loss: 0.318 | a_loss: 0.501
Train: Epoch [2052/3000], Step [150/158]| g_loss: 0.674| d_loss: 0.589| gp_loss: 0.059| r_loss: 0.055| p_loss: 0.078| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.527
Train: Epoch [2053/3000], Step [30/158]| g_loss: 0.658| d_loss: 0.766| gp_loss: 0.157| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.512
Train: Epoch [2053/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.596| gp_loss: 0.056| r_loss: 0.058| p_loss: 0.078| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.523
Train: Epoch [2053/3000], Step [90/158]| g_loss: 0.724| d_loss: 0.512| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.075| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.580
Train: Epoch [2053/3000], Step [120/158]| g_loss: 0.653| d_loss: 0.625| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.076| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.507
Train: Epoch [2053/3000], Step [150/158]| g_loss: 0.654| d_loss: 0.687| gp_loss: 0.058| r_loss: 0.056| p_loss: 0.077| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.505
Train: Epoch [2054/3000], Step [30/158]| g_loss: 0.653| d_loss: 0.678| gp_loss: 0.125| r_loss: 0.057| p_loss: 0.076| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.506
Train: Epoch [2054/3000], Step [60/158]| g_loss: 0.708| d_loss: 0.511| gp_loss: 0.060| r_loss: 0.057| p_loss: 0.079| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.559
Train: Epoch [2054/3000], Step [90/158]| g_loss: 0.685| d_loss: 0.660| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.072| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.542
Train: Epoch [2054/3000], Step [120/158]| g_loss: 0.612| d_loss: 0.655| gp_loss: 0.062| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.319 | a_loss: 0.463
Train: Epoch [2054/3000], Step [150/158]| g_loss: 0.704| d_loss: 0.575| gp_loss: 0.063| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.298 | a_loss: 0.557
Train: Epoch [2055/3000], Step [30/158]| g_loss: 0.667| d_loss: 0.741| gp_loss: 0.168| r_loss: 0.056| p_loss: 0.083| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.517
Train: Epoch [2055/3000], Step [60/158]| g_loss: 0.641| d_loss: 0.668| gp_loss: 0.060| r_loss: 0.057| p_loss: 0.081| v_loss: 0.022| per_loss: 0.299 | a_loss: 0.492
Train: Epoch [2055/3000], Step [90/158]| g_loss: 0.695| d_loss: 0.587| gp_loss: 0.063| r_loss: 0.055| p_loss: 0.078| v_loss: 0.022| per_loss: 0.318 | a_loss: 0.548
Train: Epoch [2055/3000], Step [120/158]| g_loss: 0.657| d_loss: 0.616| gp_loss: 0.060| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.511
Train: Epoch [2055/3000], Step [150/158]| g_loss: 0.695| d_loss: 0.614| gp_loss: 0.066| r_loss: 0.059| p_loss: 0.083| v_loss: 0.021| per_loss: 0.316 | a_loss: 0.542
Train: Epoch [2056/3000], Step [30/158]| g_loss: 0.724| d_loss: 0.694| gp_loss: 0.211| r_loss: 0.057| p_loss: 0.081| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.575
Train: Epoch [2056/3000], Step [60/158]| g_loss: 0.668| d_loss: 0.666| gp_loss: 0.051| r_loss: 0.057| p_loss: 0.081| v_loss: 0.021| per_loss: 0.316 | a_loss: 0.518
Train: Epoch [2056/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.588| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.077| v_loss: 0.021| per_loss: 0.316 | a_loss: 0.509
Train: Epoch [2056/3000], Step [120/158]| g_loss: 0.714| d_loss: 0.614| gp_loss: 0.058| r_loss: 0.058| p_loss: 0.077| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.565
Train: Epoch [2056/3000], Step [150/158]| g_loss: 0.651| d_loss: 0.648| gp_loss: 0.053| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.507
Train: Epoch [2057/3000], Step [30/158]| g_loss: 0.670| d_loss: 0.675| gp_loss: 0.155| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.317 | a_loss: 0.521
Train: Epoch [2057/3000], Step [60/158]| g_loss: 0.674| d_loss: 0.653| gp_loss: 0.054| r_loss: 0.053| p_loss: 0.074| v_loss: 0.021| per_loss: 0.320 | a_loss: 0.530
Train: Epoch [2057/3000], Step [90/158]| g_loss: 0.595| d_loss: 0.666| gp_loss: 0.057| r_loss: 0.057| p_loss: 0.077| v_loss: 0.021| per_loss: 0.327 | a_loss: 0.446
Train: Epoch [2057/3000], Step [120/158]| g_loss: 0.744| d_loss: 0.585| gp_loss: 0.059| r_loss: 0.059| p_loss: 0.083| v_loss: 0.023| per_loss: 0.312 | a_loss: 0.590
Train: Epoch [2057/3000], Step [150/158]| g_loss: 0.679| d_loss: 0.624| gp_loss: 0.057| r_loss: 0.058| p_loss: 0.081| v_loss: 0.022| per_loss: 0.303 | a_loss: 0.529
Train: Epoch [2058/3000], Step [30/158]| g_loss: 0.686| d_loss: 0.671| gp_loss: 0.134| r_loss: 0.056| p_loss: 0.081| v_loss: 0.021| per_loss: 0.320 | a_loss: 0.536
Train: Epoch [2058/3000], Step [60/158]| g_loss: 0.665| d_loss: 0.625| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.076| v_loss: 0.022| per_loss: 0.305 | a_loss: 0.519
Train: Epoch [2058/3000], Step [90/158]| g_loss: 0.707| d_loss: 0.527| gp_loss: 0.058| r_loss: 0.056| p_loss: 0.075| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.561
Train: Epoch [2058/3000], Step [120/158]| g_loss: 0.697| d_loss: 0.620| gp_loss: 0.058| r_loss: 0.055| p_loss: 0.079| v_loss: 0.021| per_loss: 0.290 | a_loss: 0.552
Train: Epoch [2058/3000], Step [150/158]| g_loss: 0.633| d_loss: 0.665| gp_loss: 0.060| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.486
Train: Epoch [2059/3000], Step [30/158]| g_loss: 0.630| d_loss: 0.694| gp_loss: 0.143| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.323 | a_loss: 0.483
Train: Epoch [2059/3000], Step [60/158]| g_loss: 0.693| d_loss: 0.655| gp_loss: 0.058| r_loss: 0.057| p_loss: 0.084| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.541
Train: Epoch [2059/3000], Step [90/158]| g_loss: 0.669| d_loss: 0.595| gp_loss: 0.059| r_loss: 0.057| p_loss: 0.081| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.519
Train: Epoch [2059/3000], Step [120/158]| g_loss: 0.697| d_loss: 0.620| gp_loss: 0.057| r_loss: 0.058| p_loss: 0.079| v_loss: 0.023| per_loss: 0.308 | a_loss: 0.546
Train: Epoch [2059/3000], Step [150/158]| g_loss: 0.649| d_loss: 0.584| gp_loss: 0.059| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.502
Train: Epoch [2060/3000], Step [30/158]| g_loss: 0.697| d_loss: 0.695| gp_loss: 0.155| r_loss: 0.054| p_loss: 0.074| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.555
Train: Epoch [2060/3000], Step [60/158]| g_loss: 0.651| d_loss: 0.666| gp_loss: 0.051| r_loss: 0.057| p_loss: 0.080| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.504
Train: Epoch [2060/3000], Step [90/158]| g_loss: 0.704| d_loss: 0.595| gp_loss: 0.055| r_loss: 0.066| p_loss: 0.094| v_loss: 0.020| per_loss: 0.334 | a_loss: 0.537
Train: Epoch [2060/3000], Step [120/158]| g_loss: 0.701| d_loss: 0.593| gp_loss: 0.056| r_loss: 0.070| p_loss: 0.094| v_loss: 0.021| per_loss: 0.322 | a_loss: 0.530
Train: Epoch [2060/3000], Step [150/158]| g_loss: 0.706| d_loss: 0.626| gp_loss: 0.061| r_loss: 0.067| p_loss: 0.088| v_loss: 0.023| per_loss: 0.315 | a_loss: 0.540
Train: Epoch [2061/3000], Step [30/158]| g_loss: 0.668| d_loss: 0.769| gp_loss: 0.176| r_loss: 0.059| p_loss: 0.083| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.515
Train: Epoch [2061/3000], Step [60/158]| g_loss: 0.667| d_loss: 0.585| gp_loss: 0.052| r_loss: 0.057| p_loss: 0.080| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.519
Train: Epoch [2061/3000], Step [90/158]| g_loss: 0.674| d_loss: 0.666| gp_loss: 0.055| r_loss: 0.057| p_loss: 0.078| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.524
Train: Epoch [2061/3000], Step [120/158]| g_loss: 0.665| d_loss: 0.596| gp_loss: 0.060| r_loss: 0.061| p_loss: 0.081| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.512
Train: Epoch [2061/3000], Step [150/158]| g_loss: 0.713| d_loss: 0.579| gp_loss: 0.056| r_loss: 0.060| p_loss: 0.084| v_loss: 0.022| per_loss: 0.328 | a_loss: 0.556
Train: Epoch [2062/3000], Step [30/158]| g_loss: 0.685| d_loss: 0.732| gp_loss: 0.162| r_loss: 0.056| p_loss: 0.076| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.540
Train: Epoch [2062/3000], Step [60/158]| g_loss: 0.650| d_loss: 0.681| gp_loss: 0.051| r_loss: 0.054| p_loss: 0.077| v_loss: 0.021| per_loss: 0.323 | a_loss: 0.505
Train: Epoch [2062/3000], Step [90/158]| g_loss: 0.637| d_loss: 0.595| gp_loss: 0.052| r_loss: 0.056| p_loss: 0.075| v_loss: 0.021| per_loss: 0.298 | a_loss: 0.493
Train: Epoch [2062/3000], Step [120/158]| g_loss: 0.717| d_loss: 0.499| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.081| v_loss: 0.022| per_loss: 0.307 | a_loss: 0.567
Train: Epoch [2062/3000], Step [150/158]| g_loss: 0.702| d_loss: 0.648| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.081| v_loss: 0.022| per_loss: 0.323 | a_loss: 0.548
Train: Epoch [2063/3000], Step [30/158]| g_loss: 0.650| d_loss: 0.801| gp_loss: 0.234| r_loss: 0.057| p_loss: 0.077| v_loss: 0.021| per_loss: 0.298 | a_loss: 0.504
Train: Epoch [2063/3000], Step [60/158]| g_loss: 0.680| d_loss: 0.602| gp_loss: 0.050| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.298 | a_loss: 0.534
Train: Epoch [2063/3000], Step [90/158]| g_loss: 0.671| d_loss: 0.629| gp_loss: 0.048| r_loss: 0.054| p_loss: 0.071| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.529
Train: Epoch [2063/3000], Step [120/158]| g_loss: 0.703| d_loss: 0.578| gp_loss: 0.049| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.319 | a_loss: 0.557
Train: Epoch [2063/3000], Step [150/158]| g_loss: 0.663| d_loss: 0.642| gp_loss: 0.050| r_loss: 0.057| p_loss: 0.079| v_loss: 0.022| per_loss: 0.292 | a_loss: 0.516
Train: Epoch [2064/3000], Step [30/158]| g_loss: 0.629| d_loss: 0.716| gp_loss: 0.142| r_loss: 0.055| p_loss: 0.076| v_loss: 0.022| per_loss: 0.306 | a_loss: 0.483
Train: Epoch [2064/3000], Step [60/158]| g_loss: 0.648| d_loss: 0.649| gp_loss: 0.050| r_loss: 0.056| p_loss: 0.078| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.501
Train: Epoch [2064/3000], Step [90/158]| g_loss: 0.676| d_loss: 0.616| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.074| v_loss: 0.021| per_loss: 0.295 | a_loss: 0.534
Train: Epoch [2064/3000], Step [120/158]| g_loss: 0.654| d_loss: 0.619| gp_loss: 0.053| r_loss: 0.057| p_loss: 0.077| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.505
Train: Epoch [2064/3000], Step [150/158]| g_loss: 0.692| d_loss: 0.554| gp_loss: 0.061| r_loss: 0.054| p_loss: 0.074| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.549
Train: Epoch [2065/3000], Step [30/158]| g_loss: 0.700| d_loss: 0.713| gp_loss: 0.123| r_loss: 0.058| p_loss: 0.082| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.548
Train: Epoch [2065/3000], Step [60/158]| g_loss: 0.638| d_loss: 0.645| gp_loss: 0.055| r_loss: 0.054| p_loss: 0.073| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.496
Train: Epoch [2065/3000], Step [90/158]| g_loss: 0.658| d_loss: 0.616| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.073| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.513
Train: Epoch [2065/3000], Step [120/158]| g_loss: 0.676| d_loss: 0.595| gp_loss: 0.057| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.532
Train: Epoch [2065/3000], Step [150/158]| g_loss: 0.688| d_loss: 0.542| gp_loss: 0.057| r_loss: 0.055| p_loss: 0.080| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.540
Train: Epoch [2066/3000], Step [30/158]| g_loss: 0.720| d_loss: 0.754| gp_loss: 0.242| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.574
Train: Epoch [2066/3000], Step [60/158]| g_loss: 0.699| d_loss: 0.540| gp_loss: 0.049| r_loss: 0.056| p_loss: 0.076| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.553
Train: Epoch [2066/3000], Step [90/158]| g_loss: 0.671| d_loss: 0.643| gp_loss: 0.050| r_loss: 0.056| p_loss: 0.075| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.526
Train: Epoch [2066/3000], Step [120/158]| g_loss: 0.682| d_loss: 0.681| gp_loss: 0.051| r_loss: 0.057| p_loss: 0.079| v_loss: 0.022| per_loss: 0.322 | a_loss: 0.531
Train: Epoch [2066/3000], Step [150/158]| g_loss: 0.642| d_loss: 0.583| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.076| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.498
Train: Epoch [2067/3000], Step [30/158]| g_loss: 0.627| d_loss: 0.703| gp_loss: 0.085| r_loss: 0.057| p_loss: 0.081| v_loss: 0.021| per_loss: 0.295 | a_loss: 0.479
Train: Epoch [2067/3000], Step [60/158]| g_loss: 0.659| d_loss: 0.666| gp_loss: 0.056| r_loss: 0.054| p_loss: 0.077| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.514
Train: Epoch [2067/3000], Step [90/158]| g_loss: 0.682| d_loss: 0.605| gp_loss: 0.055| r_loss: 0.054| p_loss: 0.074| v_loss: 0.021| per_loss: 0.327 | a_loss: 0.537
Train: Epoch [2067/3000], Step [120/158]| g_loss: 0.668| d_loss: 0.660| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.522
Train: Epoch [2067/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.514| gp_loss: 0.058| r_loss: 0.058| p_loss: 0.078| v_loss: 0.023| per_loss: 0.310 | a_loss: 0.510
Train: Epoch [2068/3000], Step [30/158]| g_loss: 0.675| d_loss: 0.748| gp_loss: 0.141| r_loss: 0.053| p_loss: 0.075| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.532
Train: Epoch [2068/3000], Step [60/158]| g_loss: 0.662| d_loss: 0.598| gp_loss: 0.057| r_loss: 0.057| p_loss: 0.077| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.515
Train: Epoch [2068/3000], Step [90/158]| g_loss: 0.690| d_loss: 0.623| gp_loss: 0.056| r_loss: 0.054| p_loss: 0.076| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.546
Train: Epoch [2068/3000], Step [120/158]| g_loss: 0.643| d_loss: 0.666| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.076| v_loss: 0.022| per_loss: 0.307 | a_loss: 0.495
Train: Epoch [2068/3000], Step [150/158]| g_loss: 0.663| d_loss: 0.544| gp_loss: 0.059| r_loss: 0.055| p_loss: 0.074| v_loss: 0.022| per_loss: 0.291 | a_loss: 0.519
Train: Epoch [2069/3000], Step [30/158]| g_loss: 0.749| d_loss: 0.693| gp_loss: 0.195| r_loss: 0.056| p_loss: 0.075| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.604
Train: Epoch [2069/3000], Step [60/158]| g_loss: 0.640| d_loss: 0.626| gp_loss: 0.052| r_loss: 0.055| p_loss: 0.074| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.498
Train: Epoch [2069/3000], Step [90/158]| g_loss: 0.652| d_loss: 0.597| gp_loss: 0.055| r_loss: 0.054| p_loss: 0.074| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.511
Train: Epoch [2069/3000], Step [120/158]| g_loss: 0.704| d_loss: 0.638| gp_loss: 0.053| r_loss: 0.053| p_loss: 0.076| v_loss: 0.021| per_loss: 0.323 | a_loss: 0.560
Train: Epoch [2069/3000], Step [150/158]| g_loss: 0.651| d_loss: 0.606| gp_loss: 0.055| r_loss: 0.056| p_loss: 0.076| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.504
Train: Epoch [2070/3000], Step [30/158]| g_loss: 0.680| d_loss: 0.723| gp_loss: 0.187| r_loss: 0.056| p_loss: 0.077| v_loss: 0.022| per_loss: 0.318 | a_loss: 0.533
Train: Epoch [2070/3000], Step [60/158]| g_loss: 0.649| d_loss: 0.693| gp_loss: 0.051| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.502
Train: Epoch [2070/3000], Step [90/158]| g_loss: 0.668| d_loss: 0.547| gp_loss: 0.055| r_loss: 0.055| p_loss: 0.075| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.523
Train: Epoch [2070/3000], Step [120/158]| g_loss: 0.700| d_loss: 0.629| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.077| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.556
Train: Epoch [2070/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.616| gp_loss: 0.057| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.514
Train: Epoch [2071/3000], Step [30/158]| g_loss: 0.684| d_loss: 0.685| gp_loss: 0.164| r_loss: 0.053| p_loss: 0.075| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.540
Train: Epoch [2071/3000], Step [60/158]| g_loss: 0.729| d_loss: 0.617| gp_loss: 0.049| r_loss: 0.058| p_loss: 0.080| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.577
Train: Epoch [2071/3000], Step [90/158]| g_loss: 0.661| d_loss: 0.602| gp_loss: 0.048| r_loss: 0.058| p_loss: 0.078| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.513
Train: Epoch [2071/3000], Step [120/158]| g_loss: 0.715| d_loss: 0.584| gp_loss: 0.054| r_loss: 0.058| p_loss: 0.082| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.564
Train: Epoch [2071/3000], Step [150/158]| g_loss: 0.640| d_loss: 0.680| gp_loss: 0.052| r_loss: 0.059| p_loss: 0.082| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.488
Train: Epoch [2072/3000], Step [30/158]| g_loss: 0.677| d_loss: 0.686| gp_loss: 0.087| r_loss: 0.065| p_loss: 0.088| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.516
Train: Epoch [2072/3000], Step [60/158]| g_loss: 0.655| d_loss: 0.616| gp_loss: 0.057| r_loss: 0.058| p_loss: 0.078| v_loss: 0.021| per_loss: 0.318 | a_loss: 0.506
Train: Epoch [2072/3000], Step [90/158]| g_loss: 0.644| d_loss: 0.684| gp_loss: 0.054| r_loss: 0.057| p_loss: 0.079| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.496
Train: Epoch [2072/3000], Step [120/158]| g_loss: 0.651| d_loss: 0.547| gp_loss: 0.057| r_loss: 0.056| p_loss: 0.079| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.503
Train: Epoch [2072/3000], Step [150/158]| g_loss: 0.717| d_loss: 0.610| gp_loss: 0.058| r_loss: 0.054| p_loss: 0.075| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.571
Train: Epoch [2073/3000], Step [30/158]| g_loss: 0.673| d_loss: 0.670| gp_loss: 0.151| r_loss: 0.054| p_loss: 0.074| v_loss: 0.022| per_loss: 0.307 | a_loss: 0.530
Train: Epoch [2073/3000], Step [60/158]| g_loss: 0.689| d_loss: 0.614| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.073| v_loss: 0.021| per_loss: 0.293 | a_loss: 0.549
Train: Epoch [2073/3000], Step [90/158]| g_loss: 0.649| d_loss: 0.616| gp_loss: 0.053| r_loss: 0.055| p_loss: 0.075| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.503
Train: Epoch [2073/3000], Step [120/158]| g_loss: 0.678| d_loss: 0.588| gp_loss: 0.058| r_loss: 0.057| p_loss: 0.080| v_loss: 0.022| per_loss: 0.303 | a_loss: 0.529
Train: Epoch [2073/3000], Step [150/158]| g_loss: 0.652| d_loss: 0.626| gp_loss: 0.059| r_loss: 0.057| p_loss: 0.078| v_loss: 0.022| per_loss: 0.299 | a_loss: 0.505
Train: Epoch [2074/3000], Step [30/158]| g_loss: 0.693| d_loss: 0.695| gp_loss: 0.156| r_loss: 0.054| p_loss: 0.079| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.548
Train: Epoch [2074/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.611| gp_loss: 0.054| r_loss: 0.059| p_loss: 0.081| v_loss: 0.022| per_loss: 0.303 | a_loss: 0.522
Train: Epoch [2074/3000], Step [90/158]| g_loss: 0.673| d_loss: 0.653| gp_loss: 0.061| r_loss: 0.058| p_loss: 0.078| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.523
Train: Epoch [2074/3000], Step [120/158]| g_loss: 0.663| d_loss: 0.592| gp_loss: 0.057| r_loss: 0.054| p_loss: 0.078| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.518
Train: Epoch [2074/3000], Step [150/158]| g_loss: 0.692| d_loss: 0.650| gp_loss: 0.060| r_loss: 0.057| p_loss: 0.081| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.541
Train: Epoch [2075/3000], Step [30/158]| g_loss: 0.659| d_loss: 0.803| gp_loss: 0.269| r_loss: 0.056| p_loss: 0.081| v_loss: 0.021| per_loss: 0.317 | a_loss: 0.509
Train: Epoch [2075/3000], Step [60/158]| g_loss: 0.674| d_loss: 0.654| gp_loss: 0.051| r_loss: 0.059| p_loss: 0.080| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.521
Train: Epoch [2075/3000], Step [90/158]| g_loss: 0.684| d_loss: 0.556| gp_loss: 0.053| r_loss: 0.057| p_loss: 0.081| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.533
Train: Epoch [2075/3000], Step [120/158]| g_loss: 0.679| d_loss: 0.635| gp_loss: 0.050| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.531
Train: Epoch [2075/3000], Step [150/158]| g_loss: 0.673| d_loss: 0.670| gp_loss: 0.053| r_loss: 0.055| p_loss: 0.078| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.527
Train: Epoch [2076/3000], Step [30/158]| g_loss: 0.678| d_loss: 0.669| gp_loss: 0.144| r_loss: 0.054| p_loss: 0.077| v_loss: 0.021| per_loss: 0.298 | a_loss: 0.535
Train: Epoch [2076/3000], Step [60/158]| g_loss: 0.642| d_loss: 0.670| gp_loss: 0.051| r_loss: 0.056| p_loss: 0.078| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.494
Train: Epoch [2076/3000], Step [90/158]| g_loss: 0.666| d_loss: 0.662| gp_loss: 0.055| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.520
Train: Epoch [2076/3000], Step [120/158]| g_loss: 0.684| d_loss: 0.578| gp_loss: 0.054| r_loss: 0.057| p_loss: 0.078| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.535
Train: Epoch [2076/3000], Step [150/158]| g_loss: 0.695| d_loss: 0.505| gp_loss: 0.053| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.549
Train: Epoch [2077/3000], Step [30/158]| g_loss: 0.693| d_loss: 0.658| gp_loss: 0.109| r_loss: 0.056| p_loss: 0.078| v_loss: 0.022| per_loss: 0.321 | a_loss: 0.544
Train: Epoch [2077/3000], Step [60/158]| g_loss: 0.723| d_loss: 0.613| gp_loss: 0.053| r_loss: 0.055| p_loss: 0.080| v_loss: 0.021| per_loss: 0.325 | a_loss: 0.574
Train: Epoch [2077/3000], Step [90/158]| g_loss: 0.673| d_loss: 0.667| gp_loss: 0.052| r_loss: 0.056| p_loss: 0.081| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.524
Train: Epoch [2077/3000], Step [120/158]| g_loss: 0.635| d_loss: 0.664| gp_loss: 0.054| r_loss: 0.060| p_loss: 0.085| v_loss: 0.022| per_loss: 0.299 | a_loss: 0.481
Train: Epoch [2077/3000], Step [150/158]| g_loss: 0.646| d_loss: 0.644| gp_loss: 0.058| r_loss: 0.058| p_loss: 0.085| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.493
Train: Epoch [2078/3000], Step [30/158]| g_loss: 0.678| d_loss: 0.705| gp_loss: 0.150| r_loss: 0.056| p_loss: 0.081| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.528
Train: Epoch [2078/3000], Step [60/158]| g_loss: 0.678| d_loss: 0.598| gp_loss: 0.053| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.324 | a_loss: 0.528
Train: Epoch [2078/3000], Step [90/158]| g_loss: 0.641| d_loss: 0.606| gp_loss: 0.050| r_loss: 0.058| p_loss: 0.078| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.492
Train: Epoch [2078/3000], Step [120/158]| g_loss: 0.749| d_loss: 0.500| gp_loss: 0.053| r_loss: 0.059| p_loss: 0.083| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.596
Train: Epoch [2078/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.669| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.529
Train: Epoch [2079/3000], Step [30/158]| g_loss: 0.640| d_loss: 0.777| gp_loss: 0.255| r_loss: 0.056| p_loss: 0.081| v_loss: 0.021| per_loss: 0.293 | a_loss: 0.493
Train: Epoch [2079/3000], Step [60/158]| g_loss: 0.719| d_loss: 0.599| gp_loss: 0.047| r_loss: 0.058| p_loss: 0.082| v_loss: 0.022| per_loss: 0.327 | a_loss: 0.565
Train: Epoch [2079/3000], Step [90/158]| g_loss: 0.650| d_loss: 0.687| gp_loss: 0.047| r_loss: 0.057| p_loss: 0.082| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.500
Train: Epoch [2079/3000], Step [120/158]| g_loss: 0.662| d_loss: 0.593| gp_loss: 0.051| r_loss: 0.055| p_loss: 0.074| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.519
Train: Epoch [2079/3000], Step [150/158]| g_loss: 0.672| d_loss: 0.585| gp_loss: 0.053| r_loss: 0.059| p_loss: 0.081| v_loss: 0.023| per_loss: 0.300 | a_loss: 0.520
Train: Epoch [2080/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.846| gp_loss: 0.223| r_loss: 0.054| p_loss: 0.076| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.510
Train: Epoch [2080/3000], Step [60/158]| g_loss: 0.658| d_loss: 0.626| gp_loss: 0.049| r_loss: 0.057| p_loss: 0.078| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.510
Train: Epoch [2080/3000], Step [90/158]| g_loss: 0.670| d_loss: 0.597| gp_loss: 0.049| r_loss: 0.056| p_loss: 0.078| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.521
Train: Epoch [2080/3000], Step [120/158]| g_loss: 0.698| d_loss: 0.556| gp_loss: 0.051| r_loss: 0.058| p_loss: 0.082| v_loss: 0.023| per_loss: 0.315 | a_loss: 0.545
Train: Epoch [2080/3000], Step [150/158]| g_loss: 0.676| d_loss: 0.642| gp_loss: 0.052| r_loss: 0.058| p_loss: 0.077| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.529
Train: Epoch [2081/3000], Step [30/158]| g_loss: 0.671| d_loss: 0.705| gp_loss: 0.148| r_loss: 0.055| p_loss: 0.079| v_loss: 0.021| per_loss: 0.298 | a_loss: 0.526
Train: Epoch [2081/3000], Step [60/158]| g_loss: 0.700| d_loss: 0.602| gp_loss: 0.049| r_loss: 0.057| p_loss: 0.078| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.553
Train: Epoch [2081/3000], Step [90/158]| g_loss: 0.663| d_loss: 0.685| gp_loss: 0.049| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.319 | a_loss: 0.514
Train: Epoch [2081/3000], Step [120/158]| g_loss: 0.678| d_loss: 0.598| gp_loss: 0.051| r_loss: 0.057| p_loss: 0.078| v_loss: 0.023| per_loss: 0.321 | a_loss: 0.527
Train: Epoch [2081/3000], Step [150/158]| g_loss: 0.639| d_loss: 0.598| gp_loss: 0.054| r_loss: 0.057| p_loss: 0.080| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.490
Train: Epoch [2082/3000], Step [30/158]| g_loss: 0.720| d_loss: 0.666| gp_loss: 0.151| r_loss: 0.058| p_loss: 0.079| v_loss: 0.022| per_loss: 0.311 | a_loss: 0.569
Train: Epoch [2082/3000], Step [60/158]| g_loss: 0.680| d_loss: 0.563| gp_loss: 0.051| r_loss: 0.056| p_loss: 0.076| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.535
Train: Epoch [2082/3000], Step [90/158]| g_loss: 0.658| d_loss: 0.675| gp_loss: 0.049| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.317 | a_loss: 0.511
Train: Epoch [2082/3000], Step [120/158]| g_loss: 0.661| d_loss: 0.606| gp_loss: 0.050| r_loss: 0.055| p_loss: 0.080| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.512
Train: Epoch [2082/3000], Step [150/158]| g_loss: 0.692| d_loss: 0.567| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.318 | a_loss: 0.547
Train: Epoch [2083/3000], Step [30/158]| g_loss: 0.623| d_loss: 0.752| gp_loss: 0.119| r_loss: 0.057| p_loss: 0.082| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.473
Train: Epoch [2083/3000], Step [60/158]| g_loss: 0.678| d_loss: 0.638| gp_loss: 0.055| r_loss: 0.057| p_loss: 0.080| v_loss: 0.022| per_loss: 0.300 | a_loss: 0.530
Train: Epoch [2083/3000], Step [90/158]| g_loss: 0.672| d_loss: 0.654| gp_loss: 0.053| r_loss: 0.055| p_loss: 0.079| v_loss: 0.021| per_loss: 0.325 | a_loss: 0.523
Train: Epoch [2083/3000], Step [120/158]| g_loss: 0.674| d_loss: 0.557| gp_loss: 0.058| r_loss: 0.058| p_loss: 0.079| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.523
Train: Epoch [2083/3000], Step [150/158]| g_loss: 0.695| d_loss: 0.613| gp_loss: 0.053| r_loss: 0.056| p_loss: 0.079| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.548
Train: Epoch [2084/3000], Step [30/158]| g_loss: 0.726| d_loss: 0.574| gp_loss: 0.141| r_loss: 0.058| p_loss: 0.080| v_loss: 0.022| per_loss: 0.305 | a_loss: 0.575
Train: Epoch [2084/3000], Step [60/158]| g_loss: 0.727| d_loss: 0.603| gp_loss: 0.049| r_loss: 0.055| p_loss: 0.078| v_loss: 0.022| per_loss: 0.290 | a_loss: 0.582
Train: Epoch [2084/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.612| gp_loss: 0.053| r_loss: 0.058| p_loss: 0.079| v_loss: 0.021| per_loss: 0.290 | a_loss: 0.510
Train: Epoch [2084/3000], Step [120/158]| g_loss: 0.592| d_loss: 0.847| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.080| v_loss: 0.021| per_loss: 0.319 | a_loss: 0.443
Train: Epoch [2084/3000], Step [150/158]| g_loss: 0.688| d_loss: 0.525| gp_loss: 0.059| r_loss: 0.055| p_loss: 0.077| v_loss: 0.022| per_loss: 0.336 | a_loss: 0.539
Train: Epoch [2085/3000], Step [30/158]| g_loss: 0.703| d_loss: 0.676| gp_loss: 0.160| r_loss: 0.057| p_loss: 0.080| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.553
Train: Epoch [2085/3000], Step [60/158]| g_loss: 0.659| d_loss: 0.590| gp_loss: 0.051| r_loss: 0.057| p_loss: 0.080| v_loss: 0.022| per_loss: 0.290 | a_loss: 0.511
Train: Epoch [2085/3000], Step [90/158]| g_loss: 0.706| d_loss: 0.630| gp_loss: 0.052| r_loss: 0.059| p_loss: 0.081| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.554
Train: Epoch [2085/3000], Step [120/158]| g_loss: 0.670| d_loss: 0.603| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.074| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.528
Train: Epoch [2085/3000], Step [150/158]| g_loss: 0.652| d_loss: 0.678| gp_loss: 0.055| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.319 | a_loss: 0.507
Train: Epoch [2086/3000], Step [30/158]| g_loss: 0.665| d_loss: 0.693| gp_loss: 0.146| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.517
Train: Epoch [2086/3000], Step [60/158]| g_loss: 0.631| d_loss: 0.599| gp_loss: 0.051| r_loss: 0.058| p_loss: 0.080| v_loss: 0.022| per_loss: 0.305 | a_loss: 0.481
Train: Epoch [2086/3000], Step [90/158]| g_loss: 0.718| d_loss: 0.545| gp_loss: 0.057| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.306 | a_loss: 0.565
Train: Epoch [2086/3000], Step [120/158]| g_loss: 0.708| d_loss: 0.678| gp_loss: 0.054| r_loss: 0.058| p_loss: 0.082| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.558
Train: Epoch [2086/3000], Step [150/158]| g_loss: 0.655| d_loss: 0.631| gp_loss: 0.059| r_loss: 0.056| p_loss: 0.081| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.506
Train: Epoch [2087/3000], Step [30/158]| g_loss: 0.696| d_loss: 0.715| gp_loss: 0.153| r_loss: 0.056| p_loss: 0.076| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.550
Train: Epoch [2087/3000], Step [60/158]| g_loss: 0.668| d_loss: 0.603| gp_loss: 0.053| r_loss: 0.054| p_loss: 0.076| v_loss: 0.022| per_loss: 0.306 | a_loss: 0.524
Train: Epoch [2087/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.644| gp_loss: 0.053| r_loss: 0.057| p_loss: 0.076| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.511
Train: Epoch [2087/3000], Step [120/158]| g_loss: 0.614| d_loss: 0.604| gp_loss: 0.058| r_loss: 0.055| p_loss: 0.078| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.467
Train: Epoch [2087/3000], Step [150/158]| g_loss: 0.694| d_loss: 0.551| gp_loss: 0.059| r_loss: 0.056| p_loss: 0.075| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.549
Train: Epoch [2088/3000], Step [30/158]| g_loss: 0.683| d_loss: 0.651| gp_loss: 0.136| r_loss: 0.057| p_loss: 0.082| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.533
Train: Epoch [2088/3000], Step [60/158]| g_loss: 0.776| d_loss: 0.499| gp_loss: 0.055| r_loss: 0.057| p_loss: 0.077| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.628
Train: Epoch [2088/3000], Step [90/158]| g_loss: 0.658| d_loss: 0.591| gp_loss: 0.052| r_loss: 0.052| p_loss: 0.073| v_loss: 0.021| per_loss: 0.294 | a_loss: 0.519
Train: Epoch [2088/3000], Step [120/158]| g_loss: 0.653| d_loss: 0.656| gp_loss: 0.052| r_loss: 0.055| p_loss: 0.074| v_loss: 0.022| per_loss: 0.302 | a_loss: 0.510
Train: Epoch [2088/3000], Step [150/158]| g_loss: 0.626| d_loss: 0.738| gp_loss: 0.055| r_loss: 0.056| p_loss: 0.075| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.481
Train: Epoch [2089/3000], Step [30/158]| g_loss: 0.685| d_loss: 0.620| gp_loss: 0.158| r_loss: 0.057| p_loss: 0.079| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.536
Train: Epoch [2089/3000], Step [60/158]| g_loss: 0.691| d_loss: 0.665| gp_loss: 0.053| r_loss: 0.059| p_loss: 0.083| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.538
Train: Epoch [2089/3000], Step [90/158]| g_loss: 0.693| d_loss: 0.573| gp_loss: 0.056| r_loss: 0.058| p_loss: 0.083| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.542
Train: Epoch [2089/3000], Step [120/158]| g_loss: 0.718| d_loss: 0.542| gp_loss: 0.053| r_loss: 0.059| p_loss: 0.082| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.565
Train: Epoch [2089/3000], Step [150/158]| g_loss: 0.655| d_loss: 0.710| gp_loss: 0.054| r_loss: 0.055| p_loss: 0.083| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.505
Train: Epoch [2090/3000], Step [30/158]| g_loss: 0.643| d_loss: 0.733| gp_loss: 0.102| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.489
Train: Epoch [2090/3000], Step [60/158]| g_loss: 0.665| d_loss: 0.628| gp_loss: 0.059| r_loss: 0.059| p_loss: 0.081| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.514
Train: Epoch [2090/3000], Step [90/158]| g_loss: 0.666| d_loss: 0.609| gp_loss: 0.062| r_loss: 0.059| p_loss: 0.087| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.511
Train: Epoch [2090/3000], Step [120/158]| g_loss: 0.728| d_loss: 0.515| gp_loss: 0.061| r_loss: 0.056| p_loss: 0.081| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.578
Train: Epoch [2090/3000], Step [150/158]| g_loss: 0.677| d_loss: 0.713| gp_loss: 0.055| r_loss: 0.057| p_loss: 0.083| v_loss: 0.021| per_loss: 0.330 | a_loss: 0.524
Train: Epoch [2091/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.752| gp_loss: 0.161| r_loss: 0.057| p_loss: 0.082| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.513
Train: Epoch [2091/3000], Step [60/158]| g_loss: 0.671| d_loss: 0.565| gp_loss: 0.055| r_loss: 0.057| p_loss: 0.081| v_loss: 0.022| per_loss: 0.326 | a_loss: 0.519
Train: Epoch [2091/3000], Step [90/158]| g_loss: 0.681| d_loss: 0.590| gp_loss: 0.059| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.534
Train: Epoch [2091/3000], Step [120/158]| g_loss: 0.665| d_loss: 0.577| gp_loss: 0.058| r_loss: 0.056| p_loss: 0.079| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.518
Train: Epoch [2091/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.660| gp_loss: 0.057| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.521
Train: Epoch [2092/3000], Step [30/158]| g_loss: 0.708| d_loss: 0.712| gp_loss: 0.201| r_loss: 0.057| p_loss: 0.078| v_loss: 0.021| per_loss: 0.316 | a_loss: 0.559
Train: Epoch [2092/3000], Step [60/158]| g_loss: 0.661| d_loss: 0.645| gp_loss: 0.052| r_loss: 0.060| p_loss: 0.082| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.507
Train: Epoch [2092/3000], Step [90/158]| g_loss: 0.662| d_loss: 0.661| gp_loss: 0.058| r_loss: 0.056| p_loss: 0.079| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.514
Train: Epoch [2092/3000], Step [120/158]| g_loss: 0.690| d_loss: 0.606| gp_loss: 0.058| r_loss: 0.057| p_loss: 0.080| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.541
Train: Epoch [2092/3000], Step [150/158]| g_loss: 0.714| d_loss: 0.598| gp_loss: 0.061| r_loss: 0.059| p_loss: 0.083| v_loss: 0.023| per_loss: 0.328 | a_loss: 0.558
Train: Epoch [2093/3000], Step [30/158]| g_loss: 0.691| d_loss: 0.694| gp_loss: 0.139| r_loss: 0.058| p_loss: 0.084| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.537
Train: Epoch [2093/3000], Step [60/158]| g_loss: 0.670| d_loss: 0.621| gp_loss: 0.055| r_loss: 0.058| p_loss: 0.079| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.519
Train: Epoch [2093/3000], Step [90/158]| g_loss: 0.710| d_loss: 0.537| gp_loss: 0.055| r_loss: 0.059| p_loss: 0.082| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.557
Train: Epoch [2093/3000], Step [120/158]| g_loss: 0.693| d_loss: 0.581| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.078| v_loss: 0.021| per_loss: 0.296 | a_loss: 0.545
Train: Epoch [2093/3000], Step [150/158]| g_loss: 0.629| d_loss: 0.686| gp_loss: 0.057| r_loss: 0.053| p_loss: 0.080| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.484
Train: Epoch [2094/3000], Step [30/158]| g_loss: 0.666| d_loss: 0.680| gp_loss: 0.098| r_loss: 0.058| p_loss: 0.082| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.513
Train: Epoch [2094/3000], Step [60/158]| g_loss: 0.738| d_loss: 0.599| gp_loss: 0.057| r_loss: 0.053| p_loss: 0.078| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.594
Train: Epoch [2094/3000], Step [90/158]| g_loss: 0.656| d_loss: 0.653| gp_loss: 0.055| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.510
Train: Epoch [2094/3000], Step [120/158]| g_loss: 0.670| d_loss: 0.641| gp_loss: 0.059| r_loss: 0.058| p_loss: 0.081| v_loss: 0.021| per_loss: 0.320 | a_loss: 0.517
Train: Epoch [2094/3000], Step [150/158]| g_loss: 0.642| d_loss: 0.613| gp_loss: 0.064| r_loss: 0.058| p_loss: 0.081| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.492
Train: Epoch [2095/3000], Step [30/158]| g_loss: 0.716| d_loss: 0.595| gp_loss: 0.133| r_loss: 0.057| p_loss: 0.079| v_loss: 0.023| per_loss: 0.309 | a_loss: 0.566
Train: Epoch [2095/3000], Step [60/158]| g_loss: 0.697| d_loss: 0.609| gp_loss: 0.061| r_loss: 0.054| p_loss: 0.074| v_loss: 0.020| per_loss: 0.309 | a_loss: 0.554
Train: Epoch [2095/3000], Step [90/158]| g_loss: 0.663| d_loss: 0.678| gp_loss: 0.058| r_loss: 0.058| p_loss: 0.082| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.511
Train: Epoch [2095/3000], Step [120/158]| g_loss: 0.664| d_loss: 0.632| gp_loss: 0.062| r_loss: 0.054| p_loss: 0.077| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.519
Train: Epoch [2095/3000], Step [150/158]| g_loss: 0.671| d_loss: 0.590| gp_loss: 0.062| r_loss: 0.058| p_loss: 0.078| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.521
Train: Epoch [2096/3000], Step [30/158]| g_loss: 0.676| d_loss: 0.745| gp_loss: 0.197| r_loss: 0.057| p_loss: 0.080| v_loss: 0.022| per_loss: 0.306 | a_loss: 0.526
Train: Epoch [2096/3000], Step [60/158]| g_loss: 0.685| d_loss: 0.604| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.317 | a_loss: 0.539
Train: Epoch [2096/3000], Step [90/158]| g_loss: 0.660| d_loss: 0.638| gp_loss: 0.050| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.518
Train: Epoch [2096/3000], Step [120/158]| g_loss: 0.676| d_loss: 0.578| gp_loss: 0.055| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.531
Train: Epoch [2096/3000], Step [150/158]| g_loss: 0.655| d_loss: 0.643| gp_loss: 0.058| r_loss: 0.057| p_loss: 0.076| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.508
Train: Epoch [2097/3000], Step [30/158]| g_loss: 0.671| d_loss: 0.645| gp_loss: 0.120| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.527
Train: Epoch [2097/3000], Step [60/158]| g_loss: 0.638| d_loss: 0.674| gp_loss: 0.055| r_loss: 0.056| p_loss: 0.075| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.490
Train: Epoch [2097/3000], Step [90/158]| g_loss: 0.718| d_loss: 0.595| gp_loss: 0.061| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.291 | a_loss: 0.572
Train: Epoch [2097/3000], Step [120/158]| g_loss: 0.700| d_loss: 0.521| gp_loss: 0.059| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.316 | a_loss: 0.556
Train: Epoch [2097/3000], Step [150/158]| g_loss: 0.676| d_loss: 0.671| gp_loss: 0.059| r_loss: 0.057| p_loss: 0.077| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.527
Train: Epoch [2098/3000], Step [30/158]| g_loss: 0.679| d_loss: 0.712| gp_loss: 0.063| r_loss: 0.063| p_loss: 0.086| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.520
Train: Epoch [2098/3000], Step [60/158]| g_loss: 0.646| d_loss: 0.629| gp_loss: 0.059| r_loss: 0.062| p_loss: 0.088| v_loss: 0.022| per_loss: 0.324 | a_loss: 0.486
Train: Epoch [2098/3000], Step [90/158]| g_loss: 0.675| d_loss: 0.639| gp_loss: 0.068| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.297 | a_loss: 0.523
Train: Epoch [2098/3000], Step [120/158]| g_loss: 0.699| d_loss: 0.541| gp_loss: 0.067| r_loss: 0.056| p_loss: 0.078| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.551
Train: Epoch [2098/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.636| gp_loss: 0.065| r_loss: 0.058| p_loss: 0.084| v_loss: 0.022| per_loss: 0.328 | a_loss: 0.506
Train: Epoch [2099/3000], Step [30/158]| g_loss: 0.679| d_loss: 0.699| gp_loss: 0.069| r_loss: 0.061| p_loss: 0.095| v_loss: 0.023| per_loss: 0.324 | a_loss: 0.516
Train: Epoch [2099/3000], Step [60/158]| g_loss: 0.679| d_loss: 0.672| gp_loss: 0.068| r_loss: 0.059| p_loss: 0.090| v_loss: 0.021| per_loss: 0.321 | a_loss: 0.522
Train: Epoch [2099/3000], Step [90/158]| g_loss: 0.672| d_loss: 0.591| gp_loss: 0.066| r_loss: 0.057| p_loss: 0.081| v_loss: 0.022| per_loss: 0.320 | a_loss: 0.520
Train: Epoch [2099/3000], Step [120/158]| g_loss: 0.675| d_loss: 0.578| gp_loss: 0.068| r_loss: 0.059| p_loss: 0.083| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.521
Train: Epoch [2099/3000], Step [150/158]| g_loss: 0.732| d_loss: 0.612| gp_loss: 0.066| r_loss: 0.057| p_loss: 0.080| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.583
Train: Epoch [2100/3000], Step [30/158]| g_loss: 0.664| d_loss: 0.714| gp_loss: 0.184| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.517
Train: Epoch [2100/3000], Step [60/158]| g_loss: 0.669| d_loss: 0.604| gp_loss: 0.059| r_loss: 0.053| p_loss: 0.074| v_loss: 0.020| per_loss: 0.311 | a_loss: 0.527
Train: Epoch [2100/3000], Step [90/158]| g_loss: 0.681| d_loss: 0.561| gp_loss: 0.061| r_loss: 0.056| p_loss: 0.073| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.536
Train: Epoch [2100/3000], Step [120/158]| g_loss: 0.685| d_loss: 0.606| gp_loss: 0.063| r_loss: 0.056| p_loss: 0.078| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.537
Train: Epoch [2100/3000], Step [150/158]| g_loss: 0.677| d_loss: 0.670| gp_loss: 0.065| r_loss: 0.055| p_loss: 0.075| v_loss: 0.022| per_loss: 0.305 | a_loss: 0.532
Test: Epoch [2100/3000]| g_loss: 0.632| r_loss: 0.388| p_loss: 0.303| v_loss: 0.022
Train: Epoch [2101/3000], Step [30/158]| g_loss: 0.686| d_loss: 0.597| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.078| v_loss: 0.022| per_loss: 0.327 | a_loss: 0.536
Train: Epoch [2101/3000], Step [60/158]| g_loss: 0.663| d_loss: 0.575| gp_loss: 0.057| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.520
Train: Epoch [2101/3000], Step [90/158]| g_loss: 0.740| d_loss: 0.493| gp_loss: 0.055| r_loss: 0.057| p_loss: 0.075| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.594
Train: Epoch [2101/3000], Step [120/158]| g_loss: 0.683| d_loss: 0.662| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.298 | a_loss: 0.537
Train: Epoch [2101/3000], Step [150/158]| g_loss: 0.640| d_loss: 0.699| gp_loss: 0.058| r_loss: 0.056| p_loss: 0.078| v_loss: 0.022| per_loss: 0.305 | a_loss: 0.492
Train: Epoch [2102/3000], Step [30/158]| g_loss: 0.698| d_loss: 0.600| gp_loss: 0.131| r_loss: 0.055| p_loss: 0.079| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.551
Train: Epoch [2102/3000], Step [60/158]| g_loss: 0.688| d_loss: 0.653| gp_loss: 0.055| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.321 | a_loss: 0.541
Train: Epoch [2102/3000], Step [90/158]| g_loss: 0.636| d_loss: 0.623| gp_loss: 0.058| r_loss: 0.056| p_loss: 0.076| v_loss: 0.021| per_loss: 0.324 | a_loss: 0.490
Train: Epoch [2102/3000], Step [120/158]| g_loss: 0.672| d_loss: 0.671| gp_loss: 0.063| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.524
Train: Epoch [2102/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.615| gp_loss: 0.063| r_loss: 0.055| p_loss: 0.073| v_loss: 0.022| per_loss: 0.299 | a_loss: 0.518
Train: Epoch [2103/3000], Step [30/158]| g_loss: 0.640| d_loss: 0.694| gp_loss: 0.172| r_loss: 0.057| p_loss: 0.081| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.492
Train: Epoch [2103/3000], Step [60/158]| g_loss: 0.692| d_loss: 0.670| gp_loss: 0.056| r_loss: 0.054| p_loss: 0.076| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.549
Train: Epoch [2103/3000], Step [90/158]| g_loss: 0.668| d_loss: 0.652| gp_loss: 0.058| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.524
Train: Epoch [2103/3000], Step [120/158]| g_loss: 0.673| d_loss: 0.581| gp_loss: 0.060| r_loss: 0.059| p_loss: 0.081| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.520
Train: Epoch [2103/3000], Step [150/158]| g_loss: 0.670| d_loss: 0.623| gp_loss: 0.062| r_loss: 0.058| p_loss: 0.081| v_loss: 0.022| per_loss: 0.297 | a_loss: 0.521
Train: Epoch [2104/3000], Step [30/158]| g_loss: 0.703| d_loss: 0.605| gp_loss: 0.123| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.317 | a_loss: 0.558
Train: Epoch [2104/3000], Step [60/158]| g_loss: 0.707| d_loss: 0.542| gp_loss: 0.057| r_loss: 0.057| p_loss: 0.079| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.559
Train: Epoch [2104/3000], Step [90/158]| g_loss: 0.648| d_loss: 0.769| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.077| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.500
Train: Epoch [2104/3000], Step [120/158]| g_loss: 0.650| d_loss: 0.613| gp_loss: 0.064| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.295 | a_loss: 0.506
Train: Epoch [2104/3000], Step [150/158]| g_loss: 0.697| d_loss: 0.572| gp_loss: 0.065| r_loss: 0.055| p_loss: 0.076| v_loss: 0.022| per_loss: 0.326 | a_loss: 0.548
Train: Epoch [2105/3000], Step [30/158]| g_loss: 0.667| d_loss: 0.785| gp_loss: 0.199| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.520
Train: Epoch [2105/3000], Step [60/158]| g_loss: 0.608| d_loss: 0.713| gp_loss: 0.053| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.464
Train: Epoch [2105/3000], Step [90/158]| g_loss: 0.671| d_loss: 0.598| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.078| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.524
Train: Epoch [2105/3000], Step [120/158]| g_loss: 0.681| d_loss: 0.564| gp_loss: 0.059| r_loss: 0.057| p_loss: 0.076| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.534
Train: Epoch [2105/3000], Step [150/158]| g_loss: 0.691| d_loss: 0.581| gp_loss: 0.061| r_loss: 0.056| p_loss: 0.079| v_loss: 0.022| per_loss: 0.292 | a_loss: 0.545
Train: Epoch [2106/3000], Step [30/158]| g_loss: 0.701| d_loss: 0.621| gp_loss: 0.094| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.558
Train: Epoch [2106/3000], Step [60/158]| g_loss: 0.675| d_loss: 0.639| gp_loss: 0.058| r_loss: 0.057| p_loss: 0.078| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.527
Train: Epoch [2106/3000], Step [90/158]| g_loss: 0.706| d_loss: 0.610| gp_loss: 0.057| r_loss: 0.057| p_loss: 0.077| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.559
Train: Epoch [2106/3000], Step [120/158]| g_loss: 0.659| d_loss: 0.582| gp_loss: 0.057| r_loss: 0.057| p_loss: 0.080| v_loss: 0.021| per_loss: 0.293 | a_loss: 0.511
Train: Epoch [2106/3000], Step [150/158]| g_loss: 0.682| d_loss: 0.651| gp_loss: 0.063| r_loss: 0.060| p_loss: 0.085| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.527
Train: Epoch [2107/3000], Step [30/158]| g_loss: 0.649| d_loss: 0.783| gp_loss: 0.236| r_loss: 0.058| p_loss: 0.081| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.499
Train: Epoch [2107/3000], Step [60/158]| g_loss: 0.702| d_loss: 0.563| gp_loss: 0.058| r_loss: 0.058| p_loss: 0.083| v_loss: 0.022| per_loss: 0.305 | a_loss: 0.551
Train: Epoch [2107/3000], Step [90/158]| g_loss: 0.693| d_loss: 0.679| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.080| v_loss: 0.022| per_loss: 0.325 | a_loss: 0.541
Train: Epoch [2107/3000], Step [120/158]| g_loss: 0.682| d_loss: 0.606| gp_loss: 0.057| r_loss: 0.059| p_loss: 0.079| v_loss: 0.022| per_loss: 0.292 | a_loss: 0.533
Train: Epoch [2107/3000], Step [150/158]| g_loss: 0.687| d_loss: 0.594| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.539
Train: Epoch [2108/3000], Step [30/158]| g_loss: 0.666| d_loss: 0.763| gp_loss: 0.135| r_loss: 0.060| p_loss: 0.082| v_loss: 0.022| per_loss: 0.306 | a_loss: 0.513
Train: Epoch [2108/3000], Step [60/158]| g_loss: 0.644| d_loss: 0.617| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.296 | a_loss: 0.498
Train: Epoch [2108/3000], Step [90/158]| g_loss: 0.695| d_loss: 0.574| gp_loss: 0.055| r_loss: 0.058| p_loss: 0.077| v_loss: 0.022| per_loss: 0.311 | a_loss: 0.546
Train: Epoch [2108/3000], Step [120/158]| g_loss: 0.657| d_loss: 0.660| gp_loss: 0.055| r_loss: 0.054| p_loss: 0.078| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.512
Train: Epoch [2108/3000], Step [150/158]| g_loss: 0.692| d_loss: 0.557| gp_loss: 0.063| r_loss: 0.058| p_loss: 0.082| v_loss: 0.022| per_loss: 0.306 | a_loss: 0.540
Train: Epoch [2109/3000], Step [30/158]| g_loss: 0.676| d_loss: 0.761| gp_loss: 0.204| r_loss: 0.059| p_loss: 0.082| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.525
Train: Epoch [2109/3000], Step [60/158]| g_loss: 0.662| d_loss: 0.678| gp_loss: 0.049| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.519
Train: Epoch [2109/3000], Step [90/158]| g_loss: 0.692| d_loss: 0.577| gp_loss: 0.054| r_loss: 0.055| p_loss: 0.074| v_loss: 0.022| per_loss: 0.300 | a_loss: 0.548
Train: Epoch [2109/3000], Step [120/158]| g_loss: 0.697| d_loss: 0.584| gp_loss: 0.055| r_loss: 0.055| p_loss: 0.074| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.553
Train: Epoch [2109/3000], Step [150/158]| g_loss: 0.649| d_loss: 0.603| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.073| v_loss: 0.020| per_loss: 0.311 | a_loss: 0.508
Train: Epoch [2110/3000], Step [30/158]| g_loss: 0.734| d_loss: 0.616| gp_loss: 0.163| r_loss: 0.055| p_loss: 0.073| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.590
Train: Epoch [2110/3000], Step [60/158]| g_loss: 0.655| d_loss: 0.638| gp_loss: 0.050| r_loss: 0.053| p_loss: 0.075| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.514
Train: Epoch [2110/3000], Step [90/158]| g_loss: 0.671| d_loss: 0.628| gp_loss: 0.053| r_loss: 0.056| p_loss: 0.076| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.527
Train: Epoch [2110/3000], Step [120/158]| g_loss: 0.661| d_loss: 0.636| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.074| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.517
Train: Epoch [2110/3000], Step [150/158]| g_loss: 0.682| d_loss: 0.611| gp_loss: 0.058| r_loss: 0.053| p_loss: 0.075| v_loss: 0.022| per_loss: 0.307 | a_loss: 0.538
Train: Epoch [2111/3000], Step [30/158]| g_loss: 0.645| d_loss: 0.810| gp_loss: 0.161| r_loss: 0.059| p_loss: 0.084| v_loss: 0.021| per_loss: 0.319 | a_loss: 0.492
Train: Epoch [2111/3000], Step [60/158]| g_loss: 0.668| d_loss: 0.637| gp_loss: 0.061| r_loss: 0.058| p_loss: 0.082| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.518
Train: Epoch [2111/3000], Step [90/158]| g_loss: 0.656| d_loss: 0.584| gp_loss: 0.057| r_loss: 0.059| p_loss: 0.083| v_loss: 0.021| per_loss: 0.318 | a_loss: 0.503
Train: Epoch [2111/3000], Step [120/158]| g_loss: 0.714| d_loss: 0.567| gp_loss: 0.056| r_loss: 0.059| p_loss: 0.082| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.562
Train: Epoch [2111/3000], Step [150/158]| g_loss: 0.684| d_loss: 0.649| gp_loss: 0.059| r_loss: 0.060| p_loss: 0.082| v_loss: 0.023| per_loss: 0.305 | a_loss: 0.530
Train: Epoch [2112/3000], Step [30/158]| g_loss: 0.688| d_loss: 0.685| gp_loss: 0.158| r_loss: 0.058| p_loss: 0.081| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.536
Train: Epoch [2112/3000], Step [60/158]| g_loss: 0.681| d_loss: 0.591| gp_loss: 0.056| r_loss: 0.053| p_loss: 0.076| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.538
Train: Epoch [2112/3000], Step [90/158]| g_loss: 0.674| d_loss: 0.676| gp_loss: 0.054| r_loss: 0.055| p_loss: 0.078| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.529
Train: Epoch [2112/3000], Step [120/158]| g_loss: 0.680| d_loss: 0.495| gp_loss: 0.063| r_loss: 0.061| p_loss: 0.078| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.527
Train: Epoch [2112/3000], Step [150/158]| g_loss: 0.673| d_loss: 0.693| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.527
Train: Epoch [2113/3000], Step [30/158]| g_loss: 0.666| d_loss: 0.749| gp_loss: 0.194| r_loss: 0.057| p_loss: 0.079| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.518
Train: Epoch [2113/3000], Step [60/158]| g_loss: 0.705| d_loss: 0.599| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.558
Train: Epoch [2113/3000], Step [90/158]| g_loss: 0.665| d_loss: 0.613| gp_loss: 0.050| r_loss: 0.055| p_loss: 0.078| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.518
Train: Epoch [2113/3000], Step [120/158]| g_loss: 0.704| d_loss: 0.538| gp_loss: 0.053| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.558
Train: Epoch [2113/3000], Step [150/158]| g_loss: 0.695| d_loss: 0.647| gp_loss: 0.057| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.295 | a_loss: 0.550
Train: Epoch [2114/3000], Step [30/158]| g_loss: 0.654| d_loss: 0.655| gp_loss: 0.141| r_loss: 0.055| p_loss: 0.077| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.507
Train: Epoch [2114/3000], Step [60/158]| g_loss: 0.679| d_loss: 0.665| gp_loss: 0.051| r_loss: 0.054| p_loss: 0.074| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.537
Train: Epoch [2114/3000], Step [90/158]| g_loss: 0.618| d_loss: 0.662| gp_loss: 0.055| r_loss: 0.055| p_loss: 0.073| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.475
Train: Epoch [2114/3000], Step [120/158]| g_loss: 0.687| d_loss: 0.597| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.079| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.540
Train: Epoch [2114/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.561| gp_loss: 0.055| r_loss: 0.056| p_loss: 0.079| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.521
Train: Epoch [2115/3000], Step [30/158]| g_loss: 0.678| d_loss: 0.727| gp_loss: 0.143| r_loss: 0.055| p_loss: 0.075| v_loss: 0.020| per_loss: 0.317 | a_loss: 0.534
Train: Epoch [2115/3000], Step [60/158]| g_loss: 0.679| d_loss: 0.544| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.073| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.540
Train: Epoch [2115/3000], Step [90/158]| g_loss: 0.700| d_loss: 0.579| gp_loss: 0.052| r_loss: 0.057| p_loss: 0.075| v_loss: 0.022| per_loss: 0.306 | a_loss: 0.552
Train: Epoch [2115/3000], Step [120/158]| g_loss: 0.653| d_loss: 0.639| gp_loss: 0.058| r_loss: 0.055| p_loss: 0.074| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.510
Train: Epoch [2115/3000], Step [150/158]| g_loss: 0.613| d_loss: 0.663| gp_loss: 0.059| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.469
Train: Epoch [2116/3000], Step [30/158]| g_loss: 0.694| d_loss: 0.674| gp_loss: 0.154| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.550
Train: Epoch [2116/3000], Step [60/158]| g_loss: 0.691| d_loss: 0.688| gp_loss: 0.053| r_loss: 0.055| p_loss: 0.080| v_loss: 0.022| per_loss: 0.332 | a_loss: 0.540
Train: Epoch [2116/3000], Step [90/158]| g_loss: 0.660| d_loss: 0.538| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.514
Train: Epoch [2116/3000], Step [120/158]| g_loss: 0.728| d_loss: 0.576| gp_loss: 0.058| r_loss: 0.055| p_loss: 0.074| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.586
Train: Epoch [2116/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.635| gp_loss: 0.054| r_loss: 0.057| p_loss: 0.079| v_loss: 0.021| per_loss: 0.295 | a_loss: 0.512
Train: Epoch [2117/3000], Step [30/158]| g_loss: 0.658| d_loss: 0.747| gp_loss: 0.203| r_loss: 0.053| p_loss: 0.072| v_loss: 0.021| per_loss: 0.294 | a_loss: 0.519
Train: Epoch [2117/3000], Step [60/158]| g_loss: 0.669| d_loss: 0.583| gp_loss: 0.053| r_loss: 0.054| p_loss: 0.074| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.525
Train: Epoch [2117/3000], Step [90/158]| g_loss: 0.669| d_loss: 0.629| gp_loss: 0.050| r_loss: 0.056| p_loss: 0.074| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.524
Train: Epoch [2117/3000], Step [120/158]| g_loss: 0.672| d_loss: 0.635| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.525
Train: Epoch [2117/3000], Step [150/158]| g_loss: 0.618| d_loss: 0.698| gp_loss: 0.055| r_loss: 0.055| p_loss: 0.078| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.474
Train: Epoch [2118/3000], Step [30/158]| g_loss: 0.682| d_loss: 0.735| gp_loss: 0.179| r_loss: 0.059| p_loss: 0.082| v_loss: 0.022| per_loss: 0.303 | a_loss: 0.530
Train: Epoch [2118/3000], Step [60/158]| g_loss: 0.598| d_loss: 0.700| gp_loss: 0.049| r_loss: 0.055| p_loss: 0.078| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.450
Train: Epoch [2118/3000], Step [90/158]| g_loss: 0.682| d_loss: 0.542| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.074| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.538
Train: Epoch [2118/3000], Step [120/158]| g_loss: 0.701| d_loss: 0.609| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.558
Train: Epoch [2118/3000], Step [150/158]| g_loss: 0.708| d_loss: 0.554| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.074| v_loss: 0.021| per_loss: 0.298 | a_loss: 0.566
Train: Epoch [2119/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.717| gp_loss: 0.099| r_loss: 0.054| p_loss: 0.077| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.518
Train: Epoch [2119/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.632| gp_loss: 0.054| r_loss: 0.060| p_loss: 0.080| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.519
Train: Epoch [2119/3000], Step [90/158]| g_loss: 0.675| d_loss: 0.592| gp_loss: 0.060| r_loss: 0.056| p_loss: 0.081| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.526
Train: Epoch [2119/3000], Step [120/158]| g_loss: 0.698| d_loss: 0.621| gp_loss: 0.055| r_loss: 0.056| p_loss: 0.082| v_loss: 0.022| per_loss: 0.300 | a_loss: 0.550
Train: Epoch [2119/3000], Step [150/158]| g_loss: 0.697| d_loss: 0.544| gp_loss: 0.060| r_loss: 0.059| p_loss: 0.081| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.545
Train: Epoch [2120/3000], Step [30/158]| g_loss: 0.676| d_loss: 0.734| gp_loss: 0.164| r_loss: 0.056| p_loss: 0.081| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.528
Train: Epoch [2120/3000], Step [60/158]| g_loss: 0.709| d_loss: 0.578| gp_loss: 0.053| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.565
Train: Epoch [2120/3000], Step [90/158]| g_loss: 0.664| d_loss: 0.618| gp_loss: 0.053| r_loss: 0.058| p_loss: 0.074| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.517
Train: Epoch [2120/3000], Step [120/158]| g_loss: 0.685| d_loss: 0.569| gp_loss: 0.053| r_loss: 0.055| p_loss: 0.075| v_loss: 0.020| per_loss: 0.316 | a_loss: 0.540
Train: Epoch [2120/3000], Step [150/158]| g_loss: 0.705| d_loss: 0.587| gp_loss: 0.053| r_loss: 0.062| p_loss: 0.084| v_loss: 0.022| per_loss: 0.301 | a_loss: 0.549
Train: Epoch [2121/3000], Step [30/158]| g_loss: 0.637| d_loss: 0.786| gp_loss: 0.090| r_loss: 0.061| p_loss: 0.084| v_loss: 0.021| per_loss: 0.293 | a_loss: 0.484
Train: Epoch [2121/3000], Step [60/158]| g_loss: 0.639| d_loss: 0.633| gp_loss: 0.062| r_loss: 0.055| p_loss: 0.076| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.496
Train: Epoch [2121/3000], Step [90/158]| g_loss: 0.661| d_loss: 0.596| gp_loss: 0.059| r_loss: 0.055| p_loss: 0.081| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.512
Train: Epoch [2121/3000], Step [120/158]| g_loss: 0.733| d_loss: 0.521| gp_loss: 0.059| r_loss: 0.057| p_loss: 0.078| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.584
Train: Epoch [2121/3000], Step [150/158]| g_loss: 0.687| d_loss: 0.642| gp_loss: 0.058| r_loss: 0.056| p_loss: 0.079| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.540
Train: Epoch [2122/3000], Step [30/158]| g_loss: 0.636| d_loss: 0.788| gp_loss: 0.151| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.318 | a_loss: 0.487
Train: Epoch [2122/3000], Step [60/158]| g_loss: 0.631| d_loss: 0.669| gp_loss: 0.057| r_loss: 0.056| p_loss: 0.081| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.484
Train: Epoch [2122/3000], Step [90/158]| g_loss: 0.732| d_loss: 0.482| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.075| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.586
Train: Epoch [2122/3000], Step [120/158]| g_loss: 0.717| d_loss: 0.664| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.080| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.568
Train: Epoch [2122/3000], Step [150/158]| g_loss: 0.644| d_loss: 0.590| gp_loss: 0.062| r_loss: 0.056| p_loss: 0.074| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.498
Train: Epoch [2123/3000], Step [30/158]| g_loss: 0.698| d_loss: 0.714| gp_loss: 0.190| r_loss: 0.053| p_loss: 0.072| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.558
Train: Epoch [2123/3000], Step [60/158]| g_loss: 0.663| d_loss: 0.638| gp_loss: 0.051| r_loss: 0.056| p_loss: 0.075| v_loss: 0.022| per_loss: 0.316 | a_loss: 0.516
Train: Epoch [2123/3000], Step [90/158]| g_loss: 0.655| d_loss: 0.568| gp_loss: 0.051| r_loss: 0.053| p_loss: 0.077| v_loss: 0.021| per_loss: 0.296 | a_loss: 0.513
Train: Epoch [2123/3000], Step [120/158]| g_loss: 0.728| d_loss: 0.559| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.585
Train: Epoch [2123/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.673| gp_loss: 0.055| r_loss: 0.057| p_loss: 0.076| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.512
Train: Epoch [2124/3000], Step [30/158]| g_loss: 0.689| d_loss: 0.681| gp_loss: 0.172| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.544
Train: Epoch [2124/3000], Step [60/158]| g_loss: 0.671| d_loss: 0.613| gp_loss: 0.052| r_loss: 0.053| p_loss: 0.075| v_loss: 0.022| per_loss: 0.326 | a_loss: 0.526
Train: Epoch [2124/3000], Step [90/158]| g_loss: 0.652| d_loss: 0.690| gp_loss: 0.050| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.505
Train: Epoch [2124/3000], Step [120/158]| g_loss: 0.646| d_loss: 0.662| gp_loss: 0.055| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.498
Train: Epoch [2124/3000], Step [150/158]| g_loss: 0.701| d_loss: 0.567| gp_loss: 0.055| r_loss: 0.056| p_loss: 0.076| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.555
Train: Epoch [2125/3000], Step [30/158]| g_loss: 0.694| d_loss: 0.613| gp_loss: 0.138| r_loss: 0.055| p_loss: 0.076| v_loss: 0.020| per_loss: 0.316 | a_loss: 0.549
Train: Epoch [2125/3000], Step [60/158]| g_loss: 0.698| d_loss: 0.620| gp_loss: 0.050| r_loss: 0.057| p_loss: 0.078| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.549
Train: Epoch [2125/3000], Step [90/158]| g_loss: 0.680| d_loss: 0.568| gp_loss: 0.053| r_loss: 0.054| p_loss: 0.073| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.537
Train: Epoch [2125/3000], Step [120/158]| g_loss: 0.719| d_loss: 0.629| gp_loss: 0.055| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.317 | a_loss: 0.573
Train: Epoch [2125/3000], Step [150/158]| g_loss: 0.641| d_loss: 0.629| gp_loss: 0.055| r_loss: 0.057| p_loss: 0.081| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.492
Train: Epoch [2126/3000], Step [30/158]| g_loss: 0.643| d_loss: 0.756| gp_loss: 0.167| r_loss: 0.058| p_loss: 0.082| v_loss: 0.022| per_loss: 0.327 | a_loss: 0.490
Train: Epoch [2126/3000], Step [60/158]| g_loss: 0.688| d_loss: 0.689| gp_loss: 0.050| r_loss: 0.059| p_loss: 0.084| v_loss: 0.022| per_loss: 0.306 | a_loss: 0.534
Train: Epoch [2126/3000], Step [90/158]| g_loss: 0.667| d_loss: 0.615| gp_loss: 0.054| r_loss: 0.059| p_loss: 0.080| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.515
Train: Epoch [2126/3000], Step [120/158]| g_loss: 0.651| d_loss: 0.698| gp_loss: 0.053| r_loss: 0.059| p_loss: 0.086| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.496
Train: Epoch [2126/3000], Step [150/158]| g_loss: 0.687| d_loss: 0.483| gp_loss: 0.052| r_loss: 0.057| p_loss: 0.078| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.540
Train: Epoch [2127/3000], Step [30/158]| g_loss: 0.691| d_loss: 0.659| gp_loss: 0.129| r_loss: 0.054| p_loss: 0.074| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.548
Train: Epoch [2127/3000], Step [60/158]| g_loss: 0.705| d_loss: 0.605| gp_loss: 0.051| r_loss: 0.055| p_loss: 0.077| v_loss: 0.020| per_loss: 0.324 | a_loss: 0.558
Train: Epoch [2127/3000], Step [90/158]| g_loss: 0.672| d_loss: 0.620| gp_loss: 0.050| r_loss: 0.054| p_loss: 0.076| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.528
Train: Epoch [2127/3000], Step [120/158]| g_loss: 0.638| d_loss: 0.638| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.078| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.489
Train: Epoch [2127/3000], Step [150/158]| g_loss: 0.685| d_loss: 0.534| gp_loss: 0.059| r_loss: 0.053| p_loss: 0.074| v_loss: 0.022| per_loss: 0.302 | a_loss: 0.543
Train: Epoch [2128/3000], Step [30/158]| g_loss: 0.683| d_loss: 0.736| gp_loss: 0.164| r_loss: 0.054| p_loss: 0.077| v_loss: 0.021| per_loss: 0.292 | a_loss: 0.540
Train: Epoch [2128/3000], Step [60/158]| g_loss: 0.627| d_loss: 0.670| gp_loss: 0.053| r_loss: 0.059| p_loss: 0.078| v_loss: 0.022| per_loss: 0.325 | a_loss: 0.474
Train: Epoch [2128/3000], Step [90/158]| g_loss: 0.651| d_loss: 0.613| gp_loss: 0.058| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.321 | a_loss: 0.504
Train: Epoch [2128/3000], Step [120/158]| g_loss: 0.707| d_loss: 0.582| gp_loss: 0.058| r_loss: 0.056| p_loss: 0.077| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.562
Train: Epoch [2128/3000], Step [150/158]| g_loss: 0.691| d_loss: 0.568| gp_loss: 0.060| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.546
Train: Epoch [2129/3000], Step [30/158]| g_loss: 0.688| d_loss: 0.705| gp_loss: 0.105| r_loss: 0.062| p_loss: 0.087| v_loss: 0.022| per_loss: 0.325 | a_loss: 0.529
Train: Epoch [2129/3000], Step [60/158]| g_loss: 0.696| d_loss: 0.557| gp_loss: 0.056| r_loss: 0.068| p_loss: 0.089| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.531
Train: Epoch [2129/3000], Step [90/158]| g_loss: 0.696| d_loss: 0.610| gp_loss: 0.059| r_loss: 0.058| p_loss: 0.084| v_loss: 0.022| per_loss: 0.319 | a_loss: 0.542
Train: Epoch [2129/3000], Step [120/158]| g_loss: 0.689| d_loss: 0.609| gp_loss: 0.062| r_loss: 0.054| p_loss: 0.078| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.543
Train: Epoch [2129/3000], Step [150/158]| g_loss: 0.700| d_loss: 0.586| gp_loss: 0.058| r_loss: 0.055| p_loss: 0.079| v_loss: 0.021| per_loss: 0.316 | a_loss: 0.553
Train: Epoch [2130/3000], Step [30/158]| g_loss: 0.682| d_loss: 0.733| gp_loss: 0.186| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.298 | a_loss: 0.536
Train: Epoch [2130/3000], Step [60/158]| g_loss: 0.685| d_loss: 0.570| gp_loss: 0.054| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.540
Train: Epoch [2130/3000], Step [90/158]| g_loss: 0.661| d_loss: 0.673| gp_loss: 0.054| r_loss: 0.060| p_loss: 0.082| v_loss: 0.022| per_loss: 0.325 | a_loss: 0.506
Train: Epoch [2130/3000], Step [120/158]| g_loss: 0.643| d_loss: 0.659| gp_loss: 0.055| r_loss: 0.055| p_loss: 0.079| v_loss: 0.021| per_loss: 0.316 | a_loss: 0.496
Train: Epoch [2130/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.604| gp_loss: 0.060| r_loss: 0.055| p_loss: 0.077| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.518
Train: Epoch [2131/3000], Step [30/158]| g_loss: 0.678| d_loss: 0.702| gp_loss: 0.143| r_loss: 0.055| p_loss: 0.080| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.531
Train: Epoch [2131/3000], Step [60/158]| g_loss: 0.651| d_loss: 0.685| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.075| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.506
Train: Epoch [2131/3000], Step [90/158]| g_loss: 0.677| d_loss: 0.556| gp_loss: 0.061| r_loss: 0.056| p_loss: 0.076| v_loss: 0.022| per_loss: 0.311 | a_loss: 0.531
Train: Epoch [2131/3000], Step [120/158]| g_loss: 0.703| d_loss: 0.543| gp_loss: 0.062| r_loss: 0.056| p_loss: 0.078| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.555
Train: Epoch [2131/3000], Step [150/158]| g_loss: 0.690| d_loss: 0.623| gp_loss: 0.058| r_loss: 0.056| p_loss: 0.079| v_loss: 0.022| per_loss: 0.333 | a_loss: 0.539
Train: Epoch [2132/3000], Step [30/158]| g_loss: 0.659| d_loss: 0.738| gp_loss: 0.163| r_loss: 0.056| p_loss: 0.078| v_loss: 0.022| per_loss: 0.314 | a_loss: 0.511
Train: Epoch [2132/3000], Step [60/158]| g_loss: 0.709| d_loss: 0.596| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.080| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.560
Train: Epoch [2132/3000], Step [90/158]| g_loss: 0.718| d_loss: 0.560| gp_loss: 0.053| r_loss: 0.056| p_loss: 0.075| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.572
Train: Epoch [2132/3000], Step [120/158]| g_loss: 0.662| d_loss: 0.635| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.323 | a_loss: 0.514
Train: Epoch [2132/3000], Step [150/158]| g_loss: 0.693| d_loss: 0.614| gp_loss: 0.057| r_loss: 0.054| p_loss: 0.077| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.548
Train: Epoch [2133/3000], Step [30/158]| g_loss: 0.691| d_loss: 0.649| gp_loss: 0.140| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.295 | a_loss: 0.546
Train: Epoch [2133/3000], Step [60/158]| g_loss: 0.694| d_loss: 0.639| gp_loss: 0.051| r_loss: 0.057| p_loss: 0.075| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.548
Train: Epoch [2133/3000], Step [90/158]| g_loss: 0.664| d_loss: 0.590| gp_loss: 0.058| r_loss: 0.055| p_loss: 0.074| v_loss: 0.022| per_loss: 0.326 | a_loss: 0.518
Train: Epoch [2133/3000], Step [120/158]| g_loss: 0.673| d_loss: 0.602| gp_loss: 0.056| r_loss: 0.053| p_loss: 0.071| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.533
Train: Epoch [2133/3000], Step [150/158]| g_loss: 0.660| d_loss: 0.680| gp_loss: 0.062| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.514
Train: Epoch [2134/3000], Step [30/158]| g_loss: 0.651| d_loss: 0.739| gp_loss: 0.194| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.292 | a_loss: 0.507
Train: Epoch [2134/3000], Step [60/158]| g_loss: 0.630| d_loss: 0.669| gp_loss: 0.054| r_loss: 0.053| p_loss: 0.076| v_loss: 0.021| per_loss: 0.318 | a_loss: 0.486
Train: Epoch [2134/3000], Step [90/158]| g_loss: 0.686| d_loss: 0.574| gp_loss: 0.053| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.318 | a_loss: 0.538
Train: Epoch [2134/3000], Step [120/158]| g_loss: 0.729| d_loss: 0.558| gp_loss: 0.057| r_loss: 0.056| p_loss: 0.076| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.583
Train: Epoch [2134/3000], Step [150/158]| g_loss: 0.682| d_loss: 0.627| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.539
Train: Epoch [2135/3000], Step [30/158]| g_loss: 0.662| d_loss: 0.670| gp_loss: 0.116| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.516
Train: Epoch [2135/3000], Step [60/158]| g_loss: 0.666| d_loss: 0.663| gp_loss: 0.053| r_loss: 0.057| p_loss: 0.076| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.521
Train: Epoch [2135/3000], Step [90/158]| g_loss: 0.641| d_loss: 0.594| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.073| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.502
Train: Epoch [2135/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.634| gp_loss: 0.062| r_loss: 0.054| p_loss: 0.077| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.533
Train: Epoch [2135/3000], Step [150/158]| g_loss: 0.701| d_loss: 0.574| gp_loss: 0.062| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.556
Train: Epoch [2136/3000], Step [30/158]| g_loss: 0.662| d_loss: 0.765| gp_loss: 0.174| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.515
Train: Epoch [2136/3000], Step [60/158]| g_loss: 0.712| d_loss: 0.573| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.076| v_loss: 0.022| per_loss: 0.322 | a_loss: 0.565
Train: Epoch [2136/3000], Step [90/158]| g_loss: 0.703| d_loss: 0.506| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.074| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.560
Train: Epoch [2136/3000], Step [120/158]| g_loss: 0.642| d_loss: 0.708| gp_loss: 0.055| r_loss: 0.057| p_loss: 0.076| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.495
Train: Epoch [2136/3000], Step [150/158]| g_loss: 0.641| d_loss: 0.637| gp_loss: 0.058| r_loss: 0.055| p_loss: 0.075| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.500
Train: Epoch [2137/3000], Step [30/158]| g_loss: 0.739| d_loss: 0.641| gp_loss: 0.187| r_loss: 0.058| p_loss: 0.079| v_loss: 0.023| per_loss: 0.315 | a_loss: 0.587
Train: Epoch [2137/3000], Step [60/158]| g_loss: 0.703| d_loss: 0.584| gp_loss: 0.049| r_loss: 0.054| p_loss: 0.077| v_loss: 0.022| per_loss: 0.300 | a_loss: 0.559
Train: Epoch [2137/3000], Step [90/158]| g_loss: 0.710| d_loss: 0.569| gp_loss: 0.053| r_loss: 0.056| p_loss: 0.079| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.564
Train: Epoch [2137/3000], Step [120/158]| g_loss: 0.651| d_loss: 0.638| gp_loss: 0.054| r_loss: 0.053| p_loss: 0.072| v_loss: 0.020| per_loss: 0.320 | a_loss: 0.509
Train: Epoch [2137/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.771| gp_loss: 0.053| r_loss: 0.059| p_loss: 0.079| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.514
Train: Epoch [2138/3000], Step [30/158]| g_loss: 0.631| d_loss: 0.701| gp_loss: 0.107| r_loss: 0.056| p_loss: 0.076| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.486
Train: Epoch [2138/3000], Step [60/158]| g_loss: 0.629| d_loss: 0.683| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.081| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.481
Train: Epoch [2138/3000], Step [90/158]| g_loss: 0.630| d_loss: 0.640| gp_loss: 0.057| r_loss: 0.053| p_loss: 0.074| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.488
Train: Epoch [2138/3000], Step [120/158]| g_loss: 0.702| d_loss: 0.575| gp_loss: 0.058| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.556
Train: Epoch [2138/3000], Step [150/158]| g_loss: 0.682| d_loss: 0.564| gp_loss: 0.058| r_loss: 0.056| p_loss: 0.074| v_loss: 0.020| per_loss: 0.278 | a_loss: 0.542
Train: Epoch [2139/3000], Step [30/158]| g_loss: 0.661| d_loss: 0.747| gp_loss: 0.131| r_loss: 0.058| p_loss: 0.084| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.509
Train: Epoch [2139/3000], Step [60/158]| g_loss: 0.659| d_loss: 0.659| gp_loss: 0.057| r_loss: 0.055| p_loss: 0.079| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.513
Train: Epoch [2139/3000], Step [90/158]| g_loss: 0.668| d_loss: 0.564| gp_loss: 0.058| r_loss: 0.054| p_loss: 0.073| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.526
Train: Epoch [2139/3000], Step [120/158]| g_loss: 0.698| d_loss: 0.580| gp_loss: 0.063| r_loss: 0.057| p_loss: 0.078| v_loss: 0.021| per_loss: 0.296 | a_loss: 0.552
Train: Epoch [2139/3000], Step [150/158]| g_loss: 0.686| d_loss: 0.597| gp_loss: 0.060| r_loss: 0.057| p_loss: 0.077| v_loss: 0.022| per_loss: 0.302 | a_loss: 0.539
Train: Epoch [2140/3000], Step [30/158]| g_loss: 0.693| d_loss: 0.602| gp_loss: 0.104| r_loss: 0.056| p_loss: 0.078| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.545
Train: Epoch [2140/3000], Step [60/158]| g_loss: 0.707| d_loss: 0.579| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.076| v_loss: 0.021| per_loss: 0.286 | a_loss: 0.564
Train: Epoch [2140/3000], Step [90/158]| g_loss: 0.689| d_loss: 0.610| gp_loss: 0.061| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.544
Train: Epoch [2140/3000], Step [120/158]| g_loss: 0.658| d_loss: 0.656| gp_loss: 0.062| r_loss: 0.054| p_loss: 0.076| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.515
Train: Epoch [2140/3000], Step [150/158]| g_loss: 0.667| d_loss: 0.736| gp_loss: 0.061| r_loss: 0.058| p_loss: 0.082| v_loss: 0.022| per_loss: 0.304 | a_loss: 0.516
Train: Epoch [2141/3000], Step [30/158]| g_loss: 0.639| d_loss: 0.692| gp_loss: 0.173| r_loss: 0.055| p_loss: 0.078| v_loss: 0.022| per_loss: 0.304 | a_loss: 0.492
Train: Epoch [2141/3000], Step [60/158]| g_loss: 0.658| d_loss: 0.656| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.071| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.521
Train: Epoch [2141/3000], Step [90/158]| g_loss: 0.620| d_loss: 0.709| gp_loss: 0.059| r_loss: 0.056| p_loss: 0.076| v_loss: 0.022| per_loss: 0.305 | a_loss: 0.474
Train: Epoch [2141/3000], Step [120/158]| g_loss: 0.658| d_loss: 0.542| gp_loss: 0.061| r_loss: 0.058| p_loss: 0.078| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.509
Train: Epoch [2141/3000], Step [150/158]| g_loss: 0.760| d_loss: 0.538| gp_loss: 0.062| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.288 | a_loss: 0.617
Train: Epoch [2142/3000], Step [30/158]| g_loss: 0.649| d_loss: 0.804| gp_loss: 0.120| r_loss: 0.054| p_loss: 0.077| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.507
Train: Epoch [2142/3000], Step [60/158]| g_loss: 0.646| d_loss: 0.600| gp_loss: 0.061| r_loss: 0.057| p_loss: 0.078| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.498
Train: Epoch [2142/3000], Step [90/158]| g_loss: 0.684| d_loss: 0.527| gp_loss: 0.060| r_loss: 0.056| p_loss: 0.076| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.541
Train: Epoch [2142/3000], Step [120/158]| g_loss: 0.708| d_loss: 0.609| gp_loss: 0.059| r_loss: 0.058| p_loss: 0.079| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.559
Train: Epoch [2142/3000], Step [150/158]| g_loss: 0.652| d_loss: 0.610| gp_loss: 0.063| r_loss: 0.055| p_loss: 0.076| v_loss: 0.022| per_loss: 0.307 | a_loss: 0.507
Train: Epoch [2143/3000], Step [30/158]| g_loss: 0.668| d_loss: 0.744| gp_loss: 0.147| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.525
Train: Epoch [2143/3000], Step [60/158]| g_loss: 0.663| d_loss: 0.649| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.076| v_loss: 0.021| per_loss: 0.287 | a_loss: 0.517
Train: Epoch [2143/3000], Step [90/158]| g_loss: 0.671| d_loss: 0.598| gp_loss: 0.057| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.527
Train: Epoch [2143/3000], Step [120/158]| g_loss: 0.663| d_loss: 0.586| gp_loss: 0.058| r_loss: 0.057| p_loss: 0.076| v_loss: 0.021| per_loss: 0.322 | a_loss: 0.514
Train: Epoch [2143/3000], Step [150/158]| g_loss: 0.704| d_loss: 0.589| gp_loss: 0.061| r_loss: 0.055| p_loss: 0.073| v_loss: 0.021| per_loss: 0.291 | a_loss: 0.563
Train: Epoch [2144/3000], Step [30/158]| g_loss: 0.675| d_loss: 0.710| gp_loss: 0.184| r_loss: 0.055| p_loss: 0.073| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.532
Train: Epoch [2144/3000], Step [60/158]| g_loss: 0.664| d_loss: 0.663| gp_loss: 0.054| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.521
Train: Epoch [2144/3000], Step [90/158]| g_loss: 0.651| d_loss: 0.625| gp_loss: 0.056| r_loss: 0.053| p_loss: 0.072| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.512
Train: Epoch [2144/3000], Step [120/158]| g_loss: 0.705| d_loss: 0.550| gp_loss: 0.056| r_loss: 0.054| p_loss: 0.072| v_loss: 0.022| per_loss: 0.292 | a_loss: 0.564
Train: Epoch [2144/3000], Step [150/158]| g_loss: 0.672| d_loss: 0.601| gp_loss: 0.057| r_loss: 0.053| p_loss: 0.072| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.530
Train: Epoch [2145/3000], Step [30/158]| g_loss: 0.647| d_loss: 0.719| gp_loss: 0.135| r_loss: 0.054| p_loss: 0.073| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.508
Train: Epoch [2145/3000], Step [60/158]| g_loss: 0.690| d_loss: 0.584| gp_loss: 0.052| r_loss: 0.054| p_loss: 0.076| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.547
Train: Epoch [2145/3000], Step [90/158]| g_loss: 0.672| d_loss: 0.659| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.076| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.527
Train: Epoch [2145/3000], Step [120/158]| g_loss: 0.655| d_loss: 0.594| gp_loss: 0.058| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.511
Train: Epoch [2145/3000], Step [150/158]| g_loss: 0.689| d_loss: 0.551| gp_loss: 0.063| r_loss: 0.055| p_loss: 0.073| v_loss: 0.021| per_loss: 0.298 | a_loss: 0.547
Train: Epoch [2146/3000], Step [30/158]| g_loss: 0.690| d_loss: 0.691| gp_loss: 0.175| r_loss: 0.054| p_loss: 0.074| v_loss: 0.021| per_loss: 0.295 | a_loss: 0.549
Train: Epoch [2146/3000], Step [60/158]| g_loss: 0.716| d_loss: 0.587| gp_loss: 0.051| r_loss: 0.055| p_loss: 0.073| v_loss: 0.021| per_loss: 0.290 | a_loss: 0.574
Train: Epoch [2146/3000], Step [90/158]| g_loss: 0.614| d_loss: 0.645| gp_loss: 0.058| r_loss: 0.053| p_loss: 0.073| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.474
Train: Epoch [2146/3000], Step [120/158]| g_loss: 0.699| d_loss: 0.580| gp_loss: 0.055| r_loss: 0.055| p_loss: 0.074| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.555
Train: Epoch [2146/3000], Step [150/158]| g_loss: 0.676| d_loss: 0.681| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.532
Train: Epoch [2147/3000], Step [30/158]| g_loss: 0.650| d_loss: 0.666| gp_loss: 0.095| r_loss: 0.054| p_loss: 0.078| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.504
Train: Epoch [2147/3000], Step [60/158]| g_loss: 0.717| d_loss: 0.579| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.078| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.569
Train: Epoch [2147/3000], Step [90/158]| g_loss: 0.694| d_loss: 0.585| gp_loss: 0.057| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.549
Train: Epoch [2147/3000], Step [120/158]| g_loss: 0.657| d_loss: 0.717| gp_loss: 0.056| r_loss: 0.058| p_loss: 0.081| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.507
Train: Epoch [2147/3000], Step [150/158]| g_loss: 0.630| d_loss: 0.629| gp_loss: 0.062| r_loss: 0.056| p_loss: 0.076| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.483
Train: Epoch [2148/3000], Step [30/158]| g_loss: 0.660| d_loss: 0.676| gp_loss: 0.148| r_loss: 0.056| p_loss: 0.076| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.515
Train: Epoch [2148/3000], Step [60/158]| g_loss: 0.714| d_loss: 0.576| gp_loss: 0.055| r_loss: 0.054| p_loss: 0.076| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.569
Train: Epoch [2148/3000], Step [90/158]| g_loss: 0.712| d_loss: 0.565| gp_loss: 0.060| r_loss: 0.056| p_loss: 0.077| v_loss: 0.022| per_loss: 0.303 | a_loss: 0.565
Train: Epoch [2148/3000], Step [120/158]| g_loss: 0.659| d_loss: 0.645| gp_loss: 0.056| r_loss: 0.054| p_loss: 0.076| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.516
Train: Epoch [2148/3000], Step [150/158]| g_loss: 0.693| d_loss: 0.643| gp_loss: 0.064| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.547
Train: Epoch [2149/3000], Step [30/158]| g_loss: 0.633| d_loss: 0.753| gp_loss: 0.156| r_loss: 0.055| p_loss: 0.077| v_loss: 0.022| per_loss: 0.306 | a_loss: 0.487
Train: Epoch [2149/3000], Step [60/158]| g_loss: 0.658| d_loss: 0.542| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.077| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.514
Train: Epoch [2149/3000], Step [90/158]| g_loss: 0.699| d_loss: 0.588| gp_loss: 0.058| r_loss: 0.055| p_loss: 0.073| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.556
Train: Epoch [2149/3000], Step [120/158]| g_loss: 0.697| d_loss: 0.581| gp_loss: 0.058| r_loss: 0.057| p_loss: 0.077| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.550
Train: Epoch [2149/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.706| gp_loss: 0.058| r_loss: 0.057| p_loss: 0.078| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.521
Train: Epoch [2150/3000], Step [30/158]| g_loss: 0.673| d_loss: 0.690| gp_loss: 0.099| r_loss: 0.066| p_loss: 0.092| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.509
Train: Epoch [2150/3000], Step [60/158]| g_loss: 0.689| d_loss: 0.522| gp_loss: 0.062| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.545
Train: Epoch [2150/3000], Step [90/158]| g_loss: 0.696| d_loss: 0.633| gp_loss: 0.057| r_loss: 0.056| p_loss: 0.076| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.551
Train: Epoch [2150/3000], Step [120/158]| g_loss: 0.692| d_loss: 0.598| gp_loss: 0.061| r_loss: 0.057| p_loss: 0.080| v_loss: 0.022| per_loss: 0.322 | a_loss: 0.542
Train: Epoch [2150/3000], Step [150/158]| g_loss: 0.641| d_loss: 0.660| gp_loss: 0.058| r_loss: 0.057| p_loss: 0.081| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.493
Test: Epoch [2150/3000]| g_loss: 0.629| r_loss: 0.393| p_loss: 0.312| v_loss: 0.022
Train: Epoch [2151/3000], Step [30/158]| g_loss: 0.706| d_loss: 0.605| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.559
Train: Epoch [2151/3000], Step [60/158]| g_loss: 0.647| d_loss: 0.662| gp_loss: 0.050| r_loss: 0.058| p_loss: 0.080| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.495
Train: Epoch [2151/3000], Step [90/158]| g_loss: 0.662| d_loss: 0.616| gp_loss: 0.058| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.298 | a_loss: 0.519
Train: Epoch [2151/3000], Step [120/158]| g_loss: 0.679| d_loss: 0.587| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.078| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.533
Train: Epoch [2151/3000], Step [150/158]| g_loss: 0.649| d_loss: 0.621| gp_loss: 0.058| r_loss: 0.055| p_loss: 0.074| v_loss: 0.020| per_loss: 0.311 | a_loss: 0.505
Train: Epoch [2152/3000], Step [30/158]| g_loss: 0.670| d_loss: 0.775| gp_loss: 0.174| r_loss: 0.053| p_loss: 0.076| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.527
Train: Epoch [2152/3000], Step [60/158]| g_loss: 0.626| d_loss: 0.612| gp_loss: 0.053| r_loss: 0.055| p_loss: 0.074| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.483
Train: Epoch [2152/3000], Step [90/158]| g_loss: 0.687| d_loss: 0.631| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.078| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.540
Train: Epoch [2152/3000], Step [120/158]| g_loss: 0.656| d_loss: 0.621| gp_loss: 0.060| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.513
Train: Epoch [2152/3000], Step [150/158]| g_loss: 0.723| d_loss: 0.538| gp_loss: 0.058| r_loss: 0.057| p_loss: 0.076| v_loss: 0.022| per_loss: 0.303 | a_loss: 0.576
Train: Epoch [2153/3000], Step [30/158]| g_loss: 0.722| d_loss: 0.624| gp_loss: 0.131| r_loss: 0.056| p_loss: 0.076| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.575
Train: Epoch [2153/3000], Step [60/158]| g_loss: 0.675| d_loss: 0.615| gp_loss: 0.053| r_loss: 0.055| p_loss: 0.073| v_loss: 0.021| per_loss: 0.317 | a_loss: 0.531
Train: Epoch [2153/3000], Step [90/158]| g_loss: 0.649| d_loss: 0.627| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.070| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.513
Train: Epoch [2153/3000], Step [120/158]| g_loss: 0.652| d_loss: 0.614| gp_loss: 0.058| r_loss: 0.053| p_loss: 0.073| v_loss: 0.020| per_loss: 0.311 | a_loss: 0.511
Train: Epoch [2153/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.660| gp_loss: 0.061| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.521
Train: Epoch [2154/3000], Step [30/158]| g_loss: 0.666| d_loss: 0.726| gp_loss: 0.134| r_loss: 0.057| p_loss: 0.078| v_loss: 0.022| per_loss: 0.299 | a_loss: 0.517
Train: Epoch [2154/3000], Step [60/158]| g_loss: 0.644| d_loss: 0.601| gp_loss: 0.061| r_loss: 0.057| p_loss: 0.077| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.496
Train: Epoch [2154/3000], Step [90/158]| g_loss: 0.696| d_loss: 0.633| gp_loss: 0.057| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.317 | a_loss: 0.547
Train: Epoch [2154/3000], Step [120/158]| g_loss: 0.680| d_loss: 0.614| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.080| v_loss: 0.022| per_loss: 0.324 | a_loss: 0.529
Train: Epoch [2154/3000], Step [150/158]| g_loss: 0.738| d_loss: 0.473| gp_loss: 0.058| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.593
Train: Epoch [2155/3000], Step [30/158]| g_loss: 0.664| d_loss: 0.813| gp_loss: 0.183| r_loss: 0.060| p_loss: 0.078| v_loss: 0.021| per_loss: 0.296 | a_loss: 0.516
Train: Epoch [2155/3000], Step [60/158]| g_loss: 0.667| d_loss: 0.629| gp_loss: 0.056| r_loss: 0.058| p_loss: 0.078| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.518
Train: Epoch [2155/3000], Step [90/158]| g_loss: 0.659| d_loss: 0.569| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.292 | a_loss: 0.516
Train: Epoch [2155/3000], Step [120/158]| g_loss: 0.668| d_loss: 0.664| gp_loss: 0.055| r_loss: 0.055| p_loss: 0.077| v_loss: 0.020| per_loss: 0.312 | a_loss: 0.523
Train: Epoch [2155/3000], Step [150/158]| g_loss: 0.651| d_loss: 0.573| gp_loss: 0.060| r_loss: 0.060| p_loss: 0.082| v_loss: 0.022| per_loss: 0.305 | a_loss: 0.497
Train: Epoch [2156/3000], Step [30/158]| g_loss: 0.711| d_loss: 0.696| gp_loss: 0.161| r_loss: 0.055| p_loss: 0.077| v_loss: 0.022| per_loss: 0.302 | a_loss: 0.566
Train: Epoch [2156/3000], Step [60/158]| g_loss: 0.681| d_loss: 0.587| gp_loss: 0.053| r_loss: 0.056| p_loss: 0.075| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.536
Train: Epoch [2156/3000], Step [90/158]| g_loss: 0.652| d_loss: 0.686| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.076| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.508
Train: Epoch [2156/3000], Step [120/158]| g_loss: 0.663| d_loss: 0.571| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.073| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.520
Train: Epoch [2156/3000], Step [150/158]| g_loss: 0.657| d_loss: 0.608| gp_loss: 0.057| r_loss: 0.053| p_loss: 0.071| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.517
Train: Epoch [2157/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.682| gp_loss: 0.118| r_loss: 0.053| p_loss: 0.071| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.525
Train: Epoch [2157/3000], Step [60/158]| g_loss: 0.647| d_loss: 0.622| gp_loss: 0.056| r_loss: 0.054| p_loss: 0.069| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.507
Train: Epoch [2157/3000], Step [90/158]| g_loss: 0.715| d_loss: 0.565| gp_loss: 0.060| r_loss: 0.054| p_loss: 0.073| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.573
Train: Epoch [2157/3000], Step [120/158]| g_loss: 0.689| d_loss: 0.604| gp_loss: 0.061| r_loss: 0.054| p_loss: 0.076| v_loss: 0.022| per_loss: 0.301 | a_loss: 0.546
Train: Epoch [2157/3000], Step [150/158]| g_loss: 0.666| d_loss: 0.698| gp_loss: 0.059| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.518
Train: Epoch [2158/3000], Step [30/158]| g_loss: 0.639| d_loss: 0.755| gp_loss: 0.147| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.493
Train: Epoch [2158/3000], Step [60/158]| g_loss: 0.692| d_loss: 0.591| gp_loss: 0.056| r_loss: 0.054| p_loss: 0.074| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.549
Train: Epoch [2158/3000], Step [90/158]| g_loss: 0.639| d_loss: 0.642| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.074| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.495
Train: Epoch [2158/3000], Step [120/158]| g_loss: 0.674| d_loss: 0.613| gp_loss: 0.055| r_loss: 0.055| p_loss: 0.074| v_loss: 0.022| per_loss: 0.305 | a_loss: 0.530
Train: Epoch [2158/3000], Step [150/158]| g_loss: 0.676| d_loss: 0.604| gp_loss: 0.059| r_loss: 0.053| p_loss: 0.074| v_loss: 0.021| per_loss: 0.296 | a_loss: 0.536
Train: Epoch [2159/3000], Step [30/158]| g_loss: 0.714| d_loss: 0.684| gp_loss: 0.117| r_loss: 0.055| p_loss: 0.077| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.567
Train: Epoch [2159/3000], Step [60/158]| g_loss: 0.688| d_loss: 0.535| gp_loss: 0.057| r_loss: 0.056| p_loss: 0.076| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.542
Train: Epoch [2159/3000], Step [90/158]| g_loss: 0.703| d_loss: 0.623| gp_loss: 0.064| r_loss: 0.054| p_loss: 0.076| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.559
Train: Epoch [2159/3000], Step [120/158]| g_loss: 0.607| d_loss: 0.723| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.461
Train: Epoch [2159/3000], Step [150/158]| g_loss: 0.687| d_loss: 0.588| gp_loss: 0.061| r_loss: 0.054| p_loss: 0.078| v_loss: 0.022| per_loss: 0.309 | a_loss: 0.542
Train: Epoch [2160/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.705| gp_loss: 0.133| r_loss: 0.059| p_loss: 0.075| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.502
Train: Epoch [2160/3000], Step [60/158]| g_loss: 0.696| d_loss: 0.545| gp_loss: 0.060| r_loss: 0.056| p_loss: 0.074| v_loss: 0.021| per_loss: 0.292 | a_loss: 0.553
Train: Epoch [2160/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.640| gp_loss: 0.060| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.510
Train: Epoch [2160/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.637| gp_loss: 0.060| r_loss: 0.053| p_loss: 0.075| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.523
Train: Epoch [2160/3000], Step [150/158]| g_loss: 0.688| d_loss: 0.648| gp_loss: 0.062| r_loss: 0.054| p_loss: 0.077| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.545
Train: Epoch [2161/3000], Step [30/158]| g_loss: 0.685| d_loss: 0.727| gp_loss: 0.181| r_loss: 0.054| p_loss: 0.076| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.541
Train: Epoch [2161/3000], Step [60/158]| g_loss: 0.639| d_loss: 0.669| gp_loss: 0.055| r_loss: 0.054| p_loss: 0.074| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.497
Train: Epoch [2161/3000], Step [90/158]| g_loss: 0.651| d_loss: 0.652| gp_loss: 0.057| r_loss: 0.058| p_loss: 0.077| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.504
Train: Epoch [2161/3000], Step [120/158]| g_loss: 0.711| d_loss: 0.550| gp_loss: 0.060| r_loss: 0.052| p_loss: 0.073| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.571
Train: Epoch [2161/3000], Step [150/158]| g_loss: 0.712| d_loss: 0.531| gp_loss: 0.063| r_loss: 0.056| p_loss: 0.076| v_loss: 0.022| per_loss: 0.306 | a_loss: 0.566
Train: Epoch [2162/3000], Step [30/158]| g_loss: 0.630| d_loss: 0.795| gp_loss: 0.186| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.298 | a_loss: 0.488
Train: Epoch [2162/3000], Step [60/158]| g_loss: 0.640| d_loss: 0.607| gp_loss: 0.052| r_loss: 0.056| p_loss: 0.075| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.494
Train: Epoch [2162/3000], Step [90/158]| g_loss: 0.733| d_loss: 0.516| gp_loss: 0.057| r_loss: 0.054| p_loss: 0.070| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.593
Train: Epoch [2162/3000], Step [120/158]| g_loss: 0.697| d_loss: 0.652| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.072| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.558
Train: Epoch [2162/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.702| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.071| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.520
Train: Epoch [2163/3000], Step [30/158]| g_loss: 0.632| d_loss: 0.783| gp_loss: 0.104| r_loss: 0.056| p_loss: 0.075| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.488
Train: Epoch [2163/3000], Step [60/158]| g_loss: 0.623| d_loss: 0.561| gp_loss: 0.059| r_loss: 0.056| p_loss: 0.079| v_loss: 0.021| per_loss: 0.298 | a_loss: 0.477
Train: Epoch [2163/3000], Step [90/158]| g_loss: 0.668| d_loss: 0.594| gp_loss: 0.055| r_loss: 0.053| p_loss: 0.075| v_loss: 0.021| per_loss: 0.298 | a_loss: 0.526
Train: Epoch [2163/3000], Step [120/158]| g_loss: 0.708| d_loss: 0.567| gp_loss: 0.051| r_loss: 0.053| p_loss: 0.073| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.566
Train: Epoch [2163/3000], Step [150/158]| g_loss: 0.660| d_loss: 0.618| gp_loss: 0.059| r_loss: 0.052| p_loss: 0.072| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.520
Train: Epoch [2164/3000], Step [30/158]| g_loss: 0.660| d_loss: 0.775| gp_loss: 0.147| r_loss: 0.056| p_loss: 0.076| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.514
Train: Epoch [2164/3000], Step [60/158]| g_loss: 0.668| d_loss: 0.607| gp_loss: 0.051| r_loss: 0.053| p_loss: 0.074| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.527
Train: Epoch [2164/3000], Step [90/158]| g_loss: 0.708| d_loss: 0.561| gp_loss: 0.056| r_loss: 0.054| p_loss: 0.073| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.566
Train: Epoch [2164/3000], Step [120/158]| g_loss: 0.689| d_loss: 0.603| gp_loss: 0.056| r_loss: 0.054| p_loss: 0.071| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.549
Train: Epoch [2164/3000], Step [150/158]| g_loss: 0.647| d_loss: 0.664| gp_loss: 0.057| r_loss: 0.056| p_loss: 0.078| v_loss: 0.022| per_loss: 0.315 | a_loss: 0.498
Train: Epoch [2165/3000], Step [30/158]| g_loss: 0.645| d_loss: 0.671| gp_loss: 0.088| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.500
Train: Epoch [2165/3000], Step [60/158]| g_loss: 0.660| d_loss: 0.701| gp_loss: 0.058| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.293 | a_loss: 0.515
Train: Epoch [2165/3000], Step [90/158]| g_loss: 0.632| d_loss: 0.576| gp_loss: 0.061| r_loss: 0.052| p_loss: 0.074| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.491
Train: Epoch [2165/3000], Step [120/158]| g_loss: 0.673| d_loss: 0.648| gp_loss: 0.063| r_loss: 0.058| p_loss: 0.075| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.527
Train: Epoch [2165/3000], Step [150/158]| g_loss: 0.726| d_loss: 0.544| gp_loss: 0.061| r_loss: 0.055| p_loss: 0.075| v_loss: 0.022| per_loss: 0.303 | a_loss: 0.581
Train: Epoch [2166/3000], Step [30/158]| g_loss: 0.685| d_loss: 0.703| gp_loss: 0.158| r_loss: 0.054| p_loss: 0.074| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.543
Train: Epoch [2166/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.677| gp_loss: 0.055| r_loss: 0.053| p_loss: 0.072| v_loss: 0.020| per_loss: 0.307 | a_loss: 0.533
Train: Epoch [2166/3000], Step [90/158]| g_loss: 0.598| d_loss: 0.715| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.075| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.457
Train: Epoch [2166/3000], Step [120/158]| g_loss: 0.697| d_loss: 0.499| gp_loss: 0.065| r_loss: 0.053| p_loss: 0.074| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.554
Train: Epoch [2166/3000], Step [150/158]| g_loss: 0.737| d_loss: 0.570| gp_loss: 0.062| r_loss: 0.054| p_loss: 0.074| v_loss: 0.022| per_loss: 0.294 | a_loss: 0.595
Train: Epoch [2167/3000], Step [30/158]| g_loss: 0.684| d_loss: 0.705| gp_loss: 0.156| r_loss: 0.060| p_loss: 0.078| v_loss: 0.020| per_loss: 0.307 | a_loss: 0.534
Train: Epoch [2167/3000], Step [60/158]| g_loss: 0.637| d_loss: 0.705| gp_loss: 0.052| r_loss: 0.056| p_loss: 0.074| v_loss: 0.021| per_loss: 0.294 | a_loss: 0.494
Train: Epoch [2167/3000], Step [90/158]| g_loss: 0.652| d_loss: 0.571| gp_loss: 0.058| r_loss: 0.053| p_loss: 0.071| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.513
Train: Epoch [2167/3000], Step [120/158]| g_loss: 0.667| d_loss: 0.574| gp_loss: 0.058| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.322 | a_loss: 0.522
Train: Epoch [2167/3000], Step [150/158]| g_loss: 0.688| d_loss: 0.607| gp_loss: 0.059| r_loss: 0.053| p_loss: 0.072| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.548
Train: Epoch [2168/3000], Step [30/158]| g_loss: 0.653| d_loss: 0.752| gp_loss: 0.167| r_loss: 0.056| p_loss: 0.075| v_loss: 0.022| per_loss: 0.303 | a_loss: 0.508
Train: Epoch [2168/3000], Step [60/158]| g_loss: 0.697| d_loss: 0.682| gp_loss: 0.052| r_loss: 0.053| p_loss: 0.075| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.554
Train: Epoch [2168/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.577| gp_loss: 0.058| r_loss: 0.055| p_loss: 0.075| v_loss: 0.022| per_loss: 0.298 | a_loss: 0.511
Train: Epoch [2168/3000], Step [120/158]| g_loss: 0.675| d_loss: 0.593| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.072| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.536
Train: Epoch [2168/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.628| gp_loss: 0.061| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.512
Train: Epoch [2169/3000], Step [30/158]| g_loss: 0.636| d_loss: 0.799| gp_loss: 0.143| r_loss: 0.052| p_loss: 0.077| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.493
Train: Epoch [2169/3000], Step [60/158]| g_loss: 0.627| d_loss: 0.616| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.073| v_loss: 0.021| per_loss: 0.286 | a_loss: 0.487
Train: Epoch [2169/3000], Step [90/158]| g_loss: 0.667| d_loss: 0.565| gp_loss: 0.057| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.524
Train: Epoch [2169/3000], Step [120/158]| g_loss: 0.719| d_loss: 0.611| gp_loss: 0.060| r_loss: 0.057| p_loss: 0.078| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.569
Train: Epoch [2169/3000], Step [150/158]| g_loss: 0.666| d_loss: 0.632| gp_loss: 0.060| r_loss: 0.054| p_loss: 0.074| v_loss: 0.021| per_loss: 0.296 | a_loss: 0.524
Train: Epoch [2170/3000], Step [30/158]| g_loss: 0.698| d_loss: 0.670| gp_loss: 0.149| r_loss: 0.057| p_loss: 0.077| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.551
Train: Epoch [2170/3000], Step [60/158]| g_loss: 0.637| d_loss: 0.721| gp_loss: 0.053| r_loss: 0.055| p_loss: 0.075| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.494
Train: Epoch [2170/3000], Step [90/158]| g_loss: 0.656| d_loss: 0.577| gp_loss: 0.059| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.511
Train: Epoch [2170/3000], Step [120/158]| g_loss: 0.706| d_loss: 0.589| gp_loss: 0.061| r_loss: 0.055| p_loss: 0.078| v_loss: 0.022| per_loss: 0.299 | a_loss: 0.560
Train: Epoch [2170/3000], Step [150/158]| g_loss: 0.701| d_loss: 0.581| gp_loss: 0.060| r_loss: 0.055| p_loss: 0.074| v_loss: 0.021| per_loss: 0.316 | a_loss: 0.556
Train: Epoch [2171/3000], Step [30/158]| g_loss: 0.708| d_loss: 0.599| gp_loss: 0.156| r_loss: 0.058| p_loss: 0.075| v_loss: 0.021| per_loss: 0.295 | a_loss: 0.562
Train: Epoch [2171/3000], Step [60/158]| g_loss: 0.710| d_loss: 0.633| gp_loss: 0.054| r_loss: 0.063| p_loss: 0.079| v_loss: 0.021| per_loss: 0.294 | a_loss: 0.558
Train: Epoch [2171/3000], Step [90/158]| g_loss: 0.652| d_loss: 0.624| gp_loss: 0.052| r_loss: 0.056| p_loss: 0.081| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.503
Train: Epoch [2171/3000], Step [120/158]| g_loss: 0.641| d_loss: 0.726| gp_loss: 0.055| r_loss: 0.055| p_loss: 0.075| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.498
Train: Epoch [2171/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.618| gp_loss: 0.057| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.318 | a_loss: 0.514
Train: Epoch [2172/3000], Step [30/158]| g_loss: 0.675| d_loss: 0.711| gp_loss: 0.150| r_loss: 0.051| p_loss: 0.071| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.539
Train: Epoch [2172/3000], Step [60/158]| g_loss: 0.614| d_loss: 0.628| gp_loss: 0.051| r_loss: 0.052| p_loss: 0.072| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.476
Train: Epoch [2172/3000], Step [90/158]| g_loss: 0.680| d_loss: 0.581| gp_loss: 0.060| r_loss: 0.054| p_loss: 0.071| v_loss: 0.022| per_loss: 0.317 | a_loss: 0.536
Train: Epoch [2172/3000], Step [120/158]| g_loss: 0.691| d_loss: 0.563| gp_loss: 0.059| r_loss: 0.054| p_loss: 0.073| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.549
Train: Epoch [2172/3000], Step [150/158]| g_loss: 0.676| d_loss: 0.687| gp_loss: 0.059| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.529
Train: Epoch [2173/3000], Step [30/158]| g_loss: 0.676| d_loss: 0.682| gp_loss: 0.138| r_loss: 0.057| p_loss: 0.080| v_loss: 0.022| per_loss: 0.313 | a_loss: 0.526
Train: Epoch [2173/3000], Step [60/158]| g_loss: 0.699| d_loss: 0.597| gp_loss: 0.058| r_loss: 0.056| p_loss: 0.080| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.551
Train: Epoch [2173/3000], Step [90/158]| g_loss: 0.685| d_loss: 0.611| gp_loss: 0.054| r_loss: 0.055| p_loss: 0.073| v_loss: 0.021| per_loss: 0.317 | a_loss: 0.541
Train: Epoch [2173/3000], Step [120/158]| g_loss: 0.682| d_loss: 0.552| gp_loss: 0.059| r_loss: 0.054| p_loss: 0.072| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.542
Train: Epoch [2173/3000], Step [150/158]| g_loss: 0.648| d_loss: 0.658| gp_loss: 0.057| r_loss: 0.055| p_loss: 0.074| v_loss: 0.021| per_loss: 0.293 | a_loss: 0.506
Train: Epoch [2174/3000], Step [30/158]| g_loss: 0.669| d_loss: 0.746| gp_loss: 0.198| r_loss: 0.051| p_loss: 0.070| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.532
Train: Epoch [2174/3000], Step [60/158]| g_loss: 0.621| d_loss: 0.652| gp_loss: 0.053| r_loss: 0.052| p_loss: 0.072| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.481
Train: Epoch [2174/3000], Step [90/158]| g_loss: 0.707| d_loss: 0.609| gp_loss: 0.055| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.560
Train: Epoch [2174/3000], Step [120/158]| g_loss: 0.664| d_loss: 0.621| gp_loss: 0.054| r_loss: 0.053| p_loss: 0.072| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.523
Train: Epoch [2174/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.618| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.073| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.526
Train: Epoch [2175/3000], Step [30/158]| g_loss: 0.710| d_loss: 0.596| gp_loss: 0.143| r_loss: 0.054| p_loss: 0.072| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.567
Train: Epoch [2175/3000], Step [60/158]| g_loss: 0.686| d_loss: 0.608| gp_loss: 0.052| r_loss: 0.052| p_loss: 0.072| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.548
Train: Epoch [2175/3000], Step [90/158]| g_loss: 0.696| d_loss: 0.580| gp_loss: 0.052| r_loss: 0.053| p_loss: 0.074| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.555
Train: Epoch [2175/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.651| gp_loss: 0.053| r_loss: 0.055| p_loss: 0.075| v_loss: 0.022| per_loss: 0.312 | a_loss: 0.531
Train: Epoch [2175/3000], Step [150/158]| g_loss: 0.641| d_loss: 0.678| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.498
Train: Epoch [2176/3000], Step [30/158]| g_loss: 0.622| d_loss: 0.755| gp_loss: 0.170| r_loss: 0.055| p_loss: 0.076| v_loss: 0.022| per_loss: 0.311 | a_loss: 0.476
Train: Epoch [2176/3000], Step [60/158]| g_loss: 0.655| d_loss: 0.641| gp_loss: 0.052| r_loss: 0.052| p_loss: 0.074| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.515
Train: Epoch [2176/3000], Step [90/158]| g_loss: 0.639| d_loss: 0.648| gp_loss: 0.055| r_loss: 0.053| p_loss: 0.071| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.501
Train: Epoch [2176/3000], Step [120/158]| g_loss: 0.642| d_loss: 0.650| gp_loss: 0.058| r_loss: 0.053| p_loss: 0.071| v_loss: 0.021| per_loss: 0.294 | a_loss: 0.503
Train: Epoch [2176/3000], Step [150/158]| g_loss: 0.686| d_loss: 0.562| gp_loss: 0.058| r_loss: 0.053| p_loss: 0.072| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.546
Train: Epoch [2177/3000], Step [30/158]| g_loss: 0.701| d_loss: 0.634| gp_loss: 0.143| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.565
Train: Epoch [2177/3000], Step [60/158]| g_loss: 0.725| d_loss: 0.482| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.071| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.586
Train: Epoch [2177/3000], Step [90/158]| g_loss: 0.739| d_loss: 0.577| gp_loss: 0.052| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.594
Train: Epoch [2177/3000], Step [120/158]| g_loss: 0.644| d_loss: 0.683| gp_loss: 0.055| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.502
Train: Epoch [2177/3000], Step [150/158]| g_loss: 0.644| d_loss: 0.682| gp_loss: 0.057| r_loss: 0.055| p_loss: 0.078| v_loss: 0.021| per_loss: 0.298 | a_loss: 0.499
Train: Epoch [2178/3000], Step [30/158]| g_loss: 0.656| d_loss: 0.714| gp_loss: 0.142| r_loss: 0.058| p_loss: 0.084| v_loss: 0.022| per_loss: 0.305 | a_loss: 0.504
Train: Epoch [2178/3000], Step [60/158]| g_loss: 0.669| d_loss: 0.604| gp_loss: 0.060| r_loss: 0.056| p_loss: 0.082| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.521
Train: Epoch [2178/3000], Step [90/158]| g_loss: 0.656| d_loss: 0.636| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.510
Train: Epoch [2178/3000], Step [120/158]| g_loss: 0.701| d_loss: 0.584| gp_loss: 0.059| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.294 | a_loss: 0.558
Train: Epoch [2178/3000], Step [150/158]| g_loss: 0.694| d_loss: 0.632| gp_loss: 0.056| r_loss: 0.054| p_loss: 0.070| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.553
Train: Epoch [2179/3000], Step [30/158]| g_loss: 0.654| d_loss: 0.648| gp_loss: 0.136| r_loss: 0.055| p_loss: 0.074| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.510
Train: Epoch [2179/3000], Step [60/158]| g_loss: 0.662| d_loss: 0.637| gp_loss: 0.057| r_loss: 0.058| p_loss: 0.076| v_loss: 0.021| per_loss: 0.293 | a_loss: 0.515
Train: Epoch [2179/3000], Step [90/158]| g_loss: 0.681| d_loss: 0.575| gp_loss: 0.061| r_loss: 0.052| p_loss: 0.073| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.542
Train: Epoch [2179/3000], Step [120/158]| g_loss: 0.665| d_loss: 0.668| gp_loss: 0.057| r_loss: 0.054| p_loss: 0.076| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.521
Train: Epoch [2179/3000], Step [150/158]| g_loss: 0.690| d_loss: 0.616| gp_loss: 0.061| r_loss: 0.054| p_loss: 0.074| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.548
Train: Epoch [2180/3000], Step [30/158]| g_loss: 0.699| d_loss: 0.659| gp_loss: 0.173| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.296 | a_loss: 0.556
Train: Epoch [2180/3000], Step [60/158]| g_loss: 0.686| d_loss: 0.578| gp_loss: 0.054| r_loss: 0.057| p_loss: 0.076| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.539
Train: Epoch [2180/3000], Step [90/158]| g_loss: 0.689| d_loss: 0.575| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.070| v_loss: 0.021| per_loss: 0.296 | a_loss: 0.552
Train: Epoch [2180/3000], Step [120/158]| g_loss: 0.642| d_loss: 0.758| gp_loss: 0.058| r_loss: 0.054| p_loss: 0.076| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.501
Train: Epoch [2180/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.632| gp_loss: 0.057| r_loss: 0.053| p_loss: 0.075| v_loss: 0.021| per_loss: 0.324 | a_loss: 0.514
Train: Epoch [2181/3000], Step [30/158]| g_loss: 0.624| d_loss: 0.813| gp_loss: 0.240| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.296 | a_loss: 0.482
Train: Epoch [2181/3000], Step [60/158]| g_loss: 0.701| d_loss: 0.624| gp_loss: 0.050| r_loss: 0.054| p_loss: 0.074| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.559
Train: Epoch [2181/3000], Step [90/158]| g_loss: 0.699| d_loss: 0.535| gp_loss: 0.055| r_loss: 0.053| p_loss: 0.072| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.560
Train: Epoch [2181/3000], Step [120/158]| g_loss: 0.657| d_loss: 0.654| gp_loss: 0.051| r_loss: 0.052| p_loss: 0.071| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.518
Train: Epoch [2181/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.599| gp_loss: 0.053| r_loss: 0.054| p_loss: 0.072| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.518
Train: Epoch [2182/3000], Step [30/158]| g_loss: 0.644| d_loss: 0.767| gp_loss: 0.139| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.500
Train: Epoch [2182/3000], Step [60/158]| g_loss: 0.647| d_loss: 0.600| gp_loss: 0.051| r_loss: 0.054| p_loss: 0.073| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.505
Train: Epoch [2182/3000], Step [90/158]| g_loss: 0.681| d_loss: 0.528| gp_loss: 0.057| r_loss: 0.052| p_loss: 0.074| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.542
Train: Epoch [2182/3000], Step [120/158]| g_loss: 0.710| d_loss: 0.627| gp_loss: 0.050| r_loss: 0.052| p_loss: 0.073| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.570
Train: Epoch [2182/3000], Step [150/158]| g_loss: 0.711| d_loss: 0.596| gp_loss: 0.052| r_loss: 0.055| p_loss: 0.074| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.567
Train: Epoch [2183/3000], Step [30/158]| g_loss: 0.668| d_loss: 0.682| gp_loss: 0.164| r_loss: 0.052| p_loss: 0.072| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.531
Train: Epoch [2183/3000], Step [60/158]| g_loss: 0.642| d_loss: 0.689| gp_loss: 0.049| r_loss: 0.053| p_loss: 0.074| v_loss: 0.021| per_loss: 0.296 | a_loss: 0.501
Train: Epoch [2183/3000], Step [90/158]| g_loss: 0.673| d_loss: 0.581| gp_loss: 0.054| r_loss: 0.051| p_loss: 0.071| v_loss: 0.020| per_loss: 0.312 | a_loss: 0.535
Train: Epoch [2183/3000], Step [120/158]| g_loss: 0.695| d_loss: 0.583| gp_loss: 0.051| r_loss: 0.055| p_loss: 0.072| v_loss: 0.022| per_loss: 0.322 | a_loss: 0.550
Train: Epoch [2183/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.655| gp_loss: 0.055| r_loss: 0.054| p_loss: 0.074| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.534
Train: Epoch [2184/3000], Step [30/158]| g_loss: 0.619| d_loss: 0.711| gp_loss: 0.064| r_loss: 0.053| p_loss: 0.075| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.478
Train: Epoch [2184/3000], Step [60/158]| g_loss: 0.658| d_loss: 0.602| gp_loss: 0.060| r_loss: 0.054| p_loss: 0.076| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.514
Train: Epoch [2184/3000], Step [90/158]| g_loss: 0.672| d_loss: 0.589| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.318 | a_loss: 0.527
Train: Epoch [2184/3000], Step [120/158]| g_loss: 0.688| d_loss: 0.545| gp_loss: 0.060| r_loss: 0.055| p_loss: 0.074| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.547
Train: Epoch [2184/3000], Step [150/158]| g_loss: 0.644| d_loss: 0.670| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.071| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.506
Train: Epoch [2185/3000], Step [30/158]| g_loss: 0.646| d_loss: 0.799| gp_loss: 0.174| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.502
Train: Epoch [2185/3000], Step [60/158]| g_loss: 0.653| d_loss: 0.562| gp_loss: 0.060| r_loss: 0.052| p_loss: 0.072| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.513
Train: Epoch [2185/3000], Step [90/158]| g_loss: 0.693| d_loss: 0.629| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.546
Train: Epoch [2185/3000], Step [120/158]| g_loss: 0.639| d_loss: 0.682| gp_loss: 0.052| r_loss: 0.054| p_loss: 0.074| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.498
Train: Epoch [2185/3000], Step [150/158]| g_loss: 0.697| d_loss: 0.545| gp_loss: 0.059| r_loss: 0.054| p_loss: 0.074| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.556
Train: Epoch [2186/3000], Step [30/158]| g_loss: 0.682| d_loss: 0.706| gp_loss: 0.162| r_loss: 0.054| p_loss: 0.072| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.540
Train: Epoch [2186/3000], Step [60/158]| g_loss: 0.627| d_loss: 0.601| gp_loss: 0.050| r_loss: 0.054| p_loss: 0.075| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.485
Train: Epoch [2186/3000], Step [90/158]| g_loss: 0.703| d_loss: 0.632| gp_loss: 0.053| r_loss: 0.053| p_loss: 0.070| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.565
Train: Epoch [2186/3000], Step [120/158]| g_loss: 0.681| d_loss: 0.563| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.071| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.544
Train: Epoch [2186/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.610| gp_loss: 0.052| r_loss: 0.053| p_loss: 0.072| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.529
Train: Epoch [2187/3000], Step [30/158]| g_loss: 0.638| d_loss: 0.740| gp_loss: 0.153| r_loss: 0.056| p_loss: 0.077| v_loss: 0.022| per_loss: 0.299 | a_loss: 0.492
Train: Epoch [2187/3000], Step [60/158]| g_loss: 0.678| d_loss: 0.616| gp_loss: 0.051| r_loss: 0.049| p_loss: 0.068| v_loss: 0.020| per_loss: 0.319 | a_loss: 0.543
Train: Epoch [2187/3000], Step [90/158]| g_loss: 0.699| d_loss: 0.515| gp_loss: 0.052| r_loss: 0.054| p_loss: 0.072| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.559
Train: Epoch [2187/3000], Step [120/158]| g_loss: 0.674| d_loss: 0.605| gp_loss: 0.054| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.529
Train: Epoch [2187/3000], Step [150/158]| g_loss: 0.644| d_loss: 0.703| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.315 | a_loss: 0.505
Train: Epoch [2188/3000], Step [30/158]| g_loss: 0.677| d_loss: 0.684| gp_loss: 0.165| r_loss: 0.053| p_loss: 0.073| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.537
Train: Epoch [2188/3000], Step [60/158]| g_loss: 0.692| d_loss: 0.570| gp_loss: 0.051| r_loss: 0.052| p_loss: 0.071| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.552
Train: Epoch [2188/3000], Step [90/158]| g_loss: 0.676| d_loss: 0.619| gp_loss: 0.053| r_loss: 0.054| p_loss: 0.072| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.536
Train: Epoch [2188/3000], Step [120/158]| g_loss: 0.656| d_loss: 0.649| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.077| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.511
Train: Epoch [2188/3000], Step [150/158]| g_loss: 0.651| d_loss: 0.643| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.072| v_loss: 0.020| per_loss: 0.281 | a_loss: 0.513
Train: Epoch [2189/3000], Step [30/158]| g_loss: 0.631| d_loss: 0.731| gp_loss: 0.164| r_loss: 0.056| p_loss: 0.076| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.486
Train: Epoch [2189/3000], Step [60/158]| g_loss: 0.688| d_loss: 0.635| gp_loss: 0.051| r_loss: 0.055| p_loss: 0.074| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.548
Train: Epoch [2189/3000], Step [90/158]| g_loss: 0.625| d_loss: 0.643| gp_loss: 0.055| r_loss: 0.053| p_loss: 0.073| v_loss: 0.021| per_loss: 0.316 | a_loss: 0.483
Train: Epoch [2189/3000], Step [120/158]| g_loss: 0.638| d_loss: 0.638| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.075| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.492
Train: Epoch [2189/3000], Step [150/158]| g_loss: 0.704| d_loss: 0.579| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.078| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.559
Train: Epoch [2190/3000], Step [30/158]| g_loss: 0.665| d_loss: 0.695| gp_loss: 0.121| r_loss: 0.053| p_loss: 0.074| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.522
Train: Epoch [2190/3000], Step [60/158]| g_loss: 0.679| d_loss: 0.628| gp_loss: 0.052| r_loss: 0.056| p_loss: 0.076| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.535
Train: Epoch [2190/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.601| gp_loss: 0.052| r_loss: 0.058| p_loss: 0.079| v_loss: 0.021| per_loss: 0.294 | a_loss: 0.509
Train: Epoch [2190/3000], Step [120/158]| g_loss: 0.689| d_loss: 0.570| gp_loss: 0.054| r_loss: 0.055| p_loss: 0.076| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.544
Train: Epoch [2190/3000], Step [150/158]| g_loss: 0.682| d_loss: 0.623| gp_loss: 0.059| r_loss: 0.053| p_loss: 0.073| v_loss: 0.020| per_loss: 0.311 | a_loss: 0.541
Train: Epoch [2191/3000], Step [30/158]| g_loss: 0.684| d_loss: 0.657| gp_loss: 0.129| r_loss: 0.058| p_loss: 0.081| v_loss: 0.021| per_loss: 0.298 | a_loss: 0.535
Train: Epoch [2191/3000], Step [60/158]| g_loss: 0.649| d_loss: 0.672| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.076| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.508
Train: Epoch [2191/3000], Step [90/158]| g_loss: 0.710| d_loss: 0.579| gp_loss: 0.056| r_loss: 0.057| p_loss: 0.078| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.563
Train: Epoch [2191/3000], Step [120/158]| g_loss: 0.690| d_loss: 0.501| gp_loss: 0.059| r_loss: 0.058| p_loss: 0.081| v_loss: 0.022| per_loss: 0.310 | a_loss: 0.539
Train: Epoch [2191/3000], Step [150/158]| g_loss: 0.685| d_loss: 0.724| gp_loss: 0.057| r_loss: 0.054| p_loss: 0.076| v_loss: 0.021| per_loss: 0.287 | a_loss: 0.543
Train: Epoch [2192/3000], Step [30/158]| g_loss: 0.604| d_loss: 0.735| gp_loss: 0.107| r_loss: 0.054| p_loss: 0.074| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.463
Train: Epoch [2192/3000], Step [60/158]| g_loss: 0.625| d_loss: 0.603| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.488
Train: Epoch [2192/3000], Step [90/158]| g_loss: 0.712| d_loss: 0.636| gp_loss: 0.055| r_loss: 0.054| p_loss: 0.076| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.569
Train: Epoch [2192/3000], Step [120/158]| g_loss: 0.623| d_loss: 0.618| gp_loss: 0.059| r_loss: 0.053| p_loss: 0.071| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.483
Train: Epoch [2192/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.573| gp_loss: 0.062| r_loss: 0.053| p_loss: 0.070| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.527
Train: Epoch [2193/3000], Step [30/158]| g_loss: 0.687| d_loss: 0.663| gp_loss: 0.130| r_loss: 0.053| p_loss: 0.077| v_loss: 0.021| per_loss: 0.289 | a_loss: 0.546
Train: Epoch [2193/3000], Step [60/158]| g_loss: 0.708| d_loss: 0.571| gp_loss: 0.057| r_loss: 0.056| p_loss: 0.075| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.564
Train: Epoch [2193/3000], Step [90/158]| g_loss: 0.633| d_loss: 0.692| gp_loss: 0.058| r_loss: 0.053| p_loss: 0.074| v_loss: 0.021| per_loss: 0.273 | a_loss: 0.496
Train: Epoch [2193/3000], Step [120/158]| g_loss: 0.665| d_loss: 0.580| gp_loss: 0.063| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.520
Train: Epoch [2193/3000], Step [150/158]| g_loss: 0.708| d_loss: 0.621| gp_loss: 0.062| r_loss: 0.053| p_loss: 0.074| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.566
Train: Epoch [2194/3000], Step [30/158]| g_loss: 0.665| d_loss: 0.711| gp_loss: 0.176| r_loss: 0.054| p_loss: 0.076| v_loss: 0.021| per_loss: 0.322 | a_loss: 0.520
Train: Epoch [2194/3000], Step [60/158]| g_loss: 0.722| d_loss: 0.522| gp_loss: 0.053| r_loss: 0.053| p_loss: 0.072| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.583
Train: Epoch [2194/3000], Step [90/158]| g_loss: 0.705| d_loss: 0.567| gp_loss: 0.052| r_loss: 0.052| p_loss: 0.070| v_loss: 0.021| per_loss: 0.291 | a_loss: 0.568
Train: Epoch [2194/3000], Step [120/158]| g_loss: 0.655| d_loss: 0.693| gp_loss: 0.055| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.295 | a_loss: 0.513
Train: Epoch [2194/3000], Step [150/158]| g_loss: 0.642| d_loss: 0.636| gp_loss: 0.059| r_loss: 0.055| p_loss: 0.075| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.500
Train: Epoch [2195/3000], Step [30/158]| g_loss: 0.625| d_loss: 0.770| gp_loss: 0.090| r_loss: 0.063| p_loss: 0.084| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.468
Train: Epoch [2195/3000], Step [60/158]| g_loss: 0.631| d_loss: 0.599| gp_loss: 0.060| r_loss: 0.053| p_loss: 0.076| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.491
Train: Epoch [2195/3000], Step [90/158]| g_loss: 0.697| d_loss: 0.608| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.083| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.542
Train: Epoch [2195/3000], Step [120/158]| g_loss: 0.674| d_loss: 0.649| gp_loss: 0.060| r_loss: 0.054| p_loss: 0.076| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.533
Train: Epoch [2195/3000], Step [150/158]| g_loss: 0.673| d_loss: 0.570| gp_loss: 0.059| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.295 | a_loss: 0.529
Train: Epoch [2196/3000], Step [30/158]| g_loss: 0.667| d_loss: 0.760| gp_loss: 0.205| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.295 | a_loss: 0.525
Train: Epoch [2196/3000], Step [60/158]| g_loss: 0.651| d_loss: 0.560| gp_loss: 0.054| r_loss: 0.053| p_loss: 0.068| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.515
Train: Epoch [2196/3000], Step [90/158]| g_loss: 0.723| d_loss: 0.572| gp_loss: 0.056| r_loss: 0.053| p_loss: 0.069| v_loss: 0.021| per_loss: 0.292 | a_loss: 0.586
Train: Epoch [2196/3000], Step [120/158]| g_loss: 0.664| d_loss: 0.692| gp_loss: 0.055| r_loss: 0.055| p_loss: 0.073| v_loss: 0.021| per_loss: 0.294 | a_loss: 0.523
Train: Epoch [2196/3000], Step [150/158]| g_loss: 0.628| d_loss: 0.660| gp_loss: 0.059| r_loss: 0.053| p_loss: 0.074| v_loss: 0.021| per_loss: 0.298 | a_loss: 0.487
Train: Epoch [2197/3000], Step [30/158]| g_loss: 0.686| d_loss: 0.665| gp_loss: 0.105| r_loss: 0.056| p_loss: 0.080| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.541
Train: Epoch [2197/3000], Step [60/158]| g_loss: 0.662| d_loss: 0.621| gp_loss: 0.057| r_loss: 0.052| p_loss: 0.073| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.523
Train: Epoch [2197/3000], Step [90/158]| g_loss: 0.644| d_loss: 0.667| gp_loss: 0.057| r_loss: 0.054| p_loss: 0.078| v_loss: 0.021| per_loss: 0.298 | a_loss: 0.500
Train: Epoch [2197/3000], Step [120/158]| g_loss: 0.648| d_loss: 0.645| gp_loss: 0.061| r_loss: 0.056| p_loss: 0.079| v_loss: 0.022| per_loss: 0.308 | a_loss: 0.501
Train: Epoch [2197/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.525| gp_loss: 0.062| r_loss: 0.055| p_loss: 0.073| v_loss: 0.021| per_loss: 0.280 | a_loss: 0.534
Train: Epoch [2198/3000], Step [30/158]| g_loss: 0.702| d_loss: 0.669| gp_loss: 0.143| r_loss: 0.053| p_loss: 0.073| v_loss: 0.021| per_loss: 0.298 | a_loss: 0.562
Train: Epoch [2198/3000], Step [60/158]| g_loss: 0.634| d_loss: 0.638| gp_loss: 0.053| r_loss: 0.053| p_loss: 0.073| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.494
Train: Epoch [2198/3000], Step [90/158]| g_loss: 0.696| d_loss: 0.594| gp_loss: 0.056| r_loss: 0.053| p_loss: 0.073| v_loss: 0.021| per_loss: 0.290 | a_loss: 0.557
Train: Epoch [2198/3000], Step [120/158]| g_loss: 0.691| d_loss: 0.566| gp_loss: 0.061| r_loss: 0.052| p_loss: 0.069| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.555
Train: Epoch [2198/3000], Step [150/158]| g_loss: 0.633| d_loss: 0.701| gp_loss: 0.057| r_loss: 0.054| p_loss: 0.071| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.495
Train: Epoch [2199/3000], Step [30/158]| g_loss: 0.630| d_loss: 0.743| gp_loss: 0.166| r_loss: 0.051| p_loss: 0.072| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.491
Train: Epoch [2199/3000], Step [60/158]| g_loss: 0.650| d_loss: 0.624| gp_loss: 0.058| r_loss: 0.054| p_loss: 0.072| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.509
Train: Epoch [2199/3000], Step [90/158]| g_loss: 0.691| d_loss: 0.567| gp_loss: 0.058| r_loss: 0.056| p_loss: 0.072| v_loss: 0.021| per_loss: 0.291 | a_loss: 0.549
Train: Epoch [2199/3000], Step [120/158]| g_loss: 0.703| d_loss: 0.643| gp_loss: 0.059| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.286 | a_loss: 0.562
Train: Epoch [2199/3000], Step [150/158]| g_loss: 0.673| d_loss: 0.572| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.071| v_loss: 0.021| per_loss: 0.294 | a_loss: 0.536
Train: Epoch [2200/3000], Step [30/158]| g_loss: 0.625| d_loss: 0.840| gp_loss: 0.192| r_loss: 0.055| p_loss: 0.077| v_loss: 0.022| per_loss: 0.303 | a_loss: 0.479
Train: Epoch [2200/3000], Step [60/158]| g_loss: 0.643| d_loss: 0.756| gp_loss: 0.052| r_loss: 0.051| p_loss: 0.071| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.506
Train: Epoch [2200/3000], Step [90/158]| g_loss: 0.625| d_loss: 0.584| gp_loss: 0.056| r_loss: 0.053| p_loss: 0.075| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.484
Train: Epoch [2200/3000], Step [120/158]| g_loss: 0.652| d_loss: 0.599| gp_loss: 0.057| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.293 | a_loss: 0.511
Train: Epoch [2200/3000], Step [150/158]| g_loss: 0.685| d_loss: 0.524| gp_loss: 0.058| r_loss: 0.055| p_loss: 0.072| v_loss: 0.021| per_loss: 0.281 | a_loss: 0.545
Test: Epoch [2200/3000]| g_loss: 0.636| r_loss: 0.389| p_loss: 0.303| v_loss: 0.021
Train: Epoch [2201/3000], Step [30/158]| g_loss: 0.694| d_loss: 0.516| gp_loss: 0.054| r_loss: 0.053| p_loss: 0.069| v_loss: 0.021| per_loss: 0.283 | a_loss: 0.557
Train: Epoch [2201/3000], Step [60/158]| g_loss: 0.667| d_loss: 0.590| gp_loss: 0.051| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.532
Train: Epoch [2201/3000], Step [90/158]| g_loss: 0.701| d_loss: 0.568| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.066| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.568
Train: Epoch [2201/3000], Step [120/158]| g_loss: 0.662| d_loss: 0.660| gp_loss: 0.054| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.530
Train: Epoch [2201/3000], Step [150/158]| g_loss: 0.629| d_loss: 0.683| gp_loss: 0.056| r_loss: 0.053| p_loss: 0.069| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.492
Train: Epoch [2202/3000], Step [30/158]| g_loss: 0.651| d_loss: 0.700| gp_loss: 0.129| r_loss: 0.051| p_loss: 0.070| v_loss: 0.021| per_loss: 0.281 | a_loss: 0.515
Train: Epoch [2202/3000], Step [60/158]| g_loss: 0.648| d_loss: 0.613| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.515
Train: Epoch [2202/3000], Step [90/158]| g_loss: 0.672| d_loss: 0.596| gp_loss: 0.060| r_loss: 0.053| p_loss: 0.072| v_loss: 0.020| per_loss: 0.284 | a_loss: 0.534
Train: Epoch [2202/3000], Step [120/158]| g_loss: 0.684| d_loss: 0.674| gp_loss: 0.057| r_loss: 0.053| p_loss: 0.070| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.544
Train: Epoch [2202/3000], Step [150/158]| g_loss: 0.651| d_loss: 0.601| gp_loss: 0.058| r_loss: 0.054| p_loss: 0.074| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.511
Train: Epoch [2203/3000], Step [30/158]| g_loss: 0.657| d_loss: 0.766| gp_loss: 0.134| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.298 | a_loss: 0.513
Train: Epoch [2203/3000], Step [60/158]| g_loss: 0.641| d_loss: 0.655| gp_loss: 0.058| r_loss: 0.053| p_loss: 0.074| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.501
Train: Epoch [2203/3000], Step [90/158]| g_loss: 0.652| d_loss: 0.561| gp_loss: 0.060| r_loss: 0.053| p_loss: 0.071| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.514
Train: Epoch [2203/3000], Step [120/158]| g_loss: 0.676| d_loss: 0.721| gp_loss: 0.058| r_loss: 0.053| p_loss: 0.076| v_loss: 0.021| per_loss: 0.296 | a_loss: 0.534
Train: Epoch [2203/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.539| gp_loss: 0.057| r_loss: 0.054| p_loss: 0.073| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.519
Train: Epoch [2204/3000], Step [30/158]| g_loss: 0.693| d_loss: 0.743| gp_loss: 0.177| r_loss: 0.053| p_loss: 0.071| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.554
Train: Epoch [2204/3000], Step [60/158]| g_loss: 0.672| d_loss: 0.575| gp_loss: 0.049| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.538
Train: Epoch [2204/3000], Step [90/158]| g_loss: 0.645| d_loss: 0.724| gp_loss: 0.050| r_loss: 0.053| p_loss: 0.075| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.504
Train: Epoch [2204/3000], Step [120/158]| g_loss: 0.630| d_loss: 0.616| gp_loss: 0.055| r_loss: 0.054| p_loss: 0.073| v_loss: 0.021| per_loss: 0.287 | a_loss: 0.491
Train: Epoch [2204/3000], Step [150/158]| g_loss: 0.683| d_loss: 0.601| gp_loss: 0.055| r_loss: 0.054| p_loss: 0.072| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.544
Train: Epoch [2205/3000], Step [30/158]| g_loss: 0.693| d_loss: 0.661| gp_loss: 0.186| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.291 | a_loss: 0.549
Train: Epoch [2205/3000], Step [60/158]| g_loss: 0.651| d_loss: 0.722| gp_loss: 0.047| r_loss: 0.055| p_loss: 0.072| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.510
Train: Epoch [2205/3000], Step [90/158]| g_loss: 0.639| d_loss: 0.632| gp_loss: 0.052| r_loss: 0.054| p_loss: 0.072| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.500
Train: Epoch [2205/3000], Step [120/158]| g_loss: 0.669| d_loss: 0.609| gp_loss: 0.053| r_loss: 0.054| p_loss: 0.072| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.528
Train: Epoch [2205/3000], Step [150/158]| g_loss: 0.637| d_loss: 0.599| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.074| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.495
Train: Epoch [2206/3000], Step [30/158]| g_loss: 0.727| d_loss: 0.661| gp_loss: 0.139| r_loss: 0.062| p_loss: 0.084| v_loss: 0.021| per_loss: 0.316 | a_loss: 0.571
Train: Epoch [2206/3000], Step [60/158]| g_loss: 0.652| d_loss: 0.632| gp_loss: 0.050| r_loss: 0.058| p_loss: 0.077| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.507
Train: Epoch [2206/3000], Step [90/158]| g_loss: 0.674| d_loss: 0.639| gp_loss: 0.054| r_loss: 0.055| p_loss: 0.074| v_loss: 0.021| per_loss: 0.282 | a_loss: 0.534
Train: Epoch [2206/3000], Step [120/158]| g_loss: 0.691| d_loss: 0.582| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.296 | a_loss: 0.547
Train: Epoch [2206/3000], Step [150/158]| g_loss: 0.654| d_loss: 0.586| gp_loss: 0.056| r_loss: 0.054| p_loss: 0.074| v_loss: 0.021| per_loss: 0.289 | a_loss: 0.513
Train: Epoch [2207/3000], Step [30/158]| g_loss: 0.654| d_loss: 0.756| gp_loss: 0.172| r_loss: 0.056| p_loss: 0.076| v_loss: 0.021| per_loss: 0.294 | a_loss: 0.510
Train: Epoch [2207/3000], Step [60/158]| g_loss: 0.717| d_loss: 0.535| gp_loss: 0.052| r_loss: 0.053| p_loss: 0.074| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.576
Train: Epoch [2207/3000], Step [90/158]| g_loss: 0.673| d_loss: 0.661| gp_loss: 0.053| r_loss: 0.055| p_loss: 0.074| v_loss: 0.021| per_loss: 0.285 | a_loss: 0.532
Train: Epoch [2207/3000], Step [120/158]| g_loss: 0.658| d_loss: 0.610| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.072| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.523
Train: Epoch [2207/3000], Step [150/158]| g_loss: 0.668| d_loss: 0.569| gp_loss: 0.054| r_loss: 0.053| p_loss: 0.070| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.530
Train: Epoch [2208/3000], Step [30/158]| g_loss: 0.669| d_loss: 0.755| gp_loss: 0.203| r_loss: 0.053| p_loss: 0.071| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.531
Train: Epoch [2208/3000], Step [60/158]| g_loss: 0.660| d_loss: 0.731| gp_loss: 0.046| r_loss: 0.052| p_loss: 0.072| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.523
Train: Epoch [2208/3000], Step [90/158]| g_loss: 0.665| d_loss: 0.621| gp_loss: 0.052| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.291 | a_loss: 0.524
Train: Epoch [2208/3000], Step [120/158]| g_loss: 0.646| d_loss: 0.549| gp_loss: 0.052| r_loss: 0.052| p_loss: 0.068| v_loss: 0.021| per_loss: 0.290 | a_loss: 0.510
Train: Epoch [2208/3000], Step [150/158]| g_loss: 0.654| d_loss: 0.655| gp_loss: 0.050| r_loss: 0.050| p_loss: 0.070| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.519
Train: Epoch [2209/3000], Step [30/158]| g_loss: 0.612| d_loss: 0.731| gp_loss: 0.103| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.284 | a_loss: 0.478
Train: Epoch [2209/3000], Step [60/158]| g_loss: 0.678| d_loss: 0.553| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.069| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.544
Train: Epoch [2209/3000], Step [90/158]| g_loss: 0.677| d_loss: 0.567| gp_loss: 0.054| r_loss: 0.055| p_loss: 0.071| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.535
Train: Epoch [2209/3000], Step [120/158]| g_loss: 0.693| d_loss: 0.635| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.074| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.552
Train: Epoch [2209/3000], Step [150/158]| g_loss: 0.646| d_loss: 0.714| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.072| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.509
Train: Epoch [2210/3000], Step [30/158]| g_loss: 0.672| d_loss: 0.667| gp_loss: 0.148| r_loss: 0.055| p_loss: 0.073| v_loss: 0.021| per_loss: 0.294 | a_loss: 0.530
Train: Epoch [2210/3000], Step [60/158]| g_loss: 0.661| d_loss: 0.564| gp_loss: 0.053| r_loss: 0.052| p_loss: 0.069| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.526
Train: Epoch [2210/3000], Step [90/158]| g_loss: 0.685| d_loss: 0.665| gp_loss: 0.052| r_loss: 0.052| p_loss: 0.068| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.550
Train: Epoch [2210/3000], Step [120/158]| g_loss: 0.664| d_loss: 0.571| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.528
Train: Epoch [2210/3000], Step [150/158]| g_loss: 0.667| d_loss: 0.636| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.069| v_loss: 0.021| per_loss: 0.283 | a_loss: 0.531
Train: Epoch [2211/3000], Step [30/158]| g_loss: 0.628| d_loss: 0.703| gp_loss: 0.165| r_loss: 0.054| p_loss: 0.072| v_loss: 0.021| per_loss: 0.284 | a_loss: 0.488
Train: Epoch [2211/3000], Step [60/158]| g_loss: 0.671| d_loss: 0.598| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.070| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.534
Train: Epoch [2211/3000], Step [90/158]| g_loss: 0.645| d_loss: 0.716| gp_loss: 0.051| r_loss: 0.051| p_loss: 0.071| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.508
Train: Epoch [2211/3000], Step [120/158]| g_loss: 0.644| d_loss: 0.667| gp_loss: 0.055| r_loss: 0.053| p_loss: 0.074| v_loss: 0.021| per_loss: 0.289 | a_loss: 0.505
Train: Epoch [2211/3000], Step [150/158]| g_loss: 0.703| d_loss: 0.517| gp_loss: 0.054| r_loss: 0.051| p_loss: 0.069| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.566
Train: Epoch [2212/3000], Step [30/158]| g_loss: 0.628| d_loss: 0.869| gp_loss: 0.162| r_loss: 0.055| p_loss: 0.078| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.484
Train: Epoch [2212/3000], Step [60/158]| g_loss: 0.635| d_loss: 0.623| gp_loss: 0.056| r_loss: 0.053| p_loss: 0.074| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.494
Train: Epoch [2212/3000], Step [90/158]| g_loss: 0.661| d_loss: 0.617| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.075| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.517
Train: Epoch [2212/3000], Step [120/158]| g_loss: 0.676| d_loss: 0.607| gp_loss: 0.052| r_loss: 0.053| p_loss: 0.070| v_loss: 0.020| per_loss: 0.272 | a_loss: 0.541
Train: Epoch [2212/3000], Step [150/158]| g_loss: 0.695| d_loss: 0.533| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.069| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.557
Train: Epoch [2213/3000], Step [30/158]| g_loss: 0.703| d_loss: 0.667| gp_loss: 0.156| r_loss: 0.053| p_loss: 0.071| v_loss: 0.020| per_loss: 0.282 | a_loss: 0.566
Train: Epoch [2213/3000], Step [60/158]| g_loss: 0.671| d_loss: 0.647| gp_loss: 0.050| r_loss: 0.053| p_loss: 0.071| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.533
Train: Epoch [2213/3000], Step [90/158]| g_loss: 0.643| d_loss: 0.584| gp_loss: 0.054| r_loss: 0.053| p_loss: 0.070| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.504
Train: Epoch [2213/3000], Step [120/158]| g_loss: 0.651| d_loss: 0.641| gp_loss: 0.055| r_loss: 0.053| p_loss: 0.074| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.510
Train: Epoch [2213/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.565| gp_loss: 0.058| r_loss: 0.053| p_loss: 0.073| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.525
Train: Epoch [2214/3000], Step [30/158]| g_loss: 0.683| d_loss: 0.654| gp_loss: 0.133| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.547
Train: Epoch [2214/3000], Step [60/158]| g_loss: 0.689| d_loss: 0.577| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.069| v_loss: 0.020| per_loss: 0.278 | a_loss: 0.553
Train: Epoch [2214/3000], Step [90/158]| g_loss: 0.712| d_loss: 0.619| gp_loss: 0.055| r_loss: 0.053| p_loss: 0.072| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.574
Train: Epoch [2214/3000], Step [120/158]| g_loss: 0.627| d_loss: 0.655| gp_loss: 0.052| r_loss: 0.053| p_loss: 0.076| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.486
Train: Epoch [2214/3000], Step [150/158]| g_loss: 0.712| d_loss: 0.589| gp_loss: 0.058| r_loss: 0.055| p_loss: 0.075| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.568
Train: Epoch [2215/3000], Step [30/158]| g_loss: 0.645| d_loss: 0.705| gp_loss: 0.124| r_loss: 0.052| p_loss: 0.070| v_loss: 0.020| per_loss: 0.311 | a_loss: 0.507
Train: Epoch [2215/3000], Step [60/158]| g_loss: 0.624| d_loss: 0.672| gp_loss: 0.054| r_loss: 0.051| p_loss: 0.069| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.492
Train: Epoch [2215/3000], Step [90/158]| g_loss: 0.641| d_loss: 0.614| gp_loss: 0.055| r_loss: 0.053| p_loss: 0.070| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.503
Train: Epoch [2215/3000], Step [120/158]| g_loss: 0.662| d_loss: 0.658| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.072| v_loss: 0.020| per_loss: 0.314 | a_loss: 0.523
Train: Epoch [2215/3000], Step [150/158]| g_loss: 0.673| d_loss: 0.518| gp_loss: 0.057| r_loss: 0.053| p_loss: 0.069| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.537
Train: Epoch [2216/3000], Step [30/158]| g_loss: 0.665| d_loss: 0.811| gp_loss: 0.202| r_loss: 0.053| p_loss: 0.071| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.527
Train: Epoch [2216/3000], Step [60/158]| g_loss: 0.655| d_loss: 0.630| gp_loss: 0.047| r_loss: 0.053| p_loss: 0.076| v_loss: 0.021| per_loss: 0.292 | a_loss: 0.513
Train: Epoch [2216/3000], Step [90/158]| g_loss: 0.672| d_loss: 0.596| gp_loss: 0.050| r_loss: 0.050| p_loss: 0.069| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.538
Train: Epoch [2216/3000], Step [120/158]| g_loss: 0.707| d_loss: 0.603| gp_loss: 0.051| r_loss: 0.054| p_loss: 0.071| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.566
Train: Epoch [2216/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.633| gp_loss: 0.051| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.524
Train: Epoch [2217/3000], Step [30/158]| g_loss: 0.646| d_loss: 0.700| gp_loss: 0.096| r_loss: 0.052| p_loss: 0.074| v_loss: 0.021| per_loss: 0.292 | a_loss: 0.507
Train: Epoch [2217/3000], Step [60/158]| g_loss: 0.639| d_loss: 0.612| gp_loss: 0.055| r_loss: 0.054| p_loss: 0.073| v_loss: 0.021| per_loss: 0.293 | a_loss: 0.498
Train: Epoch [2217/3000], Step [90/158]| g_loss: 0.670| d_loss: 0.606| gp_loss: 0.055| r_loss: 0.054| p_loss: 0.073| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.531
Train: Epoch [2217/3000], Step [120/158]| g_loss: 0.664| d_loss: 0.682| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.070| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.529
Train: Epoch [2217/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.495| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.529
Train: Epoch [2218/3000], Step [30/158]| g_loss: 0.714| d_loss: 0.634| gp_loss: 0.135| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.577
Train: Epoch [2218/3000], Step [60/158]| g_loss: 0.686| d_loss: 0.617| gp_loss: 0.050| r_loss: 0.054| p_loss: 0.069| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.548
Train: Epoch [2218/3000], Step [90/158]| g_loss: 0.648| d_loss: 0.636| gp_loss: 0.052| r_loss: 0.054| p_loss: 0.070| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.510
Train: Epoch [2218/3000], Step [120/158]| g_loss: 0.686| d_loss: 0.599| gp_loss: 0.054| r_loss: 0.055| p_loss: 0.075| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.543
Train: Epoch [2218/3000], Step [150/158]| g_loss: 0.677| d_loss: 0.659| gp_loss: 0.057| r_loss: 0.060| p_loss: 0.085| v_loss: 0.021| per_loss: 0.296 | a_loss: 0.525
Train: Epoch [2219/3000], Step [30/158]| g_loss: 0.640| d_loss: 0.804| gp_loss: 0.121| r_loss: 0.068| p_loss: 0.104| v_loss: 0.021| per_loss: 0.323 | a_loss: 0.467
Train: Epoch [2219/3000], Step [60/158]| g_loss: 0.653| d_loss: 0.635| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.087| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.497
Train: Epoch [2219/3000], Step [90/158]| g_loss: 0.655| d_loss: 0.583| gp_loss: 0.057| r_loss: 0.059| p_loss: 0.081| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.507
Train: Epoch [2219/3000], Step [120/158]| g_loss: 0.684| d_loss: 0.532| gp_loss: 0.061| r_loss: 0.060| p_loss: 0.078| v_loss: 0.021| per_loss: 0.289 | a_loss: 0.536
Train: Epoch [2219/3000], Step [150/158]| g_loss: 0.685| d_loss: 0.616| gp_loss: 0.056| r_loss: 0.061| p_loss: 0.089| v_loss: 0.021| per_loss: 0.293 | a_loss: 0.530
Train: Epoch [2220/3000], Step [30/158]| g_loss: 0.700| d_loss: 0.661| gp_loss: 0.093| r_loss: 0.062| p_loss: 0.090| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.540
Train: Epoch [2220/3000], Step [60/158]| g_loss: 0.696| d_loss: 0.658| gp_loss: 0.057| r_loss: 0.058| p_loss: 0.083| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.545
Train: Epoch [2220/3000], Step [90/158]| g_loss: 0.677| d_loss: 0.609| gp_loss: 0.059| r_loss: 0.053| p_loss: 0.075| v_loss: 0.021| per_loss: 0.313 | a_loss: 0.534
Train: Epoch [2220/3000], Step [120/158]| g_loss: 0.605| d_loss: 0.763| gp_loss: 0.058| r_loss: 0.054| p_loss: 0.077| v_loss: 0.021| per_loss: 0.290 | a_loss: 0.464
Train: Epoch [2220/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.518| gp_loss: 0.065| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.285 | a_loss: 0.531
Train: Epoch [2221/3000], Step [30/158]| g_loss: 0.697| d_loss: 0.702| gp_loss: 0.157| r_loss: 0.054| p_loss: 0.074| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.554
Train: Epoch [2221/3000], Step [60/158]| g_loss: 0.636| d_loss: 0.681| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.076| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.492
Train: Epoch [2221/3000], Step [90/158]| g_loss: 0.679| d_loss: 0.545| gp_loss: 0.058| r_loss: 0.053| p_loss: 0.072| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.540
Train: Epoch [2221/3000], Step [120/158]| g_loss: 0.671| d_loss: 0.666| gp_loss: 0.058| r_loss: 0.054| p_loss: 0.074| v_loss: 0.021| per_loss: 0.289 | a_loss: 0.531
Train: Epoch [2221/3000], Step [150/158]| g_loss: 0.677| d_loss: 0.590| gp_loss: 0.059| r_loss: 0.051| p_loss: 0.071| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.541
Train: Epoch [2222/3000], Step [30/158]| g_loss: 0.651| d_loss: 0.745| gp_loss: 0.189| r_loss: 0.052| p_loss: 0.069| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.514
Train: Epoch [2222/3000], Step [60/158]| g_loss: 0.623| d_loss: 0.700| gp_loss: 0.053| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.280 | a_loss: 0.487
Train: Epoch [2222/3000], Step [90/158]| g_loss: 0.642| d_loss: 0.596| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.069| v_loss: 0.021| per_loss: 0.295 | a_loss: 0.505
Train: Epoch [2222/3000], Step [120/158]| g_loss: 0.682| d_loss: 0.606| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.068| v_loss: 0.021| per_loss: 0.308 | a_loss: 0.546
Train: Epoch [2222/3000], Step [150/158]| g_loss: 0.690| d_loss: 0.576| gp_loss: 0.060| r_loss: 0.053| p_loss: 0.071| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.553
Train: Epoch [2223/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.764| gp_loss: 0.180| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.519
Train: Epoch [2223/3000], Step [60/158]| g_loss: 0.618| d_loss: 0.732| gp_loss: 0.049| r_loss: 0.055| p_loss: 0.073| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.477
Train: Epoch [2223/3000], Step [90/158]| g_loss: 0.684| d_loss: 0.565| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.549
Train: Epoch [2223/3000], Step [120/158]| g_loss: 0.681| d_loss: 0.612| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.071| v_loss: 0.020| per_loss: 0.277 | a_loss: 0.547
Train: Epoch [2223/3000], Step [150/158]| g_loss: 0.655| d_loss: 0.542| gp_loss: 0.052| r_loss: 0.051| p_loss: 0.069| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.518
Train: Epoch [2224/3000], Step [30/158]| g_loss: 0.629| d_loss: 0.870| gp_loss: 0.201| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.495
Train: Epoch [2224/3000], Step [60/158]| g_loss: 0.662| d_loss: 0.550| gp_loss: 0.048| r_loss: 0.052| p_loss: 0.069| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.525
Train: Epoch [2224/3000], Step [90/158]| g_loss: 0.651| d_loss: 0.608| gp_loss: 0.048| r_loss: 0.051| p_loss: 0.068| v_loss: 0.021| per_loss: 0.287 | a_loss: 0.516
Train: Epoch [2224/3000], Step [120/158]| g_loss: 0.718| d_loss: 0.627| gp_loss: 0.052| r_loss: 0.052| p_loss: 0.070| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.582
Train: Epoch [2224/3000], Step [150/158]| g_loss: 0.646| d_loss: 0.576| gp_loss: 0.052| r_loss: 0.052| p_loss: 0.069| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.511
Train: Epoch [2225/3000], Step [30/158]| g_loss: 0.630| d_loss: 0.730| gp_loss: 0.096| r_loss: 0.052| p_loss: 0.070| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.493
Train: Epoch [2225/3000], Step [60/158]| g_loss: 0.623| d_loss: 0.616| gp_loss: 0.053| r_loss: 0.052| p_loss: 0.069| v_loss: 0.020| per_loss: 0.281 | a_loss: 0.489
Train: Epoch [2225/3000], Step [90/158]| g_loss: 0.651| d_loss: 0.624| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.518
Train: Epoch [2225/3000], Step [120/158]| g_loss: 0.657| d_loss: 0.590| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.070| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.522
Train: Epoch [2225/3000], Step [150/158]| g_loss: 0.715| d_loss: 0.518| gp_loss: 0.061| r_loss: 0.052| p_loss: 0.069| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.578
Train: Epoch [2226/3000], Step [30/158]| g_loss: 0.692| d_loss: 0.672| gp_loss: 0.096| r_loss: 0.050| p_loss: 0.069| v_loss: 0.020| per_loss: 0.314 | a_loss: 0.556
Train: Epoch [2226/3000], Step [60/158]| g_loss: 0.624| d_loss: 0.666| gp_loss: 0.058| r_loss: 0.053| p_loss: 0.072| v_loss: 0.020| per_loss: 0.279 | a_loss: 0.487
Train: Epoch [2226/3000], Step [90/158]| g_loss: 0.648| d_loss: 0.596| gp_loss: 0.059| r_loss: 0.052| p_loss: 0.072| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.510
Train: Epoch [2226/3000], Step [120/158]| g_loss: 0.675| d_loss: 0.633| gp_loss: 0.061| r_loss: 0.054| p_loss: 0.069| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.535
Train: Epoch [2226/3000], Step [150/158]| g_loss: 0.657| d_loss: 0.631| gp_loss: 0.057| r_loss: 0.052| p_loss: 0.071| v_loss: 0.021| per_loss: 0.291 | a_loss: 0.519
Train: Epoch [2227/3000], Step [30/158]| g_loss: 0.658| d_loss: 0.739| gp_loss: 0.180| r_loss: 0.051| p_loss: 0.072| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.521
Train: Epoch [2227/3000], Step [60/158]| g_loss: 0.679| d_loss: 0.614| gp_loss: 0.053| r_loss: 0.054| p_loss: 0.071| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.539
Train: Epoch [2227/3000], Step [90/158]| g_loss: 0.643| d_loss: 0.648| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.512
Train: Epoch [2227/3000], Step [120/158]| g_loss: 0.622| d_loss: 0.665| gp_loss: 0.056| r_loss: 0.053| p_loss: 0.070| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.485
Train: Epoch [2227/3000], Step [150/158]| g_loss: 0.683| d_loss: 0.557| gp_loss: 0.062| r_loss: 0.053| p_loss: 0.070| v_loss: 0.021| per_loss: 0.305 | a_loss: 0.544
Train: Epoch [2228/3000], Step [30/158]| g_loss: 0.683| d_loss: 0.730| gp_loss: 0.190| r_loss: 0.053| p_loss: 0.071| v_loss: 0.021| per_loss: 0.291 | a_loss: 0.545
Train: Epoch [2228/3000], Step [60/158]| g_loss: 0.662| d_loss: 0.720| gp_loss: 0.052| r_loss: 0.057| p_loss: 0.076| v_loss: 0.021| per_loss: 0.289 | a_loss: 0.517
Train: Epoch [2228/3000], Step [90/158]| g_loss: 0.632| d_loss: 0.585| gp_loss: 0.054| r_loss: 0.051| p_loss: 0.071| v_loss: 0.020| per_loss: 0.309 | a_loss: 0.495
Train: Epoch [2228/3000], Step [120/158]| g_loss: 0.672| d_loss: 0.566| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.069| v_loss: 0.021| per_loss: 0.310 | a_loss: 0.534
Train: Epoch [2228/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.573| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.070| v_loss: 0.020| per_loss: 0.282 | a_loss: 0.527
Train: Epoch [2229/3000], Step [30/158]| g_loss: 0.691| d_loss: 0.737| gp_loss: 0.155| r_loss: 0.051| p_loss: 0.070| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.556
Train: Epoch [2229/3000], Step [60/158]| g_loss: 0.645| d_loss: 0.649| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.071| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.506
Train: Epoch [2229/3000], Step [90/158]| g_loss: 0.643| d_loss: 0.628| gp_loss: 0.055| r_loss: 0.053| p_loss: 0.074| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.503
Train: Epoch [2229/3000], Step [120/158]| g_loss: 0.667| d_loss: 0.551| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.074| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.523
Train: Epoch [2229/3000], Step [150/158]| g_loss: 0.713| d_loss: 0.603| gp_loss: 0.055| r_loss: 0.053| p_loss: 0.071| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.574
Train: Epoch [2230/3000], Step [30/158]| g_loss: 0.694| d_loss: 0.653| gp_loss: 0.155| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.561
Train: Epoch [2230/3000], Step [60/158]| g_loss: 0.647| d_loss: 0.671| gp_loss: 0.051| r_loss: 0.053| p_loss: 0.069| v_loss: 0.021| per_loss: 0.295 | a_loss: 0.509
Train: Epoch [2230/3000], Step [90/158]| g_loss: 0.629| d_loss: 0.668| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.073| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.489
Train: Epoch [2230/3000], Step [120/158]| g_loss: 0.633| d_loss: 0.595| gp_loss: 0.057| r_loss: 0.052| p_loss: 0.070| v_loss: 0.020| per_loss: 0.283 | a_loss: 0.498
Train: Epoch [2230/3000], Step [150/158]| g_loss: 0.668| d_loss: 0.592| gp_loss: 0.057| r_loss: 0.054| p_loss: 0.073| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.526
Train: Epoch [2231/3000], Step [30/158]| g_loss: 0.682| d_loss: 0.666| gp_loss: 0.110| r_loss: 0.052| p_loss: 0.073| v_loss: 0.021| per_loss: 0.288 | a_loss: 0.543
Train: Epoch [2231/3000], Step [60/158]| g_loss: 0.639| d_loss: 0.689| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.072| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.499
Train: Epoch [2231/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.604| gp_loss: 0.058| r_loss: 0.054| p_loss: 0.073| v_loss: 0.021| per_loss: 0.292 | a_loss: 0.513
Train: Epoch [2231/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.609| gp_loss: 0.058| r_loss: 0.054| p_loss: 0.074| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.527
Train: Epoch [2231/3000], Step [150/158]| g_loss: 0.687| d_loss: 0.554| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.070| v_loss: 0.020| per_loss: 0.281 | a_loss: 0.552
Train: Epoch [2232/3000], Step [30/158]| g_loss: 0.646| d_loss: 0.694| gp_loss: 0.104| r_loss: 0.054| p_loss: 0.077| v_loss: 0.021| per_loss: 0.312 | a_loss: 0.501
Train: Epoch [2232/3000], Step [60/158]| g_loss: 0.677| d_loss: 0.602| gp_loss: 0.055| r_loss: 0.055| p_loss: 0.073| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.537
Train: Epoch [2232/3000], Step [90/158]| g_loss: 0.694| d_loss: 0.518| gp_loss: 0.061| r_loss: 0.050| p_loss: 0.068| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.561
Train: Epoch [2232/3000], Step [120/158]| g_loss: 0.729| d_loss: 0.565| gp_loss: 0.060| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.595
Train: Epoch [2232/3000], Step [150/158]| g_loss: 0.627| d_loss: 0.725| gp_loss: 0.057| r_loss: 0.054| p_loss: 0.074| v_loss: 0.021| per_loss: 0.294 | a_loss: 0.486
Train: Epoch [2233/3000], Step [30/158]| g_loss: 0.620| d_loss: 0.783| gp_loss: 0.202| r_loss: 0.053| p_loss: 0.073| v_loss: 0.020| per_loss: 0.277 | a_loss: 0.483
Train: Epoch [2233/3000], Step [60/158]| g_loss: 0.710| d_loss: 0.548| gp_loss: 0.056| r_loss: 0.053| p_loss: 0.071| v_loss: 0.021| per_loss: 0.300 | a_loss: 0.570
Train: Epoch [2233/3000], Step [90/158]| g_loss: 0.678| d_loss: 0.581| gp_loss: 0.061| r_loss: 0.050| p_loss: 0.069| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.543
Train: Epoch [2233/3000], Step [120/158]| g_loss: 0.637| d_loss: 0.705| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.069| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.503
Train: Epoch [2233/3000], Step [150/158]| g_loss: 0.635| d_loss: 0.585| gp_loss: 0.059| r_loss: 0.053| p_loss: 0.069| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.497
Train: Epoch [2234/3000], Step [30/158]| g_loss: 0.659| d_loss: 0.733| gp_loss: 0.166| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.529
Train: Epoch [2234/3000], Step [60/158]| g_loss: 0.639| d_loss: 0.678| gp_loss: 0.051| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.505
Train: Epoch [2234/3000], Step [90/158]| g_loss: 0.663| d_loss: 0.639| gp_loss: 0.054| r_loss: 0.053| p_loss: 0.070| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.526
Train: Epoch [2234/3000], Step [120/158]| g_loss: 0.616| d_loss: 0.620| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.073| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.477
Train: Epoch [2234/3000], Step [150/158]| g_loss: 0.689| d_loss: 0.585| gp_loss: 0.058| r_loss: 0.053| p_loss: 0.075| v_loss: 0.021| per_loss: 0.294 | a_loss: 0.548
Train: Epoch [2235/3000], Step [30/158]| g_loss: 0.712| d_loss: 0.582| gp_loss: 0.151| r_loss: 0.053| p_loss: 0.069| v_loss: 0.021| per_loss: 0.288 | a_loss: 0.575
Train: Epoch [2235/3000], Step [60/158]| g_loss: 0.662| d_loss: 0.665| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.070| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.528
Train: Epoch [2235/3000], Step [90/158]| g_loss: 0.675| d_loss: 0.595| gp_loss: 0.053| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.538
Train: Epoch [2235/3000], Step [120/158]| g_loss: 0.694| d_loss: 0.622| gp_loss: 0.055| r_loss: 0.055| p_loss: 0.072| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.553
Train: Epoch [2235/3000], Step [150/158]| g_loss: 0.633| d_loss: 0.699| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.073| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.495
Train: Epoch [2236/3000], Step [30/158]| g_loss: 0.638| d_loss: 0.761| gp_loss: 0.153| r_loss: 0.054| p_loss: 0.074| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.497
Train: Epoch [2236/3000], Step [60/158]| g_loss: 0.625| d_loss: 0.598| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.070| v_loss: 0.021| per_loss: 0.304 | a_loss: 0.489
Train: Epoch [2236/3000], Step [90/158]| g_loss: 0.660| d_loss: 0.605| gp_loss: 0.057| r_loss: 0.055| p_loss: 0.074| v_loss: 0.022| per_loss: 0.285 | a_loss: 0.519
Train: Epoch [2236/3000], Step [120/158]| g_loss: 0.663| d_loss: 0.587| gp_loss: 0.053| r_loss: 0.052| p_loss: 0.074| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.523
Train: Epoch [2236/3000], Step [150/158]| g_loss: 0.676| d_loss: 0.619| gp_loss: 0.059| r_loss: 0.053| p_loss: 0.071| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.538
Train: Epoch [2237/3000], Step [30/158]| g_loss: 0.673| d_loss: 0.671| gp_loss: 0.092| r_loss: 0.054| p_loss: 0.078| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.531
Train: Epoch [2237/3000], Step [60/158]| g_loss: 0.675| d_loss: 0.610| gp_loss: 0.055| r_loss: 0.057| p_loss: 0.078| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.528
Train: Epoch [2237/3000], Step [90/158]| g_loss: 0.667| d_loss: 0.616| gp_loss: 0.060| r_loss: 0.054| p_loss: 0.077| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.525
Train: Epoch [2237/3000], Step [120/158]| g_loss: 0.703| d_loss: 0.594| gp_loss: 0.057| r_loss: 0.055| p_loss: 0.082| v_loss: 0.021| per_loss: 0.306 | a_loss: 0.556
Train: Epoch [2237/3000], Step [150/158]| g_loss: 0.637| d_loss: 0.681| gp_loss: 0.059| r_loss: 0.056| p_loss: 0.078| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.493
Train: Epoch [2238/3000], Step [30/158]| g_loss: 0.692| d_loss: 0.654| gp_loss: 0.175| r_loss: 0.052| p_loss: 0.070| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.555
Train: Epoch [2238/3000], Step [60/158]| g_loss: 0.680| d_loss: 0.587| gp_loss: 0.052| r_loss: 0.054| p_loss: 0.073| v_loss: 0.021| per_loss: 0.296 | a_loss: 0.539
Train: Epoch [2238/3000], Step [90/158]| g_loss: 0.655| d_loss: 0.595| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.524
Train: Epoch [2238/3000], Step [120/158]| g_loss: 0.662| d_loss: 0.613| gp_loss: 0.059| r_loss: 0.052| p_loss: 0.069| v_loss: 0.021| per_loss: 0.296 | a_loss: 0.525
Train: Epoch [2238/3000], Step [150/158]| g_loss: 0.676| d_loss: 0.716| gp_loss: 0.058| r_loss: 0.053| p_loss: 0.071| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.536
Train: Epoch [2239/3000], Step [30/158]| g_loss: 0.636| d_loss: 0.795| gp_loss: 0.203| r_loss: 0.052| p_loss: 0.073| v_loss: 0.020| per_loss: 0.310 | a_loss: 0.496
Train: Epoch [2239/3000], Step [60/158]| g_loss: 0.614| d_loss: 0.622| gp_loss: 0.049| r_loss: 0.054| p_loss: 0.075| v_loss: 0.021| per_loss: 0.292 | a_loss: 0.473
Train: Epoch [2239/3000], Step [90/158]| g_loss: 0.643| d_loss: 0.656| gp_loss: 0.051| r_loss: 0.052| p_loss: 0.073| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.505
Train: Epoch [2239/3000], Step [120/158]| g_loss: 0.670| d_loss: 0.623| gp_loss: 0.051| r_loss: 0.053| p_loss: 0.072| v_loss: 0.021| per_loss: 0.298 | a_loss: 0.530
Train: Epoch [2239/3000], Step [150/158]| g_loss: 0.707| d_loss: 0.530| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.574
Train: Epoch [2240/3000], Step [30/158]| g_loss: 0.690| d_loss: 0.627| gp_loss: 0.119| r_loss: 0.055| p_loss: 0.073| v_loss: 0.020| per_loss: 0.283 | a_loss: 0.550
Train: Epoch [2240/3000], Step [60/158]| g_loss: 0.685| d_loss: 0.675| gp_loss: 0.050| r_loss: 0.053| p_loss: 0.072| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.544
Train: Epoch [2240/3000], Step [90/158]| g_loss: 0.668| d_loss: 0.620| gp_loss: 0.055| r_loss: 0.052| p_loss: 0.072| v_loss: 0.021| per_loss: 0.287 | a_loss: 0.531
Train: Epoch [2240/3000], Step [120/158]| g_loss: 0.659| d_loss: 0.633| gp_loss: 0.051| r_loss: 0.052| p_loss: 0.072| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.521
Train: Epoch [2240/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.597| gp_loss: 0.055| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.527
Train: Epoch [2241/3000], Step [30/158]| g_loss: 0.646| d_loss: 0.709| gp_loss: 0.167| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.508
Train: Epoch [2241/3000], Step [60/158]| g_loss: 0.686| d_loss: 0.539| gp_loss: 0.055| r_loss: 0.051| p_loss: 0.065| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.554
Train: Epoch [2241/3000], Step [90/158]| g_loss: 0.660| d_loss: 0.650| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.527
Train: Epoch [2241/3000], Step [120/158]| g_loss: 0.636| d_loss: 0.678| gp_loss: 0.054| r_loss: 0.051| p_loss: 0.070| v_loss: 0.020| per_loss: 0.278 | a_loss: 0.502
Train: Epoch [2241/3000], Step [150/158]| g_loss: 0.631| d_loss: 0.648| gp_loss: 0.055| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.496
Train: Epoch [2242/3000], Step [30/158]| g_loss: 0.649| d_loss: 0.697| gp_loss: 0.175| r_loss: 0.052| p_loss: 0.068| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.513
Train: Epoch [2242/3000], Step [60/158]| g_loss: 0.681| d_loss: 0.619| gp_loss: 0.053| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.544
Train: Epoch [2242/3000], Step [90/158]| g_loss: 0.635| d_loss: 0.652| gp_loss: 0.051| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.498
Train: Epoch [2242/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.547| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.070| v_loss: 0.020| per_loss: 0.284 | a_loss: 0.531
Train: Epoch [2242/3000], Step [150/158]| g_loss: 0.697| d_loss: 0.649| gp_loss: 0.055| r_loss: 0.053| p_loss: 0.071| v_loss: 0.021| per_loss: 0.285 | a_loss: 0.559
Train: Epoch [2243/3000], Step [30/158]| g_loss: 0.634| d_loss: 0.709| gp_loss: 0.123| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.496
Train: Epoch [2243/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.597| gp_loss: 0.055| r_loss: 0.053| p_loss: 0.070| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.535
Train: Epoch [2243/3000], Step [90/158]| g_loss: 0.670| d_loss: 0.591| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.538
Train: Epoch [2243/3000], Step [120/158]| g_loss: 0.680| d_loss: 0.538| gp_loss: 0.057| r_loss: 0.053| p_loss: 0.073| v_loss: 0.021| per_loss: 0.293 | a_loss: 0.541
Train: Epoch [2243/3000], Step [150/158]| g_loss: 0.660| d_loss: 0.641| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.523
Train: Epoch [2244/3000], Step [30/158]| g_loss: 0.659| d_loss: 0.704| gp_loss: 0.138| r_loss: 0.052| p_loss: 0.070| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.522
Train: Epoch [2244/3000], Step [60/158]| g_loss: 0.645| d_loss: 0.688| gp_loss: 0.051| r_loss: 0.052| p_loss: 0.071| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.508
Train: Epoch [2244/3000], Step [90/158]| g_loss: 0.678| d_loss: 0.635| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.073| v_loss: 0.021| per_loss: 0.295 | a_loss: 0.540
Train: Epoch [2244/3000], Step [120/158]| g_loss: 0.676| d_loss: 0.605| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.068| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.539
Train: Epoch [2244/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.571| gp_loss: 0.061| r_loss: 0.052| p_loss: 0.069| v_loss: 0.020| per_loss: 0.275 | a_loss: 0.526
Train: Epoch [2245/3000], Step [30/158]| g_loss: 0.660| d_loss: 0.698| gp_loss: 0.129| r_loss: 0.052| p_loss: 0.069| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.523
Train: Epoch [2245/3000], Step [60/158]| g_loss: 0.664| d_loss: 0.672| gp_loss: 0.052| r_loss: 0.052| p_loss: 0.072| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.526
Train: Epoch [2245/3000], Step [90/158]| g_loss: 0.676| d_loss: 0.558| gp_loss: 0.055| r_loss: 0.056| p_loss: 0.076| v_loss: 0.021| per_loss: 0.286 | a_loss: 0.533
Train: Epoch [2245/3000], Step [120/158]| g_loss: 0.642| d_loss: 0.622| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.072| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.506
Train: Epoch [2245/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.652| gp_loss: 0.060| r_loss: 0.055| p_loss: 0.074| v_loss: 0.020| per_loss: 0.282 | a_loss: 0.518
Train: Epoch [2246/3000], Step [30/158]| g_loss: 0.621| d_loss: 0.796| gp_loss: 0.138| r_loss: 0.052| p_loss: 0.074| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.482
Train: Epoch [2246/3000], Step [60/158]| g_loss: 0.639| d_loss: 0.661| gp_loss: 0.058| r_loss: 0.056| p_loss: 0.074| v_loss: 0.021| per_loss: 0.292 | a_loss: 0.496
Train: Epoch [2246/3000], Step [90/158]| g_loss: 0.659| d_loss: 0.567| gp_loss: 0.060| r_loss: 0.058| p_loss: 0.081| v_loss: 0.021| per_loss: 0.280 | a_loss: 0.511
Train: Epoch [2246/3000], Step [120/158]| g_loss: 0.711| d_loss: 0.569| gp_loss: 0.059| r_loss: 0.052| p_loss: 0.078| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.571
Train: Epoch [2246/3000], Step [150/158]| g_loss: 0.719| d_loss: 0.619| gp_loss: 0.061| r_loss: 0.056| p_loss: 0.079| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.573
Train: Epoch [2247/3000], Step [30/158]| g_loss: 0.694| d_loss: 0.662| gp_loss: 0.131| r_loss: 0.062| p_loss: 0.085| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.540
Train: Epoch [2247/3000], Step [60/158]| g_loss: 0.681| d_loss: 0.624| gp_loss: 0.058| r_loss: 0.058| p_loss: 0.081| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.533
Train: Epoch [2247/3000], Step [90/158]| g_loss: 0.707| d_loss: 0.568| gp_loss: 0.060| r_loss: 0.061| p_loss: 0.078| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.558
Train: Epoch [2247/3000], Step [120/158]| g_loss: 0.682| d_loss: 0.633| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.077| v_loss: 0.021| per_loss: 0.286 | a_loss: 0.538
Train: Epoch [2247/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.638| gp_loss: 0.059| r_loss: 0.055| p_loss: 0.079| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.517
Train: Epoch [2248/3000], Step [30/158]| g_loss: 0.650| d_loss: 0.717| gp_loss: 0.145| r_loss: 0.059| p_loss: 0.080| v_loss: 0.021| per_loss: 0.299 | a_loss: 0.501
Train: Epoch [2248/3000], Step [60/158]| g_loss: 0.660| d_loss: 0.658| gp_loss: 0.053| r_loss: 0.058| p_loss: 0.080| v_loss: 0.021| per_loss: 0.284 | a_loss: 0.513
Train: Epoch [2248/3000], Step [90/158]| g_loss: 0.637| d_loss: 0.667| gp_loss: 0.055| r_loss: 0.056| p_loss: 0.076| v_loss: 0.021| per_loss: 0.284 | a_loss: 0.494
Train: Epoch [2248/3000], Step [120/158]| g_loss: 0.682| d_loss: 0.534| gp_loss: 0.059| r_loss: 0.053| p_loss: 0.074| v_loss: 0.021| per_loss: 0.292 | a_loss: 0.542
Train: Epoch [2248/3000], Step [150/158]| g_loss: 0.703| d_loss: 0.600| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.069| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.568
Train: Epoch [2249/3000], Step [30/158]| g_loss: 0.660| d_loss: 0.685| gp_loss: 0.127| r_loss: 0.055| p_loss: 0.071| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.521
Train: Epoch [2249/3000], Step [60/158]| g_loss: 0.655| d_loss: 0.647| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.072| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.516
Train: Epoch [2249/3000], Step [90/158]| g_loss: 0.687| d_loss: 0.538| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.555
Train: Epoch [2249/3000], Step [120/158]| g_loss: 0.658| d_loss: 0.656| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.071| v_loss: 0.020| per_loss: 0.283 | a_loss: 0.522
Train: Epoch [2249/3000], Step [150/158]| g_loss: 0.666| d_loss: 0.605| gp_loss: 0.061| r_loss: 0.053| p_loss: 0.071| v_loss: 0.021| per_loss: 0.293 | a_loss: 0.528
Train: Epoch [2250/3000], Step [30/158]| g_loss: 0.645| d_loss: 0.776| gp_loss: 0.178| r_loss: 0.051| p_loss: 0.071| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.508
Train: Epoch [2250/3000], Step [60/158]| g_loss: 0.696| d_loss: 0.537| gp_loss: 0.057| r_loss: 0.054| p_loss: 0.072| v_loss: 0.021| per_loss: 0.284 | a_loss: 0.556
Train: Epoch [2250/3000], Step [90/158]| g_loss: 0.698| d_loss: 0.600| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.564
Train: Epoch [2250/3000], Step [120/158]| g_loss: 0.669| d_loss: 0.659| gp_loss: 0.057| r_loss: 0.053| p_loss: 0.072| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.530
Train: Epoch [2250/3000], Step [150/158]| g_loss: 0.638| d_loss: 0.620| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.067| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.506
Test: Epoch [2250/3000]| g_loss: 0.627| r_loss: 0.385| p_loss: 0.300| v_loss: 0.021
Train: Epoch [2251/3000], Step [30/158]| g_loss: 0.644| d_loss: 0.669| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.508
Train: Epoch [2251/3000], Step [60/158]| g_loss: 0.668| d_loss: 0.701| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.076| v_loss: 0.022| per_loss: 0.295 | a_loss: 0.525
Train: Epoch [2251/3000], Step [90/158]| g_loss: 0.649| d_loss: 0.564| gp_loss: 0.057| r_loss: 0.053| p_loss: 0.070| v_loss: 0.021| per_loss: 0.286 | a_loss: 0.512
Train: Epoch [2251/3000], Step [120/158]| g_loss: 0.657| d_loss: 0.652| gp_loss: 0.053| r_loss: 0.052| p_loss: 0.073| v_loss: 0.021| per_loss: 0.297 | a_loss: 0.518
Train: Epoch [2251/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.593| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.542
Train: Epoch [2252/3000], Step [30/158]| g_loss: 0.667| d_loss: 0.786| gp_loss: 0.202| r_loss: 0.051| p_loss: 0.070| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.531
Train: Epoch [2252/3000], Step [60/158]| g_loss: 0.654| d_loss: 0.592| gp_loss: 0.049| r_loss: 0.052| p_loss: 0.071| v_loss: 0.021| per_loss: 0.288 | a_loss: 0.517
Train: Epoch [2252/3000], Step [90/158]| g_loss: 0.695| d_loss: 0.524| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.282 | a_loss: 0.561
Train: Epoch [2252/3000], Step [120/158]| g_loss: 0.684| d_loss: 0.561| gp_loss: 0.051| r_loss: 0.051| p_loss: 0.064| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.552
Train: Epoch [2252/3000], Step [150/158]| g_loss: 0.653| d_loss: 0.684| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.520
Train: Epoch [2253/3000], Step [30/158]| g_loss: 0.679| d_loss: 0.683| gp_loss: 0.151| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.548
Train: Epoch [2253/3000], Step [60/158]| g_loss: 0.760| d_loss: 0.463| gp_loss: 0.051| r_loss: 0.052| p_loss: 0.067| v_loss: 0.021| per_loss: 0.292 | a_loss: 0.625
Train: Epoch [2253/3000], Step [90/158]| g_loss: 0.640| d_loss: 0.697| gp_loss: 0.052| r_loss: 0.054| p_loss: 0.070| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.501
Train: Epoch [2253/3000], Step [120/158]| g_loss: 0.603| d_loss: 0.700| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.067| v_loss: 0.020| per_loss: 0.282 | a_loss: 0.473
Train: Epoch [2253/3000], Step [150/158]| g_loss: 0.637| d_loss: 0.640| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.505
Train: Epoch [2254/3000], Step [30/158]| g_loss: 0.671| d_loss: 0.636| gp_loss: 0.165| r_loss: 0.052| p_loss: 0.068| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.535
Train: Epoch [2254/3000], Step [60/158]| g_loss: 0.680| d_loss: 0.663| gp_loss: 0.047| r_loss: 0.052| p_loss: 0.070| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.543
Train: Epoch [2254/3000], Step [90/158]| g_loss: 0.609| d_loss: 0.677| gp_loss: 0.052| r_loss: 0.052| p_loss: 0.070| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.474
Train: Epoch [2254/3000], Step [120/158]| g_loss: 0.621| d_loss: 0.631| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.278 | a_loss: 0.495
Train: Epoch [2254/3000], Step [150/158]| g_loss: 0.685| d_loss: 0.627| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.069| v_loss: 0.021| per_loss: 0.287 | a_loss: 0.549
Train: Epoch [2255/3000], Step [30/158]| g_loss: 0.597| d_loss: 0.766| gp_loss: 0.092| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.463
Train: Epoch [2255/3000], Step [60/158]| g_loss: 0.647| d_loss: 0.596| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.067| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.513
Train: Epoch [2255/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.587| gp_loss: 0.057| r_loss: 0.052| p_loss: 0.071| v_loss: 0.021| per_loss: 0.302 | a_loss: 0.518
Train: Epoch [2255/3000], Step [120/158]| g_loss: 0.684| d_loss: 0.594| gp_loss: 0.056| r_loss: 0.053| p_loss: 0.073| v_loss: 0.021| per_loss: 0.276 | a_loss: 0.546
Train: Epoch [2255/3000], Step [150/158]| g_loss: 0.683| d_loss: 0.606| gp_loss: 0.057| r_loss: 0.052| p_loss: 0.072| v_loss: 0.021| per_loss: 0.296 | a_loss: 0.544
Train: Epoch [2256/3000], Step [30/158]| g_loss: 0.648| d_loss: 0.734| gp_loss: 0.197| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.515
Train: Epoch [2256/3000], Step [60/158]| g_loss: 0.676| d_loss: 0.599| gp_loss: 0.051| r_loss: 0.053| p_loss: 0.067| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.542
Train: Epoch [2256/3000], Step [90/158]| g_loss: 0.668| d_loss: 0.574| gp_loss: 0.051| r_loss: 0.051| p_loss: 0.069| v_loss: 0.021| per_loss: 0.287 | a_loss: 0.533
Train: Epoch [2256/3000], Step [120/158]| g_loss: 0.694| d_loss: 0.605| gp_loss: 0.056| r_loss: 0.053| p_loss: 0.072| v_loss: 0.020| per_loss: 0.283 | a_loss: 0.557
Train: Epoch [2256/3000], Step [150/158]| g_loss: 0.599| d_loss: 0.736| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.070| v_loss: 0.020| per_loss: 0.282 | a_loss: 0.466
Train: Epoch [2257/3000], Step [30/158]| g_loss: 0.660| d_loss: 0.689| gp_loss: 0.149| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.528
Train: Epoch [2257/3000], Step [60/158]| g_loss: 0.672| d_loss: 0.523| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.063| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.541
Train: Epoch [2257/3000], Step [90/158]| g_loss: 0.677| d_loss: 0.593| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.280 | a_loss: 0.545
Train: Epoch [2257/3000], Step [120/158]| g_loss: 0.685| d_loss: 0.663| gp_loss: 0.055| r_loss: 0.053| p_loss: 0.071| v_loss: 0.021| per_loss: 0.286 | a_loss: 0.547
Train: Epoch [2257/3000], Step [150/158]| g_loss: 0.608| d_loss: 0.667| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.477
Train: Epoch [2258/3000], Step [30/158]| g_loss: 0.625| d_loss: 0.678| gp_loss: 0.151| r_loss: 0.050| p_loss: 0.069| v_loss: 0.020| per_loss: 0.272 | a_loss: 0.494
Train: Epoch [2258/3000], Step [60/158]| g_loss: 0.706| d_loss: 0.476| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.067| v_loss: 0.021| per_loss: 0.279 | a_loss: 0.572
Train: Epoch [2258/3000], Step [90/158]| g_loss: 0.697| d_loss: 0.674| gp_loss: 0.051| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.563
Train: Epoch [2258/3000], Step [120/158]| g_loss: 0.653| d_loss: 0.594| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.066| v_loss: 0.020| per_loss: 0.279 | a_loss: 0.521
Train: Epoch [2258/3000], Step [150/158]| g_loss: 0.639| d_loss: 0.708| gp_loss: 0.055| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.505
Train: Epoch [2259/3000], Step [30/158]| g_loss: 0.608| d_loss: 0.775| gp_loss: 0.129| r_loss: 0.054| p_loss: 0.076| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.467
Train: Epoch [2259/3000], Step [60/158]| g_loss: 0.630| d_loss: 0.603| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.072| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.492
Train: Epoch [2259/3000], Step [90/158]| g_loss: 0.656| d_loss: 0.643| gp_loss: 0.061| r_loss: 0.052| p_loss: 0.072| v_loss: 0.020| per_loss: 0.280 | a_loss: 0.519
Train: Epoch [2259/3000], Step [120/158]| g_loss: 0.698| d_loss: 0.567| gp_loss: 0.058| r_loss: 0.053| p_loss: 0.069| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.562
Train: Epoch [2259/3000], Step [150/158]| g_loss: 0.672| d_loss: 0.611| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.535
Train: Epoch [2260/3000], Step [30/158]| g_loss: 0.620| d_loss: 0.700| gp_loss: 0.114| r_loss: 0.050| p_loss: 0.071| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.487
Train: Epoch [2260/3000], Step [60/158]| g_loss: 0.677| d_loss: 0.557| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.070| v_loss: 0.020| per_loss: 0.281 | a_loss: 0.542
Train: Epoch [2260/3000], Step [90/158]| g_loss: 0.666| d_loss: 0.623| gp_loss: 0.058| r_loss: 0.053| p_loss: 0.070| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.528
Train: Epoch [2260/3000], Step [120/158]| g_loss: 0.663| d_loss: 0.610| gp_loss: 0.056| r_loss: 0.054| p_loss: 0.073| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.524
Train: Epoch [2260/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.677| gp_loss: 0.061| r_loss: 0.061| p_loss: 0.078| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.509
Train: Epoch [2261/3000], Step [30/158]| g_loss: 0.701| d_loss: 0.689| gp_loss: 0.112| r_loss: 0.060| p_loss: 0.094| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.544
Train: Epoch [2261/3000], Step [60/158]| g_loss: 0.659| d_loss: 0.665| gp_loss: 0.055| r_loss: 0.063| p_loss: 0.088| v_loss: 0.021| per_loss: 0.289 | a_loss: 0.502
Train: Epoch [2261/3000], Step [90/158]| g_loss: 0.620| d_loss: 0.624| gp_loss: 0.059| r_loss: 0.054| p_loss: 0.075| v_loss: 0.020| per_loss: 0.274 | a_loss: 0.481
Train: Epoch [2261/3000], Step [120/158]| g_loss: 0.680| d_loss: 0.629| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.074| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.540
Train: Epoch [2261/3000], Step [150/158]| g_loss: 0.685| d_loss: 0.557| gp_loss: 0.060| r_loss: 0.053| p_loss: 0.073| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.546
Train: Epoch [2262/3000], Step [30/158]| g_loss: 0.673| d_loss: 0.741| gp_loss: 0.206| r_loss: 0.052| p_loss: 0.070| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.536
Train: Epoch [2262/3000], Step [60/158]| g_loss: 0.691| d_loss: 0.506| gp_loss: 0.049| r_loss: 0.053| p_loss: 0.066| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.556
Train: Epoch [2262/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.706| gp_loss: 0.051| r_loss: 0.052| p_loss: 0.068| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.519
Train: Epoch [2262/3000], Step [120/158]| g_loss: 0.621| d_loss: 0.594| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.277 | a_loss: 0.489
Train: Epoch [2262/3000], Step [150/158]| g_loss: 0.647| d_loss: 0.625| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.278 | a_loss: 0.516
Train: Epoch [2263/3000], Step [30/158]| g_loss: 0.661| d_loss: 0.710| gp_loss: 0.124| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.279 | a_loss: 0.529
Train: Epoch [2263/3000], Step [60/158]| g_loss: 0.651| d_loss: 0.604| gp_loss: 0.055| r_loss: 0.052| p_loss: 0.066| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.518
Train: Epoch [2263/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.645| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.065| v_loss: 0.020| per_loss: 0.283 | a_loss: 0.522
Train: Epoch [2263/3000], Step [120/158]| g_loss: 0.648| d_loss: 0.696| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.069| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.515
Train: Epoch [2263/3000], Step [150/158]| g_loss: 0.652| d_loss: 0.567| gp_loss: 0.060| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.518
Train: Epoch [2264/3000], Step [30/158]| g_loss: 0.642| d_loss: 0.767| gp_loss: 0.175| r_loss: 0.051| p_loss: 0.071| v_loss: 0.020| per_loss: 0.279 | a_loss: 0.507
Train: Epoch [2264/3000], Step [60/158]| g_loss: 0.640| d_loss: 0.584| gp_loss: 0.055| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.507
Train: Epoch [2264/3000], Step [90/158]| g_loss: 0.665| d_loss: 0.659| gp_loss: 0.055| r_loss: 0.052| p_loss: 0.069| v_loss: 0.020| per_loss: 0.280 | a_loss: 0.530
Train: Epoch [2264/3000], Step [120/158]| g_loss: 0.688| d_loss: 0.513| gp_loss: 0.057| r_loss: 0.052| p_loss: 0.066| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.553
Train: Epoch [2264/3000], Step [150/158]| g_loss: 0.690| d_loss: 0.651| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.563
Train: Epoch [2265/3000], Step [30/158]| g_loss: 0.612| d_loss: 0.760| gp_loss: 0.162| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.279 | a_loss: 0.479
Train: Epoch [2265/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.607| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.278 | a_loss: 0.541
Train: Epoch [2265/3000], Step [90/158]| g_loss: 0.653| d_loss: 0.599| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.068| v_loss: 0.020| per_loss: 0.280 | a_loss: 0.522
Train: Epoch [2265/3000], Step [120/158]| g_loss: 0.652| d_loss: 0.590| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.066| v_loss: 0.020| per_loss: 0.281 | a_loss: 0.519
Train: Epoch [2265/3000], Step [150/158]| g_loss: 0.690| d_loss: 0.568| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.560
Train: Epoch [2266/3000], Step [30/158]| g_loss: 0.631| d_loss: 0.775| gp_loss: 0.135| r_loss: 0.052| p_loss: 0.068| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.497
Train: Epoch [2266/3000], Step [60/158]| g_loss: 0.610| d_loss: 0.676| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.070| v_loss: 0.020| per_loss: 0.283 | a_loss: 0.477
Train: Epoch [2266/3000], Step [90/158]| g_loss: 0.690| d_loss: 0.554| gp_loss: 0.062| r_loss: 0.052| p_loss: 0.069| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.556
Train: Epoch [2266/3000], Step [120/158]| g_loss: 0.685| d_loss: 0.604| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.555
Train: Epoch [2266/3000], Step [150/158]| g_loss: 0.678| d_loss: 0.576| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.281 | a_loss: 0.545
Train: Epoch [2267/3000], Step [30/158]| g_loss: 0.688| d_loss: 0.671| gp_loss: 0.164| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.283 | a_loss: 0.555
Train: Epoch [2267/3000], Step [60/158]| g_loss: 0.628| d_loss: 0.742| gp_loss: 0.051| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.495
Train: Epoch [2267/3000], Step [90/158]| g_loss: 0.625| d_loss: 0.670| gp_loss: 0.055| r_loss: 0.053| p_loss: 0.074| v_loss: 0.021| per_loss: 0.295 | a_loss: 0.485
Train: Epoch [2267/3000], Step [120/158]| g_loss: 0.654| d_loss: 0.572| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.070| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.521
Train: Epoch [2267/3000], Step [150/158]| g_loss: 0.707| d_loss: 0.617| gp_loss: 0.059| r_loss: 0.052| p_loss: 0.072| v_loss: 0.020| per_loss: 0.280 | a_loss: 0.571
Train: Epoch [2268/3000], Step [30/158]| g_loss: 0.689| d_loss: 0.626| gp_loss: 0.136| r_loss: 0.055| p_loss: 0.075| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.548
Train: Epoch [2268/3000], Step [60/158]| g_loss: 0.672| d_loss: 0.634| gp_loss: 0.052| r_loss: 0.054| p_loss: 0.078| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.530
Train: Epoch [2268/3000], Step [90/158]| g_loss: 0.680| d_loss: 0.563| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.072| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.543
Train: Epoch [2268/3000], Step [120/158]| g_loss: 0.682| d_loss: 0.640| gp_loss: 0.058| r_loss: 0.054| p_loss: 0.072| v_loss: 0.020| per_loss: 0.278 | a_loss: 0.544
Train: Epoch [2268/3000], Step [150/158]| g_loss: 0.655| d_loss: 0.633| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.068| v_loss: 0.019| per_loss: 0.279 | a_loss: 0.524
Train: Epoch [2269/3000], Step [30/158]| g_loss: 0.607| d_loss: 0.775| gp_loss: 0.121| r_loss: 0.057| p_loss: 0.077| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.463
Train: Epoch [2269/3000], Step [60/158]| g_loss: 0.690| d_loss: 0.607| gp_loss: 0.061| r_loss: 0.053| p_loss: 0.075| v_loss: 0.020| per_loss: 0.284 | a_loss: 0.551
Train: Epoch [2269/3000], Step [90/158]| g_loss: 0.672| d_loss: 0.546| gp_loss: 0.059| r_loss: 0.051| p_loss: 0.070| v_loss: 0.020| per_loss: 0.284 | a_loss: 0.537
Train: Epoch [2269/3000], Step [120/158]| g_loss: 0.726| d_loss: 0.491| gp_loss: 0.055| r_loss: 0.052| p_loss: 0.067| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.592
Train: Epoch [2269/3000], Step [150/158]| g_loss: 0.648| d_loss: 0.706| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.515
Train: Epoch [2270/3000], Step [30/158]| g_loss: 0.630| d_loss: 0.783| gp_loss: 0.171| r_loss: 0.053| p_loss: 0.072| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.491
Train: Epoch [2270/3000], Step [60/158]| g_loss: 0.637| d_loss: 0.649| gp_loss: 0.058| r_loss: 0.054| p_loss: 0.071| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.498
Train: Epoch [2270/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.608| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.073| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.515
Train: Epoch [2270/3000], Step [120/158]| g_loss: 0.665| d_loss: 0.626| gp_loss: 0.059| r_loss: 0.054| p_loss: 0.071| v_loss: 0.020| per_loss: 0.276 | a_loss: 0.527
Train: Epoch [2270/3000], Step [150/158]| g_loss: 0.680| d_loss: 0.661| gp_loss: 0.060| r_loss: 0.051| p_loss: 0.070| v_loss: 0.019| per_loss: 0.278 | a_loss: 0.547
Train: Epoch [2271/3000], Step [30/158]| g_loss: 0.683| d_loss: 0.628| gp_loss: 0.150| r_loss: 0.054| p_loss: 0.068| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.546
Train: Epoch [2271/3000], Step [60/158]| g_loss: 0.671| d_loss: 0.627| gp_loss: 0.051| r_loss: 0.053| p_loss: 0.071| v_loss: 0.020| per_loss: 0.280 | a_loss: 0.535
Train: Epoch [2271/3000], Step [90/158]| g_loss: 0.621| d_loss: 0.665| gp_loss: 0.055| r_loss: 0.054| p_loss: 0.074| v_loss: 0.020| per_loss: 0.279 | a_loss: 0.481
Train: Epoch [2271/3000], Step [120/158]| g_loss: 0.610| d_loss: 0.649| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.478
Train: Epoch [2271/3000], Step [150/158]| g_loss: 0.654| d_loss: 0.614| gp_loss: 0.060| r_loss: 0.053| p_loss: 0.069| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.517
Train: Epoch [2272/3000], Step [30/158]| g_loss: 0.681| d_loss: 0.663| gp_loss: 0.126| r_loss: 0.052| p_loss: 0.068| v_loss: 0.020| per_loss: 0.280 | a_loss: 0.548
Train: Epoch [2272/3000], Step [60/158]| g_loss: 0.629| d_loss: 0.692| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.497
Train: Epoch [2272/3000], Step [90/158]| g_loss: 0.637| d_loss: 0.605| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.273 | a_loss: 0.508
Train: Epoch [2272/3000], Step [120/158]| g_loss: 0.663| d_loss: 0.676| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.069| v_loss: 0.020| per_loss: 0.280 | a_loss: 0.528
Train: Epoch [2272/3000], Step [150/158]| g_loss: 0.660| d_loss: 0.516| gp_loss: 0.062| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.527
Train: Epoch [2273/3000], Step [30/158]| g_loss: 0.681| d_loss: 0.726| gp_loss: 0.157| r_loss: 0.051| p_loss: 0.071| v_loss: 0.020| per_loss: 0.279 | a_loss: 0.546
Train: Epoch [2273/3000], Step [60/158]| g_loss: 0.629| d_loss: 0.637| gp_loss: 0.055| r_loss: 0.053| p_loss: 0.071| v_loss: 0.020| per_loss: 0.273 | a_loss: 0.493
Train: Epoch [2273/3000], Step [90/158]| g_loss: 0.664| d_loss: 0.596| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.532
Train: Epoch [2273/3000], Step [120/158]| g_loss: 0.686| d_loss: 0.578| gp_loss: 0.054| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.553
Train: Epoch [2273/3000], Step [150/158]| g_loss: 0.684| d_loss: 0.598| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.550
Train: Epoch [2274/3000], Step [30/158]| g_loss: 0.669| d_loss: 0.717| gp_loss: 0.212| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.279 | a_loss: 0.539
Train: Epoch [2274/3000], Step [60/158]| g_loss: 0.661| d_loss: 0.634| gp_loss: 0.052| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.279 | a_loss: 0.529
Train: Epoch [2274/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.604| gp_loss: 0.052| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.275 | a_loss: 0.526
Train: Epoch [2274/3000], Step [120/158]| g_loss: 0.647| d_loss: 0.713| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.516
Train: Epoch [2274/3000], Step [150/158]| g_loss: 0.656| d_loss: 0.593| gp_loss: 0.052| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.523
Train: Epoch [2275/3000], Step [30/158]| g_loss: 0.654| d_loss: 0.703| gp_loss: 0.163| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.521
Train: Epoch [2275/3000], Step [60/158]| g_loss: 0.638| d_loss: 0.611| gp_loss: 0.049| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.509
Train: Epoch [2275/3000], Step [90/158]| g_loss: 0.618| d_loss: 0.645| gp_loss: 0.051| r_loss: 0.051| p_loss: 0.066| v_loss: 0.019| per_loss: 0.266 | a_loss: 0.488
Train: Epoch [2275/3000], Step [120/158]| g_loss: 0.657| d_loss: 0.609| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.276 | a_loss: 0.528
Train: Epoch [2275/3000], Step [150/158]| g_loss: 0.682| d_loss: 0.589| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.277 | a_loss: 0.550
Train: Epoch [2276/3000], Step [30/158]| g_loss: 0.649| d_loss: 0.764| gp_loss: 0.167| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.276 | a_loss: 0.518
Train: Epoch [2276/3000], Step [60/158]| g_loss: 0.646| d_loss: 0.633| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.068| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.514
Train: Epoch [2276/3000], Step [90/158]| g_loss: 0.634| d_loss: 0.654| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.281 | a_loss: 0.503
Train: Epoch [2276/3000], Step [120/158]| g_loss: 0.642| d_loss: 0.601| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.067| v_loss: 0.020| per_loss: 0.279 | a_loss: 0.511
Train: Epoch [2276/3000], Step [150/158]| g_loss: 0.667| d_loss: 0.599| gp_loss: 0.059| r_loss: 0.053| p_loss: 0.067| v_loss: 0.020| per_loss: 0.281 | a_loss: 0.532
Train: Epoch [2277/3000], Step [30/158]| g_loss: 0.671| d_loss: 0.698| gp_loss: 0.177| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.272 | a_loss: 0.540
Train: Epoch [2277/3000], Step [60/158]| g_loss: 0.612| d_loss: 0.676| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.068| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.478
Train: Epoch [2277/3000], Step [90/158]| g_loss: 0.652| d_loss: 0.679| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.070| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.518
Train: Epoch [2277/3000], Step [120/158]| g_loss: 0.665| d_loss: 0.576| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.068| v_loss: 0.020| per_loss: 0.279 | a_loss: 0.532
Train: Epoch [2277/3000], Step [150/158]| g_loss: 0.688| d_loss: 0.528| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.556
Train: Epoch [2278/3000], Step [30/158]| g_loss: 0.657| d_loss: 0.687| gp_loss: 0.129| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.272 | a_loss: 0.522
Train: Epoch [2278/3000], Step [60/158]| g_loss: 0.668| d_loss: 0.627| gp_loss: 0.050| r_loss: 0.050| p_loss: 0.070| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.534
Train: Epoch [2278/3000], Step [90/158]| g_loss: 0.681| d_loss: 0.583| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.070| v_loss: 0.020| per_loss: 0.284 | a_loss: 0.545
Train: Epoch [2278/3000], Step [120/158]| g_loss: 0.689| d_loss: 0.570| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.067| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.556
Train: Epoch [2278/3000], Step [150/158]| g_loss: 0.647| d_loss: 0.638| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.069| v_loss: 0.019| per_loss: 0.263 | a_loss: 0.514
Train: Epoch [2279/3000], Step [30/158]| g_loss: 0.615| d_loss: 0.771| gp_loss: 0.126| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.279 | a_loss: 0.481
Train: Epoch [2279/3000], Step [60/158]| g_loss: 0.660| d_loss: 0.583| gp_loss: 0.057| r_loss: 0.052| p_loss: 0.070| v_loss: 0.020| per_loss: 0.280 | a_loss: 0.525
Train: Epoch [2279/3000], Step [90/158]| g_loss: 0.633| d_loss: 0.624| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.068| v_loss: 0.020| per_loss: 0.278 | a_loss: 0.500
Train: Epoch [2279/3000], Step [120/158]| g_loss: 0.640| d_loss: 0.638| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.069| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.507
Train: Epoch [2279/3000], Step [150/158]| g_loss: 0.691| d_loss: 0.535| gp_loss: 0.062| r_loss: 0.050| p_loss: 0.069| v_loss: 0.020| per_loss: 0.278 | a_loss: 0.558
Train: Epoch [2280/3000], Step [30/158]| g_loss: 0.677| d_loss: 0.762| gp_loss: 0.181| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.545
Train: Epoch [2280/3000], Step [60/158]| g_loss: 0.668| d_loss: 0.578| gp_loss: 0.052| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.281 | a_loss: 0.532
Train: Epoch [2280/3000], Step [90/158]| g_loss: 0.699| d_loss: 0.559| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.071| v_loss: 0.020| per_loss: 0.277 | a_loss: 0.560
Train: Epoch [2280/3000], Step [120/158]| g_loss: 0.640| d_loss: 0.701| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.072| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.505
Train: Epoch [2280/3000], Step [150/158]| g_loss: 0.622| d_loss: 0.605| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.070| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.486
Train: Epoch [2281/3000], Step [30/158]| g_loss: 0.662| d_loss: 0.727| gp_loss: 0.209| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.528
Train: Epoch [2281/3000], Step [60/158]| g_loss: 0.659| d_loss: 0.671| gp_loss: 0.052| r_loss: 0.053| p_loss: 0.071| v_loss: 0.020| per_loss: 0.278 | a_loss: 0.523
Train: Epoch [2281/3000], Step [90/158]| g_loss: 0.668| d_loss: 0.567| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.534
Train: Epoch [2281/3000], Step [120/158]| g_loss: 0.684| d_loss: 0.585| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.284 | a_loss: 0.551
Train: Epoch [2281/3000], Step [150/158]| g_loss: 0.638| d_loss: 0.648| gp_loss: 0.052| r_loss: 0.054| p_loss: 0.070| v_loss: 0.020| per_loss: 0.275 | a_loss: 0.501
Train: Epoch [2282/3000], Step [30/158]| g_loss: 0.602| d_loss: 0.751| gp_loss: 0.143| r_loss: 0.052| p_loss: 0.072| v_loss: 0.019| per_loss: 0.275 | a_loss: 0.468
Train: Epoch [2282/3000], Step [60/158]| g_loss: 0.662| d_loss: 0.657| gp_loss: 0.053| r_loss: 0.052| p_loss: 0.073| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.524
Train: Epoch [2282/3000], Step [90/158]| g_loss: 0.668| d_loss: 0.598| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.534
Train: Epoch [2282/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.579| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.067| v_loss: 0.021| per_loss: 0.286 | a_loss: 0.533
Train: Epoch [2282/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.643| gp_loss: 0.053| r_loss: 0.052| p_loss: 0.072| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.525
Train: Epoch [2283/3000], Step [30/158]| g_loss: 0.638| d_loss: 0.773| gp_loss: 0.166| r_loss: 0.054| p_loss: 0.075| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.496
Train: Epoch [2283/3000], Step [60/158]| g_loss: 0.627| d_loss: 0.714| gp_loss: 0.052| r_loss: 0.051| p_loss: 0.075| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.491
Train: Epoch [2283/3000], Step [90/158]| g_loss: 0.647| d_loss: 0.506| gp_loss: 0.053| r_loss: 0.056| p_loss: 0.074| v_loss: 0.021| per_loss: 0.287 | a_loss: 0.504
Train: Epoch [2283/3000], Step [120/158]| g_loss: 0.709| d_loss: 0.588| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.074| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.571
Train: Epoch [2283/3000], Step [150/158]| g_loss: 0.670| d_loss: 0.608| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.068| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.538
Train: Epoch [2284/3000], Step [30/158]| g_loss: 0.641| d_loss: 0.641| gp_loss: 0.084| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.271 | a_loss: 0.512
Train: Epoch [2284/3000], Step [60/158]| g_loss: 0.645| d_loss: 0.695| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.513
Train: Epoch [2284/3000], Step [90/158]| g_loss: 0.643| d_loss: 0.577| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.516
Train: Epoch [2284/3000], Step [120/158]| g_loss: 0.654| d_loss: 0.690| gp_loss: 0.059| r_loss: 0.053| p_loss: 0.067| v_loss: 0.020| per_loss: 0.278 | a_loss: 0.519
Train: Epoch [2284/3000], Step [150/158]| g_loss: 0.646| d_loss: 0.549| gp_loss: 0.061| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.514
Train: Epoch [2285/3000], Step [30/158]| g_loss: 0.702| d_loss: 0.626| gp_loss: 0.140| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.573
Train: Epoch [2285/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.551| gp_loss: 0.051| r_loss: 0.049| p_loss: 0.064| v_loss: 0.021| per_loss: 0.289 | a_loss: 0.543
Train: Epoch [2285/3000], Step [90/158]| g_loss: 0.699| d_loss: 0.656| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.071| v_loss: 0.020| per_loss: 0.282 | a_loss: 0.565
Train: Epoch [2285/3000], Step [120/158]| g_loss: 0.625| d_loss: 0.689| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.070| v_loss: 0.019| per_loss: 0.277 | a_loss: 0.491
Train: Epoch [2285/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.632| gp_loss: 0.062| r_loss: 0.053| p_loss: 0.069| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.527
Train: Epoch [2286/3000], Step [30/158]| g_loss: 0.638| d_loss: 0.741| gp_loss: 0.167| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.505
Train: Epoch [2286/3000], Step [60/158]| g_loss: 0.658| d_loss: 0.577| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.068| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.524
Train: Epoch [2286/3000], Step [90/158]| g_loss: 0.644| d_loss: 0.690| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.513
Train: Epoch [2286/3000], Step [120/158]| g_loss: 0.673| d_loss: 0.555| gp_loss: 0.060| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.277 | a_loss: 0.541
Train: Epoch [2286/3000], Step [150/158]| g_loss: 0.645| d_loss: 0.655| gp_loss: 0.060| r_loss: 0.050| p_loss: 0.069| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.512
Train: Epoch [2287/3000], Step [30/158]| g_loss: 0.667| d_loss: 0.635| gp_loss: 0.151| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.284 | a_loss: 0.537
Train: Epoch [2287/3000], Step [60/158]| g_loss: 0.678| d_loss: 0.688| gp_loss: 0.048| r_loss: 0.052| p_loss: 0.072| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.541
Train: Epoch [2287/3000], Step [90/158]| g_loss: 0.608| d_loss: 0.625| gp_loss: 0.052| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.472
Train: Epoch [2287/3000], Step [120/158]| g_loss: 0.687| d_loss: 0.509| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.557
Train: Epoch [2287/3000], Step [150/158]| g_loss: 0.660| d_loss: 0.674| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.066| v_loss: 0.020| per_loss: 0.280 | a_loss: 0.528
Train: Epoch [2288/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.657| gp_loss: 0.135| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.283 | a_loss: 0.534
Train: Epoch [2288/3000], Step [60/158]| g_loss: 0.657| d_loss: 0.657| gp_loss: 0.051| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.524
Train: Epoch [2288/3000], Step [90/158]| g_loss: 0.632| d_loss: 0.575| gp_loss: 0.058| r_loss: 0.053| p_loss: 0.068| v_loss: 0.020| per_loss: 0.280 | a_loss: 0.497
Train: Epoch [2288/3000], Step [120/158]| g_loss: 0.634| d_loss: 0.711| gp_loss: 0.054| r_loss: 0.051| p_loss: 0.064| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.504
Train: Epoch [2288/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.572| gp_loss: 0.061| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.282 | a_loss: 0.537
Train: Epoch [2289/3000], Step [30/158]| g_loss: 0.642| d_loss: 0.669| gp_loss: 0.088| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.283 | a_loss: 0.510
Train: Epoch [2289/3000], Step [60/158]| g_loss: 0.661| d_loss: 0.646| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.276 | a_loss: 0.534
Train: Epoch [2289/3000], Step [90/158]| g_loss: 0.646| d_loss: 0.582| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.513
Train: Epoch [2289/3000], Step [120/158]| g_loss: 0.652| d_loss: 0.690| gp_loss: 0.060| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.520
Train: Epoch [2289/3000], Step [150/158]| g_loss: 0.650| d_loss: 0.571| gp_loss: 0.064| r_loss: 0.051| p_loss: 0.066| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.518
Train: Epoch [2290/3000], Step [30/158]| g_loss: 0.650| d_loss: 0.753| gp_loss: 0.180| r_loss: 0.055| p_loss: 0.071| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.512
Train: Epoch [2290/3000], Step [60/158]| g_loss: 0.654| d_loss: 0.572| gp_loss: 0.057| r_loss: 0.055| p_loss: 0.071| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.514
Train: Epoch [2290/3000], Step [90/158]| g_loss: 0.663| d_loss: 0.609| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.274 | a_loss: 0.533
Train: Epoch [2290/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.587| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.547
Train: Epoch [2290/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.646| gp_loss: 0.061| r_loss: 0.053| p_loss: 0.067| v_loss: 0.020| per_loss: 0.279 | a_loss: 0.534
Train: Epoch [2291/3000], Step [30/158]| g_loss: 0.671| d_loss: 0.772| gp_loss: 0.180| r_loss: 0.051| p_loss: 0.073| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.534
Train: Epoch [2291/3000], Step [60/158]| g_loss: 0.644| d_loss: 0.653| gp_loss: 0.052| r_loss: 0.052| p_loss: 0.076| v_loss: 0.021| per_loss: 0.289 | a_loss: 0.504
Train: Epoch [2291/3000], Step [90/158]| g_loss: 0.638| d_loss: 0.641| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.068| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.504
Train: Epoch [2291/3000], Step [120/158]| g_loss: 0.638| d_loss: 0.668| gp_loss: 0.057| r_loss: 0.052| p_loss: 0.070| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.502
Train: Epoch [2291/3000], Step [150/158]| g_loss: 0.684| d_loss: 0.520| gp_loss: 0.060| r_loss: 0.052| p_loss: 0.067| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.549
Train: Epoch [2292/3000], Step [30/158]| g_loss: 0.682| d_loss: 0.692| gp_loss: 0.151| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.552
Train: Epoch [2292/3000], Step [60/158]| g_loss: 0.656| d_loss: 0.613| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.525
Train: Epoch [2292/3000], Step [90/158]| g_loss: 0.676| d_loss: 0.582| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.276 | a_loss: 0.549
Train: Epoch [2292/3000], Step [120/158]| g_loss: 0.629| d_loss: 0.679| gp_loss: 0.057| r_loss: 0.056| p_loss: 0.071| v_loss: 0.021| per_loss: 0.286 | a_loss: 0.488
Train: Epoch [2292/3000], Step [150/158]| g_loss: 0.641| d_loss: 0.589| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.510
Train: Epoch [2293/3000], Step [30/158]| g_loss: 0.655| d_loss: 0.688| gp_loss: 0.128| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.519
Train: Epoch [2293/3000], Step [60/158]| g_loss: 0.621| d_loss: 0.739| gp_loss: 0.060| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.278 | a_loss: 0.487
Train: Epoch [2293/3000], Step [90/158]| g_loss: 0.648| d_loss: 0.550| gp_loss: 0.061| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.518
Train: Epoch [2293/3000], Step [120/158]| g_loss: 0.719| d_loss: 0.570| gp_loss: 0.063| r_loss: 0.051| p_loss: 0.066| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.584
Train: Epoch [2293/3000], Step [150/158]| g_loss: 0.674| d_loss: 0.604| gp_loss: 0.061| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.541
Train: Epoch [2294/3000], Step [30/158]| g_loss: 0.630| d_loss: 0.780| gp_loss: 0.148| r_loss: 0.053| p_loss: 0.077| v_loss: 0.020| per_loss: 0.281 | a_loss: 0.490
Train: Epoch [2294/3000], Step [60/158]| g_loss: 0.587| d_loss: 0.755| gp_loss: 0.059| r_loss: 0.051| p_loss: 0.071| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.452
Train: Epoch [2294/3000], Step [90/158]| g_loss: 0.640| d_loss: 0.543| gp_loss: 0.060| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.277 | a_loss: 0.509
Train: Epoch [2294/3000], Step [120/158]| g_loss: 0.676| d_loss: 0.610| gp_loss: 0.062| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.543
Train: Epoch [2294/3000], Step [150/158]| g_loss: 0.654| d_loss: 0.559| gp_loss: 0.062| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.523
Train: Epoch [2295/3000], Step [30/158]| g_loss: 0.668| d_loss: 0.723| gp_loss: 0.158| r_loss: 0.050| p_loss: 0.064| v_loss: 0.020| per_loss: 0.278 | a_loss: 0.539
Train: Epoch [2295/3000], Step [60/158]| g_loss: 0.654| d_loss: 0.641| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.069| v_loss: 0.019| per_loss: 0.279 | a_loss: 0.523
Train: Epoch [2295/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.571| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.065| v_loss: 0.018| per_loss: 0.282 | a_loss: 0.525
Train: Epoch [2295/3000], Step [120/158]| g_loss: 0.723| d_loss: 0.515| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.065| v_loss: 0.021| per_loss: 0.296 | a_loss: 0.590
Train: Epoch [2295/3000], Step [150/158]| g_loss: 0.657| d_loss: 0.671| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.524
Train: Epoch [2296/3000], Step [30/158]| g_loss: 0.610| d_loss: 0.813| gp_loss: 0.186| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.479
Train: Epoch [2296/3000], Step [60/158]| g_loss: 0.668| d_loss: 0.541| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.066| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.534
Train: Epoch [2296/3000], Step [90/158]| g_loss: 0.626| d_loss: 0.710| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.067| v_loss: 0.020| per_loss: 0.278 | a_loss: 0.496
Train: Epoch [2296/3000], Step [120/158]| g_loss: 0.627| d_loss: 0.550| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.282 | a_loss: 0.497
Train: Epoch [2296/3000], Step [150/158]| g_loss: 0.672| d_loss: 0.608| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.542
Train: Epoch [2297/3000], Step [30/158]| g_loss: 0.667| d_loss: 0.656| gp_loss: 0.153| r_loss: 0.049| p_loss: 0.060| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.540
Train: Epoch [2297/3000], Step [60/158]| g_loss: 0.659| d_loss: 0.664| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.067| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.527
Train: Epoch [2297/3000], Step [90/158]| g_loss: 0.662| d_loss: 0.578| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.531
Train: Epoch [2297/3000], Step [120/158]| g_loss: 0.638| d_loss: 0.628| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.510
Train: Epoch [2297/3000], Step [150/158]| g_loss: 0.636| d_loss: 0.675| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.503
Train: Epoch [2298/3000], Step [30/158]| g_loss: 0.634| d_loss: 0.770| gp_loss: 0.168| r_loss: 0.052| p_loss: 0.067| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.500
Train: Epoch [2298/3000], Step [60/158]| g_loss: 0.623| d_loss: 0.628| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.070| v_loss: 0.020| per_loss: 0.280 | a_loss: 0.491
Train: Epoch [2298/3000], Step [90/158]| g_loss: 0.650| d_loss: 0.632| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.513
Train: Epoch [2298/3000], Step [120/158]| g_loss: 0.652| d_loss: 0.583| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.069| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.519
Train: Epoch [2298/3000], Step [150/158]| g_loss: 0.691| d_loss: 0.622| gp_loss: 0.057| r_loss: 0.052| p_loss: 0.069| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.556
Train: Epoch [2299/3000], Step [30/158]| g_loss: 0.661| d_loss: 0.679| gp_loss: 0.127| r_loss: 0.052| p_loss: 0.072| v_loss: 0.020| per_loss: 0.281 | a_loss: 0.525
Train: Epoch [2299/3000], Step [60/158]| g_loss: 0.621| d_loss: 0.649| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.490
Train: Epoch [2299/3000], Step [90/158]| g_loss: 0.642| d_loss: 0.662| gp_loss: 0.056| r_loss: 0.053| p_loss: 0.069| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.506
Train: Epoch [2299/3000], Step [120/158]| g_loss: 0.695| d_loss: 0.517| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.073| v_loss: 0.021| per_loss: 0.279 | a_loss: 0.555
Train: Epoch [2299/3000], Step [150/158]| g_loss: 0.667| d_loss: 0.621| gp_loss: 0.057| r_loss: 0.052| p_loss: 0.069| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.533
Train: Epoch [2300/3000], Step [30/158]| g_loss: 0.664| d_loss: 0.691| gp_loss: 0.090| r_loss: 0.057| p_loss: 0.078| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.520
Train: Epoch [2300/3000], Step [60/158]| g_loss: 0.659| d_loss: 0.613| gp_loss: 0.059| r_loss: 0.054| p_loss: 0.076| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.518
Train: Epoch [2300/3000], Step [90/158]| g_loss: 0.666| d_loss: 0.639| gp_loss: 0.059| r_loss: 0.063| p_loss: 0.078| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.514
Train: Epoch [2300/3000], Step [120/158]| g_loss: 0.657| d_loss: 0.657| gp_loss: 0.061| r_loss: 0.052| p_loss: 0.070| v_loss: 0.019| per_loss: 0.274 | a_loss: 0.524
Train: Epoch [2300/3000], Step [150/158]| g_loss: 0.648| d_loss: 0.584| gp_loss: 0.061| r_loss: 0.053| p_loss: 0.071| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.510
Test: Epoch [2300/3000]| g_loss: 0.631| r_loss: 0.387| p_loss: 0.309| v_loss: 0.022
Train: Epoch [2301/3000], Step [30/158]| g_loss: 0.700| d_loss: 0.564| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.070| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.566
Train: Epoch [2301/3000], Step [60/158]| g_loss: 0.681| d_loss: 0.602| gp_loss: 0.055| r_loss: 0.054| p_loss: 0.067| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.546
Train: Epoch [2301/3000], Step [90/158]| g_loss: 0.683| d_loss: 0.620| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.554
Train: Epoch [2301/3000], Step [120/158]| g_loss: 0.638| d_loss: 0.620| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.505
Train: Epoch [2301/3000], Step [150/158]| g_loss: 0.650| d_loss: 0.648| gp_loss: 0.055| r_loss: 0.052| p_loss: 0.069| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.513
Train: Epoch [2302/3000], Step [30/158]| g_loss: 0.631| d_loss: 0.730| gp_loss: 0.153| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.502
Train: Epoch [2302/3000], Step [60/158]| g_loss: 0.666| d_loss: 0.522| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.539
Train: Epoch [2302/3000], Step [90/158]| g_loss: 0.688| d_loss: 0.541| gp_loss: 0.059| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.553
Train: Epoch [2302/3000], Step [120/158]| g_loss: 0.664| d_loss: 0.696| gp_loss: 0.056| r_loss: 0.053| p_loss: 0.068| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.529
Train: Epoch [2302/3000], Step [150/158]| g_loss: 0.668| d_loss: 0.659| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.536
Train: Epoch [2303/3000], Step [30/158]| g_loss: 0.605| d_loss: 0.781| gp_loss: 0.143| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.474
Train: Epoch [2303/3000], Step [60/158]| g_loss: 0.670| d_loss: 0.539| gp_loss: 0.059| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.536
Train: Epoch [2303/3000], Step [90/158]| g_loss: 0.631| d_loss: 0.691| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.071| v_loss: 0.020| per_loss: 0.282 | a_loss: 0.496
Train: Epoch [2303/3000], Step [120/158]| g_loss: 0.643| d_loss: 0.634| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.069| v_loss: 0.019| per_loss: 0.276 | a_loss: 0.511
Train: Epoch [2303/3000], Step [150/158]| g_loss: 0.682| d_loss: 0.532| gp_loss: 0.062| r_loss: 0.051| p_loss: 0.066| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.548
Train: Epoch [2304/3000], Step [30/158]| g_loss: 0.653| d_loss: 0.692| gp_loss: 0.155| r_loss: 0.051| p_loss: 0.066| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.521
Train: Epoch [2304/3000], Step [60/158]| g_loss: 0.688| d_loss: 0.592| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.561
Train: Epoch [2304/3000], Step [90/158]| g_loss: 0.636| d_loss: 0.632| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.067| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.505
Train: Epoch [2304/3000], Step [120/158]| g_loss: 0.653| d_loss: 0.594| gp_loss: 0.060| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.521
Train: Epoch [2304/3000], Step [150/158]| g_loss: 0.674| d_loss: 0.683| gp_loss: 0.059| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.276 | a_loss: 0.542
Train: Epoch [2305/3000], Step [30/158]| g_loss: 0.622| d_loss: 0.696| gp_loss: 0.124| r_loss: 0.051| p_loss: 0.071| v_loss: 0.021| per_loss: 0.286 | a_loss: 0.485
Train: Epoch [2305/3000], Step [60/158]| g_loss: 0.708| d_loss: 0.507| gp_loss: 0.059| r_loss: 0.052| p_loss: 0.068| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.573
Train: Epoch [2305/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.674| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.527
Train: Epoch [2305/3000], Step [120/158]| g_loss: 0.616| d_loss: 0.670| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.487
Train: Epoch [2305/3000], Step [150/158]| g_loss: 0.645| d_loss: 0.623| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.281 | a_loss: 0.516
Train: Epoch [2306/3000], Step [30/158]| g_loss: 0.665| d_loss: 0.716| gp_loss: 0.177| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.535
Train: Epoch [2306/3000], Step [60/158]| g_loss: 0.644| d_loss: 0.636| gp_loss: 0.052| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.284 | a_loss: 0.512
Train: Epoch [2306/3000], Step [90/158]| g_loss: 0.681| d_loss: 0.612| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.068| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.549
Train: Epoch [2306/3000], Step [120/158]| g_loss: 0.651| d_loss: 0.601| gp_loss: 0.061| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.272 | a_loss: 0.521
Train: Epoch [2306/3000], Step [150/158]| g_loss: 0.670| d_loss: 0.659| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.535
Train: Epoch [2307/3000], Step [30/158]| g_loss: 0.687| d_loss: 0.649| gp_loss: 0.152| r_loss: 0.050| p_loss: 0.069| v_loss: 0.021| per_loss: 0.282 | a_loss: 0.553
Train: Epoch [2307/3000], Step [60/158]| g_loss: 0.632| d_loss: 0.648| gp_loss: 0.049| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.499
Train: Epoch [2307/3000], Step [90/158]| g_loss: 0.662| d_loss: 0.644| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.068| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.529
Train: Epoch [2307/3000], Step [120/158]| g_loss: 0.647| d_loss: 0.574| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.065| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.514
Train: Epoch [2307/3000], Step [150/158]| g_loss: 0.679| d_loss: 0.641| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.547
Train: Epoch [2308/3000], Step [30/158]| g_loss: 0.679| d_loss: 0.681| gp_loss: 0.167| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.550
Train: Epoch [2308/3000], Step [60/158]| g_loss: 0.644| d_loss: 0.635| gp_loss: 0.052| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.282 | a_loss: 0.511
Train: Epoch [2308/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.596| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.525
Train: Epoch [2308/3000], Step [120/158]| g_loss: 0.632| d_loss: 0.671| gp_loss: 0.056| r_loss: 0.053| p_loss: 0.066| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.497
Train: Epoch [2308/3000], Step [150/158]| g_loss: 0.656| d_loss: 0.599| gp_loss: 0.059| r_loss: 0.051| p_loss: 0.066| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.524
Train: Epoch [2309/3000], Step [30/158]| g_loss: 0.656| d_loss: 0.734| gp_loss: 0.148| r_loss: 0.055| p_loss: 0.070| v_loss: 0.021| per_loss: 0.290 | a_loss: 0.516
Train: Epoch [2309/3000], Step [60/158]| g_loss: 0.615| d_loss: 0.644| gp_loss: 0.052| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.483
Train: Epoch [2309/3000], Step [90/158]| g_loss: 0.661| d_loss: 0.569| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.533
Train: Epoch [2309/3000], Step [120/158]| g_loss: 0.652| d_loss: 0.613| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.281 | a_loss: 0.518
Train: Epoch [2309/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.637| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.543
Train: Epoch [2310/3000], Step [30/158]| g_loss: 0.672| d_loss: 0.673| gp_loss: 0.142| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.543
Train: Epoch [2310/3000], Step [60/158]| g_loss: 0.658| d_loss: 0.565| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.528
Train: Epoch [2310/3000], Step [90/158]| g_loss: 0.693| d_loss: 0.559| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.562
Train: Epoch [2310/3000], Step [120/158]| g_loss: 0.650| d_loss: 0.731| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.519
Train: Epoch [2310/3000], Step [150/158]| g_loss: 0.647| d_loss: 0.612| gp_loss: 0.060| r_loss: 0.051| p_loss: 0.069| v_loss: 0.021| per_loss: 0.288 | a_loss: 0.512
Train: Epoch [2311/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.749| gp_loss: 0.209| r_loss: 0.054| p_loss: 0.073| v_loss: 0.021| per_loss: 0.296 | a_loss: 0.511
Train: Epoch [2311/3000], Step [60/158]| g_loss: 0.710| d_loss: 0.480| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.066| v_loss: 0.021| per_loss: 0.292 | a_loss: 0.579
Train: Epoch [2311/3000], Step [90/158]| g_loss: 0.682| d_loss: 0.626| gp_loss: 0.051| r_loss: 0.053| p_loss: 0.070| v_loss: 0.019| per_loss: 0.277 | a_loss: 0.547
Train: Epoch [2311/3000], Step [120/158]| g_loss: 0.655| d_loss: 0.699| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.068| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.522
Train: Epoch [2311/3000], Step [150/158]| g_loss: 0.620| d_loss: 0.709| gp_loss: 0.052| r_loss: 0.052| p_loss: 0.070| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.485
Train: Epoch [2312/3000], Step [30/158]| g_loss: 0.660| d_loss: 0.674| gp_loss: 0.165| r_loss: 0.054| p_loss: 0.074| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.521
Train: Epoch [2312/3000], Step [60/158]| g_loss: 0.686| d_loss: 0.659| gp_loss: 0.051| r_loss: 0.056| p_loss: 0.077| v_loss: 0.020| per_loss: 0.284 | a_loss: 0.543
Train: Epoch [2312/3000], Step [90/158]| g_loss: 0.650| d_loss: 0.586| gp_loss: 0.054| r_loss: 0.061| p_loss: 0.081| v_loss: 0.020| per_loss: 0.283 | a_loss: 0.501
Train: Epoch [2312/3000], Step [120/158]| g_loss: 0.685| d_loss: 0.611| gp_loss: 0.052| r_loss: 0.067| p_loss: 0.080| v_loss: 0.020| per_loss: 0.279 | a_loss: 0.530
Train: Epoch [2312/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.687| gp_loss: 0.054| r_loss: 0.057| p_loss: 0.082| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.511
Train: Epoch [2313/3000], Step [30/158]| g_loss: 0.627| d_loss: 0.782| gp_loss: 0.093| r_loss: 0.054| p_loss: 0.076| v_loss: 0.021| per_loss: 0.298 | a_loss: 0.485
Train: Epoch [2313/3000], Step [60/158]| g_loss: 0.645| d_loss: 0.614| gp_loss: 0.056| r_loss: 0.054| p_loss: 0.071| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.507
Train: Epoch [2313/3000], Step [90/158]| g_loss: 0.648| d_loss: 0.591| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.071| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.514
Train: Epoch [2313/3000], Step [120/158]| g_loss: 0.653| d_loss: 0.592| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.070| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.517
Train: Epoch [2313/3000], Step [150/158]| g_loss: 0.680| d_loss: 0.545| gp_loss: 0.058| r_loss: 0.053| p_loss: 0.072| v_loss: 0.021| per_loss: 0.295 | a_loss: 0.541
Train: Epoch [2314/3000], Step [30/158]| g_loss: 0.624| d_loss: 0.811| gp_loss: 0.148| r_loss: 0.051| p_loss: 0.069| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.491
Train: Epoch [2314/3000], Step [60/158]| g_loss: 0.658| d_loss: 0.559| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.527
Train: Epoch [2314/3000], Step [90/158]| g_loss: 0.669| d_loss: 0.595| gp_loss: 0.052| r_loss: 0.052| p_loss: 0.070| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.533
Train: Epoch [2314/3000], Step [120/158]| g_loss: 0.654| d_loss: 0.615| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.519
Train: Epoch [2314/3000], Step [150/158]| g_loss: 0.691| d_loss: 0.574| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.563
Train: Epoch [2315/3000], Step [30/158]| g_loss: 0.688| d_loss: 0.655| gp_loss: 0.087| r_loss: 0.051| p_loss: 0.076| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.551
Train: Epoch [2315/3000], Step [60/158]| g_loss: 0.632| d_loss: 0.750| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.073| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.496
Train: Epoch [2315/3000], Step [90/158]| g_loss: 0.616| d_loss: 0.517| gp_loss: 0.061| r_loss: 0.048| p_loss: 0.066| v_loss: 0.020| per_loss: 0.283 | a_loss: 0.488
Train: Epoch [2315/3000], Step [120/158]| g_loss: 0.679| d_loss: 0.668| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.070| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.543
Train: Epoch [2315/3000], Step [150/158]| g_loss: 0.666| d_loss: 0.567| gp_loss: 0.063| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.535
Train: Epoch [2316/3000], Step [30/158]| g_loss: 0.657| d_loss: 0.755| gp_loss: 0.224| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.522
Train: Epoch [2316/3000], Step [60/158]| g_loss: 0.662| d_loss: 0.688| gp_loss: 0.050| r_loss: 0.048| p_loss: 0.067| v_loss: 0.020| per_loss: 0.284 | a_loss: 0.531
Train: Epoch [2316/3000], Step [90/158]| g_loss: 0.618| d_loss: 0.625| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.487
Train: Epoch [2316/3000], Step [120/158]| g_loss: 0.635| d_loss: 0.667| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.506
Train: Epoch [2316/3000], Step [150/158]| g_loss: 0.670| d_loss: 0.613| gp_loss: 0.059| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.536
Train: Epoch [2317/3000], Step [30/158]| g_loss: 0.656| d_loss: 0.635| gp_loss: 0.088| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.526
Train: Epoch [2317/3000], Step [60/158]| g_loss: 0.652| d_loss: 0.620| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.064| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.521
Train: Epoch [2317/3000], Step [90/158]| g_loss: 0.655| d_loss: 0.628| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.524
Train: Epoch [2317/3000], Step [120/158]| g_loss: 0.653| d_loss: 0.640| gp_loss: 0.061| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.275 | a_loss: 0.524
Train: Epoch [2317/3000], Step [150/158]| g_loss: 0.651| d_loss: 0.670| gp_loss: 0.059| r_loss: 0.051| p_loss: 0.065| v_loss: 0.020| per_loss: 0.283 | a_loss: 0.519
Train: Epoch [2318/3000], Step [30/158]| g_loss: 0.661| d_loss: 0.705| gp_loss: 0.160| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.527
Train: Epoch [2318/3000], Step [60/158]| g_loss: 0.620| d_loss: 0.679| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.069| v_loss: 0.020| per_loss: 0.284 | a_loss: 0.488
Train: Epoch [2318/3000], Step [90/158]| g_loss: 0.637| d_loss: 0.624| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.066| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.504
Train: Epoch [2318/3000], Step [120/158]| g_loss: 0.667| d_loss: 0.531| gp_loss: 0.059| r_loss: 0.051| p_loss: 0.062| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.538
Train: Epoch [2318/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.674| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.535
Train: Epoch [2319/3000], Step [30/158]| g_loss: 0.620| d_loss: 0.780| gp_loss: 0.147| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.490
Train: Epoch [2319/3000], Step [60/158]| g_loss: 0.632| d_loss: 0.545| gp_loss: 0.055| r_loss: 0.051| p_loss: 0.064| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.501
Train: Epoch [2319/3000], Step [90/158]| g_loss: 0.678| d_loss: 0.572| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.550
Train: Epoch [2319/3000], Step [120/158]| g_loss: 0.660| d_loss: 0.676| gp_loss: 0.054| r_loss: 0.051| p_loss: 0.066| v_loss: 0.019| per_loss: 0.277 | a_loss: 0.530
Train: Epoch [2319/3000], Step [150/158]| g_loss: 0.671| d_loss: 0.582| gp_loss: 0.059| r_loss: 0.052| p_loss: 0.065| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.536
Train: Epoch [2320/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.654| gp_loss: 0.183| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.276 | a_loss: 0.536
Train: Epoch [2320/3000], Step [60/158]| g_loss: 0.677| d_loss: 0.681| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.549
Train: Epoch [2320/3000], Step [90/158]| g_loss: 0.615| d_loss: 0.624| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.275 | a_loss: 0.490
Train: Epoch [2320/3000], Step [120/158]| g_loss: 0.669| d_loss: 0.634| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.065| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.537
Train: Epoch [2320/3000], Step [150/158]| g_loss: 0.617| d_loss: 0.611| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.486
Train: Epoch [2321/3000], Step [30/158]| g_loss: 0.619| d_loss: 0.872| gp_loss: 0.200| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.488
Train: Epoch [2321/3000], Step [60/158]| g_loss: 0.628| d_loss: 0.597| gp_loss: 0.048| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.504
Train: Epoch [2321/3000], Step [90/158]| g_loss: 0.663| d_loss: 0.585| gp_loss: 0.052| r_loss: 0.051| p_loss: 0.065| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.532
Train: Epoch [2321/3000], Step [120/158]| g_loss: 0.662| d_loss: 0.579| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.063| v_loss: 0.020| per_loss: 0.273 | a_loss: 0.534
Train: Epoch [2321/3000], Step [150/158]| g_loss: 0.674| d_loss: 0.591| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.548
Train: Epoch [2322/3000], Step [30/158]| g_loss: 0.692| d_loss: 0.620| gp_loss: 0.127| r_loss: 0.050| p_loss: 0.064| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.562
Train: Epoch [2322/3000], Step [60/158]| g_loss: 0.653| d_loss: 0.629| gp_loss: 0.051| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.278 | a_loss: 0.529
Train: Epoch [2322/3000], Step [90/158]| g_loss: 0.626| d_loss: 0.695| gp_loss: 0.051| r_loss: 0.052| p_loss: 0.068| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.491
Train: Epoch [2322/3000], Step [120/158]| g_loss: 0.651| d_loss: 0.564| gp_loss: 0.055| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.519
Train: Epoch [2322/3000], Step [150/158]| g_loss: 0.677| d_loss: 0.624| gp_loss: 0.055| r_loss: 0.052| p_loss: 0.069| v_loss: 0.020| per_loss: 0.273 | a_loss: 0.544
Train: Epoch [2323/3000], Step [30/158]| g_loss: 0.679| d_loss: 0.665| gp_loss: 0.159| r_loss: 0.050| p_loss: 0.064| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.547
Train: Epoch [2323/3000], Step [60/158]| g_loss: 0.653| d_loss: 0.621| gp_loss: 0.051| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.523
Train: Epoch [2323/3000], Step [90/158]| g_loss: 0.635| d_loss: 0.678| gp_loss: 0.051| r_loss: 0.046| p_loss: 0.063| v_loss: 0.019| per_loss: 0.277 | a_loss: 0.512
Train: Epoch [2323/3000], Step [120/158]| g_loss: 0.641| d_loss: 0.669| gp_loss: 0.055| r_loss: 0.052| p_loss: 0.066| v_loss: 0.019| per_loss: 0.279 | a_loss: 0.509
Train: Epoch [2323/3000], Step [150/158]| g_loss: 0.654| d_loss: 0.544| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.523
Train: Epoch [2324/3000], Step [30/158]| g_loss: 0.641| d_loss: 0.822| gp_loss: 0.231| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.276 | a_loss: 0.511
Train: Epoch [2324/3000], Step [60/158]| g_loss: 0.668| d_loss: 0.593| gp_loss: 0.049| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.539
Train: Epoch [2324/3000], Step [90/158]| g_loss: 0.629| d_loss: 0.707| gp_loss: 0.048| r_loss: 0.049| p_loss: 0.067| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.497
Train: Epoch [2324/3000], Step [120/158]| g_loss: 0.640| d_loss: 0.592| gp_loss: 0.052| r_loss: 0.053| p_loss: 0.066| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.505
Train: Epoch [2324/3000], Step [150/158]| g_loss: 0.649| d_loss: 0.579| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.518
Train: Epoch [2325/3000], Step [30/158]| g_loss: 0.713| d_loss: 0.667| gp_loss: 0.144| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.583
Train: Epoch [2325/3000], Step [60/158]| g_loss: 0.652| d_loss: 0.684| gp_loss: 0.049| r_loss: 0.051| p_loss: 0.069| v_loss: 0.019| per_loss: 0.278 | a_loss: 0.519
Train: Epoch [2325/3000], Step [90/158]| g_loss: 0.624| d_loss: 0.628| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.491
Train: Epoch [2325/3000], Step [120/158]| g_loss: 0.648| d_loss: 0.549| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.514
Train: Epoch [2325/3000], Step [150/158]| g_loss: 0.677| d_loss: 0.623| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.068| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.543
Train: Epoch [2326/3000], Step [30/158]| g_loss: 0.637| d_loss: 0.867| gp_loss: 0.279| r_loss: 0.049| p_loss: 0.069| v_loss: 0.018| per_loss: 0.284 | a_loss: 0.507
Train: Epoch [2326/3000], Step [60/158]| g_loss: 0.623| d_loss: 0.681| gp_loss: 0.048| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.277 | a_loss: 0.495
Train: Epoch [2326/3000], Step [90/158]| g_loss: 0.663| d_loss: 0.568| gp_loss: 0.049| r_loss: 0.052| p_loss: 0.066| v_loss: 0.020| per_loss: 0.283 | a_loss: 0.530
Train: Epoch [2326/3000], Step [120/158]| g_loss: 0.631| d_loss: 0.620| gp_loss: 0.047| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.503
Train: Epoch [2326/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.572| gp_loss: 0.051| r_loss: 0.050| p_loss: 0.063| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.532
Train: Epoch [2327/3000], Step [30/158]| g_loss: 0.664| d_loss: 0.699| gp_loss: 0.152| r_loss: 0.051| p_loss: 0.062| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.535
Train: Epoch [2327/3000], Step [60/158]| g_loss: 0.644| d_loss: 0.697| gp_loss: 0.048| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.512
Train: Epoch [2327/3000], Step [90/158]| g_loss: 0.611| d_loss: 0.620| gp_loss: 0.051| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.485
Train: Epoch [2327/3000], Step [120/158]| g_loss: 0.639| d_loss: 0.543| gp_loss: 0.052| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.279 | a_loss: 0.510
Train: Epoch [2327/3000], Step [150/158]| g_loss: 0.704| d_loss: 0.572| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.065| v_loss: 0.020| per_loss: 0.282 | a_loss: 0.577
Train: Epoch [2328/3000], Step [30/158]| g_loss: 0.674| d_loss: 0.752| gp_loss: 0.160| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.542
Train: Epoch [2328/3000], Step [60/158]| g_loss: 0.616| d_loss: 0.659| gp_loss: 0.048| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.489
Train: Epoch [2328/3000], Step [90/158]| g_loss: 0.653| d_loss: 0.527| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.519
Train: Epoch [2328/3000], Step [120/158]| g_loss: 0.696| d_loss: 0.603| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.565
Train: Epoch [2328/3000], Step [150/158]| g_loss: 0.653| d_loss: 0.700| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.065| v_loss: 0.018| per_loss: 0.276 | a_loss: 0.527
Train: Epoch [2329/3000], Step [30/158]| g_loss: 0.670| d_loss: 0.670| gp_loss: 0.154| r_loss: 0.050| p_loss: 0.064| v_loss: 0.020| per_loss: 0.265 | a_loss: 0.541
Train: Epoch [2329/3000], Step [60/158]| g_loss: 0.639| d_loss: 0.598| gp_loss: 0.049| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.510
Train: Epoch [2329/3000], Step [90/158]| g_loss: 0.655| d_loss: 0.600| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.529
Train: Epoch [2329/3000], Step [120/158]| g_loss: 0.616| d_loss: 0.669| gp_loss: 0.051| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.485
Train: Epoch [2329/3000], Step [150/158]| g_loss: 0.688| d_loss: 0.613| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.276 | a_loss: 0.557
Train: Epoch [2330/3000], Step [30/158]| g_loss: 0.645| d_loss: 0.685| gp_loss: 0.159| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.312 | a_loss: 0.511
Train: Epoch [2330/3000], Step [60/158]| g_loss: 0.645| d_loss: 0.633| gp_loss: 0.051| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.282 | a_loss: 0.518
Train: Epoch [2330/3000], Step [90/158]| g_loss: 0.644| d_loss: 0.621| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.516
Train: Epoch [2330/3000], Step [120/158]| g_loss: 0.640| d_loss: 0.615| gp_loss: 0.055| r_loss: 0.051| p_loss: 0.065| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.510
Train: Epoch [2330/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.646| gp_loss: 0.059| r_loss: 0.051| p_loss: 0.065| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.539
Train: Epoch [2331/3000], Step [30/158]| g_loss: 0.635| d_loss: 0.695| gp_loss: 0.094| r_loss: 0.053| p_loss: 0.072| v_loss: 0.021| per_loss: 0.282 | a_loss: 0.497
Train: Epoch [2331/3000], Step [60/158]| g_loss: 0.623| d_loss: 0.633| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.068| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.493
Train: Epoch [2331/3000], Step [90/158]| g_loss: 0.659| d_loss: 0.631| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.069| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.525
Train: Epoch [2331/3000], Step [120/158]| g_loss: 0.656| d_loss: 0.623| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.526
Train: Epoch [2331/3000], Step [150/158]| g_loss: 0.666| d_loss: 0.577| gp_loss: 0.061| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.531
Train: Epoch [2332/3000], Step [30/158]| g_loss: 0.627| d_loss: 0.722| gp_loss: 0.129| r_loss: 0.049| p_loss: 0.069| v_loss: 0.019| per_loss: 0.273 | a_loss: 0.497
Train: Epoch [2332/3000], Step [60/158]| g_loss: 0.679| d_loss: 0.569| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.551
Train: Epoch [2332/3000], Step [90/158]| g_loss: 0.653| d_loss: 0.680| gp_loss: 0.055| r_loss: 0.052| p_loss: 0.072| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.515
Train: Epoch [2332/3000], Step [120/158]| g_loss: 0.712| d_loss: 0.552| gp_loss: 0.061| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.576
Train: Epoch [2332/3000], Step [150/158]| g_loss: 0.645| d_loss: 0.626| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.511
Train: Epoch [2333/3000], Step [30/158]| g_loss: 0.644| d_loss: 0.806| gp_loss: 0.184| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.515
Train: Epoch [2333/3000], Step [60/158]| g_loss: 0.645| d_loss: 0.598| gp_loss: 0.051| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.513
Train: Epoch [2333/3000], Step [90/158]| g_loss: 0.653| d_loss: 0.615| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.069| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.520
Train: Epoch [2333/3000], Step [120/158]| g_loss: 0.654| d_loss: 0.592| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.274 | a_loss: 0.525
Train: Epoch [2333/3000], Step [150/158]| g_loss: 0.684| d_loss: 0.603| gp_loss: 0.060| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.551
Train: Epoch [2334/3000], Step [30/158]| g_loss: 0.627| d_loss: 0.806| gp_loss: 0.184| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.498
Train: Epoch [2334/3000], Step [60/158]| g_loss: 0.713| d_loss: 0.457| gp_loss: 0.052| r_loss: 0.059| p_loss: 0.074| v_loss: 0.020| per_loss: 0.282 | a_loss: 0.569
Train: Epoch [2334/3000], Step [90/158]| g_loss: 0.672| d_loss: 0.650| gp_loss: 0.049| r_loss: 0.057| p_loss: 0.075| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.529
Train: Epoch [2334/3000], Step [120/158]| g_loss: 0.654| d_loss: 0.571| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.069| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.516
Train: Epoch [2334/3000], Step [150/158]| g_loss: 0.674| d_loss: 0.668| gp_loss: 0.055| r_loss: 0.053| p_loss: 0.072| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.537
Train: Epoch [2335/3000], Step [30/158]| g_loss: 0.615| d_loss: 0.744| gp_loss: 0.119| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.486
Train: Epoch [2335/3000], Step [60/158]| g_loss: 0.657| d_loss: 0.555| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.276 | a_loss: 0.526
Train: Epoch [2335/3000], Step [90/158]| g_loss: 0.679| d_loss: 0.665| gp_loss: 0.055| r_loss: 0.051| p_loss: 0.070| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.544
Train: Epoch [2335/3000], Step [120/158]| g_loss: 0.646| d_loss: 0.676| gp_loss: 0.060| r_loss: 0.054| p_loss: 0.071| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.506
Train: Epoch [2335/3000], Step [150/158]| g_loss: 0.677| d_loss: 0.534| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.544
Train: Epoch [2336/3000], Step [30/158]| g_loss: 0.692| d_loss: 0.683| gp_loss: 0.136| r_loss: 0.050| p_loss: 0.070| v_loss: 0.020| per_loss: 0.280 | a_loss: 0.559
Train: Epoch [2336/3000], Step [60/158]| g_loss: 0.647| d_loss: 0.654| gp_loss: 0.050| r_loss: 0.052| p_loss: 0.069| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.513
Train: Epoch [2336/3000], Step [90/158]| g_loss: 0.615| d_loss: 0.710| gp_loss: 0.051| r_loss: 0.047| p_loss: 0.062| v_loss: 0.018| per_loss: 0.285 | a_loss: 0.490
Train: Epoch [2336/3000], Step [120/158]| g_loss: 0.672| d_loss: 0.542| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.067| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.537
Train: Epoch [2336/3000], Step [150/158]| g_loss: 0.728| d_loss: 0.540| gp_loss: 0.056| r_loss: 0.056| p_loss: 0.074| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.586
Train: Epoch [2337/3000], Step [30/158]| g_loss: 0.653| d_loss: 0.752| gp_loss: 0.178| r_loss: 0.051| p_loss: 0.069| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.520
Train: Epoch [2337/3000], Step [60/158]| g_loss: 0.679| d_loss: 0.551| gp_loss: 0.050| r_loss: 0.051| p_loss: 0.071| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.543
Train: Epoch [2337/3000], Step [90/158]| g_loss: 0.653| d_loss: 0.752| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.520
Train: Epoch [2337/3000], Step [120/158]| g_loss: 0.641| d_loss: 0.563| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.317 | a_loss: 0.508
Train: Epoch [2337/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.613| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.064| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.526
Train: Epoch [2338/3000], Step [30/158]| g_loss: 0.720| d_loss: 0.534| gp_loss: 0.117| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.587
Train: Epoch [2338/3000], Step [60/158]| g_loss: 0.692| d_loss: 0.673| gp_loss: 0.050| r_loss: 0.049| p_loss: 0.067| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.561
Train: Epoch [2338/3000], Step [90/158]| g_loss: 0.626| d_loss: 0.652| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.495
Train: Epoch [2338/3000], Step [120/158]| g_loss: 0.632| d_loss: 0.650| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.309 | a_loss: 0.497
Train: Epoch [2338/3000], Step [150/158]| g_loss: 0.634| d_loss: 0.652| gp_loss: 0.057| r_loss: 0.052| p_loss: 0.067| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.499
Train: Epoch [2339/3000], Step [30/158]| g_loss: 0.666| d_loss: 0.701| gp_loss: 0.188| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.536
Train: Epoch [2339/3000], Step [60/158]| g_loss: 0.657| d_loss: 0.648| gp_loss: 0.052| r_loss: 0.052| p_loss: 0.068| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.519
Train: Epoch [2339/3000], Step [90/158]| g_loss: 0.632| d_loss: 0.566| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.501
Train: Epoch [2339/3000], Step [120/158]| g_loss: 0.685| d_loss: 0.653| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.552
Train: Epoch [2339/3000], Step [150/158]| g_loss: 0.652| d_loss: 0.654| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.072| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.513
Train: Epoch [2340/3000], Step [30/158]| g_loss: 0.675| d_loss: 0.673| gp_loss: 0.164| r_loss: 0.052| p_loss: 0.068| v_loss: 0.020| per_loss: 0.316 | a_loss: 0.537
Train: Epoch [2340/3000], Step [60/158]| g_loss: 0.664| d_loss: 0.626| gp_loss: 0.051| r_loss: 0.052| p_loss: 0.072| v_loss: 0.021| per_loss: 0.290 | a_loss: 0.527
Train: Epoch [2340/3000], Step [90/158]| g_loss: 0.644| d_loss: 0.609| gp_loss: 0.054| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.511
Train: Epoch [2340/3000], Step [120/158]| g_loss: 0.695| d_loss: 0.609| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.562
Train: Epoch [2340/3000], Step [150/158]| g_loss: 0.665| d_loss: 0.602| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.537
Train: Epoch [2341/3000], Step [30/158]| g_loss: 0.635| d_loss: 0.782| gp_loss: 0.160| r_loss: 0.051| p_loss: 0.071| v_loss: 0.020| per_loss: 0.307 | a_loss: 0.499
Train: Epoch [2341/3000], Step [60/158]| g_loss: 0.670| d_loss: 0.604| gp_loss: 0.052| r_loss: 0.053| p_loss: 0.070| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.533
Train: Epoch [2341/3000], Step [90/158]| g_loss: 0.628| d_loss: 0.611| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.497
Train: Epoch [2341/3000], Step [120/158]| g_loss: 0.688| d_loss: 0.570| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.556
Train: Epoch [2341/3000], Step [150/158]| g_loss: 0.682| d_loss: 0.626| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.551
Train: Epoch [2342/3000], Step [30/158]| g_loss: 0.607| d_loss: 0.746| gp_loss: 0.108| r_loss: 0.050| p_loss: 0.072| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.470
Train: Epoch [2342/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.574| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.069| v_loss: 0.020| per_loss: 0.280 | a_loss: 0.541
Train: Epoch [2342/3000], Step [90/158]| g_loss: 0.641| d_loss: 0.618| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.508
Train: Epoch [2342/3000], Step [120/158]| g_loss: 0.647| d_loss: 0.697| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.066| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.515
Train: Epoch [2342/3000], Step [150/158]| g_loss: 0.630| d_loss: 0.609| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.498
Train: Epoch [2343/3000], Step [30/158]| g_loss: 0.666| d_loss: 0.764| gp_loss: 0.179| r_loss: 0.049| p_loss: 0.068| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.533
Train: Epoch [2343/3000], Step [60/158]| g_loss: 0.667| d_loss: 0.570| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.073| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.525
Train: Epoch [2343/3000], Step [90/158]| g_loss: 0.682| d_loss: 0.530| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.070| v_loss: 0.020| per_loss: 0.311 | a_loss: 0.545
Train: Epoch [2343/3000], Step [120/158]| g_loss: 0.694| d_loss: 0.688| gp_loss: 0.053| r_loss: 0.052| p_loss: 0.070| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.558
Train: Epoch [2343/3000], Step [150/158]| g_loss: 0.647| d_loss: 0.631| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.514
Train: Epoch [2344/3000], Step [30/158]| g_loss: 0.638| d_loss: 0.726| gp_loss: 0.164| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.503
Train: Epoch [2344/3000], Step [60/158]| g_loss: 0.630| d_loss: 0.725| gp_loss: 0.049| r_loss: 0.050| p_loss: 0.073| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.496
Train: Epoch [2344/3000], Step [90/158]| g_loss: 0.647| d_loss: 0.599| gp_loss: 0.054| r_loss: 0.051| p_loss: 0.065| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.515
Train: Epoch [2344/3000], Step [120/158]| g_loss: 0.704| d_loss: 0.510| gp_loss: 0.055| r_loss: 0.052| p_loss: 0.069| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.567
Train: Epoch [2344/3000], Step [150/158]| g_loss: 0.653| d_loss: 0.678| gp_loss: 0.053| r_loss: 0.052| p_loss: 0.069| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.517
Train: Epoch [2345/3000], Step [30/158]| g_loss: 0.626| d_loss: 0.700| gp_loss: 0.106| r_loss: 0.052| p_loss: 0.070| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.490
Train: Epoch [2345/3000], Step [60/158]| g_loss: 0.666| d_loss: 0.626| gp_loss: 0.056| r_loss: 0.054| p_loss: 0.074| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.526
Train: Epoch [2345/3000], Step [90/158]| g_loss: 0.637| d_loss: 0.628| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.067| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.505
Train: Epoch [2345/3000], Step [120/158]| g_loss: 0.653| d_loss: 0.561| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.065| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.520
Train: Epoch [2345/3000], Step [150/158]| g_loss: 0.677| d_loss: 0.646| gp_loss: 0.055| r_loss: 0.052| p_loss: 0.069| v_loss: 0.020| per_loss: 0.315 | a_loss: 0.540
Train: Epoch [2346/3000], Step [30/158]| g_loss: 0.647| d_loss: 0.856| gp_loss: 0.243| r_loss: 0.050| p_loss: 0.069| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.512
Train: Epoch [2346/3000], Step [60/158]| g_loss: 0.631| d_loss: 0.602| gp_loss: 0.052| r_loss: 0.050| p_loss: 0.069| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.498
Train: Epoch [2346/3000], Step [90/158]| g_loss: 0.678| d_loss: 0.623| gp_loss: 0.054| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.542
Train: Epoch [2346/3000], Step [120/158]| g_loss: 0.649| d_loss: 0.586| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.520
Train: Epoch [2346/3000], Step [150/158]| g_loss: 0.655| d_loss: 0.627| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.525
Train: Epoch [2347/3000], Step [30/158]| g_loss: 0.680| d_loss: 0.668| gp_loss: 0.126| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.310 | a_loss: 0.546
Train: Epoch [2347/3000], Step [60/158]| g_loss: 0.639| d_loss: 0.674| gp_loss: 0.049| r_loss: 0.047| p_loss: 0.063| v_loss: 0.018| per_loss: 0.286 | a_loss: 0.514
Train: Epoch [2347/3000], Step [90/158]| g_loss: 0.643| d_loss: 0.582| gp_loss: 0.054| r_loss: 0.051| p_loss: 0.064| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.511
Train: Epoch [2347/3000], Step [120/158]| g_loss: 0.706| d_loss: 0.529| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.575
Train: Epoch [2347/3000], Step [150/158]| g_loss: 0.674| d_loss: 0.687| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.545
Train: Epoch [2348/3000], Step [30/158]| g_loss: 0.639| d_loss: 0.650| gp_loss: 0.147| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.511
Train: Epoch [2348/3000], Step [60/158]| g_loss: 0.651| d_loss: 0.628| gp_loss: 0.054| r_loss: 0.051| p_loss: 0.063| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.518
Train: Epoch [2348/3000], Step [90/158]| g_loss: 0.628| d_loss: 0.672| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.494
Train: Epoch [2348/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.548| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.536
Train: Epoch [2348/3000], Step [150/158]| g_loss: 0.652| d_loss: 0.677| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.523
Train: Epoch [2349/3000], Step [30/158]| g_loss: 0.700| d_loss: 0.606| gp_loss: 0.138| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.569
Train: Epoch [2349/3000], Step [60/158]| g_loss: 0.664| d_loss: 0.656| gp_loss: 0.048| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.530
Train: Epoch [2349/3000], Step [90/158]| g_loss: 0.620| d_loss: 0.682| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.485
Train: Epoch [2349/3000], Step [120/158]| g_loss: 0.620| d_loss: 0.686| gp_loss: 0.059| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.280 | a_loss: 0.487
Train: Epoch [2349/3000], Step [150/158]| g_loss: 0.670| d_loss: 0.559| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.067| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.537
Train: Epoch [2350/3000], Step [30/158]| g_loss: 0.642| d_loss: 0.731| gp_loss: 0.100| r_loss: 0.050| p_loss: 0.070| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.507
Train: Epoch [2350/3000], Step [60/158]| g_loss: 0.655| d_loss: 0.543| gp_loss: 0.060| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.522
Train: Epoch [2350/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.695| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.524
Train: Epoch [2350/3000], Step [120/158]| g_loss: 0.673| d_loss: 0.535| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.544
Train: Epoch [2350/3000], Step [150/158]| g_loss: 0.702| d_loss: 0.653| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.568
Test: Epoch [2350/3000]| g_loss: 0.652| r_loss: 0.405| p_loss: 0.316| v_loss: 0.022
Train: Epoch [2351/3000], Step [30/158]| g_loss: 0.636| d_loss: 0.608| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.069| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.502
Train: Epoch [2351/3000], Step [60/158]| g_loss: 0.646| d_loss: 0.617| gp_loss: 0.055| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.512
Train: Epoch [2351/3000], Step [90/158]| g_loss: 0.647| d_loss: 0.644| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.515
Train: Epoch [2351/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.584| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.547
Train: Epoch [2351/3000], Step [150/158]| g_loss: 0.665| d_loss: 0.544| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.538
Train: Epoch [2352/3000], Step [30/158]| g_loss: 0.601| d_loss: 0.804| gp_loss: 0.101| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.472
Train: Epoch [2352/3000], Step [60/158]| g_loss: 0.632| d_loss: 0.606| gp_loss: 0.060| r_loss: 0.052| p_loss: 0.066| v_loss: 0.020| per_loss: 0.315 | a_loss: 0.496
Train: Epoch [2352/3000], Step [90/158]| g_loss: 0.642| d_loss: 0.636| gp_loss: 0.061| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.509
Train: Epoch [2352/3000], Step [120/158]| g_loss: 0.680| d_loss: 0.634| gp_loss: 0.061| r_loss: 0.051| p_loss: 0.071| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.544
Train: Epoch [2352/3000], Step [150/158]| g_loss: 0.678| d_loss: 0.593| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.547
Train: Epoch [2353/3000], Step [30/158]| g_loss: 0.664| d_loss: 0.756| gp_loss: 0.186| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.532
Train: Epoch [2353/3000], Step [60/158]| g_loss: 0.622| d_loss: 0.642| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.491
Train: Epoch [2353/3000], Step [90/158]| g_loss: 0.644| d_loss: 0.609| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.514
Train: Epoch [2353/3000], Step [120/158]| g_loss: 0.658| d_loss: 0.581| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.526
Train: Epoch [2353/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.571| gp_loss: 0.061| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.531
Train: Epoch [2354/3000], Step [30/158]| g_loss: 0.676| d_loss: 0.658| gp_loss: 0.153| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.546
Train: Epoch [2354/3000], Step [60/158]| g_loss: 0.701| d_loss: 0.615| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.571
Train: Epoch [2354/3000], Step [90/158]| g_loss: 0.680| d_loss: 0.603| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.064| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.547
Train: Epoch [2354/3000], Step [120/158]| g_loss: 0.645| d_loss: 0.630| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.513
Train: Epoch [2354/3000], Step [150/158]| g_loss: 0.665| d_loss: 0.633| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.536
Train: Epoch [2355/3000], Step [30/158]| g_loss: 0.609| d_loss: 0.847| gp_loss: 0.215| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.481
Train: Epoch [2355/3000], Step [60/158]| g_loss: 0.624| d_loss: 0.642| gp_loss: 0.053| r_loss: 0.053| p_loss: 0.064| v_loss: 0.018| per_loss: 0.293 | a_loss: 0.491
Train: Epoch [2355/3000], Step [90/158]| g_loss: 0.601| d_loss: 0.684| gp_loss: 0.052| r_loss: 0.054| p_loss: 0.074| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.461
Train: Epoch [2355/3000], Step [120/158]| g_loss: 0.643| d_loss: 0.684| gp_loss: 0.055| r_loss: 0.053| p_loss: 0.073| v_loss: 0.020| per_loss: 0.284 | a_loss: 0.505
Train: Epoch [2355/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.426| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.066| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.538
Train: Epoch [2356/3000], Step [30/158]| g_loss: 0.693| d_loss: 0.755| gp_loss: 0.191| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.566
Train: Epoch [2356/3000], Step [60/158]| g_loss: 0.649| d_loss: 0.588| gp_loss: 0.049| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.521
Train: Epoch [2356/3000], Step [90/158]| g_loss: 0.681| d_loss: 0.556| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.552
Train: Epoch [2356/3000], Step [120/158]| g_loss: 0.652| d_loss: 0.627| gp_loss: 0.050| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.278 | a_loss: 0.522
Train: Epoch [2356/3000], Step [150/158]| g_loss: 0.633| d_loss: 0.637| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.063| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.503
Train: Epoch [2357/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.678| gp_loss: 0.120| r_loss: 0.052| p_loss: 0.064| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.520
Train: Epoch [2357/3000], Step [60/158]| g_loss: 0.645| d_loss: 0.664| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.513
Train: Epoch [2357/3000], Step [90/158]| g_loss: 0.705| d_loss: 0.568| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.284 | a_loss: 0.575
Train: Epoch [2357/3000], Step [120/158]| g_loss: 0.692| d_loss: 0.621| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.070| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.557
Train: Epoch [2357/3000], Step [150/158]| g_loss: 0.646| d_loss: 0.633| gp_loss: 0.054| r_loss: 0.051| p_loss: 0.065| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.512
Train: Epoch [2358/3000], Step [30/158]| g_loss: 0.618| d_loss: 0.725| gp_loss: 0.090| r_loss: 0.049| p_loss: 0.069| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.485
Train: Epoch [2358/3000], Step [60/158]| g_loss: 0.638| d_loss: 0.662| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.509
Train: Epoch [2358/3000], Step [90/158]| g_loss: 0.651| d_loss: 0.548| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.063| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.521
Train: Epoch [2358/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.578| gp_loss: 0.057| r_loss: 0.052| p_loss: 0.068| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.543
Train: Epoch [2358/3000], Step [150/158]| g_loss: 0.672| d_loss: 0.672| gp_loss: 0.058| r_loss: 0.054| p_loss: 0.072| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.533
Train: Epoch [2359/3000], Step [30/158]| g_loss: 0.681| d_loss: 0.642| gp_loss: 0.177| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.544
Train: Epoch [2359/3000], Step [60/158]| g_loss: 0.690| d_loss: 0.561| gp_loss: 0.053| r_loss: 0.056| p_loss: 0.074| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.550
Train: Epoch [2359/3000], Step [90/158]| g_loss: 0.712| d_loss: 0.624| gp_loss: 0.054| r_loss: 0.057| p_loss: 0.080| v_loss: 0.021| per_loss: 0.277 | a_loss: 0.567
Train: Epoch [2359/3000], Step [120/158]| g_loss: 0.658| d_loss: 0.730| gp_loss: 0.055| r_loss: 0.052| p_loss: 0.073| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.520
Train: Epoch [2359/3000], Step [150/158]| g_loss: 0.628| d_loss: 0.672| gp_loss: 0.056| r_loss: 0.058| p_loss: 0.074| v_loss: 0.020| per_loss: 0.276 | a_loss: 0.485
Train: Epoch [2360/3000], Step [30/158]| g_loss: 0.646| d_loss: 0.641| gp_loss: 0.165| r_loss: 0.051| p_loss: 0.069| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.512
Train: Epoch [2360/3000], Step [60/158]| g_loss: 0.672| d_loss: 0.663| gp_loss: 0.051| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.541
Train: Epoch [2360/3000], Step [90/158]| g_loss: 0.673| d_loss: 0.592| gp_loss: 0.052| r_loss: 0.052| p_loss: 0.067| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.538
Train: Epoch [2360/3000], Step [120/158]| g_loss: 0.630| d_loss: 0.647| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.071| v_loss: 0.020| per_loss: 0.280 | a_loss: 0.495
Train: Epoch [2360/3000], Step [150/158]| g_loss: 0.647| d_loss: 0.640| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.516
Train: Epoch [2361/3000], Step [30/158]| g_loss: 0.621| d_loss: 0.759| gp_loss: 0.169| r_loss: 0.051| p_loss: 0.065| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.487
Train: Epoch [2361/3000], Step [60/158]| g_loss: 0.668| d_loss: 0.613| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.542
Train: Epoch [2361/3000], Step [90/158]| g_loss: 0.650| d_loss: 0.630| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.514
Train: Epoch [2361/3000], Step [120/158]| g_loss: 0.641| d_loss: 0.595| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.511
Train: Epoch [2361/3000], Step [150/158]| g_loss: 0.660| d_loss: 0.633| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.271 | a_loss: 0.529
Train: Epoch [2362/3000], Step [30/158]| g_loss: 0.661| d_loss: 0.707| gp_loss: 0.188| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.532
Train: Epoch [2362/3000], Step [60/158]| g_loss: 0.626| d_loss: 0.655| gp_loss: 0.049| r_loss: 0.047| p_loss: 0.063| v_loss: 0.020| per_loss: 0.310 | a_loss: 0.496
Train: Epoch [2362/3000], Step [90/158]| g_loss: 0.653| d_loss: 0.651| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.065| v_loss: 0.019| per_loss: 0.275 | a_loss: 0.523
Train: Epoch [2362/3000], Step [120/158]| g_loss: 0.654| d_loss: 0.585| gp_loss: 0.055| r_loss: 0.051| p_loss: 0.065| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.522
Train: Epoch [2362/3000], Step [150/158]| g_loss: 0.685| d_loss: 0.672| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.556
Train: Epoch [2363/3000], Step [30/158]| g_loss: 0.690| d_loss: 0.646| gp_loss: 0.160| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.561
Train: Epoch [2363/3000], Step [60/158]| g_loss: 0.657| d_loss: 0.628| gp_loss: 0.045| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.530
Train: Epoch [2363/3000], Step [90/158]| g_loss: 0.644| d_loss: 0.602| gp_loss: 0.049| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.279 | a_loss: 0.517
Train: Epoch [2363/3000], Step [120/158]| g_loss: 0.640| d_loss: 0.684| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.278 | a_loss: 0.514
Train: Epoch [2363/3000], Step [150/158]| g_loss: 0.601| d_loss: 0.679| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.067| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.470
Train: Epoch [2364/3000], Step [30/158]| g_loss: 0.617| d_loss: 0.837| gp_loss: 0.175| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.488
Train: Epoch [2364/3000], Step [60/158]| g_loss: 0.602| d_loss: 0.612| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.280 | a_loss: 0.473
Train: Epoch [2364/3000], Step [90/158]| g_loss: 0.693| d_loss: 0.552| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.283 | a_loss: 0.564
Train: Epoch [2364/3000], Step [120/158]| g_loss: 0.647| d_loss: 0.572| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.519
Train: Epoch [2364/3000], Step [150/158]| g_loss: 0.685| d_loss: 0.568| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.279 | a_loss: 0.557
Train: Epoch [2365/3000], Step [30/158]| g_loss: 0.681| d_loss: 0.723| gp_loss: 0.161| r_loss: 0.049| p_loss: 0.067| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.550
Train: Epoch [2365/3000], Step [60/158]| g_loss: 0.671| d_loss: 0.555| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.064| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.546
Train: Epoch [2365/3000], Step [90/158]| g_loss: 0.640| d_loss: 0.746| gp_loss: 0.052| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.506
Train: Epoch [2365/3000], Step [120/158]| g_loss: 0.610| d_loss: 0.666| gp_loss: 0.052| r_loss: 0.052| p_loss: 0.068| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.478
Train: Epoch [2365/3000], Step [150/158]| g_loss: 0.693| d_loss: 0.516| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.561
Train: Epoch [2366/3000], Step [30/158]| g_loss: 0.679| d_loss: 0.721| gp_loss: 0.171| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.546
Train: Epoch [2366/3000], Step [60/158]| g_loss: 0.622| d_loss: 0.636| gp_loss: 0.049| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.284 | a_loss: 0.494
Train: Epoch [2366/3000], Step [90/158]| g_loss: 0.638| d_loss: 0.635| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.272 | a_loss: 0.513
Train: Epoch [2366/3000], Step [120/158]| g_loss: 0.636| d_loss: 0.602| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.060| v_loss: 0.018| per_loss: 0.284 | a_loss: 0.513
Train: Epoch [2366/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.631| gp_loss: 0.055| r_loss: 0.051| p_loss: 0.066| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.537
Train: Epoch [2367/3000], Step [30/158]| g_loss: 0.718| d_loss: 0.659| gp_loss: 0.156| r_loss: 0.052| p_loss: 0.067| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.584
Train: Epoch [2367/3000], Step [60/158]| g_loss: 0.666| d_loss: 0.609| gp_loss: 0.047| r_loss: 0.057| p_loss: 0.075| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.521
Train: Epoch [2367/3000], Step [90/158]| g_loss: 0.646| d_loss: 0.573| gp_loss: 0.050| r_loss: 0.055| p_loss: 0.072| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.505
Train: Epoch [2367/3000], Step [120/158]| g_loss: 0.647| d_loss: 0.611| gp_loss: 0.053| r_loss: 0.052| p_loss: 0.068| v_loss: 0.018| per_loss: 0.272 | a_loss: 0.515
Train: Epoch [2367/3000], Step [150/158]| g_loss: 0.650| d_loss: 0.680| gp_loss: 0.052| r_loss: 0.058| p_loss: 0.070| v_loss: 0.018| per_loss: 0.293 | a_loss: 0.509
Train: Epoch [2368/3000], Step [30/158]| g_loss: 0.670| d_loss: 0.706| gp_loss: 0.093| r_loss: 0.056| p_loss: 0.084| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.525
Train: Epoch [2368/3000], Step [60/158]| g_loss: 0.658| d_loss: 0.540| gp_loss: 0.053| r_loss: 0.053| p_loss: 0.069| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.524
Train: Epoch [2368/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.673| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.068| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.522
Train: Epoch [2368/3000], Step [120/158]| g_loss: 0.614| d_loss: 0.671| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.073| v_loss: 0.020| per_loss: 0.281 | a_loss: 0.476
Train: Epoch [2368/3000], Step [150/158]| g_loss: 0.673| d_loss: 0.583| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.541
Train: Epoch [2369/3000], Step [30/158]| g_loss: 0.656| d_loss: 0.666| gp_loss: 0.082| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.524
Train: Epoch [2369/3000], Step [60/158]| g_loss: 0.644| d_loss: 0.706| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.282 | a_loss: 0.511
Train: Epoch [2369/3000], Step [90/158]| g_loss: 0.634| d_loss: 0.561| gp_loss: 0.062| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.501
Train: Epoch [2369/3000], Step [120/158]| g_loss: 0.652| d_loss: 0.680| gp_loss: 0.064| r_loss: 0.053| p_loss: 0.068| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.517
Train: Epoch [2369/3000], Step [150/158]| g_loss: 0.685| d_loss: 0.564| gp_loss: 0.067| r_loss: 0.051| p_loss: 0.070| v_loss: 0.020| per_loss: 0.272 | a_loss: 0.552
Train: Epoch [2370/3000], Step [30/158]| g_loss: 0.677| d_loss: 0.722| gp_loss: 0.164| r_loss: 0.053| p_loss: 0.069| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.539
Train: Epoch [2370/3000], Step [60/158]| g_loss: 0.649| d_loss: 0.616| gp_loss: 0.050| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.521
Train: Epoch [2370/3000], Step [90/158]| g_loss: 0.637| d_loss: 0.589| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.506
Train: Epoch [2370/3000], Step [120/158]| g_loss: 0.641| d_loss: 0.618| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.060| v_loss: 0.018| per_loss: 0.294 | a_loss: 0.517
Train: Epoch [2370/3000], Step [150/158]| g_loss: 0.674| d_loss: 0.583| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.545
Train: Epoch [2371/3000], Step [30/158]| g_loss: 0.643| d_loss: 0.797| gp_loss: 0.207| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.513
Train: Epoch [2371/3000], Step [60/158]| g_loss: 0.634| d_loss: 0.644| gp_loss: 0.051| r_loss: 0.047| p_loss: 0.061| v_loss: 0.018| per_loss: 0.286 | a_loss: 0.510
Train: Epoch [2371/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.591| gp_loss: 0.051| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.526
Train: Epoch [2371/3000], Step [120/158]| g_loss: 0.671| d_loss: 0.580| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.544
Train: Epoch [2371/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.658| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.068| v_loss: 0.019| per_loss: 0.273 | a_loss: 0.528
Train: Epoch [2372/3000], Step [30/158]| g_loss: 0.658| d_loss: 0.651| gp_loss: 0.138| r_loss: 0.052| p_loss: 0.072| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.524
Train: Epoch [2372/3000], Step [60/158]| g_loss: 0.665| d_loss: 0.657| gp_loss: 0.051| r_loss: 0.051| p_loss: 0.073| v_loss: 0.019| per_loss: 0.279 | a_loss: 0.531
Train: Epoch [2372/3000], Step [90/158]| g_loss: 0.634| d_loss: 0.576| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.506
Train: Epoch [2372/3000], Step [120/158]| g_loss: 0.655| d_loss: 0.619| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.527
Train: Epoch [2372/3000], Step [150/158]| g_loss: 0.684| d_loss: 0.630| gp_loss: 0.057| r_loss: 0.052| p_loss: 0.069| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.550
Train: Epoch [2373/3000], Step [30/158]| g_loss: 0.651| d_loss: 0.690| gp_loss: 0.116| r_loss: 0.053| p_loss: 0.074| v_loss: 0.020| per_loss: 0.281 | a_loss: 0.513
Train: Epoch [2373/3000], Step [60/158]| g_loss: 0.672| d_loss: 0.564| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.069| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.539
Train: Epoch [2373/3000], Step [90/158]| g_loss: 0.648| d_loss: 0.681| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.064| v_loss: 0.018| per_loss: 0.285 | a_loss: 0.521
Train: Epoch [2373/3000], Step [120/158]| g_loss: 0.661| d_loss: 0.597| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.531
Train: Epoch [2373/3000], Step [150/158]| g_loss: 0.668| d_loss: 0.611| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.538
Train: Epoch [2374/3000], Step [30/158]| g_loss: 0.614| d_loss: 0.828| gp_loss: 0.177| r_loss: 0.051| p_loss: 0.070| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.480
Train: Epoch [2374/3000], Step [60/158]| g_loss: 0.666| d_loss: 0.549| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.536
Train: Epoch [2374/3000], Step [90/158]| g_loss: 0.696| d_loss: 0.573| gp_loss: 0.059| r_loss: 0.052| p_loss: 0.069| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.560
Train: Epoch [2374/3000], Step [120/158]| g_loss: 0.663| d_loss: 0.608| gp_loss: 0.052| r_loss: 0.050| p_loss: 0.063| v_loss: 0.018| per_loss: 0.285 | a_loss: 0.535
Train: Epoch [2374/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.664| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.063| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.532
Train: Epoch [2375/3000], Step [30/158]| g_loss: 0.645| d_loss: 0.677| gp_loss: 0.139| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.514
Train: Epoch [2375/3000], Step [60/158]| g_loss: 0.659| d_loss: 0.620| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.529
Train: Epoch [2375/3000], Step [90/158]| g_loss: 0.687| d_loss: 0.577| gp_loss: 0.052| r_loss: 0.050| p_loss: 0.060| v_loss: 0.018| per_loss: 0.269 | a_loss: 0.562
Train: Epoch [2375/3000], Step [120/158]| g_loss: 0.654| d_loss: 0.630| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.529
Train: Epoch [2375/3000], Step [150/158]| g_loss: 0.640| d_loss: 0.621| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.278 | a_loss: 0.516
Train: Epoch [2376/3000], Step [30/158]| g_loss: 0.599| d_loss: 0.829| gp_loss: 0.222| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.279 | a_loss: 0.475
Train: Epoch [2376/3000], Step [60/158]| g_loss: 0.670| d_loss: 0.584| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.061| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.543
Train: Epoch [2376/3000], Step [90/158]| g_loss: 0.646| d_loss: 0.537| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.061| v_loss: 0.019| per_loss: 0.276 | a_loss: 0.520
Train: Epoch [2376/3000], Step [120/158]| g_loss: 0.668| d_loss: 0.700| gp_loss: 0.052| r_loss: 0.049| p_loss: 0.061| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.540
Train: Epoch [2376/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.612| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.530
Train: Epoch [2377/3000], Step [30/158]| g_loss: 0.645| d_loss: 0.656| gp_loss: 0.170| r_loss: 0.048| p_loss: 0.066| v_loss: 0.018| per_loss: 0.281 | a_loss: 0.517
Train: Epoch [2377/3000], Step [60/158]| g_loss: 0.672| d_loss: 0.668| gp_loss: 0.051| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.541
Train: Epoch [2377/3000], Step [90/158]| g_loss: 0.633| d_loss: 0.696| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.282 | a_loss: 0.501
Train: Epoch [2377/3000], Step [120/158]| g_loss: 0.611| d_loss: 0.642| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.482
Train: Epoch [2377/3000], Step [150/158]| g_loss: 0.660| d_loss: 0.587| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.530
Train: Epoch [2378/3000], Step [30/158]| g_loss: 0.677| d_loss: 0.732| gp_loss: 0.187| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.549
Train: Epoch [2378/3000], Step [60/158]| g_loss: 0.691| d_loss: 0.565| gp_loss: 0.052| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.559
Train: Epoch [2378/3000], Step [90/158]| g_loss: 0.604| d_loss: 0.672| gp_loss: 0.048| r_loss: 0.049| p_loss: 0.068| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.473
Train: Epoch [2378/3000], Step [120/158]| g_loss: 0.650| d_loss: 0.608| gp_loss: 0.051| r_loss: 0.045| p_loss: 0.058| v_loss: 0.018| per_loss: 0.286 | a_loss: 0.529
Train: Epoch [2378/3000], Step [150/158]| g_loss: 0.676| d_loss: 0.608| gp_loss: 0.051| r_loss: 0.048| p_loss: 0.063| v_loss: 0.018| per_loss: 0.276 | a_loss: 0.551
Train: Epoch [2379/3000], Step [30/158]| g_loss: 0.655| d_loss: 0.709| gp_loss: 0.177| r_loss: 0.050| p_loss: 0.063| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.526
Train: Epoch [2379/3000], Step [60/158]| g_loss: 0.598| d_loss: 0.739| gp_loss: 0.048| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.471
Train: Epoch [2379/3000], Step [90/158]| g_loss: 0.663| d_loss: 0.588| gp_loss: 0.052| r_loss: 0.050| p_loss: 0.063| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.533
Train: Epoch [2379/3000], Step [120/158]| g_loss: 0.645| d_loss: 0.611| gp_loss: 0.051| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.519
Train: Epoch [2379/3000], Step [150/158]| g_loss: 0.633| d_loss: 0.621| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.277 | a_loss: 0.504
Train: Epoch [2380/3000], Step [30/158]| g_loss: 0.632| d_loss: 0.755| gp_loss: 0.168| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.504
Train: Epoch [2380/3000], Step [60/158]| g_loss: 0.622| d_loss: 0.612| gp_loss: 0.050| r_loss: 0.051| p_loss: 0.064| v_loss: 0.019| per_loss: 0.277 | a_loss: 0.492
Train: Epoch [2380/3000], Step [90/158]| g_loss: 0.677| d_loss: 0.624| gp_loss: 0.051| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.279 | a_loss: 0.549
Train: Epoch [2380/3000], Step [120/158]| g_loss: 0.625| d_loss: 0.625| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.500
Train: Epoch [2380/3000], Step [150/158]| g_loss: 0.672| d_loss: 0.547| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.548
Train: Epoch [2381/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.713| gp_loss: 0.136| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.526
Train: Epoch [2381/3000], Step [60/158]| g_loss: 0.663| d_loss: 0.666| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.065| v_loss: 0.018| per_loss: 0.285 | a_loss: 0.538
Train: Epoch [2381/3000], Step [90/158]| g_loss: 0.629| d_loss: 0.700| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.074| v_loss: 0.021| per_loss: 0.288 | a_loss: 0.491
Train: Epoch [2381/3000], Step [120/158]| g_loss: 0.645| d_loss: 0.548| gp_loss: 0.057| r_loss: 0.054| p_loss: 0.070| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.508
Train: Epoch [2381/3000], Step [150/158]| g_loss: 0.703| d_loss: 0.551| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.070| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.568
Train: Epoch [2382/3000], Step [30/158]| g_loss: 0.699| d_loss: 0.697| gp_loss: 0.173| r_loss: 0.053| p_loss: 0.068| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.564
Train: Epoch [2382/3000], Step [60/158]| g_loss: 0.666| d_loss: 0.589| gp_loss: 0.052| r_loss: 0.053| p_loss: 0.066| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.533
Train: Epoch [2382/3000], Step [90/158]| g_loss: 0.671| d_loss: 0.595| gp_loss: 0.052| r_loss: 0.053| p_loss: 0.070| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.535
Train: Epoch [2382/3000], Step [120/158]| g_loss: 0.648| d_loss: 0.573| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.069| v_loss: 0.019| per_loss: 0.272 | a_loss: 0.516
Train: Epoch [2382/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.654| gp_loss: 0.055| r_loss: 0.052| p_loss: 0.069| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.524
Train: Epoch [2383/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.721| gp_loss: 0.162| r_loss: 0.055| p_loss: 0.069| v_loss: 0.019| per_loss: 0.279 | a_loss: 0.515
Train: Epoch [2383/3000], Step [60/158]| g_loss: 0.650| d_loss: 0.686| gp_loss: 0.051| r_loss: 0.054| p_loss: 0.075| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.509
Train: Epoch [2383/3000], Step [90/158]| g_loss: 0.616| d_loss: 0.681| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.070| v_loss: 0.020| per_loss: 0.281 | a_loss: 0.481
Train: Epoch [2383/3000], Step [120/158]| g_loss: 0.626| d_loss: 0.600| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.497
Train: Epoch [2383/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.563| gp_loss: 0.060| r_loss: 0.051| p_loss: 0.071| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.540
Train: Epoch [2384/3000], Step [30/158]| g_loss: 0.733| d_loss: 0.615| gp_loss: 0.132| r_loss: 0.053| p_loss: 0.073| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.594
Train: Epoch [2384/3000], Step [60/158]| g_loss: 0.708| d_loss: 0.544| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.580
Train: Epoch [2384/3000], Step [90/158]| g_loss: 0.658| d_loss: 0.692| gp_loss: 0.052| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.528
Train: Epoch [2384/3000], Step [120/158]| g_loss: 0.629| d_loss: 0.700| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.495
Train: Epoch [2384/3000], Step [150/158]| g_loss: 0.657| d_loss: 0.553| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.528
Train: Epoch [2385/3000], Step [30/158]| g_loss: 0.640| d_loss: 0.776| gp_loss: 0.147| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.506
Train: Epoch [2385/3000], Step [60/158]| g_loss: 0.599| d_loss: 0.636| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.063| v_loss: 0.018| per_loss: 0.284 | a_loss: 0.475
Train: Epoch [2385/3000], Step [90/158]| g_loss: 0.699| d_loss: 0.519| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.571
Train: Epoch [2385/3000], Step [120/158]| g_loss: 0.675| d_loss: 0.610| gp_loss: 0.054| r_loss: 0.051| p_loss: 0.065| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.542
Train: Epoch [2385/3000], Step [150/158]| g_loss: 0.639| d_loss: 0.666| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.512
Train: Epoch [2386/3000], Step [30/158]| g_loss: 0.642| d_loss: 0.744| gp_loss: 0.089| r_loss: 0.047| p_loss: 0.066| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.514
Train: Epoch [2386/3000], Step [60/158]| g_loss: 0.631| d_loss: 0.600| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.276 | a_loss: 0.502
Train: Epoch [2386/3000], Step [90/158]| g_loss: 0.679| d_loss: 0.537| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.547
Train: Epoch [2386/3000], Step [120/158]| g_loss: 0.647| d_loss: 0.685| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.515
Train: Epoch [2386/3000], Step [150/158]| g_loss: 0.690| d_loss: 0.549| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.279 | a_loss: 0.561
Train: Epoch [2387/3000], Step [30/158]| g_loss: 0.625| d_loss: 0.732| gp_loss: 0.103| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.493
Train: Epoch [2387/3000], Step [60/158]| g_loss: 0.627| d_loss: 0.628| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.499
Train: Epoch [2387/3000], Step [90/158]| g_loss: 0.644| d_loss: 0.678| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.279 | a_loss: 0.516
Train: Epoch [2387/3000], Step [120/158]| g_loss: 0.657| d_loss: 0.593| gp_loss: 0.061| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.526
Train: Epoch [2387/3000], Step [150/158]| g_loss: 0.688| d_loss: 0.557| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.558
Train: Epoch [2388/3000], Step [30/158]| g_loss: 0.637| d_loss: 0.734| gp_loss: 0.153| r_loss: 0.051| p_loss: 0.066| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.505
Train: Epoch [2388/3000], Step [60/158]| g_loss: 0.650| d_loss: 0.643| gp_loss: 0.051| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.520
Train: Epoch [2388/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.594| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.068| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.522
Train: Epoch [2388/3000], Step [120/158]| g_loss: 0.656| d_loss: 0.582| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.064| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.530
Train: Epoch [2388/3000], Step [150/158]| g_loss: 0.677| d_loss: 0.606| gp_loss: 0.060| r_loss: 0.046| p_loss: 0.060| v_loss: 0.018| per_loss: 0.272 | a_loss: 0.555
Train: Epoch [2389/3000], Step [30/158]| g_loss: 0.620| d_loss: 0.796| gp_loss: 0.140| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.490
Train: Epoch [2389/3000], Step [60/158]| g_loss: 0.624| d_loss: 0.598| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.494
Train: Epoch [2389/3000], Step [90/158]| g_loss: 0.669| d_loss: 0.585| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.536
Train: Epoch [2389/3000], Step [120/158]| g_loss: 0.663| d_loss: 0.582| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.062| v_loss: 0.018| per_loss: 0.283 | a_loss: 0.536
Train: Epoch [2389/3000], Step [150/158]| g_loss: 0.643| d_loss: 0.637| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.515
Train: Epoch [2390/3000], Step [30/158]| g_loss: 0.700| d_loss: 0.665| gp_loss: 0.178| r_loss: 0.045| p_loss: 0.059| v_loss: 0.018| per_loss: 0.283 | a_loss: 0.580
Train: Epoch [2390/3000], Step [60/158]| g_loss: 0.680| d_loss: 0.577| gp_loss: 0.049| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.551
Train: Epoch [2390/3000], Step [90/158]| g_loss: 0.661| d_loss: 0.562| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.532
Train: Epoch [2390/3000], Step [120/158]| g_loss: 0.663| d_loss: 0.666| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.062| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.534
Train: Epoch [2390/3000], Step [150/158]| g_loss: 0.644| d_loss: 0.673| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.517
Train: Epoch [2391/3000], Step [30/158]| g_loss: 0.636| d_loss: 0.681| gp_loss: 0.140| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.509
Train: Epoch [2391/3000], Step [60/158]| g_loss: 0.675| d_loss: 0.582| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.550
Train: Epoch [2391/3000], Step [90/158]| g_loss: 0.631| d_loss: 0.684| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.503
Train: Epoch [2391/3000], Step [120/158]| g_loss: 0.654| d_loss: 0.566| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.064| v_loss: 0.019| per_loss: 0.278 | a_loss: 0.524
Train: Epoch [2391/3000], Step [150/158]| g_loss: 0.644| d_loss: 0.663| gp_loss: 0.061| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.516
Train: Epoch [2392/3000], Step [30/158]| g_loss: 0.656| d_loss: 0.772| gp_loss: 0.182| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.524
Train: Epoch [2392/3000], Step [60/158]| g_loss: 0.645| d_loss: 0.635| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.275 | a_loss: 0.513
Train: Epoch [2392/3000], Step [90/158]| g_loss: 0.641| d_loss: 0.578| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.061| v_loss: 0.018| per_loss: 0.287 | a_loss: 0.516
Train: Epoch [2392/3000], Step [120/158]| g_loss: 0.644| d_loss: 0.653| gp_loss: 0.055| r_loss: 0.051| p_loss: 0.065| v_loss: 0.020| per_loss: 0.277 | a_loss: 0.512
Train: Epoch [2392/3000], Step [150/158]| g_loss: 0.653| d_loss: 0.583| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.522
Train: Epoch [2393/3000], Step [30/158]| g_loss: 0.659| d_loss: 0.663| gp_loss: 0.140| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.535
Train: Epoch [2393/3000], Step [60/158]| g_loss: 0.692| d_loss: 0.719| gp_loss: 0.051| r_loss: 0.050| p_loss: 0.068| v_loss: 0.019| per_loss: 0.278 | a_loss: 0.561
Train: Epoch [2393/3000], Step [90/158]| g_loss: 0.636| d_loss: 0.581| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.509
Train: Epoch [2393/3000], Step [120/158]| g_loss: 0.628| d_loss: 0.648| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.498
Train: Epoch [2393/3000], Step [150/158]| g_loss: 0.637| d_loss: 0.640| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.509
Train: Epoch [2394/3000], Step [30/158]| g_loss: 0.699| d_loss: 0.598| gp_loss: 0.161| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.570
Train: Epoch [2394/3000], Step [60/158]| g_loss: 0.677| d_loss: 0.660| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.548
Train: Epoch [2394/3000], Step [90/158]| g_loss: 0.652| d_loss: 0.577| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.273 | a_loss: 0.525
Train: Epoch [2394/3000], Step [120/158]| g_loss: 0.637| d_loss: 0.631| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.508
Train: Epoch [2394/3000], Step [150/158]| g_loss: 0.667| d_loss: 0.637| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.540
Train: Epoch [2395/3000], Step [30/158]| g_loss: 0.613| d_loss: 0.754| gp_loss: 0.150| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.487
Train: Epoch [2395/3000], Step [60/158]| g_loss: 0.660| d_loss: 0.593| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.528
Train: Epoch [2395/3000], Step [90/158]| g_loss: 0.653| d_loss: 0.552| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.525
Train: Epoch [2395/3000], Step [120/158]| g_loss: 0.673| d_loss: 0.635| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.546
Train: Epoch [2395/3000], Step [150/158]| g_loss: 0.622| d_loss: 0.625| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.490
Train: Epoch [2396/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.686| gp_loss: 0.140| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.284 | a_loss: 0.523
Train: Epoch [2396/3000], Step [60/158]| g_loss: 0.632| d_loss: 0.659| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.505
Train: Epoch [2396/3000], Step [90/158]| g_loss: 0.679| d_loss: 0.558| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.072| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.543
Train: Epoch [2396/3000], Step [120/158]| g_loss: 0.680| d_loss: 0.640| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.070| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.546
Train: Epoch [2396/3000], Step [150/158]| g_loss: 0.623| d_loss: 0.625| gp_loss: 0.060| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.268 | a_loss: 0.493
Train: Epoch [2397/3000], Step [30/158]| g_loss: 0.704| d_loss: 0.754| gp_loss: 0.193| r_loss: 0.069| p_loss: 0.112| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.529
Train: Epoch [2397/3000], Step [60/158]| g_loss: 0.697| d_loss: 0.534| gp_loss: 0.055| r_loss: 0.067| p_loss: 0.090| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.535
Train: Epoch [2397/3000], Step [90/158]| g_loss: 0.687| d_loss: 0.657| gp_loss: 0.051| r_loss: 0.063| p_loss: 0.090| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.528
Train: Epoch [2397/3000], Step [120/158]| g_loss: 0.639| d_loss: 0.662| gp_loss: 0.054| r_loss: 0.056| p_loss: 0.075| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.497
Train: Epoch [2397/3000], Step [150/158]| g_loss: 0.688| d_loss: 0.565| gp_loss: 0.057| r_loss: 0.062| p_loss: 0.090| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.531
Train: Epoch [2398/3000], Step [30/158]| g_loss: 0.707| d_loss: 0.701| gp_loss: 0.172| r_loss: 0.058| p_loss: 0.089| v_loss: 0.020| per_loss: 0.307 | a_loss: 0.554
Train: Epoch [2398/3000], Step [60/158]| g_loss: 0.674| d_loss: 0.616| gp_loss: 0.055| r_loss: 0.053| p_loss: 0.076| v_loss: 0.020| per_loss: 0.311 | a_loss: 0.532
Train: Epoch [2398/3000], Step [90/158]| g_loss: 0.719| d_loss: 0.517| gp_loss: 0.055| r_loss: 0.051| p_loss: 0.071| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.584
Train: Epoch [2398/3000], Step [120/158]| g_loss: 0.681| d_loss: 0.689| gp_loss: 0.052| r_loss: 0.052| p_loss: 0.069| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.544
Train: Epoch [2398/3000], Step [150/158]| g_loss: 0.633| d_loss: 0.614| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.501
Train: Epoch [2399/3000], Step [30/158]| g_loss: 0.617| d_loss: 0.739| gp_loss: 0.174| r_loss: 0.048| p_loss: 0.064| v_loss: 0.018| per_loss: 0.309 | a_loss: 0.488
Train: Epoch [2399/3000], Step [60/158]| g_loss: 0.637| d_loss: 0.701| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.504
Train: Epoch [2399/3000], Step [90/158]| g_loss: 0.618| d_loss: 0.641| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.067| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.484
Train: Epoch [2399/3000], Step [120/158]| g_loss: 0.684| d_loss: 0.602| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.555
Train: Epoch [2399/3000], Step [150/158]| g_loss: 0.666| d_loss: 0.615| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.536
Train: Epoch [2400/3000], Step [30/158]| g_loss: 0.665| d_loss: 0.759| gp_loss: 0.192| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.536
Train: Epoch [2400/3000], Step [60/158]| g_loss: 0.624| d_loss: 0.652| gp_loss: 0.045| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.490
Train: Epoch [2400/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.567| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.527
Train: Epoch [2400/3000], Step [120/158]| g_loss: 0.647| d_loss: 0.637| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.521
Train: Epoch [2400/3000], Step [150/158]| g_loss: 0.650| d_loss: 0.656| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.525
Test: Epoch [2400/3000]| g_loss: 0.657| r_loss: 0.407| p_loss: 0.317| v_loss: 0.022
Train: Epoch [2401/3000], Step [30/158]| g_loss: 0.699| d_loss: 0.507| gp_loss: 0.051| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.278 | a_loss: 0.572
Train: Epoch [2401/3000], Step [60/158]| g_loss: 0.689| d_loss: 0.541| gp_loss: 0.047| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.564
Train: Epoch [2401/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.681| gp_loss: 0.047| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.528
Train: Epoch [2401/3000], Step [120/158]| g_loss: 0.635| d_loss: 0.665| gp_loss: 0.048| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.508
Train: Epoch [2401/3000], Step [150/158]| g_loss: 0.601| d_loss: 0.701| gp_loss: 0.049| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.474
Train: Epoch [2402/3000], Step [30/158]| g_loss: 0.643| d_loss: 0.691| gp_loss: 0.148| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.514
Train: Epoch [2402/3000], Step [60/158]| g_loss: 0.613| d_loss: 0.719| gp_loss: 0.048| r_loss: 0.047| p_loss: 0.061| v_loss: 0.018| per_loss: 0.285 | a_loss: 0.489
Train: Epoch [2402/3000], Step [90/158]| g_loss: 0.626| d_loss: 0.608| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.499
Train: Epoch [2402/3000], Step [120/158]| g_loss: 0.646| d_loss: 0.543| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.060| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.519
Train: Epoch [2402/3000], Step [150/158]| g_loss: 0.715| d_loss: 0.606| gp_loss: 0.051| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.589
Train: Epoch [2403/3000], Step [30/158]| g_loss: 0.654| d_loss: 0.706| gp_loss: 0.134| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.529
Train: Epoch [2403/3000], Step [60/158]| g_loss: 0.615| d_loss: 0.672| gp_loss: 0.052| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.485
Train: Epoch [2403/3000], Step [90/158]| g_loss: 0.658| d_loss: 0.618| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.533
Train: Epoch [2403/3000], Step [120/158]| g_loss: 0.609| d_loss: 0.623| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.062| v_loss: 0.018| per_loss: 0.269 | a_loss: 0.486
Train: Epoch [2403/3000], Step [150/158]| g_loss: 0.684| d_loss: 0.530| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.062| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.557
Train: Epoch [2404/3000], Step [30/158]| g_loss: 0.664| d_loss: 0.725| gp_loss: 0.101| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.281 | a_loss: 0.532
Train: Epoch [2404/3000], Step [60/158]| g_loss: 0.641| d_loss: 0.625| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.069| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.510
Train: Epoch [2404/3000], Step [90/158]| g_loss: 0.655| d_loss: 0.662| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.526
Train: Epoch [2404/3000], Step [120/158]| g_loss: 0.699| d_loss: 0.534| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.569
Train: Epoch [2404/3000], Step [150/158]| g_loss: 0.655| d_loss: 0.688| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.067| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.524
Train: Epoch [2405/3000], Step [30/158]| g_loss: 0.645| d_loss: 0.706| gp_loss: 0.190| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.274 | a_loss: 0.518
Train: Epoch [2405/3000], Step [60/158]| g_loss: 0.643| d_loss: 0.658| gp_loss: 0.049| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.276 | a_loss: 0.519
Train: Epoch [2405/3000], Step [90/158]| g_loss: 0.676| d_loss: 0.566| gp_loss: 0.051| r_loss: 0.049| p_loss: 0.061| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.549
Train: Epoch [2405/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.592| gp_loss: 0.050| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.538
Train: Epoch [2405/3000], Step [150/158]| g_loss: 0.634| d_loss: 0.664| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.506
Train: Epoch [2406/3000], Step [30/158]| g_loss: 0.651| d_loss: 0.702| gp_loss: 0.129| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.524
Train: Epoch [2406/3000], Step [60/158]| g_loss: 0.633| d_loss: 0.675| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.278 | a_loss: 0.505
Train: Epoch [2406/3000], Step [90/158]| g_loss: 0.609| d_loss: 0.643| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.480
Train: Epoch [2406/3000], Step [120/158]| g_loss: 0.650| d_loss: 0.643| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.520
Train: Epoch [2406/3000], Step [150/158]| g_loss: 0.701| d_loss: 0.514| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.059| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.575
Train: Epoch [2407/3000], Step [30/158]| g_loss: 0.667| d_loss: 0.743| gp_loss: 0.223| r_loss: 0.049| p_loss: 0.063| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.538
Train: Epoch [2407/3000], Step [60/158]| g_loss: 0.645| d_loss: 0.606| gp_loss: 0.048| r_loss: 0.048| p_loss: 0.059| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.520
Train: Epoch [2407/3000], Step [90/158]| g_loss: 0.672| d_loss: 0.585| gp_loss: 0.051| r_loss: 0.047| p_loss: 0.060| v_loss: 0.018| per_loss: 0.299 | a_loss: 0.546
Train: Epoch [2407/3000], Step [120/158]| g_loss: 0.674| d_loss: 0.613| gp_loss: 0.051| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.550
Train: Epoch [2407/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.586| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.530
Train: Epoch [2408/3000], Step [30/158]| g_loss: 0.588| d_loss: 0.812| gp_loss: 0.090| r_loss: 0.047| p_loss: 0.064| v_loss: 0.018| per_loss: 0.289 | a_loss: 0.461
Train: Epoch [2408/3000], Step [60/158]| g_loss: 0.639| d_loss: 0.636| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.063| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.511
Train: Epoch [2408/3000], Step [90/158]| g_loss: 0.677| d_loss: 0.519| gp_loss: 0.060| r_loss: 0.050| p_loss: 0.062| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.548
Train: Epoch [2408/3000], Step [120/158]| g_loss: 0.695| d_loss: 0.574| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.566
Train: Epoch [2408/3000], Step [150/158]| g_loss: 0.626| d_loss: 0.702| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.499
Train: Epoch [2409/3000], Step [30/158]| g_loss: 0.645| d_loss: 0.689| gp_loss: 0.120| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.516
Train: Epoch [2409/3000], Step [60/158]| g_loss: 0.685| d_loss: 0.547| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.555
Train: Epoch [2409/3000], Step [90/158]| g_loss: 0.653| d_loss: 0.661| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.276 | a_loss: 0.523
Train: Epoch [2409/3000], Step [120/158]| g_loss: 0.656| d_loss: 0.578| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.528
Train: Epoch [2409/3000], Step [150/158]| g_loss: 0.654| d_loss: 0.683| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.522
Train: Epoch [2410/3000], Step [30/158]| g_loss: 0.650| d_loss: 0.682| gp_loss: 0.136| r_loss: 0.049| p_loss: 0.067| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.520
Train: Epoch [2410/3000], Step [60/158]| g_loss: 0.651| d_loss: 0.587| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.522
Train: Epoch [2410/3000], Step [90/158]| g_loss: 0.669| d_loss: 0.563| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.061| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.542
Train: Epoch [2410/3000], Step [120/158]| g_loss: 0.667| d_loss: 0.659| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.540
Train: Epoch [2410/3000], Step [150/158]| g_loss: 0.640| d_loss: 0.631| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.512
Train: Epoch [2411/3000], Step [30/158]| g_loss: 0.680| d_loss: 0.627| gp_loss: 0.145| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.551
Train: Epoch [2411/3000], Step [60/158]| g_loss: 0.648| d_loss: 0.735| gp_loss: 0.052| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.517
Train: Epoch [2411/3000], Step [90/158]| g_loss: 0.621| d_loss: 0.643| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.493
Train: Epoch [2411/3000], Step [120/158]| g_loss: 0.656| d_loss: 0.558| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.531
Train: Epoch [2411/3000], Step [150/158]| g_loss: 0.677| d_loss: 0.563| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.549
Train: Epoch [2412/3000], Step [30/158]| g_loss: 0.666| d_loss: 0.721| gp_loss: 0.154| r_loss: 0.051| p_loss: 0.065| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.535
Train: Epoch [2412/3000], Step [60/158]| g_loss: 0.636| d_loss: 0.616| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.510
Train: Epoch [2412/3000], Step [90/158]| g_loss: 0.687| d_loss: 0.537| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.563
Train: Epoch [2412/3000], Step [120/158]| g_loss: 0.672| d_loss: 0.702| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.544
Train: Epoch [2412/3000], Step [150/158]| g_loss: 0.627| d_loss: 0.626| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.497
Train: Epoch [2413/3000], Step [30/158]| g_loss: 0.627| d_loss: 0.722| gp_loss: 0.159| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.501
Train: Epoch [2413/3000], Step [60/158]| g_loss: 0.682| d_loss: 0.523| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.554
Train: Epoch [2413/3000], Step [90/158]| g_loss: 0.655| d_loss: 0.640| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.528
Train: Epoch [2413/3000], Step [120/158]| g_loss: 0.658| d_loss: 0.650| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.527
Train: Epoch [2413/3000], Step [150/158]| g_loss: 0.623| d_loss: 0.682| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.277 | a_loss: 0.493
Train: Epoch [2414/3000], Step [30/158]| g_loss: 0.657| d_loss: 0.741| gp_loss: 0.162| r_loss: 0.050| p_loss: 0.068| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.525
Train: Epoch [2414/3000], Step [60/158]| g_loss: 0.626| d_loss: 0.624| gp_loss: 0.051| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.499
Train: Epoch [2414/3000], Step [90/158]| g_loss: 0.644| d_loss: 0.565| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.061| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.515
Train: Epoch [2414/3000], Step [120/158]| g_loss: 0.692| d_loss: 0.620| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.563
Train: Epoch [2414/3000], Step [150/158]| g_loss: 0.652| d_loss: 0.600| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.525
Train: Epoch [2415/3000], Step [30/158]| g_loss: 0.676| d_loss: 0.674| gp_loss: 0.168| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.546
Train: Epoch [2415/3000], Step [60/158]| g_loss: 0.653| d_loss: 0.700| gp_loss: 0.050| r_loss: 0.047| p_loss: 0.065| v_loss: 0.018| per_loss: 0.292 | a_loss: 0.526
Train: Epoch [2415/3000], Step [90/158]| g_loss: 0.661| d_loss: 0.560| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.062| v_loss: 0.020| per_loss: 0.284 | a_loss: 0.533
Train: Epoch [2415/3000], Step [120/158]| g_loss: 0.621| d_loss: 0.641| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.496
Train: Epoch [2415/3000], Step [150/158]| g_loss: 0.641| d_loss: 0.661| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.509
Train: Epoch [2416/3000], Step [30/158]| g_loss: 0.662| d_loss: 0.649| gp_loss: 0.114| r_loss: 0.049| p_loss: 0.068| v_loss: 0.020| per_loss: 0.283 | a_loss: 0.531
Train: Epoch [2416/3000], Step [60/158]| g_loss: 0.685| d_loss: 0.605| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.071| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.549
Train: Epoch [2416/3000], Step [90/158]| g_loss: 0.636| d_loss: 0.679| gp_loss: 0.055| r_loss: 0.054| p_loss: 0.070| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.497
Train: Epoch [2416/3000], Step [120/158]| g_loss: 0.686| d_loss: 0.572| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.068| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.556
Train: Epoch [2416/3000], Step [150/158]| g_loss: 0.673| d_loss: 0.602| gp_loss: 0.060| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.282 | a_loss: 0.540
Train: Epoch [2417/3000], Step [30/158]| g_loss: 0.680| d_loss: 0.653| gp_loss: 0.185| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.550
Train: Epoch [2417/3000], Step [60/158]| g_loss: 0.706| d_loss: 0.590| gp_loss: 0.051| r_loss: 0.050| p_loss: 0.068| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.574
Train: Epoch [2417/3000], Step [90/158]| g_loss: 0.622| d_loss: 0.731| gp_loss: 0.052| r_loss: 0.060| p_loss: 0.078| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.476
Train: Epoch [2417/3000], Step [120/158]| g_loss: 0.636| d_loss: 0.618| gp_loss: 0.057| r_loss: 0.052| p_loss: 0.074| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.499
Train: Epoch [2417/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.653| gp_loss: 0.058| r_loss: 0.054| p_loss: 0.072| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.531
Train: Epoch [2418/3000], Step [30/158]| g_loss: 0.670| d_loss: 0.711| gp_loss: 0.171| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.541
Train: Epoch [2418/3000], Step [60/158]| g_loss: 0.668| d_loss: 0.592| gp_loss: 0.052| r_loss: 0.050| p_loss: 0.064| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.537
Train: Epoch [2418/3000], Step [90/158]| g_loss: 0.601| d_loss: 0.709| gp_loss: 0.053| r_loss: 0.045| p_loss: 0.062| v_loss: 0.018| per_loss: 0.279 | a_loss: 0.479
Train: Epoch [2418/3000], Step [120/158]| g_loss: 0.635| d_loss: 0.529| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.507
Train: Epoch [2418/3000], Step [150/158]| g_loss: 0.702| d_loss: 0.614| gp_loss: 0.057| r_loss: 0.054| p_loss: 0.071| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.563
Train: Epoch [2419/3000], Step [30/158]| g_loss: 0.644| d_loss: 0.732| gp_loss: 0.131| r_loss: 0.052| p_loss: 0.069| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.510
Train: Epoch [2419/3000], Step [60/158]| g_loss: 0.693| d_loss: 0.526| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.562
Train: Epoch [2419/3000], Step [90/158]| g_loss: 0.664| d_loss: 0.604| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.278 | a_loss: 0.538
Train: Epoch [2419/3000], Step [120/158]| g_loss: 0.641| d_loss: 0.638| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.278 | a_loss: 0.514
Train: Epoch [2419/3000], Step [150/158]| g_loss: 0.656| d_loss: 0.636| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.526
Train: Epoch [2420/3000], Step [30/158]| g_loss: 0.628| d_loss: 0.730| gp_loss: 0.180| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.269 | a_loss: 0.503
Train: Epoch [2420/3000], Step [60/158]| g_loss: 0.674| d_loss: 0.703| gp_loss: 0.052| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.543
Train: Epoch [2420/3000], Step [90/158]| g_loss: 0.619| d_loss: 0.606| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.492
Train: Epoch [2420/3000], Step [120/158]| g_loss: 0.682| d_loss: 0.548| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.062| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.553
Train: Epoch [2420/3000], Step [150/158]| g_loss: 0.643| d_loss: 0.611| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.517
Train: Epoch [2421/3000], Step [30/158]| g_loss: 0.661| d_loss: 0.680| gp_loss: 0.121| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.535
Train: Epoch [2421/3000], Step [60/158]| g_loss: 0.641| d_loss: 0.633| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.515
Train: Epoch [2421/3000], Step [90/158]| g_loss: 0.651| d_loss: 0.627| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.526
Train: Epoch [2421/3000], Step [120/158]| g_loss: 0.625| d_loss: 0.635| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.278 | a_loss: 0.500
Train: Epoch [2421/3000], Step [150/158]| g_loss: 0.632| d_loss: 0.590| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.061| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.505
Train: Epoch [2422/3000], Step [30/158]| g_loss: 0.709| d_loss: 0.542| gp_loss: 0.139| r_loss: 0.047| p_loss: 0.059| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.585
Train: Epoch [2422/3000], Step [60/158]| g_loss: 0.730| d_loss: 0.553| gp_loss: 0.052| r_loss: 0.049| p_loss: 0.061| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.602
Train: Epoch [2422/3000], Step [90/158]| g_loss: 0.692| d_loss: 0.601| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.565
Train: Epoch [2422/3000], Step [120/158]| g_loss: 0.650| d_loss: 0.765| gp_loss: 0.051| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.521
Train: Epoch [2422/3000], Step [150/158]| g_loss: 0.589| d_loss: 0.697| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.068| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.457
Train: Epoch [2423/3000], Step [30/158]| g_loss: 0.596| d_loss: 0.723| gp_loss: 0.119| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.465
Train: Epoch [2423/3000], Step [60/158]| g_loss: 0.678| d_loss: 0.558| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.547
Train: Epoch [2423/3000], Step [90/158]| g_loss: 0.662| d_loss: 0.647| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.528
Train: Epoch [2423/3000], Step [120/158]| g_loss: 0.646| d_loss: 0.660| gp_loss: 0.060| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.515
Train: Epoch [2423/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.600| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.528
Train: Epoch [2424/3000], Step [30/158]| g_loss: 0.645| d_loss: 0.807| gp_loss: 0.228| r_loss: 0.051| p_loss: 0.070| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.510
Train: Epoch [2424/3000], Step [60/158]| g_loss: 0.666| d_loss: 0.581| gp_loss: 0.051| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.275 | a_loss: 0.536
Train: Epoch [2424/3000], Step [90/158]| g_loss: 0.636| d_loss: 0.665| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.063| v_loss: 0.018| per_loss: 0.285 | a_loss: 0.511
Train: Epoch [2424/3000], Step [120/158]| g_loss: 0.636| d_loss: 0.609| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.511
Train: Epoch [2424/3000], Step [150/158]| g_loss: 0.679| d_loss: 0.597| gp_loss: 0.055| r_loss: 0.056| p_loss: 0.074| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.536
Train: Epoch [2425/3000], Step [30/158]| g_loss: 0.647| d_loss: 0.685| gp_loss: 0.146| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.516
Train: Epoch [2425/3000], Step [60/158]| g_loss: 0.666| d_loss: 0.665| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.538
Train: Epoch [2425/3000], Step [90/158]| g_loss: 0.650| d_loss: 0.617| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.519
Train: Epoch [2425/3000], Step [120/158]| g_loss: 0.661| d_loss: 0.609| gp_loss: 0.056| r_loss: 0.053| p_loss: 0.070| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.526
Train: Epoch [2425/3000], Step [150/158]| g_loss: 0.642| d_loss: 0.651| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.068| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.509
Train: Epoch [2426/3000], Step [30/158]| g_loss: 0.661| d_loss: 0.683| gp_loss: 0.128| r_loss: 0.049| p_loss: 0.065| v_loss: 0.018| per_loss: 0.286 | a_loss: 0.532
Train: Epoch [2426/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.556| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.545
Train: Epoch [2426/3000], Step [90/158]| g_loss: 0.631| d_loss: 0.647| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.505
Train: Epoch [2426/3000], Step [120/158]| g_loss: 0.635| d_loss: 0.630| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.509
Train: Epoch [2426/3000], Step [150/158]| g_loss: 0.676| d_loss: 0.607| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.065| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.543
Train: Epoch [2427/3000], Step [30/158]| g_loss: 0.667| d_loss: 0.670| gp_loss: 0.154| r_loss: 0.049| p_loss: 0.061| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.539
Train: Epoch [2427/3000], Step [60/158]| g_loss: 0.659| d_loss: 0.584| gp_loss: 0.054| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.282 | a_loss: 0.526
Train: Epoch [2427/3000], Step [90/158]| g_loss: 0.648| d_loss: 0.593| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.277 | a_loss: 0.523
Train: Epoch [2427/3000], Step [120/158]| g_loss: 0.686| d_loss: 0.602| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.560
Train: Epoch [2427/3000], Step [150/158]| g_loss: 0.618| d_loss: 0.746| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.488
Train: Epoch [2428/3000], Step [30/158]| g_loss: 0.634| d_loss: 0.674| gp_loss: 0.127| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.500
Train: Epoch [2428/3000], Step [60/158]| g_loss: 0.645| d_loss: 0.603| gp_loss: 0.057| r_loss: 0.046| p_loss: 0.061| v_loss: 0.018| per_loss: 0.283 | a_loss: 0.522
Train: Epoch [2428/3000], Step [90/158]| g_loss: 0.668| d_loss: 0.557| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.540
Train: Epoch [2428/3000], Step [120/158]| g_loss: 0.668| d_loss: 0.612| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.279 | a_loss: 0.539
Train: Epoch [2428/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.613| gp_loss: 0.060| r_loss: 0.046| p_loss: 0.063| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.538
Train: Epoch [2429/3000], Step [30/158]| g_loss: 0.641| d_loss: 0.809| gp_loss: 0.179| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.508
Train: Epoch [2429/3000], Step [60/158]| g_loss: 0.663| d_loss: 0.558| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.062| v_loss: 0.020| per_loss: 0.284 | a_loss: 0.536
Train: Epoch [2429/3000], Step [90/158]| g_loss: 0.669| d_loss: 0.597| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.538
Train: Epoch [2429/3000], Step [120/158]| g_loss: 0.675| d_loss: 0.631| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.543
Train: Epoch [2429/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.619| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.068| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.531
Train: Epoch [2430/3000], Step [30/158]| g_loss: 0.640| d_loss: 0.789| gp_loss: 0.197| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.508
Train: Epoch [2430/3000], Step [60/158]| g_loss: 0.631| d_loss: 0.570| gp_loss: 0.048| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.505
Train: Epoch [2430/3000], Step [90/158]| g_loss: 0.700| d_loss: 0.597| gp_loss: 0.051| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.568
Train: Epoch [2430/3000], Step [120/158]| g_loss: 0.637| d_loss: 0.645| gp_loss: 0.052| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.507
Train: Epoch [2430/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.598| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.067| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.532
Train: Epoch [2431/3000], Step [30/158]| g_loss: 0.668| d_loss: 0.644| gp_loss: 0.124| r_loss: 0.056| p_loss: 0.071| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.528
Train: Epoch [2431/3000], Step [60/158]| g_loss: 0.700| d_loss: 0.668| gp_loss: 0.051| r_loss: 0.055| p_loss: 0.072| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.560
Train: Epoch [2431/3000], Step [90/158]| g_loss: 0.656| d_loss: 0.556| gp_loss: 0.052| r_loss: 0.054| p_loss: 0.073| v_loss: 0.019| per_loss: 0.278 | a_loss: 0.519
Train: Epoch [2431/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.599| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.068| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.543
Train: Epoch [2431/3000], Step [150/158]| g_loss: 0.630| d_loss: 0.692| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.070| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.495
Train: Epoch [2432/3000], Step [30/158]| g_loss: 0.664| d_loss: 0.673| gp_loss: 0.162| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.535
Train: Epoch [2432/3000], Step [60/158]| g_loss: 0.628| d_loss: 0.675| gp_loss: 0.054| r_loss: 0.053| p_loss: 0.067| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.494
Train: Epoch [2432/3000], Step [90/158]| g_loss: 0.645| d_loss: 0.602| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.512
Train: Epoch [2432/3000], Step [120/158]| g_loss: 0.672| d_loss: 0.632| gp_loss: 0.055| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.282 | a_loss: 0.539
Train: Epoch [2432/3000], Step [150/158]| g_loss: 0.696| d_loss: 0.594| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.562
Train: Epoch [2433/3000], Step [30/158]| g_loss: 0.687| d_loss: 0.691| gp_loss: 0.175| r_loss: 0.049| p_loss: 0.067| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.555
Train: Epoch [2433/3000], Step [60/158]| g_loss: 0.647| d_loss: 0.640| gp_loss: 0.049| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.517
Train: Epoch [2433/3000], Step [90/158]| g_loss: 0.655| d_loss: 0.532| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.529
Train: Epoch [2433/3000], Step [120/158]| g_loss: 0.635| d_loss: 0.695| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.506
Train: Epoch [2433/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.629| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.533
Train: Epoch [2434/3000], Step [30/158]| g_loss: 0.648| d_loss: 0.735| gp_loss: 0.164| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.519
Train: Epoch [2434/3000], Step [60/158]| g_loss: 0.667| d_loss: 0.662| gp_loss: 0.049| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.538
Train: Epoch [2434/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.560| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.068| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.518
Train: Epoch [2434/3000], Step [120/158]| g_loss: 0.645| d_loss: 0.668| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.516
Train: Epoch [2434/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.585| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.063| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.529
Train: Epoch [2435/3000], Step [30/158]| g_loss: 0.695| d_loss: 0.619| gp_loss: 0.130| r_loss: 0.049| p_loss: 0.069| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.563
Train: Epoch [2435/3000], Step [60/158]| g_loss: 0.632| d_loss: 0.684| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.503
Train: Epoch [2435/3000], Step [90/158]| g_loss: 0.660| d_loss: 0.581| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.533
Train: Epoch [2435/3000], Step [120/158]| g_loss: 0.665| d_loss: 0.610| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.535
Train: Epoch [2435/3000], Step [150/158]| g_loss: 0.626| d_loss: 0.636| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.497
Train: Epoch [2436/3000], Step [30/158]| g_loss: 0.636| d_loss: 0.712| gp_loss: 0.102| r_loss: 0.049| p_loss: 0.068| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.504
Train: Epoch [2436/3000], Step [60/158]| g_loss: 0.674| d_loss: 0.623| gp_loss: 0.057| r_loss: 0.053| p_loss: 0.070| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.536
Train: Epoch [2436/3000], Step [90/158]| g_loss: 0.650| d_loss: 0.573| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.068| v_loss: 0.020| per_loss: 0.282 | a_loss: 0.517
Train: Epoch [2436/3000], Step [120/158]| g_loss: 0.655| d_loss: 0.640| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.069| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.523
Train: Epoch [2436/3000], Step [150/158]| g_loss: 0.708| d_loss: 0.581| gp_loss: 0.061| r_loss: 0.052| p_loss: 0.076| v_loss: 0.020| per_loss: 0.312 | a_loss: 0.567
Train: Epoch [2437/3000], Step [30/158]| g_loss: 0.647| d_loss: 0.753| gp_loss: 0.163| r_loss: 0.052| p_loss: 0.077| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.506
Train: Epoch [2437/3000], Step [60/158]| g_loss: 0.698| d_loss: 0.561| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.072| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.560
Train: Epoch [2437/3000], Step [90/158]| g_loss: 0.663| d_loss: 0.598| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.532
Train: Epoch [2437/3000], Step [120/158]| g_loss: 0.679| d_loss: 0.624| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.068| v_loss: 0.020| per_loss: 0.310 | a_loss: 0.545
Train: Epoch [2437/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.616| gp_loss: 0.060| r_loss: 0.051| p_loss: 0.066| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.527
Train: Epoch [2438/3000], Step [30/158]| g_loss: 0.659| d_loss: 0.706| gp_loss: 0.174| r_loss: 0.050| p_loss: 0.069| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.526
Train: Epoch [2438/3000], Step [60/158]| g_loss: 0.665| d_loss: 0.603| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.536
Train: Epoch [2438/3000], Step [90/158]| g_loss: 0.701| d_loss: 0.578| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.068| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.566
Train: Epoch [2438/3000], Step [120/158]| g_loss: 0.638| d_loss: 0.705| gp_loss: 0.054| r_loss: 0.055| p_loss: 0.074| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.495
Train: Epoch [2438/3000], Step [150/158]| g_loss: 0.634| d_loss: 0.607| gp_loss: 0.059| r_loss: 0.062| p_loss: 0.077| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.484
Train: Epoch [2439/3000], Step [30/158]| g_loss: 0.683| d_loss: 0.685| gp_loss: 0.180| r_loss: 0.053| p_loss: 0.074| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.545
Train: Epoch [2439/3000], Step [60/158]| g_loss: 0.659| d_loss: 0.600| gp_loss: 0.051| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.528
Train: Epoch [2439/3000], Step [90/158]| g_loss: 0.642| d_loss: 0.704| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.068| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.511
Train: Epoch [2439/3000], Step [120/158]| g_loss: 0.647| d_loss: 0.557| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.070| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.511
Train: Epoch [2439/3000], Step [150/158]| g_loss: 0.687| d_loss: 0.620| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.316 | a_loss: 0.551
Train: Epoch [2440/3000], Step [30/158]| g_loss: 0.639| d_loss: 0.705| gp_loss: 0.132| r_loss: 0.050| p_loss: 0.069| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.505
Train: Epoch [2440/3000], Step [60/158]| g_loss: 0.657| d_loss: 0.557| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.529
Train: Epoch [2440/3000], Step [90/158]| g_loss: 0.664| d_loss: 0.617| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.065| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.532
Train: Epoch [2440/3000], Step [120/158]| g_loss: 0.667| d_loss: 0.645| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.067| v_loss: 0.020| per_loss: 0.307 | a_loss: 0.535
Train: Epoch [2440/3000], Step [150/158]| g_loss: 0.654| d_loss: 0.611| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.524
Train: Epoch [2441/3000], Step [30/158]| g_loss: 0.671| d_loss: 0.705| gp_loss: 0.157| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.541
Train: Epoch [2441/3000], Step [60/158]| g_loss: 0.644| d_loss: 0.590| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.514
Train: Epoch [2441/3000], Step [90/158]| g_loss: 0.692| d_loss: 0.566| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.563
Train: Epoch [2441/3000], Step [120/158]| g_loss: 0.672| d_loss: 0.640| gp_loss: 0.055| r_loss: 0.051| p_loss: 0.070| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.536
Train: Epoch [2441/3000], Step [150/158]| g_loss: 0.600| d_loss: 0.739| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.067| v_loss: 0.018| per_loss: 0.294 | a_loss: 0.470
Train: Epoch [2442/3000], Step [30/158]| g_loss: 0.634| d_loss: 0.671| gp_loss: 0.111| r_loss: 0.053| p_loss: 0.068| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.496
Train: Epoch [2442/3000], Step [60/158]| g_loss: 0.679| d_loss: 0.616| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.069| v_loss: 0.020| per_loss: 0.323 | a_loss: 0.543
Train: Epoch [2442/3000], Step [90/158]| g_loss: 0.659| d_loss: 0.598| gp_loss: 0.059| r_loss: 0.055| p_loss: 0.073| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.517
Train: Epoch [2442/3000], Step [120/158]| g_loss: 0.646| d_loss: 0.634| gp_loss: 0.059| r_loss: 0.051| p_loss: 0.069| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.511
Train: Epoch [2442/3000], Step [150/158]| g_loss: 0.642| d_loss: 0.611| gp_loss: 0.065| r_loss: 0.051| p_loss: 0.070| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.506
Train: Epoch [2443/3000], Step [30/158]| g_loss: 0.650| d_loss: 0.706| gp_loss: 0.135| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.523
Train: Epoch [2443/3000], Step [60/158]| g_loss: 0.655| d_loss: 0.583| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.523
Train: Epoch [2443/3000], Step [90/158]| g_loss: 0.683| d_loss: 0.598| gp_loss: 0.059| r_loss: 0.052| p_loss: 0.070| v_loss: 0.020| per_loss: 0.323 | a_loss: 0.544
Train: Epoch [2443/3000], Step [120/158]| g_loss: 0.693| d_loss: 0.618| gp_loss: 0.061| r_loss: 0.051| p_loss: 0.070| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.556
Train: Epoch [2443/3000], Step [150/158]| g_loss: 0.638| d_loss: 0.635| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.505
Train: Epoch [2444/3000], Step [30/158]| g_loss: 0.643| d_loss: 0.757| gp_loss: 0.213| r_loss: 0.051| p_loss: 0.071| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.505
Train: Epoch [2444/3000], Step [60/158]| g_loss: 0.669| d_loss: 0.623| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.307 | a_loss: 0.536
Train: Epoch [2444/3000], Step [90/158]| g_loss: 0.647| d_loss: 0.684| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.307 | a_loss: 0.509
Train: Epoch [2444/3000], Step [120/158]| g_loss: 0.628| d_loss: 0.624| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.066| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.494
Train: Epoch [2444/3000], Step [150/158]| g_loss: 0.654| d_loss: 0.579| gp_loss: 0.060| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.522
Train: Epoch [2445/3000], Step [30/158]| g_loss: 0.670| d_loss: 0.717| gp_loss: 0.190| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.313 | a_loss: 0.538
Train: Epoch [2445/3000], Step [60/158]| g_loss: 0.689| d_loss: 0.547| gp_loss: 0.050| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.556
Train: Epoch [2445/3000], Step [90/158]| g_loss: 0.691| d_loss: 0.515| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.564
Train: Epoch [2445/3000], Step [120/158]| g_loss: 0.658| d_loss: 0.686| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.527
Train: Epoch [2445/3000], Step [150/158]| g_loss: 0.594| d_loss: 0.770| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.460
Train: Epoch [2446/3000], Step [30/158]| g_loss: 0.612| d_loss: 0.659| gp_loss: 0.124| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.314 | a_loss: 0.481
Train: Epoch [2446/3000], Step [60/158]| g_loss: 0.652| d_loss: 0.683| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.314 | a_loss: 0.519
Train: Epoch [2446/3000], Step [90/158]| g_loss: 0.646| d_loss: 0.655| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.512
Train: Epoch [2446/3000], Step [120/158]| g_loss: 0.649| d_loss: 0.638| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.514
Train: Epoch [2446/3000], Step [150/158]| g_loss: 0.645| d_loss: 0.608| gp_loss: 0.061| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.271 | a_loss: 0.519
Train: Epoch [2447/3000], Step [30/158]| g_loss: 0.662| d_loss: 0.689| gp_loss: 0.094| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.530
Train: Epoch [2447/3000], Step [60/158]| g_loss: 0.661| d_loss: 0.587| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.532
Train: Epoch [2447/3000], Step [90/158]| g_loss: 0.640| d_loss: 0.674| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.309 | a_loss: 0.508
Train: Epoch [2447/3000], Step [120/158]| g_loss: 0.628| d_loss: 0.617| gp_loss: 0.063| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.307 | a_loss: 0.494
Train: Epoch [2447/3000], Step [150/158]| g_loss: 0.655| d_loss: 0.599| gp_loss: 0.062| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.524
Train: Epoch [2448/3000], Step [30/158]| g_loss: 0.688| d_loss: 0.700| gp_loss: 0.185| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.309 | a_loss: 0.552
Train: Epoch [2448/3000], Step [60/158]| g_loss: 0.640| d_loss: 0.611| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.511
Train: Epoch [2448/3000], Step [90/158]| g_loss: 0.653| d_loss: 0.653| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.524
Train: Epoch [2448/3000], Step [120/158]| g_loss: 0.672| d_loss: 0.557| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.544
Train: Epoch [2448/3000], Step [150/158]| g_loss: 0.643| d_loss: 0.687| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.512
Train: Epoch [2449/3000], Step [30/158]| g_loss: 0.659| d_loss: 0.669| gp_loss: 0.100| r_loss: 0.051| p_loss: 0.066| v_loss: 0.019| per_loss: 0.324 | a_loss: 0.523
Train: Epoch [2449/3000], Step [60/158]| g_loss: 0.654| d_loss: 0.688| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.069| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.521
Train: Epoch [2449/3000], Step [90/158]| g_loss: 0.656| d_loss: 0.586| gp_loss: 0.063| r_loss: 0.051| p_loss: 0.066| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.522
Train: Epoch [2449/3000], Step [120/158]| g_loss: 0.667| d_loss: 0.571| gp_loss: 0.066| r_loss: 0.051| p_loss: 0.066| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.533
Train: Epoch [2449/3000], Step [150/158]| g_loss: 0.654| d_loss: 0.633| gp_loss: 0.063| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.307 | a_loss: 0.521
Train: Epoch [2450/3000], Step [30/158]| g_loss: 0.669| d_loss: 0.771| gp_loss: 0.211| r_loss: 0.050| p_loss: 0.068| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.534
Train: Epoch [2450/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.649| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.067| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.540
Train: Epoch [2450/3000], Step [90/158]| g_loss: 0.634| d_loss: 0.605| gp_loss: 0.052| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.502
Train: Epoch [2450/3000], Step [120/158]| g_loss: 0.623| d_loss: 0.675| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.491
Train: Epoch [2450/3000], Step [150/158]| g_loss: 0.641| d_loss: 0.584| gp_loss: 0.062| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.515
Test: Epoch [2450/3000]| g_loss: 0.648| r_loss: 0.393| p_loss: 0.314| v_loss: 0.021
Train: Epoch [2451/3000], Step [30/158]| g_loss: 0.669| d_loss: 0.629| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.537
Train: Epoch [2451/3000], Step [60/158]| g_loss: 0.633| d_loss: 0.668| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.503
Train: Epoch [2451/3000], Step [90/158]| g_loss: 0.645| d_loss: 0.593| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.061| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.519
Train: Epoch [2451/3000], Step [120/158]| g_loss: 0.645| d_loss: 0.637| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.515
Train: Epoch [2451/3000], Step [150/158]| g_loss: 0.684| d_loss: 0.508| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.553
Train: Epoch [2452/3000], Step [30/158]| g_loss: 0.660| d_loss: 0.763| gp_loss: 0.157| r_loss: 0.051| p_loss: 0.066| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.527
Train: Epoch [2452/3000], Step [60/158]| g_loss: 0.634| d_loss: 0.605| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.504
Train: Epoch [2452/3000], Step [90/158]| g_loss: 0.651| d_loss: 0.643| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.064| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.523
Train: Epoch [2452/3000], Step [120/158]| g_loss: 0.658| d_loss: 0.597| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.531
Train: Epoch [2452/3000], Step [150/158]| g_loss: 0.631| d_loss: 0.686| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.503
Train: Epoch [2453/3000], Step [30/158]| g_loss: 0.705| d_loss: 0.588| gp_loss: 0.157| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.579
Train: Epoch [2453/3000], Step [60/158]| g_loss: 0.680| d_loss: 0.551| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.065| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.550
Train: Epoch [2453/3000], Step [90/158]| g_loss: 0.666| d_loss: 0.684| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.063| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.538
Train: Epoch [2453/3000], Step [120/158]| g_loss: 0.637| d_loss: 0.598| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.507
Train: Epoch [2453/3000], Step [150/158]| g_loss: 0.630| d_loss: 0.711| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.500
Train: Epoch [2454/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.754| gp_loss: 0.213| r_loss: 0.053| p_loss: 0.072| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.524
Train: Epoch [2454/3000], Step [60/158]| g_loss: 0.679| d_loss: 0.557| gp_loss: 0.049| r_loss: 0.054| p_loss: 0.075| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.537
Train: Epoch [2454/3000], Step [90/158]| g_loss: 0.682| d_loss: 0.599| gp_loss: 0.051| r_loss: 0.050| p_loss: 0.071| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.546
Train: Epoch [2454/3000], Step [120/158]| g_loss: 0.638| d_loss: 0.688| gp_loss: 0.050| r_loss: 0.051| p_loss: 0.069| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.504
Train: Epoch [2454/3000], Step [150/158]| g_loss: 0.637| d_loss: 0.585| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.064| v_loss: 0.018| per_loss: 0.291 | a_loss: 0.509
Train: Epoch [2455/3000], Step [30/158]| g_loss: 0.585| d_loss: 0.809| gp_loss: 0.130| r_loss: 0.052| p_loss: 0.069| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.450
Train: Epoch [2455/3000], Step [60/158]| g_loss: 0.656| d_loss: 0.582| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.526
Train: Epoch [2455/3000], Step [90/158]| g_loss: 0.651| d_loss: 0.639| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.521
Train: Epoch [2455/3000], Step [120/158]| g_loss: 0.656| d_loss: 0.543| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.527
Train: Epoch [2455/3000], Step [150/158]| g_loss: 0.677| d_loss: 0.684| gp_loss: 0.059| r_loss: 0.053| p_loss: 0.072| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.538
Train: Epoch [2456/3000], Step [30/158]| g_loss: 0.618| d_loss: 0.814| gp_loss: 0.136| r_loss: 0.053| p_loss: 0.077| v_loss: 0.020| per_loss: 0.313 | a_loss: 0.475
Train: Epoch [2456/3000], Step [60/158]| g_loss: 0.621| d_loss: 0.587| gp_loss: 0.052| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.488
Train: Epoch [2456/3000], Step [90/158]| g_loss: 0.689| d_loss: 0.593| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.070| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.555
Train: Epoch [2456/3000], Step [120/158]| g_loss: 0.674| d_loss: 0.579| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.544
Train: Epoch [2456/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.606| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.070| v_loss: 0.020| per_loss: 0.310 | a_loss: 0.533
Train: Epoch [2457/3000], Step [30/158]| g_loss: 0.683| d_loss: 0.715| gp_loss: 0.178| r_loss: 0.051| p_loss: 0.071| v_loss: 0.020| per_loss: 0.311 | a_loss: 0.546
Train: Epoch [2457/3000], Step [60/158]| g_loss: 0.668| d_loss: 0.602| gp_loss: 0.050| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.538
Train: Epoch [2457/3000], Step [90/158]| g_loss: 0.628| d_loss: 0.651| gp_loss: 0.051| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.498
Train: Epoch [2457/3000], Step [120/158]| g_loss: 0.664| d_loss: 0.624| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.535
Train: Epoch [2457/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.566| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.537
Train: Epoch [2458/3000], Step [30/158]| g_loss: 0.647| d_loss: 0.704| gp_loss: 0.157| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.515
Train: Epoch [2458/3000], Step [60/158]| g_loss: 0.653| d_loss: 0.652| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.526
Train: Epoch [2458/3000], Step [90/158]| g_loss: 0.629| d_loss: 0.642| gp_loss: 0.054| r_loss: 0.051| p_loss: 0.066| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.495
Train: Epoch [2458/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.584| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.534
Train: Epoch [2458/3000], Step [150/158]| g_loss: 0.657| d_loss: 0.618| gp_loss: 0.059| r_loss: 0.046| p_loss: 0.059| v_loss: 0.018| per_loss: 0.296 | a_loss: 0.533
Train: Epoch [2459/3000], Step [30/158]| g_loss: 0.682| d_loss: 0.617| gp_loss: 0.150| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.553
Train: Epoch [2459/3000], Step [60/158]| g_loss: 0.698| d_loss: 0.589| gp_loss: 0.052| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.570
Train: Epoch [2459/3000], Step [90/158]| g_loss: 0.665| d_loss: 0.614| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.063| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.534
Train: Epoch [2459/3000], Step [120/158]| g_loss: 0.608| d_loss: 0.742| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.477
Train: Epoch [2459/3000], Step [150/158]| g_loss: 0.631| d_loss: 0.637| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.497
Train: Epoch [2460/3000], Step [30/158]| g_loss: 0.671| d_loss: 0.775| gp_loss: 0.215| r_loss: 0.048| p_loss: 0.067| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.540
Train: Epoch [2460/3000], Step [60/158]| g_loss: 0.658| d_loss: 0.604| gp_loss: 0.052| r_loss: 0.052| p_loss: 0.067| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.523
Train: Epoch [2460/3000], Step [90/158]| g_loss: 0.669| d_loss: 0.614| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.066| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.535
Train: Epoch [2460/3000], Step [120/158]| g_loss: 0.635| d_loss: 0.691| gp_loss: 0.052| r_loss: 0.056| p_loss: 0.074| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.491
Train: Epoch [2460/3000], Step [150/158]| g_loss: 0.642| d_loss: 0.554| gp_loss: 0.060| r_loss: 0.053| p_loss: 0.071| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.504
Train: Epoch [2461/3000], Step [30/158]| g_loss: 0.671| d_loss: 0.753| gp_loss: 0.195| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.537
Train: Epoch [2461/3000], Step [60/158]| g_loss: 0.640| d_loss: 0.639| gp_loss: 0.052| r_loss: 0.052| p_loss: 0.072| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.503
Train: Epoch [2461/3000], Step [90/158]| g_loss: 0.672| d_loss: 0.590| gp_loss: 0.057| r_loss: 0.054| p_loss: 0.069| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.535
Train: Epoch [2461/3000], Step [120/158]| g_loss: 0.664| d_loss: 0.612| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.531
Train: Epoch [2461/3000], Step [150/158]| g_loss: 0.686| d_loss: 0.632| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.067| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.554
Train: Epoch [2462/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.655| gp_loss: 0.134| r_loss: 0.048| p_loss: 0.068| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.533
Train: Epoch [2462/3000], Step [60/158]| g_loss: 0.671| d_loss: 0.553| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.543
Train: Epoch [2462/3000], Step [90/158]| g_loss: 0.671| d_loss: 0.677| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.536
Train: Epoch [2462/3000], Step [120/158]| g_loss: 0.619| d_loss: 0.696| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.065| v_loss: 0.018| per_loss: 0.304 | a_loss: 0.488
Train: Epoch [2462/3000], Step [150/158]| g_loss: 0.677| d_loss: 0.562| gp_loss: 0.062| r_loss: 0.055| p_loss: 0.071| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.537
Train: Epoch [2463/3000], Step [30/158]| g_loss: 0.691| d_loss: 0.623| gp_loss: 0.125| r_loss: 0.054| p_loss: 0.069| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.552
Train: Epoch [2463/3000], Step [60/158]| g_loss: 0.635| d_loss: 0.696| gp_loss: 0.052| r_loss: 0.049| p_loss: 0.068| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.503
Train: Epoch [2463/3000], Step [90/158]| g_loss: 0.638| d_loss: 0.588| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.513
Train: Epoch [2463/3000], Step [120/158]| g_loss: 0.660| d_loss: 0.549| gp_loss: 0.059| r_loss: 0.051| p_loss: 0.065| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.527
Train: Epoch [2463/3000], Step [150/158]| g_loss: 0.690| d_loss: 0.695| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.066| v_loss: 0.020| per_loss: 0.316 | a_loss: 0.557
Train: Epoch [2464/3000], Step [30/158]| g_loss: 0.662| d_loss: 0.745| gp_loss: 0.205| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.533
Train: Epoch [2464/3000], Step [60/158]| g_loss: 0.642| d_loss: 0.640| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.513
Train: Epoch [2464/3000], Step [90/158]| g_loss: 0.662| d_loss: 0.609| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.064| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.530
Train: Epoch [2464/3000], Step [120/158]| g_loss: 0.670| d_loss: 0.524| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.064| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.536
Train: Epoch [2464/3000], Step [150/158]| g_loss: 0.672| d_loss: 0.687| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.547
Train: Epoch [2465/3000], Step [30/158]| g_loss: 0.623| d_loss: 0.736| gp_loss: 0.152| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.493
Train: Epoch [2465/3000], Step [60/158]| g_loss: 0.659| d_loss: 0.665| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.315 | a_loss: 0.525
Train: Epoch [2465/3000], Step [90/158]| g_loss: 0.618| d_loss: 0.671| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.060| v_loss: 0.018| per_loss: 0.303 | a_loss: 0.493
Train: Epoch [2465/3000], Step [120/158]| g_loss: 0.637| d_loss: 0.605| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.278 | a_loss: 0.507
Train: Epoch [2465/3000], Step [150/158]| g_loss: 0.665| d_loss: 0.574| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.065| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.531
Train: Epoch [2466/3000], Step [30/158]| g_loss: 0.702| d_loss: 0.682| gp_loss: 0.203| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.571
Train: Epoch [2466/3000], Step [60/158]| g_loss: 0.641| d_loss: 0.702| gp_loss: 0.050| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.511
Train: Epoch [2466/3000], Step [90/158]| g_loss: 0.647| d_loss: 0.642| gp_loss: 0.048| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.517
Train: Epoch [2466/3000], Step [120/158]| g_loss: 0.643| d_loss: 0.591| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.064| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.510
Train: Epoch [2466/3000], Step [150/158]| g_loss: 0.683| d_loss: 0.613| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.555
Train: Epoch [2467/3000], Step [30/158]| g_loss: 0.643| d_loss: 0.806| gp_loss: 0.256| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.510
Train: Epoch [2467/3000], Step [60/158]| g_loss: 0.635| d_loss: 0.665| gp_loss: 0.045| r_loss: 0.047| p_loss: 0.060| v_loss: 0.018| per_loss: 0.284 | a_loss: 0.511
Train: Epoch [2467/3000], Step [90/158]| g_loss: 0.638| d_loss: 0.608| gp_loss: 0.048| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.512
Train: Epoch [2467/3000], Step [120/158]| g_loss: 0.629| d_loss: 0.640| gp_loss: 0.050| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.504
Train: Epoch [2467/3000], Step [150/158]| g_loss: 0.643| d_loss: 0.625| gp_loss: 0.049| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.512
Train: Epoch [2468/3000], Step [30/158]| g_loss: 0.701| d_loss: 0.652| gp_loss: 0.147| r_loss: 0.048| p_loss: 0.066| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.569
Train: Epoch [2468/3000], Step [60/158]| g_loss: 0.638| d_loss: 0.645| gp_loss: 0.048| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.512
Train: Epoch [2468/3000], Step [90/158]| g_loss: 0.647| d_loss: 0.579| gp_loss: 0.050| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.518
Train: Epoch [2468/3000], Step [120/158]| g_loss: 0.639| d_loss: 0.636| gp_loss: 0.052| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.508
Train: Epoch [2468/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.595| gp_loss: 0.051| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.544
Train: Epoch [2469/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.586| gp_loss: 0.128| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.540
Train: Epoch [2469/3000], Step [60/158]| g_loss: 0.685| d_loss: 0.638| gp_loss: 0.050| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.559
Train: Epoch [2469/3000], Step [90/158]| g_loss: 0.623| d_loss: 0.716| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.495
Train: Epoch [2469/3000], Step [120/158]| g_loss: 0.624| d_loss: 0.636| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.496
Train: Epoch [2469/3000], Step [150/158]| g_loss: 0.647| d_loss: 0.591| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.516
Train: Epoch [2470/3000], Step [30/158]| g_loss: 0.659| d_loss: 0.731| gp_loss: 0.144| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.530
Train: Epoch [2470/3000], Step [60/158]| g_loss: 0.654| d_loss: 0.549| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.524
Train: Epoch [2470/3000], Step [90/158]| g_loss: 0.628| d_loss: 0.734| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.500
Train: Epoch [2470/3000], Step [120/158]| g_loss: 0.638| d_loss: 0.575| gp_loss: 0.062| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.508
Train: Epoch [2470/3000], Step [150/158]| g_loss: 0.678| d_loss: 0.520| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.552
Train: Epoch [2471/3000], Step [30/158]| g_loss: 0.725| d_loss: 0.587| gp_loss: 0.139| r_loss: 0.051| p_loss: 0.063| v_loss: 0.018| per_loss: 0.291 | a_loss: 0.595
Train: Epoch [2471/3000], Step [60/158]| g_loss: 0.698| d_loss: 0.580| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.563
Train: Epoch [2471/3000], Step [90/158]| g_loss: 0.677| d_loss: 0.621| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.548
Train: Epoch [2471/3000], Step [120/158]| g_loss: 0.632| d_loss: 0.693| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.505
Train: Epoch [2471/3000], Step [150/158]| g_loss: 0.634| d_loss: 0.642| gp_loss: 0.055| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.499
Train: Epoch [2472/3000], Step [30/158]| g_loss: 0.623| d_loss: 0.727| gp_loss: 0.094| r_loss: 0.049| p_loss: 0.069| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.490
Train: Epoch [2472/3000], Step [60/158]| g_loss: 0.678| d_loss: 0.603| gp_loss: 0.059| r_loss: 0.053| p_loss: 0.069| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.541
Train: Epoch [2472/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.668| gp_loss: 0.061| r_loss: 0.053| p_loss: 0.070| v_loss: 0.020| per_loss: 0.310 | a_loss: 0.515
Train: Epoch [2472/3000], Step [120/158]| g_loss: 0.655| d_loss: 0.589| gp_loss: 0.065| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.519
Train: Epoch [2472/3000], Step [150/158]| g_loss: 0.685| d_loss: 0.624| gp_loss: 0.063| r_loss: 0.048| p_loss: 0.068| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.554
Train: Epoch [2473/3000], Step [30/158]| g_loss: 0.648| d_loss: 0.701| gp_loss: 0.195| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.518
Train: Epoch [2473/3000], Step [60/158]| g_loss: 0.650| d_loss: 0.693| gp_loss: 0.051| r_loss: 0.049| p_loss: 0.069| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.516
Train: Epoch [2473/3000], Step [90/158]| g_loss: 0.675| d_loss: 0.535| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.543
Train: Epoch [2473/3000], Step [120/158]| g_loss: 0.689| d_loss: 0.621| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.559
Train: Epoch [2473/3000], Step [150/158]| g_loss: 0.640| d_loss: 0.660| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.508
Train: Epoch [2474/3000], Step [30/158]| g_loss: 0.631| d_loss: 0.713| gp_loss: 0.126| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.502
Train: Epoch [2474/3000], Step [60/158]| g_loss: 0.661| d_loss: 0.597| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.309 | a_loss: 0.528
Train: Epoch [2474/3000], Step [90/158]| g_loss: 0.668| d_loss: 0.579| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.535
Train: Epoch [2474/3000], Step [120/158]| g_loss: 0.665| d_loss: 0.598| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.536
Train: Epoch [2474/3000], Step [150/158]| g_loss: 0.647| d_loss: 0.593| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.516
Train: Epoch [2475/3000], Step [30/158]| g_loss: 0.682| d_loss: 0.700| gp_loss: 0.154| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.551
Train: Epoch [2475/3000], Step [60/158]| g_loss: 0.740| d_loss: 0.493| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.607
Train: Epoch [2475/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.685| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.524
Train: Epoch [2475/3000], Step [120/158]| g_loss: 0.619| d_loss: 0.648| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.489
Train: Epoch [2475/3000], Step [150/158]| g_loss: 0.638| d_loss: 0.658| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.067| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.502
Train: Epoch [2476/3000], Step [30/158]| g_loss: 0.634| d_loss: 0.813| gp_loss: 0.203| r_loss: 0.049| p_loss: 0.068| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.502
Train: Epoch [2476/3000], Step [60/158]| g_loss: 0.645| d_loss: 0.656| gp_loss: 0.050| r_loss: 0.053| p_loss: 0.072| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.506
Train: Epoch [2476/3000], Step [90/158]| g_loss: 0.633| d_loss: 0.621| gp_loss: 0.051| r_loss: 0.051| p_loss: 0.068| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.499
Train: Epoch [2476/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.611| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.536
Train: Epoch [2476/3000], Step [150/158]| g_loss: 0.630| d_loss: 0.587| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.502
Train: Epoch [2477/3000], Step [30/158]| g_loss: 0.678| d_loss: 0.660| gp_loss: 0.115| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.548
Train: Epoch [2477/3000], Step [60/158]| g_loss: 0.654| d_loss: 0.609| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.523
Train: Epoch [2477/3000], Step [90/158]| g_loss: 0.666| d_loss: 0.611| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.063| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.535
Train: Epoch [2477/3000], Step [120/158]| g_loss: 0.660| d_loss: 0.576| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.535
Train: Epoch [2477/3000], Step [150/158]| g_loss: 0.657| d_loss: 0.621| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.528
Train: Epoch [2478/3000], Step [30/158]| g_loss: 0.692| d_loss: 0.681| gp_loss: 0.177| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.562
Train: Epoch [2478/3000], Step [60/158]| g_loss: 0.675| d_loss: 0.629| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.547
Train: Epoch [2478/3000], Step [90/158]| g_loss: 0.669| d_loss: 0.549| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.063| v_loss: 0.018| per_loss: 0.290 | a_loss: 0.542
Train: Epoch [2478/3000], Step [120/158]| g_loss: 0.695| d_loss: 0.590| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.064| v_loss: 0.020| per_loss: 0.312 | a_loss: 0.562
Train: Epoch [2478/3000], Step [150/158]| g_loss: 0.627| d_loss: 0.735| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.070| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.492
Train: Epoch [2479/3000], Step [30/158]| g_loss: 0.642| d_loss: 0.760| gp_loss: 0.166| r_loss: 0.050| p_loss: 0.069| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.509
Train: Epoch [2479/3000], Step [60/158]| g_loss: 0.609| d_loss: 0.713| gp_loss: 0.050| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.472
Train: Epoch [2479/3000], Step [90/158]| g_loss: 0.651| d_loss: 0.581| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.314 | a_loss: 0.513
Train: Epoch [2479/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.580| gp_loss: 0.055| r_loss: 0.054| p_loss: 0.069| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.528
Train: Epoch [2479/3000], Step [150/158]| g_loss: 0.663| d_loss: 0.610| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.069| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.528
Train: Epoch [2480/3000], Step [30/158]| g_loss: 0.687| d_loss: 0.667| gp_loss: 0.128| r_loss: 0.052| p_loss: 0.070| v_loss: 0.021| per_loss: 0.309 | a_loss: 0.549
Train: Epoch [2480/3000], Step [60/158]| g_loss: 0.657| d_loss: 0.698| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.071| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.522
Train: Epoch [2480/3000], Step [90/158]| g_loss: 0.647| d_loss: 0.625| gp_loss: 0.055| r_loss: 0.051| p_loss: 0.068| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.513
Train: Epoch [2480/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.526| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.535
Train: Epoch [2480/3000], Step [150/158]| g_loss: 0.696| d_loss: 0.596| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.565
Train: Epoch [2481/3000], Step [30/158]| g_loss: 0.660| d_loss: 0.675| gp_loss: 0.140| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.529
Train: Epoch [2481/3000], Step [60/158]| g_loss: 0.662| d_loss: 0.619| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.531
Train: Epoch [2481/3000], Step [90/158]| g_loss: 0.673| d_loss: 0.642| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.542
Train: Epoch [2481/3000], Step [120/158]| g_loss: 0.652| d_loss: 0.613| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.520
Train: Epoch [2481/3000], Step [150/158]| g_loss: 0.687| d_loss: 0.597| gp_loss: 0.060| r_loss: 0.052| p_loss: 0.067| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.552
Train: Epoch [2482/3000], Step [30/158]| g_loss: 0.627| d_loss: 0.763| gp_loss: 0.137| r_loss: 0.049| p_loss: 0.070| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.493
Train: Epoch [2482/3000], Step [60/158]| g_loss: 0.605| d_loss: 0.644| gp_loss: 0.062| r_loss: 0.051| p_loss: 0.066| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.472
Train: Epoch [2482/3000], Step [90/158]| g_loss: 0.708| d_loss: 0.498| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.067| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.572
Train: Epoch [2482/3000], Step [120/158]| g_loss: 0.667| d_loss: 0.634| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.065| v_loss: 0.018| per_loss: 0.286 | a_loss: 0.539
Train: Epoch [2482/3000], Step [150/158]| g_loss: 0.680| d_loss: 0.638| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.068| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.548
Train: Epoch [2483/3000], Step [30/158]| g_loss: 0.654| d_loss: 0.739| gp_loss: 0.143| r_loss: 0.048| p_loss: 0.067| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.525
Train: Epoch [2483/3000], Step [60/158]| g_loss: 0.639| d_loss: 0.592| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.067| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.510
Train: Epoch [2483/3000], Step [90/158]| g_loss: 0.686| d_loss: 0.545| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.314 | a_loss: 0.551
Train: Epoch [2483/3000], Step [120/158]| g_loss: 0.688| d_loss: 0.571| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.064| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.558
Train: Epoch [2483/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.637| gp_loss: 0.054| r_loss: 0.051| p_loss: 0.066| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.541
Train: Epoch [2484/3000], Step [30/158]| g_loss: 0.636| d_loss: 0.765| gp_loss: 0.193| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.511
Train: Epoch [2484/3000], Step [60/158]| g_loss: 0.605| d_loss: 0.705| gp_loss: 0.049| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.310 | a_loss: 0.471
Train: Epoch [2484/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.597| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.526
Train: Epoch [2484/3000], Step [120/158]| g_loss: 0.641| d_loss: 0.607| gp_loss: 0.052| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.516
Train: Epoch [2484/3000], Step [150/158]| g_loss: 0.668| d_loss: 0.608| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.537
Train: Epoch [2485/3000], Step [30/158]| g_loss: 0.676| d_loss: 0.699| gp_loss: 0.125| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.542
Train: Epoch [2485/3000], Step [60/158]| g_loss: 0.658| d_loss: 0.537| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.313 | a_loss: 0.526
Train: Epoch [2485/3000], Step [90/158]| g_loss: 0.666| d_loss: 0.645| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.540
Train: Epoch [2485/3000], Step [120/158]| g_loss: 0.621| d_loss: 0.723| gp_loss: 0.055| r_loss: 0.053| p_loss: 0.069| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.483
Train: Epoch [2485/3000], Step [150/158]| g_loss: 0.671| d_loss: 0.542| gp_loss: 0.063| r_loss: 0.047| p_loss: 0.066| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.544
Train: Epoch [2486/3000], Step [30/158]| g_loss: 0.596| d_loss: 0.842| gp_loss: 0.168| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.466
Train: Epoch [2486/3000], Step [60/158]| g_loss: 0.613| d_loss: 0.651| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.066| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.481
Train: Epoch [2486/3000], Step [90/158]| g_loss: 0.658| d_loss: 0.554| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.531
Train: Epoch [2486/3000], Step [120/158]| g_loss: 0.707| d_loss: 0.592| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.067| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.576
Train: Epoch [2486/3000], Step [150/158]| g_loss: 0.616| d_loss: 0.603| gp_loss: 0.052| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.485
Train: Epoch [2487/3000], Step [30/158]| g_loss: 0.683| d_loss: 0.724| gp_loss: 0.179| r_loss: 0.049| p_loss: 0.061| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.555
Train: Epoch [2487/3000], Step [60/158]| g_loss: 0.631| d_loss: 0.670| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.502
Train: Epoch [2487/3000], Step [90/158]| g_loss: 0.615| d_loss: 0.667| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.485
Train: Epoch [2487/3000], Step [120/158]| g_loss: 0.664| d_loss: 0.591| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.307 | a_loss: 0.532
Train: Epoch [2487/3000], Step [150/158]| g_loss: 0.650| d_loss: 0.545| gp_loss: 0.057| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.526
Train: Epoch [2488/3000], Step [30/158]| g_loss: 0.690| d_loss: 0.628| gp_loss: 0.117| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.561
Train: Epoch [2488/3000], Step [60/158]| g_loss: 0.698| d_loss: 0.609| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.569
Train: Epoch [2488/3000], Step [90/158]| g_loss: 0.662| d_loss: 0.588| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.531
Train: Epoch [2488/3000], Step [120/158]| g_loss: 0.665| d_loss: 0.713| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.532
Train: Epoch [2488/3000], Step [150/158]| g_loss: 0.625| d_loss: 0.625| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.067| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.496
Train: Epoch [2489/3000], Step [30/158]| g_loss: 0.607| d_loss: 0.764| gp_loss: 0.147| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.479
Train: Epoch [2489/3000], Step [60/158]| g_loss: 0.643| d_loss: 0.529| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.515
Train: Epoch [2489/3000], Step [90/158]| g_loss: 0.697| d_loss: 0.544| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.068| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.564
Train: Epoch [2489/3000], Step [120/158]| g_loss: 0.669| d_loss: 0.677| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.538
Train: Epoch [2489/3000], Step [150/158]| g_loss: 0.693| d_loss: 0.641| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.066| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.560
Train: Epoch [2490/3000], Step [30/158]| g_loss: 0.625| d_loss: 0.734| gp_loss: 0.148| r_loss: 0.051| p_loss: 0.070| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.488
Train: Epoch [2490/3000], Step [60/158]| g_loss: 0.638| d_loss: 0.619| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.510
Train: Epoch [2490/3000], Step [90/158]| g_loss: 0.676| d_loss: 0.623| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.307 | a_loss: 0.540
Train: Epoch [2490/3000], Step [120/158]| g_loss: 0.650| d_loss: 0.641| gp_loss: 0.062| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.518
Train: Epoch [2490/3000], Step [150/158]| g_loss: 0.689| d_loss: 0.564| gp_loss: 0.063| r_loss: 0.054| p_loss: 0.067| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.549
Train: Epoch [2491/3000], Step [30/158]| g_loss: 0.681| d_loss: 0.742| gp_loss: 0.185| r_loss: 0.056| p_loss: 0.077| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.536
Train: Epoch [2491/3000], Step [60/158]| g_loss: 0.658| d_loss: 0.626| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.068| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.523
Train: Epoch [2491/3000], Step [90/158]| g_loss: 0.682| d_loss: 0.599| gp_loss: 0.055| r_loss: 0.056| p_loss: 0.074| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.540
Train: Epoch [2491/3000], Step [120/158]| g_loss: 0.678| d_loss: 0.613| gp_loss: 0.056| r_loss: 0.055| p_loss: 0.071| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.539
Train: Epoch [2491/3000], Step [150/158]| g_loss: 0.646| d_loss: 0.628| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.069| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.512
Train: Epoch [2492/3000], Step [30/158]| g_loss: 0.641| d_loss: 0.741| gp_loss: 0.215| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.514
Train: Epoch [2492/3000], Step [60/158]| g_loss: 0.619| d_loss: 0.640| gp_loss: 0.051| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.492
Train: Epoch [2492/3000], Step [90/158]| g_loss: 0.640| d_loss: 0.654| gp_loss: 0.051| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.513
Train: Epoch [2492/3000], Step [120/158]| g_loss: 0.685| d_loss: 0.527| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.554
Train: Epoch [2492/3000], Step [150/158]| g_loss: 0.695| d_loss: 0.620| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.064| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.563
Train: Epoch [2493/3000], Step [30/158]| g_loss: 0.636| d_loss: 0.754| gp_loss: 0.112| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.509
Train: Epoch [2493/3000], Step [60/158]| g_loss: 0.646| d_loss: 0.662| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.519
Train: Epoch [2493/3000], Step [90/158]| g_loss: 0.613| d_loss: 0.619| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.486
Train: Epoch [2493/3000], Step [120/158]| g_loss: 0.660| d_loss: 0.653| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.066| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.526
Train: Epoch [2493/3000], Step [150/158]| g_loss: 0.663| d_loss: 0.524| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.535
Train: Epoch [2494/3000], Step [30/158]| g_loss: 0.673| d_loss: 0.708| gp_loss: 0.125| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.544
Train: Epoch [2494/3000], Step [60/158]| g_loss: 0.640| d_loss: 0.586| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.510
Train: Epoch [2494/3000], Step [90/158]| g_loss: 0.690| d_loss: 0.570| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.564
Train: Epoch [2494/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.592| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.061| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.548
Train: Epoch [2494/3000], Step [150/158]| g_loss: 0.656| d_loss: 0.647| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.525
Train: Epoch [2495/3000], Step [30/158]| g_loss: 0.637| d_loss: 0.742| gp_loss: 0.147| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.507
Train: Epoch [2495/3000], Step [60/158]| g_loss: 0.662| d_loss: 0.575| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.537
Train: Epoch [2495/3000], Step [90/158]| g_loss: 0.625| d_loss: 0.685| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.497
Train: Epoch [2495/3000], Step [120/158]| g_loss: 0.660| d_loss: 0.602| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.061| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.532
Train: Epoch [2495/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.577| gp_loss: 0.061| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.532
Train: Epoch [2496/3000], Step [30/158]| g_loss: 0.617| d_loss: 0.728| gp_loss: 0.156| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.490
Train: Epoch [2496/3000], Step [60/158]| g_loss: 0.629| d_loss: 0.687| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.500
Train: Epoch [2496/3000], Step [90/158]| g_loss: 0.692| d_loss: 0.566| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.070| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.557
Train: Epoch [2496/3000], Step [120/158]| g_loss: 0.673| d_loss: 0.544| gp_loss: 0.056| r_loss: 0.054| p_loss: 0.071| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.536
Train: Epoch [2496/3000], Step [150/158]| g_loss: 0.657| d_loss: 0.684| gp_loss: 0.055| r_loss: 0.052| p_loss: 0.070| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.522
Train: Epoch [2497/3000], Step [30/158]| g_loss: 0.635| d_loss: 0.745| gp_loss: 0.152| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.502
Train: Epoch [2497/3000], Step [60/158]| g_loss: 0.653| d_loss: 0.585| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.068| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.522
Train: Epoch [2497/3000], Step [90/158]| g_loss: 0.667| d_loss: 0.582| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.534
Train: Epoch [2497/3000], Step [120/158]| g_loss: 0.649| d_loss: 0.696| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.515
Train: Epoch [2497/3000], Step [150/158]| g_loss: 0.668| d_loss: 0.580| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.537
Train: Epoch [2498/3000], Step [30/158]| g_loss: 0.666| d_loss: 0.740| gp_loss: 0.180| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.536
Train: Epoch [2498/3000], Step [60/158]| g_loss: 0.670| d_loss: 0.573| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.062| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.538
Train: Epoch [2498/3000], Step [90/158]| g_loss: 0.681| d_loss: 0.577| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.549
Train: Epoch [2498/3000], Step [120/158]| g_loss: 0.654| d_loss: 0.583| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.527
Train: Epoch [2498/3000], Step [150/158]| g_loss: 0.672| d_loss: 0.668| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.069| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.540
Train: Epoch [2499/3000], Step [30/158]| g_loss: 0.658| d_loss: 0.697| gp_loss: 0.171| r_loss: 0.049| p_loss: 0.067| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.528
Train: Epoch [2499/3000], Step [60/158]| g_loss: 0.634| d_loss: 0.674| gp_loss: 0.047| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.502
Train: Epoch [2499/3000], Step [90/158]| g_loss: 0.653| d_loss: 0.566| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.526
Train: Epoch [2499/3000], Step [120/158]| g_loss: 0.671| d_loss: 0.635| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.543
Train: Epoch [2499/3000], Step [150/158]| g_loss: 0.648| d_loss: 0.614| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.516
Train: Epoch [2500/3000], Step [30/158]| g_loss: 0.673| d_loss: 0.631| gp_loss: 0.131| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.545
Train: Epoch [2500/3000], Step [60/158]| g_loss: 0.660| d_loss: 0.604| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.534
Train: Epoch [2500/3000], Step [90/158]| g_loss: 0.683| d_loss: 0.629| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.555
Train: Epoch [2500/3000], Step [120/158]| g_loss: 0.656| d_loss: 0.621| gp_loss: 0.055| r_loss: 0.051| p_loss: 0.065| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.523
Train: Epoch [2500/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.633| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.528
Test: Epoch [2500/3000]| g_loss: 0.639| r_loss: 0.393| p_loss: 0.314| v_loss: 0.021
Train: Epoch [2501/3000], Step [30/158]| g_loss: 0.591| d_loss: 0.691| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.463
Train: Epoch [2501/3000], Step [60/158]| g_loss: 0.644| d_loss: 0.621| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.510
Train: Epoch [2501/3000], Step [90/158]| g_loss: 0.678| d_loss: 0.575| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.547
Train: Epoch [2501/3000], Step [120/158]| g_loss: 0.622| d_loss: 0.675| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.069| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.489
Train: Epoch [2501/3000], Step [150/158]| g_loss: 0.690| d_loss: 0.545| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.558
Train: Epoch [2502/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.716| gp_loss: 0.180| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.534
Train: Epoch [2502/3000], Step [60/158]| g_loss: 0.680| d_loss: 0.585| gp_loss: 0.051| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.547
Train: Epoch [2502/3000], Step [90/158]| g_loss: 0.701| d_loss: 0.607| gp_loss: 0.050| r_loss: 0.048| p_loss: 0.067| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.571
Train: Epoch [2502/3000], Step [120/158]| g_loss: 0.645| d_loss: 0.683| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.514
Train: Epoch [2502/3000], Step [150/158]| g_loss: 0.627| d_loss: 0.604| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.498
Train: Epoch [2503/3000], Step [30/158]| g_loss: 0.681| d_loss: 0.681| gp_loss: 0.150| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.550
Train: Epoch [2503/3000], Step [60/158]| g_loss: 0.675| d_loss: 0.524| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.550
Train: Epoch [2503/3000], Step [90/158]| g_loss: 0.685| d_loss: 0.663| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.555
Train: Epoch [2503/3000], Step [120/158]| g_loss: 0.604| d_loss: 0.656| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.476
Train: Epoch [2503/3000], Step [150/158]| g_loss: 0.644| d_loss: 0.607| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.514
Train: Epoch [2504/3000], Step [30/158]| g_loss: 0.668| d_loss: 0.758| gp_loss: 0.174| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.536
Train: Epoch [2504/3000], Step [60/158]| g_loss: 0.677| d_loss: 0.553| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.550
Train: Epoch [2504/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.616| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.064| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.526
Train: Epoch [2504/3000], Step [120/158]| g_loss: 0.668| d_loss: 0.571| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.539
Train: Epoch [2504/3000], Step [150/158]| g_loss: 0.641| d_loss: 0.669| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.307 | a_loss: 0.508
Train: Epoch [2505/3000], Step [30/158]| g_loss: 0.618| d_loss: 0.781| gp_loss: 0.165| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.489
Train: Epoch [2505/3000], Step [60/158]| g_loss: 0.630| d_loss: 0.651| gp_loss: 0.051| r_loss: 0.053| p_loss: 0.070| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.492
Train: Epoch [2505/3000], Step [90/158]| g_loss: 0.645| d_loss: 0.588| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.514
Train: Epoch [2505/3000], Step [120/158]| g_loss: 0.687| d_loss: 0.626| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.555
Train: Epoch [2505/3000], Step [150/158]| g_loss: 0.630| d_loss: 0.607| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.501
Train: Epoch [2506/3000], Step [30/158]| g_loss: 0.670| d_loss: 0.756| gp_loss: 0.194| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.540
Train: Epoch [2506/3000], Step [60/158]| g_loss: 0.632| d_loss: 0.664| gp_loss: 0.049| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.501
Train: Epoch [2506/3000], Step [90/158]| g_loss: 0.627| d_loss: 0.640| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.498
Train: Epoch [2506/3000], Step [120/158]| g_loss: 0.641| d_loss: 0.615| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.510
Train: Epoch [2506/3000], Step [150/158]| g_loss: 0.700| d_loss: 0.583| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.567
Train: Epoch [2507/3000], Step [30/158]| g_loss: 0.701| d_loss: 0.613| gp_loss: 0.119| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.570
Train: Epoch [2507/3000], Step [60/158]| g_loss: 0.665| d_loss: 0.588| gp_loss: 0.049| r_loss: 0.051| p_loss: 0.065| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.533
Train: Epoch [2507/3000], Step [90/158]| g_loss: 0.617| d_loss: 0.690| gp_loss: 0.050| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.491
Train: Epoch [2507/3000], Step [120/158]| g_loss: 0.670| d_loss: 0.595| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.543
Train: Epoch [2507/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.617| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.528
Train: Epoch [2508/3000], Step [30/158]| g_loss: 0.649| d_loss: 0.710| gp_loss: 0.152| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.519
Train: Epoch [2508/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.565| gp_loss: 0.051| r_loss: 0.051| p_loss: 0.068| v_loss: 0.021| per_loss: 0.294 | a_loss: 0.538
Train: Epoch [2508/3000], Step [90/158]| g_loss: 0.647| d_loss: 0.662| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.515
Train: Epoch [2508/3000], Step [120/158]| g_loss: 0.635| d_loss: 0.666| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.067| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.505
Train: Epoch [2508/3000], Step [150/158]| g_loss: 0.663| d_loss: 0.573| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.533
Train: Epoch [2509/3000], Step [30/158]| g_loss: 0.667| d_loss: 0.636| gp_loss: 0.127| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.539
Train: Epoch [2509/3000], Step [60/158]| g_loss: 0.689| d_loss: 0.541| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.064| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.556
Train: Epoch [2509/3000], Step [90/158]| g_loss: 0.655| d_loss: 0.755| gp_loss: 0.050| r_loss: 0.046| p_loss: 0.063| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.530
Train: Epoch [2509/3000], Step [120/158]| g_loss: 0.633| d_loss: 0.667| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.499
Train: Epoch [2509/3000], Step [150/158]| g_loss: 0.632| d_loss: 0.564| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.505
Train: Epoch [2510/3000], Step [30/158]| g_loss: 0.668| d_loss: 0.854| gp_loss: 0.244| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.538
Train: Epoch [2510/3000], Step [60/158]| g_loss: 0.650| d_loss: 0.639| gp_loss: 0.052| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.309 | a_loss: 0.517
Train: Epoch [2510/3000], Step [90/158]| g_loss: 0.644| d_loss: 0.610| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.513
Train: Epoch [2510/3000], Step [120/158]| g_loss: 0.650| d_loss: 0.642| gp_loss: 0.050| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.518
Train: Epoch [2510/3000], Step [150/158]| g_loss: 0.690| d_loss: 0.536| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.067| v_loss: 0.020| per_loss: 0.284 | a_loss: 0.560
Train: Epoch [2511/3000], Step [30/158]| g_loss: 0.601| d_loss: 0.787| gp_loss: 0.105| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.470
Train: Epoch [2511/3000], Step [60/158]| g_loss: 0.656| d_loss: 0.551| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.528
Train: Epoch [2511/3000], Step [90/158]| g_loss: 0.665| d_loss: 0.663| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.283 | a_loss: 0.536
Train: Epoch [2511/3000], Step [120/158]| g_loss: 0.643| d_loss: 0.614| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.516
Train: Epoch [2511/3000], Step [150/158]| g_loss: 0.685| d_loss: 0.581| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.556
Train: Epoch [2512/3000], Step [30/158]| g_loss: 0.636| d_loss: 0.693| gp_loss: 0.142| r_loss: 0.047| p_loss: 0.063| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.508
Train: Epoch [2512/3000], Step [60/158]| g_loss: 0.667| d_loss: 0.602| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.064| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.534
Train: Epoch [2512/3000], Step [90/158]| g_loss: 0.675| d_loss: 0.514| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.546
Train: Epoch [2512/3000], Step [120/158]| g_loss: 0.658| d_loss: 0.717| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.530
Train: Epoch [2512/3000], Step [150/158]| g_loss: 0.654| d_loss: 0.566| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.063| v_loss: 0.018| per_loss: 0.280 | a_loss: 0.528
Train: Epoch [2513/3000], Step [30/158]| g_loss: 0.639| d_loss: 0.853| gp_loss: 0.221| r_loss: 0.049| p_loss: 0.067| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.508
Train: Epoch [2513/3000], Step [60/158]| g_loss: 0.612| d_loss: 0.668| gp_loss: 0.050| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.482
Train: Epoch [2513/3000], Step [90/158]| g_loss: 0.650| d_loss: 0.555| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.521
Train: Epoch [2513/3000], Step [120/158]| g_loss: 0.680| d_loss: 0.629| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.547
Train: Epoch [2513/3000], Step [150/158]| g_loss: 0.688| d_loss: 0.609| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.555
Train: Epoch [2514/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.709| gp_loss: 0.136| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.525
Train: Epoch [2514/3000], Step [60/158]| g_loss: 0.608| d_loss: 0.641| gp_loss: 0.054| r_loss: 0.054| p_loss: 0.066| v_loss: 0.019| per_loss: 0.273 | a_loss: 0.475
Train: Epoch [2514/3000], Step [90/158]| g_loss: 0.677| d_loss: 0.511| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.545
Train: Epoch [2514/3000], Step [120/158]| g_loss: 0.692| d_loss: 0.583| gp_loss: 0.051| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.315 | a_loss: 0.559
Train: Epoch [2514/3000], Step [150/158]| g_loss: 0.660| d_loss: 0.660| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.066| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.527
Train: Epoch [2515/3000], Step [30/158]| g_loss: 0.641| d_loss: 0.747| gp_loss: 0.145| r_loss: 0.060| p_loss: 0.074| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.495
Train: Epoch [2515/3000], Step [60/158]| g_loss: 0.662| d_loss: 0.614| gp_loss: 0.056| r_loss: 0.053| p_loss: 0.072| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.523
Train: Epoch [2515/3000], Step [90/158]| g_loss: 0.667| d_loss: 0.595| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.538
Train: Epoch [2515/3000], Step [120/158]| g_loss: 0.668| d_loss: 0.647| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.537
Train: Epoch [2515/3000], Step [150/158]| g_loss: 0.650| d_loss: 0.651| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.516
Train: Epoch [2516/3000], Step [30/158]| g_loss: 0.630| d_loss: 0.727| gp_loss: 0.142| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.502
Train: Epoch [2516/3000], Step [60/158]| g_loss: 0.632| d_loss: 0.594| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.503
Train: Epoch [2516/3000], Step [90/158]| g_loss: 0.658| d_loss: 0.631| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.530
Train: Epoch [2516/3000], Step [120/158]| g_loss: 0.675| d_loss: 0.504| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.543
Train: Epoch [2516/3000], Step [150/158]| g_loss: 0.677| d_loss: 0.681| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.067| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.546
Train: Epoch [2517/3000], Step [30/158]| g_loss: 0.655| d_loss: 0.647| gp_loss: 0.114| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.527
Train: Epoch [2517/3000], Step [60/158]| g_loss: 0.658| d_loss: 0.529| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.063| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.528
Train: Epoch [2517/3000], Step [90/158]| g_loss: 0.691| d_loss: 0.598| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.564
Train: Epoch [2517/3000], Step [120/158]| g_loss: 0.651| d_loss: 0.685| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.521
Train: Epoch [2517/3000], Step [150/158]| g_loss: 0.622| d_loss: 0.642| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.492
Train: Epoch [2518/3000], Step [30/158]| g_loss: 0.659| d_loss: 0.755| gp_loss: 0.203| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.284 | a_loss: 0.531
Train: Epoch [2518/3000], Step [60/158]| g_loss: 0.663| d_loss: 0.598| gp_loss: 0.050| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.533
Train: Epoch [2518/3000], Step [90/158]| g_loss: 0.674| d_loss: 0.595| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.547
Train: Epoch [2518/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.602| gp_loss: 0.052| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.535
Train: Epoch [2518/3000], Step [150/158]| g_loss: 0.610| d_loss: 0.681| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.481
Train: Epoch [2519/3000], Step [30/158]| g_loss: 0.654| d_loss: 0.665| gp_loss: 0.126| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.527
Train: Epoch [2519/3000], Step [60/158]| g_loss: 0.643| d_loss: 0.679| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.514
Train: Epoch [2519/3000], Step [90/158]| g_loss: 0.652| d_loss: 0.542| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.528
Train: Epoch [2519/3000], Step [120/158]| g_loss: 0.655| d_loss: 0.651| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.525
Train: Epoch [2519/3000], Step [150/158]| g_loss: 0.622| d_loss: 0.637| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.494
Train: Epoch [2520/3000], Step [30/158]| g_loss: 0.665| d_loss: 0.668| gp_loss: 0.155| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.537
Train: Epoch [2520/3000], Step [60/158]| g_loss: 0.685| d_loss: 0.525| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.557
Train: Epoch [2520/3000], Step [90/158]| g_loss: 0.704| d_loss: 0.640| gp_loss: 0.050| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.576
Train: Epoch [2520/3000], Step [120/158]| g_loss: 0.609| d_loss: 0.691| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.479
Train: Epoch [2520/3000], Step [150/158]| g_loss: 0.638| d_loss: 0.612| gp_loss: 0.059| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.501
Train: Epoch [2521/3000], Step [30/158]| g_loss: 0.650| d_loss: 0.707| gp_loss: 0.164| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.520
Train: Epoch [2521/3000], Step [60/158]| g_loss: 0.670| d_loss: 0.604| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.537
Train: Epoch [2521/3000], Step [90/158]| g_loss: 0.627| d_loss: 0.644| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.069| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.492
Train: Epoch [2521/3000], Step [120/158]| g_loss: 0.668| d_loss: 0.613| gp_loss: 0.055| r_loss: 0.053| p_loss: 0.070| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.532
Train: Epoch [2521/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.593| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.069| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.533
Train: Epoch [2522/3000], Step [30/158]| g_loss: 0.661| d_loss: 0.738| gp_loss: 0.164| r_loss: 0.056| p_loss: 0.072| v_loss: 0.018| per_loss: 0.290 | a_loss: 0.522
Train: Epoch [2522/3000], Step [60/158]| g_loss: 0.677| d_loss: 0.576| gp_loss: 0.050| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.547
Train: Epoch [2522/3000], Step [90/158]| g_loss: 0.643| d_loss: 0.682| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.068| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.511
Train: Epoch [2522/3000], Step [120/158]| g_loss: 0.667| d_loss: 0.573| gp_loss: 0.057| r_loss: 0.052| p_loss: 0.070| v_loss: 0.021| per_loss: 0.290 | a_loss: 0.530
Train: Epoch [2522/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.589| gp_loss: 0.058| r_loss: 0.053| p_loss: 0.069| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.525
Train: Epoch [2523/3000], Step [30/158]| g_loss: 0.659| d_loss: 0.686| gp_loss: 0.142| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.530
Train: Epoch [2523/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.626| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.541
Train: Epoch [2523/3000], Step [90/158]| g_loss: 0.645| d_loss: 0.646| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.068| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.510
Train: Epoch [2523/3000], Step [120/158]| g_loss: 0.640| d_loss: 0.626| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.510
Train: Epoch [2523/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.619| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.312 | a_loss: 0.536
Train: Epoch [2524/3000], Step [30/158]| g_loss: 0.681| d_loss: 0.621| gp_loss: 0.113| r_loss: 0.051| p_loss: 0.072| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.544
Train: Epoch [2524/3000], Step [60/158]| g_loss: 0.667| d_loss: 0.636| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.067| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.536
Train: Epoch [2524/3000], Step [90/158]| g_loss: 0.641| d_loss: 0.640| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.512
Train: Epoch [2524/3000], Step [120/158]| g_loss: 0.603| d_loss: 0.692| gp_loss: 0.061| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.472
Train: Epoch [2524/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.609| gp_loss: 0.062| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.527
Train: Epoch [2525/3000], Step [30/158]| g_loss: 0.677| d_loss: 0.679| gp_loss: 0.104| r_loss: 0.055| p_loss: 0.080| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.532
Train: Epoch [2525/3000], Step [60/158]| g_loss: 0.655| d_loss: 0.615| gp_loss: 0.060| r_loss: 0.056| p_loss: 0.079| v_loss: 0.020| per_loss: 0.307 | a_loss: 0.509
Train: Epoch [2525/3000], Step [90/158]| g_loss: 0.659| d_loss: 0.688| gp_loss: 0.059| r_loss: 0.052| p_loss: 0.073| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.520
Train: Epoch [2525/3000], Step [120/158]| g_loss: 0.646| d_loss: 0.598| gp_loss: 0.066| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.517
Train: Epoch [2525/3000], Step [150/158]| g_loss: 0.660| d_loss: 0.555| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.529
Train: Epoch [2526/3000], Step [30/158]| g_loss: 0.679| d_loss: 0.670| gp_loss: 0.164| r_loss: 0.049| p_loss: 0.067| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.547
Train: Epoch [2526/3000], Step [60/158]| g_loss: 0.693| d_loss: 0.543| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.063| v_loss: 0.018| per_loss: 0.283 | a_loss: 0.568
Train: Epoch [2526/3000], Step [90/158]| g_loss: 0.671| d_loss: 0.633| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.541
Train: Epoch [2526/3000], Step [120/158]| g_loss: 0.629| d_loss: 0.692| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.064| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.497
Train: Epoch [2526/3000], Step [150/158]| g_loss: 0.651| d_loss: 0.605| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.526
Train: Epoch [2527/3000], Step [30/158]| g_loss: 0.627| d_loss: 0.773| gp_loss: 0.192| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.497
Train: Epoch [2527/3000], Step [60/158]| g_loss: 0.632| d_loss: 0.637| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.507
Train: Epoch [2527/3000], Step [90/158]| g_loss: 0.653| d_loss: 0.667| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.524
Train: Epoch [2527/3000], Step [120/158]| g_loss: 0.647| d_loss: 0.597| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.519
Train: Epoch [2527/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.552| gp_loss: 0.063| r_loss: 0.051| p_loss: 0.066| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.528
Train: Epoch [2528/3000], Step [30/158]| g_loss: 0.623| d_loss: 0.758| gp_loss: 0.098| r_loss: 0.051| p_loss: 0.070| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.487
Train: Epoch [2528/3000], Step [60/158]| g_loss: 0.706| d_loss: 0.535| gp_loss: 0.063| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.577
Train: Epoch [2528/3000], Step [90/158]| g_loss: 0.661| d_loss: 0.649| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.064| v_loss: 0.020| per_loss: 0.317 | a_loss: 0.528
Train: Epoch [2528/3000], Step [120/158]| g_loss: 0.626| d_loss: 0.738| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.068| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.494
Train: Epoch [2528/3000], Step [150/158]| g_loss: 0.668| d_loss: 0.525| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.539
Train: Epoch [2529/3000], Step [30/158]| g_loss: 0.661| d_loss: 0.808| gp_loss: 0.208| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.531
Train: Epoch [2529/3000], Step [60/158]| g_loss: 0.600| d_loss: 0.677| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.471
Train: Epoch [2529/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.641| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.526
Train: Epoch [2529/3000], Step [120/158]| g_loss: 0.649| d_loss: 0.587| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.522
Train: Epoch [2529/3000], Step [150/158]| g_loss: 0.671| d_loss: 0.517| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.543
Train: Epoch [2530/3000], Step [30/158]| g_loss: 0.722| d_loss: 0.603| gp_loss: 0.158| r_loss: 0.047| p_loss: 0.061| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.596
Train: Epoch [2530/3000], Step [60/158]| g_loss: 0.659| d_loss: 0.612| gp_loss: 0.049| r_loss: 0.047| p_loss: 0.059| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.535
Train: Epoch [2530/3000], Step [90/158]| g_loss: 0.633| d_loss: 0.767| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.502
Train: Epoch [2530/3000], Step [120/158]| g_loss: 0.629| d_loss: 0.646| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.497
Train: Epoch [2530/3000], Step [150/158]| g_loss: 0.682| d_loss: 0.596| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.289 | a_loss: 0.552
Train: Epoch [2531/3000], Step [30/158]| g_loss: 0.626| d_loss: 0.741| gp_loss: 0.134| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.495
Train: Epoch [2531/3000], Step [60/158]| g_loss: 0.670| d_loss: 0.611| gp_loss: 0.059| r_loss: 0.051| p_loss: 0.066| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.538
Train: Epoch [2531/3000], Step [90/158]| g_loss: 0.609| d_loss: 0.652| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.481
Train: Epoch [2531/3000], Step [120/158]| g_loss: 0.701| d_loss: 0.509| gp_loss: 0.062| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.571
Train: Epoch [2531/3000], Step [150/158]| g_loss: 0.683| d_loss: 0.583| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.551
Train: Epoch [2532/3000], Step [30/158]| g_loss: 0.702| d_loss: 0.616| gp_loss: 0.165| r_loss: 0.050| p_loss: 0.072| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.567
Train: Epoch [2532/3000], Step [60/158]| g_loss: 0.706| d_loss: 0.640| gp_loss: 0.053| r_loss: 0.053| p_loss: 0.068| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.570
Train: Epoch [2532/3000], Step [90/158]| g_loss: 0.637| d_loss: 0.660| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.503
Train: Epoch [2532/3000], Step [120/158]| g_loss: 0.618| d_loss: 0.772| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.069| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.485
Train: Epoch [2532/3000], Step [150/158]| g_loss: 0.627| d_loss: 0.531| gp_loss: 0.062| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.495
Train: Epoch [2533/3000], Step [30/158]| g_loss: 0.676| d_loss: 0.619| gp_loss: 0.139| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.546
Train: Epoch [2533/3000], Step [60/158]| g_loss: 0.689| d_loss: 0.627| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.556
Train: Epoch [2533/3000], Step [90/158]| g_loss: 0.690| d_loss: 0.580| gp_loss: 0.054| r_loss: 0.051| p_loss: 0.064| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.558
Train: Epoch [2533/3000], Step [120/158]| g_loss: 0.667| d_loss: 0.657| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.539
Train: Epoch [2533/3000], Step [150/158]| g_loss: 0.626| d_loss: 0.637| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.496
Train: Epoch [2534/3000], Step [30/158]| g_loss: 0.658| d_loss: 0.703| gp_loss: 0.166| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.530
Train: Epoch [2534/3000], Step [60/158]| g_loss: 0.649| d_loss: 0.658| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.520
Train: Epoch [2534/3000], Step [90/158]| g_loss: 0.658| d_loss: 0.586| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.529
Train: Epoch [2534/3000], Step [120/158]| g_loss: 0.600| d_loss: 0.689| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.471
Train: Epoch [2534/3000], Step [150/158]| g_loss: 0.672| d_loss: 0.574| gp_loss: 0.062| r_loss: 0.049| p_loss: 0.063| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.541
Train: Epoch [2535/3000], Step [30/158]| g_loss: 0.632| d_loss: 0.738| gp_loss: 0.106| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.502
Train: Epoch [2535/3000], Step [60/158]| g_loss: 0.660| d_loss: 0.603| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.532
Train: Epoch [2535/3000], Step [90/158]| g_loss: 0.658| d_loss: 0.631| gp_loss: 0.062| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.532
Train: Epoch [2535/3000], Step [120/158]| g_loss: 0.680| d_loss: 0.581| gp_loss: 0.067| r_loss: 0.050| p_loss: 0.066| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.544
Train: Epoch [2535/3000], Step [150/158]| g_loss: 0.668| d_loss: 0.638| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.539
Train: Epoch [2536/3000], Step [30/158]| g_loss: 0.630| d_loss: 0.759| gp_loss: 0.159| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.318 | a_loss: 0.497
Train: Epoch [2536/3000], Step [60/158]| g_loss: 0.670| d_loss: 0.603| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.069| v_loss: 0.021| per_loss: 0.301 | a_loss: 0.533
Train: Epoch [2536/3000], Step [90/158]| g_loss: 0.647| d_loss: 0.659| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.513
Train: Epoch [2536/3000], Step [120/158]| g_loss: 0.593| d_loss: 0.676| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.064| v_loss: 0.018| per_loss: 0.293 | a_loss: 0.467
Train: Epoch [2536/3000], Step [150/158]| g_loss: 0.673| d_loss: 0.547| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.547
Train: Epoch [2537/3000], Step [30/158]| g_loss: 0.649| d_loss: 0.681| gp_loss: 0.099| r_loss: 0.047| p_loss: 0.063| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.522
Train: Epoch [2537/3000], Step [60/158]| g_loss: 0.684| d_loss: 0.600| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.061| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.557
Train: Epoch [2537/3000], Step [90/158]| g_loss: 0.645| d_loss: 0.618| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.062| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.516
Train: Epoch [2537/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.614| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.546
Train: Epoch [2537/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.628| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.067| v_loss: 0.020| per_loss: 0.312 | a_loss: 0.525
Train: Epoch [2538/3000], Step [30/158]| g_loss: 0.626| d_loss: 0.779| gp_loss: 0.147| r_loss: 0.050| p_loss: 0.068| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.493
Train: Epoch [2538/3000], Step [60/158]| g_loss: 0.633| d_loss: 0.606| gp_loss: 0.059| r_loss: 0.052| p_loss: 0.070| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.495
Train: Epoch [2538/3000], Step [90/158]| g_loss: 0.680| d_loss: 0.536| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.552
Train: Epoch [2538/3000], Step [120/158]| g_loss: 0.691| d_loss: 0.672| gp_loss: 0.062| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.557
Train: Epoch [2538/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.632| gp_loss: 0.060| r_loss: 0.052| p_loss: 0.069| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.533
Train: Epoch [2539/3000], Step [30/158]| g_loss: 0.665| d_loss: 0.684| gp_loss: 0.191| r_loss: 0.049| p_loss: 0.069| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.531
Train: Epoch [2539/3000], Step [60/158]| g_loss: 0.675| d_loss: 0.575| gp_loss: 0.049| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.543
Train: Epoch [2539/3000], Step [90/158]| g_loss: 0.671| d_loss: 0.566| gp_loss: 0.055| r_loss: 0.052| p_loss: 0.066| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.537
Train: Epoch [2539/3000], Step [120/158]| g_loss: 0.681| d_loss: 0.595| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.554
Train: Epoch [2539/3000], Step [150/158]| g_loss: 0.628| d_loss: 0.788| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.061| v_loss: 0.018| per_loss: 0.305 | a_loss: 0.501
Train: Epoch [2540/3000], Step [30/158]| g_loss: 0.603| d_loss: 0.736| gp_loss: 0.139| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.470
Train: Epoch [2540/3000], Step [60/158]| g_loss: 0.636| d_loss: 0.647| gp_loss: 0.053| r_loss: 0.045| p_loss: 0.060| v_loss: 0.018| per_loss: 0.300 | a_loss: 0.512
Train: Epoch [2540/3000], Step [90/158]| g_loss: 0.636| d_loss: 0.613| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.509
Train: Epoch [2540/3000], Step [120/158]| g_loss: 0.661| d_loss: 0.527| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.532
Train: Epoch [2540/3000], Step [150/158]| g_loss: 0.670| d_loss: 0.610| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.536
Train: Epoch [2541/3000], Step [30/158]| g_loss: 0.666| d_loss: 0.716| gp_loss: 0.178| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.537
Train: Epoch [2541/3000], Step [60/158]| g_loss: 0.657| d_loss: 0.653| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.307 | a_loss: 0.527
Train: Epoch [2541/3000], Step [90/158]| g_loss: 0.693| d_loss: 0.558| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.069| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.556
Train: Epoch [2541/3000], Step [120/158]| g_loss: 0.621| d_loss: 0.700| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.491
Train: Epoch [2541/3000], Step [150/158]| g_loss: 0.654| d_loss: 0.553| gp_loss: 0.063| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.526
Train: Epoch [2542/3000], Step [30/158]| g_loss: 0.664| d_loss: 0.789| gp_loss: 0.202| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.537
Train: Epoch [2542/3000], Step [60/158]| g_loss: 0.624| d_loss: 0.596| gp_loss: 0.052| r_loss: 0.051| p_loss: 0.068| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.490
Train: Epoch [2542/3000], Step [90/158]| g_loss: 0.652| d_loss: 0.614| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.526
Train: Epoch [2542/3000], Step [120/158]| g_loss: 0.696| d_loss: 0.534| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.564
Train: Epoch [2542/3000], Step [150/158]| g_loss: 0.653| d_loss: 0.667| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.522
Train: Epoch [2543/3000], Step [30/158]| g_loss: 0.667| d_loss: 0.605| gp_loss: 0.143| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.542
Train: Epoch [2543/3000], Step [60/158]| g_loss: 0.667| d_loss: 0.675| gp_loss: 0.051| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.541
Train: Epoch [2543/3000], Step [90/158]| g_loss: 0.696| d_loss: 0.568| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.065| v_loss: 0.021| per_loss: 0.294 | a_loss: 0.564
Train: Epoch [2543/3000], Step [120/158]| g_loss: 0.623| d_loss: 0.656| gp_loss: 0.054| r_loss: 0.051| p_loss: 0.064| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.493
Train: Epoch [2543/3000], Step [150/158]| g_loss: 0.651| d_loss: 0.682| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.519
Train: Epoch [2544/3000], Step [30/158]| g_loss: 0.635| d_loss: 0.723| gp_loss: 0.148| r_loss: 0.049| p_loss: 0.068| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.504
Train: Epoch [2544/3000], Step [60/158]| g_loss: 0.616| d_loss: 0.706| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.486
Train: Epoch [2544/3000], Step [90/158]| g_loss: 0.665| d_loss: 0.569| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.532
Train: Epoch [2544/3000], Step [120/158]| g_loss: 0.657| d_loss: 0.567| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.063| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.526
Train: Epoch [2544/3000], Step [150/158]| g_loss: 0.688| d_loss: 0.572| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.560
Train: Epoch [2545/3000], Step [30/158]| g_loss: 0.659| d_loss: 0.678| gp_loss: 0.116| r_loss: 0.050| p_loss: 0.063| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.529
Train: Epoch [2545/3000], Step [60/158]| g_loss: 0.665| d_loss: 0.601| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.540
Train: Epoch [2545/3000], Step [90/158]| g_loss: 0.682| d_loss: 0.544| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.312 | a_loss: 0.549
Train: Epoch [2545/3000], Step [120/158]| g_loss: 0.663| d_loss: 0.576| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.539
Train: Epoch [2545/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.624| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.533
Train: Epoch [2546/3000], Step [30/158]| g_loss: 0.617| d_loss: 0.829| gp_loss: 0.195| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.484
Train: Epoch [2546/3000], Step [60/158]| g_loss: 0.680| d_loss: 0.650| gp_loss: 0.060| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.548
Train: Epoch [2546/3000], Step [90/158]| g_loss: 0.650| d_loss: 0.521| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.064| v_loss: 0.020| per_loss: 0.284 | a_loss: 0.523
Train: Epoch [2546/3000], Step [120/158]| g_loss: 0.641| d_loss: 0.672| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.512
Train: Epoch [2546/3000], Step [150/158]| g_loss: 0.641| d_loss: 0.612| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.511
Train: Epoch [2547/3000], Step [30/158]| g_loss: 0.625| d_loss: 0.731| gp_loss: 0.106| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.495
Train: Epoch [2547/3000], Step [60/158]| g_loss: 0.671| d_loss: 0.587| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.544
Train: Epoch [2547/3000], Step [90/158]| g_loss: 0.655| d_loss: 0.597| gp_loss: 0.058| r_loss: 0.054| p_loss: 0.072| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.517
Train: Epoch [2547/3000], Step [120/158]| g_loss: 0.672| d_loss: 0.592| gp_loss: 0.058| r_loss: 0.055| p_loss: 0.072| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.531
Train: Epoch [2547/3000], Step [150/158]| g_loss: 0.678| d_loss: 0.649| gp_loss: 0.059| r_loss: 0.053| p_loss: 0.072| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.541
Train: Epoch [2548/3000], Step [30/158]| g_loss: 0.650| d_loss: 0.645| gp_loss: 0.104| r_loss: 0.052| p_loss: 0.071| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.514
Train: Epoch [2548/3000], Step [60/158]| g_loss: 0.660| d_loss: 0.648| gp_loss: 0.061| r_loss: 0.054| p_loss: 0.074| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.521
Train: Epoch [2548/3000], Step [90/158]| g_loss: 0.658| d_loss: 0.583| gp_loss: 0.064| r_loss: 0.052| p_loss: 0.068| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.522
Train: Epoch [2548/3000], Step [120/158]| g_loss: 0.662| d_loss: 0.608| gp_loss: 0.064| r_loss: 0.048| p_loss: 0.067| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.530
Train: Epoch [2548/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.652| gp_loss: 0.062| r_loss: 0.051| p_loss: 0.066| v_loss: 0.020| per_loss: 0.276 | a_loss: 0.531
Train: Epoch [2549/3000], Step [30/158]| g_loss: 0.635| d_loss: 0.755| gp_loss: 0.102| r_loss: 0.050| p_loss: 0.070| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.500
Train: Epoch [2549/3000], Step [60/158]| g_loss: 0.686| d_loss: 0.566| gp_loss: 0.063| r_loss: 0.058| p_loss: 0.073| v_loss: 0.021| per_loss: 0.307 | a_loss: 0.541
Train: Epoch [2549/3000], Step [90/158]| g_loss: 0.678| d_loss: 0.588| gp_loss: 0.061| r_loss: 0.052| p_loss: 0.068| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.542
Train: Epoch [2549/3000], Step [120/158]| g_loss: 0.627| d_loss: 0.673| gp_loss: 0.062| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.493
Train: Epoch [2549/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.609| gp_loss: 0.068| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.540
Train: Epoch [2550/3000], Step [30/158]| g_loss: 0.617| d_loss: 0.862| gp_loss: 0.215| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.488
Train: Epoch [2550/3000], Step [60/158]| g_loss: 0.607| d_loss: 0.678| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.059| v_loss: 0.018| per_loss: 0.294 | a_loss: 0.483
Train: Epoch [2550/3000], Step [90/158]| g_loss: 0.650| d_loss: 0.573| gp_loss: 0.055| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.516
Train: Epoch [2550/3000], Step [120/158]| g_loss: 0.674| d_loss: 0.574| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.545
Train: Epoch [2550/3000], Step [150/158]| g_loss: 0.698| d_loss: 0.590| gp_loss: 0.062| r_loss: 0.050| p_loss: 0.068| v_loss: 0.021| per_loss: 0.311 | a_loss: 0.563
Test: Epoch [2550/3000]| g_loss: 0.649| r_loss: 0.392| p_loss: 0.320| v_loss: 0.021
Train: Epoch [2551/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.638| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.523
Train: Epoch [2551/3000], Step [60/158]| g_loss: 0.672| d_loss: 0.559| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.063| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.542
Train: Epoch [2551/3000], Step [90/158]| g_loss: 0.668| d_loss: 0.693| gp_loss: 0.051| r_loss: 0.047| p_loss: 0.065| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.539
Train: Epoch [2551/3000], Step [120/158]| g_loss: 0.644| d_loss: 0.572| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.064| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.513
Train: Epoch [2551/3000], Step [150/158]| g_loss: 0.650| d_loss: 0.668| gp_loss: 0.060| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.525
Train: Epoch [2552/3000], Step [30/158]| g_loss: 0.659| d_loss: 0.761| gp_loss: 0.189| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.526
Train: Epoch [2552/3000], Step [60/158]| g_loss: 0.622| d_loss: 0.625| gp_loss: 0.051| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.496
Train: Epoch [2552/3000], Step [90/158]| g_loss: 0.638| d_loss: 0.607| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.512
Train: Epoch [2552/3000], Step [120/158]| g_loss: 0.656| d_loss: 0.543| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.060| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.529
Train: Epoch [2552/3000], Step [150/158]| g_loss: 0.684| d_loss: 0.592| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.062| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.555
Train: Epoch [2553/3000], Step [30/158]| g_loss: 0.665| d_loss: 0.619| gp_loss: 0.114| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.541
Train: Epoch [2553/3000], Step [60/158]| g_loss: 0.693| d_loss: 0.605| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.060| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.564
Train: Epoch [2553/3000], Step [90/158]| g_loss: 0.641| d_loss: 0.649| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.513
Train: Epoch [2553/3000], Step [120/158]| g_loss: 0.675| d_loss: 0.599| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.547
Train: Epoch [2553/3000], Step [150/158]| g_loss: 0.657| d_loss: 0.642| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.064| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.526
Train: Epoch [2554/3000], Step [30/158]| g_loss: 0.603| d_loss: 0.831| gp_loss: 0.204| r_loss: 0.046| p_loss: 0.062| v_loss: 0.018| per_loss: 0.294 | a_loss: 0.478
Train: Epoch [2554/3000], Step [60/158]| g_loss: 0.646| d_loss: 0.512| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.519
Train: Epoch [2554/3000], Step [90/158]| g_loss: 0.693| d_loss: 0.608| gp_loss: 0.052| r_loss: 0.049| p_loss: 0.062| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.563
Train: Epoch [2554/3000], Step [120/158]| g_loss: 0.627| d_loss: 0.652| gp_loss: 0.054| r_loss: 0.045| p_loss: 0.058| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.506
Train: Epoch [2554/3000], Step [150/158]| g_loss: 0.644| d_loss: 0.613| gp_loss: 0.060| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.512
Train: Epoch [2555/3000], Step [30/158]| g_loss: 0.658| d_loss: 0.706| gp_loss: 0.167| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.529
Train: Epoch [2555/3000], Step [60/158]| g_loss: 0.676| d_loss: 0.597| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.546
Train: Epoch [2555/3000], Step [90/158]| g_loss: 0.612| d_loss: 0.689| gp_loss: 0.052| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.489
Train: Epoch [2555/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.631| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.063| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.536
Train: Epoch [2555/3000], Step [150/158]| g_loss: 0.667| d_loss: 0.519| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.542
Train: Epoch [2556/3000], Step [30/158]| g_loss: 0.643| d_loss: 0.748| gp_loss: 0.165| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.516
Train: Epoch [2556/3000], Step [60/158]| g_loss: 0.649| d_loss: 0.632| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.517
Train: Epoch [2556/3000], Step [90/158]| g_loss: 0.655| d_loss: 0.608| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.061| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.529
Train: Epoch [2556/3000], Step [120/158]| g_loss: 0.658| d_loss: 0.649| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.533
Train: Epoch [2556/3000], Step [150/158]| g_loss: 0.635| d_loss: 0.602| gp_loss: 0.059| r_loss: 0.046| p_loss: 0.061| v_loss: 0.018| per_loss: 0.279 | a_loss: 0.512
Train: Epoch [2557/3000], Step [30/158]| g_loss: 0.664| d_loss: 0.680| gp_loss: 0.178| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.539
Train: Epoch [2557/3000], Step [60/158]| g_loss: 0.649| d_loss: 0.680| gp_loss: 0.051| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.523
Train: Epoch [2557/3000], Step [90/158]| g_loss: 0.633| d_loss: 0.616| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.508
Train: Epoch [2557/3000], Step [120/158]| g_loss: 0.648| d_loss: 0.595| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.066| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.518
Train: Epoch [2557/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.630| gp_loss: 0.054| r_loss: 0.051| p_loss: 0.064| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.530
Train: Epoch [2558/3000], Step [30/158]| g_loss: 0.640| d_loss: 0.796| gp_loss: 0.203| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.513
Train: Epoch [2558/3000], Step [60/158]| g_loss: 0.633| d_loss: 0.562| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.274 | a_loss: 0.511
Train: Epoch [2558/3000], Step [90/158]| g_loss: 0.678| d_loss: 0.546| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.059| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.552
Train: Epoch [2558/3000], Step [120/158]| g_loss: 0.693| d_loss: 0.632| gp_loss: 0.050| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.565
Train: Epoch [2558/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.639| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.535
Train: Epoch [2559/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.680| gp_loss: 0.168| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.523
Train: Epoch [2559/3000], Step [60/158]| g_loss: 0.681| d_loss: 0.563| gp_loss: 0.051| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.549
Train: Epoch [2559/3000], Step [90/158]| g_loss: 0.663| d_loss: 0.642| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.534
Train: Epoch [2559/3000], Step [120/158]| g_loss: 0.638| d_loss: 0.671| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.062| v_loss: 0.018| per_loss: 0.288 | a_loss: 0.513
Train: Epoch [2559/3000], Step [150/158]| g_loss: 0.607| d_loss: 0.640| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.480
Train: Epoch [2560/3000], Step [30/158]| g_loss: 0.668| d_loss: 0.653| gp_loss: 0.163| r_loss: 0.046| p_loss: 0.056| v_loss: 0.018| per_loss: 0.286 | a_loss: 0.547
Train: Epoch [2560/3000], Step [60/158]| g_loss: 0.679| d_loss: 0.575| gp_loss: 0.051| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.310 | a_loss: 0.550
Train: Epoch [2560/3000], Step [90/158]| g_loss: 0.617| d_loss: 0.701| gp_loss: 0.051| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.491
Train: Epoch [2560/3000], Step [120/158]| g_loss: 0.656| d_loss: 0.661| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.528
Train: Epoch [2560/3000], Step [150/158]| g_loss: 0.640| d_loss: 0.518| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.509
Train: Epoch [2561/3000], Step [30/158]| g_loss: 0.649| d_loss: 0.712| gp_loss: 0.135| r_loss: 0.046| p_loss: 0.061| v_loss: 0.018| per_loss: 0.286 | a_loss: 0.524
Train: Epoch [2561/3000], Step [60/158]| g_loss: 0.636| d_loss: 0.690| gp_loss: 0.051| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.508
Train: Epoch [2561/3000], Step [90/158]| g_loss: 0.674| d_loss: 0.621| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.543
Train: Epoch [2561/3000], Step [120/158]| g_loss: 0.653| d_loss: 0.633| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.525
Train: Epoch [2561/3000], Step [150/158]| g_loss: 0.673| d_loss: 0.604| gp_loss: 0.055| r_loss: 0.056| p_loss: 0.074| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.530
Train: Epoch [2562/3000], Step [30/158]| g_loss: 0.669| d_loss: 0.647| gp_loss: 0.099| r_loss: 0.050| p_loss: 0.069| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.537
Train: Epoch [2562/3000], Step [60/158]| g_loss: 0.647| d_loss: 0.603| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.520
Train: Epoch [2562/3000], Step [90/158]| g_loss: 0.664| d_loss: 0.681| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.537
Train: Epoch [2562/3000], Step [120/158]| g_loss: 0.639| d_loss: 0.599| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.511
Train: Epoch [2562/3000], Step [150/158]| g_loss: 0.634| d_loss: 0.617| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.505
Train: Epoch [2563/3000], Step [30/158]| g_loss: 0.645| d_loss: 0.745| gp_loss: 0.139| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.517
Train: Epoch [2563/3000], Step [60/158]| g_loss: 0.652| d_loss: 0.536| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.522
Train: Epoch [2563/3000], Step [90/158]| g_loss: 0.692| d_loss: 0.549| gp_loss: 0.060| r_loss: 0.052| p_loss: 0.064| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.560
Train: Epoch [2563/3000], Step [120/158]| g_loss: 0.659| d_loss: 0.628| gp_loss: 0.057| r_loss: 0.046| p_loss: 0.063| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.532
Train: Epoch [2563/3000], Step [150/158]| g_loss: 0.666| d_loss: 0.651| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.063| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.537
Train: Epoch [2564/3000], Step [30/158]| g_loss: 0.625| d_loss: 0.747| gp_loss: 0.122| r_loss: 0.049| p_loss: 0.066| v_loss: 0.018| per_loss: 0.296 | a_loss: 0.495
Train: Epoch [2564/3000], Step [60/158]| g_loss: 0.627| d_loss: 0.618| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.071| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.492
Train: Epoch [2564/3000], Step [90/158]| g_loss: 0.716| d_loss: 0.500| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.586
Train: Epoch [2564/3000], Step [120/158]| g_loss: 0.673| d_loss: 0.632| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.547
Train: Epoch [2564/3000], Step [150/158]| g_loss: 0.634| d_loss: 0.671| gp_loss: 0.060| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.510
Train: Epoch [2565/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.644| gp_loss: 0.098| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.523
Train: Epoch [2565/3000], Step [60/158]| g_loss: 0.650| d_loss: 0.626| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.522
Train: Epoch [2565/3000], Step [90/158]| g_loss: 0.633| d_loss: 0.638| gp_loss: 0.058| r_loss: 0.045| p_loss: 0.061| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.508
Train: Epoch [2565/3000], Step [120/158]| g_loss: 0.645| d_loss: 0.601| gp_loss: 0.063| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.517
Train: Epoch [2565/3000], Step [150/158]| g_loss: 0.688| d_loss: 0.624| gp_loss: 0.063| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.557
Train: Epoch [2566/3000], Step [30/158]| g_loss: 0.609| d_loss: 0.726| gp_loss: 0.118| r_loss: 0.048| p_loss: 0.071| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.479
Train: Epoch [2566/3000], Step [60/158]| g_loss: 0.629| d_loss: 0.611| gp_loss: 0.060| r_loss: 0.046| p_loss: 0.058| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.507
Train: Epoch [2566/3000], Step [90/158]| g_loss: 0.650| d_loss: 0.685| gp_loss: 0.062| r_loss: 0.048| p_loss: 0.062| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.522
Train: Epoch [2566/3000], Step [120/158]| g_loss: 0.662| d_loss: 0.537| gp_loss: 0.064| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.532
Train: Epoch [2566/3000], Step [150/158]| g_loss: 0.679| d_loss: 0.585| gp_loss: 0.062| r_loss: 0.050| p_loss: 0.063| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.548
Train: Epoch [2567/3000], Step [30/158]| g_loss: 0.662| d_loss: 0.716| gp_loss: 0.185| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.535
Train: Epoch [2567/3000], Step [60/158]| g_loss: 0.654| d_loss: 0.607| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.064| v_loss: 0.018| per_loss: 0.299 | a_loss: 0.526
Train: Epoch [2567/3000], Step [90/158]| g_loss: 0.650| d_loss: 0.603| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.522
Train: Epoch [2567/3000], Step [120/158]| g_loss: 0.674| d_loss: 0.590| gp_loss: 0.062| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.545
Train: Epoch [2567/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.683| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.533
Train: Epoch [2568/3000], Step [30/158]| g_loss: 0.651| d_loss: 0.710| gp_loss: 0.173| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.524
Train: Epoch [2568/3000], Step [60/158]| g_loss: 0.643| d_loss: 0.626| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.061| v_loss: 0.018| per_loss: 0.294 | a_loss: 0.519
Train: Epoch [2568/3000], Step [90/158]| g_loss: 0.618| d_loss: 0.700| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.061| v_loss: 0.018| per_loss: 0.304 | a_loss: 0.493
Train: Epoch [2568/3000], Step [120/158]| g_loss: 0.690| d_loss: 0.478| gp_loss: 0.061| r_loss: 0.050| p_loss: 0.066| v_loss: 0.021| per_loss: 0.296 | a_loss: 0.557
Train: Epoch [2568/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.674| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.532
Train: Epoch [2569/3000], Step [30/158]| g_loss: 0.618| d_loss: 0.788| gp_loss: 0.172| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.490
Train: Epoch [2569/3000], Step [60/158]| g_loss: 0.655| d_loss: 0.554| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.527
Train: Epoch [2569/3000], Step [90/158]| g_loss: 0.689| d_loss: 0.624| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.562
Train: Epoch [2569/3000], Step [120/158]| g_loss: 0.596| d_loss: 0.710| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.471
Train: Epoch [2569/3000], Step [150/158]| g_loss: 0.665| d_loss: 0.525| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.060| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.538
Train: Epoch [2570/3000], Step [30/158]| g_loss: 0.676| d_loss: 0.704| gp_loss: 0.090| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.546
Train: Epoch [2570/3000], Step [60/158]| g_loss: 0.647| d_loss: 0.647| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.075| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.510
Train: Epoch [2570/3000], Step [90/158]| g_loss: 0.646| d_loss: 0.645| gp_loss: 0.059| r_loss: 0.053| p_loss: 0.069| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.508
Train: Epoch [2570/3000], Step [120/158]| g_loss: 0.653| d_loss: 0.525| gp_loss: 0.061| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.525
Train: Epoch [2570/3000], Step [150/158]| g_loss: 0.686| d_loss: 0.606| gp_loss: 0.059| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.562
Train: Epoch [2571/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.790| gp_loss: 0.173| r_loss: 0.047| p_loss: 0.062| v_loss: 0.018| per_loss: 0.289 | a_loss: 0.538
Train: Epoch [2571/3000], Step [60/158]| g_loss: 0.626| d_loss: 0.570| gp_loss: 0.054| r_loss: 0.045| p_loss: 0.058| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.503
Train: Epoch [2571/3000], Step [90/158]| g_loss: 0.609| d_loss: 0.749| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.482
Train: Epoch [2571/3000], Step [120/158]| g_loss: 0.634| d_loss: 0.559| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.509
Train: Epoch [2571/3000], Step [150/158]| g_loss: 0.691| d_loss: 0.523| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.563
Train: Epoch [2572/3000], Step [30/158]| g_loss: 0.690| d_loss: 0.706| gp_loss: 0.194| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.562
Train: Epoch [2572/3000], Step [60/158]| g_loss: 0.690| d_loss: 0.583| gp_loss: 0.049| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.564
Train: Epoch [2572/3000], Step [90/158]| g_loss: 0.621| d_loss: 0.642| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.059| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.498
Train: Epoch [2572/3000], Step [120/158]| g_loss: 0.633| d_loss: 0.644| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.507
Train: Epoch [2572/3000], Step [150/158]| g_loss: 0.644| d_loss: 0.591| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.059| v_loss: 0.018| per_loss: 0.284 | a_loss: 0.522
Train: Epoch [2573/3000], Step [30/158]| g_loss: 0.658| d_loss: 0.733| gp_loss: 0.154| r_loss: 0.050| p_loss: 0.062| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.528
Train: Epoch [2573/3000], Step [60/158]| g_loss: 0.620| d_loss: 0.675| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.491
Train: Epoch [2573/3000], Step [90/158]| g_loss: 0.650| d_loss: 0.558| gp_loss: 0.060| r_loss: 0.051| p_loss: 0.066| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.517
Train: Epoch [2573/3000], Step [120/158]| g_loss: 0.685| d_loss: 0.592| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.063| v_loss: 0.018| per_loss: 0.271 | a_loss: 0.558
Train: Epoch [2573/3000], Step [150/158]| g_loss: 0.668| d_loss: 0.559| gp_loss: 0.057| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.543
Train: Epoch [2574/3000], Step [30/158]| g_loss: 0.673| d_loss: 0.678| gp_loss: 0.146| r_loss: 0.050| p_loss: 0.063| v_loss: 0.018| per_loss: 0.291 | a_loss: 0.544
Train: Epoch [2574/3000], Step [60/158]| g_loss: 0.656| d_loss: 0.677| gp_loss: 0.057| r_loss: 0.052| p_loss: 0.069| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.522
Train: Epoch [2574/3000], Step [90/158]| g_loss: 0.671| d_loss: 0.544| gp_loss: 0.060| r_loss: 0.051| p_loss: 0.068| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.536
Train: Epoch [2574/3000], Step [120/158]| g_loss: 0.675| d_loss: 0.656| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.543
Train: Epoch [2574/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.566| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.535
Train: Epoch [2575/3000], Step [30/158]| g_loss: 0.675| d_loss: 0.663| gp_loss: 0.095| r_loss: 0.049| p_loss: 0.067| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.544
Train: Epoch [2575/3000], Step [60/158]| g_loss: 0.652| d_loss: 0.585| gp_loss: 0.060| r_loss: 0.046| p_loss: 0.063| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.526
Train: Epoch [2575/3000], Step [90/158]| g_loss: 0.677| d_loss: 0.628| gp_loss: 0.064| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.550
Train: Epoch [2575/3000], Step [120/158]| g_loss: 0.653| d_loss: 0.643| gp_loss: 0.062| r_loss: 0.051| p_loss: 0.063| v_loss: 0.020| per_loss: 0.307 | a_loss: 0.520
Train: Epoch [2575/3000], Step [150/158]| g_loss: 0.618| d_loss: 0.673| gp_loss: 0.061| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.488
Train: Epoch [2576/3000], Step [30/158]| g_loss: 0.640| d_loss: 0.756| gp_loss: 0.218| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.513
Train: Epoch [2576/3000], Step [60/158]| g_loss: 0.635| d_loss: 0.692| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.505
Train: Epoch [2576/3000], Step [90/158]| g_loss: 0.656| d_loss: 0.603| gp_loss: 0.063| r_loss: 0.048| p_loss: 0.066| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.526
Train: Epoch [2576/3000], Step [120/158]| g_loss: 0.693| d_loss: 0.528| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.061| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.564
Train: Epoch [2576/3000], Step [150/158]| g_loss: 0.693| d_loss: 0.604| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.567
Train: Epoch [2577/3000], Step [30/158]| g_loss: 0.641| d_loss: 0.711| gp_loss: 0.084| r_loss: 0.049| p_loss: 0.067| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.511
Train: Epoch [2577/3000], Step [60/158]| g_loss: 0.656| d_loss: 0.546| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.063| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.526
Train: Epoch [2577/3000], Step [90/158]| g_loss: 0.666| d_loss: 0.629| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.534
Train: Epoch [2577/3000], Step [120/158]| g_loss: 0.664| d_loss: 0.625| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.532
Train: Epoch [2577/3000], Step [150/158]| g_loss: 0.652| d_loss: 0.648| gp_loss: 0.062| r_loss: 0.055| p_loss: 0.074| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.511
Train: Epoch [2578/3000], Step [30/158]| g_loss: 0.661| d_loss: 0.691| gp_loss: 0.143| r_loss: 0.052| p_loss: 0.073| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.523
Train: Epoch [2578/3000], Step [60/158]| g_loss: 0.664| d_loss: 0.636| gp_loss: 0.058| r_loss: 0.056| p_loss: 0.077| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.520
Train: Epoch [2578/3000], Step [90/158]| g_loss: 0.652| d_loss: 0.643| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.068| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.518
Train: Epoch [2578/3000], Step [120/158]| g_loss: 0.682| d_loss: 0.631| gp_loss: 0.061| r_loss: 0.050| p_loss: 0.070| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.550
Train: Epoch [2578/3000], Step [150/158]| g_loss: 0.656| d_loss: 0.565| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.068| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.522
Train: Epoch [2579/3000], Step [30/158]| g_loss: 0.645| d_loss: 0.660| gp_loss: 0.123| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.517
Train: Epoch [2579/3000], Step [60/158]| g_loss: 0.629| d_loss: 0.656| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.503
Train: Epoch [2579/3000], Step [90/158]| g_loss: 0.643| d_loss: 0.603| gp_loss: 0.062| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.516
Train: Epoch [2579/3000], Step [120/158]| g_loss: 0.709| d_loss: 0.592| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.578
Train: Epoch [2579/3000], Step [150/158]| g_loss: 0.651| d_loss: 0.639| gp_loss: 0.063| r_loss: 0.049| p_loss: 0.061| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.524
Train: Epoch [2580/3000], Step [30/158]| g_loss: 0.637| d_loss: 0.782| gp_loss: 0.160| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.503
Train: Epoch [2580/3000], Step [60/158]| g_loss: 0.613| d_loss: 0.654| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.486
Train: Epoch [2580/3000], Step [90/158]| g_loss: 0.662| d_loss: 0.528| gp_loss: 0.059| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.537
Train: Epoch [2580/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.592| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.058| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.543
Train: Epoch [2580/3000], Step [150/158]| g_loss: 0.678| d_loss: 0.594| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.549
Train: Epoch [2581/3000], Step [30/158]| g_loss: 0.689| d_loss: 0.622| gp_loss: 0.146| r_loss: 0.050| p_loss: 0.061| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.559
Train: Epoch [2581/3000], Step [60/158]| g_loss: 0.646| d_loss: 0.681| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.518
Train: Epoch [2581/3000], Step [90/158]| g_loss: 0.631| d_loss: 0.673| gp_loss: 0.061| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.503
Train: Epoch [2581/3000], Step [120/158]| g_loss: 0.659| d_loss: 0.552| gp_loss: 0.058| r_loss: 0.045| p_loss: 0.060| v_loss: 0.018| per_loss: 0.286 | a_loss: 0.537
Train: Epoch [2581/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.660| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.065| v_loss: 0.020| per_loss: 0.311 | a_loss: 0.525
Train: Epoch [2582/3000], Step [30/158]| g_loss: 0.662| d_loss: 0.613| gp_loss: 0.118| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.533
Train: Epoch [2582/3000], Step [60/158]| g_loss: 0.665| d_loss: 0.598| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.537
Train: Epoch [2582/3000], Step [90/158]| g_loss: 0.661| d_loss: 0.627| gp_loss: 0.056| r_loss: 0.045| p_loss: 0.060| v_loss: 0.018| per_loss: 0.306 | a_loss: 0.537
Train: Epoch [2582/3000], Step [120/158]| g_loss: 0.643| d_loss: 0.674| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.514
Train: Epoch [2582/3000], Step [150/158]| g_loss: 0.632| d_loss: 0.645| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.504
Train: Epoch [2583/3000], Step [30/158]| g_loss: 0.640| d_loss: 0.695| gp_loss: 0.185| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.514
Train: Epoch [2583/3000], Step [60/158]| g_loss: 0.653| d_loss: 0.656| gp_loss: 0.053| r_loss: 0.045| p_loss: 0.060| v_loss: 0.018| per_loss: 0.276 | a_loss: 0.532
Train: Epoch [2583/3000], Step [90/158]| g_loss: 0.685| d_loss: 0.571| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.560
Train: Epoch [2583/3000], Step [120/158]| g_loss: 0.662| d_loss: 0.631| gp_loss: 0.052| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.532
Train: Epoch [2583/3000], Step [150/158]| g_loss: 0.632| d_loss: 0.601| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.505
Train: Epoch [2584/3000], Step [30/158]| g_loss: 0.646| d_loss: 0.733| gp_loss: 0.185| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.520
Train: Epoch [2584/3000], Step [60/158]| g_loss: 0.617| d_loss: 0.675| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.491
Train: Epoch [2584/3000], Step [90/158]| g_loss: 0.638| d_loss: 0.637| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.061| v_loss: 0.018| per_loss: 0.293 | a_loss: 0.514
Train: Epoch [2584/3000], Step [120/158]| g_loss: 0.644| d_loss: 0.586| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.516
Train: Epoch [2584/3000], Step [150/158]| g_loss: 0.689| d_loss: 0.601| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.563
Train: Epoch [2585/3000], Step [30/158]| g_loss: 0.631| d_loss: 0.701| gp_loss: 0.114| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.500
Train: Epoch [2585/3000], Step [60/158]| g_loss: 0.672| d_loss: 0.599| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.547
Train: Epoch [2585/3000], Step [90/158]| g_loss: 0.655| d_loss: 0.663| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.526
Train: Epoch [2585/3000], Step [120/158]| g_loss: 0.664| d_loss: 0.555| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.535
Train: Epoch [2585/3000], Step [150/158]| g_loss: 0.665| d_loss: 0.692| gp_loss: 0.057| r_loss: 0.045| p_loss: 0.061| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.541
Train: Epoch [2586/3000], Step [30/158]| g_loss: 0.617| d_loss: 0.752| gp_loss: 0.167| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.489
Train: Epoch [2586/3000], Step [60/158]| g_loss: 0.608| d_loss: 0.683| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.483
Train: Epoch [2586/3000], Step [90/158]| g_loss: 0.650| d_loss: 0.540| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.524
Train: Epoch [2586/3000], Step [120/158]| g_loss: 0.675| d_loss: 0.627| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.549
Train: Epoch [2586/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.599| gp_loss: 0.060| r_loss: 0.050| p_loss: 0.063| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.531
Train: Epoch [2587/3000], Step [30/158]| g_loss: 0.674| d_loss: 0.660| gp_loss: 0.123| r_loss: 0.057| p_loss: 0.068| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.535
Train: Epoch [2587/3000], Step [60/158]| g_loss: 0.672| d_loss: 0.679| gp_loss: 0.057| r_loss: 0.065| p_loss: 0.082| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.518
Train: Epoch [2587/3000], Step [90/158]| g_loss: 0.666| d_loss: 0.630| gp_loss: 0.057| r_loss: 0.055| p_loss: 0.080| v_loss: 0.020| per_loss: 0.315 | a_loss: 0.520
Train: Epoch [2587/3000], Step [120/158]| g_loss: 0.658| d_loss: 0.591| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.070| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.524
Train: Epoch [2587/3000], Step [150/158]| g_loss: 0.690| d_loss: 0.581| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.069| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.556
Train: Epoch [2588/3000], Step [30/158]| g_loss: 0.680| d_loss: 0.666| gp_loss: 0.104| r_loss: 0.051| p_loss: 0.077| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.541
Train: Epoch [2588/3000], Step [60/158]| g_loss: 0.656| d_loss: 0.611| gp_loss: 0.055| r_loss: 0.054| p_loss: 0.073| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.515
Train: Epoch [2588/3000], Step [90/158]| g_loss: 0.719| d_loss: 0.622| gp_loss: 0.059| r_loss: 0.051| p_loss: 0.068| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.584
Train: Epoch [2588/3000], Step [120/158]| g_loss: 0.631| d_loss: 0.628| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.073| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.495
Train: Epoch [2588/3000], Step [150/158]| g_loss: 0.643| d_loss: 0.612| gp_loss: 0.060| r_loss: 0.053| p_loss: 0.082| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.500
Train: Epoch [2589/3000], Step [30/158]| g_loss: 0.644| d_loss: 0.780| gp_loss: 0.110| r_loss: 0.055| p_loss: 0.081| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.499
Train: Epoch [2589/3000], Step [60/158]| g_loss: 0.681| d_loss: 0.542| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.068| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.548
Train: Epoch [2589/3000], Step [90/158]| g_loss: 0.656| d_loss: 0.599| gp_loss: 0.061| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.529
Train: Epoch [2589/3000], Step [120/158]| g_loss: 0.662| d_loss: 0.569| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.279 | a_loss: 0.532
Train: Epoch [2589/3000], Step [150/158]| g_loss: 0.654| d_loss: 0.588| gp_loss: 0.063| r_loss: 0.048| p_loss: 0.067| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.523
Train: Epoch [2590/3000], Step [30/158]| g_loss: 0.675| d_loss: 0.693| gp_loss: 0.166| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.546
Train: Epoch [2590/3000], Step [60/158]| g_loss: 0.674| d_loss: 0.595| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.549
Train: Epoch [2590/3000], Step [90/158]| g_loss: 0.646| d_loss: 0.725| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.064| v_loss: 0.020| per_loss: 0.283 | a_loss: 0.517
Train: Epoch [2590/3000], Step [120/158]| g_loss: 0.640| d_loss: 0.542| gp_loss: 0.062| r_loss: 0.045| p_loss: 0.058| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.516
Train: Epoch [2590/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.638| gp_loss: 0.063| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.538
Train: Epoch [2591/3000], Step [30/158]| g_loss: 0.642| d_loss: 0.741| gp_loss: 0.195| r_loss: 0.050| p_loss: 0.062| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.512
Train: Epoch [2591/3000], Step [60/158]| g_loss: 0.715| d_loss: 0.551| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.062| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.586
Train: Epoch [2591/3000], Step [90/158]| g_loss: 0.659| d_loss: 0.608| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.532
Train: Epoch [2591/3000], Step [120/158]| g_loss: 0.638| d_loss: 0.598| gp_loss: 0.059| r_loss: 0.046| p_loss: 0.063| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.512
Train: Epoch [2591/3000], Step [150/158]| g_loss: 0.665| d_loss: 0.626| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.537
Train: Epoch [2592/3000], Step [30/158]| g_loss: 0.623| d_loss: 0.786| gp_loss: 0.140| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.495
Train: Epoch [2592/3000], Step [60/158]| g_loss: 0.653| d_loss: 0.597| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.062| v_loss: 0.018| per_loss: 0.296 | a_loss: 0.525
Train: Epoch [2592/3000], Step [90/158]| g_loss: 0.625| d_loss: 0.683| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.497
Train: Epoch [2592/3000], Step [120/158]| g_loss: 0.634| d_loss: 0.602| gp_loss: 0.060| r_loss: 0.045| p_loss: 0.058| v_loss: 0.018| per_loss: 0.296 | a_loss: 0.512
Train: Epoch [2592/3000], Step [150/158]| g_loss: 0.634| d_loss: 0.587| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.063| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.505
Train: Epoch [2593/3000], Step [30/158]| g_loss: 0.667| d_loss: 0.704| gp_loss: 0.124| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.541
Train: Epoch [2593/3000], Step [60/158]| g_loss: 0.658| d_loss: 0.540| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.534
Train: Epoch [2593/3000], Step [90/158]| g_loss: 0.690| d_loss: 0.582| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.058| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.566
Train: Epoch [2593/3000], Step [120/158]| g_loss: 0.601| d_loss: 0.708| gp_loss: 0.056| r_loss: 0.045| p_loss: 0.062| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.477
Train: Epoch [2593/3000], Step [150/158]| g_loss: 0.654| d_loss: 0.608| gp_loss: 0.065| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.524
Train: Epoch [2594/3000], Step [30/158]| g_loss: 0.661| d_loss: 0.702| gp_loss: 0.158| r_loss: 0.048| p_loss: 0.062| v_loss: 0.020| per_loss: 0.307 | a_loss: 0.532
Train: Epoch [2594/3000], Step [60/158]| g_loss: 0.654| d_loss: 0.607| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.528
Train: Epoch [2594/3000], Step [90/158]| g_loss: 0.681| d_loss: 0.583| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.553
Train: Epoch [2594/3000], Step [120/158]| g_loss: 0.667| d_loss: 0.620| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.539
Train: Epoch [2594/3000], Step [150/158]| g_loss: 0.667| d_loss: 0.640| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.282 | a_loss: 0.538
Train: Epoch [2595/3000], Step [30/158]| g_loss: 0.670| d_loss: 0.648| gp_loss: 0.116| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.541
Train: Epoch [2595/3000], Step [60/158]| g_loss: 0.686| d_loss: 0.525| gp_loss: 0.055| r_loss: 0.045| p_loss: 0.059| v_loss: 0.018| per_loss: 0.280 | a_loss: 0.565
Train: Epoch [2595/3000], Step [90/158]| g_loss: 0.635| d_loss: 0.675| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.510
Train: Epoch [2595/3000], Step [120/158]| g_loss: 0.635| d_loss: 0.641| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.504
Train: Epoch [2595/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.632| gp_loss: 0.064| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.540
Train: Epoch [2596/3000], Step [30/158]| g_loss: 0.620| d_loss: 0.781| gp_loss: 0.164| r_loss: 0.050| p_loss: 0.069| v_loss: 0.020| per_loss: 0.317 | a_loss: 0.483
Train: Epoch [2596/3000], Step [60/158]| g_loss: 0.633| d_loss: 0.673| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.500
Train: Epoch [2596/3000], Step [90/158]| g_loss: 0.622| d_loss: 0.680| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.493
Train: Epoch [2596/3000], Step [120/158]| g_loss: 0.676| d_loss: 0.506| gp_loss: 0.064| r_loss: 0.049| p_loss: 0.063| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.547
Train: Epoch [2596/3000], Step [150/158]| g_loss: 0.673| d_loss: 0.579| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.278 | a_loss: 0.547
Train: Epoch [2597/3000], Step [30/158]| g_loss: 0.659| d_loss: 0.712| gp_loss: 0.152| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.531
Train: Epoch [2597/3000], Step [60/158]| g_loss: 0.655| d_loss: 0.597| gp_loss: 0.057| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.531
Train: Epoch [2597/3000], Step [90/158]| g_loss: 0.673| d_loss: 0.605| gp_loss: 0.061| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.546
Train: Epoch [2597/3000], Step [120/158]| g_loss: 0.694| d_loss: 0.561| gp_loss: 0.062| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.567
Train: Epoch [2597/3000], Step [150/158]| g_loss: 0.623| d_loss: 0.751| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.492
Train: Epoch [2598/3000], Step [30/158]| g_loss: 0.627| d_loss: 0.833| gp_loss: 0.240| r_loss: 0.046| p_loss: 0.063| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.501
Train: Epoch [2598/3000], Step [60/158]| g_loss: 0.615| d_loss: 0.612| gp_loss: 0.049| r_loss: 0.048| p_loss: 0.059| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.489
Train: Epoch [2598/3000], Step [90/158]| g_loss: 0.651| d_loss: 0.547| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.061| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.524
Train: Epoch [2598/3000], Step [120/158]| g_loss: 0.646| d_loss: 0.621| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.519
Train: Epoch [2598/3000], Step [150/158]| g_loss: 0.696| d_loss: 0.617| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.570
Train: Epoch [2599/3000], Step [30/158]| g_loss: 0.623| d_loss: 0.799| gp_loss: 0.158| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.494
Train: Epoch [2599/3000], Step [60/158]| g_loss: 0.629| d_loss: 0.594| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.061| v_loss: 0.018| per_loss: 0.273 | a_loss: 0.507
Train: Epoch [2599/3000], Step [90/158]| g_loss: 0.669| d_loss: 0.607| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.540
Train: Epoch [2599/3000], Step [120/158]| g_loss: 0.662| d_loss: 0.635| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.535
Train: Epoch [2599/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.483| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.062| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.546
Train: Epoch [2600/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.710| gp_loss: 0.118| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.524
Train: Epoch [2600/3000], Step [60/158]| g_loss: 0.634| d_loss: 0.680| gp_loss: 0.054| r_loss: 0.045| p_loss: 0.061| v_loss: 0.018| per_loss: 0.308 | a_loss: 0.509
Train: Epoch [2600/3000], Step [90/158]| g_loss: 0.669| d_loss: 0.617| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.541
Train: Epoch [2600/3000], Step [120/158]| g_loss: 0.648| d_loss: 0.558| gp_loss: 0.062| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.518
Train: Epoch [2600/3000], Step [150/158]| g_loss: 0.691| d_loss: 0.536| gp_loss: 0.060| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.567
Test: Epoch [2600/3000]| g_loss: 0.754| r_loss: 0.471| p_loss: 0.369| v_loss: 0.023
Train: Epoch [2601/3000], Step [30/158]| g_loss: 0.647| d_loss: 0.624| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.514
Train: Epoch [2601/3000], Step [60/158]| g_loss: 0.682| d_loss: 0.583| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.062| v_loss: 0.018| per_loss: 0.292 | a_loss: 0.556
Train: Epoch [2601/3000], Step [90/158]| g_loss: 0.636| d_loss: 0.691| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.506
Train: Epoch [2601/3000], Step [120/158]| g_loss: 0.662| d_loss: 0.596| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.064| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.530
Train: Epoch [2601/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.637| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.528
Train: Epoch [2602/3000], Step [30/158]| g_loss: 0.699| d_loss: 0.578| gp_loss: 0.154| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.570
Train: Epoch [2602/3000], Step [60/158]| g_loss: 0.659| d_loss: 0.638| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.059| v_loss: 0.018| per_loss: 0.288 | a_loss: 0.536
Train: Epoch [2602/3000], Step [90/158]| g_loss: 0.670| d_loss: 0.617| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.063| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.542
Train: Epoch [2602/3000], Step [120/158]| g_loss: 0.630| d_loss: 0.601| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.059| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.505
Train: Epoch [2602/3000], Step [150/158]| g_loss: 0.649| d_loss: 0.635| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.520
Train: Epoch [2603/3000], Step [30/158]| g_loss: 0.655| d_loss: 0.696| gp_loss: 0.164| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.525
Train: Epoch [2603/3000], Step [60/158]| g_loss: 0.699| d_loss: 0.559| gp_loss: 0.051| r_loss: 0.048| p_loss: 0.062| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.569
Train: Epoch [2603/3000], Step [90/158]| g_loss: 0.665| d_loss: 0.679| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.536
Train: Epoch [2603/3000], Step [120/158]| g_loss: 0.608| d_loss: 0.688| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.481
Train: Epoch [2603/3000], Step [150/158]| g_loss: 0.631| d_loss: 0.592| gp_loss: 0.060| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.505
Train: Epoch [2604/3000], Step [30/158]| g_loss: 0.656| d_loss: 0.710| gp_loss: 0.157| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.527
Train: Epoch [2604/3000], Step [60/158]| g_loss: 0.655| d_loss: 0.565| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.531
Train: Epoch [2604/3000], Step [90/158]| g_loss: 0.695| d_loss: 0.548| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.063| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.564
Train: Epoch [2604/3000], Step [120/158]| g_loss: 0.636| d_loss: 0.728| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.508
Train: Epoch [2604/3000], Step [150/158]| g_loss: 0.648| d_loss: 0.602| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.521
Train: Epoch [2605/3000], Step [30/158]| g_loss: 0.645| d_loss: 0.764| gp_loss: 0.150| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.278 | a_loss: 0.517
Train: Epoch [2605/3000], Step [60/158]| g_loss: 0.661| d_loss: 0.661| gp_loss: 0.049| r_loss: 0.049| p_loss: 0.068| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.527
Train: Epoch [2605/3000], Step [90/158]| g_loss: 0.626| d_loss: 0.604| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.064| v_loss: 0.018| per_loss: 0.291 | a_loss: 0.499
Train: Epoch [2605/3000], Step [120/158]| g_loss: 0.662| d_loss: 0.629| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.531
Train: Epoch [2605/3000], Step [150/158]| g_loss: 0.682| d_loss: 0.552| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.555
Train: Epoch [2606/3000], Step [30/158]| g_loss: 0.682| d_loss: 0.684| gp_loss: 0.134| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.552
Train: Epoch [2606/3000], Step [60/158]| g_loss: 0.638| d_loss: 0.625| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.509
Train: Epoch [2606/3000], Step [90/158]| g_loss: 0.630| d_loss: 0.655| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.504
Train: Epoch [2606/3000], Step [120/158]| g_loss: 0.668| d_loss: 0.610| gp_loss: 0.062| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.534
Train: Epoch [2606/3000], Step [150/158]| g_loss: 0.671| d_loss: 0.506| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.539
Train: Epoch [2607/3000], Step [30/158]| g_loss: 0.660| d_loss: 0.820| gp_loss: 0.172| r_loss: 0.052| p_loss: 0.069| v_loss: 0.019| per_loss: 0.277 | a_loss: 0.527
Train: Epoch [2607/3000], Step [60/158]| g_loss: 0.652| d_loss: 0.547| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.066| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.523
Train: Epoch [2607/3000], Step [90/158]| g_loss: 0.671| d_loss: 0.596| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.543
Train: Epoch [2607/3000], Step [120/158]| g_loss: 0.665| d_loss: 0.645| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.538
Train: Epoch [2607/3000], Step [150/158]| g_loss: 0.665| d_loss: 0.646| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.535
Train: Epoch [2608/3000], Step [30/158]| g_loss: 0.706| d_loss: 0.589| gp_loss: 0.144| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.576
Train: Epoch [2608/3000], Step [60/158]| g_loss: 0.648| d_loss: 0.662| gp_loss: 0.051| r_loss: 0.049| p_loss: 0.067| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.517
Train: Epoch [2608/3000], Step [90/158]| g_loss: 0.659| d_loss: 0.550| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.531
Train: Epoch [2608/3000], Step [120/158]| g_loss: 0.709| d_loss: 0.548| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.061| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.579
Train: Epoch [2608/3000], Step [150/158]| g_loss: 0.633| d_loss: 0.740| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.062| v_loss: 0.018| per_loss: 0.290 | a_loss: 0.507
Train: Epoch [2609/3000], Step [30/158]| g_loss: 0.643| d_loss: 0.775| gp_loss: 0.158| r_loss: 0.051| p_loss: 0.065| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.512
Train: Epoch [2609/3000], Step [60/158]| g_loss: 0.651| d_loss: 0.524| gp_loss: 0.055| r_loss: 0.054| p_loss: 0.073| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.511
Train: Epoch [2609/3000], Step [90/158]| g_loss: 0.633| d_loss: 0.699| gp_loss: 0.052| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.279 | a_loss: 0.504
Train: Epoch [2609/3000], Step [120/158]| g_loss: 0.668| d_loss: 0.591| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.062| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.540
Train: Epoch [2609/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.574| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.531
Train: Epoch [2610/3000], Step [30/158]| g_loss: 0.629| d_loss: 0.773| gp_loss: 0.160| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.503
Train: Epoch [2610/3000], Step [60/158]| g_loss: 0.643| d_loss: 0.591| gp_loss: 0.052| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.514
Train: Epoch [2610/3000], Step [90/158]| g_loss: 0.680| d_loss: 0.558| gp_loss: 0.052| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.557
Train: Epoch [2610/3000], Step [120/158]| g_loss: 0.688| d_loss: 0.611| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.559
Train: Epoch [2610/3000], Step [150/158]| g_loss: 0.641| d_loss: 0.603| gp_loss: 0.056| r_loss: 0.045| p_loss: 0.060| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.518
Train: Epoch [2611/3000], Step [30/158]| g_loss: 0.635| d_loss: 0.721| gp_loss: 0.132| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.510
Train: Epoch [2611/3000], Step [60/158]| g_loss: 0.630| d_loss: 0.639| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.059| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.506
Train: Epoch [2611/3000], Step [90/158]| g_loss: 0.677| d_loss: 0.631| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.549
Train: Epoch [2611/3000], Step [120/158]| g_loss: 0.619| d_loss: 0.617| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.059| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.494
Train: Epoch [2611/3000], Step [150/158]| g_loss: 0.635| d_loss: 0.589| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.062| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.509
Train: Epoch [2612/3000], Step [30/158]| g_loss: 0.704| d_loss: 0.594| gp_loss: 0.130| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.572
Train: Epoch [2612/3000], Step [60/158]| g_loss: 0.703| d_loss: 0.568| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.579
Train: Epoch [2612/3000], Step [90/158]| g_loss: 0.624| d_loss: 0.735| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.497
Train: Epoch [2612/3000], Step [120/158]| g_loss: 0.652| d_loss: 0.598| gp_loss: 0.062| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.522
Train: Epoch [2612/3000], Step [150/158]| g_loss: 0.660| d_loss: 0.618| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.062| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.532
Train: Epoch [2613/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.731| gp_loss: 0.165| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.527
Train: Epoch [2613/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.541| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.546
Train: Epoch [2613/3000], Step [90/158]| g_loss: 0.686| d_loss: 0.640| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.556
Train: Epoch [2613/3000], Step [120/158]| g_loss: 0.647| d_loss: 0.636| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.519
Train: Epoch [2613/3000], Step [150/158]| g_loss: 0.636| d_loss: 0.630| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.062| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.506
Train: Epoch [2614/3000], Step [30/158]| g_loss: 0.662| d_loss: 0.738| gp_loss: 0.174| r_loss: 0.045| p_loss: 0.060| v_loss: 0.018| per_loss: 0.296 | a_loss: 0.539
Train: Epoch [2614/3000], Step [60/158]| g_loss: 0.644| d_loss: 0.581| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.518
Train: Epoch [2614/3000], Step [90/158]| g_loss: 0.686| d_loss: 0.669| gp_loss: 0.060| r_loss: 0.053| p_loss: 0.070| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.547
Train: Epoch [2614/3000], Step [120/158]| g_loss: 0.656| d_loss: 0.571| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.318 | a_loss: 0.519
Train: Epoch [2614/3000], Step [150/158]| g_loss: 0.674| d_loss: 0.621| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.067| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.543
Train: Epoch [2615/3000], Step [30/158]| g_loss: 0.647| d_loss: 0.753| gp_loss: 0.184| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.518
Train: Epoch [2615/3000], Step [60/158]| g_loss: 0.725| d_loss: 0.470| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.596
Train: Epoch [2615/3000], Step [90/158]| g_loss: 0.676| d_loss: 0.660| gp_loss: 0.049| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.545
Train: Epoch [2615/3000], Step [120/158]| g_loss: 0.639| d_loss: 0.626| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.066| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.508
Train: Epoch [2615/3000], Step [150/158]| g_loss: 0.693| d_loss: 0.603| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.565
Train: Epoch [2616/3000], Step [30/158]| g_loss: 0.673| d_loss: 0.690| gp_loss: 0.130| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.545
Train: Epoch [2616/3000], Step [60/158]| g_loss: 0.618| d_loss: 0.667| gp_loss: 0.051| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.485
Train: Epoch [2616/3000], Step [90/158]| g_loss: 0.711| d_loss: 0.506| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.585
Train: Epoch [2616/3000], Step [120/158]| g_loss: 0.651| d_loss: 0.649| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.526
Train: Epoch [2616/3000], Step [150/158]| g_loss: 0.642| d_loss: 0.658| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.517
Train: Epoch [2617/3000], Step [30/158]| g_loss: 0.635| d_loss: 0.717| gp_loss: 0.159| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.506
Train: Epoch [2617/3000], Step [60/158]| g_loss: 0.657| d_loss: 0.579| gp_loss: 0.051| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.530
Train: Epoch [2617/3000], Step [90/158]| g_loss: 0.637| d_loss: 0.601| gp_loss: 0.053| r_loss: 0.045| p_loss: 0.058| v_loss: 0.018| per_loss: 0.290 | a_loss: 0.516
Train: Epoch [2617/3000], Step [120/158]| g_loss: 0.650| d_loss: 0.648| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.061| v_loss: 0.020| per_loss: 0.286 | a_loss: 0.524
Train: Epoch [2617/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.571| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.532
Train: Epoch [2618/3000], Step [30/158]| g_loss: 0.708| d_loss: 0.646| gp_loss: 0.188| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.580
Train: Epoch [2618/3000], Step [60/158]| g_loss: 0.653| d_loss: 0.716| gp_loss: 0.051| r_loss: 0.049| p_loss: 0.063| v_loss: 0.020| per_loss: 0.310 | a_loss: 0.522
Train: Epoch [2618/3000], Step [90/158]| g_loss: 0.640| d_loss: 0.606| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.514
Train: Epoch [2618/3000], Step [120/158]| g_loss: 0.676| d_loss: 0.548| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.550
Train: Epoch [2618/3000], Step [150/158]| g_loss: 0.630| d_loss: 0.661| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.272 | a_loss: 0.503
Train: Epoch [2619/3000], Step [30/158]| g_loss: 0.697| d_loss: 0.737| gp_loss: 0.140| r_loss: 0.066| p_loss: 0.087| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.538
Train: Epoch [2619/3000], Step [60/158]| g_loss: 0.627| d_loss: 0.648| gp_loss: 0.054| r_loss: 0.059| p_loss: 0.089| v_loss: 0.020| per_loss: 0.288 | a_loss: 0.474
Train: Epoch [2619/3000], Step [90/158]| g_loss: 0.672| d_loss: 0.547| gp_loss: 0.057| r_loss: 0.052| p_loss: 0.074| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.532
Train: Epoch [2619/3000], Step [120/158]| g_loss: 0.662| d_loss: 0.618| gp_loss: 0.057| r_loss: 0.052| p_loss: 0.069| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.527
Train: Epoch [2619/3000], Step [150/158]| g_loss: 0.682| d_loss: 0.596| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.064| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.556
Train: Epoch [2620/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.720| gp_loss: 0.212| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.533
Train: Epoch [2620/3000], Step [60/158]| g_loss: 0.629| d_loss: 0.698| gp_loss: 0.048| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.498
Train: Epoch [2620/3000], Step [90/158]| g_loss: 0.638| d_loss: 0.670| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.068| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.507
Train: Epoch [2620/3000], Step [120/158]| g_loss: 0.695| d_loss: 0.523| gp_loss: 0.057| r_loss: 0.062| p_loss: 0.073| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.546
Train: Epoch [2620/3000], Step [150/158]| g_loss: 0.703| d_loss: 0.574| gp_loss: 0.056| r_loss: 0.059| p_loss: 0.077| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.559
Train: Epoch [2621/3000], Step [30/158]| g_loss: 0.705| d_loss: 0.629| gp_loss: 0.157| r_loss: 0.056| p_loss: 0.072| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.565
Train: Epoch [2621/3000], Step [60/158]| g_loss: 0.654| d_loss: 0.667| gp_loss: 0.051| r_loss: 0.051| p_loss: 0.071| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.518
Train: Epoch [2621/3000], Step [90/158]| g_loss: 0.636| d_loss: 0.616| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.066| v_loss: 0.018| per_loss: 0.283 | a_loss: 0.509
Train: Epoch [2621/3000], Step [120/158]| g_loss: 0.658| d_loss: 0.613| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.527
Train: Epoch [2621/3000], Step [150/158]| g_loss: 0.682| d_loss: 0.549| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.555
Train: Epoch [2622/3000], Step [30/158]| g_loss: 0.572| d_loss: 0.841| gp_loss: 0.097| r_loss: 0.049| p_loss: 0.070| v_loss: 0.020| per_loss: 0.318 | a_loss: 0.436
Train: Epoch [2622/3000], Step [60/158]| g_loss: 0.667| d_loss: 0.588| gp_loss: 0.062| r_loss: 0.051| p_loss: 0.066| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.533
Train: Epoch [2622/3000], Step [90/158]| g_loss: 0.643| d_loss: 0.633| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.514
Train: Epoch [2622/3000], Step [120/158]| g_loss: 0.655| d_loss: 0.636| gp_loss: 0.062| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.525
Train: Epoch [2622/3000], Step [150/158]| g_loss: 0.681| d_loss: 0.518| gp_loss: 0.066| r_loss: 0.049| p_loss: 0.067| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.550
Train: Epoch [2623/3000], Step [30/158]| g_loss: 0.655| d_loss: 0.746| gp_loss: 0.192| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.524
Train: Epoch [2623/3000], Step [60/158]| g_loss: 0.686| d_loss: 0.593| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.064| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.554
Train: Epoch [2623/3000], Step [90/158]| g_loss: 0.653| d_loss: 0.649| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.525
Train: Epoch [2623/3000], Step [120/158]| g_loss: 0.663| d_loss: 0.616| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.064| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.535
Train: Epoch [2623/3000], Step [150/158]| g_loss: 0.672| d_loss: 0.598| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.544
Train: Epoch [2624/3000], Step [30/158]| g_loss: 0.627| d_loss: 0.785| gp_loss: 0.176| r_loss: 0.049| p_loss: 0.068| v_loss: 0.020| per_loss: 0.318 | a_loss: 0.492
Train: Epoch [2624/3000], Step [60/158]| g_loss: 0.642| d_loss: 0.578| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.517
Train: Epoch [2624/3000], Step [90/158]| g_loss: 0.650| d_loss: 0.604| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.522
Train: Epoch [2624/3000], Step [120/158]| g_loss: 0.663| d_loss: 0.579| gp_loss: 0.060| r_loss: 0.046| p_loss: 0.061| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.537
Train: Epoch [2624/3000], Step [150/158]| g_loss: 0.693| d_loss: 0.607| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.561
Train: Epoch [2625/3000], Step [30/158]| g_loss: 0.672| d_loss: 0.665| gp_loss: 0.144| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.543
Train: Epoch [2625/3000], Step [60/158]| g_loss: 0.658| d_loss: 0.586| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.526
Train: Epoch [2625/3000], Step [90/158]| g_loss: 0.671| d_loss: 0.613| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.061| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.543
Train: Epoch [2625/3000], Step [120/158]| g_loss: 0.623| d_loss: 0.688| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.495
Train: Epoch [2625/3000], Step [150/158]| g_loss: 0.672| d_loss: 0.588| gp_loss: 0.060| r_loss: 0.046| p_loss: 0.063| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.543
Train: Epoch [2626/3000], Step [30/158]| g_loss: 0.591| d_loss: 0.747| gp_loss: 0.061| r_loss: 0.048| p_loss: 0.069| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.460
Train: Epoch [2626/3000], Step [60/158]| g_loss: 0.677| d_loss: 0.623| gp_loss: 0.064| r_loss: 0.050| p_loss: 0.070| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.541
Train: Epoch [2626/3000], Step [90/158]| g_loss: 0.651| d_loss: 0.616| gp_loss: 0.068| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.517
Train: Epoch [2626/3000], Step [120/158]| g_loss: 0.646| d_loss: 0.530| gp_loss: 0.065| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.310 | a_loss: 0.515
Train: Epoch [2626/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.686| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.530
Train: Epoch [2627/3000], Step [30/158]| g_loss: 0.672| d_loss: 0.665| gp_loss: 0.107| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.538
Train: Epoch [2627/3000], Step [60/158]| g_loss: 0.652| d_loss: 0.699| gp_loss: 0.062| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.522
Train: Epoch [2627/3000], Step [90/158]| g_loss: 0.618| d_loss: 0.595| gp_loss: 0.067| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.491
Train: Epoch [2627/3000], Step [120/158]| g_loss: 0.713| d_loss: 0.498| gp_loss: 0.065| r_loss: 0.047| p_loss: 0.063| v_loss: 0.021| per_loss: 0.318 | a_loss: 0.582
Train: Epoch [2627/3000], Step [150/158]| g_loss: 0.656| d_loss: 0.673| gp_loss: 0.063| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.309 | a_loss: 0.525
Train: Epoch [2628/3000], Step [30/158]| g_loss: 0.608| d_loss: 0.796| gp_loss: 0.188| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.479
Train: Epoch [2628/3000], Step [60/158]| g_loss: 0.681| d_loss: 0.610| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.316 | a_loss: 0.546
Train: Epoch [2628/3000], Step [90/158]| g_loss: 0.675| d_loss: 0.510| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.062| v_loss: 0.020| per_loss: 0.312 | a_loss: 0.544
Train: Epoch [2628/3000], Step [120/158]| g_loss: 0.657| d_loss: 0.658| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.527
Train: Epoch [2628/3000], Step [150/158]| g_loss: 0.711| d_loss: 0.544| gp_loss: 0.064| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.583
Train: Epoch [2629/3000], Step [30/158]| g_loss: 0.650| d_loss: 0.715| gp_loss: 0.163| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.519
Train: Epoch [2629/3000], Step [60/158]| g_loss: 0.704| d_loss: 0.535| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.060| v_loss: 0.020| per_loss: 0.313 | a_loss: 0.576
Train: Epoch [2629/3000], Step [90/158]| g_loss: 0.665| d_loss: 0.595| gp_loss: 0.052| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.315 | a_loss: 0.533
Train: Epoch [2629/3000], Step [120/158]| g_loss: 0.621| d_loss: 0.716| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.068| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.491
Train: Epoch [2629/3000], Step [150/158]| g_loss: 0.653| d_loss: 0.650| gp_loss: 0.063| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.525
Train: Epoch [2630/3000], Step [30/158]| g_loss: 0.617| d_loss: 0.709| gp_loss: 0.109| r_loss: 0.048| p_loss: 0.067| v_loss: 0.020| per_loss: 0.311 | a_loss: 0.484
Train: Epoch [2630/3000], Step [60/158]| g_loss: 0.664| d_loss: 0.521| gp_loss: 0.064| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.310 | a_loss: 0.533
Train: Epoch [2630/3000], Step [90/158]| g_loss: 0.671| d_loss: 0.598| gp_loss: 0.065| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.537
Train: Epoch [2630/3000], Step [120/158]| g_loss: 0.680| d_loss: 0.625| gp_loss: 0.063| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.321 | a_loss: 0.545
Train: Epoch [2630/3000], Step [150/158]| g_loss: 0.642| d_loss: 0.632| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.511
Train: Epoch [2631/3000], Step [30/158]| g_loss: 0.643| d_loss: 0.737| gp_loss: 0.178| r_loss: 0.047| p_loss: 0.066| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.514
Train: Epoch [2631/3000], Step [60/158]| g_loss: 0.648| d_loss: 0.587| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.062| v_loss: 0.020| per_loss: 0.316 | a_loss: 0.517
Train: Epoch [2631/3000], Step [90/158]| g_loss: 0.706| d_loss: 0.654| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.063| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.574
Train: Epoch [2631/3000], Step [120/158]| g_loss: 0.626| d_loss: 0.609| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.500
Train: Epoch [2631/3000], Step [150/158]| g_loss: 0.670| d_loss: 0.577| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.062| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.541
Train: Epoch [2632/3000], Step [30/158]| g_loss: 0.640| d_loss: 0.785| gp_loss: 0.175| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.513
Train: Epoch [2632/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.519| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.316 | a_loss: 0.543
Train: Epoch [2632/3000], Step [90/158]| g_loss: 0.675| d_loss: 0.639| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.540
Train: Epoch [2632/3000], Step [120/158]| g_loss: 0.646| d_loss: 0.597| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.516
Train: Epoch [2632/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.639| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.322 | a_loss: 0.534
Train: Epoch [2633/3000], Step [30/158]| g_loss: 0.629| d_loss: 0.719| gp_loss: 0.118| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.328 | a_loss: 0.496
Train: Epoch [2633/3000], Step [60/158]| g_loss: 0.645| d_loss: 0.557| gp_loss: 0.062| r_loss: 0.046| p_loss: 0.060| v_loss: 0.020| per_loss: 0.311 | a_loss: 0.519
Train: Epoch [2633/3000], Step [90/158]| g_loss: 0.723| d_loss: 0.494| gp_loss: 0.064| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.328 | a_loss: 0.593
Train: Epoch [2633/3000], Step [120/158]| g_loss: 0.660| d_loss: 0.740| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.067| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.529
Train: Epoch [2633/3000], Step [150/158]| g_loss: 0.643| d_loss: 0.658| gp_loss: 0.061| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.312 | a_loss: 0.512
Train: Epoch [2634/3000], Step [30/158]| g_loss: 0.642| d_loss: 0.702| gp_loss: 0.148| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.513
Train: Epoch [2634/3000], Step [60/158]| g_loss: 0.616| d_loss: 0.628| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.063| v_loss: 0.020| per_loss: 0.314 | a_loss: 0.486
Train: Epoch [2634/3000], Step [90/158]| g_loss: 0.676| d_loss: 0.607| gp_loss: 0.063| r_loss: 0.052| p_loss: 0.066| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.542
Train: Epoch [2634/3000], Step [120/158]| g_loss: 0.679| d_loss: 0.661| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.327 | a_loss: 0.545
Train: Epoch [2634/3000], Step [150/158]| g_loss: 0.692| d_loss: 0.526| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.060| v_loss: 0.020| per_loss: 0.317 | a_loss: 0.564
Train: Epoch [2635/3000], Step [30/158]| g_loss: 0.633| d_loss: 0.737| gp_loss: 0.126| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.315 | a_loss: 0.498
Train: Epoch [2635/3000], Step [60/158]| g_loss: 0.665| d_loss: 0.528| gp_loss: 0.061| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.538
Train: Epoch [2635/3000], Step [90/158]| g_loss: 0.663| d_loss: 0.590| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.536
Train: Epoch [2635/3000], Step [120/158]| g_loss: 0.648| d_loss: 0.674| gp_loss: 0.062| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.323 | a_loss: 0.516
Train: Epoch [2635/3000], Step [150/158]| g_loss: 0.656| d_loss: 0.594| gp_loss: 0.062| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.529
Train: Epoch [2636/3000], Step [30/158]| g_loss: 0.644| d_loss: 0.728| gp_loss: 0.152| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.517
Train: Epoch [2636/3000], Step [60/158]| g_loss: 0.648| d_loss: 0.609| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.311 | a_loss: 0.517
Train: Epoch [2636/3000], Step [90/158]| g_loss: 0.678| d_loss: 0.549| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.313 | a_loss: 0.548
Train: Epoch [2636/3000], Step [120/158]| g_loss: 0.725| d_loss: 0.581| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.320 | a_loss: 0.593
Train: Epoch [2636/3000], Step [150/158]| g_loss: 0.644| d_loss: 0.664| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.515
Train: Epoch [2637/3000], Step [30/158]| g_loss: 0.654| d_loss: 0.721| gp_loss: 0.123| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.327 | a_loss: 0.522
Train: Epoch [2637/3000], Step [60/158]| g_loss: 0.678| d_loss: 0.554| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.319 | a_loss: 0.546
Train: Epoch [2637/3000], Step [90/158]| g_loss: 0.667| d_loss: 0.585| gp_loss: 0.062| r_loss: 0.049| p_loss: 0.067| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.533
Train: Epoch [2637/3000], Step [120/158]| g_loss: 0.657| d_loss: 0.651| gp_loss: 0.060| r_loss: 0.053| p_loss: 0.068| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.520
Train: Epoch [2637/3000], Step [150/158]| g_loss: 0.653| d_loss: 0.623| gp_loss: 0.063| r_loss: 0.050| p_loss: 0.070| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.518
Train: Epoch [2638/3000], Step [30/158]| g_loss: 0.620| d_loss: 0.746| gp_loss: 0.145| r_loss: 0.049| p_loss: 0.068| v_loss: 0.019| per_loss: 0.325 | a_loss: 0.486
Train: Epoch [2638/3000], Step [60/158]| g_loss: 0.684| d_loss: 0.583| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.316 | a_loss: 0.550
Train: Epoch [2638/3000], Step [90/158]| g_loss: 0.670| d_loss: 0.595| gp_loss: 0.063| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.313 | a_loss: 0.537
Train: Epoch [2638/3000], Step [120/158]| g_loss: 0.678| d_loss: 0.600| gp_loss: 0.063| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.552
Train: Epoch [2638/3000], Step [150/158]| g_loss: 0.663| d_loss: 0.597| gp_loss: 0.061| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.307 | a_loss: 0.532
Train: Epoch [2639/3000], Step [30/158]| g_loss: 0.641| d_loss: 0.814| gp_loss: 0.203| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.312 | a_loss: 0.509
Train: Epoch [2639/3000], Step [60/158]| g_loss: 0.659| d_loss: 0.753| gp_loss: 0.055| r_loss: 0.052| p_loss: 0.068| v_loss: 0.020| per_loss: 0.323 | a_loss: 0.521
Train: Epoch [2639/3000], Step [90/158]| g_loss: 0.625| d_loss: 0.657| gp_loss: 0.060| r_loss: 0.051| p_loss: 0.076| v_loss: 0.020| per_loss: 0.324 | a_loss: 0.484
Train: Epoch [2639/3000], Step [120/158]| g_loss: 0.679| d_loss: 0.526| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.067| v_loss: 0.020| per_loss: 0.313 | a_loss: 0.546
Train: Epoch [2639/3000], Step [150/158]| g_loss: 0.680| d_loss: 0.541| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.066| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.551
Train: Epoch [2640/3000], Step [30/158]| g_loss: 0.699| d_loss: 0.697| gp_loss: 0.169| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.320 | a_loss: 0.565
Train: Epoch [2640/3000], Step [60/158]| g_loss: 0.639| d_loss: 0.627| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.315 | a_loss: 0.506
Train: Epoch [2640/3000], Step [90/158]| g_loss: 0.671| d_loss: 0.625| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.067| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.538
Train: Epoch [2640/3000], Step [120/158]| g_loss: 0.683| d_loss: 0.586| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.553
Train: Epoch [2640/3000], Step [150/158]| g_loss: 0.674| d_loss: 0.575| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.542
Train: Epoch [2641/3000], Step [30/158]| g_loss: 0.689| d_loss: 0.689| gp_loss: 0.136| r_loss: 0.051| p_loss: 0.070| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.553
Train: Epoch [2641/3000], Step [60/158]| g_loss: 0.689| d_loss: 0.619| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.322 | a_loss: 0.555
Train: Epoch [2641/3000], Step [90/158]| g_loss: 0.639| d_loss: 0.634| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.509
Train: Epoch [2641/3000], Step [120/158]| g_loss: 0.658| d_loss: 0.561| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.313 | a_loss: 0.526
Train: Epoch [2641/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.637| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.537
Train: Epoch [2642/3000], Step [30/158]| g_loss: 0.612| d_loss: 0.804| gp_loss: 0.159| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.483
Train: Epoch [2642/3000], Step [60/158]| g_loss: 0.652| d_loss: 0.542| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.522
Train: Epoch [2642/3000], Step [90/158]| g_loss: 0.710| d_loss: 0.584| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.581
Train: Epoch [2642/3000], Step [120/158]| g_loss: 0.658| d_loss: 0.630| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.307 | a_loss: 0.526
Train: Epoch [2642/3000], Step [150/158]| g_loss: 0.648| d_loss: 0.589| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.516
Train: Epoch [2643/3000], Step [30/158]| g_loss: 0.690| d_loss: 0.673| gp_loss: 0.145| r_loss: 0.050| p_loss: 0.069| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.555
Train: Epoch [2643/3000], Step [60/158]| g_loss: 0.712| d_loss: 0.465| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.581
Train: Epoch [2643/3000], Step [90/158]| g_loss: 0.690| d_loss: 0.655| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.560
Train: Epoch [2643/3000], Step [120/158]| g_loss: 0.635| d_loss: 0.660| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.065| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.501
Train: Epoch [2643/3000], Step [150/158]| g_loss: 0.656| d_loss: 0.633| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.328 | a_loss: 0.521
Train: Epoch [2644/3000], Step [30/158]| g_loss: 0.618| d_loss: 0.799| gp_loss: 0.182| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.484
Train: Epoch [2644/3000], Step [60/158]| g_loss: 0.670| d_loss: 0.562| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.322 | a_loss: 0.535
Train: Epoch [2644/3000], Step [90/158]| g_loss: 0.692| d_loss: 0.537| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.560
Train: Epoch [2644/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.650| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.309 | a_loss: 0.533
Train: Epoch [2644/3000], Step [150/158]| g_loss: 0.643| d_loss: 0.693| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.315 | a_loss: 0.512
Train: Epoch [2645/3000], Step [30/158]| g_loss: 0.701| d_loss: 0.602| gp_loss: 0.120| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.314 | a_loss: 0.566
Train: Epoch [2645/3000], Step [60/158]| g_loss: 0.611| d_loss: 0.696| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.481
Train: Epoch [2645/3000], Step [90/158]| g_loss: 0.675| d_loss: 0.543| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.062| v_loss: 0.020| per_loss: 0.313 | a_loss: 0.545
Train: Epoch [2645/3000], Step [120/158]| g_loss: 0.689| d_loss: 0.583| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.063| v_loss: 0.019| per_loss: 0.324 | a_loss: 0.556
Train: Epoch [2645/3000], Step [150/158]| g_loss: 0.644| d_loss: 0.658| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.068| v_loss: 0.020| per_loss: 0.311 | a_loss: 0.510
Train: Epoch [2646/3000], Step [30/158]| g_loss: 0.728| d_loss: 0.715| gp_loss: 0.090| r_loss: 0.070| p_loss: 0.113| v_loss: 0.021| per_loss: 0.353 | a_loss: 0.546
Train: Epoch [2646/3000], Step [60/158]| g_loss: 0.820| d_loss: 0.538| gp_loss: 0.056| r_loss: 0.092| p_loss: 0.150| v_loss: 0.022| per_loss: 0.370 | a_loss: 0.595
Train: Epoch [2646/3000], Step [90/158]| g_loss: 0.727| d_loss: 0.639| gp_loss: 0.057| r_loss: 0.079| p_loss: 0.110| v_loss: 0.021| per_loss: 0.342 | a_loss: 0.537
Train: Epoch [2646/3000], Step [120/158]| g_loss: 0.654| d_loss: 0.591| gp_loss: 0.061| r_loss: 0.057| p_loss: 0.089| v_loss: 0.020| per_loss: 0.336 | a_loss: 0.498
Train: Epoch [2646/3000], Step [150/158]| g_loss: 0.682| d_loss: 0.579| gp_loss: 0.062| r_loss: 0.050| p_loss: 0.072| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.548
Train: Epoch [2647/3000], Step [30/158]| g_loss: 0.665| d_loss: 0.723| gp_loss: 0.174| r_loss: 0.053| p_loss: 0.074| v_loss: 0.020| per_loss: 0.330 | a_loss: 0.522
Train: Epoch [2647/3000], Step [60/158]| g_loss: 0.626| d_loss: 0.684| gp_loss: 0.055| r_loss: 0.051| p_loss: 0.072| v_loss: 0.020| per_loss: 0.324 | a_loss: 0.487
Train: Epoch [2647/3000], Step [90/158]| g_loss: 0.629| d_loss: 0.604| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.499
Train: Epoch [2647/3000], Step [120/158]| g_loss: 0.724| d_loss: 0.548| gp_loss: 0.057| r_loss: 0.052| p_loss: 0.067| v_loss: 0.020| per_loss: 0.316 | a_loss: 0.587
Train: Epoch [2647/3000], Step [150/158]| g_loss: 0.685| d_loss: 0.550| gp_loss: 0.061| r_loss: 0.048| p_loss: 0.066| v_loss: 0.020| per_loss: 0.316 | a_loss: 0.552
Train: Epoch [2648/3000], Step [30/158]| g_loss: 0.660| d_loss: 0.694| gp_loss: 0.136| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.321 | a_loss: 0.525
Train: Epoch [2648/3000], Step [60/158]| g_loss: 0.685| d_loss: 0.584| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.067| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.550
Train: Epoch [2648/3000], Step [90/158]| g_loss: 0.648| d_loss: 0.650| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.520
Train: Epoch [2648/3000], Step [120/158]| g_loss: 0.632| d_loss: 0.704| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.503
Train: Epoch [2648/3000], Step [150/158]| g_loss: 0.655| d_loss: 0.544| gp_loss: 0.066| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.526
Train: Epoch [2649/3000], Step [30/158]| g_loss: 0.698| d_loss: 0.725| gp_loss: 0.203| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.326 | a_loss: 0.566
Train: Epoch [2649/3000], Step [60/158]| g_loss: 0.647| d_loss: 0.640| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.515
Train: Epoch [2649/3000], Step [90/158]| g_loss: 0.635| d_loss: 0.618| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.505
Train: Epoch [2649/3000], Step [120/158]| g_loss: 0.727| d_loss: 0.476| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.063| v_loss: 0.021| per_loss: 0.323 | a_loss: 0.595
Train: Epoch [2649/3000], Step [150/158]| g_loss: 0.653| d_loss: 0.657| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.524
Train: Epoch [2650/3000], Step [30/158]| g_loss: 0.640| d_loss: 0.759| gp_loss: 0.183| r_loss: 0.045| p_loss: 0.059| v_loss: 0.018| per_loss: 0.316 | a_loss: 0.516
Train: Epoch [2650/3000], Step [60/158]| g_loss: 0.674| d_loss: 0.571| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.547
Train: Epoch [2650/3000], Step [90/158]| g_loss: 0.683| d_loss: 0.582| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.554
Train: Epoch [2650/3000], Step [120/158]| g_loss: 0.688| d_loss: 0.529| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.063| v_loss: 0.020| per_loss: 0.323 | a_loss: 0.553
Train: Epoch [2650/3000], Step [150/158]| g_loss: 0.648| d_loss: 0.696| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.516
Test: Epoch [2650/3000]| g_loss: 0.758| r_loss: 0.473| p_loss: 0.386| v_loss: 0.024
Train: Epoch [2651/3000], Step [30/158]| g_loss: 0.629| d_loss: 0.635| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.064| v_loss: 0.021| per_loss: 0.315 | a_loss: 0.497
Train: Epoch [2651/3000], Step [60/158]| g_loss: 0.614| d_loss: 0.677| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.064| v_loss: 0.020| per_loss: 0.322 | a_loss: 0.483
Train: Epoch [2651/3000], Step [90/158]| g_loss: 0.700| d_loss: 0.643| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.316 | a_loss: 0.569
Train: Epoch [2651/3000], Step [120/158]| g_loss: 0.674| d_loss: 0.527| gp_loss: 0.062| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.544
Train: Epoch [2651/3000], Step [150/158]| g_loss: 0.665| d_loss: 0.635| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.535
Train: Epoch [2652/3000], Step [30/158]| g_loss: 0.686| d_loss: 0.719| gp_loss: 0.172| r_loss: 0.047| p_loss: 0.061| v_loss: 0.020| per_loss: 0.307 | a_loss: 0.558
Train: Epoch [2652/3000], Step [60/158]| g_loss: 0.650| d_loss: 0.577| gp_loss: 0.050| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.523
Train: Epoch [2652/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.602| gp_loss: 0.051| r_loss: 0.048| p_loss: 0.062| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.527
Train: Epoch [2652/3000], Step [120/158]| g_loss: 0.673| d_loss: 0.628| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.542
Train: Epoch [2652/3000], Step [150/158]| g_loss: 0.640| d_loss: 0.636| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.511
Train: Epoch [2653/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.719| gp_loss: 0.179| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.312 | a_loss: 0.531
Train: Epoch [2653/3000], Step [60/158]| g_loss: 0.632| d_loss: 0.627| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.502
Train: Epoch [2653/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.632| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.526
Train: Epoch [2653/3000], Step [120/158]| g_loss: 0.628| d_loss: 0.665| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.060| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.499
Train: Epoch [2653/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.541| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.533
Train: Epoch [2654/3000], Step [30/158]| g_loss: 0.689| d_loss: 0.729| gp_loss: 0.129| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.318 | a_loss: 0.557
Train: Epoch [2654/3000], Step [60/158]| g_loss: 0.670| d_loss: 0.582| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.062| v_loss: 0.020| per_loss: 0.321 | a_loss: 0.539
Train: Epoch [2654/3000], Step [90/158]| g_loss: 0.693| d_loss: 0.557| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.563
Train: Epoch [2654/3000], Step [120/158]| g_loss: 0.633| d_loss: 0.626| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.506
Train: Epoch [2654/3000], Step [150/158]| g_loss: 0.667| d_loss: 0.547| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.061| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.538
Train: Epoch [2655/3000], Step [30/158]| g_loss: 0.640| d_loss: 0.697| gp_loss: 0.104| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.515
Train: Epoch [2655/3000], Step [60/158]| g_loss: 0.677| d_loss: 0.597| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.328 | a_loss: 0.549
Train: Epoch [2655/3000], Step [90/158]| g_loss: 0.675| d_loss: 0.603| gp_loss: 0.062| r_loss: 0.049| p_loss: 0.062| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.544
Train: Epoch [2655/3000], Step [120/158]| g_loss: 0.675| d_loss: 0.545| gp_loss: 0.061| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.546
Train: Epoch [2655/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.678| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.067| v_loss: 0.020| per_loss: 0.318 | a_loss: 0.531
Train: Epoch [2656/3000], Step [30/158]| g_loss: 0.632| d_loss: 0.772| gp_loss: 0.163| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.314 | a_loss: 0.500
Train: Epoch [2656/3000], Step [60/158]| g_loss: 0.691| d_loss: 0.549| gp_loss: 0.060| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.321 | a_loss: 0.557
Train: Epoch [2656/3000], Step [90/158]| g_loss: 0.667| d_loss: 0.646| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.537
Train: Epoch [2656/3000], Step [120/158]| g_loss: 0.672| d_loss: 0.627| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.543
Train: Epoch [2656/3000], Step [150/158]| g_loss: 0.645| d_loss: 0.640| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.317 | a_loss: 0.513
Train: Epoch [2657/3000], Step [30/158]| g_loss: 0.639| d_loss: 0.741| gp_loss: 0.157| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.511
Train: Epoch [2657/3000], Step [60/158]| g_loss: 0.610| d_loss: 0.731| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.302 | a_loss: 0.476
Train: Epoch [2657/3000], Step [90/158]| g_loss: 0.661| d_loss: 0.503| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.531
Train: Epoch [2657/3000], Step [120/158]| g_loss: 0.696| d_loss: 0.550| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.067| v_loss: 0.020| per_loss: 0.318 | a_loss: 0.562
Train: Epoch [2657/3000], Step [150/158]| g_loss: 0.692| d_loss: 0.606| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.556
Train: Epoch [2658/3000], Step [30/158]| g_loss: 0.694| d_loss: 0.675| gp_loss: 0.167| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.562
Train: Epoch [2658/3000], Step [60/158]| g_loss: 0.645| d_loss: 0.632| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.515
Train: Epoch [2658/3000], Step [90/158]| g_loss: 0.663| d_loss: 0.679| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.531
Train: Epoch [2658/3000], Step [120/158]| g_loss: 0.656| d_loss: 0.619| gp_loss: 0.061| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.528
Train: Epoch [2658/3000], Step [150/158]| g_loss: 0.663| d_loss: 0.586| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.061| v_loss: 0.020| per_loss: 0.317 | a_loss: 0.535
Train: Epoch [2659/3000], Step [30/158]| g_loss: 0.689| d_loss: 0.621| gp_loss: 0.140| r_loss: 0.047| p_loss: 0.061| v_loss: 0.020| per_loss: 0.325 | a_loss: 0.560
Train: Epoch [2659/3000], Step [60/158]| g_loss: 0.629| d_loss: 0.716| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.060| v_loss: 0.018| per_loss: 0.301 | a_loss: 0.503
Train: Epoch [2659/3000], Step [90/158]| g_loss: 0.636| d_loss: 0.635| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.062| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.509
Train: Epoch [2659/3000], Step [120/158]| g_loss: 0.616| d_loss: 0.607| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.061| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.488
Train: Epoch [2659/3000], Step [150/158]| g_loss: 0.691| d_loss: 0.591| gp_loss: 0.064| r_loss: 0.051| p_loss: 0.065| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.558
Train: Epoch [2660/3000], Step [30/158]| g_loss: 0.634| d_loss: 0.775| gp_loss: 0.174| r_loss: 0.050| p_loss: 0.070| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.499
Train: Epoch [2660/3000], Step [60/158]| g_loss: 0.671| d_loss: 0.562| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.541
Train: Epoch [2660/3000], Step [90/158]| g_loss: 0.617| d_loss: 0.733| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.488
Train: Epoch [2660/3000], Step [120/158]| g_loss: 0.659| d_loss: 0.525| gp_loss: 0.066| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.526
Train: Epoch [2660/3000], Step [150/158]| g_loss: 0.699| d_loss: 0.617| gp_loss: 0.063| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.325 | a_loss: 0.564
Train: Epoch [2661/3000], Step [30/158]| g_loss: 0.683| d_loss: 0.667| gp_loss: 0.147| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.552
Train: Epoch [2661/3000], Step [60/158]| g_loss: 0.674| d_loss: 0.594| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.544
Train: Epoch [2661/3000], Step [90/158]| g_loss: 0.632| d_loss: 0.733| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.506
Train: Epoch [2661/3000], Step [120/158]| g_loss: 0.650| d_loss: 0.570| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.315 | a_loss: 0.519
Train: Epoch [2661/3000], Step [150/158]| g_loss: 0.668| d_loss: 0.639| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.318 | a_loss: 0.534
Train: Epoch [2662/3000], Step [30/158]| g_loss: 0.689| d_loss: 0.611| gp_loss: 0.149| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.324 | a_loss: 0.559
Train: Epoch [2662/3000], Step [60/158]| g_loss: 0.694| d_loss: 0.589| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.564
Train: Epoch [2662/3000], Step [90/158]| g_loss: 0.687| d_loss: 0.577| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.561
Train: Epoch [2662/3000], Step [120/158]| g_loss: 0.612| d_loss: 0.679| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.482
Train: Epoch [2662/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.682| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.533
Train: Epoch [2663/3000], Step [30/158]| g_loss: 0.646| d_loss: 0.671| gp_loss: 0.126| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.514
Train: Epoch [2663/3000], Step [60/158]| g_loss: 0.647| d_loss: 0.591| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.518
Train: Epoch [2663/3000], Step [90/158]| g_loss: 0.679| d_loss: 0.580| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.549
Train: Epoch [2663/3000], Step [120/158]| g_loss: 0.696| d_loss: 0.627| gp_loss: 0.062| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.330 | a_loss: 0.563
Train: Epoch [2663/3000], Step [150/158]| g_loss: 0.642| d_loss: 0.656| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.509
Train: Epoch [2664/3000], Step [30/158]| g_loss: 0.602| d_loss: 0.794| gp_loss: 0.179| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.473
Train: Epoch [2664/3000], Step [60/158]| g_loss: 0.643| d_loss: 0.566| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.510
Train: Epoch [2664/3000], Step [90/158]| g_loss: 0.675| d_loss: 0.621| gp_loss: 0.060| r_loss: 0.045| p_loss: 0.061| v_loss: 0.018| per_loss: 0.305 | a_loss: 0.551
Train: Epoch [2664/3000], Step [120/158]| g_loss: 0.682| d_loss: 0.551| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.550
Train: Epoch [2664/3000], Step [150/158]| g_loss: 0.680| d_loss: 0.658| gp_loss: 0.062| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.546
Train: Epoch [2665/3000], Step [30/158]| g_loss: 0.647| d_loss: 0.754| gp_loss: 0.160| r_loss: 0.050| p_loss: 0.071| v_loss: 0.020| per_loss: 0.322 | a_loss: 0.509
Train: Epoch [2665/3000], Step [60/158]| g_loss: 0.617| d_loss: 0.727| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.066| v_loss: 0.018| per_loss: 0.297 | a_loss: 0.488
Train: Epoch [2665/3000], Step [90/158]| g_loss: 0.644| d_loss: 0.517| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.515
Train: Epoch [2665/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.664| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.532
Train: Epoch [2665/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.546| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.542
Train: Epoch [2666/3000], Step [30/158]| g_loss: 0.665| d_loss: 0.719| gp_loss: 0.112| r_loss: 0.049| p_loss: 0.068| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.532
Train: Epoch [2666/3000], Step [60/158]| g_loss: 0.651| d_loss: 0.545| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.520
Train: Epoch [2666/3000], Step [90/158]| g_loss: 0.665| d_loss: 0.620| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.533
Train: Epoch [2666/3000], Step [120/158]| g_loss: 0.684| d_loss: 0.605| gp_loss: 0.062| r_loss: 0.049| p_loss: 0.067| v_loss: 0.020| per_loss: 0.312 | a_loss: 0.551
Train: Epoch [2666/3000], Step [150/158]| g_loss: 0.694| d_loss: 0.635| gp_loss: 0.062| r_loss: 0.050| p_loss: 0.069| v_loss: 0.019| per_loss: 0.325 | a_loss: 0.558
Train: Epoch [2667/3000], Step [30/158]| g_loss: 0.618| d_loss: 0.696| gp_loss: 0.111| r_loss: 0.050| p_loss: 0.070| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.483
Train: Epoch [2667/3000], Step [60/158]| g_loss: 0.696| d_loss: 0.620| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.566
Train: Epoch [2667/3000], Step [90/158]| g_loss: 0.661| d_loss: 0.557| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.530
Train: Epoch [2667/3000], Step [120/158]| g_loss: 0.682| d_loss: 0.633| gp_loss: 0.064| r_loss: 0.052| p_loss: 0.066| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.547
Train: Epoch [2667/3000], Step [150/158]| g_loss: 0.628| d_loss: 0.666| gp_loss: 0.063| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.329 | a_loss: 0.492
Train: Epoch [2668/3000], Step [30/158]| g_loss: 0.648| d_loss: 0.684| gp_loss: 0.122| r_loss: 0.051| p_loss: 0.069| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.513
Train: Epoch [2668/3000], Step [60/158]| g_loss: 0.669| d_loss: 0.582| gp_loss: 0.060| r_loss: 0.052| p_loss: 0.067| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.534
Train: Epoch [2668/3000], Step [90/158]| g_loss: 0.653| d_loss: 0.660| gp_loss: 0.063| r_loss: 0.052| p_loss: 0.071| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.515
Train: Epoch [2668/3000], Step [120/158]| g_loss: 0.670| d_loss: 0.675| gp_loss: 0.062| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.319 | a_loss: 0.531
Train: Epoch [2668/3000], Step [150/158]| g_loss: 0.655| d_loss: 0.521| gp_loss: 0.066| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.524
Train: Epoch [2669/3000], Step [30/158]| g_loss: 0.651| d_loss: 0.765| gp_loss: 0.153| r_loss: 0.049| p_loss: 0.068| v_loss: 0.019| per_loss: 0.315 | a_loss: 0.517
Train: Epoch [2669/3000], Step [60/158]| g_loss: 0.660| d_loss: 0.602| gp_loss: 0.060| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.524
Train: Epoch [2669/3000], Step [90/158]| g_loss: 0.684| d_loss: 0.611| gp_loss: 0.063| r_loss: 0.054| p_loss: 0.071| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.545
Train: Epoch [2669/3000], Step [120/158]| g_loss: 0.631| d_loss: 0.691| gp_loss: 0.064| r_loss: 0.047| p_loss: 0.065| v_loss: 0.018| per_loss: 0.306 | a_loss: 0.502
Train: Epoch [2669/3000], Step [150/158]| g_loss: 0.683| d_loss: 0.527| gp_loss: 0.069| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.554
Train: Epoch [2670/3000], Step [30/158]| g_loss: 0.673| d_loss: 0.775| gp_loss: 0.191| r_loss: 0.051| p_loss: 0.071| v_loss: 0.020| per_loss: 0.314 | a_loss: 0.536
Train: Epoch [2670/3000], Step [60/158]| g_loss: 0.702| d_loss: 0.537| gp_loss: 0.051| r_loss: 0.048| p_loss: 0.066| v_loss: 0.020| per_loss: 0.310 | a_loss: 0.570
Train: Epoch [2670/3000], Step [90/158]| g_loss: 0.662| d_loss: 0.670| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.060| v_loss: 0.018| per_loss: 0.308 | a_loss: 0.536
Train: Epoch [2670/3000], Step [120/158]| g_loss: 0.604| d_loss: 0.650| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.473
Train: Epoch [2670/3000], Step [150/158]| g_loss: 0.643| d_loss: 0.552| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.057| v_loss: 0.018| per_loss: 0.302 | a_loss: 0.519
Train: Epoch [2671/3000], Step [30/158]| g_loss: 0.692| d_loss: 0.701| gp_loss: 0.192| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.565
Train: Epoch [2671/3000], Step [60/158]| g_loss: 0.653| d_loss: 0.645| gp_loss: 0.048| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.311 | a_loss: 0.522
Train: Epoch [2671/3000], Step [90/158]| g_loss: 0.658| d_loss: 0.634| gp_loss: 0.052| r_loss: 0.046| p_loss: 0.061| v_loss: 0.020| per_loss: 0.322 | a_loss: 0.530
Train: Epoch [2671/3000], Step [120/158]| g_loss: 0.623| d_loss: 0.674| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.495
Train: Epoch [2671/3000], Step [150/158]| g_loss: 0.665| d_loss: 0.575| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.060| v_loss: 0.018| per_loss: 0.303 | a_loss: 0.539
Train: Epoch [2672/3000], Step [30/158]| g_loss: 0.653| d_loss: 0.713| gp_loss: 0.179| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.526
Train: Epoch [2672/3000], Step [60/158]| g_loss: 0.660| d_loss: 0.664| gp_loss: 0.052| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.318 | a_loss: 0.524
Train: Epoch [2672/3000], Step [90/158]| g_loss: 0.652| d_loss: 0.671| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.520
Train: Epoch [2672/3000], Step [120/158]| g_loss: 0.660| d_loss: 0.566| gp_loss: 0.059| r_loss: 0.052| p_loss: 0.066| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.526
Train: Epoch [2672/3000], Step [150/158]| g_loss: 0.666| d_loss: 0.577| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.319 | a_loss: 0.530
Train: Epoch [2673/3000], Step [30/158]| g_loss: 0.632| d_loss: 0.752| gp_loss: 0.144| r_loss: 0.050| p_loss: 0.071| v_loss: 0.019| per_loss: 0.318 | a_loss: 0.496
Train: Epoch [2673/3000], Step [60/158]| g_loss: 0.705| d_loss: 0.541| gp_loss: 0.059| r_loss: 0.053| p_loss: 0.071| v_loss: 0.020| per_loss: 0.314 | a_loss: 0.565
Train: Epoch [2673/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.615| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.068| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.524
Train: Epoch [2673/3000], Step [120/158]| g_loss: 0.705| d_loss: 0.579| gp_loss: 0.061| r_loss: 0.052| p_loss: 0.071| v_loss: 0.020| per_loss: 0.316 | a_loss: 0.566
Train: Epoch [2673/3000], Step [150/158]| g_loss: 0.660| d_loss: 0.633| gp_loss: 0.060| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.526
Train: Epoch [2674/3000], Step [30/158]| g_loss: 0.599| d_loss: 0.739| gp_loss: 0.098| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.470
Train: Epoch [2674/3000], Step [60/158]| g_loss: 0.659| d_loss: 0.598| gp_loss: 0.062| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.326 | a_loss: 0.528
Train: Epoch [2674/3000], Step [90/158]| g_loss: 0.681| d_loss: 0.592| gp_loss: 0.065| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.549
Train: Epoch [2674/3000], Step [120/158]| g_loss: 0.628| d_loss: 0.640| gp_loss: 0.063| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.323 | a_loss: 0.493
Train: Epoch [2674/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.546| gp_loss: 0.067| r_loss: 0.051| p_loss: 0.069| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.540
Train: Epoch [2675/3000], Step [30/158]| g_loss: 0.635| d_loss: 0.860| gp_loss: 0.191| r_loss: 0.049| p_loss: 0.068| v_loss: 0.020| per_loss: 0.311 | a_loss: 0.501
Train: Epoch [2675/3000], Step [60/158]| g_loss: 0.647| d_loss: 0.615| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.514
Train: Epoch [2675/3000], Step [90/158]| g_loss: 0.666| d_loss: 0.622| gp_loss: 0.063| r_loss: 0.050| p_loss: 0.069| v_loss: 0.018| per_loss: 0.325 | a_loss: 0.531
Train: Epoch [2675/3000], Step [120/158]| g_loss: 0.660| d_loss: 0.560| gp_loss: 0.063| r_loss: 0.052| p_loss: 0.066| v_loss: 0.020| per_loss: 0.313 | a_loss: 0.524
Train: Epoch [2675/3000], Step [150/158]| g_loss: 0.690| d_loss: 0.558| gp_loss: 0.063| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.558
Train: Epoch [2676/3000], Step [30/158]| g_loss: 0.696| d_loss: 0.753| gp_loss: 0.183| r_loss: 0.052| p_loss: 0.079| v_loss: 0.020| per_loss: 0.322 | a_loss: 0.552
Train: Epoch [2676/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.665| gp_loss: 0.060| r_loss: 0.056| p_loss: 0.085| v_loss: 0.020| per_loss: 0.329 | a_loss: 0.522
Train: Epoch [2676/3000], Step [90/158]| g_loss: 0.689| d_loss: 0.545| gp_loss: 0.067| r_loss: 0.053| p_loss: 0.075| v_loss: 0.020| per_loss: 0.314 | a_loss: 0.547
Train: Epoch [2676/3000], Step [120/158]| g_loss: 0.642| d_loss: 0.684| gp_loss: 0.062| r_loss: 0.053| p_loss: 0.074| v_loss: 0.020| per_loss: 0.324 | a_loss: 0.500
Train: Epoch [2676/3000], Step [150/158]| g_loss: 0.717| d_loss: 0.532| gp_loss: 0.065| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.318 | a_loss: 0.584
Train: Epoch [2677/3000], Step [30/158]| g_loss: 0.658| d_loss: 0.813| gp_loss: 0.280| r_loss: 0.049| p_loss: 0.070| v_loss: 0.020| per_loss: 0.313 | a_loss: 0.523
Train: Epoch [2677/3000], Step [60/158]| g_loss: 0.645| d_loss: 0.676| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.512
Train: Epoch [2677/3000], Step [90/158]| g_loss: 0.640| d_loss: 0.635| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.511
Train: Epoch [2677/3000], Step [120/158]| g_loss: 0.651| d_loss: 0.614| gp_loss: 0.063| r_loss: 0.050| p_loss: 0.069| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.516
Train: Epoch [2677/3000], Step [150/158]| g_loss: 0.660| d_loss: 0.620| gp_loss: 0.063| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.531
Train: Epoch [2678/3000], Step [30/158]| g_loss: 0.644| d_loss: 0.704| gp_loss: 0.152| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.512
Train: Epoch [2678/3000], Step [60/158]| g_loss: 0.650| d_loss: 0.684| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.520
Train: Epoch [2678/3000], Step [90/158]| g_loss: 0.660| d_loss: 0.540| gp_loss: 0.061| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.526
Train: Epoch [2678/3000], Step [120/158]| g_loss: 0.700| d_loss: 0.594| gp_loss: 0.063| r_loss: 0.051| p_loss: 0.068| v_loss: 0.019| per_loss: 0.324 | a_loss: 0.564
Train: Epoch [2678/3000], Step [150/158]| g_loss: 0.682| d_loss: 0.645| gp_loss: 0.059| r_loss: 0.051| p_loss: 0.071| v_loss: 0.019| per_loss: 0.319 | a_loss: 0.544
Train: Epoch [2679/3000], Step [30/158]| g_loss: 0.673| d_loss: 0.745| gp_loss: 0.180| r_loss: 0.053| p_loss: 0.075| v_loss: 0.020| per_loss: 0.331 | a_loss: 0.529
Train: Epoch [2679/3000], Step [60/158]| g_loss: 0.665| d_loss: 0.486| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.068| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.533
Train: Epoch [2679/3000], Step [90/158]| g_loss: 0.667| d_loss: 0.584| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.062| v_loss: 0.018| per_loss: 0.299 | a_loss: 0.542
Train: Epoch [2679/3000], Step [120/158]| g_loss: 0.686| d_loss: 0.611| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.065| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.552
Train: Epoch [2679/3000], Step [150/158]| g_loss: 0.631| d_loss: 0.700| gp_loss: 0.059| r_loss: 0.052| p_loss: 0.070| v_loss: 0.020| per_loss: 0.317 | a_loss: 0.493
Train: Epoch [2680/3000], Step [30/158]| g_loss: 0.672| d_loss: 0.779| gp_loss: 0.209| r_loss: 0.054| p_loss: 0.071| v_loss: 0.020| per_loss: 0.331 | a_loss: 0.530
Train: Epoch [2680/3000], Step [60/158]| g_loss: 0.599| d_loss: 0.725| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.065| v_loss: 0.018| per_loss: 0.314 | a_loss: 0.470
Train: Epoch [2680/3000], Step [90/158]| g_loss: 0.615| d_loss: 0.564| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.482
Train: Epoch [2680/3000], Step [120/158]| g_loss: 0.655| d_loss: 0.589| gp_loss: 0.060| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.524
Train: Epoch [2680/3000], Step [150/158]| g_loss: 0.703| d_loss: 0.498| gp_loss: 0.062| r_loss: 0.050| p_loss: 0.063| v_loss: 0.020| per_loss: 0.312 | a_loss: 0.571
Train: Epoch [2681/3000], Step [30/158]| g_loss: 0.689| d_loss: 0.730| gp_loss: 0.156| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.559
Train: Epoch [2681/3000], Step [60/158]| g_loss: 0.662| d_loss: 0.645| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.530
Train: Epoch [2681/3000], Step [90/158]| g_loss: 0.645| d_loss: 0.639| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.069| v_loss: 0.020| per_loss: 0.312 | a_loss: 0.509
Train: Epoch [2681/3000], Step [120/158]| g_loss: 0.661| d_loss: 0.571| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.532
Train: Epoch [2681/3000], Step [150/158]| g_loss: 0.667| d_loss: 0.571| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.535
Train: Epoch [2682/3000], Step [30/158]| g_loss: 0.661| d_loss: 0.770| gp_loss: 0.208| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.531
Train: Epoch [2682/3000], Step [60/158]| g_loss: 0.687| d_loss: 0.588| gp_loss: 0.050| r_loss: 0.048| p_loss: 0.062| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.558
Train: Epoch [2682/3000], Step [90/158]| g_loss: 0.652| d_loss: 0.594| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.063| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.522
Train: Epoch [2682/3000], Step [120/158]| g_loss: 0.635| d_loss: 0.644| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.506
Train: Epoch [2682/3000], Step [150/158]| g_loss: 0.640| d_loss: 0.640| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.512
Train: Epoch [2683/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.689| gp_loss: 0.147| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.279 | a_loss: 0.526
Train: Epoch [2683/3000], Step [60/158]| g_loss: 0.658| d_loss: 0.643| gp_loss: 0.052| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.312 | a_loss: 0.526
Train: Epoch [2683/3000], Step [90/158]| g_loss: 0.647| d_loss: 0.628| gp_loss: 0.052| r_loss: 0.045| p_loss: 0.060| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.523
Train: Epoch [2683/3000], Step [120/158]| g_loss: 0.648| d_loss: 0.594| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.521
Train: Epoch [2683/3000], Step [150/158]| g_loss: 0.692| d_loss: 0.559| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.566
Train: Epoch [2684/3000], Step [30/158]| g_loss: 0.661| d_loss: 0.705| gp_loss: 0.133| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.305 | a_loss: 0.529
Train: Epoch [2684/3000], Step [60/158]| g_loss: 0.630| d_loss: 0.669| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.502
Train: Epoch [2684/3000], Step [90/158]| g_loss: 0.642| d_loss: 0.654| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.515
Train: Epoch [2684/3000], Step [120/158]| g_loss: 0.656| d_loss: 0.587| gp_loss: 0.062| r_loss: 0.047| p_loss: 0.063| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.528
Train: Epoch [2684/3000], Step [150/158]| g_loss: 0.690| d_loss: 0.574| gp_loss: 0.062| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.301 | a_loss: 0.557
Train: Epoch [2685/3000], Step [30/158]| g_loss: 0.647| d_loss: 0.697| gp_loss: 0.111| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.518
Train: Epoch [2685/3000], Step [60/158]| g_loss: 0.660| d_loss: 0.571| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.530
Train: Epoch [2685/3000], Step [90/158]| g_loss: 0.674| d_loss: 0.595| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.544
Train: Epoch [2685/3000], Step [120/158]| g_loss: 0.639| d_loss: 0.715| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.509
Train: Epoch [2685/3000], Step [150/158]| g_loss: 0.685| d_loss: 0.523| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.556
Train: Epoch [2686/3000], Step [30/158]| g_loss: 0.683| d_loss: 0.690| gp_loss: 0.188| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.557
Train: Epoch [2686/3000], Step [60/158]| g_loss: 0.640| d_loss: 0.663| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.515
Train: Epoch [2686/3000], Step [90/158]| g_loss: 0.638| d_loss: 0.669| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.063| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.507
Train: Epoch [2686/3000], Step [120/158]| g_loss: 0.686| d_loss: 0.546| gp_loss: 0.060| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.553
Train: Epoch [2686/3000], Step [150/158]| g_loss: 0.671| d_loss: 0.593| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.541
Train: Epoch [2687/3000], Step [30/158]| g_loss: 0.637| d_loss: 0.744| gp_loss: 0.142| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.507
Train: Epoch [2687/3000], Step [60/158]| g_loss: 0.669| d_loss: 0.620| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.066| v_loss: 0.021| per_loss: 0.303 | a_loss: 0.536
Train: Epoch [2687/3000], Step [90/158]| g_loss: 0.686| d_loss: 0.567| gp_loss: 0.060| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.562
Train: Epoch [2687/3000], Step [120/158]| g_loss: 0.691| d_loss: 0.553| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.062| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.561
Train: Epoch [2687/3000], Step [150/158]| g_loss: 0.635| d_loss: 0.648| gp_loss: 0.059| r_loss: 0.045| p_loss: 0.059| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.512
Train: Epoch [2688/3000], Step [30/158]| g_loss: 0.666| d_loss: 0.728| gp_loss: 0.163| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.538
Train: Epoch [2688/3000], Step [60/158]| g_loss: 0.663| d_loss: 0.601| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.532
Train: Epoch [2688/3000], Step [90/158]| g_loss: 0.677| d_loss: 0.553| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.549
Train: Epoch [2688/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.626| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.537
Train: Epoch [2688/3000], Step [150/158]| g_loss: 0.618| d_loss: 0.671| gp_loss: 0.061| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.490
Train: Epoch [2689/3000], Step [30/158]| g_loss: 0.671| d_loss: 0.757| gp_loss: 0.186| r_loss: 0.048| p_loss: 0.067| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.541
Train: Epoch [2689/3000], Step [60/158]| g_loss: 0.651| d_loss: 0.600| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.523
Train: Epoch [2689/3000], Step [90/158]| g_loss: 0.671| d_loss: 0.593| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.063| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.539
Train: Epoch [2689/3000], Step [120/158]| g_loss: 0.684| d_loss: 0.605| gp_loss: 0.057| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.557
Train: Epoch [2689/3000], Step [150/158]| g_loss: 0.644| d_loss: 0.646| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.065| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.512
Train: Epoch [2690/3000], Step [30/158]| g_loss: 0.642| d_loss: 0.679| gp_loss: 0.104| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.516
Train: Epoch [2690/3000], Step [60/158]| g_loss: 0.654| d_loss: 0.554| gp_loss: 0.059| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.530
Train: Epoch [2690/3000], Step [90/158]| g_loss: 0.621| d_loss: 0.692| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.493
Train: Epoch [2690/3000], Step [120/158]| g_loss: 0.625| d_loss: 0.598| gp_loss: 0.062| r_loss: 0.047| p_loss: 0.058| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.502
Train: Epoch [2690/3000], Step [150/158]| g_loss: 0.670| d_loss: 0.609| gp_loss: 0.061| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.543
Train: Epoch [2691/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.722| gp_loss: 0.181| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.528
Train: Epoch [2691/3000], Step [60/158]| g_loss: 0.662| d_loss: 0.593| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.535
Train: Epoch [2691/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.639| gp_loss: 0.052| r_loss: 0.049| p_loss: 0.059| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.532
Train: Epoch [2691/3000], Step [120/158]| g_loss: 0.684| d_loss: 0.611| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.558
Train: Epoch [2691/3000], Step [150/158]| g_loss: 0.649| d_loss: 0.605| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.525
Train: Epoch [2692/3000], Step [30/158]| g_loss: 0.641| d_loss: 0.800| gp_loss: 0.206| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.513
Train: Epoch [2692/3000], Step [60/158]| g_loss: 0.609| d_loss: 0.698| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.480
Train: Epoch [2692/3000], Step [90/158]| g_loss: 0.616| d_loss: 0.588| gp_loss: 0.054| r_loss: 0.045| p_loss: 0.059| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.493
Train: Epoch [2692/3000], Step [120/158]| g_loss: 0.670| d_loss: 0.598| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.543
Train: Epoch [2692/3000], Step [150/158]| g_loss: 0.684| d_loss: 0.548| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.554
Train: Epoch [2693/3000], Step [30/158]| g_loss: 0.711| d_loss: 0.658| gp_loss: 0.194| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.584
Train: Epoch [2693/3000], Step [60/158]| g_loss: 0.642| d_loss: 0.708| gp_loss: 0.049| r_loss: 0.045| p_loss: 0.059| v_loss: 0.018| per_loss: 0.299 | a_loss: 0.519
Train: Epoch [2693/3000], Step [90/158]| g_loss: 0.614| d_loss: 0.624| gp_loss: 0.054| r_loss: 0.045| p_loss: 0.058| v_loss: 0.018| per_loss: 0.291 | a_loss: 0.493
Train: Epoch [2693/3000], Step [120/158]| g_loss: 0.669| d_loss: 0.653| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.537
Train: Epoch [2693/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.600| gp_loss: 0.052| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.537
Train: Epoch [2694/3000], Step [30/158]| g_loss: 0.661| d_loss: 0.630| gp_loss: 0.134| r_loss: 0.047| p_loss: 0.066| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.533
Train: Epoch [2694/3000], Step [60/158]| g_loss: 0.635| d_loss: 0.681| gp_loss: 0.052| r_loss: 0.045| p_loss: 0.062| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.510
Train: Epoch [2694/3000], Step [90/158]| g_loss: 0.678| d_loss: 0.572| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.553
Train: Epoch [2694/3000], Step [120/158]| g_loss: 0.652| d_loss: 0.664| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.523
Train: Epoch [2694/3000], Step [150/158]| g_loss: 0.652| d_loss: 0.621| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.069| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.517
Train: Epoch [2695/3000], Step [30/158]| g_loss: 0.664| d_loss: 0.699| gp_loss: 0.164| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.285 | a_loss: 0.535
Train: Epoch [2695/3000], Step [60/158]| g_loss: 0.649| d_loss: 0.654| gp_loss: 0.048| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.521
Train: Epoch [2695/3000], Step [90/158]| g_loss: 0.601| d_loss: 0.619| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.477
Train: Epoch [2695/3000], Step [120/158]| g_loss: 0.690| d_loss: 0.583| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.565
Train: Epoch [2695/3000], Step [150/158]| g_loss: 0.670| d_loss: 0.587| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.540
Train: Epoch [2696/3000], Step [30/158]| g_loss: 0.680| d_loss: 0.658| gp_loss: 0.140| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.554
Train: Epoch [2696/3000], Step [60/158]| g_loss: 0.660| d_loss: 0.628| gp_loss: 0.051| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.533
Train: Epoch [2696/3000], Step [90/158]| g_loss: 0.672| d_loss: 0.579| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.543
Train: Epoch [2696/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.660| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.544
Train: Epoch [2696/3000], Step [150/158]| g_loss: 0.626| d_loss: 0.610| gp_loss: 0.055| r_loss: 0.045| p_loss: 0.060| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.502
Train: Epoch [2697/3000], Step [30/158]| g_loss: 0.661| d_loss: 0.716| gp_loss: 0.193| r_loss: 0.047| p_loss: 0.058| v_loss: 0.019| per_loss: 0.278 | a_loss: 0.538
Train: Epoch [2697/3000], Step [60/158]| g_loss: 0.652| d_loss: 0.656| gp_loss: 0.050| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.525
Train: Epoch [2697/3000], Step [90/158]| g_loss: 0.665| d_loss: 0.583| gp_loss: 0.053| r_loss: 0.045| p_loss: 0.059| v_loss: 0.018| per_loss: 0.294 | a_loss: 0.543
Train: Epoch [2697/3000], Step [120/158]| g_loss: 0.644| d_loss: 0.628| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.518
Train: Epoch [2697/3000], Step [150/158]| g_loss: 0.660| d_loss: 0.626| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.062| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.532
Train: Epoch [2698/3000], Step [30/158]| g_loss: 0.626| d_loss: 0.729| gp_loss: 0.167| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.499
Train: Epoch [2698/3000], Step [60/158]| g_loss: 0.643| d_loss: 0.621| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.276 | a_loss: 0.520
Train: Epoch [2698/3000], Step [90/158]| g_loss: 0.647| d_loss: 0.625| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.520
Train: Epoch [2698/3000], Step [120/158]| g_loss: 0.660| d_loss: 0.634| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.063| v_loss: 0.018| per_loss: 0.296 | a_loss: 0.534
Train: Epoch [2698/3000], Step [150/158]| g_loss: 0.685| d_loss: 0.551| gp_loss: 0.056| r_loss: 0.052| p_loss: 0.066| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.550
Train: Epoch [2699/3000], Step [30/158]| g_loss: 0.687| d_loss: 0.710| gp_loss: 0.124| r_loss: 0.050| p_loss: 0.070| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.552
Train: Epoch [2699/3000], Step [60/158]| g_loss: 0.645| d_loss: 0.614| gp_loss: 0.050| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.517
Train: Epoch [2699/3000], Step [90/158]| g_loss: 0.624| d_loss: 0.703| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.274 | a_loss: 0.497
Train: Epoch [2699/3000], Step [120/158]| g_loss: 0.664| d_loss: 0.579| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.067| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.533
Train: Epoch [2699/3000], Step [150/158]| g_loss: 0.639| d_loss: 0.595| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.512
Train: Epoch [2700/3000], Step [30/158]| g_loss: 0.669| d_loss: 0.686| gp_loss: 0.147| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.541
Train: Epoch [2700/3000], Step [60/158]| g_loss: 0.647| d_loss: 0.619| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.063| v_loss: 0.018| per_loss: 0.289 | a_loss: 0.519
Train: Epoch [2700/3000], Step [90/158]| g_loss: 0.620| d_loss: 0.701| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.067| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.490
Train: Epoch [2700/3000], Step [120/158]| g_loss: 0.657| d_loss: 0.615| gp_loss: 0.061| r_loss: 0.050| p_loss: 0.062| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.527
Train: Epoch [2700/3000], Step [150/158]| g_loss: 0.671| d_loss: 0.526| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.063| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.544
Test: Epoch [2700/3000]| g_loss: 0.728| r_loss: 0.445| p_loss: 0.379| v_loss: 0.024
Train: Epoch [2701/3000], Step [30/158]| g_loss: 0.693| d_loss: 0.526| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.059| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.568
Train: Epoch [2701/3000], Step [60/158]| g_loss: 0.713| d_loss: 0.546| gp_loss: 0.053| r_loss: 0.044| p_loss: 0.059| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.591
Train: Epoch [2701/3000], Step [90/158]| g_loss: 0.643| d_loss: 0.697| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.061| v_loss: 0.018| per_loss: 0.272 | a_loss: 0.519
Train: Epoch [2701/3000], Step [120/158]| g_loss: 0.632| d_loss: 0.600| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.060| v_loss: 0.018| per_loss: 0.288 | a_loss: 0.508
Train: Epoch [2701/3000], Step [150/158]| g_loss: 0.622| d_loss: 0.661| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.494
Train: Epoch [2702/3000], Step [30/158]| g_loss: 0.668| d_loss: 0.712| gp_loss: 0.151| r_loss: 0.048| p_loss: 0.066| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.536
Train: Epoch [2702/3000], Step [60/158]| g_loss: 0.642| d_loss: 0.582| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.063| v_loss: 0.018| per_loss: 0.277 | a_loss: 0.518
Train: Epoch [2702/3000], Step [90/158]| g_loss: 0.635| d_loss: 0.609| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.506
Train: Epoch [2702/3000], Step [120/158]| g_loss: 0.679| d_loss: 0.640| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.555
Train: Epoch [2702/3000], Step [150/158]| g_loss: 0.652| d_loss: 0.642| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.527
Train: Epoch [2703/3000], Step [30/158]| g_loss: 0.658| d_loss: 0.680| gp_loss: 0.148| r_loss: 0.045| p_loss: 0.058| v_loss: 0.018| per_loss: 0.293 | a_loss: 0.537
Train: Epoch [2703/3000], Step [60/158]| g_loss: 0.637| d_loss: 0.683| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.511
Train: Epoch [2703/3000], Step [90/158]| g_loss: 0.650| d_loss: 0.655| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.522
Train: Epoch [2703/3000], Step [120/158]| g_loss: 0.648| d_loss: 0.527| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.063| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.519
Train: Epoch [2703/3000], Step [150/158]| g_loss: 0.694| d_loss: 0.590| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.562
Train: Epoch [2704/3000], Step [30/158]| g_loss: 0.656| d_loss: 0.725| gp_loss: 0.168| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.527
Train: Epoch [2704/3000], Step [60/158]| g_loss: 0.699| d_loss: 0.575| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.568
Train: Epoch [2704/3000], Step [90/158]| g_loss: 0.631| d_loss: 0.624| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.508
Train: Epoch [2704/3000], Step [120/158]| g_loss: 0.645| d_loss: 0.636| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.059| v_loss: 0.018| per_loss: 0.290 | a_loss: 0.522
Train: Epoch [2704/3000], Step [150/158]| g_loss: 0.700| d_loss: 0.588| gp_loss: 0.057| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.577
Train: Epoch [2705/3000], Step [30/158]| g_loss: 0.627| d_loss: 0.786| gp_loss: 0.195| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.501
Train: Epoch [2705/3000], Step [60/158]| g_loss: 0.668| d_loss: 0.584| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.542
Train: Epoch [2705/3000], Step [90/158]| g_loss: 0.691| d_loss: 0.551| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.063| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.562
Train: Epoch [2705/3000], Step [120/158]| g_loss: 0.613| d_loss: 0.682| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.061| v_loss: 0.018| per_loss: 0.294 | a_loss: 0.488
Train: Epoch [2705/3000], Step [150/158]| g_loss: 0.691| d_loss: 0.566| gp_loss: 0.059| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.568
Train: Epoch [2706/3000], Step [30/158]| g_loss: 0.612| d_loss: 0.772| gp_loss: 0.092| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.488
Train: Epoch [2706/3000], Step [60/158]| g_loss: 0.603| d_loss: 0.678| gp_loss: 0.056| r_loss: 0.045| p_loss: 0.058| v_loss: 0.018| per_loss: 0.288 | a_loss: 0.482
Train: Epoch [2706/3000], Step [90/158]| g_loss: 0.643| d_loss: 0.592| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.059| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.518
Train: Epoch [2706/3000], Step [120/158]| g_loss: 0.663| d_loss: 0.525| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.061| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.537
Train: Epoch [2706/3000], Step [150/158]| g_loss: 0.676| d_loss: 0.601| gp_loss: 0.063| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.550
Train: Epoch [2707/3000], Step [30/158]| g_loss: 0.674| d_loss: 0.806| gp_loss: 0.246| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.546
Train: Epoch [2707/3000], Step [60/158]| g_loss: 0.630| d_loss: 0.628| gp_loss: 0.052| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.501
Train: Epoch [2707/3000], Step [90/158]| g_loss: 0.658| d_loss: 0.551| gp_loss: 0.053| r_loss: 0.054| p_loss: 0.062| v_loss: 0.018| per_loss: 0.288 | a_loss: 0.526
Train: Epoch [2707/3000], Step [120/158]| g_loss: 0.725| d_loss: 0.570| gp_loss: 0.055| r_loss: 0.052| p_loss: 0.068| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.589
Train: Epoch [2707/3000], Step [150/158]| g_loss: 0.648| d_loss: 0.668| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.061| v_loss: 0.018| per_loss: 0.280 | a_loss: 0.524
Train: Epoch [2708/3000], Step [30/158]| g_loss: 0.657| d_loss: 0.691| gp_loss: 0.133| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.529
Train: Epoch [2708/3000], Step [60/158]| g_loss: 0.644| d_loss: 0.614| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.516
Train: Epoch [2708/3000], Step [90/158]| g_loss: 0.663| d_loss: 0.618| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.533
Train: Epoch [2708/3000], Step [120/158]| g_loss: 0.669| d_loss: 0.593| gp_loss: 0.057| r_loss: 0.054| p_loss: 0.074| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.529
Train: Epoch [2708/3000], Step [150/158]| g_loss: 0.693| d_loss: 0.576| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.067| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.558
Train: Epoch [2709/3000], Step [30/158]| g_loss: 0.642| d_loss: 0.692| gp_loss: 0.104| r_loss: 0.061| p_loss: 0.079| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.493
Train: Epoch [2709/3000], Step [60/158]| g_loss: 0.716| d_loss: 0.554| gp_loss: 0.057| r_loss: 0.055| p_loss: 0.076| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.576
Train: Epoch [2709/3000], Step [90/158]| g_loss: 0.661| d_loss: 0.644| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.069| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.529
Train: Epoch [2709/3000], Step [120/158]| g_loss: 0.621| d_loss: 0.662| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.275 | a_loss: 0.494
Train: Epoch [2709/3000], Step [150/158]| g_loss: 0.647| d_loss: 0.586| gp_loss: 0.061| r_loss: 0.046| p_loss: 0.062| v_loss: 0.018| per_loss: 0.292 | a_loss: 0.522
Train: Epoch [2710/3000], Step [30/158]| g_loss: 0.667| d_loss: 0.697| gp_loss: 0.143| r_loss: 0.050| p_loss: 0.070| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.532
Train: Epoch [2710/3000], Step [60/158]| g_loss: 0.674| d_loss: 0.640| gp_loss: 0.056| r_loss: 0.053| p_loss: 0.069| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.536
Train: Epoch [2710/3000], Step [90/158]| g_loss: 0.670| d_loss: 0.582| gp_loss: 0.062| r_loss: 0.048| p_loss: 0.066| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.540
Train: Epoch [2710/3000], Step [120/158]| g_loss: 0.672| d_loss: 0.587| gp_loss: 0.060| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.546
Train: Epoch [2710/3000], Step [150/158]| g_loss: 0.651| d_loss: 0.630| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.062| v_loss: 0.018| per_loss: 0.277 | a_loss: 0.528
Train: Epoch [2711/3000], Step [30/158]| g_loss: 0.634| d_loss: 0.702| gp_loss: 0.169| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.511
Train: Epoch [2711/3000], Step [60/158]| g_loss: 0.678| d_loss: 0.618| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.552
Train: Epoch [2711/3000], Step [90/158]| g_loss: 0.633| d_loss: 0.660| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.503
Train: Epoch [2711/3000], Step [120/158]| g_loss: 0.657| d_loss: 0.673| gp_loss: 0.061| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.530
Train: Epoch [2711/3000], Step [150/158]| g_loss: 0.632| d_loss: 0.563| gp_loss: 0.062| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.507
Train: Epoch [2712/3000], Step [30/158]| g_loss: 0.666| d_loss: 0.721| gp_loss: 0.190| r_loss: 0.046| p_loss: 0.058| v_loss: 0.018| per_loss: 0.284 | a_loss: 0.544
Train: Epoch [2712/3000], Step [60/158]| g_loss: 0.655| d_loss: 0.582| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.530
Train: Epoch [2712/3000], Step [90/158]| g_loss: 0.661| d_loss: 0.701| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.535
Train: Epoch [2712/3000], Step [120/158]| g_loss: 0.650| d_loss: 0.563| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.062| v_loss: 0.020| per_loss: 0.284 | a_loss: 0.525
Train: Epoch [2712/3000], Step [150/158]| g_loss: 0.671| d_loss: 0.603| gp_loss: 0.057| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.546
Train: Epoch [2713/3000], Step [30/158]| g_loss: 0.674| d_loss: 0.619| gp_loss: 0.137| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.548
Train: Epoch [2713/3000], Step [60/158]| g_loss: 0.664| d_loss: 0.729| gp_loss: 0.050| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.310 | a_loss: 0.531
Train: Epoch [2713/3000], Step [90/158]| g_loss: 0.661| d_loss: 0.544| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.535
Train: Epoch [2713/3000], Step [120/158]| g_loss: 0.680| d_loss: 0.623| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.547
Train: Epoch [2713/3000], Step [150/158]| g_loss: 0.645| d_loss: 0.627| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.515
Train: Epoch [2714/3000], Step [30/158]| g_loss: 0.658| d_loss: 0.655| gp_loss: 0.148| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.530
Train: Epoch [2714/3000], Step [60/158]| g_loss: 0.604| d_loss: 0.773| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.064| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.477
Train: Epoch [2714/3000], Step [90/158]| g_loss: 0.670| d_loss: 0.507| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.058| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.544
Train: Epoch [2714/3000], Step [120/158]| g_loss: 0.698| d_loss: 0.639| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.574
Train: Epoch [2714/3000], Step [150/158]| g_loss: 0.626| d_loss: 0.667| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.501
Train: Epoch [2715/3000], Step [30/158]| g_loss: 0.681| d_loss: 0.582| gp_loss: 0.124| r_loss: 0.045| p_loss: 0.058| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.556
Train: Epoch [2715/3000], Step [60/158]| g_loss: 0.645| d_loss: 0.621| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.059| v_loss: 0.018| per_loss: 0.277 | a_loss: 0.524
Train: Epoch [2715/3000], Step [90/158]| g_loss: 0.648| d_loss: 0.630| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.522
Train: Epoch [2715/3000], Step [120/158]| g_loss: 0.647| d_loss: 0.629| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.522
Train: Epoch [2715/3000], Step [150/158]| g_loss: 0.653| d_loss: 0.668| gp_loss: 0.061| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.526
Train: Epoch [2716/3000], Step [30/158]| g_loss: 0.626| d_loss: 0.677| gp_loss: 0.145| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.498
Train: Epoch [2716/3000], Step [60/158]| g_loss: 0.659| d_loss: 0.597| gp_loss: 0.061| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.533
Train: Epoch [2716/3000], Step [90/158]| g_loss: 0.696| d_loss: 0.528| gp_loss: 0.062| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.569
Train: Epoch [2716/3000], Step [120/158]| g_loss: 0.715| d_loss: 0.625| gp_loss: 0.059| r_loss: 0.045| p_loss: 0.059| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.591
Train: Epoch [2716/3000], Step [150/158]| g_loss: 0.627| d_loss: 0.680| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.500
Train: Epoch [2717/3000], Step [30/158]| g_loss: 0.654| d_loss: 0.652| gp_loss: 0.124| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.524
Train: Epoch [2717/3000], Step [60/158]| g_loss: 0.633| d_loss: 0.664| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.070| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.499
Train: Epoch [2717/3000], Step [90/158]| g_loss: 0.684| d_loss: 0.594| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.553
Train: Epoch [2717/3000], Step [120/158]| g_loss: 0.655| d_loss: 0.604| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.529
Train: Epoch [2717/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.581| gp_loss: 0.062| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.532
Train: Epoch [2718/3000], Step [30/158]| g_loss: 0.638| d_loss: 0.791| gp_loss: 0.178| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.508
Train: Epoch [2718/3000], Step [60/158]| g_loss: 0.603| d_loss: 0.686| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.471
Train: Epoch [2718/3000], Step [90/158]| g_loss: 0.665| d_loss: 0.604| gp_loss: 0.063| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.538
Train: Epoch [2718/3000], Step [120/158]| g_loss: 0.684| d_loss: 0.619| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.553
Train: Epoch [2718/3000], Step [150/158]| g_loss: 0.656| d_loss: 0.539| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.528
Train: Epoch [2719/3000], Step [30/158]| g_loss: 0.692| d_loss: 0.668| gp_loss: 0.203| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.561
Train: Epoch [2719/3000], Step [60/158]| g_loss: 0.649| d_loss: 0.643| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.063| v_loss: 0.020| per_loss: 0.311 | a_loss: 0.519
Train: Epoch [2719/3000], Step [90/158]| g_loss: 0.650| d_loss: 0.656| gp_loss: 0.054| r_loss: 0.051| p_loss: 0.075| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.511
Train: Epoch [2719/3000], Step [120/158]| g_loss: 0.712| d_loss: 0.534| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.068| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.580
Train: Epoch [2719/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.678| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.533
Train: Epoch [2720/3000], Step [30/158]| g_loss: 0.613| d_loss: 0.678| gp_loss: 0.102| r_loss: 0.051| p_loss: 0.067| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.480
Train: Epoch [2720/3000], Step [60/158]| g_loss: 0.654| d_loss: 0.627| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.523
Train: Epoch [2720/3000], Step [90/158]| g_loss: 0.633| d_loss: 0.695| gp_loss: 0.061| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.507
Train: Epoch [2720/3000], Step [120/158]| g_loss: 0.703| d_loss: 0.541| gp_loss: 0.062| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.571
Train: Epoch [2720/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.644| gp_loss: 0.067| r_loss: 0.048| p_loss: 0.067| v_loss: 0.020| per_loss: 0.304 | a_loss: 0.527
Train: Epoch [2721/3000], Step [30/158]| g_loss: 0.631| d_loss: 0.905| gp_loss: 0.250| r_loss: 0.048| p_loss: 0.068| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.500
Train: Epoch [2721/3000], Step [60/158]| g_loss: 0.638| d_loss: 0.688| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.509
Train: Epoch [2721/3000], Step [90/158]| g_loss: 0.635| d_loss: 0.536| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.507
Train: Epoch [2721/3000], Step [120/158]| g_loss: 0.672| d_loss: 0.577| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.063| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.543
Train: Epoch [2721/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.643| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.528
Train: Epoch [2722/3000], Step [30/158]| g_loss: 0.638| d_loss: 0.676| gp_loss: 0.122| r_loss: 0.047| p_loss: 0.062| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.510
Train: Epoch [2722/3000], Step [60/158]| g_loss: 0.712| d_loss: 0.567| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.062| v_loss: 0.020| per_loss: 0.312 | a_loss: 0.582
Train: Epoch [2722/3000], Step [90/158]| g_loss: 0.665| d_loss: 0.602| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.538
Train: Epoch [2722/3000], Step [120/158]| g_loss: 0.637| d_loss: 0.645| gp_loss: 0.057| r_loss: 0.046| p_loss: 0.067| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.509
Train: Epoch [2722/3000], Step [150/158]| g_loss: 0.640| d_loss: 0.654| gp_loss: 0.059| r_loss: 0.046| p_loss: 0.062| v_loss: 0.018| per_loss: 0.301 | a_loss: 0.515
Train: Epoch [2723/3000], Step [30/158]| g_loss: 0.644| d_loss: 0.781| gp_loss: 0.175| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.518
Train: Epoch [2723/3000], Step [60/158]| g_loss: 0.622| d_loss: 0.624| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.494
Train: Epoch [2723/3000], Step [90/158]| g_loss: 0.651| d_loss: 0.573| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.527
Train: Epoch [2723/3000], Step [120/158]| g_loss: 0.686| d_loss: 0.577| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.553
Train: Epoch [2723/3000], Step [150/158]| g_loss: 0.666| d_loss: 0.580| gp_loss: 0.059| r_loss: 0.045| p_loss: 0.059| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.543
Train: Epoch [2724/3000], Step [30/158]| g_loss: 0.647| d_loss: 0.746| gp_loss: 0.185| r_loss: 0.044| p_loss: 0.060| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.524
Train: Epoch [2724/3000], Step [60/158]| g_loss: 0.681| d_loss: 0.585| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.309 | a_loss: 0.549
Train: Epoch [2724/3000], Step [90/158]| g_loss: 0.658| d_loss: 0.612| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.529
Train: Epoch [2724/3000], Step [120/158]| g_loss: 0.625| d_loss: 0.705| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.062| v_loss: 0.018| per_loss: 0.289 | a_loss: 0.501
Train: Epoch [2724/3000], Step [150/158]| g_loss: 0.650| d_loss: 0.507| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.523
Train: Epoch [2725/3000], Step [30/158]| g_loss: 0.637| d_loss: 0.753| gp_loss: 0.100| r_loss: 0.049| p_loss: 0.067| v_loss: 0.020| per_loss: 0.296 | a_loss: 0.505
Train: Epoch [2725/3000], Step [60/158]| g_loss: 0.650| d_loss: 0.688| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.523
Train: Epoch [2725/3000], Step [90/158]| g_loss: 0.633| d_loss: 0.661| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.506
Train: Epoch [2725/3000], Step [120/158]| g_loss: 0.668| d_loss: 0.536| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.537
Train: Epoch [2725/3000], Step [150/158]| g_loss: 0.638| d_loss: 0.643| gp_loss: 0.060| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.506
Train: Epoch [2726/3000], Step [30/158]| g_loss: 0.740| d_loss: 0.616| gp_loss: 0.164| r_loss: 0.056| p_loss: 0.078| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.595
Train: Epoch [2726/3000], Step [60/158]| g_loss: 0.613| d_loss: 0.792| gp_loss: 0.049| r_loss: 0.062| p_loss: 0.079| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.464
Train: Epoch [2726/3000], Step [90/158]| g_loss: 0.636| d_loss: 0.589| gp_loss: 0.058| r_loss: 0.061| p_loss: 0.083| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.485
Train: Epoch [2726/3000], Step [120/158]| g_loss: 0.694| d_loss: 0.581| gp_loss: 0.058| r_loss: 0.052| p_loss: 0.070| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.559
Train: Epoch [2726/3000], Step [150/158]| g_loss: 0.686| d_loss: 0.542| gp_loss: 0.060| r_loss: 0.050| p_loss: 0.069| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.553
Train: Epoch [2727/3000], Step [30/158]| g_loss: 0.637| d_loss: 0.746| gp_loss: 0.107| r_loss: 0.051| p_loss: 0.070| v_loss: 0.020| per_loss: 0.295 | a_loss: 0.502
Train: Epoch [2727/3000], Step [60/158]| g_loss: 0.685| d_loss: 0.548| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.555
Train: Epoch [2727/3000], Step [90/158]| g_loss: 0.637| d_loss: 0.758| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.064| v_loss: 0.018| per_loss: 0.272 | a_loss: 0.512
Train: Epoch [2727/3000], Step [120/158]| g_loss: 0.611| d_loss: 0.583| gp_loss: 0.063| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.481
Train: Epoch [2727/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.521| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.535
Train: Epoch [2728/3000], Step [30/158]| g_loss: 0.649| d_loss: 0.733| gp_loss: 0.129| r_loss: 0.046| p_loss: 0.063| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.523
Train: Epoch [2728/3000], Step [60/158]| g_loss: 0.672| d_loss: 0.635| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.543
Train: Epoch [2728/3000], Step [90/158]| g_loss: 0.652| d_loss: 0.556| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.062| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.522
Train: Epoch [2728/3000], Step [120/158]| g_loss: 0.670| d_loss: 0.677| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.545
Train: Epoch [2728/3000], Step [150/158]| g_loss: 0.616| d_loss: 0.645| gp_loss: 0.063| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.489
Train: Epoch [2729/3000], Step [30/158]| g_loss: 0.659| d_loss: 0.696| gp_loss: 0.205| r_loss: 0.047| p_loss: 0.058| v_loss: 0.019| per_loss: 0.277 | a_loss: 0.536
Train: Epoch [2729/3000], Step [60/158]| g_loss: 0.676| d_loss: 0.597| gp_loss: 0.050| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.547
Train: Epoch [2729/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.665| gp_loss: 0.055| r_loss: 0.044| p_loss: 0.059| v_loss: 0.019| per_loss: 0.272 | a_loss: 0.538
Train: Epoch [2729/3000], Step [120/158]| g_loss: 0.641| d_loss: 0.608| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.058| v_loss: 0.020| per_loss: 0.315 | a_loss: 0.513
Train: Epoch [2729/3000], Step [150/158]| g_loss: 0.653| d_loss: 0.620| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.529
Train: Epoch [2730/3000], Step [30/158]| g_loss: 0.612| d_loss: 0.784| gp_loss: 0.164| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.484
Train: Epoch [2730/3000], Step [60/158]| g_loss: 0.636| d_loss: 0.616| gp_loss: 0.056| r_loss: 0.045| p_loss: 0.060| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.513
Train: Epoch [2730/3000], Step [90/158]| g_loss: 0.694| d_loss: 0.582| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.570
Train: Epoch [2730/3000], Step [120/158]| g_loss: 0.669| d_loss: 0.568| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.546
Train: Epoch [2730/3000], Step [150/158]| g_loss: 0.645| d_loss: 0.622| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.280 | a_loss: 0.518
Train: Epoch [2731/3000], Step [30/158]| g_loss: 0.616| d_loss: 0.798| gp_loss: 0.193| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.488
Train: Epoch [2731/3000], Step [60/158]| g_loss: 0.657| d_loss: 0.568| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.063| v_loss: 0.020| per_loss: 0.290 | a_loss: 0.528
Train: Epoch [2731/3000], Step [90/158]| g_loss: 0.640| d_loss: 0.681| gp_loss: 0.055| r_loss: 0.044| p_loss: 0.060| v_loss: 0.018| per_loss: 0.282 | a_loss: 0.519
Train: Epoch [2731/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.554| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.060| v_loss: 0.020| per_loss: 0.293 | a_loss: 0.540
Train: Epoch [2731/3000], Step [150/158]| g_loss: 0.646| d_loss: 0.636| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.523
Train: Epoch [2732/3000], Step [30/158]| g_loss: 0.694| d_loss: 0.635| gp_loss: 0.148| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.567
Train: Epoch [2732/3000], Step [60/158]| g_loss: 0.632| d_loss: 0.733| gp_loss: 0.054| r_loss: 0.045| p_loss: 0.061| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.509
Train: Epoch [2732/3000], Step [90/158]| g_loss: 0.610| d_loss: 0.651| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.483
Train: Epoch [2732/3000], Step [120/158]| g_loss: 0.642| d_loss: 0.603| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.515
Train: Epoch [2732/3000], Step [150/158]| g_loss: 0.695| d_loss: 0.572| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.568
Train: Epoch [2733/3000], Step [30/158]| g_loss: 0.674| d_loss: 0.699| gp_loss: 0.169| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.548
Train: Epoch [2733/3000], Step [60/158]| g_loss: 0.641| d_loss: 0.679| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.512
Train: Epoch [2733/3000], Step [90/158]| g_loss: 0.663| d_loss: 0.576| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.283 | a_loss: 0.535
Train: Epoch [2733/3000], Step [120/158]| g_loss: 0.655| d_loss: 0.632| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.528
Train: Epoch [2733/3000], Step [150/158]| g_loss: 0.644| d_loss: 0.607| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.059| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.521
Train: Epoch [2734/3000], Step [30/158]| g_loss: 0.683| d_loss: 0.645| gp_loss: 0.144| r_loss: 0.047| p_loss: 0.061| v_loss: 0.020| per_loss: 0.297 | a_loss: 0.556
Train: Epoch [2734/3000], Step [60/158]| g_loss: 0.629| d_loss: 0.674| gp_loss: 0.051| r_loss: 0.048| p_loss: 0.061| v_loss: 0.018| per_loss: 0.296 | a_loss: 0.503
Train: Epoch [2734/3000], Step [90/158]| g_loss: 0.660| d_loss: 0.494| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.276 | a_loss: 0.538
Train: Epoch [2734/3000], Step [120/158]| g_loss: 0.705| d_loss: 0.611| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.581
Train: Epoch [2734/3000], Step [150/158]| g_loss: 0.627| d_loss: 0.719| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.057| v_loss: 0.018| per_loss: 0.276 | a_loss: 0.507
Train: Epoch [2735/3000], Step [30/158]| g_loss: 0.605| d_loss: 0.736| gp_loss: 0.138| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.479
Train: Epoch [2735/3000], Step [60/158]| g_loss: 0.645| d_loss: 0.586| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.521
Train: Epoch [2735/3000], Step [90/158]| g_loss: 0.635| d_loss: 0.608| gp_loss: 0.059| r_loss: 0.045| p_loss: 0.057| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.514
Train: Epoch [2735/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.545| gp_loss: 0.058| r_loss: 0.045| p_loss: 0.057| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.556
Train: Epoch [2735/3000], Step [150/158]| g_loss: 0.645| d_loss: 0.666| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.519
Train: Epoch [2736/3000], Step [30/158]| g_loss: 0.582| d_loss: 0.862| gp_loss: 0.221| r_loss: 0.048| p_loss: 0.067| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.454
Train: Epoch [2736/3000], Step [60/158]| g_loss: 0.625| d_loss: 0.702| gp_loss: 0.053| r_loss: 0.052| p_loss: 0.065| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.492
Train: Epoch [2736/3000], Step [90/158]| g_loss: 0.639| d_loss: 0.594| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.059| v_loss: 0.018| per_loss: 0.284 | a_loss: 0.516
Train: Epoch [2736/3000], Step [120/158]| g_loss: 0.642| d_loss: 0.525| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.059| v_loss: 0.019| per_loss: 0.277 | a_loss: 0.518
Train: Epoch [2736/3000], Step [150/158]| g_loss: 0.678| d_loss: 0.627| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.551
Train: Epoch [2737/3000], Step [30/158]| g_loss: 0.629| d_loss: 0.675| gp_loss: 0.156| r_loss: 0.044| p_loss: 0.058| v_loss: 0.018| per_loss: 0.288 | a_loss: 0.509
Train: Epoch [2737/3000], Step [60/158]| g_loss: 0.678| d_loss: 0.594| gp_loss: 0.050| r_loss: 0.050| p_loss: 0.063| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.550
Train: Epoch [2737/3000], Step [90/158]| g_loss: 0.689| d_loss: 0.597| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.563
Train: Epoch [2737/3000], Step [120/158]| g_loss: 0.670| d_loss: 0.645| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.544
Train: Epoch [2737/3000], Step [150/158]| g_loss: 0.634| d_loss: 0.720| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.506
Train: Epoch [2738/3000], Step [30/158]| g_loss: 0.614| d_loss: 0.766| gp_loss: 0.175| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.483
Train: Epoch [2738/3000], Step [60/158]| g_loss: 0.659| d_loss: 0.528| gp_loss: 0.052| r_loss: 0.050| p_loss: 0.064| v_loss: 0.020| per_loss: 0.292 | a_loss: 0.529
Train: Epoch [2738/3000], Step [90/158]| g_loss: 0.655| d_loss: 0.647| gp_loss: 0.054| r_loss: 0.045| p_loss: 0.060| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.532
Train: Epoch [2738/3000], Step [120/158]| g_loss: 0.626| d_loss: 0.725| gp_loss: 0.052| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.496
Train: Epoch [2738/3000], Step [150/158]| g_loss: 0.635| d_loss: 0.522| gp_loss: 0.063| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.511
Train: Epoch [2739/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.695| gp_loss: 0.107| r_loss: 0.045| p_loss: 0.059| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.530
Train: Epoch [2739/3000], Step [60/158]| g_loss: 0.675| d_loss: 0.579| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.062| v_loss: 0.020| per_loss: 0.291 | a_loss: 0.548
Train: Epoch [2739/3000], Step [90/158]| g_loss: 0.614| d_loss: 0.654| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.061| v_loss: 0.018| per_loss: 0.282 | a_loss: 0.491
Train: Epoch [2739/3000], Step [120/158]| g_loss: 0.697| d_loss: 0.543| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.058| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.572
Train: Epoch [2739/3000], Step [150/158]| g_loss: 0.629| d_loss: 0.674| gp_loss: 0.057| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.505
Train: Epoch [2740/3000], Step [30/158]| g_loss: 0.626| d_loss: 0.661| gp_loss: 0.074| r_loss: 0.045| p_loss: 0.063| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.498
Train: Epoch [2740/3000], Step [60/158]| g_loss: 0.679| d_loss: 0.589| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.061| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.550
Train: Epoch [2740/3000], Step [90/158]| g_loss: 0.676| d_loss: 0.605| gp_loss: 0.061| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.276 | a_loss: 0.550
Train: Epoch [2740/3000], Step [120/158]| g_loss: 0.644| d_loss: 0.623| gp_loss: 0.064| r_loss: 0.045| p_loss: 0.059| v_loss: 0.018| per_loss: 0.290 | a_loss: 0.522
Train: Epoch [2740/3000], Step [150/158]| g_loss: 0.651| d_loss: 0.655| gp_loss: 0.065| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.523
Train: Epoch [2741/3000], Step [30/158]| g_loss: 0.628| d_loss: 0.697| gp_loss: 0.192| r_loss: 0.047| p_loss: 0.061| v_loss: 0.018| per_loss: 0.274 | a_loss: 0.505
Train: Epoch [2741/3000], Step [60/158]| g_loss: 0.641| d_loss: 0.657| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.518
Train: Epoch [2741/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.652| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.529
Train: Epoch [2741/3000], Step [120/158]| g_loss: 0.638| d_loss: 0.699| gp_loss: 0.059| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.514
Train: Epoch [2741/3000], Step [150/158]| g_loss: 0.637| d_loss: 0.562| gp_loss: 0.065| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.511
Train: Epoch [2742/3000], Step [30/158]| g_loss: 0.658| d_loss: 0.705| gp_loss: 0.157| r_loss: 0.046| p_loss: 0.060| v_loss: 0.020| per_loss: 0.298 | a_loss: 0.532
Train: Epoch [2742/3000], Step [60/158]| g_loss: 0.637| d_loss: 0.632| gp_loss: 0.054| r_loss: 0.045| p_loss: 0.059| v_loss: 0.018| per_loss: 0.282 | a_loss: 0.516
Train: Epoch [2742/3000], Step [90/158]| g_loss: 0.660| d_loss: 0.570| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.057| v_loss: 0.018| per_loss: 0.292 | a_loss: 0.537
Train: Epoch [2742/3000], Step [120/158]| g_loss: 0.663| d_loss: 0.657| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.538
Train: Epoch [2742/3000], Step [150/158]| g_loss: 0.627| d_loss: 0.600| gp_loss: 0.058| r_loss: 0.045| p_loss: 0.056| v_loss: 0.018| per_loss: 0.293 | a_loss: 0.506
Train: Epoch [2743/3000], Step [30/158]| g_loss: 0.641| d_loss: 0.782| gp_loss: 0.214| r_loss: 0.045| p_loss: 0.060| v_loss: 0.018| per_loss: 0.292 | a_loss: 0.519
Train: Epoch [2743/3000], Step [60/158]| g_loss: 0.637| d_loss: 0.576| gp_loss: 0.054| r_loss: 0.045| p_loss: 0.058| v_loss: 0.018| per_loss: 0.277 | a_loss: 0.517
Train: Epoch [2743/3000], Step [90/158]| g_loss: 0.669| d_loss: 0.665| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.545
Train: Epoch [2743/3000], Step [120/158]| g_loss: 0.629| d_loss: 0.605| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.505
Train: Epoch [2743/3000], Step [150/158]| g_loss: 0.645| d_loss: 0.655| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.518
Train: Epoch [2744/3000], Step [30/158]| g_loss: 0.677| d_loss: 0.642| gp_loss: 0.148| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.284 | a_loss: 0.553
Train: Epoch [2744/3000], Step [60/158]| g_loss: 0.671| d_loss: 0.639| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.544
Train: Epoch [2744/3000], Step [90/158]| g_loss: 0.667| d_loss: 0.557| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.541
Train: Epoch [2744/3000], Step [120/158]| g_loss: 0.695| d_loss: 0.626| gp_loss: 0.052| r_loss: 0.045| p_loss: 0.058| v_loss: 0.018| per_loss: 0.280 | a_loss: 0.575
Train: Epoch [2744/3000], Step [150/158]| g_loss: 0.601| d_loss: 0.709| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.267 | a_loss: 0.477
Train: Epoch [2745/3000], Step [30/158]| g_loss: 0.637| d_loss: 0.733| gp_loss: 0.142| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.507
Train: Epoch [2745/3000], Step [60/158]| g_loss: 0.652| d_loss: 0.559| gp_loss: 0.052| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.524
Train: Epoch [2745/3000], Step [90/158]| g_loss: 0.632| d_loss: 0.697| gp_loss: 0.052| r_loss: 0.046| p_loss: 0.060| v_loss: 0.018| per_loss: 0.289 | a_loss: 0.508
Train: Epoch [2745/3000], Step [120/158]| g_loss: 0.646| d_loss: 0.579| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.059| v_loss: 0.020| per_loss: 0.276 | a_loss: 0.523
Train: Epoch [2745/3000], Step [150/158]| g_loss: 0.636| d_loss: 0.614| gp_loss: 0.058| r_loss: 0.045| p_loss: 0.058| v_loss: 0.018| per_loss: 0.266 | a_loss: 0.517
Train: Epoch [2746/3000], Step [30/158]| g_loss: 0.619| d_loss: 0.706| gp_loss: 0.092| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.280 | a_loss: 0.493
Train: Epoch [2746/3000], Step [60/158]| g_loss: 0.711| d_loss: 0.476| gp_loss: 0.056| r_loss: 0.044| p_loss: 0.057| v_loss: 0.019| per_loss: 0.287 | a_loss: 0.592
Train: Epoch [2746/3000], Step [90/158]| g_loss: 0.667| d_loss: 0.647| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.539
Train: Epoch [2746/3000], Step [120/158]| g_loss: 0.636| d_loss: 0.721| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.067| v_loss: 0.020| per_loss: 0.294 | a_loss: 0.506
Train: Epoch [2746/3000], Step [150/158]| g_loss: 0.635| d_loss: 0.603| gp_loss: 0.064| r_loss: 0.046| p_loss: 0.061| v_loss: 0.018| per_loss: 0.285 | a_loss: 0.512
Train: Epoch [2747/3000], Step [30/158]| g_loss: 0.666| d_loss: 0.688| gp_loss: 0.178| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.542
Train: Epoch [2747/3000], Step [60/158]| g_loss: 0.639| d_loss: 0.661| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.512
Train: Epoch [2747/3000], Step [90/158]| g_loss: 0.649| d_loss: 0.630| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.525
Train: Epoch [2747/3000], Step [120/158]| g_loss: 0.670| d_loss: 0.612| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.274 | a_loss: 0.544
Train: Epoch [2747/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.585| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.531
Train: Epoch [2748/3000], Step [30/158]| g_loss: 0.653| d_loss: 0.707| gp_loss: 0.120| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.525
Train: Epoch [2748/3000], Step [60/158]| g_loss: 0.590| d_loss: 0.661| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.273 | a_loss: 0.466
Train: Epoch [2748/3000], Step [90/158]| g_loss: 0.677| d_loss: 0.619| gp_loss: 0.060| r_loss: 0.053| p_loss: 0.068| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.541
Train: Epoch [2748/3000], Step [120/158]| g_loss: 0.654| d_loss: 0.647| gp_loss: 0.058| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.520
Train: Epoch [2748/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.562| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.064| v_loss: 0.020| per_loss: 0.300 | a_loss: 0.547
Train: Epoch [2749/3000], Step [30/158]| g_loss: 0.674| d_loss: 0.648| gp_loss: 0.148| r_loss: 0.048| p_loss: 0.059| v_loss: 0.018| per_loss: 0.287 | a_loss: 0.550
Train: Epoch [2749/3000], Step [60/158]| g_loss: 0.631| d_loss: 0.695| gp_loss: 0.052| r_loss: 0.046| p_loss: 0.063| v_loss: 0.019| per_loss: 0.278 | a_loss: 0.507
Train: Epoch [2749/3000], Step [90/158]| g_loss: 0.650| d_loss: 0.610| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.063| v_loss: 0.020| per_loss: 0.299 | a_loss: 0.521
Train: Epoch [2749/3000], Step [120/158]| g_loss: 0.670| d_loss: 0.618| gp_loss: 0.059| r_loss: 0.046| p_loss: 0.061| v_loss: 0.018| per_loss: 0.293 | a_loss: 0.545
Train: Epoch [2749/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.682| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.533
Train: Epoch [2750/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.710| gp_loss: 0.159| r_loss: 0.049| p_loss: 0.076| v_loss: 0.019| per_loss: 0.319 | a_loss: 0.525
Train: Epoch [2750/3000], Step [60/158]| g_loss: 0.644| d_loss: 0.650| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.072| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.510
Train: Epoch [2750/3000], Step [90/158]| g_loss: 0.661| d_loss: 0.562| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.532
Train: Epoch [2750/3000], Step [120/158]| g_loss: 0.650| d_loss: 0.644| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.522
Train: Epoch [2750/3000], Step [150/158]| g_loss: 0.610| d_loss: 0.636| gp_loss: 0.056| r_loss: 0.045| p_loss: 0.059| v_loss: 0.018| per_loss: 0.288 | a_loss: 0.489
Test: Epoch [2750/3000]| g_loss: 0.646| r_loss: 0.387| p_loss: 0.330| v_loss: 0.021
Train: Epoch [2751/3000], Step [30/158]| g_loss: 0.653| d_loss: 0.667| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.528
Train: Epoch [2751/3000], Step [60/158]| g_loss: 0.631| d_loss: 0.584| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.506
Train: Epoch [2751/3000], Step [90/158]| g_loss: 0.648| d_loss: 0.643| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.059| v_loss: 0.018| per_loss: 0.287 | a_loss: 0.523
Train: Epoch [2751/3000], Step [120/158]| g_loss: 0.663| d_loss: 0.647| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.063| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.533
Train: Epoch [2751/3000], Step [150/158]| g_loss: 0.650| d_loss: 0.557| gp_loss: 0.062| r_loss: 0.043| p_loss: 0.056| v_loss: 0.018| per_loss: 0.280 | a_loss: 0.533
Train: Epoch [2752/3000], Step [30/158]| g_loss: 0.677| d_loss: 0.642| gp_loss: 0.174| r_loss: 0.046| p_loss: 0.056| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.555
Train: Epoch [2752/3000], Step [60/158]| g_loss: 0.652| d_loss: 0.693| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.524
Train: Epoch [2752/3000], Step [90/158]| g_loss: 0.609| d_loss: 0.658| gp_loss: 0.054| r_loss: 0.044| p_loss: 0.059| v_loss: 0.018| per_loss: 0.288 | a_loss: 0.489
Train: Epoch [2752/3000], Step [120/158]| g_loss: 0.708| d_loss: 0.562| gp_loss: 0.059| r_loss: 0.045| p_loss: 0.059| v_loss: 0.018| per_loss: 0.290 | a_loss: 0.586
Train: Epoch [2752/3000], Step [150/158]| g_loss: 0.648| d_loss: 0.654| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.061| v_loss: 0.018| per_loss: 0.301 | a_loss: 0.522
Train: Epoch [2753/3000], Step [30/158]| g_loss: 0.610| d_loss: 0.686| gp_loss: 0.102| r_loss: 0.044| p_loss: 0.059| v_loss: 0.018| per_loss: 0.278 | a_loss: 0.491
Train: Epoch [2753/3000], Step [60/158]| g_loss: 0.647| d_loss: 0.574| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.520
Train: Epoch [2753/3000], Step [90/158]| g_loss: 0.707| d_loss: 0.625| gp_loss: 0.061| r_loss: 0.047| p_loss: 0.061| v_loss: 0.020| per_loss: 0.307 | a_loss: 0.579
Train: Epoch [2753/3000], Step [120/158]| g_loss: 0.637| d_loss: 0.659| gp_loss: 0.062| r_loss: 0.045| p_loss: 0.060| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.514
Train: Epoch [2753/3000], Step [150/158]| g_loss: 0.614| d_loss: 0.633| gp_loss: 0.062| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.488
Train: Epoch [2754/3000], Step [30/158]| g_loss: 0.671| d_loss: 0.679| gp_loss: 0.163| r_loss: 0.047| p_loss: 0.060| v_loss: 0.018| per_loss: 0.282 | a_loss: 0.547
Train: Epoch [2754/3000], Step [60/158]| g_loss: 0.671| d_loss: 0.584| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.544
Train: Epoch [2754/3000], Step [90/158]| g_loss: 0.598| d_loss: 0.711| gp_loss: 0.052| r_loss: 0.046| p_loss: 0.059| v_loss: 0.018| per_loss: 0.285 | a_loss: 0.476
Train: Epoch [2754/3000], Step [120/158]| g_loss: 0.622| d_loss: 0.641| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.058| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.498
Train: Epoch [2754/3000], Step [150/158]| g_loss: 0.663| d_loss: 0.507| gp_loss: 0.061| r_loss: 0.046| p_loss: 0.057| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.542
Train: Epoch [2755/3000], Step [30/158]| g_loss: 0.647| d_loss: 0.784| gp_loss: 0.138| r_loss: 0.048| p_loss: 0.061| v_loss: 0.018| per_loss: 0.280 | a_loss: 0.522
Train: Epoch [2755/3000], Step [60/158]| g_loss: 0.642| d_loss: 0.583| gp_loss: 0.058| r_loss: 0.045| p_loss: 0.060| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.518
Train: Epoch [2755/3000], Step [90/158]| g_loss: 0.643| d_loss: 0.648| gp_loss: 0.060| r_loss: 0.044| p_loss: 0.057| v_loss: 0.018| per_loss: 0.298 | a_loss: 0.522
Train: Epoch [2755/3000], Step [120/158]| g_loss: 0.664| d_loss: 0.578| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.277 | a_loss: 0.540
Train: Epoch [2755/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.561| gp_loss: 0.062| r_loss: 0.047| p_loss: 0.062| v_loss: 0.018| per_loss: 0.290 | a_loss: 0.537
Train: Epoch [2756/3000], Step [30/158]| g_loss: 0.688| d_loss: 0.682| gp_loss: 0.137| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.287 | a_loss: 0.560
Train: Epoch [2756/3000], Step [60/158]| g_loss: 0.643| d_loss: 0.620| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.519
Train: Epoch [2756/3000], Step [90/158]| g_loss: 0.630| d_loss: 0.718| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.506
Train: Epoch [2756/3000], Step [120/158]| g_loss: 0.657| d_loss: 0.661| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.527
Train: Epoch [2756/3000], Step [150/158]| g_loss: 0.644| d_loss: 0.598| gp_loss: 0.061| r_loss: 0.045| p_loss: 0.059| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.520
Train: Epoch [2757/3000], Step [30/158]| g_loss: 0.680| d_loss: 0.627| gp_loss: 0.130| r_loss: 0.045| p_loss: 0.060| v_loss: 0.018| per_loss: 0.296 | a_loss: 0.557
Train: Epoch [2757/3000], Step [60/158]| g_loss: 0.640| d_loss: 0.670| gp_loss: 0.054| r_loss: 0.045| p_loss: 0.058| v_loss: 0.018| per_loss: 0.287 | a_loss: 0.519
Train: Epoch [2757/3000], Step [90/158]| g_loss: 0.631| d_loss: 0.585| gp_loss: 0.057| r_loss: 0.045| p_loss: 0.057| v_loss: 0.018| per_loss: 0.291 | a_loss: 0.510
Train: Epoch [2757/3000], Step [120/158]| g_loss: 0.705| d_loss: 0.545| gp_loss: 0.060| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.581
Train: Epoch [2757/3000], Step [150/158]| g_loss: 0.648| d_loss: 0.669| gp_loss: 0.059| r_loss: 0.046| p_loss: 0.059| v_loss: 0.018| per_loss: 0.269 | a_loss: 0.527
Train: Epoch [2758/3000], Step [30/158]| g_loss: 0.593| d_loss: 0.761| gp_loss: 0.125| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.288 | a_loss: 0.468
Train: Epoch [2758/3000], Step [60/158]| g_loss: 0.653| d_loss: 0.545| gp_loss: 0.061| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.282 | a_loss: 0.530
Train: Epoch [2758/3000], Step [90/158]| g_loss: 0.679| d_loss: 0.584| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.058| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.556
Train: Epoch [2758/3000], Step [120/158]| g_loss: 0.638| d_loss: 0.626| gp_loss: 0.061| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.286 | a_loss: 0.514
Train: Epoch [2758/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.628| gp_loss: 0.062| r_loss: 0.046| p_loss: 0.057| v_loss: 0.018| per_loss: 0.284 | a_loss: 0.543
Train: Epoch [2759/3000], Step [30/158]| g_loss: 0.594| d_loss: 0.835| gp_loss: 0.185| r_loss: 0.045| p_loss: 0.061| v_loss: 0.018| per_loss: 0.285 | a_loss: 0.471
Train: Epoch [2759/3000], Step [60/158]| g_loss: 0.612| d_loss: 0.630| gp_loss: 0.055| r_loss: 0.045| p_loss: 0.058| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.490
Train: Epoch [2759/3000], Step [90/158]| g_loss: 0.683| d_loss: 0.555| gp_loss: 0.057| r_loss: 0.045| p_loss: 0.059| v_loss: 0.019| per_loss: 0.279 | a_loss: 0.562
Train: Epoch [2759/3000], Step [120/158]| g_loss: 0.651| d_loss: 0.608| gp_loss: 0.057| r_loss: 0.044| p_loss: 0.057| v_loss: 0.018| per_loss: 0.302 | a_loss: 0.530
Train: Epoch [2759/3000], Step [150/158]| g_loss: 0.641| d_loss: 0.623| gp_loss: 0.063| r_loss: 0.046| p_loss: 0.060| v_loss: 0.018| per_loss: 0.287 | a_loss: 0.518
Train: Epoch [2760/3000], Step [30/158]| g_loss: 0.701| d_loss: 0.598| gp_loss: 0.159| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.575
Train: Epoch [2760/3000], Step [60/158]| g_loss: 0.687| d_loss: 0.601| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.562
Train: Epoch [2760/3000], Step [90/158]| g_loss: 0.613| d_loss: 0.692| gp_loss: 0.054| r_loss: 0.045| p_loss: 0.060| v_loss: 0.018| per_loss: 0.291 | a_loss: 0.490
Train: Epoch [2760/3000], Step [120/158]| g_loss: 0.658| d_loss: 0.621| gp_loss: 0.057| r_loss: 0.046| p_loss: 0.056| v_loss: 0.018| per_loss: 0.278 | a_loss: 0.538
Train: Epoch [2760/3000], Step [150/158]| g_loss: 0.614| d_loss: 0.670| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.060| v_loss: 0.018| per_loss: 0.283 | a_loss: 0.492
Train: Epoch [2761/3000], Step [30/158]| g_loss: 0.597| d_loss: 0.729| gp_loss: 0.133| r_loss: 0.047| p_loss: 0.060| v_loss: 0.018| per_loss: 0.264 | a_loss: 0.475
Train: Epoch [2761/3000], Step [60/158]| g_loss: 0.618| d_loss: 0.666| gp_loss: 0.061| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.283 | a_loss: 0.492
Train: Epoch [2761/3000], Step [90/158]| g_loss: 0.661| d_loss: 0.563| gp_loss: 0.063| r_loss: 0.056| p_loss: 0.071| v_loss: 0.019| per_loss: 0.289 | a_loss: 0.521
Train: Epoch [2761/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.684| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.070| v_loss: 0.018| per_loss: 0.292 | a_loss: 0.533
Train: Epoch [2761/3000], Step [150/158]| g_loss: 0.682| d_loss: 0.607| gp_loss: 0.066| r_loss: 0.047| p_loss: 0.068| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.551
Train: Epoch [2762/3000], Step [30/158]| g_loss: 0.639| d_loss: 0.771| gp_loss: 0.214| r_loss: 0.045| p_loss: 0.061| v_loss: 0.018| per_loss: 0.292 | a_loss: 0.517
Train: Epoch [2762/3000], Step [60/158]| g_loss: 0.632| d_loss: 0.632| gp_loss: 0.052| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.507
Train: Epoch [2762/3000], Step [90/158]| g_loss: 0.651| d_loss: 0.566| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.058| v_loss: 0.018| per_loss: 0.270 | a_loss: 0.530
Train: Epoch [2762/3000], Step [120/158]| g_loss: 0.649| d_loss: 0.631| gp_loss: 0.057| r_loss: 0.044| p_loss: 0.058| v_loss: 0.018| per_loss: 0.286 | a_loss: 0.530
Train: Epoch [2762/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.583| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.532
Train: Epoch [2763/3000], Step [30/158]| g_loss: 0.655| d_loss: 0.713| gp_loss: 0.091| r_loss: 0.045| p_loss: 0.060| v_loss: 0.018| per_loss: 0.292 | a_loss: 0.533
Train: Epoch [2763/3000], Step [60/158]| g_loss: 0.679| d_loss: 0.609| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.281 | a_loss: 0.555
Train: Epoch [2763/3000], Step [90/158]| g_loss: 0.612| d_loss: 0.709| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.064| v_loss: 0.018| per_loss: 0.294 | a_loss: 0.486
Train: Epoch [2763/3000], Step [120/158]| g_loss: 0.635| d_loss: 0.607| gp_loss: 0.062| r_loss: 0.045| p_loss: 0.059| v_loss: 0.018| per_loss: 0.279 | a_loss: 0.515
Train: Epoch [2763/3000], Step [150/158]| g_loss: 0.647| d_loss: 0.619| gp_loss: 0.063| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.522
Train: Epoch [2764/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.605| gp_loss: 0.149| r_loss: 0.045| p_loss: 0.058| v_loss: 0.019| per_loss: 0.276 | a_loss: 0.543
Train: Epoch [2764/3000], Step [60/158]| g_loss: 0.664| d_loss: 0.595| gp_loss: 0.057| r_loss: 0.043| p_loss: 0.057| v_loss: 0.018| per_loss: 0.296 | a_loss: 0.545
Train: Epoch [2764/3000], Step [90/158]| g_loss: 0.648| d_loss: 0.696| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.285 | a_loss: 0.523
Train: Epoch [2764/3000], Step [120/158]| g_loss: 0.656| d_loss: 0.616| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.528
Train: Epoch [2764/3000], Step [150/158]| g_loss: 0.634| d_loss: 0.645| gp_loss: 0.062| r_loss: 0.044| p_loss: 0.060| v_loss: 0.018| per_loss: 0.311 | a_loss: 0.511
Train: Epoch [2765/3000], Step [30/158]| g_loss: 0.631| d_loss: 0.702| gp_loss: 0.129| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.504
Train: Epoch [2765/3000], Step [60/158]| g_loss: 0.654| d_loss: 0.621| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.290 | a_loss: 0.528
Train: Epoch [2765/3000], Step [90/158]| g_loss: 0.650| d_loss: 0.619| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.522
Train: Epoch [2765/3000], Step [120/158]| g_loss: 0.665| d_loss: 0.578| gp_loss: 0.062| r_loss: 0.044| p_loss: 0.060| v_loss: 0.018| per_loss: 0.300 | a_loss: 0.544
Train: Epoch [2765/3000], Step [150/158]| g_loss: 0.692| d_loss: 0.596| gp_loss: 0.064| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.319 | a_loss: 0.561
Train: Epoch [2766/3000], Step [30/158]| g_loss: 0.602| d_loss: 0.851| gp_loss: 0.184| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.471
Train: Epoch [2766/3000], Step [60/158]| g_loss: 0.649| d_loss: 0.585| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.518
Train: Epoch [2766/3000], Step [90/158]| g_loss: 0.622| d_loss: 0.677| gp_loss: 0.063| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.489
Train: Epoch [2766/3000], Step [120/158]| g_loss: 0.625| d_loss: 0.692| gp_loss: 0.064| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.497
Train: Epoch [2766/3000], Step [150/158]| g_loss: 0.686| d_loss: 0.461| gp_loss: 0.065| r_loss: 0.045| p_loss: 0.062| v_loss: 0.018| per_loss: 0.300 | a_loss: 0.562
Train: Epoch [2767/3000], Step [30/158]| g_loss: 0.657| d_loss: 0.793| gp_loss: 0.162| r_loss: 0.047| p_loss: 0.065| v_loss: 0.018| per_loss: 0.313 | a_loss: 0.528
Train: Epoch [2767/3000], Step [60/158]| g_loss: 0.671| d_loss: 0.523| gp_loss: 0.058| r_loss: 0.045| p_loss: 0.061| v_loss: 0.019| per_loss: 0.322 | a_loss: 0.545
Train: Epoch [2767/3000], Step [90/158]| g_loss: 0.645| d_loss: 0.656| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.059| v_loss: 0.018| per_loss: 0.301 | a_loss: 0.521
Train: Epoch [2767/3000], Step [120/158]| g_loss: 0.648| d_loss: 0.596| gp_loss: 0.059| r_loss: 0.044| p_loss: 0.061| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.524
Train: Epoch [2767/3000], Step [150/158]| g_loss: 0.678| d_loss: 0.619| gp_loss: 0.065| r_loss: 0.048| p_loss: 0.059| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.550
Train: Epoch [2768/3000], Step [30/158]| g_loss: 0.623| d_loss: 0.806| gp_loss: 0.155| r_loss: 0.047| p_loss: 0.064| v_loss: 0.018| per_loss: 0.314 | a_loss: 0.494
Train: Epoch [2768/3000], Step [60/158]| g_loss: 0.661| d_loss: 0.547| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.299 | a_loss: 0.535
Train: Epoch [2768/3000], Step [90/158]| g_loss: 0.676| d_loss: 0.641| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.546
Train: Epoch [2768/3000], Step [120/158]| g_loss: 0.618| d_loss: 0.630| gp_loss: 0.062| r_loss: 0.046| p_loss: 0.063| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.490
Train: Epoch [2768/3000], Step [150/158]| g_loss: 0.680| d_loss: 0.575| gp_loss: 0.065| r_loss: 0.048| p_loss: 0.062| v_loss: 0.018| per_loss: 0.312 | a_loss: 0.552
Train: Epoch [2769/3000], Step [30/158]| g_loss: 0.649| d_loss: 0.739| gp_loss: 0.202| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.522
Train: Epoch [2769/3000], Step [60/158]| g_loss: 0.634| d_loss: 0.712| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.507
Train: Epoch [2769/3000], Step [90/158]| g_loss: 0.672| d_loss: 0.613| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.328 | a_loss: 0.543
Train: Epoch [2769/3000], Step [120/158]| g_loss: 0.633| d_loss: 0.551| gp_loss: 0.057| r_loss: 0.044| p_loss: 0.059| v_loss: 0.018| per_loss: 0.298 | a_loss: 0.511
Train: Epoch [2769/3000], Step [150/158]| g_loss: 0.721| d_loss: 0.600| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.327 | a_loss: 0.590
Train: Epoch [2770/3000], Step [30/158]| g_loss: 0.644| d_loss: 0.721| gp_loss: 0.161| r_loss: 0.048| p_loss: 0.062| v_loss: 0.018| per_loss: 0.311 | a_loss: 0.516
Train: Epoch [2770/3000], Step [60/158]| g_loss: 0.649| d_loss: 0.578| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.326 | a_loss: 0.518
Train: Epoch [2770/3000], Step [90/158]| g_loss: 0.645| d_loss: 0.645| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.062| v_loss: 0.018| per_loss: 0.312 | a_loss: 0.518
Train: Epoch [2770/3000], Step [120/158]| g_loss: 0.668| d_loss: 0.550| gp_loss: 0.057| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.327 | a_loss: 0.540
Train: Epoch [2770/3000], Step [150/158]| g_loss: 0.635| d_loss: 0.666| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.062| v_loss: 0.018| per_loss: 0.301 | a_loss: 0.510
Train: Epoch [2771/3000], Step [30/158]| g_loss: 0.642| d_loss: 0.738| gp_loss: 0.189| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.326 | a_loss: 0.512
Train: Epoch [2771/3000], Step [60/158]| g_loss: 0.639| d_loss: 0.717| gp_loss: 0.050| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.319 | a_loss: 0.509
Train: Epoch [2771/3000], Step [90/158]| g_loss: 0.651| d_loss: 0.564| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.315 | a_loss: 0.522
Train: Epoch [2771/3000], Step [120/158]| g_loss: 0.692| d_loss: 0.665| gp_loss: 0.060| r_loss: 0.050| p_loss: 0.068| v_loss: 0.020| per_loss: 0.328 | a_loss: 0.555
Train: Epoch [2771/3000], Step [150/158]| g_loss: 0.637| d_loss: 0.591| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.065| v_loss: 0.018| per_loss: 0.315 | a_loss: 0.507
Train: Epoch [2772/3000], Step [30/158]| g_loss: 0.676| d_loss: 0.675| gp_loss: 0.146| r_loss: 0.047| p_loss: 0.063| v_loss: 0.018| per_loss: 0.303 | a_loss: 0.549
Train: Epoch [2772/3000], Step [60/158]| g_loss: 0.605| d_loss: 0.675| gp_loss: 0.052| r_loss: 0.045| p_loss: 0.058| v_loss: 0.018| per_loss: 0.301 | a_loss: 0.483
Train: Epoch [2772/3000], Step [90/158]| g_loss: 0.642| d_loss: 0.541| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.514
Train: Epoch [2772/3000], Step [120/158]| g_loss: 0.689| d_loss: 0.548| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.059| v_loss: 0.018| per_loss: 0.333 | a_loss: 0.562
Train: Epoch [2772/3000], Step [150/158]| g_loss: 0.693| d_loss: 0.734| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.061| v_loss: 0.018| per_loss: 0.326 | a_loss: 0.566
Train: Epoch [2773/3000], Step [30/158]| g_loss: 0.620| d_loss: 0.731| gp_loss: 0.072| r_loss: 0.052| p_loss: 0.072| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.480
Train: Epoch [2773/3000], Step [60/158]| g_loss: 0.600| d_loss: 0.614| gp_loss: 0.062| r_loss: 0.049| p_loss: 0.070| v_loss: 0.019| per_loss: 0.331 | a_loss: 0.464
Train: Epoch [2773/3000], Step [90/158]| g_loss: 0.648| d_loss: 0.592| gp_loss: 0.062| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.318 | a_loss: 0.516
Train: Epoch [2773/3000], Step [120/158]| g_loss: 0.670| d_loss: 0.657| gp_loss: 0.062| r_loss: 0.049| p_loss: 0.068| v_loss: 0.019| per_loss: 0.331 | a_loss: 0.535
Train: Epoch [2773/3000], Step [150/158]| g_loss: 0.668| d_loss: 0.537| gp_loss: 0.062| r_loss: 0.052| p_loss: 0.067| v_loss: 0.018| per_loss: 0.310 | a_loss: 0.533
Train: Epoch [2774/3000], Step [30/158]| g_loss: 0.637| d_loss: 0.746| gp_loss: 0.147| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.504
Train: Epoch [2774/3000], Step [60/158]| g_loss: 0.648| d_loss: 0.545| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.062| v_loss: 0.018| per_loss: 0.313 | a_loss: 0.521
Train: Epoch [2774/3000], Step [90/158]| g_loss: 0.694| d_loss: 0.634| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.069| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.558
Train: Epoch [2774/3000], Step [120/158]| g_loss: 0.653| d_loss: 0.657| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.065| v_loss: 0.018| per_loss: 0.325 | a_loss: 0.521
Train: Epoch [2774/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.591| gp_loss: 0.067| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.319 | a_loss: 0.531
Train: Epoch [2775/3000], Step [30/158]| g_loss: 0.622| d_loss: 0.701| gp_loss: 0.110| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.494
Train: Epoch [2775/3000], Step [60/158]| g_loss: 0.654| d_loss: 0.645| gp_loss: 0.062| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.520
Train: Epoch [2775/3000], Step [90/158]| g_loss: 0.665| d_loss: 0.630| gp_loss: 0.067| r_loss: 0.052| p_loss: 0.066| v_loss: 0.019| per_loss: 0.325 | a_loss: 0.528
Train: Epoch [2775/3000], Step [120/158]| g_loss: 0.631| d_loss: 0.735| gp_loss: 0.063| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.336 | a_loss: 0.497
Train: Epoch [2775/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.526| gp_loss: 0.064| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.323 | a_loss: 0.527
Train: Epoch [2776/3000], Step [30/158]| g_loss: 0.694| d_loss: 0.681| gp_loss: 0.181| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.562
Train: Epoch [2776/3000], Step [60/158]| g_loss: 0.638| d_loss: 0.674| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.326 | a_loss: 0.507
Train: Epoch [2776/3000], Step [90/158]| g_loss: 0.662| d_loss: 0.604| gp_loss: 0.061| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.328 | a_loss: 0.530
Train: Epoch [2776/3000], Step [120/158]| g_loss: 0.653| d_loss: 0.631| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.528
Train: Epoch [2776/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.613| gp_loss: 0.062| r_loss: 0.047| p_loss: 0.063| v_loss: 0.018| per_loss: 0.315 | a_loss: 0.535
Train: Epoch [2777/3000], Step [30/158]| g_loss: 0.654| d_loss: 0.735| gp_loss: 0.118| r_loss: 0.049| p_loss: 0.067| v_loss: 0.019| per_loss: 0.322 | a_loss: 0.521
Train: Epoch [2777/3000], Step [60/158]| g_loss: 0.654| d_loss: 0.562| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.525
Train: Epoch [2777/3000], Step [90/158]| g_loss: 0.669| d_loss: 0.630| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.539
Train: Epoch [2777/3000], Step [120/158]| g_loss: 0.641| d_loss: 0.629| gp_loss: 0.062| r_loss: 0.045| p_loss: 0.060| v_loss: 0.018| per_loss: 0.301 | a_loss: 0.518
Train: Epoch [2777/3000], Step [150/158]| g_loss: 0.645| d_loss: 0.585| gp_loss: 0.060| r_loss: 0.046| p_loss: 0.063| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.516
Train: Epoch [2778/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.848| gp_loss: 0.279| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.526
Train: Epoch [2778/3000], Step [60/158]| g_loss: 0.640| d_loss: 0.692| gp_loss: 0.050| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.334 | a_loss: 0.512
Train: Epoch [2778/3000], Step [90/158]| g_loss: 0.597| d_loss: 0.677| gp_loss: 0.052| r_loss: 0.045| p_loss: 0.059| v_loss: 0.018| per_loss: 0.291 | a_loss: 0.476
Train: Epoch [2778/3000], Step [120/158]| g_loss: 0.626| d_loss: 0.599| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.059| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.499
Train: Epoch [2778/3000], Step [150/158]| g_loss: 0.668| d_loss: 0.533| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.541
Train: Epoch [2779/3000], Step [30/158]| g_loss: 0.677| d_loss: 0.707| gp_loss: 0.169| r_loss: 0.045| p_loss: 0.057| v_loss: 0.018| per_loss: 0.314 | a_loss: 0.554
Train: Epoch [2779/3000], Step [60/158]| g_loss: 0.655| d_loss: 0.606| gp_loss: 0.049| r_loss: 0.044| p_loss: 0.057| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.534
Train: Epoch [2779/3000], Step [90/158]| g_loss: 0.680| d_loss: 0.596| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.060| v_loss: 0.018| per_loss: 0.297 | a_loss: 0.556
Train: Epoch [2779/3000], Step [120/158]| g_loss: 0.651| d_loss: 0.651| gp_loss: 0.051| r_loss: 0.044| p_loss: 0.058| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.528
Train: Epoch [2779/3000], Step [150/158]| g_loss: 0.628| d_loss: 0.612| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.058| v_loss: 0.019| per_loss: 0.315 | a_loss: 0.501
Train: Epoch [2780/3000], Step [30/158]| g_loss: 0.658| d_loss: 0.698| gp_loss: 0.148| r_loss: 0.049| p_loss: 0.060| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.529
Train: Epoch [2780/3000], Step [60/158]| g_loss: 0.656| d_loss: 0.616| gp_loss: 0.052| r_loss: 0.045| p_loss: 0.059| v_loss: 0.018| per_loss: 0.301 | a_loss: 0.533
Train: Epoch [2780/3000], Step [90/158]| g_loss: 0.634| d_loss: 0.650| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.059| v_loss: 0.018| per_loss: 0.305 | a_loss: 0.509
Train: Epoch [2780/3000], Step [120/158]| g_loss: 0.641| d_loss: 0.642| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.061| v_loss: 0.018| per_loss: 0.303 | a_loss: 0.516
Train: Epoch [2780/3000], Step [150/158]| g_loss: 0.630| d_loss: 0.608| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.504
Train: Epoch [2781/3000], Step [30/158]| g_loss: 0.701| d_loss: 0.673| gp_loss: 0.201| r_loss: 0.045| p_loss: 0.058| v_loss: 0.018| per_loss: 0.306 | a_loss: 0.578
Train: Epoch [2781/3000], Step [60/158]| g_loss: 0.683| d_loss: 0.537| gp_loss: 0.050| r_loss: 0.045| p_loss: 0.057| v_loss: 0.018| per_loss: 0.304 | a_loss: 0.560
Train: Epoch [2781/3000], Step [90/158]| g_loss: 0.634| d_loss: 0.702| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.059| v_loss: 0.018| per_loss: 0.316 | a_loss: 0.507
Train: Epoch [2781/3000], Step [120/158]| g_loss: 0.672| d_loss: 0.599| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.545
Train: Epoch [2781/3000], Step [150/158]| g_loss: 0.642| d_loss: 0.689| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.511
Train: Epoch [2782/3000], Step [30/158]| g_loss: 0.618| d_loss: 0.679| gp_loss: 0.130| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.493
Train: Epoch [2782/3000], Step [60/158]| g_loss: 0.645| d_loss: 0.603| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.518
Train: Epoch [2782/3000], Step [90/158]| g_loss: 0.655| d_loss: 0.671| gp_loss: 0.057| r_loss: 0.046| p_loss: 0.064| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.526
Train: Epoch [2782/3000], Step [120/158]| g_loss: 0.647| d_loss: 0.601| gp_loss: 0.058| r_loss: 0.045| p_loss: 0.059| v_loss: 0.018| per_loss: 0.299 | a_loss: 0.523
Train: Epoch [2782/3000], Step [150/158]| g_loss: 0.674| d_loss: 0.599| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.061| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.544
Train: Epoch [2783/3000], Step [30/158]| g_loss: 0.653| d_loss: 0.636| gp_loss: 0.099| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.528
Train: Epoch [2783/3000], Step [60/158]| g_loss: 0.637| d_loss: 0.658| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.295 | a_loss: 0.510
Train: Epoch [2783/3000], Step [90/158]| g_loss: 0.616| d_loss: 0.619| gp_loss: 0.063| r_loss: 0.047| p_loss: 0.060| v_loss: 0.018| per_loss: 0.291 | a_loss: 0.492
Train: Epoch [2783/3000], Step [120/158]| g_loss: 0.705| d_loss: 0.505| gp_loss: 0.066| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.576
Train: Epoch [2783/3000], Step [150/158]| g_loss: 0.663| d_loss: 0.738| gp_loss: 0.063| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.531
Train: Epoch [2784/3000], Step [30/158]| g_loss: 0.617| d_loss: 0.864| gp_loss: 0.254| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.486
Train: Epoch [2784/3000], Step [60/158]| g_loss: 0.620| d_loss: 0.679| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.072| v_loss: 0.019| per_loss: 0.318 | a_loss: 0.482
Train: Epoch [2784/3000], Step [90/158]| g_loss: 0.642| d_loss: 0.581| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.066| v_loss: 0.018| per_loss: 0.326 | a_loss: 0.511
Train: Epoch [2784/3000], Step [120/158]| g_loss: 0.665| d_loss: 0.565| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.539
Train: Epoch [2784/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.601| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.303 | a_loss: 0.527
Train: Epoch [2785/3000], Step [30/158]| g_loss: 0.621| d_loss: 0.741| gp_loss: 0.171| r_loss: 0.048| p_loss: 0.062| v_loss: 0.018| per_loss: 0.296 | a_loss: 0.495
Train: Epoch [2785/3000], Step [60/158]| g_loss: 0.675| d_loss: 0.638| gp_loss: 0.057| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.550
Train: Epoch [2785/3000], Step [90/158]| g_loss: 0.598| d_loss: 0.702| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.062| v_loss: 0.018| per_loss: 0.284 | a_loss: 0.473
Train: Epoch [2785/3000], Step [120/158]| g_loss: 0.598| d_loss: 0.604| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.059| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.471
Train: Epoch [2785/3000], Step [150/158]| g_loss: 0.691| d_loss: 0.500| gp_loss: 0.063| r_loss: 0.046| p_loss: 0.060| v_loss: 0.018| per_loss: 0.296 | a_loss: 0.569
Train: Epoch [2786/3000], Step [30/158]| g_loss: 0.688| d_loss: 0.761| gp_loss: 0.185| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.559
Train: Epoch [2786/3000], Step [60/158]| g_loss: 0.628| d_loss: 0.611| gp_loss: 0.051| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.500
Train: Epoch [2786/3000], Step [90/158]| g_loss: 0.681| d_loss: 0.560| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.060| v_loss: 0.018| per_loss: 0.302 | a_loss: 0.554
Train: Epoch [2786/3000], Step [120/158]| g_loss: 0.653| d_loss: 0.674| gp_loss: 0.055| r_loss: 0.045| p_loss: 0.059| v_loss: 0.018| per_loss: 0.298 | a_loss: 0.530
Train: Epoch [2786/3000], Step [150/158]| g_loss: 0.620| d_loss: 0.605| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.060| v_loss: 0.018| per_loss: 0.287 | a_loss: 0.496
Train: Epoch [2787/3000], Step [30/158]| g_loss: 0.661| d_loss: 0.697| gp_loss: 0.146| r_loss: 0.048| p_loss: 0.060| v_loss: 0.018| per_loss: 0.288 | a_loss: 0.536
Train: Epoch [2787/3000], Step [60/158]| g_loss: 0.681| d_loss: 0.546| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.060| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.553
Train: Epoch [2787/3000], Step [90/158]| g_loss: 0.658| d_loss: 0.615| gp_loss: 0.053| r_loss: 0.044| p_loss: 0.057| v_loss: 0.018| per_loss: 0.320 | a_loss: 0.535
Train: Epoch [2787/3000], Step [120/158]| g_loss: 0.626| d_loss: 0.702| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.296 | a_loss: 0.501
Train: Epoch [2787/3000], Step [150/158]| g_loss: 0.630| d_loss: 0.579| gp_loss: 0.058| r_loss: 0.044| p_loss: 0.057| v_loss: 0.018| per_loss: 0.302 | a_loss: 0.509
Train: Epoch [2788/3000], Step [30/158]| g_loss: 0.648| d_loss: 0.730| gp_loss: 0.165| r_loss: 0.046| p_loss: 0.059| v_loss: 0.018| per_loss: 0.300 | a_loss: 0.524
Train: Epoch [2788/3000], Step [60/158]| g_loss: 0.620| d_loss: 0.620| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.493
Train: Epoch [2788/3000], Step [90/158]| g_loss: 0.676| d_loss: 0.614| gp_loss: 0.055| r_loss: 0.043| p_loss: 0.057| v_loss: 0.018| per_loss: 0.312 | a_loss: 0.555
Train: Epoch [2788/3000], Step [120/158]| g_loss: 0.650| d_loss: 0.551| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.523
Train: Epoch [2788/3000], Step [150/158]| g_loss: 0.671| d_loss: 0.682| gp_loss: 0.058| r_loss: 0.045| p_loss: 0.061| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.548
Train: Epoch [2789/3000], Step [30/158]| g_loss: 0.629| d_loss: 0.779| gp_loss: 0.157| r_loss: 0.046| p_loss: 0.064| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.501
Train: Epoch [2789/3000], Step [60/158]| g_loss: 0.611| d_loss: 0.630| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.066| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.480
Train: Epoch [2789/3000], Step [90/158]| g_loss: 0.668| d_loss: 0.554| gp_loss: 0.060| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.315 | a_loss: 0.542
Train: Epoch [2789/3000], Step [120/158]| g_loss: 0.660| d_loss: 0.598| gp_loss: 0.057| r_loss: 0.045| p_loss: 0.059| v_loss: 0.018| per_loss: 0.304 | a_loss: 0.537
Train: Epoch [2789/3000], Step [150/158]| g_loss: 0.686| d_loss: 0.602| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.557
Train: Epoch [2790/3000], Step [30/158]| g_loss: 0.611| d_loss: 0.826| gp_loss: 0.213| r_loss: 0.047| p_loss: 0.061| v_loss: 0.018| per_loss: 0.317 | a_loss: 0.484
Train: Epoch [2790/3000], Step [60/158]| g_loss: 0.680| d_loss: 0.557| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.551
Train: Epoch [2790/3000], Step [90/158]| g_loss: 0.661| d_loss: 0.630| gp_loss: 0.050| r_loss: 0.049| p_loss: 0.064| v_loss: 0.018| per_loss: 0.303 | a_loss: 0.532
Train: Epoch [2790/3000], Step [120/158]| g_loss: 0.649| d_loss: 0.643| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.061| v_loss: 0.018| per_loss: 0.300 | a_loss: 0.524
Train: Epoch [2790/3000], Step [150/158]| g_loss: 0.656| d_loss: 0.557| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.060| v_loss: 0.018| per_loss: 0.303 | a_loss: 0.529
Train: Epoch [2791/3000], Step [30/158]| g_loss: 0.693| d_loss: 0.634| gp_loss: 0.181| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.563
Train: Epoch [2791/3000], Step [60/158]| g_loss: 0.668| d_loss: 0.663| gp_loss: 0.049| r_loss: 0.048| p_loss: 0.067| v_loss: 0.019| per_loss: 0.319 | a_loss: 0.536
Train: Epoch [2791/3000], Step [90/158]| g_loss: 0.679| d_loss: 0.560| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.063| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.546
Train: Epoch [2791/3000], Step [120/158]| g_loss: 0.646| d_loss: 0.651| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.061| v_loss: 0.018| per_loss: 0.300 | a_loss: 0.519
Train: Epoch [2791/3000], Step [150/158]| g_loss: 0.633| d_loss: 0.694| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.062| v_loss: 0.018| per_loss: 0.287 | a_loss: 0.509
Train: Epoch [2792/3000], Step [30/158]| g_loss: 0.638| d_loss: 0.662| gp_loss: 0.135| r_loss: 0.047| p_loss: 0.064| v_loss: 0.020| per_loss: 0.316 | a_loss: 0.509
Train: Epoch [2792/3000], Step [60/158]| g_loss: 0.665| d_loss: 0.618| gp_loss: 0.053| r_loss: 0.045| p_loss: 0.059| v_loss: 0.018| per_loss: 0.319 | a_loss: 0.540
Train: Epoch [2792/3000], Step [90/158]| g_loss: 0.652| d_loss: 0.683| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.521
Train: Epoch [2792/3000], Step [120/158]| g_loss: 0.644| d_loss: 0.625| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.059| v_loss: 0.018| per_loss: 0.283 | a_loss: 0.522
Train: Epoch [2792/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.630| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.532
Train: Epoch [2793/3000], Step [30/158]| g_loss: 0.678| d_loss: 0.598| gp_loss: 0.154| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.549
Train: Epoch [2793/3000], Step [60/158]| g_loss: 0.652| d_loss: 0.666| gp_loss: 0.052| r_loss: 0.046| p_loss: 0.060| v_loss: 0.018| per_loss: 0.307 | a_loss: 0.527
Train: Epoch [2793/3000], Step [90/158]| g_loss: 0.639| d_loss: 0.615| gp_loss: 0.055| r_loss: 0.045| p_loss: 0.059| v_loss: 0.018| per_loss: 0.291 | a_loss: 0.517
Train: Epoch [2793/3000], Step [120/158]| g_loss: 0.638| d_loss: 0.617| gp_loss: 0.061| r_loss: 0.046| p_loss: 0.059| v_loss: 0.018| per_loss: 0.287 | a_loss: 0.516
Train: Epoch [2793/3000], Step [150/158]| g_loss: 0.653| d_loss: 0.658| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.060| v_loss: 0.018| per_loss: 0.310 | a_loss: 0.527
Train: Epoch [2794/3000], Step [30/158]| g_loss: 0.620| d_loss: 0.810| gp_loss: 0.198| r_loss: 0.046| p_loss: 0.059| v_loss: 0.018| per_loss: 0.311 | a_loss: 0.495
Train: Epoch [2794/3000], Step [60/158]| g_loss: 0.650| d_loss: 0.609| gp_loss: 0.050| r_loss: 0.047| p_loss: 0.061| v_loss: 0.018| per_loss: 0.294 | a_loss: 0.525
Train: Epoch [2794/3000], Step [90/158]| g_loss: 0.667| d_loss: 0.601| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.291 | a_loss: 0.540
Train: Epoch [2794/3000], Step [120/158]| g_loss: 0.616| d_loss: 0.632| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.490
Train: Epoch [2794/3000], Step [150/158]| g_loss: 0.655| d_loss: 0.553| gp_loss: 0.057| r_loss: 0.044| p_loss: 0.056| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.533
Train: Epoch [2795/3000], Step [30/158]| g_loss: 0.653| d_loss: 0.727| gp_loss: 0.181| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.526
Train: Epoch [2795/3000], Step [60/158]| g_loss: 0.628| d_loss: 0.672| gp_loss: 0.049| r_loss: 0.046| p_loss: 0.061| v_loss: 0.018| per_loss: 0.313 | a_loss: 0.502
Train: Epoch [2795/3000], Step [90/158]| g_loss: 0.674| d_loss: 0.582| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.061| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.546
Train: Epoch [2795/3000], Step [120/158]| g_loss: 0.697| d_loss: 0.558| gp_loss: 0.056| r_loss: 0.045| p_loss: 0.060| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.573
Train: Epoch [2795/3000], Step [150/158]| g_loss: 0.624| d_loss: 0.692| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.061| v_loss: 0.018| per_loss: 0.298 | a_loss: 0.500
Train: Epoch [2796/3000], Step [30/158]| g_loss: 0.645| d_loss: 0.706| gp_loss: 0.113| r_loss: 0.045| p_loss: 0.059| v_loss: 0.018| per_loss: 0.300 | a_loss: 0.522
Train: Epoch [2796/3000], Step [60/158]| g_loss: 0.624| d_loss: 0.645| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.494
Train: Epoch [2796/3000], Step [90/158]| g_loss: 0.683| d_loss: 0.582| gp_loss: 0.060| r_loss: 0.052| p_loss: 0.071| v_loss: 0.019| per_loss: 0.315 | a_loss: 0.545
Train: Epoch [2796/3000], Step [120/158]| g_loss: 0.681| d_loss: 0.583| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.063| v_loss: 0.018| per_loss: 0.305 | a_loss: 0.553
Train: Epoch [2796/3000], Step [150/158]| g_loss: 0.651| d_loss: 0.627| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.067| v_loss: 0.020| per_loss: 0.308 | a_loss: 0.517
Train: Epoch [2797/3000], Step [30/158]| g_loss: 0.629| d_loss: 0.714| gp_loss: 0.091| r_loss: 0.047| p_loss: 0.065| v_loss: 0.018| per_loss: 0.307 | a_loss: 0.500
Train: Epoch [2797/3000], Step [60/158]| g_loss: 0.651| d_loss: 0.549| gp_loss: 0.062| r_loss: 0.049| p_loss: 0.061| v_loss: 0.018| per_loss: 0.312 | a_loss: 0.522
Train: Epoch [2797/3000], Step [90/158]| g_loss: 0.669| d_loss: 0.640| gp_loss: 0.063| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.319 | a_loss: 0.541
Train: Epoch [2797/3000], Step [120/158]| g_loss: 0.658| d_loss: 0.605| gp_loss: 0.061| r_loss: 0.045| p_loss: 0.058| v_loss: 0.019| per_loss: 0.292 | a_loss: 0.536
Train: Epoch [2797/3000], Step [150/158]| g_loss: 0.646| d_loss: 0.605| gp_loss: 0.061| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.518
Train: Epoch [2798/3000], Step [30/158]| g_loss: 0.627| d_loss: 0.761| gp_loss: 0.171| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.315 | a_loss: 0.499
Train: Epoch [2798/3000], Step [60/158]| g_loss: 0.649| d_loss: 0.615| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.061| v_loss: 0.018| per_loss: 0.310 | a_loss: 0.521
Train: Epoch [2798/3000], Step [90/158]| g_loss: 0.756| d_loss: 0.625| gp_loss: 0.059| r_loss: 0.083| p_loss: 0.144| v_loss: 0.021| per_loss: 0.369 | a_loss: 0.543
Train: Epoch [2798/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.584| gp_loss: 0.059| r_loss: 0.063| p_loss: 0.105| v_loss: 0.019| per_loss: 0.330 | a_loss: 0.509
Train: Epoch [2798/3000], Step [150/158]| g_loss: 0.705| d_loss: 0.571| gp_loss: 0.064| r_loss: 0.067| p_loss: 0.102| v_loss: 0.020| per_loss: 0.322 | a_loss: 0.535
Train: Epoch [2799/3000], Step [30/158]| g_loss: 0.686| d_loss: 0.681| gp_loss: 0.131| r_loss: 0.060| p_loss: 0.085| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.533
Train: Epoch [2799/3000], Step [60/158]| g_loss: 0.694| d_loss: 0.611| gp_loss: 0.060| r_loss: 0.055| p_loss: 0.084| v_loss: 0.019| per_loss: 0.332 | a_loss: 0.544
Train: Epoch [2799/3000], Step [90/158]| g_loss: 0.717| d_loss: 0.564| gp_loss: 0.061| r_loss: 0.057| p_loss: 0.094| v_loss: 0.020| per_loss: 0.350 | a_loss: 0.559
Train: Epoch [2799/3000], Step [120/158]| g_loss: 0.686| d_loss: 0.572| gp_loss: 0.061| r_loss: 0.059| p_loss: 0.087| v_loss: 0.019| per_loss: 0.334 | a_loss: 0.531
Train: Epoch [2799/3000], Step [150/158]| g_loss: 0.648| d_loss: 0.732| gp_loss: 0.062| r_loss: 0.055| p_loss: 0.078| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.504
Train: Epoch [2800/3000], Step [30/158]| g_loss: 0.649| d_loss: 0.769| gp_loss: 0.208| r_loss: 0.054| p_loss: 0.077| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.506
Train: Epoch [2800/3000], Step [60/158]| g_loss: 0.646| d_loss: 0.635| gp_loss: 0.056| r_loss: 0.054| p_loss: 0.074| v_loss: 0.020| per_loss: 0.310 | a_loss: 0.505
Train: Epoch [2800/3000], Step [90/158]| g_loss: 0.653| d_loss: 0.613| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.073| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.516
Train: Epoch [2800/3000], Step [120/158]| g_loss: 0.698| d_loss: 0.540| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.072| v_loss: 0.019| per_loss: 0.339 | a_loss: 0.558
Train: Epoch [2800/3000], Step [150/158]| g_loss: 0.697| d_loss: 0.637| gp_loss: 0.059| r_loss: 0.051| p_loss: 0.067| v_loss: 0.018| per_loss: 0.329 | a_loss: 0.561
Test: Epoch [2800/3000]| g_loss: 0.605| r_loss: 0.373| p_loss: 0.292| v_loss: 0.020
Train: Epoch [2801/3000], Step [30/158]| g_loss: 0.651| d_loss: 0.585| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.064| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.519
Train: Epoch [2801/3000], Step [60/158]| g_loss: 0.669| d_loss: 0.604| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.538
Train: Epoch [2801/3000], Step [90/158]| g_loss: 0.674| d_loss: 0.600| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.329 | a_loss: 0.543
Train: Epoch [2801/3000], Step [120/158]| g_loss: 0.685| d_loss: 0.627| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.064| v_loss: 0.018| per_loss: 0.333 | a_loss: 0.555
Train: Epoch [2801/3000], Step [150/158]| g_loss: 0.668| d_loss: 0.661| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.540
Train: Epoch [2802/3000], Step [30/158]| g_loss: 0.600| d_loss: 0.741| gp_loss: 0.110| r_loss: 0.050| p_loss: 0.065| v_loss: 0.018| per_loss: 0.301 | a_loss: 0.469
Train: Epoch [2802/3000], Step [60/158]| g_loss: 0.602| d_loss: 0.655| gp_loss: 0.057| r_loss: 0.051| p_loss: 0.072| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.466
Train: Epoch [2802/3000], Step [90/158]| g_loss: 0.639| d_loss: 0.639| gp_loss: 0.059| r_loss: 0.051| p_loss: 0.070| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.503
Train: Epoch [2802/3000], Step [120/158]| g_loss: 0.683| d_loss: 0.620| gp_loss: 0.061| r_loss: 0.051| p_loss: 0.073| v_loss: 0.019| per_loss: 0.329 | a_loss: 0.544
Train: Epoch [2802/3000], Step [150/158]| g_loss: 0.693| d_loss: 0.546| gp_loss: 0.062| r_loss: 0.048| p_loss: 0.070| v_loss: 0.018| per_loss: 0.329 | a_loss: 0.559
Train: Epoch [2803/3000], Step [30/158]| g_loss: 0.702| d_loss: 0.622| gp_loss: 0.156| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.572
Train: Epoch [2803/3000], Step [60/158]| g_loss: 0.637| d_loss: 0.646| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.508
Train: Epoch [2803/3000], Step [90/158]| g_loss: 0.653| d_loss: 0.676| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.067| v_loss: 0.019| per_loss: 0.318 | a_loss: 0.520
Train: Epoch [2803/3000], Step [120/158]| g_loss: 0.651| d_loss: 0.582| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.070| v_loss: 0.019| per_loss: 0.323 | a_loss: 0.518
Train: Epoch [2803/3000], Step [150/158]| g_loss: 0.698| d_loss: 0.597| gp_loss: 0.061| r_loss: 0.053| p_loss: 0.085| v_loss: 0.019| per_loss: 0.344 | a_loss: 0.549
Train: Epoch [2804/3000], Step [30/158]| g_loss: 0.662| d_loss: 0.796| gp_loss: 0.228| r_loss: 0.055| p_loss: 0.082| v_loss: 0.019| per_loss: 0.328 | a_loss: 0.515
Train: Epoch [2804/3000], Step [60/158]| g_loss: 0.670| d_loss: 0.538| gp_loss: 0.052| r_loss: 0.057| p_loss: 0.079| v_loss: 0.019| per_loss: 0.339 | a_loss: 0.521
Train: Epoch [2804/3000], Step [90/158]| g_loss: 0.684| d_loss: 0.607| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.067| v_loss: 0.019| per_loss: 0.323 | a_loss: 0.550
Train: Epoch [2804/3000], Step [120/158]| g_loss: 0.685| d_loss: 0.553| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.066| v_loss: 0.018| per_loss: 0.333 | a_loss: 0.551
Train: Epoch [2804/3000], Step [150/158]| g_loss: 0.651| d_loss: 0.713| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.069| v_loss: 0.019| per_loss: 0.322 | a_loss: 0.516
Train: Epoch [2805/3000], Step [30/158]| g_loss: 0.651| d_loss: 0.689| gp_loss: 0.149| r_loss: 0.052| p_loss: 0.068| v_loss: 0.018| per_loss: 0.322 | a_loss: 0.514
Train: Epoch [2805/3000], Step [60/158]| g_loss: 0.686| d_loss: 0.495| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.062| v_loss: 0.018| per_loss: 0.322 | a_loss: 0.553
Train: Epoch [2805/3000], Step [90/158]| g_loss: 0.717| d_loss: 0.564| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.351 | a_loss: 0.582
Train: Epoch [2805/3000], Step [120/158]| g_loss: 0.633| d_loss: 0.646| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.063| v_loss: 0.018| per_loss: 0.307 | a_loss: 0.506
Train: Epoch [2805/3000], Step [150/158]| g_loss: 0.683| d_loss: 0.693| gp_loss: 0.060| r_loss: 0.050| p_loss: 0.072| v_loss: 0.020| per_loss: 0.328 | a_loss: 0.544
Train: Epoch [2806/3000], Step [30/158]| g_loss: 0.638| d_loss: 0.850| gp_loss: 0.272| r_loss: 0.049| p_loss: 0.067| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.505
Train: Epoch [2806/3000], Step [60/158]| g_loss: 0.648| d_loss: 0.580| gp_loss: 0.051| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.326 | a_loss: 0.513
Train: Epoch [2806/3000], Step [90/158]| g_loss: 0.661| d_loss: 0.636| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.334 | a_loss: 0.528
Train: Epoch [2806/3000], Step [120/158]| g_loss: 0.645| d_loss: 0.659| gp_loss: 0.048| r_loss: 0.052| p_loss: 0.079| v_loss: 0.019| per_loss: 0.323 | a_loss: 0.501
Train: Epoch [2806/3000], Step [150/158]| g_loss: 0.668| d_loss: 0.588| gp_loss: 0.057| r_loss: 0.056| p_loss: 0.072| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.526
Train: Epoch [2807/3000], Step [30/158]| g_loss: 0.639| d_loss: 0.736| gp_loss: 0.102| r_loss: 0.049| p_loss: 0.072| v_loss: 0.018| per_loss: 0.344 | a_loss: 0.501
Train: Epoch [2807/3000], Step [60/158]| g_loss: 0.676| d_loss: 0.551| gp_loss: 0.050| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.326 | a_loss: 0.543
Train: Epoch [2807/3000], Step [90/158]| g_loss: 0.663| d_loss: 0.604| gp_loss: 0.049| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.532
Train: Epoch [2807/3000], Step [120/158]| g_loss: 0.639| d_loss: 0.631| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.064| v_loss: 0.018| per_loss: 0.310 | a_loss: 0.509
Train: Epoch [2807/3000], Step [150/158]| g_loss: 0.676| d_loss: 0.601| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.550
Train: Epoch [2808/3000], Step [30/158]| g_loss: 0.636| d_loss: 0.780| gp_loss: 0.127| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.506
Train: Epoch [2808/3000], Step [60/158]| g_loss: 0.597| d_loss: 0.737| gp_loss: 0.055| r_loss: 0.045| p_loss: 0.061| v_loss: 0.018| per_loss: 0.311 | a_loss: 0.471
Train: Epoch [2808/3000], Step [90/158]| g_loss: 0.628| d_loss: 0.550| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.319 | a_loss: 0.499
Train: Epoch [2808/3000], Step [120/158]| g_loss: 0.631| d_loss: 0.605| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.062| v_loss: 0.018| per_loss: 0.321 | a_loss: 0.501
Train: Epoch [2808/3000], Step [150/158]| g_loss: 0.716| d_loss: 0.483| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.061| v_loss: 0.018| per_loss: 0.322 | a_loss: 0.587
Train: Epoch [2809/3000], Step [30/158]| g_loss: 0.651| d_loss: 0.710| gp_loss: 0.171| r_loss: 0.046| p_loss: 0.062| v_loss: 0.018| per_loss: 0.325 | a_loss: 0.523
Train: Epoch [2809/3000], Step [60/158]| g_loss: 0.672| d_loss: 0.700| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.545
Train: Epoch [2809/3000], Step [90/158]| g_loss: 0.666| d_loss: 0.602| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.062| v_loss: 0.018| per_loss: 0.332 | a_loss: 0.537
Train: Epoch [2809/3000], Step [120/158]| g_loss: 0.661| d_loss: 0.536| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.532
Train: Epoch [2809/3000], Step [150/158]| g_loss: 0.665| d_loss: 0.710| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.063| v_loss: 0.018| per_loss: 0.316 | a_loss: 0.537
Train: Epoch [2810/3000], Step [30/158]| g_loss: 0.644| d_loss: 0.672| gp_loss: 0.134| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.338 | a_loss: 0.510
Train: Epoch [2810/3000], Step [60/158]| g_loss: 0.648| d_loss: 0.652| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.322 | a_loss: 0.515
Train: Epoch [2810/3000], Step [90/158]| g_loss: 0.725| d_loss: 0.526| gp_loss: 0.064| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.325 | a_loss: 0.591
Train: Epoch [2810/3000], Step [120/158]| g_loss: 0.639| d_loss: 0.714| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.068| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.507
Train: Epoch [2810/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.576| gp_loss: 0.060| r_loss: 0.045| p_loss: 0.062| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.537
Train: Epoch [2811/3000], Step [30/158]| g_loss: 0.644| d_loss: 0.718| gp_loss: 0.137| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.319 | a_loss: 0.511
Train: Epoch [2811/3000], Step [60/158]| g_loss: 0.626| d_loss: 0.659| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.497
Train: Epoch [2811/3000], Step [90/158]| g_loss: 0.627| d_loss: 0.665| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.060| v_loss: 0.018| per_loss: 0.304 | a_loss: 0.501
Train: Epoch [2811/3000], Step [120/158]| g_loss: 0.679| d_loss: 0.525| gp_loss: 0.062| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.326 | a_loss: 0.550
Train: Epoch [2811/3000], Step [150/158]| g_loss: 0.713| d_loss: 0.537| gp_loss: 0.059| r_loss: 0.044| p_loss: 0.059| v_loss: 0.018| per_loss: 0.320 | a_loss: 0.589
Train: Epoch [2812/3000], Step [30/158]| g_loss: 0.616| d_loss: 0.790| gp_loss: 0.136| r_loss: 0.049| p_loss: 0.068| v_loss: 0.020| per_loss: 0.331 | a_loss: 0.480
Train: Epoch [2812/3000], Step [60/158]| g_loss: 0.628| d_loss: 0.660| gp_loss: 0.061| r_loss: 0.045| p_loss: 0.061| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.503
Train: Epoch [2812/3000], Step [90/158]| g_loss: 0.618| d_loss: 0.673| gp_loss: 0.059| r_loss: 0.046| p_loss: 0.062| v_loss: 0.018| per_loss: 0.311 | a_loss: 0.492
Train: Epoch [2812/3000], Step [120/158]| g_loss: 0.684| d_loss: 0.484| gp_loss: 0.065| r_loss: 0.046| p_loss: 0.059| v_loss: 0.018| per_loss: 0.307 | a_loss: 0.559
Train: Epoch [2812/3000], Step [150/158]| g_loss: 0.697| d_loss: 0.632| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.569
Train: Epoch [2813/3000], Step [30/158]| g_loss: 0.624| d_loss: 0.710| gp_loss: 0.119| r_loss: 0.047| p_loss: 0.062| v_loss: 0.018| per_loss: 0.321 | a_loss: 0.496
Train: Epoch [2813/3000], Step [60/158]| g_loss: 0.649| d_loss: 0.626| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.061| v_loss: 0.018| per_loss: 0.327 | a_loss: 0.520
Train: Epoch [2813/3000], Step [90/158]| g_loss: 0.681| d_loss: 0.628| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.554
Train: Epoch [2813/3000], Step [120/158]| g_loss: 0.651| d_loss: 0.653| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.062| v_loss: 0.018| per_loss: 0.310 | a_loss: 0.524
Train: Epoch [2813/3000], Step [150/158]| g_loss: 0.646| d_loss: 0.582| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.515
Train: Epoch [2814/3000], Step [30/158]| g_loss: 0.687| d_loss: 0.660| gp_loss: 0.168| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.558
Train: Epoch [2814/3000], Step [60/158]| g_loss: 0.654| d_loss: 0.539| gp_loss: 0.052| r_loss: 0.044| p_loss: 0.056| v_loss: 0.018| per_loss: 0.292 | a_loss: 0.535
Train: Epoch [2814/3000], Step [90/158]| g_loss: 0.679| d_loss: 0.562| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.059| v_loss: 0.018| per_loss: 0.333 | a_loss: 0.552
Train: Epoch [2814/3000], Step [120/158]| g_loss: 0.676| d_loss: 0.687| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.545
Train: Epoch [2814/3000], Step [150/158]| g_loss: 0.619| d_loss: 0.735| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.489
Train: Epoch [2815/3000], Step [30/158]| g_loss: 0.633| d_loss: 0.736| gp_loss: 0.161| r_loss: 0.046| p_loss: 0.058| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.509
Train: Epoch [2815/3000], Step [60/158]| g_loss: 0.636| d_loss: 0.591| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.327 | a_loss: 0.504
Train: Epoch [2815/3000], Step [90/158]| g_loss: 0.673| d_loss: 0.656| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.547
Train: Epoch [2815/3000], Step [120/158]| g_loss: 0.647| d_loss: 0.604| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.517
Train: Epoch [2815/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.602| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.061| v_loss: 0.018| per_loss: 0.302 | a_loss: 0.532
Train: Epoch [2816/3000], Step [30/158]| g_loss: 0.636| d_loss: 0.767| gp_loss: 0.142| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.319 | a_loss: 0.507
Train: Epoch [2816/3000], Step [60/158]| g_loss: 0.628| d_loss: 0.615| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.502
Train: Epoch [2816/3000], Step [90/158]| g_loss: 0.615| d_loss: 0.606| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.060| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.488
Train: Epoch [2816/3000], Step [120/158]| g_loss: 0.683| d_loss: 0.536| gp_loss: 0.061| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.328 | a_loss: 0.555
Train: Epoch [2816/3000], Step [150/158]| g_loss: 0.689| d_loss: 0.575| gp_loss: 0.060| r_loss: 0.044| p_loss: 0.058| v_loss: 0.018| per_loss: 0.317 | a_loss: 0.566
Train: Epoch [2817/3000], Step [30/158]| g_loss: 0.654| d_loss: 0.661| gp_loss: 0.117| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.524
Train: Epoch [2817/3000], Step [60/158]| g_loss: 0.636| d_loss: 0.699| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.063| v_loss: 0.018| per_loss: 0.293 | a_loss: 0.510
Train: Epoch [2817/3000], Step [90/158]| g_loss: 0.649| d_loss: 0.675| gp_loss: 0.062| r_loss: 0.046| p_loss: 0.063| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.521
Train: Epoch [2817/3000], Step [120/158]| g_loss: 0.633| d_loss: 0.638| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.061| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.504
Train: Epoch [2817/3000], Step [150/158]| g_loss: 0.648| d_loss: 0.595| gp_loss: 0.059| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.328 | a_loss: 0.520
Train: Epoch [2818/3000], Step [30/158]| g_loss: 0.660| d_loss: 0.744| gp_loss: 0.188| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.533
Train: Epoch [2818/3000], Step [60/158]| g_loss: 0.647| d_loss: 0.638| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.520
Train: Epoch [2818/3000], Step [90/158]| g_loss: 0.677| d_loss: 0.503| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.545
Train: Epoch [2818/3000], Step [120/158]| g_loss: 0.650| d_loss: 0.657| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.061| v_loss: 0.018| per_loss: 0.311 | a_loss: 0.522
Train: Epoch [2818/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.612| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.535
Train: Epoch [2819/3000], Step [30/158]| g_loss: 0.674| d_loss: 0.599| gp_loss: 0.141| r_loss: 0.044| p_loss: 0.056| v_loss: 0.018| per_loss: 0.309 | a_loss: 0.552
Train: Epoch [2819/3000], Step [60/158]| g_loss: 0.677| d_loss: 0.634| gp_loss: 0.049| r_loss: 0.049| p_loss: 0.060| v_loss: 0.019| per_loss: 0.323 | a_loss: 0.546
Train: Epoch [2819/3000], Step [90/158]| g_loss: 0.651| d_loss: 0.704| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.524
Train: Epoch [2819/3000], Step [120/158]| g_loss: 0.623| d_loss: 0.628| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.294 | a_loss: 0.496
Train: Epoch [2819/3000], Step [150/158]| g_loss: 0.674| d_loss: 0.546| gp_loss: 0.061| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.325 | a_loss: 0.545
Train: Epoch [2820/3000], Step [30/158]| g_loss: 0.626| d_loss: 0.733| gp_loss: 0.107| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.500
Train: Epoch [2820/3000], Step [60/158]| g_loss: 0.655| d_loss: 0.585| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.318 | a_loss: 0.528
Train: Epoch [2820/3000], Step [90/158]| g_loss: 0.655| d_loss: 0.595| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.527
Train: Epoch [2820/3000], Step [120/158]| g_loss: 0.651| d_loss: 0.577| gp_loss: 0.060| r_loss: 0.046| p_loss: 0.059| v_loss: 0.018| per_loss: 0.293 | a_loss: 0.529
Train: Epoch [2820/3000], Step [150/158]| g_loss: 0.680| d_loss: 0.675| gp_loss: 0.062| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.552
Train: Epoch [2821/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.651| gp_loss: 0.137| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.327 | a_loss: 0.521
Train: Epoch [2821/3000], Step [60/158]| g_loss: 0.627| d_loss: 0.650| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.498
Train: Epoch [2821/3000], Step [90/158]| g_loss: 0.653| d_loss: 0.610| gp_loss: 0.063| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.526
Train: Epoch [2821/3000], Step [120/158]| g_loss: 0.661| d_loss: 0.608| gp_loss: 0.063| r_loss: 0.050| p_loss: 0.062| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.530
Train: Epoch [2821/3000], Step [150/158]| g_loss: 0.650| d_loss: 0.608| gp_loss: 0.062| r_loss: 0.045| p_loss: 0.059| v_loss: 0.018| per_loss: 0.317 | a_loss: 0.526
Train: Epoch [2822/3000], Step [30/158]| g_loss: 0.678| d_loss: 0.704| gp_loss: 0.176| r_loss: 0.047| p_loss: 0.062| v_loss: 0.018| per_loss: 0.306 | a_loss: 0.552
Train: Epoch [2822/3000], Step [60/158]| g_loss: 0.666| d_loss: 0.592| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.539
Train: Epoch [2822/3000], Step [90/158]| g_loss: 0.653| d_loss: 0.652| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.063| v_loss: 0.018| per_loss: 0.324 | a_loss: 0.523
Train: Epoch [2822/3000], Step [120/158]| g_loss: 0.624| d_loss: 0.633| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.495
Train: Epoch [2822/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.599| gp_loss: 0.061| r_loss: 0.051| p_loss: 0.064| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.529
Train: Epoch [2823/3000], Step [30/158]| g_loss: 0.665| d_loss: 0.724| gp_loss: 0.170| r_loss: 0.053| p_loss: 0.072| v_loss: 0.019| per_loss: 0.323 | a_loss: 0.524
Train: Epoch [2823/3000], Step [60/158]| g_loss: 0.659| d_loss: 0.623| gp_loss: 0.059| r_loss: 0.052| p_loss: 0.069| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.524
Train: Epoch [2823/3000], Step [90/158]| g_loss: 0.682| d_loss: 0.624| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.335 | a_loss: 0.547
Train: Epoch [2823/3000], Step [120/158]| g_loss: 0.681| d_loss: 0.581| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.315 | a_loss: 0.554
Train: Epoch [2823/3000], Step [150/158]| g_loss: 0.651| d_loss: 0.599| gp_loss: 0.059| r_loss: 0.046| p_loss: 0.059| v_loss: 0.018| per_loss: 0.314 | a_loss: 0.526
Train: Epoch [2824/3000], Step [30/158]| g_loss: 0.675| d_loss: 0.690| gp_loss: 0.143| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.349 | a_loss: 0.540
Train: Epoch [2824/3000], Step [60/158]| g_loss: 0.667| d_loss: 0.566| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.059| v_loss: 0.019| per_loss: 0.297 | a_loss: 0.543
Train: Epoch [2824/3000], Step [90/158]| g_loss: 0.666| d_loss: 0.626| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.063| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.534
Train: Epoch [2824/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.524| gp_loss: 0.059| r_loss: 0.045| p_loss: 0.057| v_loss: 0.019| per_loss: 0.319 | a_loss: 0.553
Train: Epoch [2824/3000], Step [150/158]| g_loss: 0.623| d_loss: 0.735| gp_loss: 0.057| r_loss: 0.045| p_loss: 0.061| v_loss: 0.018| per_loss: 0.292 | a_loss: 0.500
Train: Epoch [2825/3000], Step [30/158]| g_loss: 0.667| d_loss: 0.633| gp_loss: 0.105| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.331 | a_loss: 0.534
Train: Epoch [2825/3000], Step [60/158]| g_loss: 0.657| d_loss: 0.587| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.525
Train: Epoch [2825/3000], Step [90/158]| g_loss: 0.675| d_loss: 0.603| gp_loss: 0.062| r_loss: 0.048| p_loss: 0.067| v_loss: 0.019| per_loss: 0.323 | a_loss: 0.542
Train: Epoch [2825/3000], Step [120/158]| g_loss: 0.645| d_loss: 0.706| gp_loss: 0.062| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.516
Train: Epoch [2825/3000], Step [150/158]| g_loss: 0.640| d_loss: 0.621| gp_loss: 0.064| r_loss: 0.046| p_loss: 0.061| v_loss: 0.018| per_loss: 0.302 | a_loss: 0.515
Train: Epoch [2826/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.762| gp_loss: 0.179| r_loss: 0.049| p_loss: 0.072| v_loss: 0.018| per_loss: 0.318 | a_loss: 0.517
Train: Epoch [2826/3000], Step [60/158]| g_loss: 0.648| d_loss: 0.715| gp_loss: 0.055| r_loss: 0.064| p_loss: 0.100| v_loss: 0.019| per_loss: 0.339 | a_loss: 0.480
Train: Epoch [2826/3000], Step [90/158]| g_loss: 0.636| d_loss: 0.581| gp_loss: 0.060| r_loss: 0.057| p_loss: 0.089| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.484
Train: Epoch [2826/3000], Step [120/158]| g_loss: 0.673| d_loss: 0.579| gp_loss: 0.057| r_loss: 0.057| p_loss: 0.078| v_loss: 0.020| per_loss: 0.327 | a_loss: 0.525
Train: Epoch [2826/3000], Step [150/158]| g_loss: 0.683| d_loss: 0.542| gp_loss: 0.066| r_loss: 0.049| p_loss: 0.069| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.550
Train: Epoch [2827/3000], Step [30/158]| g_loss: 0.673| d_loss: 0.853| gp_loss: 0.254| r_loss: 0.055| p_loss: 0.077| v_loss: 0.021| per_loss: 0.314 | a_loss: 0.528
Train: Epoch [2827/3000], Step [60/158]| g_loss: 0.635| d_loss: 0.652| gp_loss: 0.049| r_loss: 0.048| p_loss: 0.071| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.502
Train: Epoch [2827/3000], Step [90/158]| g_loss: 0.647| d_loss: 0.618| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.520
Train: Epoch [2827/3000], Step [120/158]| g_loss: 0.675| d_loss: 0.565| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.065| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.546
Train: Epoch [2827/3000], Step [150/158]| g_loss: 0.695| d_loss: 0.589| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.326 | a_loss: 0.561
Train: Epoch [2828/3000], Step [30/158]| g_loss: 0.658| d_loss: 0.681| gp_loss: 0.090| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.298 | a_loss: 0.532
Train: Epoch [2828/3000], Step [60/158]| g_loss: 0.647| d_loss: 0.639| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.517
Train: Epoch [2828/3000], Step [90/158]| g_loss: 0.630| d_loss: 0.626| gp_loss: 0.060| r_loss: 0.050| p_loss: 0.065| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.497
Train: Epoch [2828/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.590| gp_loss: 0.062| r_loss: 0.053| p_loss: 0.068| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.540
Train: Epoch [2828/3000], Step [150/158]| g_loss: 0.690| d_loss: 0.578| gp_loss: 0.063| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.322 | a_loss: 0.560
Train: Epoch [2829/3000], Step [30/158]| g_loss: 0.637| d_loss: 0.704| gp_loss: 0.108| r_loss: 0.046| p_loss: 0.065| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.508
Train: Epoch [2829/3000], Step [60/158]| g_loss: 0.639| d_loss: 0.648| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.315 | a_loss: 0.507
Train: Epoch [2829/3000], Step [90/158]| g_loss: 0.682| d_loss: 0.554| gp_loss: 0.063| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.550
Train: Epoch [2829/3000], Step [120/158]| g_loss: 0.708| d_loss: 0.584| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.324 | a_loss: 0.577
Train: Epoch [2829/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.668| gp_loss: 0.065| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.529
Train: Epoch [2830/3000], Step [30/158]| g_loss: 0.630| d_loss: 0.759| gp_loss: 0.208| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.503
Train: Epoch [2830/3000], Step [60/158]| g_loss: 0.653| d_loss: 0.586| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.319 | a_loss: 0.524
Train: Epoch [2830/3000], Step [90/158]| g_loss: 0.686| d_loss: 0.568| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.337 | a_loss: 0.555
Train: Epoch [2830/3000], Step [120/158]| g_loss: 0.642| d_loss: 0.653| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.061| v_loss: 0.018| per_loss: 0.280 | a_loss: 0.519
Train: Epoch [2830/3000], Step [150/158]| g_loss: 0.645| d_loss: 0.655| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.513
Train: Epoch [2831/3000], Step [30/158]| g_loss: 0.634| d_loss: 0.766| gp_loss: 0.216| r_loss: 0.047| p_loss: 0.061| v_loss: 0.018| per_loss: 0.293 | a_loss: 0.509
Train: Epoch [2831/3000], Step [60/158]| g_loss: 0.640| d_loss: 0.612| gp_loss: 0.050| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.324 | a_loss: 0.512
Train: Epoch [2831/3000], Step [90/158]| g_loss: 0.668| d_loss: 0.583| gp_loss: 0.057| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.541
Train: Epoch [2831/3000], Step [120/158]| g_loss: 0.673| d_loss: 0.673| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.545
Train: Epoch [2831/3000], Step [150/158]| g_loss: 0.647| d_loss: 0.554| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.063| v_loss: 0.018| per_loss: 0.313 | a_loss: 0.517
Train: Epoch [2832/3000], Step [30/158]| g_loss: 0.612| d_loss: 0.807| gp_loss: 0.151| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.481
Train: Epoch [2832/3000], Step [60/158]| g_loss: 0.643| d_loss: 0.629| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.323 | a_loss: 0.511
Train: Epoch [2832/3000], Step [90/158]| g_loss: 0.627| d_loss: 0.605| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.060| v_loss: 0.018| per_loss: 0.302 | a_loss: 0.501
Train: Epoch [2832/3000], Step [120/158]| g_loss: 0.664| d_loss: 0.574| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.536
Train: Epoch [2832/3000], Step [150/158]| g_loss: 0.682| d_loss: 0.600| gp_loss: 0.058| r_loss: 0.045| p_loss: 0.060| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.556
Train: Epoch [2833/3000], Step [30/158]| g_loss: 0.634| d_loss: 0.732| gp_loss: 0.097| r_loss: 0.046| p_loss: 0.062| v_loss: 0.018| per_loss: 0.300 | a_loss: 0.509
Train: Epoch [2833/3000], Step [60/158]| g_loss: 0.662| d_loss: 0.651| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.527
Train: Epoch [2833/3000], Step [90/158]| g_loss: 0.652| d_loss: 0.614| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.323 | a_loss: 0.520
Train: Epoch [2833/3000], Step [120/158]| g_loss: 0.695| d_loss: 0.511| gp_loss: 0.064| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.567
Train: Epoch [2833/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.603| gp_loss: 0.062| r_loss: 0.043| p_loss: 0.058| v_loss: 0.018| per_loss: 0.314 | a_loss: 0.540
Train: Epoch [2834/3000], Step [30/158]| g_loss: 0.650| d_loss: 0.733| gp_loss: 0.165| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.521
Train: Epoch [2834/3000], Step [60/158]| g_loss: 0.665| d_loss: 0.515| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.332 | a_loss: 0.535
Train: Epoch [2834/3000], Step [90/158]| g_loss: 0.663| d_loss: 0.666| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.323 | a_loss: 0.534
Train: Epoch [2834/3000], Step [120/158]| g_loss: 0.685| d_loss: 0.598| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.559
Train: Epoch [2834/3000], Step [150/158]| g_loss: 0.667| d_loss: 0.610| gp_loss: 0.062| r_loss: 0.050| p_loss: 0.064| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.535
Train: Epoch [2835/3000], Step [30/158]| g_loss: 0.631| d_loss: 0.730| gp_loss: 0.110| r_loss: 0.047| p_loss: 0.066| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.501
Train: Epoch [2835/3000], Step [60/158]| g_loss: 0.660| d_loss: 0.618| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.062| v_loss: 0.018| per_loss: 0.321 | a_loss: 0.529
Train: Epoch [2835/3000], Step [90/158]| g_loss: 0.648| d_loss: 0.579| gp_loss: 0.059| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.522
Train: Epoch [2835/3000], Step [120/158]| g_loss: 0.637| d_loss: 0.583| gp_loss: 0.063| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.326 | a_loss: 0.508
Train: Epoch [2835/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.659| gp_loss: 0.065| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.329 | a_loss: 0.526
Train: Epoch [2836/3000], Step [30/158]| g_loss: 0.678| d_loss: 0.782| gp_loss: 0.238| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.344 | a_loss: 0.545
Train: Epoch [2836/3000], Step [60/158]| g_loss: 0.666| d_loss: 0.602| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.062| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.536
Train: Epoch [2836/3000], Step [90/158]| g_loss: 0.640| d_loss: 0.646| gp_loss: 0.051| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.511
Train: Epoch [2836/3000], Step [120/158]| g_loss: 0.655| d_loss: 0.645| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.324 | a_loss: 0.523
Train: Epoch [2836/3000], Step [150/158]| g_loss: 0.716| d_loss: 0.557| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.318 | a_loss: 0.585
Train: Epoch [2837/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.669| gp_loss: 0.126| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.337 | a_loss: 0.531
Train: Epoch [2837/3000], Step [60/158]| g_loss: 0.634| d_loss: 0.634| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.062| v_loss: 0.018| per_loss: 0.314 | a_loss: 0.507
Train: Epoch [2837/3000], Step [90/158]| g_loss: 0.630| d_loss: 0.692| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.325 | a_loss: 0.500
Train: Epoch [2837/3000], Step [120/158]| g_loss: 0.703| d_loss: 0.523| gp_loss: 0.063| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.313 | a_loss: 0.571
Train: Epoch [2837/3000], Step [150/158]| g_loss: 0.654| d_loss: 0.719| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.065| v_loss: 0.018| per_loss: 0.322 | a_loss: 0.523
Train: Epoch [2838/3000], Step [30/158]| g_loss: 0.668| d_loss: 0.676| gp_loss: 0.193| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.324 | a_loss: 0.536
Train: Epoch [2838/3000], Step [60/158]| g_loss: 0.710| d_loss: 0.483| gp_loss: 0.055| r_loss: 0.045| p_loss: 0.056| v_loss: 0.018| per_loss: 0.331 | a_loss: 0.585
Train: Epoch [2838/3000], Step [90/158]| g_loss: 0.659| d_loss: 0.720| gp_loss: 0.052| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.325 | a_loss: 0.526
Train: Epoch [2838/3000], Step [120/158]| g_loss: 0.607| d_loss: 0.731| gp_loss: 0.058| r_loss: 0.045| p_loss: 0.061| v_loss: 0.018| per_loss: 0.295 | a_loss: 0.484
Train: Epoch [2838/3000], Step [150/158]| g_loss: 0.631| d_loss: 0.582| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.502
Train: Epoch [2839/3000], Step [30/158]| g_loss: 0.634| d_loss: 0.674| gp_loss: 0.104| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.306 | a_loss: 0.506
Train: Epoch [2839/3000], Step [60/158]| g_loss: 0.664| d_loss: 0.569| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.535
Train: Epoch [2839/3000], Step [90/158]| g_loss: 0.649| d_loss: 0.642| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.060| v_loss: 0.018| per_loss: 0.314 | a_loss: 0.522
Train: Epoch [2839/3000], Step [120/158]| g_loss: 0.670| d_loss: 0.589| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.337 | a_loss: 0.536
Train: Epoch [2839/3000], Step [150/158]| g_loss: 0.693| d_loss: 0.602| gp_loss: 0.062| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.565
Train: Epoch [2840/3000], Step [30/158]| g_loss: 0.636| d_loss: 0.715| gp_loss: 0.125| r_loss: 0.048| p_loss: 0.066| v_loss: 0.018| per_loss: 0.303 | a_loss: 0.506
Train: Epoch [2840/3000], Step [60/158]| g_loss: 0.676| d_loss: 0.622| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.325 | a_loss: 0.544
Train: Epoch [2840/3000], Step [90/158]| g_loss: 0.605| d_loss: 0.683| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.327 | a_loss: 0.475
Train: Epoch [2840/3000], Step [120/158]| g_loss: 0.638| d_loss: 0.612| gp_loss: 0.062| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.322 | a_loss: 0.508
Train: Epoch [2840/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.585| gp_loss: 0.065| r_loss: 0.048| p_loss: 0.061| v_loss: 0.018| per_loss: 0.314 | a_loss: 0.541
Train: Epoch [2841/3000], Step [30/158]| g_loss: 0.665| d_loss: 0.763| gp_loss: 0.239| r_loss: 0.047| p_loss: 0.060| v_loss: 0.018| per_loss: 0.317 | a_loss: 0.538
Train: Epoch [2841/3000], Step [60/158]| g_loss: 0.640| d_loss: 0.648| gp_loss: 0.052| r_loss: 0.046| p_loss: 0.059| v_loss: 0.018| per_loss: 0.326 | a_loss: 0.514
Train: Epoch [2841/3000], Step [90/158]| g_loss: 0.656| d_loss: 0.552| gp_loss: 0.058| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.321 | a_loss: 0.521
Train: Epoch [2841/3000], Step [120/158]| g_loss: 0.674| d_loss: 0.611| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.318 | a_loss: 0.543
Train: Epoch [2841/3000], Step [150/158]| g_loss: 0.668| d_loss: 0.677| gp_loss: 0.057| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.319 | a_loss: 0.541
Train: Epoch [2842/3000], Step [30/158]| g_loss: 0.679| d_loss: 0.678| gp_loss: 0.135| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.325 | a_loss: 0.544
Train: Epoch [2842/3000], Step [60/158]| g_loss: 0.629| d_loss: 0.673| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.502
Train: Epoch [2842/3000], Step [90/158]| g_loss: 0.641| d_loss: 0.610| gp_loss: 0.061| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.512
Train: Epoch [2842/3000], Step [120/158]| g_loss: 0.672| d_loss: 0.554| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.059| v_loss: 0.018| per_loss: 0.301 | a_loss: 0.546
Train: Epoch [2842/3000], Step [150/158]| g_loss: 0.698| d_loss: 0.623| gp_loss: 0.063| r_loss: 0.065| p_loss: 0.078| v_loss: 0.019| per_loss: 0.318 | a_loss: 0.543
Train: Epoch [2843/3000], Step [30/158]| g_loss: 0.643| d_loss: 0.779| gp_loss: 0.160| r_loss: 0.055| p_loss: 0.079| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.498
Train: Epoch [2843/3000], Step [60/158]| g_loss: 0.635| d_loss: 0.695| gp_loss: 0.061| r_loss: 0.053| p_loss: 0.070| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.498
Train: Epoch [2843/3000], Step [90/158]| g_loss: 0.634| d_loss: 0.560| gp_loss: 0.061| r_loss: 0.051| p_loss: 0.070| v_loss: 0.019| per_loss: 0.324 | a_loss: 0.497
Train: Epoch [2843/3000], Step [120/158]| g_loss: 0.703| d_loss: 0.547| gp_loss: 0.062| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.328 | a_loss: 0.570
Train: Epoch [2843/3000], Step [150/158]| g_loss: 0.709| d_loss: 0.559| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.579
Train: Epoch [2844/3000], Step [30/158]| g_loss: 0.661| d_loss: 0.753| gp_loss: 0.148| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.530
Train: Epoch [2844/3000], Step [60/158]| g_loss: 0.675| d_loss: 0.621| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.067| v_loss: 0.020| per_loss: 0.314 | a_loss: 0.542
Train: Epoch [2844/3000], Step [90/158]| g_loss: 0.637| d_loss: 0.657| gp_loss: 0.060| r_loss: 0.046| p_loss: 0.059| v_loss: 0.018| per_loss: 0.306 | a_loss: 0.512
Train: Epoch [2844/3000], Step [120/158]| g_loss: 0.660| d_loss: 0.572| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.318 | a_loss: 0.534
Train: Epoch [2844/3000], Step [150/158]| g_loss: 0.656| d_loss: 0.604| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.527
Train: Epoch [2845/3000], Step [30/158]| g_loss: 0.659| d_loss: 0.643| gp_loss: 0.147| r_loss: 0.044| p_loss: 0.058| v_loss: 0.017| per_loss: 0.306 | a_loss: 0.538
Train: Epoch [2845/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.679| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.546
Train: Epoch [2845/3000], Step [90/158]| g_loss: 0.621| d_loss: 0.586| gp_loss: 0.059| r_loss: 0.045| p_loss: 0.060| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.496
Train: Epoch [2845/3000], Step [120/158]| g_loss: 0.670| d_loss: 0.644| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.326 | a_loss: 0.540
Train: Epoch [2845/3000], Step [150/158]| g_loss: 0.627| d_loss: 0.651| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.061| v_loss: 0.019| per_loss: 0.322 | a_loss: 0.496
Train: Epoch [2846/3000], Step [30/158]| g_loss: 0.644| d_loss: 0.672| gp_loss: 0.144| r_loss: 0.048| p_loss: 0.059| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.518
Train: Epoch [2846/3000], Step [60/158]| g_loss: 0.631| d_loss: 0.680| gp_loss: 0.056| r_loss: 0.045| p_loss: 0.059| v_loss: 0.019| per_loss: 0.318 | a_loss: 0.506
Train: Epoch [2846/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.711| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.329 | a_loss: 0.524
Train: Epoch [2846/3000], Step [120/158]| g_loss: 0.674| d_loss: 0.536| gp_loss: 0.064| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.545
Train: Epoch [2846/3000], Step [150/158]| g_loss: 0.671| d_loss: 0.584| gp_loss: 0.060| r_loss: 0.046| p_loss: 0.061| v_loss: 0.020| per_loss: 0.315 | a_loss: 0.544
Train: Epoch [2847/3000], Step [30/158]| g_loss: 0.667| d_loss: 0.712| gp_loss: 0.113| r_loss: 0.047| p_loss: 0.063| v_loss: 0.018| per_loss: 0.324 | a_loss: 0.538
Train: Epoch [2847/3000], Step [60/158]| g_loss: 0.637| d_loss: 0.602| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.511
Train: Epoch [2847/3000], Step [90/158]| g_loss: 0.649| d_loss: 0.641| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.519
Train: Epoch [2847/3000], Step [120/158]| g_loss: 0.657| d_loss: 0.575| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.058| v_loss: 0.018| per_loss: 0.319 | a_loss: 0.532
Train: Epoch [2847/3000], Step [150/158]| g_loss: 0.651| d_loss: 0.669| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.315 | a_loss: 0.520
Train: Epoch [2848/3000], Step [30/158]| g_loss: 0.652| d_loss: 0.729| gp_loss: 0.188| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.303 | a_loss: 0.524
Train: Epoch [2848/3000], Step [60/158]| g_loss: 0.627| d_loss: 0.645| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.323 | a_loss: 0.496
Train: Epoch [2848/3000], Step [90/158]| g_loss: 0.656| d_loss: 0.585| gp_loss: 0.060| r_loss: 0.045| p_loss: 0.056| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.533
Train: Epoch [2848/3000], Step [120/158]| g_loss: 0.672| d_loss: 0.571| gp_loss: 0.056| r_loss: 0.045| p_loss: 0.059| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.547
Train: Epoch [2848/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.637| gp_loss: 0.059| r_loss: 0.045| p_loss: 0.058| v_loss: 0.018| per_loss: 0.331 | a_loss: 0.533
Train: Epoch [2849/3000], Step [30/158]| g_loss: 0.670| d_loss: 0.749| gp_loss: 0.194| r_loss: 0.047| p_loss: 0.059| v_loss: 0.018| per_loss: 0.324 | a_loss: 0.543
Train: Epoch [2849/3000], Step [60/158]| g_loss: 0.670| d_loss: 0.505| gp_loss: 0.052| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.324 | a_loss: 0.543
Train: Epoch [2849/3000], Step [90/158]| g_loss: 0.662| d_loss: 0.695| gp_loss: 0.052| r_loss: 0.046| p_loss: 0.060| v_loss: 0.018| per_loss: 0.313 | a_loss: 0.536
Train: Epoch [2849/3000], Step [120/158]| g_loss: 0.665| d_loss: 0.606| gp_loss: 0.055| r_loss: 0.044| p_loss: 0.058| v_loss: 0.018| per_loss: 0.320 | a_loss: 0.541
Train: Epoch [2849/3000], Step [150/158]| g_loss: 0.614| d_loss: 0.616| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.300 | a_loss: 0.488
Train: Epoch [2850/3000], Step [30/158]| g_loss: 0.654| d_loss: 0.790| gp_loss: 0.199| r_loss: 0.051| p_loss: 0.064| v_loss: 0.020| per_loss: 0.309 | a_loss: 0.520
Train: Epoch [2850/3000], Step [60/158]| g_loss: 0.635| d_loss: 0.655| gp_loss: 0.051| r_loss: 0.047| p_loss: 0.061| v_loss: 0.020| per_loss: 0.321 | a_loss: 0.506
Train: Epoch [2850/3000], Step [90/158]| g_loss: 0.614| d_loss: 0.639| gp_loss: 0.051| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.487
Train: Epoch [2850/3000], Step [120/158]| g_loss: 0.651| d_loss: 0.559| gp_loss: 0.057| r_loss: 0.044| p_loss: 0.057| v_loss: 0.018| per_loss: 0.311 | a_loss: 0.530
Train: Epoch [2850/3000], Step [150/158]| g_loss: 0.680| d_loss: 0.602| gp_loss: 0.056| r_loss: 0.045| p_loss: 0.058| v_loss: 0.018| per_loss: 0.318 | a_loss: 0.555
Test: Epoch [2850/3000]| g_loss: 0.588| r_loss: 0.359| p_loss: 0.276| v_loss: 0.019
Train: Epoch [2851/3000], Step [30/158]| g_loss: 0.650| d_loss: 0.716| gp_loss: 0.051| r_loss: 0.045| p_loss: 0.057| v_loss: 0.018| per_loss: 0.314 | a_loss: 0.527
Train: Epoch [2851/3000], Step [60/158]| g_loss: 0.610| d_loss: 0.670| gp_loss: 0.050| r_loss: 0.045| p_loss: 0.059| v_loss: 0.019| per_loss: 0.301 | a_loss: 0.486
Train: Epoch [2851/3000], Step [90/158]| g_loss: 0.677| d_loss: 0.501| gp_loss: 0.052| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.550
Train: Epoch [2851/3000], Step [120/158]| g_loss: 0.687| d_loss: 0.533| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.559
Train: Epoch [2851/3000], Step [150/158]| g_loss: 0.668| d_loss: 0.610| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.059| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.539
Train: Epoch [2852/3000], Step [30/158]| g_loss: 0.692| d_loss: 0.621| gp_loss: 0.117| r_loss: 0.047| p_loss: 0.058| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.565
Train: Epoch [2852/3000], Step [60/158]| g_loss: 0.631| d_loss: 0.656| gp_loss: 0.049| r_loss: 0.046| p_loss: 0.060| v_loss: 0.018| per_loss: 0.324 | a_loss: 0.505
Train: Epoch [2852/3000], Step [90/158]| g_loss: 0.660| d_loss: 0.692| gp_loss: 0.051| r_loss: 0.047| p_loss: 0.059| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.533
Train: Epoch [2852/3000], Step [120/158]| g_loss: 0.626| d_loss: 0.634| gp_loss: 0.058| r_loss: 0.045| p_loss: 0.062| v_loss: 0.019| per_loss: 0.304 | a_loss: 0.501
Train: Epoch [2852/3000], Step [150/158]| g_loss: 0.673| d_loss: 0.562| gp_loss: 0.055| r_loss: 0.045| p_loss: 0.058| v_loss: 0.019| per_loss: 0.323 | a_loss: 0.547
Train: Epoch [2853/3000], Step [30/158]| g_loss: 0.649| d_loss: 0.735| gp_loss: 0.134| r_loss: 0.045| p_loss: 0.057| v_loss: 0.018| per_loss: 0.308 | a_loss: 0.526
Train: Epoch [2853/3000], Step [60/158]| g_loss: 0.643| d_loss: 0.648| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.061| v_loss: 0.020| per_loss: 0.331 | a_loss: 0.512
Train: Epoch [2853/3000], Step [90/158]| g_loss: 0.662| d_loss: 0.550| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.536
Train: Epoch [2853/3000], Step [120/158]| g_loss: 0.686| d_loss: 0.591| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.331 | a_loss: 0.558
Train: Epoch [2853/3000], Step [150/158]| g_loss: 0.651| d_loss: 0.602| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.065| v_loss: 0.018| per_loss: 0.310 | a_loss: 0.522
Train: Epoch [2854/3000], Step [30/158]| g_loss: 0.679| d_loss: 0.762| gp_loss: 0.197| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.327 | a_loss: 0.549
Train: Epoch [2854/3000], Step [60/158]| g_loss: 0.658| d_loss: 0.666| gp_loss: 0.052| r_loss: 0.044| p_loss: 0.058| v_loss: 0.018| per_loss: 0.325 | a_loss: 0.534
Train: Epoch [2854/3000], Step [90/158]| g_loss: 0.640| d_loss: 0.652| gp_loss: 0.048| r_loss: 0.047| p_loss: 0.063| v_loss: 0.020| per_loss: 0.324 | a_loss: 0.509
Train: Epoch [2854/3000], Step [120/158]| g_loss: 0.641| d_loss: 0.599| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.293 | a_loss: 0.516
Train: Epoch [2854/3000], Step [150/158]| g_loss: 0.624| d_loss: 0.611| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.057| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.498
Train: Epoch [2855/3000], Step [30/158]| g_loss: 0.654| d_loss: 0.831| gp_loss: 0.265| r_loss: 0.045| p_loss: 0.059| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.529
Train: Epoch [2855/3000], Step [60/158]| g_loss: 0.645| d_loss: 0.663| gp_loss: 0.049| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.324 | a_loss: 0.515
Train: Epoch [2855/3000], Step [90/158]| g_loss: 0.640| d_loss: 0.606| gp_loss: 0.048| r_loss: 0.046| p_loss: 0.057| v_loss: 0.018| per_loss: 0.306 | a_loss: 0.516
Train: Epoch [2855/3000], Step [120/158]| g_loss: 0.640| d_loss: 0.647| gp_loss: 0.050| r_loss: 0.045| p_loss: 0.057| v_loss: 0.019| per_loss: 0.324 | a_loss: 0.515
Train: Epoch [2855/3000], Step [150/158]| g_loss: 0.644| d_loss: 0.513| gp_loss: 0.052| r_loss: 0.045| p_loss: 0.054| v_loss: 0.018| per_loss: 0.320 | a_loss: 0.522
Train: Epoch [2856/3000], Step [30/158]| g_loss: 0.677| d_loss: 0.746| gp_loss: 0.185| r_loss: 0.046| p_loss: 0.058| v_loss: 0.018| per_loss: 0.313 | a_loss: 0.552
Train: Epoch [2856/3000], Step [60/158]| g_loss: 0.685| d_loss: 0.604| gp_loss: 0.047| r_loss: 0.048| p_loss: 0.060| v_loss: 0.020| per_loss: 0.326 | a_loss: 0.555
Train: Epoch [2856/3000], Step [90/158]| g_loss: 0.664| d_loss: 0.543| gp_loss: 0.049| r_loss: 0.045| p_loss: 0.055| v_loss: 0.018| per_loss: 0.325 | a_loss: 0.540
Train: Epoch [2856/3000], Step [120/158]| g_loss: 0.658| d_loss: 0.631| gp_loss: 0.049| r_loss: 0.043| p_loss: 0.057| v_loss: 0.018| per_loss: 0.296 | a_loss: 0.539
Train: Epoch [2856/3000], Step [150/158]| g_loss: 0.625| d_loss: 0.678| gp_loss: 0.049| r_loss: 0.045| p_loss: 0.056| v_loss: 0.018| per_loss: 0.312 | a_loss: 0.502
Train: Epoch [2857/3000], Step [30/158]| g_loss: 0.677| d_loss: 0.741| gp_loss: 0.186| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.549
Train: Epoch [2857/3000], Step [60/158]| g_loss: 0.632| d_loss: 0.642| gp_loss: 0.046| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.506
Train: Epoch [2857/3000], Step [90/158]| g_loss: 0.686| d_loss: 0.468| gp_loss: 0.046| r_loss: 0.046| p_loss: 0.057| v_loss: 0.018| per_loss: 0.303 | a_loss: 0.563
Train: Epoch [2857/3000], Step [120/158]| g_loss: 0.691| d_loss: 0.581| gp_loss: 0.045| r_loss: 0.046| p_loss: 0.058| v_loss: 0.019| per_loss: 0.325 | a_loss: 0.565
Train: Epoch [2857/3000], Step [150/158]| g_loss: 0.644| d_loss: 0.724| gp_loss: 0.046| r_loss: 0.043| p_loss: 0.054| v_loss: 0.018| per_loss: 0.318 | a_loss: 0.525
Train: Epoch [2858/3000], Step [30/158]| g_loss: 0.602| d_loss: 0.734| gp_loss: 0.159| r_loss: 0.045| p_loss: 0.056| v_loss: 0.018| per_loss: 0.300 | a_loss: 0.481
Train: Epoch [2858/3000], Step [60/158]| g_loss: 0.613| d_loss: 0.685| gp_loss: 0.048| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.315 | a_loss: 0.485
Train: Epoch [2858/3000], Step [90/158]| g_loss: 0.641| d_loss: 0.557| gp_loss: 0.050| r_loss: 0.044| p_loss: 0.056| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.520
Train: Epoch [2858/3000], Step [120/158]| g_loss: 0.684| d_loss: 0.533| gp_loss: 0.052| r_loss: 0.046| p_loss: 0.058| v_loss: 0.018| per_loss: 0.309 | a_loss: 0.561
Train: Epoch [2858/3000], Step [150/158]| g_loss: 0.666| d_loss: 0.611| gp_loss: 0.050| r_loss: 0.045| p_loss: 0.057| v_loss: 0.018| per_loss: 0.316 | a_loss: 0.543
Train: Epoch [2859/3000], Step [30/158]| g_loss: 0.703| d_loss: 0.664| gp_loss: 0.129| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.319 | a_loss: 0.575
Train: Epoch [2859/3000], Step [60/158]| g_loss: 0.675| d_loss: 0.586| gp_loss: 0.047| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.335 | a_loss: 0.547
Train: Epoch [2859/3000], Step [90/158]| g_loss: 0.638| d_loss: 0.590| gp_loss: 0.053| r_loss: 0.045| p_loss: 0.058| v_loss: 0.018| per_loss: 0.330 | a_loss: 0.512
Train: Epoch [2859/3000], Step [120/158]| g_loss: 0.684| d_loss: 0.537| gp_loss: 0.051| r_loss: 0.044| p_loss: 0.060| v_loss: 0.018| per_loss: 0.295 | a_loss: 0.562
Train: Epoch [2859/3000], Step [150/158]| g_loss: 0.686| d_loss: 0.622| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.557
Train: Epoch [2860/3000], Step [30/158]| g_loss: 0.605| d_loss: 0.817| gp_loss: 0.111| r_loss: 0.047| p_loss: 0.059| v_loss: 0.018| per_loss: 0.310 | a_loss: 0.479
Train: Epoch [2860/3000], Step [60/158]| g_loss: 0.602| d_loss: 0.623| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.471
Train: Epoch [2860/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.603| gp_loss: 0.057| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.319 | a_loss: 0.529
Train: Epoch [2860/3000], Step [120/158]| g_loss: 0.633| d_loss: 0.554| gp_loss: 0.058| r_loss: 0.045| p_loss: 0.061| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.506
Train: Epoch [2860/3000], Step [150/158]| g_loss: 0.699| d_loss: 0.558| gp_loss: 0.062| r_loss: 0.045| p_loss: 0.060| v_loss: 0.018| per_loss: 0.327 | a_loss: 0.573
Train: Epoch [2861/3000], Step [30/158]| g_loss: 0.673| d_loss: 0.747| gp_loss: 0.153| r_loss: 0.047| p_loss: 0.063| v_loss: 0.020| per_loss: 0.341 | a_loss: 0.541
Train: Epoch [2861/3000], Step [60/158]| g_loss: 0.670| d_loss: 0.678| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.062| v_loss: 0.018| per_loss: 0.335 | a_loss: 0.539
Train: Epoch [2861/3000], Step [90/158]| g_loss: 0.629| d_loss: 0.602| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.308 | a_loss: 0.502
Train: Epoch [2861/3000], Step [120/158]| g_loss: 0.700| d_loss: 0.555| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.057| v_loss: 0.019| per_loss: 0.319 | a_loss: 0.574
Train: Epoch [2861/3000], Step [150/158]| g_loss: 0.638| d_loss: 0.561| gp_loss: 0.056| r_loss: 0.045| p_loss: 0.058| v_loss: 0.018| per_loss: 0.311 | a_loss: 0.515
Train: Epoch [2862/3000], Step [30/158]| g_loss: 0.683| d_loss: 0.700| gp_loss: 0.158| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.315 | a_loss: 0.557
Train: Epoch [2862/3000], Step [60/158]| g_loss: 0.645| d_loss: 0.668| gp_loss: 0.050| r_loss: 0.046| p_loss: 0.056| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.520
Train: Epoch [2862/3000], Step [90/158]| g_loss: 0.641| d_loss: 0.637| gp_loss: 0.051| r_loss: 0.048| p_loss: 0.059| v_loss: 0.019| per_loss: 0.334 | a_loss: 0.512
Train: Epoch [2862/3000], Step [120/158]| g_loss: 0.697| d_loss: 0.535| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.572
Train: Epoch [2862/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.663| gp_loss: 0.056| r_loss: 0.045| p_loss: 0.058| v_loss: 0.018| per_loss: 0.312 | a_loss: 0.535
Train: Epoch [2863/3000], Step [30/158]| g_loss: 0.675| d_loss: 0.681| gp_loss: 0.164| r_loss: 0.045| p_loss: 0.059| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.549
Train: Epoch [2863/3000], Step [60/158]| g_loss: 0.608| d_loss: 0.710| gp_loss: 0.050| r_loss: 0.045| p_loss: 0.061| v_loss: 0.018| per_loss: 0.315 | a_loss: 0.483
Train: Epoch [2863/3000], Step [90/158]| g_loss: 0.637| d_loss: 0.563| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.511
Train: Epoch [2863/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.641| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.318 | a_loss: 0.549
Train: Epoch [2863/3000], Step [150/158]| g_loss: 0.672| d_loss: 0.555| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.063| v_loss: 0.020| per_loss: 0.340 | a_loss: 0.538
Train: Epoch [2864/3000], Step [30/158]| g_loss: 0.679| d_loss: 0.700| gp_loss: 0.175| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.549
Train: Epoch [2864/3000], Step [60/158]| g_loss: 0.680| d_loss: 0.633| gp_loss: 0.051| r_loss: 0.048| p_loss: 0.059| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.552
Train: Epoch [2864/3000], Step [90/158]| g_loss: 0.648| d_loss: 0.596| gp_loss: 0.055| r_loss: 0.045| p_loss: 0.061| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.523
Train: Epoch [2864/3000], Step [120/158]| g_loss: 0.681| d_loss: 0.596| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.062| v_loss: 0.018| per_loss: 0.311 | a_loss: 0.554
Train: Epoch [2864/3000], Step [150/158]| g_loss: 0.676| d_loss: 0.597| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.329 | a_loss: 0.543
Train: Epoch [2865/3000], Step [30/158]| g_loss: 0.628| d_loss: 0.778| gp_loss: 0.172| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.500
Train: Epoch [2865/3000], Step [60/158]| g_loss: 0.629| d_loss: 0.610| gp_loss: 0.049| r_loss: 0.046| p_loss: 0.060| v_loss: 0.018| per_loss: 0.305 | a_loss: 0.504
Train: Epoch [2865/3000], Step [90/158]| g_loss: 0.636| d_loss: 0.613| gp_loss: 0.050| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.510
Train: Epoch [2865/3000], Step [120/158]| g_loss: 0.678| d_loss: 0.599| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.061| v_loss: 0.020| per_loss: 0.329 | a_loss: 0.547
Train: Epoch [2865/3000], Step [150/158]| g_loss: 0.694| d_loss: 0.547| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.342 | a_loss: 0.563
Train: Epoch [2866/3000], Step [30/158]| g_loss: 0.699| d_loss: 0.616| gp_loss: 0.125| r_loss: 0.048| p_loss: 0.060| v_loss: 0.018| per_loss: 0.334 | a_loss: 0.569
Train: Epoch [2866/3000], Step [60/158]| g_loss: 0.669| d_loss: 0.669| gp_loss: 0.052| r_loss: 0.048| p_loss: 0.059| v_loss: 0.019| per_loss: 0.315 | a_loss: 0.542
Train: Epoch [2866/3000], Step [90/158]| g_loss: 0.633| d_loss: 0.662| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.507
Train: Epoch [2866/3000], Step [120/158]| g_loss: 0.634| d_loss: 0.584| gp_loss: 0.056| r_loss: 0.045| p_loss: 0.060| v_loss: 0.019| per_loss: 0.319 | a_loss: 0.509
Train: Epoch [2866/3000], Step [150/158]| g_loss: 0.668| d_loss: 0.579| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.542
Train: Epoch [2867/3000], Step [30/158]| g_loss: 0.670| d_loss: 0.724| gp_loss: 0.170| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.333 | a_loss: 0.537
Train: Epoch [2867/3000], Step [60/158]| g_loss: 0.675| d_loss: 0.619| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.058| v_loss: 0.019| per_loss: 0.315 | a_loss: 0.549
Train: Epoch [2867/3000], Step [90/158]| g_loss: 0.658| d_loss: 0.604| gp_loss: 0.053| r_loss: 0.045| p_loss: 0.059| v_loss: 0.019| per_loss: 0.302 | a_loss: 0.534
Train: Epoch [2867/3000], Step [120/158]| g_loss: 0.683| d_loss: 0.576| gp_loss: 0.059| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.328 | a_loss: 0.554
Train: Epoch [2867/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.635| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.064| v_loss: 0.018| per_loss: 0.325 | a_loss: 0.545
Train: Epoch [2868/3000], Step [30/158]| g_loss: 0.655| d_loss: 0.715| gp_loss: 0.192| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.525
Train: Epoch [2868/3000], Step [60/158]| g_loss: 0.652| d_loss: 0.599| gp_loss: 0.050| r_loss: 0.048| p_loss: 0.060| v_loss: 0.018| per_loss: 0.315 | a_loss: 0.523
Train: Epoch [2868/3000], Step [90/158]| g_loss: 0.640| d_loss: 0.638| gp_loss: 0.050| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.515
Train: Epoch [2868/3000], Step [120/158]| g_loss: 0.689| d_loss: 0.572| gp_loss: 0.055| r_loss: 0.050| p_loss: 0.063| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.558
Train: Epoch [2868/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.652| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.318 | a_loss: 0.530
Train: Epoch [2869/3000], Step [30/158]| g_loss: 0.650| d_loss: 0.768| gp_loss: 0.185| r_loss: 0.049| p_loss: 0.061| v_loss: 0.018| per_loss: 0.327 | a_loss: 0.520
Train: Epoch [2869/3000], Step [60/158]| g_loss: 0.625| d_loss: 0.578| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.318 | a_loss: 0.494
Train: Epoch [2869/3000], Step [90/158]| g_loss: 0.659| d_loss: 0.666| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.064| v_loss: 0.018| per_loss: 0.314 | a_loss: 0.527
Train: Epoch [2869/3000], Step [120/158]| g_loss: 0.650| d_loss: 0.534| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.523
Train: Epoch [2869/3000], Step [150/158]| g_loss: 0.665| d_loss: 0.640| gp_loss: 0.061| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.322 | a_loss: 0.536
Train: Epoch [2870/3000], Step [30/158]| g_loss: 0.680| d_loss: 0.661| gp_loss: 0.129| r_loss: 0.045| p_loss: 0.060| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.555
Train: Epoch [2870/3000], Step [60/158]| g_loss: 0.675| d_loss: 0.569| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.547
Train: Epoch [2870/3000], Step [90/158]| g_loss: 0.636| d_loss: 0.659| gp_loss: 0.054| r_loss: 0.045| p_loss: 0.060| v_loss: 0.019| per_loss: 0.323 | a_loss: 0.510
Train: Epoch [2870/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.616| gp_loss: 0.057| r_loss: 0.045| p_loss: 0.061| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.550
Train: Epoch [2870/3000], Step [150/158]| g_loss: 0.668| d_loss: 0.542| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.059| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.541
Train: Epoch [2871/3000], Step [30/158]| g_loss: 0.657| d_loss: 0.771| gp_loss: 0.177| r_loss: 0.048| p_loss: 0.059| v_loss: 0.019| per_loss: 0.305 | a_loss: 0.530
Train: Epoch [2871/3000], Step [60/158]| g_loss: 0.647| d_loss: 0.619| gp_loss: 0.054| r_loss: 0.044| p_loss: 0.058| v_loss: 0.018| per_loss: 0.315 | a_loss: 0.523
Train: Epoch [2871/3000], Step [90/158]| g_loss: 0.660| d_loss: 0.597| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.334 | a_loss: 0.530
Train: Epoch [2871/3000], Step [120/158]| g_loss: 0.684| d_loss: 0.587| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.061| v_loss: 0.020| per_loss: 0.332 | a_loss: 0.553
Train: Epoch [2871/3000], Step [150/158]| g_loss: 0.671| d_loss: 0.604| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.318 | a_loss: 0.545
Train: Epoch [2872/3000], Step [30/158]| g_loss: 0.651| d_loss: 0.689| gp_loss: 0.125| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.322 | a_loss: 0.523
Train: Epoch [2872/3000], Step [60/158]| g_loss: 0.632| d_loss: 0.652| gp_loss: 0.056| r_loss: 0.045| p_loss: 0.058| v_loss: 0.018| per_loss: 0.319 | a_loss: 0.507
Train: Epoch [2872/3000], Step [90/158]| g_loss: 0.651| d_loss: 0.641| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.058| v_loss: 0.019| per_loss: 0.328 | a_loss: 0.525
Train: Epoch [2872/3000], Step [120/158]| g_loss: 0.671| d_loss: 0.541| gp_loss: 0.058| r_loss: 0.043| p_loss: 0.056| v_loss: 0.019| per_loss: 0.309 | a_loss: 0.550
Train: Epoch [2872/3000], Step [150/158]| g_loss: 0.676| d_loss: 0.605| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.327 | a_loss: 0.548
Train: Epoch [2873/3000], Step [30/158]| g_loss: 0.639| d_loss: 0.738| gp_loss: 0.128| r_loss: 0.050| p_loss: 0.060| v_loss: 0.019| per_loss: 0.329 | a_loss: 0.507
Train: Epoch [2873/3000], Step [60/158]| g_loss: 0.626| d_loss: 0.601| gp_loss: 0.057| r_loss: 0.044| p_loss: 0.057| v_loss: 0.018| per_loss: 0.313 | a_loss: 0.504
Train: Epoch [2873/3000], Step [90/158]| g_loss: 0.660| d_loss: 0.536| gp_loss: 0.057| r_loss: 0.044| p_loss: 0.055| v_loss: 0.018| per_loss: 0.305 | a_loss: 0.540
Train: Epoch [2873/3000], Step [120/158]| g_loss: 0.679| d_loss: 0.615| gp_loss: 0.061| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.551
Train: Epoch [2873/3000], Step [150/158]| g_loss: 0.687| d_loss: 0.637| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.330 | a_loss: 0.557
Train: Epoch [2874/3000], Step [30/158]| g_loss: 0.674| d_loss: 0.679| gp_loss: 0.110| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.322 | a_loss: 0.546
Train: Epoch [2874/3000], Step [60/158]| g_loss: 0.633| d_loss: 0.634| gp_loss: 0.056| r_loss: 0.044| p_loss: 0.058| v_loss: 0.019| per_loss: 0.325 | a_loss: 0.509
Train: Epoch [2874/3000], Step [90/158]| g_loss: 0.664| d_loss: 0.571| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.335 | a_loss: 0.531
Train: Epoch [2874/3000], Step [120/158]| g_loss: 0.683| d_loss: 0.647| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.061| v_loss: 0.018| per_loss: 0.323 | a_loss: 0.552
Train: Epoch [2874/3000], Step [150/158]| g_loss: 0.644| d_loss: 0.595| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.514
Train: Epoch [2875/3000], Step [30/158]| g_loss: 0.638| d_loss: 0.698| gp_loss: 0.133| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.341 | a_loss: 0.506
Train: Epoch [2875/3000], Step [60/158]| g_loss: 0.675| d_loss: 0.600| gp_loss: 0.059| r_loss: 0.051| p_loss: 0.066| v_loss: 0.020| per_loss: 0.342 | a_loss: 0.537
Train: Epoch [2875/3000], Step [90/158]| g_loss: 0.671| d_loss: 0.608| gp_loss: 0.058| r_loss: 0.054| p_loss: 0.072| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.531
Train: Epoch [2875/3000], Step [120/158]| g_loss: 0.691| d_loss: 0.632| gp_loss: 0.057| r_loss: 0.057| p_loss: 0.076| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.545
Train: Epoch [2875/3000], Step [150/158]| g_loss: 0.681| d_loss: 0.603| gp_loss: 0.057| r_loss: 0.054| p_loss: 0.079| v_loss: 0.019| per_loss: 0.326 | a_loss: 0.537
Train: Epoch [2876/3000], Step [30/158]| g_loss: 0.707| d_loss: 0.640| gp_loss: 0.165| r_loss: 0.051| p_loss: 0.076| v_loss: 0.019| per_loss: 0.332 | a_loss: 0.566
Train: Epoch [2876/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.628| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.070| v_loss: 0.019| per_loss: 0.338 | a_loss: 0.535
Train: Epoch [2876/3000], Step [90/158]| g_loss: 0.663| d_loss: 0.609| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.535
Train: Epoch [2876/3000], Step [120/158]| g_loss: 0.638| d_loss: 0.645| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.322 | a_loss: 0.510
Train: Epoch [2876/3000], Step [150/158]| g_loss: 0.647| d_loss: 0.627| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.332 | a_loss: 0.518
Train: Epoch [2877/3000], Step [30/158]| g_loss: 0.633| d_loss: 0.783| gp_loss: 0.187| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.334 | a_loss: 0.503
Train: Epoch [2877/3000], Step [60/158]| g_loss: 0.637| d_loss: 0.608| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.333 | a_loss: 0.506
Train: Epoch [2877/3000], Step [90/158]| g_loss: 0.676| d_loss: 0.580| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.062| v_loss: 0.018| per_loss: 0.311 | a_loss: 0.550
Train: Epoch [2877/3000], Step [120/158]| g_loss: 0.660| d_loss: 0.640| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.066| v_loss: 0.019| per_loss: 0.333 | a_loss: 0.528
Train: Epoch [2877/3000], Step [150/158]| g_loss: 0.683| d_loss: 0.556| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.061| v_loss: 0.018| per_loss: 0.326 | a_loss: 0.554
Train: Epoch [2878/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.780| gp_loss: 0.177| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.354 | a_loss: 0.531
Train: Epoch [2878/3000], Step [60/158]| g_loss: 0.642| d_loss: 0.582| gp_loss: 0.051| r_loss: 0.045| p_loss: 0.057| v_loss: 0.018| per_loss: 0.335 | a_loss: 0.516
Train: Epoch [2878/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.624| gp_loss: 0.052| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.323 | a_loss: 0.526
Train: Epoch [2878/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.500| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.056| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.552
Train: Epoch [2878/3000], Step [150/158]| g_loss: 0.654| d_loss: 0.680| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.332 | a_loss: 0.525
Train: Epoch [2879/3000], Step [30/158]| g_loss: 0.668| d_loss: 0.642| gp_loss: 0.126| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.331 | a_loss: 0.538
Train: Epoch [2879/3000], Step [60/158]| g_loss: 0.679| d_loss: 0.577| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.364 | a_loss: 0.549
Train: Epoch [2879/3000], Step [90/158]| g_loss: 0.652| d_loss: 0.707| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.061| v_loss: 0.018| per_loss: 0.318 | a_loss: 0.524
Train: Epoch [2879/3000], Step [120/158]| g_loss: 0.663| d_loss: 0.524| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.326 | a_loss: 0.536
Train: Epoch [2879/3000], Step [150/158]| g_loss: 0.648| d_loss: 0.656| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.058| v_loss: 0.020| per_loss: 0.328 | a_loss: 0.521
Train: Epoch [2880/3000], Step [30/158]| g_loss: 0.654| d_loss: 0.673| gp_loss: 0.151| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.338 | a_loss: 0.525
Train: Epoch [2880/3000], Step [60/158]| g_loss: 0.708| d_loss: 0.510| gp_loss: 0.057| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.582
Train: Epoch [2880/3000], Step [90/158]| g_loss: 0.665| d_loss: 0.655| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.326 | a_loss: 0.534
Train: Epoch [2880/3000], Step [120/158]| g_loss: 0.645| d_loss: 0.587| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.324 | a_loss: 0.516
Train: Epoch [2880/3000], Step [150/158]| g_loss: 0.694| d_loss: 0.597| gp_loss: 0.057| r_loss: 0.059| p_loss: 0.070| v_loss: 0.020| per_loss: 0.336 | a_loss: 0.547
Train: Epoch [2881/3000], Step [30/158]| g_loss: 0.627| d_loss: 0.779| gp_loss: 0.113| r_loss: 0.051| p_loss: 0.076| v_loss: 0.019| per_loss: 0.337 | a_loss: 0.486
Train: Epoch [2881/3000], Step [60/158]| g_loss: 0.672| d_loss: 0.609| gp_loss: 0.057| r_loss: 0.057| p_loss: 0.078| v_loss: 0.020| per_loss: 0.362 | a_loss: 0.520
Train: Epoch [2881/3000], Step [90/158]| g_loss: 0.638| d_loss: 0.636| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.068| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.505
Train: Epoch [2881/3000], Step [120/158]| g_loss: 0.678| d_loss: 0.614| gp_loss: 0.061| r_loss: 0.046| p_loss: 0.064| v_loss: 0.019| per_loss: 0.348 | a_loss: 0.546
Train: Epoch [2881/3000], Step [150/158]| g_loss: 0.647| d_loss: 0.572| gp_loss: 0.062| r_loss: 0.049| p_loss: 0.063| v_loss: 0.020| per_loss: 0.309 | a_loss: 0.516
Train: Epoch [2882/3000], Step [30/158]| g_loss: 0.689| d_loss: 0.764| gp_loss: 0.187| r_loss: 0.049| p_loss: 0.068| v_loss: 0.019| per_loss: 0.336 | a_loss: 0.553
Train: Epoch [2882/3000], Step [60/158]| g_loss: 0.641| d_loss: 0.646| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.066| v_loss: 0.019| per_loss: 0.352 | a_loss: 0.507
Train: Epoch [2882/3000], Step [90/158]| g_loss: 0.672| d_loss: 0.568| gp_loss: 0.057| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.340 | a_loss: 0.542
Train: Epoch [2882/3000], Step [120/158]| g_loss: 0.663| d_loss: 0.643| gp_loss: 0.064| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.337 | a_loss: 0.531
Train: Epoch [2882/3000], Step [150/158]| g_loss: 0.654| d_loss: 0.584| gp_loss: 0.059| r_loss: 0.046| p_loss: 0.061| v_loss: 0.020| per_loss: 0.306 | a_loss: 0.528
Train: Epoch [2883/3000], Step [30/158]| g_loss: 0.650| d_loss: 0.794| gp_loss: 0.194| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.339 | a_loss: 0.517
Train: Epoch [2883/3000], Step [60/158]| g_loss: 0.671| d_loss: 0.584| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.335 | a_loss: 0.542
Train: Epoch [2883/3000], Step [90/158]| g_loss: 0.663| d_loss: 0.540| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.059| v_loss: 0.019| per_loss: 0.326 | a_loss: 0.534
Train: Epoch [2883/3000], Step [120/158]| g_loss: 0.697| d_loss: 0.614| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.321 | a_loss: 0.565
Train: Epoch [2883/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.643| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.344 | a_loss: 0.529
Train: Epoch [2884/3000], Step [30/158]| g_loss: 0.649| d_loss: 0.745| gp_loss: 0.163| r_loss: 0.048| p_loss: 0.067| v_loss: 0.019| per_loss: 0.331 | a_loss: 0.516
Train: Epoch [2884/3000], Step [60/158]| g_loss: 0.681| d_loss: 0.537| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.323 | a_loss: 0.552
Train: Epoch [2884/3000], Step [90/158]| g_loss: 0.646| d_loss: 0.579| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.325 | a_loss: 0.518
Train: Epoch [2884/3000], Step [120/158]| g_loss: 0.669| d_loss: 0.719| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.064| v_loss: 0.020| per_loss: 0.343 | a_loss: 0.536
Train: Epoch [2884/3000], Step [150/158]| g_loss: 0.664| d_loss: 0.558| gp_loss: 0.061| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.322 | a_loss: 0.537
Train: Epoch [2885/3000], Step [30/158]| g_loss: 0.653| d_loss: 0.700| gp_loss: 0.182| r_loss: 0.045| p_loss: 0.057| v_loss: 0.019| per_loss: 0.328 | a_loss: 0.528
Train: Epoch [2885/3000], Step [60/158]| g_loss: 0.661| d_loss: 0.620| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.339 | a_loss: 0.533
Train: Epoch [2885/3000], Step [90/158]| g_loss: 0.638| d_loss: 0.673| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.325 | a_loss: 0.509
Train: Epoch [2885/3000], Step [120/158]| g_loss: 0.651| d_loss: 0.645| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.062| v_loss: 0.020| per_loss: 0.326 | a_loss: 0.522
Train: Epoch [2885/3000], Step [150/158]| g_loss: 0.693| d_loss: 0.571| gp_loss: 0.061| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.344 | a_loss: 0.559
Train: Epoch [2886/3000], Step [30/158]| g_loss: 0.683| d_loss: 0.612| gp_loss: 0.118| r_loss: 0.056| p_loss: 0.072| v_loss: 0.019| per_loss: 0.337 | a_loss: 0.538
Train: Epoch [2886/3000], Step [60/158]| g_loss: 0.722| d_loss: 0.575| gp_loss: 0.056| r_loss: 0.054| p_loss: 0.069| v_loss: 0.020| per_loss: 0.345 | a_loss: 0.579
Train: Epoch [2886/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.553| gp_loss: 0.062| r_loss: 0.046| p_loss: 0.061| v_loss: 0.018| per_loss: 0.327 | a_loss: 0.529
Train: Epoch [2886/3000], Step [120/158]| g_loss: 0.689| d_loss: 0.565| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.558
Train: Epoch [2886/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.747| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.062| v_loss: 0.018| per_loss: 0.345 | a_loss: 0.536
Train: Epoch [2887/3000], Step [30/158]| g_loss: 0.667| d_loss: 0.644| gp_loss: 0.165| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.354 | a_loss: 0.534
Train: Epoch [2887/3000], Step [60/158]| g_loss: 0.633| d_loss: 0.654| gp_loss: 0.055| r_loss: 0.045| p_loss: 0.059| v_loss: 0.019| per_loss: 0.323 | a_loss: 0.508
Train: Epoch [2887/3000], Step [90/158]| g_loss: 0.636| d_loss: 0.657| gp_loss: 0.055| r_loss: 0.045| p_loss: 0.061| v_loss: 0.019| per_loss: 0.340 | a_loss: 0.507
Train: Epoch [2887/3000], Step [120/158]| g_loss: 0.661| d_loss: 0.642| gp_loss: 0.062| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.340 | a_loss: 0.527
Train: Epoch [2887/3000], Step [150/158]| g_loss: 0.663| d_loss: 0.629| gp_loss: 0.064| r_loss: 0.051| p_loss: 0.061| v_loss: 0.019| per_loss: 0.329 | a_loss: 0.530
Train: Epoch [2888/3000], Step [30/158]| g_loss: 0.672| d_loss: 0.741| gp_loss: 0.166| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.347 | a_loss: 0.542
Train: Epoch [2888/3000], Step [60/158]| g_loss: 0.629| d_loss: 0.574| gp_loss: 0.054| r_loss: 0.045| p_loss: 0.059| v_loss: 0.018| per_loss: 0.334 | a_loss: 0.503
Train: Epoch [2888/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.582| gp_loss: 0.059| r_loss: 0.045| p_loss: 0.059| v_loss: 0.019| per_loss: 0.330 | a_loss: 0.528
Train: Epoch [2888/3000], Step [120/158]| g_loss: 0.694| d_loss: 0.627| gp_loss: 0.060| r_loss: 0.049| p_loss: 0.063| v_loss: 0.020| per_loss: 0.311 | a_loss: 0.563
Train: Epoch [2888/3000], Step [150/158]| g_loss: 0.657| d_loss: 0.639| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.063| v_loss: 0.019| per_loss: 0.337 | a_loss: 0.527
Train: Epoch [2889/3000], Step [30/158]| g_loss: 0.716| d_loss: 0.670| gp_loss: 0.199| r_loss: 0.047| p_loss: 0.061| v_loss: 0.020| per_loss: 0.349 | a_loss: 0.584
Train: Epoch [2889/3000], Step [60/158]| g_loss: 0.654| d_loss: 0.641| gp_loss: 0.052| r_loss: 0.045| p_loss: 0.059| v_loss: 0.019| per_loss: 0.330 | a_loss: 0.527
Train: Epoch [2889/3000], Step [90/158]| g_loss: 0.657| d_loss: 0.583| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.059| v_loss: 0.020| per_loss: 0.340 | a_loss: 0.528
Train: Epoch [2889/3000], Step [120/158]| g_loss: 0.657| d_loss: 0.657| gp_loss: 0.052| r_loss: 0.046| p_loss: 0.060| v_loss: 0.018| per_loss: 0.335 | a_loss: 0.529
Train: Epoch [2889/3000], Step [150/158]| g_loss: 0.626| d_loss: 0.714| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.334 | a_loss: 0.492
Train: Epoch [2890/3000], Step [30/158]| g_loss: 0.640| d_loss: 0.732| gp_loss: 0.180| r_loss: 0.048| p_loss: 0.062| v_loss: 0.020| per_loss: 0.342 | a_loss: 0.506
Train: Epoch [2890/3000], Step [60/158]| g_loss: 0.678| d_loss: 0.556| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.063| v_loss: 0.020| per_loss: 0.337 | a_loss: 0.547
Train: Epoch [2890/3000], Step [90/158]| g_loss: 0.597| d_loss: 0.739| gp_loss: 0.055| r_loss: 0.045| p_loss: 0.060| v_loss: 0.019| per_loss: 0.342 | a_loss: 0.469
Train: Epoch [2890/3000], Step [120/158]| g_loss: 0.662| d_loss: 0.530| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.338 | a_loss: 0.532
Train: Epoch [2890/3000], Step [150/158]| g_loss: 0.677| d_loss: 0.584| gp_loss: 0.062| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.334 | a_loss: 0.548
Train: Epoch [2891/3000], Step [30/158]| g_loss: 0.676| d_loss: 0.701| gp_loss: 0.197| r_loss: 0.046| p_loss: 0.061| v_loss: 0.020| per_loss: 0.317 | a_loss: 0.548
Train: Epoch [2891/3000], Step [60/158]| g_loss: 0.658| d_loss: 0.604| gp_loss: 0.051| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.327 | a_loss: 0.530
Train: Epoch [2891/3000], Step [90/158]| g_loss: 0.680| d_loss: 0.592| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.059| v_loss: 0.018| per_loss: 0.323 | a_loss: 0.552
Train: Epoch [2891/3000], Step [120/158]| g_loss: 0.671| d_loss: 0.652| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.060| v_loss: 0.018| per_loss: 0.317 | a_loss: 0.546
Train: Epoch [2891/3000], Step [150/158]| g_loss: 0.657| d_loss: 0.588| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.063| v_loss: 0.020| per_loss: 0.356 | a_loss: 0.523
Train: Epoch [2892/3000], Step [30/158]| g_loss: 0.629| d_loss: 0.704| gp_loss: 0.081| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.331 | a_loss: 0.499
Train: Epoch [2892/3000], Step [60/158]| g_loss: 0.673| d_loss: 0.540| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.060| v_loss: 0.020| per_loss: 0.326 | a_loss: 0.543
Train: Epoch [2892/3000], Step [90/158]| g_loss: 0.642| d_loss: 0.743| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.327 | a_loss: 0.507
Train: Epoch [2892/3000], Step [120/158]| g_loss: 0.631| d_loss: 0.557| gp_loss: 0.062| r_loss: 0.046| p_loss: 0.062| v_loss: 0.018| per_loss: 0.327 | a_loss: 0.503
Train: Epoch [2892/3000], Step [150/158]| g_loss: 0.674| d_loss: 0.600| gp_loss: 0.064| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.324 | a_loss: 0.546
Train: Epoch [2893/3000], Step [30/158]| g_loss: 0.659| d_loss: 0.743| gp_loss: 0.170| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.344 | a_loss: 0.525
Train: Epoch [2893/3000], Step [60/158]| g_loss: 0.663| d_loss: 0.597| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.061| v_loss: 0.020| per_loss: 0.335 | a_loss: 0.532
Train: Epoch [2893/3000], Step [90/158]| g_loss: 0.675| d_loss: 0.574| gp_loss: 0.059| r_loss: 0.044| p_loss: 0.058| v_loss: 0.019| per_loss: 0.327 | a_loss: 0.551
Train: Epoch [2893/3000], Step [120/158]| g_loss: 0.665| d_loss: 0.630| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.062| v_loss: 0.020| per_loss: 0.325 | a_loss: 0.535
Train: Epoch [2893/3000], Step [150/158]| g_loss: 0.703| d_loss: 0.572| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.328 | a_loss: 0.573
Train: Epoch [2894/3000], Step [30/158]| g_loss: 0.630| d_loss: 0.723| gp_loss: 0.093| r_loss: 0.046| p_loss: 0.064| v_loss: 0.020| per_loss: 0.326 | a_loss: 0.498
Train: Epoch [2894/3000], Step [60/158]| g_loss: 0.655| d_loss: 0.592| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.059| v_loss: 0.018| per_loss: 0.328 | a_loss: 0.529
Train: Epoch [2894/3000], Step [90/158]| g_loss: 0.631| d_loss: 0.635| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.336 | a_loss: 0.500
Train: Epoch [2894/3000], Step [120/158]| g_loss: 0.667| d_loss: 0.602| gp_loss: 0.064| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.344 | a_loss: 0.535
Train: Epoch [2894/3000], Step [150/158]| g_loss: 0.698| d_loss: 0.609| gp_loss: 0.067| r_loss: 0.048| p_loss: 0.059| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.568
Train: Epoch [2895/3000], Step [30/158]| g_loss: 0.628| d_loss: 0.756| gp_loss: 0.167| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.340 | a_loss: 0.496
Train: Epoch [2895/3000], Step [60/158]| g_loss: 0.668| d_loss: 0.622| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.063| v_loss: 0.020| per_loss: 0.337 | a_loss: 0.536
Train: Epoch [2895/3000], Step [90/158]| g_loss: 0.693| d_loss: 0.525| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.058| v_loss: 0.018| per_loss: 0.319 | a_loss: 0.567
Train: Epoch [2895/3000], Step [120/158]| g_loss: 0.691| d_loss: 0.630| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.063| v_loss: 0.020| per_loss: 0.338 | a_loss: 0.559
Train: Epoch [2895/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.610| gp_loss: 0.062| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.530
Train: Epoch [2896/3000], Step [30/158]| g_loss: 0.644| d_loss: 0.730| gp_loss: 0.189| r_loss: 0.044| p_loss: 0.057| v_loss: 0.019| per_loss: 0.331 | a_loss: 0.519
Train: Epoch [2896/3000], Step [60/158]| g_loss: 0.669| d_loss: 0.595| gp_loss: 0.055| r_loss: 0.044| p_loss: 0.061| v_loss: 0.019| per_loss: 0.336 | a_loss: 0.542
Train: Epoch [2896/3000], Step [90/158]| g_loss: 0.640| d_loss: 0.711| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.509
Train: Epoch [2896/3000], Step [120/158]| g_loss: 0.671| d_loss: 0.638| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.541
Train: Epoch [2896/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.571| gp_loss: 0.066| r_loss: 0.048| p_loss: 0.061| v_loss: 0.020| per_loss: 0.337 | a_loss: 0.530
Train: Epoch [2897/3000], Step [30/158]| g_loss: 0.667| d_loss: 0.639| gp_loss: 0.145| r_loss: 0.045| p_loss: 0.062| v_loss: 0.019| per_loss: 0.336 | a_loss: 0.538
Train: Epoch [2897/3000], Step [60/158]| g_loss: 0.658| d_loss: 0.598| gp_loss: 0.061| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.334 | a_loss: 0.527
Train: Epoch [2897/3000], Step [90/158]| g_loss: 0.724| d_loss: 0.579| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.067| v_loss: 0.020| per_loss: 0.322 | a_loss: 0.591
Train: Epoch [2897/3000], Step [120/158]| g_loss: 0.684| d_loss: 0.601| gp_loss: 0.062| r_loss: 0.048| p_loss: 0.058| v_loss: 0.019| per_loss: 0.322 | a_loss: 0.556
Train: Epoch [2897/3000], Step [150/158]| g_loss: 0.655| d_loss: 0.695| gp_loss: 0.061| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.335 | a_loss: 0.526
Train: Epoch [2898/3000], Step [30/158]| g_loss: 0.637| d_loss: 0.709| gp_loss: 0.135| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.342 | a_loss: 0.506
Train: Epoch [2898/3000], Step [60/158]| g_loss: 0.679| d_loss: 0.604| gp_loss: 0.057| r_loss: 0.045| p_loss: 0.064| v_loss: 0.020| per_loss: 0.341 | a_loss: 0.548
Train: Epoch [2898/3000], Step [90/158]| g_loss: 0.634| d_loss: 0.681| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.329 | a_loss: 0.502
Train: Epoch [2898/3000], Step [120/158]| g_loss: 0.652| d_loss: 0.581| gp_loss: 0.063| r_loss: 0.047| p_loss: 0.065| v_loss: 0.020| per_loss: 0.338 | a_loss: 0.519
Train: Epoch [2898/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.672| gp_loss: 0.064| r_loss: 0.051| p_loss: 0.070| v_loss: 0.020| per_loss: 0.337 | a_loss: 0.522
Train: Epoch [2899/3000], Step [30/158]| g_loss: 0.708| d_loss: 0.629| gp_loss: 0.153| r_loss: 0.047| p_loss: 0.067| v_loss: 0.018| per_loss: 0.327 | a_loss: 0.576
Train: Epoch [2899/3000], Step [60/158]| g_loss: 0.676| d_loss: 0.604| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.339 | a_loss: 0.543
Train: Epoch [2899/3000], Step [90/158]| g_loss: 0.652| d_loss: 0.626| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.066| v_loss: 0.020| per_loss: 0.344 | a_loss: 0.515
Train: Epoch [2899/3000], Step [120/158]| g_loss: 0.680| d_loss: 0.622| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.339 | a_loss: 0.547
Train: Epoch [2899/3000], Step [150/158]| g_loss: 0.661| d_loss: 0.584| gp_loss: 0.065| r_loss: 0.047| p_loss: 0.063| v_loss: 0.020| per_loss: 0.335 | a_loss: 0.529
Train: Epoch [2900/3000], Step [30/158]| g_loss: 0.628| d_loss: 0.778| gp_loss: 0.153| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.339 | a_loss: 0.499
Train: Epoch [2900/3000], Step [60/158]| g_loss: 0.666| d_loss: 0.573| gp_loss: 0.059| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.333 | a_loss: 0.535
Train: Epoch [2900/3000], Step [90/158]| g_loss: 0.674| d_loss: 0.568| gp_loss: 0.056| r_loss: 0.050| p_loss: 0.065| v_loss: 0.020| per_loss: 0.339 | a_loss: 0.538
Train: Epoch [2900/3000], Step [120/158]| g_loss: 0.648| d_loss: 0.688| gp_loss: 0.059| r_loss: 0.051| p_loss: 0.067| v_loss: 0.019| per_loss: 0.340 | a_loss: 0.510
Train: Epoch [2900/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.576| gp_loss: 0.061| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.337 | a_loss: 0.541
Test: Epoch [2900/3000]| g_loss: 0.626| r_loss: 0.388| p_loss: 0.289| v_loss: 0.020
Train: Epoch [2901/3000], Step [30/158]| g_loss: 0.697| d_loss: 0.584| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.060| v_loss: 0.018| per_loss: 0.339 | a_loss: 0.568
Train: Epoch [2901/3000], Step [60/158]| g_loss: 0.658| d_loss: 0.622| gp_loss: 0.051| r_loss: 0.048| p_loss: 0.059| v_loss: 0.019| per_loss: 0.337 | a_loss: 0.527
Train: Epoch [2901/3000], Step [90/158]| g_loss: 0.621| d_loss: 0.715| gp_loss: 0.054| r_loss: 0.048| p_loss: 0.068| v_loss: 0.019| per_loss: 0.330 | a_loss: 0.488
Train: Epoch [2901/3000], Step [120/158]| g_loss: 0.654| d_loss: 0.558| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.060| v_loss: 0.018| per_loss: 0.337 | a_loss: 0.525
Train: Epoch [2901/3000], Step [150/158]| g_loss: 0.656| d_loss: 0.607| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.347 | a_loss: 0.519
Train: Epoch [2902/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.718| gp_loss: 0.156| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.346 | a_loss: 0.529
Train: Epoch [2902/3000], Step [60/158]| g_loss: 0.630| d_loss: 0.670| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.061| v_loss: 0.018| per_loss: 0.331 | a_loss: 0.502
Train: Epoch [2902/3000], Step [90/158]| g_loss: 0.663| d_loss: 0.543| gp_loss: 0.063| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.335 | a_loss: 0.534
Train: Epoch [2902/3000], Step [120/158]| g_loss: 0.734| d_loss: 0.563| gp_loss: 0.059| r_loss: 0.051| p_loss: 0.065| v_loss: 0.020| per_loss: 0.381 | a_loss: 0.594
Train: Epoch [2902/3000], Step [150/158]| g_loss: 0.689| d_loss: 0.585| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.337 | a_loss: 0.556
Train: Epoch [2903/3000], Step [30/158]| g_loss: 0.674| d_loss: 0.738| gp_loss: 0.146| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.342 | a_loss: 0.543
Train: Epoch [2903/3000], Step [60/158]| g_loss: 0.628| d_loss: 0.586| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.367 | a_loss: 0.496
Train: Epoch [2903/3000], Step [90/158]| g_loss: 0.652| d_loss: 0.610| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.062| v_loss: 0.018| per_loss: 0.346 | a_loss: 0.521
Train: Epoch [2903/3000], Step [120/158]| g_loss: 0.698| d_loss: 0.525| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.347 | a_loss: 0.564
Train: Epoch [2903/3000], Step [150/158]| g_loss: 0.703| d_loss: 0.612| gp_loss: 0.064| r_loss: 0.048| p_loss: 0.065| v_loss: 0.019| per_loss: 0.343 | a_loss: 0.569
Train: Epoch [2904/3000], Step [30/158]| g_loss: 0.676| d_loss: 0.759| gp_loss: 0.208| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.363 | a_loss: 0.541
Train: Epoch [2904/3000], Step [60/158]| g_loss: 0.650| d_loss: 0.636| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.346 | a_loss: 0.518
Train: Epoch [2904/3000], Step [90/158]| g_loss: 0.698| d_loss: 0.578| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.067| v_loss: 0.020| per_loss: 0.364 | a_loss: 0.559
Train: Epoch [2904/3000], Step [120/158]| g_loss: 0.660| d_loss: 0.558| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.352 | a_loss: 0.525
Train: Epoch [2904/3000], Step [150/158]| g_loss: 0.692| d_loss: 0.669| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.067| v_loss: 0.019| per_loss: 0.332 | a_loss: 0.557
Train: Epoch [2905/3000], Step [30/158]| g_loss: 0.646| d_loss: 0.746| gp_loss: 0.141| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.342 | a_loss: 0.514
Train: Epoch [2905/3000], Step [60/158]| g_loss: 0.656| d_loss: 0.596| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.062| v_loss: 0.020| per_loss: 0.344 | a_loss: 0.521
Train: Epoch [2905/3000], Step [90/158]| g_loss: 0.665| d_loss: 0.606| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.344 | a_loss: 0.532
Train: Epoch [2905/3000], Step [120/158]| g_loss: 0.656| d_loss: 0.581| gp_loss: 0.059| r_loss: 0.045| p_loss: 0.060| v_loss: 0.019| per_loss: 0.337 | a_loss: 0.528
Train: Epoch [2905/3000], Step [150/158]| g_loss: 0.708| d_loss: 0.526| gp_loss: 0.059| r_loss: 0.046| p_loss: 0.060| v_loss: 0.018| per_loss: 0.335 | a_loss: 0.581
Train: Epoch [2906/3000], Step [30/158]| g_loss: 0.649| d_loss: 0.786| gp_loss: 0.180| r_loss: 0.045| p_loss: 0.060| v_loss: 0.019| per_loss: 0.336 | a_loss: 0.521
Train: Epoch [2906/3000], Step [60/158]| g_loss: 0.663| d_loss: 0.585| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.058| v_loss: 0.019| per_loss: 0.335 | a_loss: 0.534
Train: Epoch [2906/3000], Step [90/158]| g_loss: 0.669| d_loss: 0.627| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.063| v_loss: 0.019| per_loss: 0.341 | a_loss: 0.538
Train: Epoch [2906/3000], Step [120/158]| g_loss: 0.651| d_loss: 0.617| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.350 | a_loss: 0.516
Train: Epoch [2906/3000], Step [150/158]| g_loss: 0.639| d_loss: 0.594| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.061| v_loss: 0.019| per_loss: 0.346 | a_loss: 0.507
Train: Epoch [2907/3000], Step [30/158]| g_loss: 0.685| d_loss: 0.636| gp_loss: 0.128| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.330 | a_loss: 0.557
Train: Epoch [2907/3000], Step [60/158]| g_loss: 0.663| d_loss: 0.577| gp_loss: 0.057| r_loss: 0.046| p_loss: 0.059| v_loss: 0.018| per_loss: 0.333 | a_loss: 0.535
Train: Epoch [2907/3000], Step [90/158]| g_loss: 0.706| d_loss: 0.619| gp_loss: 0.058| r_loss: 0.045| p_loss: 0.061| v_loss: 0.019| per_loss: 0.342 | a_loss: 0.576
Train: Epoch [2907/3000], Step [120/158]| g_loss: 0.649| d_loss: 0.606| gp_loss: 0.062| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.344 | a_loss: 0.515
Train: Epoch [2907/3000], Step [150/158]| g_loss: 0.629| d_loss: 0.660| gp_loss: 0.065| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.330 | a_loss: 0.496
Train: Epoch [2908/3000], Step [30/158]| g_loss: 0.624| d_loss: 0.759| gp_loss: 0.177| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.340 | a_loss: 0.492
Train: Epoch [2908/3000], Step [60/158]| g_loss: 0.625| d_loss: 0.674| gp_loss: 0.056| r_loss: 0.045| p_loss: 0.059| v_loss: 0.019| per_loss: 0.340 | a_loss: 0.497
Train: Epoch [2908/3000], Step [90/158]| g_loss: 0.670| d_loss: 0.600| gp_loss: 0.064| r_loss: 0.048| p_loss: 0.069| v_loss: 0.020| per_loss: 0.343 | a_loss: 0.534
Train: Epoch [2908/3000], Step [120/158]| g_loss: 0.696| d_loss: 0.578| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.341 | a_loss: 0.564
Train: Epoch [2908/3000], Step [150/158]| g_loss: 0.666| d_loss: 0.583| gp_loss: 0.062| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.348 | a_loss: 0.531
Train: Epoch [2909/3000], Step [30/158]| g_loss: 0.661| d_loss: 0.703| gp_loss: 0.141| r_loss: 0.045| p_loss: 0.062| v_loss: 0.019| per_loss: 0.331 | a_loss: 0.533
Train: Epoch [2909/3000], Step [60/158]| g_loss: 0.629| d_loss: 0.653| gp_loss: 0.052| r_loss: 0.045| p_loss: 0.062| v_loss: 0.019| per_loss: 0.334 | a_loss: 0.501
Train: Epoch [2909/3000], Step [90/158]| g_loss: 0.722| d_loss: 0.525| gp_loss: 0.061| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.353 | a_loss: 0.589
Train: Epoch [2909/3000], Step [120/158]| g_loss: 0.673| d_loss: 0.633| gp_loss: 0.057| r_loss: 0.049| p_loss: 0.061| v_loss: 0.019| per_loss: 0.332 | a_loss: 0.542
Train: Epoch [2909/3000], Step [150/158]| g_loss: 0.659| d_loss: 0.662| gp_loss: 0.061| r_loss: 0.051| p_loss: 0.066| v_loss: 0.020| per_loss: 0.339 | a_loss: 0.522
Train: Epoch [2910/3000], Step [30/158]| g_loss: 0.685| d_loss: 0.630| gp_loss: 0.161| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.340 | a_loss: 0.554
Train: Epoch [2910/3000], Step [60/158]| g_loss: 0.624| d_loss: 0.691| gp_loss: 0.052| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.346 | a_loss: 0.494
Train: Epoch [2910/3000], Step [90/158]| g_loss: 0.664| d_loss: 0.555| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.065| v_loss: 0.020| per_loss: 0.342 | a_loss: 0.531
Train: Epoch [2910/3000], Step [120/158]| g_loss: 0.690| d_loss: 0.627| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.062| v_loss: 0.020| per_loss: 0.320 | a_loss: 0.558
Train: Epoch [2910/3000], Step [150/158]| g_loss: 0.648| d_loss: 0.655| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.327 | a_loss: 0.516
Train: Epoch [2911/3000], Step [30/158]| g_loss: 0.677| d_loss: 0.698| gp_loss: 0.195| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.339 | a_loss: 0.541
Train: Epoch [2911/3000], Step [60/158]| g_loss: 0.639| d_loss: 0.693| gp_loss: 0.051| r_loss: 0.051| p_loss: 0.064| v_loss: 0.020| per_loss: 0.346 | a_loss: 0.502
Train: Epoch [2911/3000], Step [90/158]| g_loss: 0.644| d_loss: 0.622| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.338 | a_loss: 0.513
Train: Epoch [2911/3000], Step [120/158]| g_loss: 0.656| d_loss: 0.597| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.061| v_loss: 0.018| per_loss: 0.324 | a_loss: 0.528
Train: Epoch [2911/3000], Step [150/158]| g_loss: 0.700| d_loss: 0.530| gp_loss: 0.062| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.351 | a_loss: 0.569
Train: Epoch [2912/3000], Step [30/158]| g_loss: 0.648| d_loss: 0.748| gp_loss: 0.136| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.333 | a_loss: 0.519
Train: Epoch [2912/3000], Step [60/158]| g_loss: 0.664| d_loss: 0.564| gp_loss: 0.058| r_loss: 0.049| p_loss: 0.065| v_loss: 0.020| per_loss: 0.344 | a_loss: 0.528
Train: Epoch [2912/3000], Step [90/158]| g_loss: 0.648| d_loss: 0.611| gp_loss: 0.057| r_loss: 0.050| p_loss: 0.062| v_loss: 0.019| per_loss: 0.329 | a_loss: 0.515
Train: Epoch [2912/3000], Step [120/158]| g_loss: 0.700| d_loss: 0.599| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.571
Train: Epoch [2912/3000], Step [150/158]| g_loss: 0.653| d_loss: 0.661| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.522
Train: Epoch [2913/3000], Step [30/158]| g_loss: 0.699| d_loss: 0.705| gp_loss: 0.181| r_loss: 0.047| p_loss: 0.065| v_loss: 0.019| per_loss: 0.326 | a_loss: 0.568
Train: Epoch [2913/3000], Step [60/158]| g_loss: 0.612| d_loss: 0.628| gp_loss: 0.054| r_loss: 0.050| p_loss: 0.063| v_loss: 0.019| per_loss: 0.336 | a_loss: 0.478
Train: Epoch [2913/3000], Step [90/158]| g_loss: 0.690| d_loss: 0.596| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.330 | a_loss: 0.563
Train: Epoch [2913/3000], Step [120/158]| g_loss: 0.671| d_loss: 0.593| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.059| v_loss: 0.019| per_loss: 0.327 | a_loss: 0.543
Train: Epoch [2913/3000], Step [150/158]| g_loss: 0.647| d_loss: 0.603| gp_loss: 0.060| r_loss: 0.046| p_loss: 0.063| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.519
Train: Epoch [2914/3000], Step [30/158]| g_loss: 0.633| d_loss: 0.703| gp_loss: 0.096| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.335 | a_loss: 0.501
Train: Epoch [2914/3000], Step [60/158]| g_loss: 0.671| d_loss: 0.493| gp_loss: 0.057| r_loss: 0.045| p_loss: 0.059| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.546
Train: Epoch [2914/3000], Step [90/158]| g_loss: 0.680| d_loss: 0.661| gp_loss: 0.061| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.329 | a_loss: 0.553
Train: Epoch [2914/3000], Step [120/158]| g_loss: 0.623| d_loss: 0.728| gp_loss: 0.063| r_loss: 0.046| p_loss: 0.062| v_loss: 0.018| per_loss: 0.310 | a_loss: 0.496
Train: Epoch [2914/3000], Step [150/158]| g_loss: 0.672| d_loss: 0.567| gp_loss: 0.067| r_loss: 0.048| p_loss: 0.062| v_loss: 0.020| per_loss: 0.332 | a_loss: 0.541
Train: Epoch [2915/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.756| gp_loss: 0.168| r_loss: 0.049| p_loss: 0.068| v_loss: 0.020| per_loss: 0.338 | a_loss: 0.527
Train: Epoch [2915/3000], Step [60/158]| g_loss: 0.612| d_loss: 0.630| gp_loss: 0.061| r_loss: 0.047| p_loss: 0.066| v_loss: 0.019| per_loss: 0.318 | a_loss: 0.481
Train: Epoch [2915/3000], Step [90/158]| g_loss: 0.647| d_loss: 0.660| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.339 | a_loss: 0.514
Train: Epoch [2915/3000], Step [120/158]| g_loss: 0.701| d_loss: 0.509| gp_loss: 0.062| r_loss: 0.049| p_loss: 0.064| v_loss: 0.020| per_loss: 0.325 | a_loss: 0.568
Train: Epoch [2915/3000], Step [150/158]| g_loss: 0.688| d_loss: 0.566| gp_loss: 0.062| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.328 | a_loss: 0.561
Train: Epoch [2916/3000], Step [30/158]| g_loss: 0.647| d_loss: 0.742| gp_loss: 0.134| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.518
Train: Epoch [2916/3000], Step [60/158]| g_loss: 0.645| d_loss: 0.594| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.518
Train: Epoch [2916/3000], Step [90/158]| g_loss: 0.654| d_loss: 0.630| gp_loss: 0.058| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.334 | a_loss: 0.523
Train: Epoch [2916/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.575| gp_loss: 0.063| r_loss: 0.047| p_loss: 0.059| v_loss: 0.018| per_loss: 0.312 | a_loss: 0.541
Train: Epoch [2916/3000], Step [150/158]| g_loss: 0.668| d_loss: 0.615| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.063| v_loss: 0.020| per_loss: 0.353 | a_loss: 0.534
Train: Epoch [2917/3000], Step [30/158]| g_loss: 0.704| d_loss: 0.711| gp_loss: 0.194| r_loss: 0.049| p_loss: 0.066| v_loss: 0.020| per_loss: 0.331 | a_loss: 0.570
Train: Epoch [2917/3000], Step [60/158]| g_loss: 0.668| d_loss: 0.605| gp_loss: 0.051| r_loss: 0.047| p_loss: 0.061| v_loss: 0.018| per_loss: 0.302 | a_loss: 0.542
Train: Epoch [2917/3000], Step [90/158]| g_loss: 0.658| d_loss: 0.675| gp_loss: 0.051| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.525
Train: Epoch [2917/3000], Step [120/158]| g_loss: 0.654| d_loss: 0.574| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.523
Train: Epoch [2917/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.635| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.334 | a_loss: 0.543
Train: Epoch [2918/3000], Step [30/158]| g_loss: 0.618| d_loss: 0.753| gp_loss: 0.138| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.325 | a_loss: 0.483
Train: Epoch [2918/3000], Step [60/158]| g_loss: 0.684| d_loss: 0.558| gp_loss: 0.056| r_loss: 0.047| p_loss: 0.062| v_loss: 0.020| per_loss: 0.326 | a_loss: 0.554
Train: Epoch [2918/3000], Step [90/158]| g_loss: 0.641| d_loss: 0.655| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.331 | a_loss: 0.509
Train: Epoch [2918/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.551| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.548
Train: Epoch [2918/3000], Step [150/158]| g_loss: 0.683| d_loss: 0.594| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.323 | a_loss: 0.552
Train: Epoch [2919/3000], Step [30/158]| g_loss: 0.704| d_loss: 0.714| gp_loss: 0.197| r_loss: 0.050| p_loss: 0.064| v_loss: 0.020| per_loss: 0.335 | a_loss: 0.569
Train: Epoch [2919/3000], Step [60/158]| g_loss: 0.680| d_loss: 0.562| gp_loss: 0.051| r_loss: 0.047| p_loss: 0.056| v_loss: 0.018| per_loss: 0.309 | a_loss: 0.556
Train: Epoch [2919/3000], Step [90/158]| g_loss: 0.675| d_loss: 0.608| gp_loss: 0.053| r_loss: 0.045| p_loss: 0.059| v_loss: 0.018| per_loss: 0.320 | a_loss: 0.550
Train: Epoch [2919/3000], Step [120/158]| g_loss: 0.617| d_loss: 0.622| gp_loss: 0.052| r_loss: 0.045| p_loss: 0.056| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.494
Train: Epoch [2919/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.596| gp_loss: 0.059| r_loss: 0.044| p_loss: 0.055| v_loss: 0.018| per_loss: 0.307 | a_loss: 0.542
Train: Epoch [2920/3000], Step [30/158]| g_loss: 0.637| d_loss: 0.758| gp_loss: 0.153| r_loss: 0.045| p_loss: 0.058| v_loss: 0.019| per_loss: 0.313 | a_loss: 0.512
Train: Epoch [2920/3000], Step [60/158]| g_loss: 0.676| d_loss: 0.537| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.058| v_loss: 0.019| per_loss: 0.324 | a_loss: 0.550
Train: Epoch [2920/3000], Step [90/158]| g_loss: 0.643| d_loss: 0.724| gp_loss: 0.052| r_loss: 0.044| p_loss: 0.057| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.521
Train: Epoch [2920/3000], Step [120/158]| g_loss: 0.643| d_loss: 0.581| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.059| v_loss: 0.019| per_loss: 0.328 | a_loss: 0.515
Train: Epoch [2920/3000], Step [150/158]| g_loss: 0.652| d_loss: 0.654| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.057| v_loss: 0.018| per_loss: 0.310 | a_loss: 0.526
Train: Epoch [2921/3000], Step [30/158]| g_loss: 0.644| d_loss: 0.871| gp_loss: 0.302| r_loss: 0.045| p_loss: 0.057| v_loss: 0.018| per_loss: 0.322 | a_loss: 0.520
Train: Epoch [2921/3000], Step [60/158]| g_loss: 0.645| d_loss: 0.636| gp_loss: 0.047| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.318 | a_loss: 0.519
Train: Epoch [2921/3000], Step [90/158]| g_loss: 0.643| d_loss: 0.597| gp_loss: 0.048| r_loss: 0.048| p_loss: 0.061| v_loss: 0.020| per_loss: 0.315 | a_loss: 0.513
Train: Epoch [2921/3000], Step [120/158]| g_loss: 0.655| d_loss: 0.585| gp_loss: 0.050| r_loss: 0.046| p_loss: 0.057| v_loss: 0.019| per_loss: 0.312 | a_loss: 0.531
Train: Epoch [2921/3000], Step [150/158]| g_loss: 0.662| d_loss: 0.610| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.314 | a_loss: 0.536
Train: Epoch [2922/3000], Step [30/158]| g_loss: 0.664| d_loss: 0.707| gp_loss: 0.148| r_loss: 0.046| p_loss: 0.056| v_loss: 0.019| per_loss: 0.323 | a_loss: 0.540
Train: Epoch [2922/3000], Step [60/158]| g_loss: 0.648| d_loss: 0.576| gp_loss: 0.050| r_loss: 0.047| p_loss: 0.057| v_loss: 0.019| per_loss: 0.328 | a_loss: 0.522
Train: Epoch [2922/3000], Step [90/158]| g_loss: 0.667| d_loss: 0.554| gp_loss: 0.052| r_loss: 0.043| p_loss: 0.055| v_loss: 0.018| per_loss: 0.302 | a_loss: 0.547
Train: Epoch [2922/3000], Step [120/158]| g_loss: 0.661| d_loss: 0.637| gp_loss: 0.053| r_loss: 0.044| p_loss: 0.058| v_loss: 0.018| per_loss: 0.307 | a_loss: 0.538
Train: Epoch [2922/3000], Step [150/158]| g_loss: 0.610| d_loss: 0.670| gp_loss: 0.056| r_loss: 0.045| p_loss: 0.055| v_loss: 0.018| per_loss: 0.307 | a_loss: 0.487
Train: Epoch [2923/3000], Step [30/158]| g_loss: 0.682| d_loss: 0.631| gp_loss: 0.128| r_loss: 0.046| p_loss: 0.058| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.556
Train: Epoch [2923/3000], Step [60/158]| g_loss: 0.717| d_loss: 0.540| gp_loss: 0.054| r_loss: 0.045| p_loss: 0.056| v_loss: 0.018| per_loss: 0.309 | a_loss: 0.594
Train: Epoch [2923/3000], Step [90/158]| g_loss: 0.623| d_loss: 0.698| gp_loss: 0.049| r_loss: 0.045| p_loss: 0.060| v_loss: 0.019| per_loss: 0.329 | a_loss: 0.496
Train: Epoch [2923/3000], Step [120/158]| g_loss: 0.664| d_loss: 0.627| gp_loss: 0.052| r_loss: 0.046| p_loss: 0.058| v_loss: 0.018| per_loss: 0.333 | a_loss: 0.538
Train: Epoch [2923/3000], Step [150/158]| g_loss: 0.646| d_loss: 0.631| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.059| v_loss: 0.018| per_loss: 0.312 | a_loss: 0.520
Train: Epoch [2924/3000], Step [30/158]| g_loss: 0.624| d_loss: 0.767| gp_loss: 0.139| r_loss: 0.047| p_loss: 0.064| v_loss: 0.019| per_loss: 0.318 | a_loss: 0.494
Train: Epoch [2924/3000], Step [60/158]| g_loss: 0.649| d_loss: 0.610| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.329 | a_loss: 0.517
Train: Epoch [2924/3000], Step [90/158]| g_loss: 0.638| d_loss: 0.628| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.508
Train: Epoch [2924/3000], Step [120/158]| g_loss: 0.642| d_loss: 0.599| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.059| v_loss: 0.019| per_loss: 0.318 | a_loss: 0.514
Train: Epoch [2924/3000], Step [150/158]| g_loss: 0.706| d_loss: 0.545| gp_loss: 0.059| r_loss: 0.046| p_loss: 0.058| v_loss: 0.019| per_loss: 0.322 | a_loss: 0.580
Train: Epoch [2925/3000], Step [30/158]| g_loss: 0.654| d_loss: 0.731| gp_loss: 0.186| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.525
Train: Epoch [2925/3000], Step [60/158]| g_loss: 0.638| d_loss: 0.673| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.333 | a_loss: 0.509
Train: Epoch [2925/3000], Step [90/158]| g_loss: 0.615| d_loss: 0.651| gp_loss: 0.053| r_loss: 0.044| p_loss: 0.058| v_loss: 0.018| per_loss: 0.320 | a_loss: 0.491
Train: Epoch [2925/3000], Step [120/158]| g_loss: 0.696| d_loss: 0.554| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.328 | a_loss: 0.569
Train: Epoch [2925/3000], Step [150/158]| g_loss: 0.678| d_loss: 0.585| gp_loss: 0.058| r_loss: 0.046| p_loss: 0.057| v_loss: 0.018| per_loss: 0.326 | a_loss: 0.552
Train: Epoch [2926/3000], Step [30/158]| g_loss: 0.638| d_loss: 0.845| gp_loss: 0.175| r_loss: 0.044| p_loss: 0.059| v_loss: 0.018| per_loss: 0.323 | a_loss: 0.514
Train: Epoch [2926/3000], Step [60/158]| g_loss: 0.597| d_loss: 0.688| gp_loss: 0.050| r_loss: 0.044| p_loss: 0.058| v_loss: 0.018| per_loss: 0.338 | a_loss: 0.472
Train: Epoch [2926/3000], Step [90/158]| g_loss: 0.639| d_loss: 0.530| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.056| v_loss: 0.019| per_loss: 0.307 | a_loss: 0.516
Train: Epoch [2926/3000], Step [120/158]| g_loss: 0.680| d_loss: 0.541| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.058| v_loss: 0.018| per_loss: 0.311 | a_loss: 0.556
Train: Epoch [2926/3000], Step [150/158]| g_loss: 0.680| d_loss: 0.565| gp_loss: 0.055| r_loss: 0.047| p_loss: 0.057| v_loss: 0.019| per_loss: 0.348 | a_loss: 0.551
Train: Epoch [2927/3000], Step [30/158]| g_loss: 0.711| d_loss: 0.668| gp_loss: 0.133| r_loss: 0.047| p_loss: 0.059| v_loss: 0.018| per_loss: 0.305 | a_loss: 0.585
Train: Epoch [2927/3000], Step [60/158]| g_loss: 0.652| d_loss: 0.628| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.332 | a_loss: 0.524
Train: Epoch [2927/3000], Step [90/158]| g_loss: 0.661| d_loss: 0.621| gp_loss: 0.054| r_loss: 0.044| p_loss: 0.055| v_loss: 0.018| per_loss: 0.325 | a_loss: 0.539
Train: Epoch [2927/3000], Step [120/158]| g_loss: 0.670| d_loss: 0.612| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.332 | a_loss: 0.537
Train: Epoch [2927/3000], Step [150/158]| g_loss: 0.669| d_loss: 0.588| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.340 | a_loss: 0.539
Train: Epoch [2928/3000], Step [30/158]| g_loss: 0.657| d_loss: 0.673| gp_loss: 0.167| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.327 | a_loss: 0.527
Train: Epoch [2928/3000], Step [60/158]| g_loss: 0.677| d_loss: 0.659| gp_loss: 0.051| r_loss: 0.052| p_loss: 0.066| v_loss: 0.019| per_loss: 0.336 | a_loss: 0.540
Train: Epoch [2928/3000], Step [90/158]| g_loss: 0.651| d_loss: 0.653| gp_loss: 0.053| r_loss: 0.050| p_loss: 0.066| v_loss: 0.019| per_loss: 0.334 | a_loss: 0.516
Train: Epoch [2928/3000], Step [120/158]| g_loss: 0.652| d_loss: 0.594| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.063| v_loss: 0.020| per_loss: 0.323 | a_loss: 0.520
Train: Epoch [2928/3000], Step [150/158]| g_loss: 0.708| d_loss: 0.627| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.063| v_loss: 0.019| per_loss: 0.345 | a_loss: 0.576
Train: Epoch [2929/3000], Step [30/158]| g_loss: 0.641| d_loss: 0.738| gp_loss: 0.161| r_loss: 0.048| p_loss: 0.060| v_loss: 0.018| per_loss: 0.326 | a_loss: 0.512
Train: Epoch [2929/3000], Step [60/158]| g_loss: 0.661| d_loss: 0.645| gp_loss: 0.053| r_loss: 0.052| p_loss: 0.066| v_loss: 0.019| per_loss: 0.334 | a_loss: 0.523
Train: Epoch [2929/3000], Step [90/158]| g_loss: 0.682| d_loss: 0.545| gp_loss: 0.054| r_loss: 0.052| p_loss: 0.066| v_loss: 0.019| per_loss: 0.337 | a_loss: 0.544
Train: Epoch [2929/3000], Step [120/158]| g_loss: 0.684| d_loss: 0.591| gp_loss: 0.051| r_loss: 0.049| p_loss: 0.062| v_loss: 0.019| per_loss: 0.340 | a_loss: 0.551
Train: Epoch [2929/3000], Step [150/158]| g_loss: 0.631| d_loss: 0.654| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.061| v_loss: 0.018| per_loss: 0.322 | a_loss: 0.504
Train: Epoch [2930/3000], Step [30/158]| g_loss: 0.655| d_loss: 0.702| gp_loss: 0.188| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.343 | a_loss: 0.522
Train: Epoch [2930/3000], Step [60/158]| g_loss: 0.668| d_loss: 0.683| gp_loss: 0.048| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.341 | a_loss: 0.536
Train: Epoch [2930/3000], Step [90/158]| g_loss: 0.644| d_loss: 0.618| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.057| v_loss: 0.018| per_loss: 0.316 | a_loss: 0.519
Train: Epoch [2930/3000], Step [120/158]| g_loss: 0.629| d_loss: 0.682| gp_loss: 0.051| r_loss: 0.047| p_loss: 0.059| v_loss: 0.019| per_loss: 0.336 | a_loss: 0.501
Train: Epoch [2930/3000], Step [150/158]| g_loss: 0.658| d_loss: 0.530| gp_loss: 0.055| r_loss: 0.044| p_loss: 0.056| v_loss: 0.019| per_loss: 0.316 | a_loss: 0.535
Train: Epoch [2931/3000], Step [30/158]| g_loss: 0.666| d_loss: 0.703| gp_loss: 0.139| r_loss: 0.045| p_loss: 0.058| v_loss: 0.019| per_loss: 0.323 | a_loss: 0.541
Train: Epoch [2931/3000], Step [60/158]| g_loss: 0.664| d_loss: 0.565| gp_loss: 0.051| r_loss: 0.047| p_loss: 0.061| v_loss: 0.020| per_loss: 0.353 | a_loss: 0.532
Train: Epoch [2931/3000], Step [90/158]| g_loss: 0.659| d_loss: 0.648| gp_loss: 0.052| r_loss: 0.047| p_loss: 0.058| v_loss: 0.018| per_loss: 0.312 | a_loss: 0.534
Train: Epoch [2931/3000], Step [120/158]| g_loss: 0.627| d_loss: 0.650| gp_loss: 0.053| r_loss: 0.051| p_loss: 0.061| v_loss: 0.019| per_loss: 0.331 | a_loss: 0.494
Train: Epoch [2931/3000], Step [150/158]| g_loss: 0.678| d_loss: 0.545| gp_loss: 0.057| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.325 | a_loss: 0.548
Train: Epoch [2932/3000], Step [30/158]| g_loss: 0.688| d_loss: 0.687| gp_loss: 0.144| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.324 | a_loss: 0.556
Train: Epoch [2932/3000], Step [60/158]| g_loss: 0.685| d_loss: 0.641| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.327 | a_loss: 0.557
Train: Epoch [2932/3000], Step [90/158]| g_loss: 0.619| d_loss: 0.656| gp_loss: 0.052| r_loss: 0.046| p_loss: 0.061| v_loss: 0.018| per_loss: 0.318 | a_loss: 0.492
Train: Epoch [2932/3000], Step [120/158]| g_loss: 0.631| d_loss: 0.630| gp_loss: 0.055| r_loss: 0.048| p_loss: 0.062| v_loss: 0.020| per_loss: 0.340 | a_loss: 0.498
Train: Epoch [2932/3000], Step [150/158]| g_loss: 0.691| d_loss: 0.511| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.335 | a_loss: 0.560
Train: Epoch [2933/3000], Step [30/158]| g_loss: 0.709| d_loss: 0.610| gp_loss: 0.117| r_loss: 0.048| p_loss: 0.061| v_loss: 0.020| per_loss: 0.342 | a_loss: 0.577
Train: Epoch [2933/3000], Step [60/158]| g_loss: 0.663| d_loss: 0.624| gp_loss: 0.051| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.327 | a_loss: 0.532
Train: Epoch [2933/3000], Step [90/158]| g_loss: 0.684| d_loss: 0.532| gp_loss: 0.054| r_loss: 0.045| p_loss: 0.062| v_loss: 0.019| per_loss: 0.328 | a_loss: 0.557
Train: Epoch [2933/3000], Step [120/158]| g_loss: 0.657| d_loss: 0.636| gp_loss: 0.057| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.327 | a_loss: 0.529
Train: Epoch [2933/3000], Step [150/158]| g_loss: 0.633| d_loss: 0.679| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.061| v_loss: 0.018| per_loss: 0.326 | a_loss: 0.503
Train: Epoch [2934/3000], Step [30/158]| g_loss: 0.625| d_loss: 0.815| gp_loss: 0.213| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.333 | a_loss: 0.495
Train: Epoch [2934/3000], Step [60/158]| g_loss: 0.669| d_loss: 0.611| gp_loss: 0.053| r_loss: 0.049| p_loss: 0.060| v_loss: 0.019| per_loss: 0.334 | a_loss: 0.537
Train: Epoch [2934/3000], Step [90/158]| g_loss: 0.662| d_loss: 0.560| gp_loss: 0.053| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.535
Train: Epoch [2934/3000], Step [120/158]| g_loss: 0.650| d_loss: 0.639| gp_loss: 0.055| r_loss: 0.045| p_loss: 0.057| v_loss: 0.018| per_loss: 0.332 | a_loss: 0.525
Train: Epoch [2934/3000], Step [150/158]| g_loss: 0.649| d_loss: 0.616| gp_loss: 0.055| r_loss: 0.044| p_loss: 0.057| v_loss: 0.018| per_loss: 0.331 | a_loss: 0.525
Train: Epoch [2935/3000], Step [30/158]| g_loss: 0.647| d_loss: 0.709| gp_loss: 0.161| r_loss: 0.050| p_loss: 0.063| v_loss: 0.019| per_loss: 0.346 | a_loss: 0.511
Train: Epoch [2935/3000], Step [60/158]| g_loss: 0.650| d_loss: 0.629| gp_loss: 0.052| r_loss: 0.046| p_loss: 0.059| v_loss: 0.018| per_loss: 0.306 | a_loss: 0.526
Train: Epoch [2935/3000], Step [90/158]| g_loss: 0.688| d_loss: 0.530| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.061| v_loss: 0.019| per_loss: 0.327 | a_loss: 0.559
Train: Epoch [2935/3000], Step [120/158]| g_loss: 0.716| d_loss: 0.555| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.343 | a_loss: 0.585
Train: Epoch [2935/3000], Step [150/158]| g_loss: 0.628| d_loss: 0.688| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.067| v_loss: 0.019| per_loss: 0.326 | a_loss: 0.496
Train: Epoch [2936/3000], Step [30/158]| g_loss: 0.643| d_loss: 0.733| gp_loss: 0.121| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.327 | a_loss: 0.514
Train: Epoch [2936/3000], Step [60/158]| g_loss: 0.652| d_loss: 0.556| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.060| v_loss: 0.019| per_loss: 0.343 | a_loss: 0.521
Train: Epoch [2936/3000], Step [90/158]| g_loss: 0.676| d_loss: 0.625| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.061| v_loss: 0.020| per_loss: 0.316 | a_loss: 0.546
Train: Epoch [2936/3000], Step [120/158]| g_loss: 0.607| d_loss: 0.626| gp_loss: 0.059| r_loss: 0.045| p_loss: 0.061| v_loss: 0.019| per_loss: 0.342 | a_loss: 0.479
Train: Epoch [2936/3000], Step [150/158]| g_loss: 0.731| d_loss: 0.564| gp_loss: 0.060| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.345 | a_loss: 0.601
Train: Epoch [2937/3000], Step [30/158]| g_loss: 0.655| d_loss: 0.696| gp_loss: 0.172| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.331 | a_loss: 0.526
Train: Epoch [2937/3000], Step [60/158]| g_loss: 0.689| d_loss: 0.639| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.063| v_loss: 0.019| per_loss: 0.315 | a_loss: 0.560
Train: Epoch [2937/3000], Step [90/158]| g_loss: 0.634| d_loss: 0.647| gp_loss: 0.055| r_loss: 0.046| p_loss: 0.062| v_loss: 0.019| per_loss: 0.333 | a_loss: 0.505
Train: Epoch [2937/3000], Step [120/158]| g_loss: 0.677| d_loss: 0.551| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.059| v_loss: 0.019| per_loss: 0.322 | a_loss: 0.550
Train: Epoch [2937/3000], Step [150/158]| g_loss: 0.633| d_loss: 0.669| gp_loss: 0.054| r_loss: 0.046| p_loss: 0.058| v_loss: 0.018| per_loss: 0.341 | a_loss: 0.505
Train: Epoch [2938/3000], Step [30/158]| g_loss: 0.658| d_loss: 0.656| gp_loss: 0.105| r_loss: 0.047| p_loss: 0.060| v_loss: 0.019| per_loss: 0.323 | a_loss: 0.530
Train: Epoch [2938/3000], Step [60/158]| g_loss: 0.653| d_loss: 0.648| gp_loss: 0.056| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.334 | a_loss: 0.519
Train: Epoch [2938/3000], Step [90/158]| g_loss: 0.670| d_loss: 0.690| gp_loss: 0.061| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.541
Train: Epoch [2938/3000], Step [120/158]| g_loss: 0.634| d_loss: 0.570| gp_loss: 0.064| r_loss: 0.045| p_loss: 0.058| v_loss: 0.018| per_loss: 0.324 | a_loss: 0.509
Train: Epoch [2938/3000], Step [150/158]| g_loss: 0.697| d_loss: 0.541| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.063| v_loss: 0.019| per_loss: 0.350 | a_loss: 0.563
Train: Epoch [2939/3000], Step [30/158]| g_loss: 0.671| d_loss: 0.738| gp_loss: 0.137| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.337 | a_loss: 0.541
Train: Epoch [2939/3000], Step [60/158]| g_loss: 0.640| d_loss: 0.601| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.063| v_loss: 0.018| per_loss: 0.332 | a_loss: 0.509
Train: Epoch [2939/3000], Step [90/158]| g_loss: 0.632| d_loss: 0.713| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.066| v_loss: 0.019| per_loss: 0.318 | a_loss: 0.501
Train: Epoch [2939/3000], Step [120/158]| g_loss: 0.660| d_loss: 0.573| gp_loss: 0.060| r_loss: 0.048| p_loss: 0.065| v_loss: 0.020| per_loss: 0.336 | a_loss: 0.526
Train: Epoch [2939/3000], Step [150/158]| g_loss: 0.676| d_loss: 0.535| gp_loss: 0.061| r_loss: 0.048| p_loss: 0.061| v_loss: 0.020| per_loss: 0.325 | a_loss: 0.545
Train: Epoch [2940/3000], Step [30/158]| g_loss: 0.704| d_loss: 0.706| gp_loss: 0.224| r_loss: 0.047| p_loss: 0.066| v_loss: 0.020| per_loss: 0.334 | a_loss: 0.570
Train: Epoch [2940/3000], Step [60/158]| g_loss: 0.670| d_loss: 0.649| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.065| v_loss: 0.018| per_loss: 0.309 | a_loss: 0.541
Train: Epoch [2940/3000], Step [90/158]| g_loss: 0.688| d_loss: 0.620| gp_loss: 0.057| r_loss: 0.048| p_loss: 0.064| v_loss: 0.020| per_loss: 0.345 | a_loss: 0.553
Train: Epoch [2940/3000], Step [120/158]| g_loss: 0.633| d_loss: 0.645| gp_loss: 0.053| r_loss: 0.048| p_loss: 0.064| v_loss: 0.019| per_loss: 0.336 | a_loss: 0.501
Train: Epoch [2940/3000], Step [150/158]| g_loss: 0.693| d_loss: 0.596| gp_loss: 0.058| r_loss: 0.048| p_loss: 0.062| v_loss: 0.019| per_loss: 0.323 | a_loss: 0.562
Train: Epoch [2941/3000], Step [30/158]| g_loss: 0.662| d_loss: 0.688| gp_loss: 0.128| r_loss: 0.045| p_loss: 0.060| v_loss: 0.018| per_loss: 0.312 | a_loss: 0.538
Train: Epoch [2941/3000], Step [60/158]| g_loss: 0.665| d_loss: 0.600| gp_loss: 0.050| r_loss: 0.045| p_loss: 0.058| v_loss: 0.019| per_loss: 0.342 | a_loss: 0.538
Train: Epoch [2941/3000], Step [90/158]| g_loss: 0.656| d_loss: 0.576| gp_loss: 0.053| r_loss: 0.047| p_loss: 0.057| v_loss: 0.019| per_loss: 0.334 | a_loss: 0.528
Train: Epoch [2941/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.629| gp_loss: 0.056| r_loss: 0.051| p_loss: 0.063| v_loss: 0.019| per_loss: 0.340 | a_loss: 0.531
Train: Epoch [2941/3000], Step [150/158]| g_loss: 0.639| d_loss: 0.636| gp_loss: 0.059| r_loss: 0.050| p_loss: 0.067| v_loss: 0.019| per_loss: 0.321 | a_loss: 0.504
Train: Epoch [2942/3000], Step [30/158]| g_loss: 0.658| d_loss: 0.699| gp_loss: 0.087| r_loss: 0.045| p_loss: 0.063| v_loss: 0.019| per_loss: 0.310 | a_loss: 0.532
Train: Epoch [2942/3000], Step [60/158]| g_loss: 0.630| d_loss: 0.679| gp_loss: 0.059| r_loss: 0.049| p_loss: 0.065| v_loss: 0.019| per_loss: 0.330 | a_loss: 0.496
Train: Epoch [2942/3000], Step [90/158]| g_loss: 0.613| d_loss: 0.644| gp_loss: 0.062| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.318 | a_loss: 0.485
Train: Epoch [2942/3000], Step [120/158]| g_loss: 0.666| d_loss: 0.586| gp_loss: 0.064| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.339 | a_loss: 0.533
Train: Epoch [2942/3000], Step [150/158]| g_loss: 0.702| d_loss: 0.543| gp_loss: 0.064| r_loss: 0.049| p_loss: 0.062| v_loss: 0.020| per_loss: 0.340 | a_loss: 0.568
Train: Epoch [2943/3000], Step [30/158]| g_loss: 0.656| d_loss: 0.767| gp_loss: 0.203| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.334 | a_loss: 0.526
Train: Epoch [2943/3000], Step [60/158]| g_loss: 0.649| d_loss: 0.632| gp_loss: 0.057| r_loss: 0.046| p_loss: 0.060| v_loss: 0.019| per_loss: 0.320 | a_loss: 0.522
Train: Epoch [2943/3000], Step [90/158]| g_loss: 0.670| d_loss: 0.645| gp_loss: 0.060| r_loss: 0.047| p_loss: 0.062| v_loss: 0.019| per_loss: 0.341 | a_loss: 0.539
Train: Epoch [2943/3000], Step [120/158]| g_loss: 0.671| d_loss: 0.543| gp_loss: 0.058| r_loss: 0.045| p_loss: 0.058| v_loss: 0.018| per_loss: 0.338 | a_loss: 0.545
Train: Epoch [2943/3000], Step [150/158]| g_loss: 0.675| d_loss: 0.603| gp_loss: 0.056| r_loss: 0.046| p_loss: 0.058| v_loss: 0.019| per_loss: 0.319 | a_loss: 0.549
Train: Epoch [2944/3000], Step [30/158]| g_loss: 0.645| d_loss: 0.839| gp_loss: 0.249| r_loss: 0.047| p_loss: 0.061| v_loss: 0.019| per_loss: 0.311 | a_loss: 0.518
Train: Epoch [2944/3000], Step [60/158]| g_loss: 0.634| d_loss: 0.635| gp_loss: 0.054| r_loss: 0.045| p_loss: 0.060| v_loss: 0.018| per_loss: 0.335 | a_loss: 0.508
Train: Epoch [2944/3000], Step [90/158]| g_loss: 0.623| d_loss: 0.614| gp_loss: 0.050| r_loss: 0.043| p_loss: 0.056| v_loss: 0.018| per_loss: 0.329 | a_loss: 0.501
Train: Epoch [2944/3000], Step [120/158]| g_loss: 0.667| d_loss: 0.580| gp_loss: 0.054| r_loss: 0.047| p_loss: 0.059| v_loss: 0.019| per_loss: 0.315 | a_loss: 0.539
Train: Epoch [2944/3000], Step [150/158]| g_loss: 0.707| d_loss: 0.558| gp_loss: 0.059| r_loss: 0.048| p_loss: 0.062| v_loss: 0.020| per_loss: 0.348 | a_loss: 0.574
Train: Epoch [2945/3000], Step [30/158]| g_loss: 0.673| d_loss: 0.722| gp_loss: 0.142| r_loss: 0.047| p_loss: 0.066| v_loss: 0.020| per_loss: 0.342 | a_loss: 0.539
Train: Epoch [2945/3000], Step [60/158]| g_loss: 0.650| d_loss: 0.645| gp_loss: 0.052| r_loss: 0.045| p_loss: 0.060| v_loss: 0.019| per_loss: 0.333 | a_loss: 0.523
Train: Epoch [2945/3000], Step [90/158]| g_loss: 0.627| d_loss: 0.596| gp_loss: 0.053| r_loss: 0.045| p_loss: 0.058| v_loss: 0.018| per_loss: 0.323 | a_loss: 0.502
Train: Epoch [2945/3000], Step [120/158]| g_loss: 0.656| d_loss: 0.652| gp_loss: 0.054| r_loss: 0.049| p_loss: 0.061| v_loss: 0.019| per_loss: 0.338 | a_loss: 0.523
Train: Epoch [2945/3000], Step [150/158]| g_loss: 0.666| d_loss: 0.567| gp_loss: 0.056| r_loss: 0.049| p_loss: 0.064| v_loss: 0.019| per_loss: 0.343 | a_loss: 0.532
Train: Epoch [2946/3000], Step [30/158]| g_loss: 0.663| d_loss: 0.737| gp_loss: 0.135| r_loss: 0.048| p_loss: 0.063| v_loss: 0.018| per_loss: 0.321 | a_loss: 0.533
Train: Epoch [2946/3000], Step [60/158]| g_loss: 0.688| d_loss: 0.482| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.328 | a_loss: 0.556
Train: Epoch [2946/3000], Step [90/158]| g_loss: 0.668| d_loss: 0.614| gp_loss: 0.055| r_loss: 0.049| p_loss: 0.063| v_loss: 0.019| per_loss: 0.317 | a_loss: 0.536
